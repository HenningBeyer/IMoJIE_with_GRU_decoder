python allennlp_script.py --param_path imojie/configs/imojie_gru.json --mode test --s models/imojie_gru_bs8_cd0
[?2004l{'<arg1>': '[unused1]', '</arg1>': '[unused2]', '<rel>': '[unused3]', '</rel>': '[unused4]', '<arg2>': '[unused5]', '</arg2>': '[unused6]', 'SENT': '[unused7]', 'PRED': '[unused8]', '@COPY@': '[unused9]', 'EOE': '[unused10]'}
/u/hbeyer/anaconda3/envs/imojie/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.
  warnings.warn(message, FutureWarning)
============== GENERATING OUTPUTS ==============
5
6
2021-12-31 19:49:39,722 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-12-31 19:49:39,740 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-12-31 19:49:40,058 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-12-31 19:49:40,060 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-12-31 19:49:40,073 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-12-31 19:49:40,076 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-12-31 19:49:40,562 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
2021-12-31 19:49:40,563 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
2021-12-31 19:49:40,564 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
2021-12-31 19:49:40,564 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
{'<arg1>': '[unused1]', '</arg1>': '[unused2]', '<rel>': '[unused3]', '</rel>': '[unused4]', '<arg2>': '[unused5]', '</arg2>': '[unused6]', 'SENT': '[unused7]', 'PRED': '[unused8]', '@COPY@': '[unused9]', 'EOE': '[unused10]'}
/u/hbeyer/anaconda3/envs/imojie/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.
  warnings.warn(message, FutureWarning)
2021-12-31 19:49:40,651 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
2021-12-31 19:49:40,652 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
2021-12-31 19:49:40,653 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
2021-12-31 19:49:40,653 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
2021-12-31 19:49:40,721 - INFO - allennlp.models.archival - loading archive file models/imojie_gru_bs8_cd0
{'<arg1>': '[unused1]', '</arg1>': '[unused2]', '<rel>': '[unused3]', '</rel>': '[unused4]', '<arg2>': '[unused5]', '</arg2>': '[unused6]', 'SENT': '[unused7]', 'PRED': '[unused8]', '@COPY@': '[unused9]', 'EOE': '[unused10]'}
/u/hbeyer/anaconda3/envs/imojie/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.
  warnings.warn(message, FutureWarning)
2021-12-31 19:49:40,746 - INFO - allennlp.common.registrable - instantiating registered subclass copy_seq2seq_bahdanu of <class 'allennlp.models.model.Model'>
2021-12-31 19:49:40,746 - INFO - allennlp.common.params - vocabulary.type = default
2021-12-31 19:49:40,746 - INFO - allennlp.common.registrable - instantiating registered subclass default of <class 'allennlp.data.vocabulary.Vocabulary'>
2021-12-31 19:49:40,746 - INFO - allennlp.data.vocabulary - Loading token dictionary from models/imojie_gru_bs8_cd0/vocabulary.
2021-12-31 19:49:40,748 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'target_namespace': 'bert', 'attention': {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'}, 'source_embedder': {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}}, 'type': 'copy_seq2seq_bahdanu', 'decoder_layers': 1, 'target_embedding_dim': 100, 'bert': True, 'append': True, 'max_decoding_steps': 50, 'decoder_type': 'gru', 'max_extractions': 10, 'token_based_metric': {'dev_set': 'dev', 'type': 'carb'}, 'encoder': {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'}, 'source_namespace': 'bert', 'beam_size': 1} and extras {'vocab'}
2021-12-31 19:49:40,748 - INFO - allennlp.common.params - model.type = copy_seq2seq_bahdanu
2021-12-31 19:49:40,748 - INFO - allennlp.common.from_params - instantiating class <class 'imojie.models.copy_seq2seq_bahdanu.CopyNetSeq2Seq'> from params {'target_namespace': 'bert', 'attention': {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'}, 'source_embedder': {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}}, 'decoder_layers': 1, 'target_embedding_dim': 100, 'bert': True, 'append': True, 'max_decoding_steps': 50, 'decoder_type': 'gru', 'max_extractions': 10, 'token_based_metric': {'dev_set': 'dev', 'type': 'carb'}, 'encoder': {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'}, 'source_namespace': 'bert', 'beam_size': 1} and extras {'vocab'}
2021-12-31 19:49:40,748 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}} and extras {'vocab'}
2021-12-31 19:49:40,748 - INFO - allennlp.common.params - model.source_embedder.type = basic
2021-12-31 19:49:40,748 - INFO - allennlp.common.params - model.source_embedder.embedder_to_indexer_map = None
2021-12-31 19:49:40,748 - INFO - allennlp.common.params - model.source_embedder.allow_unmatched_keys = False
2021-12-31 19:49:40,748 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'} and extras {'vocab'}
2021-12-31 19:49:40,748 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.type = pretrained_transformer
2021-12-31 19:49:40,749 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'bert-base-cased', 'requires_grad': True} and extras {'vocab'}
2021-12-31 19:49:40,749 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.model_name = bert-base-cased
2021-12-31 19:49:40,749 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.requires_grad = True
2021-12-31 19:49:40,755 - INFO - allennlp.models.archival - loading archive file models/imojie_gru_bs8_cd0
2021-12-31 19:49:40,780 - INFO - allennlp.common.registrable - instantiating registered subclass copy_seq2seq_bahdanu of <class 'allennlp.models.model.Model'>
2021-12-31 19:49:40,781 - INFO - allennlp.common.params - vocabulary.type = default
2021-12-31 19:49:40,781 - INFO - allennlp.common.registrable - instantiating registered subclass default of <class 'allennlp.data.vocabulary.Vocabulary'>
2021-12-31 19:49:40,781 - INFO - allennlp.data.vocabulary - Loading token dictionary from models/imojie_gru_bs8_cd0/vocabulary.
2021-12-31 19:49:40,782 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'source_embedder': {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}}, 'type': 'copy_seq2seq_bahdanu', 'target_embedding_dim': 100, 'append': True, 'bert': True, 'source_namespace': 'bert', 'encoder': {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'}, 'token_based_metric': {'dev_set': 'dev', 'type': 'carb'}, 'decoder_type': 'gru', 'max_decoding_steps': 50, 'decoder_layers': 1, 'attention': {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'}, 'target_namespace': 'bert', 'max_extractions': 10, 'beam_size': 1} and extras {'vocab'}
2021-12-31 19:49:40,782 - INFO - allennlp.common.params - model.type = copy_seq2seq_bahdanu
2021-12-31 19:49:40,782 - INFO - allennlp.common.from_params - instantiating class <class 'imojie.models.copy_seq2seq_bahdanu.CopyNetSeq2Seq'> from params {'source_embedder': {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}}, 'target_embedding_dim': 100, 'append': True, 'bert': True, 'source_namespace': 'bert', 'encoder': {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'}, 'token_based_metric': {'dev_set': 'dev', 'type': 'carb'}, 'decoder_type': 'gru', 'max_decoding_steps': 50, 'decoder_layers': 1, 'attention': {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'}, 'target_namespace': 'bert', 'max_extractions': 10, 'beam_size': 1} and extras {'vocab'}
2021-12-31 19:49:40,782 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}} and extras {'vocab'}
2021-12-31 19:49:40,782 - INFO - allennlp.common.params - model.source_embedder.type = basic
2021-12-31 19:49:40,782 - INFO - allennlp.common.params - model.source_embedder.embedder_to_indexer_map = None
2021-12-31 19:49:40,782 - INFO - allennlp.common.params - model.source_embedder.allow_unmatched_keys = False
2021-12-31 19:49:40,782 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'} and extras {'vocab'}
2021-12-31 19:49:40,782 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.type = pretrained_transformer
2021-12-31 19:49:40,783 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'bert-base-cased', 'requires_grad': True} and extras {'vocab'}
2021-12-31 19:49:40,783 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.model_name = bert-base-cased
2021-12-31 19:49:40,783 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.requires_grad = True
2021-12-31 19:49:41,228 - INFO - pytorch_transformers.modeling_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /u/hbeyer/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-12-31 19:49:41,228 - INFO - pytorch_transformers.modeling_utils - Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

2021-12-31 19:49:41,257 - INFO - pytorch_transformers.modeling_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /u/hbeyer/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-12-31 19:49:41,258 - INFO - pytorch_transformers.modeling_utils - Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

2021-12-31 19:49:41,711 - INFO - pytorch_transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /u/hbeyer/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-12-31 19:49:41,728 - INFO - pytorch_transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /u/hbeyer/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-12-31 19:49:43,671 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'} and extras {'vocab'}
2021-12-31 19:49:43,671 - INFO - allennlp.common.params - model.encoder.type = feedforward
2021-12-31 19:49:43,671 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.feedforward_encoder.FeedForwardEncoder'> from params {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}} and extras {'vocab'}
2021-12-31 19:49:43,671 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}
2021-12-31 19:49:43,671 - INFO - allennlp.common.params - model.encoder.feedforward.input_dim = 768
2021-12-31 19:49:43,671 - INFO - allennlp.common.params - model.encoder.feedforward.num_layers = 1
2021-12-31 19:49:43,672 - INFO - allennlp.common.params - model.encoder.feedforward.hidden_dims = [256]
2021-12-31 19:49:43,672 - INFO - allennlp.common.params - model.encoder.feedforward.hidden_dims = [256]
2021-12-31 19:49:43,672 - INFO - allennlp.common.params - model.encoder.feedforward.activations = ['relu']
2021-12-31 19:49:43,672 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params ['relu'] and extras {'vocab'}
2021-12-31 19:49:43,672 - INFO - allennlp.common.params - model.encoder.feedforward.activations = ['relu']
2021-12-31 19:49:43,672 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params relu and extras {'vocab'}
2021-12-31 19:49:43,672 - INFO - allennlp.common.params - type = relu
2021-12-31 19:49:43,672 - INFO - allennlp.common.params - model.encoder.feedforward.dropout = 0.1
2021-12-31 19:49:43,674 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.attention.attention.Attention'> from params {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'} and extras {'vocab'}
2021-12-31 19:49:43,674 - INFO - allennlp.common.params - model.attention.type = linear
2021-12-31 19:49:43,674 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.attention.linear_attention.LinearAttention'> from params {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256'} and extras {'vocab'}
2021-12-31 19:49:43,674 - INFO - allennlp.common.params - model.attention.tensor_1_dim = 256
2021-12-31 19:49:43,674 - INFO - allennlp.common.params - model.attention.tensor_2_dim = 256
2021-12-31 19:49:43,674 - INFO - allennlp.common.params - model.attention.combination = x,y
2021-12-31 19:49:43,674 - INFO - allennlp.common.params - model.attention.activation = tanh
2021-12-31 19:49:43,674 - INFO - allennlp.common.registrable - instantiating registered subclass tanh of <class 'allennlp.nn.activations.Activation'>
2021-12-31 19:49:43,674 - INFO - allennlp.common.params - model.attention.normalize = True
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.beam_size = 1
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.max_decoding_steps = 50
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.target_embedding_dim = 100
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.decoder_layers = 1
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.copy_token = @COPY@
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.source_namespace = bert
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.target_namespace = bert
2021-12-31 19:49:43,675 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.training.metrics.metric.Metric'> from params {'dev_set': 'dev', 'type': 'carb'} and extras {'vocab'}
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.token_based_metric.type = carb
2021-12-31 19:49:43,675 - INFO - allennlp.common.from_params - instantiating class <class 'imojie.carb_metric.Carb'> from params {'dev_set': 'dev'} and extras {'vocab'}
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.token_based_metric.dev_set = dev
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.lambda_diversity = 5
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.beam_search_type = beam_search
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.bert = True
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.append = True
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.coverage = False
2021-12-31 19:49:43,675 - INFO - allennlp.common.params - model.max_extractions = 10
2021-12-31 19:49:43,676 - INFO - allennlp.common.params - model.decoder_config = 
2021-12-31 19:49:43,676 - INFO - allennlp.common.params - model.decoder_type = gru
2021-12-31 19:49:43,676 - INFO - allennlp.common.params - model.teacher_forcing = True
2021-12-31 19:49:43,689 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'} and extras {'vocab'}
2021-12-31 19:49:43,690 - INFO - allennlp.common.params - model.encoder.type = feedforward
2021-12-31 19:49:43,690 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.feedforward_encoder.FeedForwardEncoder'> from params {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}} and extras {'vocab'}
2021-12-31 19:49:43,690 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}
2021-12-31 19:49:43,690 - INFO - allennlp.common.params - model.encoder.feedforward.input_dim = 768
2021-12-31 19:49:43,690 - INFO - allennlp.common.params - model.encoder.feedforward.num_layers = 1
2021-12-31 19:49:43,690 - INFO - allennlp.common.params - model.encoder.feedforward.hidden_dims = [256]
2021-12-31 19:49:43,690 - INFO - allennlp.common.params - model.encoder.feedforward.hidden_dims = [256]
2021-12-31 19:49:43,690 - INFO - allennlp.common.params - model.encoder.feedforward.activations = ['relu']
2021-12-31 19:49:43,691 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params ['relu'] and extras {'vocab'}
2021-12-31 19:49:43,691 - INFO - allennlp.common.params - model.encoder.feedforward.activations = ['relu']
2021-12-31 19:49:43,691 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params relu and extras {'vocab'}
2021-12-31 19:49:43,691 - INFO - allennlp.common.params - type = relu
2021-12-31 19:49:43,691 - INFO - allennlp.common.params - model.encoder.feedforward.dropout = 0.1
2021-12-31 19:49:43,693 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.attention.attention.Attention'> from params {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'} and extras {'vocab'}
2021-12-31 19:49:43,693 - INFO - allennlp.common.params - model.attention.type = linear
2021-12-31 19:49:43,693 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.attention.linear_attention.LinearAttention'> from params {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256'} and extras {'vocab'}
2021-12-31 19:49:43,693 - INFO - allennlp.common.params - model.attention.tensor_1_dim = 256
2021-12-31 19:49:43,693 - INFO - allennlp.common.params - model.attention.tensor_2_dim = 256
2021-12-31 19:49:43,693 - INFO - allennlp.common.params - model.attention.combination = x,y
2021-12-31 19:49:43,693 - INFO - allennlp.common.params - model.attention.activation = tanh
2021-12-31 19:49:43,693 - INFO - allennlp.common.registrable - instantiating registered subclass tanh of <class 'allennlp.nn.activations.Activation'>
2021-12-31 19:49:43,693 - INFO - allennlp.common.params - model.attention.normalize = True
2021-12-31 19:49:43,693 - INFO - allennlp.common.params - model.beam_size = 1
2021-12-31 19:49:43,693 - INFO - allennlp.common.params - model.max_decoding_steps = 50
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.target_embedding_dim = 100
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.decoder_layers = 1
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.copy_token = @COPY@
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.source_namespace = bert
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.target_namespace = bert
2021-12-31 19:49:43,694 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.training.metrics.metric.Metric'> from params {'dev_set': 'dev', 'type': 'carb'} and extras {'vocab'}
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.token_based_metric.type = carb
2021-12-31 19:49:43,694 - INFO - allennlp.common.from_params - instantiating class <class 'imojie.carb_metric.Carb'> from params {'dev_set': 'dev'} and extras {'vocab'}
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.token_based_metric.dev_set = dev
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.lambda_diversity = 5
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.beam_search_type = beam_search
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.bert = True
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.append = True
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.coverage = False
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.max_extractions = 10
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.decoder_config = 
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.decoder_type = gru
2021-12-31 19:49:43,694 - INFO - allennlp.common.params - model.teacher_forcing = True
2021-12-31 19:49:43,743 - INFO - allennlp.nn.initializers - Initializing parameters
2021-12-31 19:49:43,744 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-12-31 19:49:43,744 - INFO - allennlp.nn.initializers -    _attention._bias
2021-12-31 19:49:43,744 - INFO - allennlp.nn.initializers -    _attention._weight_vector
2021-12-31 19:49:43,744 - INFO - allennlp.nn.initializers -    _decoder_cell.bias_hh_l0
2021-12-31 19:49:43,744 - INFO - allennlp.nn.initializers -    _decoder_cell.bias_ih_l0
2021-12-31 19:49:43,744 - INFO - allennlp.nn.initializers -    _decoder_cell.weight_hh_l0
2021-12-31 19:49:43,744 - INFO - allennlp.nn.initializers -    _decoder_cell.weight_ih_l0
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _encoder._feedforward._linear_layers.0.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _encoder._feedforward._linear_layers.0.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _input_projection_layer.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _input_projection_layer.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _output_copying_layer.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _output_copying_layer.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _output_generation_layer.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _output_generation_layer.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2021-12-31 19:49:43,745 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2021-12-31 19:49:43,746 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2021-12-31 19:49:43,747 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2021-12-31 19:49:43,748 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2021-12-31 19:49:43,749 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2021-12-31 19:49:43,750 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2021-12-31 19:49:43,750 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2021-12-31 19:49:43,750 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2021-12-31 19:49:43,750 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2021-12-31 19:49:43,750 - INFO - allennlp.nn.initializers -    _target_embedder.weight
2021-12-31 19:49:43,750 - INFO - root - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.
2021-12-31 19:49:43,762 - INFO - allennlp.nn.initializers - Initializing parameters
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _attention._bias
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _attention._weight_vector
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _decoder_cell.bias_hh_l0
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _decoder_cell.bias_ih_l0
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _decoder_cell.weight_hh_l0
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _decoder_cell.weight_ih_l0
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _encoder._feedforward._linear_layers.0.bias
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _encoder._feedforward._linear_layers.0.weight
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _input_projection_layer.bias
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _input_projection_layer.weight
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _output_copying_layer.bias
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _output_copying_layer.weight
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _output_generation_layer.bias
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _output_generation_layer.weight
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2021-12-31 19:49:43,763 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2021-12-31 19:49:43,764 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2021-12-31 19:49:43,765 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2021-12-31 19:49:43,766 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2021-12-31 19:49:43,767 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2021-12-31 19:49:43,768 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2021-12-31 19:49:43,768 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2021-12-31 19:49:43,768 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2021-12-31 19:49:43,768 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2021-12-31 19:49:43,768 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2021-12-31 19:49:43,768 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2021-12-31 19:49:43,768 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2021-12-31 19:49:43,768 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2021-12-31 19:49:43,768 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2021-12-31 19:49:43,768 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2021-12-31 19:49:43,768 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2021-12-31 19:49:43,768 - INFO - allennlp.nn.initializers -    _target_embedder.weight
2021-12-31 19:49:43,768 - INFO - root - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.
############################################################
############################################################
############################################################
2021-12-31 19:49:47,546 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'bert': True, 'lazy': True, 'max_extractions': 10, 'max_tokens': 500, 'source_token_indexers': {'tokens': {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'}}, 'source_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'target_namespace': 'bert', 'target_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'type': 'copy_seq2multiseq', 'validation': True} and extras set()
2021-12-31 19:49:47,546 - INFO - allennlp.common.params - validation_dataset_reader.type = copy_seq2multiseq
2021-12-31 19:49:47,547 - INFO - allennlp.common.from_params - instantiating class <class 'imojie.dataset_readers.copy_seq2multiseq.CopySeq2MultiSeqNetDatasetReader'> from params {'bert': True, 'lazy': True, 'max_extractions': 10, 'max_tokens': 500, 'source_token_indexers': {'tokens': {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'}}, 'source_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'target_namespace': 'bert', 'target_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'validation': True} and extras set()
2021-12-31 19:49:47,547 - INFO - allennlp.common.params - validation_dataset_reader.target_namespace = bert
2021-12-31 19:49:47,547 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'} and extras set()
2021-12-31 19:49:47,547 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.type = pretrained_transformer
2021-12-31 19:49:47,547 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': []} and extras set()
2021-12-31 19:49:47,547 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.model_name = bert-base-cased
2021-12-31 19:49:47,547 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.do_lowercase = False
2021-12-31 19:49:47,547 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.start_tokens = []
2021-12-31 19:49:47,547 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.end_tokens = []
############################################################
############################################################
############################################################
2021-12-31 19:49:47,565 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'bert': True, 'lazy': True, 'max_extractions': 10, 'max_tokens': 500, 'source_token_indexers': {'tokens': {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'}}, 'source_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'target_namespace': 'bert', 'target_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'type': 'copy_seq2multiseq', 'validation': True} and extras set()
2021-12-31 19:49:47,566 - INFO - allennlp.common.params - validation_dataset_reader.type = copy_seq2multiseq
2021-12-31 19:49:47,566 - INFO - allennlp.common.from_params - instantiating class <class 'imojie.dataset_readers.copy_seq2multiseq.CopySeq2MultiSeqNetDatasetReader'> from params {'bert': True, 'lazy': True, 'max_extractions': 10, 'max_tokens': 500, 'source_token_indexers': {'tokens': {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'}}, 'source_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'target_namespace': 'bert', 'target_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'validation': True} and extras set()
2021-12-31 19:49:47,566 - INFO - allennlp.common.params - validation_dataset_reader.target_namespace = bert
2021-12-31 19:49:47,566 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'} and extras set()
2021-12-31 19:49:47,566 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.type = pretrained_transformer
2021-12-31 19:49:47,566 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': []} and extras set()
2021-12-31 19:49:47,566 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.model_name = bert-base-cased
2021-12-31 19:49:47,566 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.do_lowercase = False
2021-12-31 19:49:47,566 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.start_tokens = []
2021-12-31 19:49:47,566 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.end_tokens = []
2021-12-31 19:49:48,021 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /u/hbeyer/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-12-31 19:49:48,024 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /u/hbeyer/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-12-31 19:49:48,182 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'} and extras set()
2021-12-31 19:49:48,182 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.type = pretrained_transformer
2021-12-31 19:49:48,182 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': []} and extras set()
2021-12-31 19:49:48,182 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.model_name = bert-base-cased
2021-12-31 19:49:48,182 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.do_lowercase = False
2021-12-31 19:49:48,182 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.start_tokens = []
2021-12-31 19:49:48,182 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.end_tokens = []
2021-12-31 19:49:48,193 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'} and extras set()
2021-12-31 19:49:48,193 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.type = pretrained_transformer
2021-12-31 19:49:48,193 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': []} and extras set()
2021-12-31 19:49:48,193 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.model_name = bert-base-cased
2021-12-31 19:49:48,193 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.do_lowercase = False
2021-12-31 19:49:48,193 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.start_tokens = []
2021-12-31 19:49:48,193 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.end_tokens = []
2021-12-31 19:49:48,640 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /u/hbeyer/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-12-31 19:49:48,651 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /u/hbeyer/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-12-31 19:49:48,690 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'} and extras set()
2021-12-31 19:49:48,690 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.type = pretrained_transformer
2021-12-31 19:49:48,691 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert'} and extras set()
2021-12-31 19:49:48,691 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.model_name = bert-base-cased
2021-12-31 19:49:48,691 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.do_lowercase = False
2021-12-31 19:49:48,691 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.namespace = bert
2021-12-31 19:49:48,691 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.token_min_padding_length = 0
2021-12-31 19:49:48,705 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'} and extras set()
2021-12-31 19:49:48,705 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.type = pretrained_transformer
2021-12-31 19:49:48,705 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert'} and extras set()
2021-12-31 19:49:48,705 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.model_name = bert-base-cased
2021-12-31 19:49:48,705 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.do_lowercase = False
2021-12-31 19:49:48,705 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.namespace = bert
2021-12-31 19:49:48,705 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.token_min_padding_length = 0
2021-12-31 19:49:49,162 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /u/hbeyer/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-12-31 19:49:49,177 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /u/hbeyer/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-12-31 19:49:49,225 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 0
2021-12-31 19:49:49,225 - INFO - allennlp.common.params - validation_dataset_reader.lazy = True
2021-12-31 19:49:49,225 - INFO - allennlp.common.params - validation_dataset_reader.max_tokens = 500
2021-12-31 19:49:49,226 - INFO - allennlp.common.params - validation_dataset_reader.bert = True
2021-12-31 19:49:49,226 - INFO - allennlp.common.params - validation_dataset_reader.max_extractions = 10
2021-12-31 19:49:49,226 - INFO - allennlp.common.params - validation_dataset_reader.dev_path = None
2021-12-31 19:49:49,226 - INFO - allennlp.common.params - validation_dataset_reader.min_confidence = None
2021-12-31 19:49:49,226 - INFO - allennlp.common.params - validation_dataset_reader.max_confidence = None
2021-12-31 19:49:49,226 - INFO - allennlp.common.params - validation_dataset_reader.extraction_ratio = 1
2021-12-31 19:49:49,226 - INFO - allennlp.common.params - validation_dataset_reader.validation = True
2021-12-31 19:49:49,226 - INFO - allennlp.common.params - validation_dataset_reader.gradients = True
2021-12-31 19:49:49,226 - INFO - allennlp.common.params - validation_dataset_reader.append_test = False
2021-12-31 19:49:49,226 - INFO - allennlp.common.params - validation_dataset_reader.probability = False
2021-12-31 19:49:49,226 - INFO - allennlp.common.params - validation_dataset_reader.order_sentences = 
2021-12-31 19:49:49,228 - INFO - allennlp.common.registrable - instantiating registered subclass noie_seq2seq of <class 'allennlp.predictors.predictor.Predictor'>
Starting prediction
2021-12-31 19:49:49,244 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 0
2021-12-31 19:49:49,244 - INFO - allennlp.common.params - validation_dataset_reader.lazy = True
2021-12-31 19:49:49,245 - INFO - allennlp.common.params - validation_dataset_reader.max_tokens = 500
2021-12-31 19:49:49,245 - INFO - allennlp.common.params - validation_dataset_reader.bert = True
2021-12-31 19:49:49,245 - INFO - allennlp.common.params - validation_dataset_reader.max_extractions = 10
2021-12-31 19:49:49,245 - INFO - allennlp.common.params - validation_dataset_reader.dev_path = None
2021-12-31 19:49:49,245 - INFO - allennlp.common.params - validation_dataset_reader.min_confidence = None
2021-12-31 19:49:49,245 - INFO - allennlp.common.params - validation_dataset_reader.max_confidence = None
2021-12-31 19:49:49,245 - INFO - allennlp.common.params - validation_dataset_reader.extraction_ratio = 1
2021-12-31 19:49:49,245 - INFO - allennlp.common.params - validation_dataset_reader.validation = True
2021-12-31 19:49:49,245 - INFO - allennlp.common.params - validation_dataset_reader.gradients = True
2021-12-31 19:49:49,245 - INFO - allennlp.common.params - validation_dataset_reader.append_test = False
2021-12-31 19:49:49,245 - INFO - allennlp.common.params - validation_dataset_reader.probability = False
2021-12-31 19:49:49,245 - INFO - allennlp.common.params - validation_dataset_reader.order_sentences = 
2021-12-31 19:49:49,247 - INFO - allennlp.common.registrable - instantiating registered subclass noie_seq2seq of <class 'allennlp.predictors.predictor.Predictor'>
Starting prediction
Decodertime : 0.00041103363037109375
Decodertime : 0.0003368854522705078
g_f_logprobs : 0.09198284149169922
Decodertime : 0.00018930435180664062
g_f_logprobs : 0.06528520584106445
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.0663301944732666
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.0649862289428711
Decodertime : 0.00014209747314453125
g_f_logprobs : 0.06624197959899902
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.06512880325317383
Decodertime : 0.0001423358917236328
g_f_logprobs : 0.06595182418823242
Decodertime : 0.000171661376953125
g_f_logprobs : 0.06514787673950195
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.06719088554382324
Decodertime : 0.000213623046875
g_f_logprobs : 0.06519269943237305
Decodertime : 0.0001964569091796875
g_f_logprobs : 0.06546807289123535
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.06550836563110352
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.0660090446472168
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.06493639945983887
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.06779336929321289
Decodertime : 0.00019669532775878906
g_f_logprobs : 0.06357192993164062
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.06608939170837402
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.06621384620666504
Decodertime : 0.00019311904907226562
g_f_logprobs : 0.06603717803955078
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.06508827209472656
Decodertime : 0.00014281272888183594
g_f_logprobs : 0.06614160537719727
g_f_logprobs : 0.06388711929321289
Decodertime : 0.00017976760864257812
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.06484723091125488
g_f_logprobs : 0.06636762619018555
Decodertime : 0.00014710426330566406
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.06580829620361328
g_f_logprobs : 0.06528520584106445
Decodertime : 0.00014591217041015625
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.06553864479064941
g_f_logprobs : 0.06563448905944824
Decodertime : 0.00014543533325195312
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.06605267524719238
g_f_logprobs : 0.06507015228271484
Decodertime : 0.0001437664031982422
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.06580352783203125
g_f_logprobs : 0.06525516510009766
Decodertime : 0.00014448165893554688
Decodertime : 0.0001690387725830078
g_f_logprobs : 0.06573915481567383
g_f_logprobs : 0.06578731536865234
Decodertime : 0.0001442432403564453
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.0661005973815918
g_f_logprobs : 0.06512045860290527
Decodertime : 0.0001430511474609375
Decodertime : 0.0001728534698486328
g_f_logprobs : 0.06577467918395996
g_f_logprobs : 0.06525278091430664
Decodertime : 0.00014519691467285156
Decodertime : 0.0001678466796875
g_f_logprobs : 0.06561470031738281
g_f_logprobs : 0.0659329891204834
Decodertime : 0.0001494884490966797
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.06561970710754395
Decodertime : 0.00016689300537109375
g_f_logprobs : 0.06427145004272461
Decodertime : 0.0002086162567138672
g_f_logprobs : 0.06530523300170898
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.06560659408569336
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.06505966186523438
Decodertime : 0.00013399124145507812
g_f_logprobs : 0.06591010093688965
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.06467795372009277
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.06585454940795898
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.06503772735595703
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.06582379341125488
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.0651559829711914
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.06572556495666504
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.06460404396057129
Decodertime : 0.00014400482177734375
g_f_logprobs : 0.06614422798156738
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.06503653526306152
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.06580424308776855
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.06516313552856445
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.06576275825500488
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.06478214263916016
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.06629300117492676
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.06502699851989746
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.06575608253479004
Decodertime : 0.000156402587890625
g_f_logprobs : 0.06516337394714355
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.0657355785369873
Decodertime : 0.000152587890625
g_f_logprobs : 0.06467700004577637
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.06637191772460938
Decodertime : 0.000217437744140625
g_f_logprobs : 0.0650472640991211
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.06593847274780273
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.06483101844787598
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.06641745567321777
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.06512784957885742
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.06580615043640137
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.06511116027832031
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.06573653221130371
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.06505298614501953
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.06578326225280762
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.0645303726196289
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.06623339653015137
Decodertime : 0.00018978118896484375
g_f_logprobs : 0.06490612030029297
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.06595253944396973
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.06480813026428223
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.06565308570861816
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.06526494026184082
Decodertime : 0.00021123886108398438
g_f_logprobs : 0.06581354141235352
Decodertime : 0.00017786026000976562
g_f_logprobs : 0.0649867057800293
Decodertime : 0.0001399517059326172
g_f_logprobs : 0.06583094596862793
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.06489133834838867
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.06566786766052246
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.06506156921386719
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.06569957733154297
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.06509685516357422
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.0657799243927002
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.06519031524658203
Decodertime : 0.00014829635620117188
g_f_logprobs : 0.06585144996643066
Decodertime : 0.00018334388732910156
g_f_logprobs : 0.06508851051330566
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.06575965881347656
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.06506681442260742
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.06581687927246094
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.06510019302368164
beam_search_time: 3.3465476036071777 s
g_f_logprobs : 0.16954994201660156
beam_search_time: 3.539214611053467 s
Decodertime : 0.0001773834228515625
Decodertime : 0.00020313262939453125
g_f_logprobs : 0.21224617958068848
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.10561656951904297
Decodertime : 0.0003008842468261719
g_f_logprobs : 0.09701085090637207
Decodertime : 0.00020694732666015625
g_f_logprobs : 0.1060028076171875
Decodertime : 0.00017642974853515625
g_f_logprobs : 0.09647822380065918
Decodertime : 0.00014209747314453125
g_f_logprobs : 0.10616207122802734
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.09646415710449219
Decodertime : 0.0001347064971923828
g_f_logprobs : 0.09536027908325195
Decodertime : 0.00014090538024902344
g_f_logprobs : 0.10779333114624023
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.09636640548706055
Decodertime : 0.00017595291137695312
g_f_logprobs : 0.1067347526550293
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.09644746780395508
Decodertime : 0.00014209747314453125
g_f_logprobs : 0.10616064071655273
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.09646129608154297
Decodertime : 0.00014257431030273438
g_f_logprobs : 0.10618352890014648
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.09651827812194824
Decodertime : 0.00013971328735351562
g_f_logprobs : 0.10617327690124512
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.09681296348571777
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.10634469985961914
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.09674692153930664
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.10630249977111816
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.09645557403564453
Decodertime : 0.00014066696166992188
g_f_logprobs : 0.10625171661376953
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.09657049179077148
Decodertime : 0.0001862049102783203
g_f_logprobs : 0.10611367225646973
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.09644842147827148
Decodertime : 0.00013375282287597656
g_f_logprobs : 0.10660767555236816
g_f_logprobs : 0.0950934886932373
Decodertime : 0.0001971721649169922
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.09623122215270996
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.10845518112182617
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.0965585708618164
Decodertime : 0.000133514404296875
g_f_logprobs : 0.10618782043457031
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.09656596183776855
Decodertime : 0.00013589859008789062
g_f_logprobs : 0.10619759559631348
Decodertime : 0.000152587890625
g_f_logprobs : 0.09585881233215332
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.10715985298156738
Decodertime : 0.0002200603485107422
g_f_logprobs : 0.09624409675598145
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.10622501373291016
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.09681344032287598
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.10637664794921875
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.0967862606048584
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.10635709762573242
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.09644389152526855
Decodertime : 0.00014138221740722656
g_f_logprobs : 0.10620903968811035
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.09695219993591309
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.10642528533935547
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.09642815589904785
Decodertime : 0.0001347064971923828
g_f_logprobs : 0.0953829288482666
Decodertime : 0.00014448165893554688
g_f_logprobs : 0.10781526565551758
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.0959324836730957
Decodertime : 0.00014162063598632812
g_f_logprobs : 0.10723257064819336
Decodertime : 0.0001914501190185547
g_f_logprobs : 0.09619665145874023
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.10634517669677734
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.09643411636352539
Decodertime : 0.0001347064971923828
g_f_logprobs : 0.10616374015808105
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.09680390357971191
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.10634565353393555
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.0964505672454834
Decodertime : 0.000148773193359375
g_f_logprobs : 0.10613512992858887
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.09650111198425293
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.10614156723022461
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.09654378890991211
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.10619235038757324
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.09692525863647461
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.10656285285949707
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.09721899032592773
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.09520435333251953
g_f_logprobs : 0.10656499862670898
Decodertime : 0.00014019012451171875
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.09746694564819336
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.10747194290161133
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.09662961959838867
Decodertime : 0.0001480579376220703
g_f_logprobs : 0.10607337951660156
Decodertime : 0.000202178955078125
g_f_logprobs : 0.0966026782989502
Decodertime : 0.00014781951904296875
g_f_logprobs : 0.10624408721923828
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.09675979614257812
Decodertime : 0.0002033710479736328
g_f_logprobs : 0.10569310188293457
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.09678196907043457
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.10627007484436035
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.09642291069030762
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.10613417625427246
Decodertime : 0.00017499923706054688
g_f_logprobs : 0.09667754173278809
Decodertime : 0.0001480579376220703
g_f_logprobs : 0.10614323616027832
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.09656214714050293
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10614180564880371
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.0964806079864502
Decodertime : 0.0001430511474609375
g_f_logprobs : 0.106170654296875
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.09656524658203125
Decodertime : 0.0001480579376220703
g_f_logprobs : 0.09535598754882812
Decodertime : 0.00014781951904296875
g_f_logprobs : 0.10620832443237305
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.09744524955749512
Decodertime : 0.0001709461212158203
g_f_logprobs : 0.1063394546508789
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.09640121459960938
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.10618162155151367
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.09657764434814453
beam_search_time: 5.027152061462402 s
g_f_logprobs : 0.1880660057067871
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.4303708076477051
Decodertime : 0.00016450881958007812
Decodertime : 0.00017952919006347656
g_f_logprobs : 0.1021268367767334
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.13359999656677246
Decodertime : 0.00014495849609375
g_f_logprobs : 0.10587453842163086
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.13354706764221191
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.10647964477539062
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.13283753395080566
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.10641169548034668
beam_search_time: 5.827946186065674 s
g_f_logprobs : 0.5249052047729492
Decodertime : 0.00015878677368164062
Decodertime : 0.00018358230590820312
g_f_logprobs : 0.1282062530517578
Decodertime : 0.0002052783966064453
g_f_logprobs : 0.12844514846801758
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.1328880786895752
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.12812376022338867
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.12549304962158203
g_f_logprobs : 0.13387393951416016
Decodertime : 0.00018405914306640625
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.12873482704162598
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.13452458381652832
Decodertime : 0.00014829635620117188
g_f_logprobs : 0.12784075736999512
Decodertime : 0.00017642974853515625
g_f_logprobs : 0.1333937644958496
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.12789058685302734
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.13346505165100098
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.12795734405517578
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.13344478607177734
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.12784600257873535
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.13377118110656738
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.12836670875549316
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.13354921340942383
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.12855195999145508
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.13390612602233887
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.12807202339172363
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.13331389427185059
Decodertime : 0.00014829635620117188
g_f_logprobs : 0.12798619270324707
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.1337602138519287
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.12819433212280273
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.13380837440490723
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.12815499305725098
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.13355302810668945
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.12790751457214355
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.13364624977111816
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.12795543670654297
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.13343596458435059
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.12793684005737305
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.1334514617919922
Decodertime : 0.00014090538024902344
g_f_logprobs : 0.12801408767700195
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.13367772102355957
Decodertime : 0.0001480579376220703
g_f_logprobs : 0.12800359725952148
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.13335633277893066
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.12780547142028809
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.13294672966003418
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.12834858894348145
Decodertime : 0.00021910667419433594
g_f_logprobs : 0.13334965705871582
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.12817764282226562
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.13353371620178223
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.12795472145080566
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.13344907760620117
Decodertime : 0.0001480579376220703
g_f_logprobs : 0.12780022621154785
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.13337993621826172
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.12784838676452637
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.13344645500183105
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.1278226375579834
Decodertime : 0.0001747608184814453
g_f_logprobs : 0.1329352855682373
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.12803006172180176
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.13345670700073242
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.12635087966918945
Decodertime : 0.00016021728515625
g_f_logprobs : 0.12543797492980957
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.13503122329711914
Decodertime : 0.0001480579376220703
g_f_logprobs : 0.12805390357971191
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.13345861434936523
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.1280074119567871
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.13359546661376953
Decodertime : 0.000148773193359375
g_f_logprobs : 0.12864112854003906
Decodertime : 0.000152587890625
g_f_logprobs : 0.1335279941558838
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.12935829162597656
Decodertime : 0.00019407272338867188
g_f_logprobs : 0.13405632972717285
Decodertime : 0.000148773193359375
g_f_logprobs : 0.12825226783752441
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.13327932357788086
Decodertime : 0.000148773193359375
g_f_logprobs : 0.12846016883850098
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.13339447975158691
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.12845325469970703
Decodertime : 0.00017404556274414062
g_f_logprobs : 0.13408803939819336
Decodertime : 0.000202178955078125
g_f_logprobs : 0.12764477729797363
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.1338033676147461
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.12810373306274414
Decodertime : 0.000152587890625
g_f_logprobs : 0.13338994979858398
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.12839055061340332
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.13334155082702637
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.128434419631958
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.13328957557678223
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.12830018997192383
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.13363409042358398
Decodertime : 0.00014781951904296875
g_f_logprobs : 0.12804961204528809
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.1336500644683838
Decodertime : 0.00014781951904296875
g_f_logprobs : 0.1280348300933838
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.1335916519165039
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.1280214786529541
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.13342070579528809
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.12792086601257324
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.13320112228393555
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.12818002700805664
beam_search_time: 5.982353210449219 s
g_f_logprobs : 0.45633721351623535
Decodertime : 0.00017833709716796875
Decodertime : 0.00019025802612304688
g_f_logprobs : 0.30414366722106934
beam_search_time: 7.647255897521973 s
g_f_logprobs : 0.6798830032348633
Decodertime : 0.0002143383026123047
Decodertime : 0.000164031982421875
g_f_logprobs : 0.17117905616760254
Decodertime : 0.0001728534698486328
g_f_logprobs : 0.17021727561950684
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.16546392440795898
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.17041659355163574
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.16608929634094238
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.16977787017822266
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.16619086265563965
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.1698448657989502
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.16609930992126465
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.16988635063171387
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.1660919189453125
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.17007970809936523
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.16594409942626953
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.16974496841430664
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.165910005569458
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.16968321800231934
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.16591787338256836
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.16968750953674316
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.1657857894897461
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.16963815689086914
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.16602396965026855
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.16999340057373047
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.16594362258911133
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.16977548599243164
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.16603708267211914
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.17003250122070312
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.16597795486450195
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.16988897323608398
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.1657390594482422
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.1697697639465332
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.16574740409851074
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.16968584060668945
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.16559934616088867
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.16963982582092285
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.16574430465698242
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.16985177993774414
Decodertime : 0.0001823902130126953
g_f_logprobs : 0.16583895683288574
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.16971230506896973
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.16575288772583008
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.16956567764282227
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.16569137573242188
Decodertime : 0.0001761913299560547
g_f_logprobs : 0.1698451042175293
Decodertime : 0.0001480579376220703
g_f_logprobs : 0.16575860977172852
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.16977524757385254
Decodertime : 0.00014829635620117188
g_f_logprobs : 0.16548871994018555
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.16940832138061523
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.16564345359802246
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.16957449913024902
Decodertime : 0.000148773193359375
g_f_logprobs : 0.16585421562194824
Decodertime : 0.0001690387725830078
g_f_logprobs : 0.16911530494689941
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.16596627235412598
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.16960358619689941
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.16571784019470215
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.16319680213928223
g_f_logprobs : 0.16981029510498047
Decodertime : 0.0001742839813232422
Decodertime : 0.00014162063598632812
g_f_logprobs : 0.16680383682250977
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.17164945602416992
Decodertime : 0.000152587890625
g_f_logprobs : 0.16623759269714355
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.17009806632995605
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.1661360263824463
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.1699824333190918
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.16637945175170898
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.1701812744140625
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.16629457473754883
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.1702711582183838
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.16612648963928223
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.17006444931030273
Decodertime : 0.000148773193359375
g_f_logprobs : 0.16618061065673828
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.17002201080322266
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.16623735427856445
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.17003750801086426
Decodertime : 0.000148773193359375
g_f_logprobs : 0.16613292694091797
Decodertime : 0.0001964569091796875
g_f_logprobs : 0.16957497596740723
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.16635775566101074
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.1701803207397461
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.16605091094970703
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.16986656188964844
Decodertime : 0.0001480579376220703
g_f_logprobs : 0.1660017967224121
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.17041754722595215
Decodertime : 0.00017118453979492188
g_f_logprobs : 0.1662428379058838
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.17012882232666016
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.16598868370056152
Decodertime : 0.0001735687255859375
g_f_logprobs : 0.1700890064239502
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.16614627838134766
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.16987943649291992
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.16582417488098145
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.17011237144470215
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.16616249084472656
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.1701672077178955
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.16593694686889648
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.17003631591796875
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.16592907905578613
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.16996455192565918
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.16594552993774414
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.17002153396606445
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.16585969924926758
beam_search_time: 8.92575216293335 s
g_f_logprobs : 0.18154692649841309
Decodertime : 0.0001430511474609375
g_f_logprobs : 0.7887487411499023
Decodertime : 0.00015735626220703125
Decodertime : 0.000179290771484375
g_f_logprobs : 0.16337013244628906
beam_search_time: 9.205278873443604 s
g_f_logprobs : 0.4017965793609619
Decodertime : 0.0001583099365234375
Decodertime : 0.000156402587890625
g_f_logprobs : 0.6734466552734375
Decodertime : 0.00024771690368652344
g_f_logprobs : 0.21362686157226562
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.20527911186218262
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.2026233673095703
g_f_logprobs : 0.21388483047485352
Decodertime : 0.00013518333435058594
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.20579934120178223
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.21735572814941406
Decodertime : 0.0001430511474609375
g_f_logprobs : 0.20584988594055176
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.2150115966796875
Decodertime : 0.0001342296600341797
g_f_logprobs : 0.2057487964630127
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.21489453315734863
Decodertime : 0.0001354217529296875
g_f_logprobs : 0.20568132400512695
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.21485280990600586
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.20559072494506836
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.2146754264831543
Decodertime : 0.00013518333435058594
g_f_logprobs : 0.20537185668945312
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.2154688835144043
Decodertime : 0.0002040863037109375
g_f_logprobs : 0.20581531524658203
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.21469879150390625
Decodertime : 0.0001342296600341797
g_f_logprobs : 0.20564746856689453
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.21470022201538086
Decodertime : 0.00017309188842773438
g_f_logprobs : 0.20543909072875977
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.2145695686340332
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.20531463623046875
Decodertime : 0.00017571449279785156
g_f_logprobs : 0.21446704864501953
Decodertime : 0.00013518333435058594
g_f_logprobs : 0.20534038543701172
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.21436572074890137
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.20626187324523926
Decodertime : 0.00020813941955566406
g_f_logprobs : 0.2138674259185791
Decodertime : 0.00013518333435058594
g_f_logprobs : 0.20512008666992188
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.21427178382873535
Decodertime : 0.0001342296600341797
g_f_logprobs : 0.20535016059875488
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.2143383026123047
Decodertime : 0.00013446807861328125
g_f_logprobs : 0.2049858570098877
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.21429896354675293
Decodertime : 0.00013494491577148438
g_f_logprobs : 0.20525288581848145
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.21438264846801758
Decodertime : 0.00013446807861328125
g_f_logprobs : 0.2052171230316162
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.2142026424407959
Decodertime : 0.00013589859008789062
g_f_logprobs : 0.20502400398254395
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.2142348289489746
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.2050924301147461
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.21424031257629395
Decodertime : 0.00013518333435058594
g_f_logprobs : 0.20502543449401855
beam_search_time: 5.651633262634277 s
g_f_logprobs : 0.28990817070007324
Decodertime : 0.00019550323486328125
Decodertime : 0.00018930435180664062
g_f_logprobs : 0.7859022617340088
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.226776123046875
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.21468853950500488
Decodertime : 0.00014257431030273438
g_f_logprobs : 0.21262192726135254
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.22820401191711426
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.21434473991394043
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.22554564476013184
Decodertime : 0.00017189979553222656
g_f_logprobs : 0.21426963806152344
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.22477149963378906
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.2142956256866455
Decodertime : 0.00013518333435058594
g_f_logprobs : 0.2248210906982422
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.2144937515258789
Decodertime : 0.00013327598571777344
g_f_logprobs : 0.2249610424041748
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.2143850326538086
Decodertime : 0.00013494491577148438
g_f_logprobs : 0.22482895851135254
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.21448588371276855
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.2250351905822754
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.21447348594665527
Decodertime : 0.0001342296600341797
g_f_logprobs : 0.22496771812438965
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.21451663970947266
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.2250080108642578
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.21459364891052246
Decodertime : 0.0001354217529296875
g_f_logprobs : 0.225144624710083
Decodertime : 0.0001914501190185547
g_f_logprobs : 0.21479415893554688
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.22523212432861328
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.2146286964416504
Decodertime : 0.00014138221740722656
g_f_logprobs : 0.225142240524292
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.21481704711914062
Decodertime : 0.00014162063598632812
g_f_logprobs : 0.22528314590454102
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.21476435661315918
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.22527098655700684
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.21475958824157715
Decodertime : 0.00014257431030273438
g_f_logprobs : 0.22532963752746582
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.21488094329833984
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.22507953643798828
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.21457409858703613
Decodertime : 0.0001404285430908203
g_f_logprobs : 0.22532200813293457
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.21494793891906738
Decodertime : 0.0001373291015625
g_f_logprobs : 0.22548627853393555
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.21500062942504883
Decodertime : 0.00014257431030273438
g_f_logprobs : 0.22556066513061523
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.2148878574371338
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.21259593963623047
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.22790908813476562
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.21419596672058105
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.22472262382507324
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.21425604820251465
beam_search_time: 10.823001146316528 s
g_f_logprobs : 0.23501229286193848
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.8325800895690918
Decodertime : 0.00015425682067871094
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.3681814670562744
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.24143767356872559
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.22514796257019043
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.2413783073425293
Decodertime : 0.00014066696166992188
g_f_logprobs : 0.22506117820739746
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.2411034107208252
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.22547674179077148
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.2410261631011963
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.2247626781463623
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.24103593826293945
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.224639892578125
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.24102449417114258
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.2246866226196289
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.22275042533874512
Decodertime : 0.00018644332885742188
g_f_logprobs : 0.243255615234375
Decodertime : 0.00013589859008789062
g_f_logprobs : 0.22585248947143555
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.24187183380126953
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.22571897506713867
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.24212169647216797
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.2256016731262207
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.24181771278381348
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.2255549430847168
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.24179553985595703
Decodertime : 0.00013518333435058594
g_f_logprobs : 0.2253413200378418
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.24178099632263184
Decodertime : 0.00013446807861328125
g_f_logprobs : 0.22540688514709473
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.24147582054138184
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.2251601219177246
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.24175310134887695
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.2253587245941162
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.24155783653259277
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.22515439987182617
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.24134016036987305
Decodertime : 0.00013971328735351562
g_f_logprobs : 0.22585177421569824
Decodertime : 0.000152587890625
g_f_logprobs : 0.24120068550109863
Decodertime : 0.00014019012451171875
g_f_logprobs : 0.2248232364654541
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.24135541915893555
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.2249433994293213
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.24103665351867676
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.2247152328491211
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.24106645584106445
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.22463488578796387
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.22271060943603516
Decodertime : 0.000152587890625
g_f_logprobs : 0.24376392364501953
Decodertime : 0.0001342296600341797
g_f_logprobs : 0.22568988800048828
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.24193716049194336
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.22556614875793457
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.24188518524169922
Decodertime : 0.00013399124145507812
g_f_logprobs : 0.22561955451965332
beam_search_time: 12.135393381118774 s
g_f_logprobs : 0.43400096893310547
Decodertime : 0.0001461505889892578
Decodertime : 0.0001842975616455078
g_f_logprobs : 0.9204254150390625
Decodertime : 0.00014281272888183594
g_f_logprobs : 0.2702906131744385
Decodertime : 0.000171661376953125
g_f_logprobs : 0.2417006492614746
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.24015212059020996
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.2721219062805176
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.24169564247131348
Decodertime : 0.00014138221740722656
g_f_logprobs : 0.26836180686950684
Decodertime : 0.0001780986785888672
g_f_logprobs : 0.2416372299194336
Decodertime : 0.0001342296600341797
g_f_logprobs : 0.2683403491973877
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.2420024871826172
Decodertime : 0.00013446807861328125
g_f_logprobs : 0.26851701736450195
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.2420365810394287
Decodertime : 0.00013446807861328125
g_f_logprobs : 0.26876354217529297
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.2420504093170166
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.2685658931732178
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.2422647476196289
Decodertime : 0.00013518333435058594
g_f_logprobs : 0.2690260410308838
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.24239182472229004
Decodertime : 0.00014138221740722656
g_f_logprobs : 0.26905322074890137
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.24237608909606934
Decodertime : 0.00014138221740722656
g_f_logprobs : 0.2690002918243408
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.24254250526428223
Decodertime : 0.00013589859008789062
g_f_logprobs : 0.23992443084716797
Decodertime : 0.00014781951904296875
g_f_logprobs : 0.27140212059020996
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.24156498908996582
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.26823925971984863
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.24177885055541992
Decodertime : 0.00013494491577148438
g_f_logprobs : 0.2684614658355713
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.24241018295288086
Decodertime : 0.0001347064971923828
g_f_logprobs : 0.2689478397369385
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.24211955070495605
Decodertime : 0.00013375282287597656
g_f_logprobs : 0.26894640922546387
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.24237799644470215
Decodertime : 0.0001342296600341797
g_f_logprobs : 0.26873159408569336
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.24192190170288086
Decodertime : 0.0001354217529296875
g_f_logprobs : 0.2695803642272949
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.24251198768615723
Decodertime : 0.00013589859008789062
g_f_logprobs : 0.2694075107574463
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.24330615997314453
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.26938939094543457
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.24234867095947266
Decodertime : 0.0001354217529296875
g_f_logprobs : 0.24008655548095703
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.2719542980194092
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.24200201034545898
Decodertime : 0.00013518333435058594
g_f_logprobs : 0.26854705810546875
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.2416219711303711
Decodertime : 0.00013518333435058594
g_f_logprobs : 0.2682018280029297
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.24166131019592285
beam_search_time: 13.058550357818604 s
g_f_logprobs : 0.307633638381958
Decodertime : 0.00016021728515625
g_f_logprobs : 1.144817590713501
Decodertime : 0.0001952648162841797
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.2644515037536621
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.28815150260925293
Decodertime : 0.00014400482177734375
g_f_logprobs : 0.27011728286743164
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.2868385314941406
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.2704436779022217
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.28760814666748047
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.27031397819519043
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.2881355285644531
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.27065229415893555
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.28744959831237793
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.27033495903015137
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.287473201751709
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.2699136734008789
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.2872200012207031
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.27011895179748535
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.286914587020874
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.2712371349334717
Decodertime : 0.00022411346435546875
g_f_logprobs : 0.2870347499847412
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.2694425582885742
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.28679561614990234
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.26947593688964844
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.2868661880493164
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.26949143409729004
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.28641414642333984
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.2700662612915039
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.28687596321105957
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.2694854736328125
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.2674384117126465
g_f_logprobs : 0.2868332862854004
Decodertime : 0.00015878677368164062
Decodertime : 0.00014400482177734375
g_f_logprobs : 0.2699470520019531
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.28989601135253906
Decodertime : 0.00020599365234375
g_f_logprobs : 0.27027201652526855
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.28714966773986816
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.27078890800476074
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.2879934310913086
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.27013206481933594
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.2873806953430176
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.2699282169342041
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.2871067523956299
Decodertime : 0.0001373291015625
g_f_logprobs : 0.2701873779296875
Decodertime : 0.00019884109497070312
g_f_logprobs : 0.28748130798339844
Decodertime : 0.0001373291015625
g_f_logprobs : 0.2699925899505615
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.2877030372619629
Decodertime : 0.00013589859008789062
g_f_logprobs : 0.2703425884246826
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.2872042655944824
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.2698836326599121
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.2871718406677246
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.26990771293640137
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.2877488136291504
Decodertime : 0.0001373291015625
g_f_logprobs : 0.27135801315307617
beam_search_time: 14.501139402389526 s
g_f_logprobs : 1.045682430267334
Decodertime : 0.0001385211944580078
Decodertime : 0.00022554397583007812
g_f_logprobs : 0.38677215576171875
Decodertime : 0.0001437664031982422
g_f_logprobs : 0.271669864654541
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.2868809700012207
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.26951026916503906
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.2871253490447998
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.26987266540527344
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.28690385818481445
Decodertime : 0.00014281272888183594
g_f_logprobs : 0.26949596405029297
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.28801798820495605
Decodertime : 0.00017571449279785156
g_f_logprobs : 0.2705819606781006
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.26703333854675293
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.29030919075012207
Decodertime : 0.00014257431030273438
g_f_logprobs : 0.27060723304748535
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.2875378131866455
Decodertime : 0.00014019012451171875
g_f_logprobs : 0.2704451084136963
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.28763556480407715
Decodertime : 0.00014162063598632812
g_f_logprobs : 0.27035999298095703
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.2875800132751465
beam_search_time: 10.702310800552368 s
g_f_logprobs : 0.7074763774871826
Decodertime : 0.000164031982421875
Decodertime : 0.0001709461212158203
g_f_logprobs : 0.849844217300415
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.2682628631591797
Decodertime : 0.0001735687255859375
g_f_logprobs : 0.31984448432922363
Decodertime : 0.00014328956604003906
g_f_logprobs : 0.2712550163269043
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.31664252281188965
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.27103590965270996
Decodertime : 0.0001685619354248047
g_f_logprobs : 0.31688857078552246
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.270343542098999
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.3160226345062256
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.26981401443481445
Decodertime : 0.0002040863037109375
g_f_logprobs : 0.3158609867095947
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.269946813583374
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.3159902095794678
Decodertime : 0.00014209747314453125
g_f_logprobs : 0.2695577144622803
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.26828598976135254
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.3192253112792969
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.2709200382232666
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.31665968894958496
Decodertime : 0.00014352798461914062
g_f_logprobs : 0.27045178413391113
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.3160834312438965
Decodertime : 0.00014352798461914062
g_f_logprobs : 0.26999759674072266
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.3159818649291992
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.2700014114379883
Decodertime : 0.000156402587890625
g_f_logprobs : 0.3158283233642578
Decodertime : 0.0001418590545654297
g_f_logprobs : 0.2696957588195801
Decodertime : 0.000156402587890625
g_f_logprobs : 0.3158557415008545
Decodertime : 0.0001437664031982422
g_f_logprobs : 0.2695658206939697
Decodertime : 0.000156402587890625
g_f_logprobs : 0.2669343948364258
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.31870198249816895
Decodertime : 0.0001423358917236328
g_f_logprobs : 0.27095556259155273
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.3167836666107178
Decodertime : 0.0001404285430908203
g_f_logprobs : 0.2705411911010742
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.31694746017456055
Decodertime : 0.00014019012451171875
g_f_logprobs : 0.27080750465393066
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.31604957580566406
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.2699587345123291
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.3157672882080078
Decodertime : 0.0001392364501953125
g_f_logprobs : 0.2694716453552246
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.26659727096557617
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.31821107864379883
Decodertime : 0.00014066696166992188
g_f_logprobs : 0.2711813449859619
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.3163876533508301
Decodertime : 0.00014209747314453125
g_f_logprobs : 0.27056264877319336
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.31647205352783203
Decodertime : 0.00014209747314453125
g_f_logprobs : 0.270449161529541
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.31615138053894043
Decodertime : 0.00014209747314453125
g_f_logprobs : 0.27013158798217773
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.3158752918243408
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.27060961723327637
Decodertime : 0.00017786026000976562
g_f_logprobs : 0.316084623336792
Decodertime : 0.00014019012451171875
g_f_logprobs : 0.26997923851013184
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.26687169075012207
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.3192868232727051
Decodertime : 0.000141143798828125
g_f_logprobs : 0.2711751461029053
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.31671857833862305
Decodertime : 0.0001392364501953125
g_f_logprobs : 0.2707209587097168
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.316669225692749
Decodertime : 0.00017452239990234375
g_f_logprobs : 0.2704904079437256
Decodertime : 0.000156402587890625
g_f_logprobs : 0.3160374164581299
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.2697787284851074
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.31594133377075195
Decodertime : 0.00013589859008789062
g_f_logprobs : 0.2699859142303467
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.31575822830200195
Decodertime : 0.0001373291015625
g_f_logprobs : 0.26961684226989746
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.2670111656188965
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.3181033134460449
Decodertime : 0.00013494491577148438
g_f_logprobs : 0.2707490921020508
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.3166036605834961
Decodertime : 0.0001354217529296875
g_f_logprobs : 0.270618200302124
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.31714391708374023
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.270963191986084
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.3168056011199951
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.27051639556884766
beam_search_time: 14.625471115112305 s
g_f_logprobs : 1.1299090385437012
Decodertime : 0.00013828277587890625
Decodertime : 0.0001704692840576172
g_f_logprobs : 0.37136220932006836
Decodertime : 0.00014328956604003906
g_f_logprobs : 0.2713282108306885
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.26654672622680664
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.31849098205566406
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.27091383934020996
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.3168373107910156
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.2706141471862793
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.3163471221923828
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.2701904773712158
Decodertime : 0.000152587890625
g_f_logprobs : 0.3161754608154297
Decodertime : 0.00013494491577148438
g_f_logprobs : 0.27010655403137207
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.31551146507263184
Decodertime : 0.00013518333435058594
g_f_logprobs : 0.2692580223083496
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.31572556495666504
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.2695281505584717
Decodertime : 0.00018310546875
g_f_logprobs : 0.26667118072509766
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.3186073303222656
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.27081871032714844
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.3163883686065674
Decodertime : 0.00013518333435058594
g_f_logprobs : 0.2705233097076416
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.3163895606994629
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.2701711654663086
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.3160851001739502
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.2701582908630371
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.31612706184387207
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.269977331161499
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.26698851585388184
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.3193323612213135
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.2709636688232422
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.3165700435638428
Decodertime : 0.0001373291015625
g_f_logprobs : 0.27052879333496094
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.31644487380981445
Decodertime : 0.0001347064971923828
g_f_logprobs : 0.27068519592285156
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.316317081451416
beam_search_time: 16.80551838874817 s
g_f_logprobs : 0.2645699977874756
Decodertime : 0.0001671314239501953
> [0;32m/home/hbeyer/imojie-master/imojie/models/copy_seq2seq_bahdanu.py[0m(679)[0;36m_encode[0;34m()[0m
[0;32m    678 [0;31m        [0;31m# shape: (batch_size, max_input_sequence_length)[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m--> 679 [0;31m        [0msource_mask[0m [0;34m=[0m [0mutil[0m[0;34m.[0m[0mget_text_field_mask[0m[0;34m([0m[0msource_tokens[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m    680 [0;31m        [0;31m#t1 = time.time()[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0m
ipdb> 
Exiting Debugger.
g_f_logprobs : 0.2649102210998535
beam_search_time: 5.430406332015991 s
Decodertime : 0.00025343894958496094
g_f_logprobs : 0.20720219612121582
Decodertime : 0.00017571449279785156
g_f_logprobs : 0.20555543899536133
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.20612287521362305
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.20608997344970703
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.20567011833190918
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.20562076568603516
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.20504498481750488
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.20534968376159668
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.20592904090881348
Decodertime : 0.00018024444580078125
g_f_logprobs : 0.20543718338012695
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.20566797256469727
Decodertime : 0.000152587890625
g_f_logprobs : 0.20552611351013184
beam_search_time: 2.492846965789795 s
input 0:  {"source": "32.7 % of all households were made up of individuals and 15.7 % had someone living alone who was 65 years of age or older .\n"}
prediction:  {"predictions": [[1, 2724, 28138, 1559, 110, 1104, 1155, 3065, 2, 3, 1127, 1189, 1146, 4, 5, 1104, 2833, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1405, 28138, 1559, 110, 2, 3, 1125, 4, 5, 1800, 1690, 2041, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1800, 1690, 2041, 2, 3, 1129, 1150, 1108, 4, 5, 2625, 1201, 1104, 1425, 1137, 2214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02708885632455349, -0.031023526564240456, -0.06666332483291626, -0.10416984558105469, -0.0865182876586914, -0.0865182876586914, -0.0865182876586914, -0.0865182876586914, -0.0865182876586914, -0.0865182876586914], "metadata": {"source_tokens": ["32", "##.", "##7", "%", "of", "all", "households", "were", "made", "up", "of", "individuals", "and", "15", "##.", "##7", "%", "had", "someone", "living", "alone", "who", "was", "65", "years", "of", "age", "or", "older", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "32", "##.", "##7", "%", "of", "all", "households", "[unused2]", "[unused3]", "were", "made", "up", "[unused4]", "[unused5]", "of", "individuals", "[unused6]", "[SEP]", "[unused1]", "15", "##.", "##7", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "someone", "living", "alone", "[unused6]", "[SEP]", "[unused1]", "someone", "living", "alone", "[unused2]", "[unused3]", "be", "who", "was", "[unused4]", "[unused5]", "65", "years", "of", "age", "or", "older", "[unused6]", "[SEP]"]]}

input 1:  {"source": "A CEN forms an important but small part of a Local Strategic Partnership .\n"}
prediction:  {"predictions": [[1, 138, 9855, 2249, 2, 3, 2769, 4, 5, 1126, 1696, 1133, 1353, 1226, 1104, 170, 5328, 12367, 17330, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-1.743861685099546e-05, -0.019173145294189453, -0.019133567810058594, -0.019133567810058594, -0.019133567810058594, -0.019133567810058594, -0.019133567810058594, -0.019133567810058594, -0.019133567810058594, -0.019133567810058594], "metadata": {"source_tokens": ["A", "CE", "##N", "forms", "an", "important", "but", "small", "part", "of", "a", "Local", "Strategic", "Partnership", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "CE", "##N", "[unused2]", "[unused3]", "forms", "[unused4]", "[unused5]", "an", "important", "but", "small", "part", "of", "a", "Local", "Strategic", "Partnership", "[unused6]", "[SEP]"]]}

input 2:  {"source": "A Democrat , he became the youngest mayor in Pittsburgh 's history in September 2006 at the age of 26 .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1245, 4, 5, 1103, 6074, 4398, 1107, 5610, 112, 1116, 1607, 1107, 1347, 1386, 1120, 1103, 1425, 1104, 1744, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0010923345107585192, -0.12680768966674805, -0.13009071350097656, -0.13009119033813477, -0.13009071350097656, -0.13009119033813477, -0.13009071350097656, -0.13009071350097656, -0.13009071350097656, -0.13009071350097656], "metadata": {"source_tokens": ["A", "Democrat", ",", "he", "became", "the", "youngest", "mayor", "in", "Pittsburgh", "'", "##s", "history", "in", "September", "2006", "at", "the", "age", "of", "26", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "the", "youngest", "mayor", "in", "Pittsburgh", "'", "##s", "history", "in", "September", "2006", "at", "the", "age", "of", "26", "[unused6]", "[SEP]"]]}

input 3:  {"source": "A cafeteria is also located on the sixth floor , a chapel on the 14th floor , and a study hall on the 15th floor .\n"}
prediction:  {"predictions": [[1, 138, 18698, 2, 3, 1110, 1145, 1388, 4, 5, 1113, 1103, 3971, 1837, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03485540300607681, -0.30916690826416016, -0.32679224014282227, -0.32679176330566406, -0.32679224014282227, -0.32679224014282227, -0.32679176330566406, -0.32679176330566406, -0.32679176330566406, -0.32679176330566406], "metadata": {"source_tokens": ["A", "cafeteria", "is", "also", "located", "on", "the", "sixth", "floor", ",", "a", "chapel", "on", "the", "14th", "floor", ",", "and", "a", "study", "hall", "on", "the", "15th", "floor", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "cafeteria", "[unused2]", "[unused3]", "is", "also", "located", "[unused4]", "[unused5]", "on", "the", "sixth", "floor", "[unused6]", "[SEP]"]]}

input 4:  {"source": "A casting director at the time told Scott that he had wished that he 'd met him a week before ; he was casting for the `` G.I. Joe '' cartoon .\n"}
prediction:  {"predictions": [[1, 138, 9616, 1900, 1120, 1103, 1159, 2, 3, 1500, 4, 5, 2796, 1115, 1119, 1125, 5608, 1115, 1119, 112, 1181, 1899, 1140, 170, 1989, 1196, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 9616, 4, 5, 1111, 1103, 169, 28152, 144, 28138, 2240, 28138, 2658, 112, 28131, 11540, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1125, 5608, 4, 5, 1115, 1119, 112, 1181, 1899, 1140, 170, 1989, 1196, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.020572394132614136, -0.029113471508026123, -0.05081777647137642, -0.11426019668579102, -0.14963960647583008, -0.14963960647583008, -0.14963912963867188, -0.14963912963867188, -0.14963912963867188, -0.14963912963867188], "metadata": {"source_tokens": ["A", "casting", "director", "at", "the", "time", "told", "Scott", "that", "he", "had", "wished", "that", "he", "'", "##d", "met", "him", "a", "week", "before", ";", "he", "was", "casting", "for", "the", "`", "##`", "G", "##.", "##I", "##.", "Joe", "'", "##'", "cartoon", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "casting", "director", "at", "the", "time", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "Scott", "that", "he", "had", "wished", "that", "he", "'", "##d", "met", "him", "a", "week", "before", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "casting", "[unused4]", "[unused5]", "for", "the", "`", "##`", "G", "##.", "##I", "##.", "Joe", "'", "##'", "cartoon", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "had", "wished", "[unused4]", "[unused5]", "that", "he", "'", "##d", "met", "him", "a", "week", "before", "[unused6]", "[SEP]"]]}

input 5:  {"source": "A common name , logo , and programming schedule followed in 1982 , with the establishment of the `` TV8 '' network between the three stations , changed to the `` Southern Cross Network '' seven years later .\n"}
prediction:  {"predictions": [[1, 138, 1887, 1271, 7998, 1105, 4159, 6030, 2, 3, 1723, 4, 5, 1107, 2294, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 1887, 1271, 7998, 1105, 4159, 6030, 2, 3, 1723, 4, 5, 1107, 2294, 1114, 1103, 4544, 1104, 1103, 1794, 1604, 2443, 1206, 1103, 1210, 2930, 2014, 1106, 1103, 2685, 3156, 3998, 1978, 1201, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4544, 1104, 1103, 1794, 1604, 2443, 1206, 1103, 1210, 2930, 2, 3, 2014, 4, 5, 1106, 1103, 2685, 3156, 3998, 1978, 1201, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04388854652643204, -0.10923159867525101, -0.13283877074718475, -0.0426483154296875, -0.041965484619140625, -0.041965484619140625, -0.041965484619140625, -0.041965484619140625, -0.041965484619140625, -0.041965484619140625], "metadata": {"source_tokens": ["A", "common", "name", ",", "logo", ",", "and", "programming", "schedule", "followed", "in", "1982", ",", "with", "the", "establishment", "of", "the", "`", "##`", "TV", "##8", "'", "##'", "network", "between", "the", "three", "stations", ",", "changed", "to", "the", "`", "##`", "Southern", "Cross", "Network", "'", "##'", "seven", "years", "later", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "common", "name", "logo", "and", "programming", "schedule", "[unused2]", "[unused3]", "followed", "[unused4]", "[unused5]", "in", "1982", "[unused6]", "[SEP]", "[unused1]", "A", "common", "name", "logo", "and", "programming", "schedule", "[unused2]", "[unused3]", "followed", "[unused4]", "[unused5]", "in", "1982", "with", "the", "establishment", "of", "the", "TV", "##8", "network", "between", "the", "three", "stations", "changed", "to", "the", "Southern", "Cross", "Network", "seven", "years", "later", "[unused6]", "[SEP]", "[unused1]", "the", "establishment", "of", "the", "TV", "##8", "network", "between", "the", "three", "stations", "[unused2]", "[unused3]", "changed", "[unused4]", "[unused5]", "to", "the", "Southern", "Cross", "Network", "seven", "years", "later", "[unused6]", "[SEP]"]]}

input 6:  {"source": "A cooling center is a temporary air-conditioned public space set up by local authorities to deal with the health effects of a heat wave .\n"}
prediction:  {"predictions": [[1, 138, 12147, 2057, 2, 3, 1110, 4, 5, 170, 5335, 1586, 28137, 7235, 14669, 1174, 1470, 2000, 1383, 1146, 1118, 1469, 3912, 1106, 2239, 1114, 1103, 2332, 3154, 1104, 170, 3208, 4003, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006468983832746744, -0.23166418075561523, -0.1648998260498047, -0.1648998260498047, -0.1648998260498047, -0.1648998260498047, -0.1649003028869629, -0.1649003028869629, -0.1649003028869629, -0.1649003028869629], "metadata": {"source_tokens": ["A", "cooling", "center", "is", "a", "temporary", "air", "##-", "##con", "##dition", "##ed", "public", "space", "set", "up", "by", "local", "authorities", "to", "deal", "with", "the", "health", "effects", "of", "a", "heat", "wave", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "cooling", "center", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "temporary", "air", "##-", "##con", "##dition", "##ed", "public", "space", "set", "up", "by", "local", "authorities", "to", "deal", "with", "the", "health", "effects", "of", "a", "heat", "wave", "[unused6]", "[SEP]"]]}

input 7:  {"source": "A manifold is `` prime '' if it can not be presented as a connected sum of more than one manifold , none of which is the sphere of the same dimension .\n"}
prediction:  {"predictions": [[1, 3839, 1104, 1134, 2, 3, 1110, 4, 5, 1103, 11036, 1104, 1103, 1269, 11025, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 22502, 2, 3, 1110, 4, 5, 5748, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1169, 1136, 1129, 2756, 4, 5, 1112, 170, 3387, 7584, 1104, 1167, 1190, 1141, 22502, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.025188680738210678, -0.06444952636957169, -0.013021980412304401, -0.1076045036315918, -0.10746002197265625, -0.10746002197265625, -0.10746002197265625, -0.10746002197265625, -0.10746002197265625, -0.10746002197265625], "metadata": {"source_tokens": ["A", "manifold", "is", "`", "##`", "prime", "'", "##'", "if", "it", "can", "not", "be", "presented", "as", "a", "connected", "sum", "of", "more", "than", "one", "manifold", ",", "none", "of", "which", "is", "the", "sphere", "of", "the", "same", "dimension", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "none", "of", "which", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "sphere", "of", "the", "same", "dimension", "[unused6]", "[SEP]", "[unused1]", "A", "manifold", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "prime", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "can", "not", "be", "presented", "[unused4]", "[unused5]", "as", "a", "connected", "sum", "of", "more", "than", "one", "manifold", "[unused6]", "[SEP]"]]}

input 8:  {"source": "A mid-March 2002 court order to stop printing for three months , was evaded by printing under other titles , such as `` Not That Respublika '' .\n"}
prediction:  {"predictions": [[1, 138, 2286, 28137, 2107, 1813, 1732, 1617, 2175, 1546, 2, 3, 1108, 174, 27923, 1181, 4, 5, 1118, 8455, 1223, 1168, 3727, 117, 1216, 1112, 169, 28152, 1753, 1337, 11336, 20080, 10354, 19921, 1161, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04529811814427376, -0.16673994064331055, -0.16880130767822266, -0.16880130767822266, -0.16880130767822266, -0.16880083084106445, -0.16880130767822266, -0.16880130767822266, -0.16880130767822266, -0.16880130767822266], "metadata": {"source_tokens": ["A", "mid", "##-", "##M", "##ar", "##ch", "2002", "court", "order", "to", "stop", "printing", "for", "three", "months", ",", "was", "e", "##vade", "##d", "by", "printing", "under", "other", "titles", ",", "such", "as", "`", "##`", "Not", "That", "Re", "##sp", "##ub", "##lik", "##a", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "mid", "##-", "##M", "##ar", "##ch", "2002", "court", "order", "[unused2]", "[unused3]", "was", "e", "##vade", "##d", "[unused4]", "[unused5]", "by", "printing", "under", "other", "titles", ",", "such", "as", "`", "##`", "Not", "That", "Re", "##sp", "##ub", "##lik", "##a", "[unused6]", "[SEP]"]]}

input 9:  {"source": "A motorcycle speedway long-track meeting , one of the few held in the UK , was staged at Ammanford .\n"}
prediction:  {"predictions": [[1, 1103, 1374, 2, 3, 1316, 4, 5, 1107, 1103, 1993, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 9580, 2420, 2787, 1263, 28137, 22117, 2309, 2, 3, 1110, 4, 5, 1141, 1104, 1103, 1374, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 9580, 2420, 2787, 1263, 28137, 22117, 2309, 2, 3, 1108, 9645, 4, 5, 1120, 7277, 1399, 2821, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005634885746985674, -0.08631923049688339, -0.03703223913908005, -0.011264801025390625, -0.009718894958496094, -0.009718894958496094, -0.009718894958496094, -0.009718894958496094, -0.009718894958496094, -0.009718894958496094], "metadata": {"source_tokens": ["A", "motorcycle", "speed", "##way", "long", "##-", "##track", "meeting", ",", "one", "of", "the", "few", "held", "in", "the", "UK", ",", "was", "staged", "at", "Am", "##man", "##ford", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "few", "[unused2]", "[unused3]", "held", "[unused4]", "[unused5]", "in", "the", "UK", "[unused6]", "[SEP]", "[unused1]", "A", "motorcycle", "speed", "##way", "long", "##-", "##track", "meeting", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "one", "of", "the", "few", "[unused6]", "[SEP]", "[unused1]", "A", "motorcycle", "speed", "##way", "long", "##-", "##track", "meeting", "[unused2]", "[unused3]", "was", "staged", "[unused4]", "[unused5]", "at", "Am", "##man", "##ford", "[unused6]", "[SEP]"]]}

input 10:  {"source": "A partial list of turbomachinery that may use one or more centrifugal compressors within the machine are listed here .\n"}
prediction:  {"predictions": [[1, 189, 2149, 4043, 1918, 12285, 5075, 2, 3, 1336, 1329, 4, 5, 1141, 1137, 1167, 9848, 2047, 14703, 6997, 3254, 11135, 3864, 1439, 1103, 3395, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 7597, 2190, 1104, 189, 2149, 4043, 1918, 12285, 5075, 2, 3, 1132, 2345, 4, 5, 1303, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02584579959511757, -0.012819531373679638, -0.013659477233886719, -0.015128612518310547, -0.015128612518310547, -0.015128612518310547, -0.015128612518310547, -0.015128612518310547, -0.015128612518310547, -0.015128612518310547], "metadata": {"source_tokens": ["A", "partial", "list", "of", "t", "##ur", "##bo", "##ma", "##chin", "##ery", "that", "may", "use", "one", "or", "more", "cent", "##ri", "##fu", "##gal", "com", "##press", "##ors", "within", "the", "machine", "are", "listed", "here", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "t", "##ur", "##bo", "##ma", "##chin", "##ery", "[unused2]", "[unused3]", "may", "use", "[unused4]", "[unused5]", "one", "or", "more", "cent", "##ri", "##fu", "##gal", "com", "##press", "##ors", "within", "the", "machine", "[unused6]", "[SEP]", "[unused1]", "A", "partial", "list", "of", "t", "##ur", "##bo", "##ma", "##chin", "##ery", "[unused2]", "[unused3]", "are", "listed", "[unused4]", "[unused5]", "here", "[unused6]", "[SEP]"]]}

input 11:  {"source": "A short distance to the east , NC 111 diverges on Greenwood Boulevard .\n"}
prediction:  {"predictions": [[1, 14056, 11084, 2, 3, 23448, 7562, 4, 5, 1113, 17999, 8691, 138, 1603, 2462, 1106, 1103, 1746, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00012750625319313258, -0.0063991546630859375, -0.0066967010498046875, -0.0066967010498046875, -0.0066967010498046875, -0.0066967010498046875, -0.0066967010498046875, -0.0066967010498046875, -0.0066967010498046875, -0.0066967010498046875], "metadata": {"source_tokens": ["A", "short", "distance", "to", "the", "east", ",", "NC", "111", "diver", "##ges", "on", "Greenwood", "Boulevard", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "NC", "111", "[unused2]", "[unused3]", "diver", "##ges", "[unused4]", "[unused5]", "on", "Greenwood", "Boulevard", "A", "short", "distance", "to", "the", "east", "[unused6]", "[SEP]"]]}

input 12:  {"source": "A spectrum from a single FID has a low signal-to-noise ratio , but fortunately it improves readily with averaging of repeated acquisitions .\n"}
prediction:  {"predictions": [[1, 138, 10122, 1121, 170, 1423, 143, 9949, 2, 3, 1144, 4, 5, 170, 1822, 4344, 28137, 2430, 28137, 2728, 4862, 6022, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 4607, 1116, 4, 5, 12337, 1114, 15883, 1104, 4892, 23345, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0034138064365833998, -0.0805853083729744, -0.12584686279296875, -0.12323236465454102, -0.12323236465454102, -0.12323236465454102, -0.12323236465454102, -0.12323236465454102, -0.12323236465454102, -0.12323236465454102], "metadata": {"source_tokens": ["A", "spectrum", "from", "a", "single", "F", "##ID", "has", "a", "low", "signal", "##-", "##to", "##-", "##no", "##ise", "ratio", ",", "but", "fortunate", "##ly", "it", "improve", "##s", "readily", "with", "averaging", "of", "repeated", "acquisitions", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "spectrum", "from", "a", "single", "F", "##ID", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "a", "low", "signal", "##-", "##to", "##-", "##no", "##ise", "ratio", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "improve", "##s", "[unused4]", "[unused5]", "readily", "with", "averaging", "of", "repeated", "acquisitions", "[unused6]", "[SEP]"]]}

input 13:  {"source": "According to Hofmann , while still a teenage coin collector , he forged a rare mint mark on a dime and was told by an organization of coin collectors that it was genuine .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 17667, 4, 5, 170, 4054, 22532, 4551, 1113, 170, 12563, 1162, 1229, 1253, 170, 11009, 9584, 12116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1500, 4, 5, 1118, 1126, 2369, 1104, 9584, 16801, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 10416, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014720662496984005, -0.09229648858308792, -0.02166522666811943, -0.025287151336669922, -0.02496480941772461, -0.02496480941772461, -0.02496480941772461, -0.02496480941772461, -0.02496480941772461, -0.02496480941772461], "metadata": {"source_tokens": ["According", "to", "Ho", "##f", "##mann", ",", "while", "still", "a", "teenage", "coin", "collector", ",", "he", "forged", "a", "rare", "mint", "mark", "on", "a", "dim", "##e", "and", "was", "told", "by", "an", "organization", "of", "coin", "collectors", "that", "it", "was", "genuine", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "forged", "[unused4]", "[unused5]", "a", "rare", "mint", "mark", "on", "a", "dim", "##e", "while", "still", "a", "teenage", "coin", "collector", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "told", "[unused4]", "[unused5]", "by", "an", "organization", "of", "coin", "collectors", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "genuine", "[unused6]", "[SEP]"]]}

input 14:  {"source": "According to Samaritan tradition , however , the Samaritan ethnonym is not derived from the region of Samaria , but from the fact that they were the `` Guardians '' of the true Israelite religion .\n"}
prediction:  {"predictions": [[1, 1103, 2687, 7710, 5108, 3084, 7272, 10031, 1306, 2, 3, 1110, 1136, 4408, 4, 5, 1121, 1103, 1805, 1104, 2687, 11315, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1127, 4, 5, 1103, 169, 28152, 21444, 112, 28131, 1104, 1103, 2276, 4878, 1566, 4483, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.035087957978248596, -0.019263993948698044, -0.0629425048828125, -0.06208324432373047, -0.06208324432373047, -0.06208324432373047, -0.06208324432373047, -0.06208324432373047, -0.06208324432373047, -0.06208324432373047], "metadata": {"source_tokens": ["According", "to", "Sam", "##ari", "##tan", "tradition", ",", "however", ",", "the", "Sam", "##ari", "##tan", "et", "##hn", "##ony", "##m", "is", "not", "derived", "from", "the", "region", "of", "Sam", "##aria", ",", "but", "from", "the", "fact", "that", "they", "were", "the", "`", "##`", "Guardians", "'", "##'", "of", "the", "true", "Israeli", "##te", "religion", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Sam", "##ari", "##tan", "et", "##hn", "##ony", "##m", "[unused2]", "[unused3]", "is", "not", "derived", "[unused4]", "[unused5]", "from", "the", "region", "of", "Sam", "##aria", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "the", "`", "##`", "Guardians", "'", "##'", "of", "the", "true", "Israeli", "##te", "religion", "[unused6]", "[SEP]"]]}

input 15:  {"source": "According to the 2010 census , the population of the town is 2,310 .\n"}
prediction:  {"predictions": [[1, 1103, 1416, 1104, 1103, 1411, 2, 3, 1110, 4, 5, 123, 28136, 22639, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-4.8967107431963086e-05, -0.029307842254638672, -0.028735637664794922, -0.028735637664794922, -0.028735637664794922, -0.028735637664794922, -0.028735637664794922, -0.028735637664794922, -0.028735637664794922, -0.028735637664794922], "metadata": {"source_tokens": ["According", "to", "the", "2010", "census", ",", "the", "population", "of", "the", "town", "is", "2", "##,", "##31", "##0", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "population", "of", "the", "town", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "2", "##,", "##31", "##0", "[unused6]", "[SEP]"]]}

input 16:  {"source": "According to the South Koreans , many Koreans became victims of Japanese brutalities during the colonial period .\n"}
prediction:  {"predictions": [[1, 1242, 27757, 2, 3, 1245, 4, 5, 5256, 1104, 1983, 12800, 4233, 1219, 1103, 5929, 1669, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-6.866455078125e-05, -0.028116226196289062, -0.028340816497802734, -0.028340816497802734, -0.028340816497802734, -0.028340816497802734, -0.028340816497802734, -0.028340816497802734, -0.028340816497802734, -0.028340816497802734], "metadata": {"source_tokens": ["According", "to", "the", "South", "Koreans", ",", "many", "Koreans", "became", "victims", "of", "Japanese", "brutal", "##ities", "during", "the", "colonial", "period", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "many", "Koreans", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "victims", "of", "Japanese", "brutal", "##ities", "during", "the", "colonial", "period", "[unused6]", "[SEP]"]]}

input 17:  {"source": "According to the United States Census Bureau , the town has a total area of , all of it land .\n"}
prediction:  {"predictions": [[1, 1103, 1411, 2, 3, 1144, 4, 5, 170, 1703, 1298, 1104, 117, 1155, 1104, 1122, 1657, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.028818940743803978, -0.019504547119140625, -0.01913738250732422, -0.01913738250732422, -0.01913738250732422, -0.01913738250732422, -0.01913738250732422, -0.01913738250732422, -0.01913738250732422, -0.01913738250732422], "metadata": {"source_tokens": ["According", "to", "the", "United", "States", "Census", "Bureau", ",", "the", "town", "has", "a", "total", "area", "of", ",", "all", "of", "it", "land", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "town", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "a", "total", "area", "of", ",", "all", "of", "it", "land", "[unused6]", "[SEP]"]]}

input 18:  {"source": "According to the indictment , Gonzalez is accused of defrauding the West Bronx Neighborhood Association Inc. , a not-for-profit corporation , by using funds donated to the organization in order to pay for over $ 37,000 in personal expenses .\n"}
prediction:  {"predictions": [[1, 21125, 2, 3, 1110, 4806, 4, 5, 1104, 19353, 1611, 21705, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 1118, 1606, 4381, 6384, 1106, 1103, 2369, 1107, 1546, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21125, 2, 3, 1110, 4806, 4, 5, 1104, 19353, 1611, 21705, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 28138, 1118, 1606, 4381, 6384, 1106, 1103, 2369, 1107, 1546, 1106, 2653, 1106, 2653, 1106, 2653, 1106, 2653, 1106, 2653, 1106, 2653, 1106, 2653, 1106, 2653, 1106, 2653, 102, 1, 21125, 2, 3, 1110, 4806, 4, 5, 1104, 19353, 1611, 21705, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 28138, 1118, 1606, 4381, 6384, 1106, 1103, 2369, 1107, 1546, 1106, 2653, 1111, 1166, 109, 3413, 28136, 7629, 1568, 1107, 2357, 11928, 6, 102, 102, 1, 21125, 2, 3, 1110, 4806, 4, 5, 1104, 19353, 1611, 21705, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 28138, 1118, 1606, 4381, 6384, 1106, 1103, 2369, 1107, 1546, 1106, 2653, 1111, 1166, 109, 3413, 28136, 7629, 1568, 1107, 2357, 11928, 6, 102, 102, 102, 102, 102, 102, 1, 21125, 2, 3, 1110, 4806, 4, 5, 1104, 19353, 1611, 21705, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 6, 102, 102, 1, 21125, 2, 3, 1110, 4806, 4, 5, 1104, 19353, 1611, 21705, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 28138, 1118, 1606, 4381, 6384, 1106, 1103, 2369, 1107, 1546, 1106, 2653, 1111, 1166, 109, 3413, 28136, 7629, 1568, 1107, 2357, 11928, 1792, 1106, 1103, 27926, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.041059065610170364, -0.12396041303873062, -0.10229481011629105, -0.14422069489955902, -0.13895899057388306, -0.1303161084651947, -0.31392955780029297, -0.3056802749633789, -0.3056802749633789, -0.3056802749633789], "metadata": {"source_tokens": ["According", "to", "the", "indictment", ",", "Gonzalez", "is", "accused", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "##.", ",", "a", "not", "##-", "##fo", "##r", "##-", "##p", "##ro", "##fit", "corporation", ",", "by", "using", "funds", "donated", "to", "the", "organization", "in", "order", "to", "pay", "for", "over", "$", "37", "##,", "##00", "##0", "in", "personal", "expenses", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Gonzalez", "[unused2]", "[unused3]", "is", "accused", "[unused4]", "[unused5]", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "by", "using", "funds", "donated", "to", "the", "organization", "in", "order", "[unused6]", "[SEP]", "[unused1]", "Gonzalez", "[unused2]", "[unused3]", "is", "accused", "[unused4]", "[unused5]", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "##.", "by", "using", "funds", "donated", "to", "the", "organization", "in", "order", "to", "pay", "to", "pay", "to", "pay", "to", "pay", "to", "pay", "to", "pay", "to", "pay", "to", "pay", "to", "pay", "[SEP]", "[unused1]", "Gonzalez", "[unused2]", "[unused3]", "is", "accused", "[unused4]", "[unused5]", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "##.", "by", "using", "funds", "donated", "to", "the", "organization", "in", "order", "to", "pay", "for", "over", "$", "37", "##,", "##00", "##0", "in", "personal", "expenses", "[unused6]", "[SEP]", "[unused1]", "Gonzalez", "[unused2]", "[unused3]", "is", "accused", "[unused4]", "[unused5]", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "##.", "by", "using", "funds", "donated", "to", "the", "organization", "in", "order", "to", "pay", "for", "over", "$", "37", "##,", "##00", "##0", "in", "personal", "expenses", "[unused6]", "[SEP]", "[unused1]", "Gonzalez", "[unused2]", "[unused3]", "is", "accused", "[unused4]", "[unused5]", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "[unused6]", "[SEP]", "[unused1]", "Gonzalez", "[unused2]", "[unused3]", "is", "accused", "[unused4]", "[unused5]", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "##.", "by", "using", "funds", "donated", "to", "the", "organization", "in", "order", "to", "pay", "for", "over", "$", "37", "##,", "##00", "##0", "in", "personal", "expenses", "According", "to", "the", "indictment", "[unused6]", "[SEP]"]]}

input 19:  {"source": "Accordingly , the 1962 Roman Missal , the edition whose continued use as an extraordinary form of the Roman Rite is authorized by the motu proprio `` Summorum Pontificum '' , also has no mention of her .\n"}
prediction:  {"predictions": [[1, 1103, 2832, 2264, 3056, 1348, 2, 3, 1144, 4, 5, 1185, 4734, 1104, 1123, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2596, 2133, 1598, 1329, 1112, 1126, 10264, 1532, 1104, 1103, 2264, 23787, 2, 3, 1110, 9320, 4, 5, 1118, 1103, 182, 3329, 1358, 21146, 8558, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.029894180595874786, -0.057528600096702576, -0.06391334533691406, -0.06197786331176758, -0.06197786331176758, -0.06197786331176758, -0.06197786331176758, -0.06197786331176758, -0.06197786331176758, -0.06197786331176758], "metadata": {"source_tokens": ["Accordingly", ",", "the", "1962", "Roman", "Miss", "##al", ",", "the", "edition", "whose", "continued", "use", "as", "an", "extraordinary", "form", "of", "the", "Roman", "Rite", "is", "authorized", "by", "the", "m", "##ot", "##u", "prop", "##rio", "`", "##`", "Su", "##mm", "##orum", "Pont", "##ific", "##um", "'", "##'", ",", "also", "has", "no", "mention", "of", "her", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "1962", "Roman", "Miss", "##al", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "no", "mention", "of", "her", "[unused6]", "[SEP]", "[unused1]", "the", "edition", "whose", "continued", "use", "as", "an", "extraordinary", "form", "of", "the", "Roman", "Rite", "[unused2]", "[unused3]", "is", "authorized", "[unused4]", "[unused5]", "by", "the", "m", "##ot", "##u", "prop", "##rio", "[unused6]", "[SEP]"]]}

input 20:  {"source": "Additionally , the French Community of Belgium has controversially begun referring to itself exclusively as the ` Wallonia-Brussels Federation ' to emphasize the links between the French Community , Wallonia and Brussels .\n"}
prediction:  {"predictions": [[1, 1103, 1497, 3704, 1104, 4990, 2, 3, 1144, 6241, 1193, 4972, 4, 5, 7455, 1106, 2111, 7097, 1112, 1103, 169, 6250, 11357, 28137, 2064, 25357, 5999, 4245, 1106, 19291, 1103, 6743, 1206, 1103, 1497, 3704, 117, 6250, 11357, 1105, 9062, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03483528643846512, -0.07617855072021484, -0.07866382598876953, -0.07866382598876953, -0.07866382598876953, -0.07866382598876953, -0.07866382598876953, -0.07866382598876953, -0.07866382598876953, -0.07866382598876953], "metadata": {"source_tokens": ["Additionally", ",", "the", "French", "Community", "of", "Belgium", "has", "controversial", "##ly", "begun", "referring", "to", "itself", "exclusively", "as", "the", "`", "Wall", "##onia", "##-", "##B", "##russ", "##els", "Federation", "'", "to", "emphasize", "the", "links", "between", "the", "French", "Community", ",", "Wall", "##onia", "and", "Brussels", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "French", "Community", "of", "Belgium", "[unused2]", "[unused3]", "has", "controversial", "##ly", "begun", "[unused4]", "[unused5]", "referring", "to", "itself", "exclusively", "as", "the", "`", "Wall", "##onia", "##-", "##B", "##russ", "##els", "Federation", "to", "emphasize", "the", "links", "between", "the", "French", "Community", ",", "Wall", "##onia", "and", "Brussels", "[unused6]", "[SEP]"]]}

input 21:  {"source": "After 1895 cable hauling ceased and locomotives pulled trains the whole length of the Victoria and Waterloo tunnels .\n"}
prediction:  {"predictions": [[1, 7499, 2, 3, 1865, 4, 5, 3918, 1103, 2006, 2251, 1104, 1103, 3006, 1105, 14233, 11175, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5639, 26483, 26483, 2, 3, 6445, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26483, 26483, 26483, 2, 3, 6445, 4, 5, 1105, 7499, 1865, 1103, 2006, 2251, 1104, 1103, 3006, 1105, 14233, 11175, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 26483, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.019559785723686218, -0.24363833665847778, -0.329297810792923, -0.8666252493858337, -0.32221508026123047, -0.15724897384643555, -0.15724897384643555, -0.15724897384643555, -0.15724897384643555, -0.15724897384643555], "metadata": {"source_tokens": ["After", "1895", "cable", "hauling", "ceased", "and", "locomotives", "pulled", "trains", "the", "whole", "length", "of", "the", "Victoria", "and", "Waterloo", "tunnels", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "locomotives", "[unused2]", "[unused3]", "pulled", "[unused4]", "[unused5]", "trains", "the", "whole", "length", "of", "the", "Victoria", "and", "Waterloo", "tunnels", "[unused6]", "[SEP]", "[unused1]", "1895", "hauling", "hauling", "[unused2]", "[unused3]", "ceased", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "hauling", "hauling", "hauling", "[unused2]", "[unused3]", "ceased", "[unused4]", "[unused5]", "and", "locomotives", "pulled", "the", "whole", "length", "of", "the", "Victoria", "and", "Waterloo", "tunnels", "[unused6]", "[SEP]", "[unused1]", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "hauling", "[SEP]"]]}

input 22:  {"source": "After five years of searching , the Colonials found a primitive , lush and vibrant new world and named it Earth .\n"}
prediction:  {"predictions": [[1, 1103, 10319, 1116, 2, 3, 1276, 4, 5, 170, 12130, 117, 19302, 1105, 18652, 1207, 1362, 1258, 1421, 1201, 1104, 6205, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 10319, 1116, 2, 3, 1417, 4, 5, 1122, 2746, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03199203312397003, -0.04710563272237778, -0.2476658821105957, -0.24438095092773438, -0.24438095092773438, -0.24438095092773438, -0.24438095092773438, -0.24438095092773438, -0.24438095092773438, -0.24438095092773438], "metadata": {"source_tokens": ["After", "five", "years", "of", "searching", ",", "the", "Colonial", "##s", "found", "a", "primitive", ",", "lush", "and", "vibrant", "new", "world", "and", "named", "it", "Earth", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Colonial", "##s", "[unused2]", "[unused3]", "found", "[unused4]", "[unused5]", "a", "primitive", ",", "lush", "and", "vibrant", "new", "world", "After", "five", "years", "of", "searching", "[unused6]", "[SEP]", "[unused1]", "the", "Colonial", "##s", "[unused2]", "[unused3]", "named", "[unused4]", "[unused5]", "it", "Earth", "[unused6]", "[SEP]"]]}

input 23:  {"source": "After leaving `` Hex '' , Cole went on to appear as Blanche Ingram in the critically acclaimed `` Jane Eyre '' TV serial for the BBC and guest starred as Lilith in the `` Doctor Who '' episode `` The Shakespeare Code '' .\n"}
prediction:  {"predictions": [[1, 4922, 2, 3, 1355, 1113, 4, 5, 1106, 2845, 1112, 21086, 25885, 1107, 1103, 11774, 10214, 4074, 142, 10930, 1794, 7838, 1111, 1103, 3173, 1258, 2128, 169, 28152, 1124, 1775, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4922, 2, 3, 1106, 2845, 4, 5, 1112, 21086, 25885, 1107, 1103, 11774, 10214, 4074, 142, 10930, 1794, 7838, 1111, 1103, 3173, 1105, 3648, 4950, 1112, 14138, 7088, 1107, 1103, 169, 28152, 4157, 2627, 112, 28131, 2004, 169, 28152, 1109, 7647, 6741, 6, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.039021432399749756, -0.1069495752453804, -0.07711219787597656, -0.07775115966796875, -0.07775115966796875, -0.07775115966796875, -0.07775115966796875, -0.07775115966796875, -0.07775115966796875, -0.07775115966796875], "metadata": {"source_tokens": ["After", "leaving", "`", "##`", "He", "##x", "'", "##'", ",", "Cole", "went", "on", "to", "appear", "as", "Blanche", "Ingram", "in", "the", "critically", "acclaimed", "`", "##`", "Jane", "E", "##yre", "'", "##'", "TV", "serial", "for", "the", "BBC", "and", "guest", "starred", "as", "Lil", "##ith", "in", "the", "`", "##`", "Doctor", "Who", "'", "##'", "episode", "`", "##`", "The", "Shakespeare", "Code", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Cole", "[unused2]", "[unused3]", "went", "on", "[unused4]", "[unused5]", "to", "appear", "as", "Blanche", "Ingram", "in", "the", "critically", "acclaimed", "Jane", "E", "##yre", "TV", "serial", "for", "the", "BBC", "After", "leaving", "`", "##`", "He", "##x", "[unused6]", "[SEP]", "[unused1]", "Cole", "[unused2]", "[unused3]", "to", "appear", "[unused4]", "[unused5]", "as", "Blanche", "Ingram", "in", "the", "critically", "acclaimed", "Jane", "E", "##yre", "TV", "serial", "for", "the", "BBC", "and", "guest", "starred", "as", "Lil", "##ith", "in", "the", "`", "##`", "Doctor", "Who", "'", "##'", "episode", "`", "##`", "The", "Shakespeare", "Code", "[unused6]", "[SEP]"]]}

input 24:  {"source": "After the battle , Battra rested in the Arctic Ocean , whereas Mothra retired to Infant Island , accompanied by the two Cosmos .\n"}
prediction:  {"predictions": [[1, 21928, 4487, 2, 3, 8237, 4, 5, 1107, 1103, 10925, 4879, 6142, 12556, 1582, 1611, 2623, 1106, 1130, 26636, 2054, 1258, 1103, 2321, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1130, 26636, 2054, 2, 3, 4977, 4, 5, 1118, 1103, 1160, 3291, 18818, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12556, 1582, 1611, 2, 3, 2623, 4, 5, 1106, 1130, 26636, 2054, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014485051855444908, -0.12066765874624252, -0.004726804327219725, -0.056303977966308594, -0.05930280685424805, -0.05930280685424805, -0.05930280685424805, -0.05930280685424805, -0.05930280685424805, -0.05930280685424805], "metadata": {"source_tokens": ["After", "the", "battle", ",", "Bat", "##tra", "rested", "in", "the", "Arctic", "Ocean", ",", "whereas", "Mo", "##th", "##ra", "retired", "to", "In", "##fant", "Island", ",", "accompanied", "by", "the", "two", "Co", "##smos", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Bat", "##tra", "[unused2]", "[unused3]", "rested", "[unused4]", "[unused5]", "in", "the", "Arctic", "Ocean", "whereas", "Mo", "##th", "##ra", "retired", "to", "In", "##fant", "Island", "After", "the", "battle", "[unused6]", "[SEP]", "[unused1]", "In", "##fant", "Island", "[unused2]", "[unused3]", "accompanied", "[unused4]", "[unused5]", "by", "the", "two", "Co", "##smos", "[unused6]", "[SEP]", "[unused1]", "Mo", "##th", "##ra", "[unused2]", "[unused3]", "retired", "[unused4]", "[unused5]", "to", "In", "##fant", "Island", "[unused6]", "[SEP]"]]}

input 25:  {"source": "After this point many of the republicans were arrested in Free State `` round ups '' when they had come out of hiding and returned home .\n"}
prediction:  {"predictions": [[1, 1242, 1104, 1103, 22679, 1116, 2, 3, 1127, 3950, 4, 5, 1107, 4299, 1426, 1668, 12534, 1165, 1152, 1125, 1435, 1149, 1104, 5797, 1105, 1608, 1313, 1258, 1142, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1125, 1435, 4, 5, 1149, 1104, 5797, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027015261352062225, -0.32218074798583984, -0.08302591741085052, -0.0651698112487793, -0.06493616104125977, -0.06493616104125977, -0.06493616104125977, -0.06493616104125977, -0.06493616104125977, -0.06493616104125977], "metadata": {"source_tokens": ["After", "this", "point", "many", "of", "the", "republican", "##s", "were", "arrested", "in", "Free", "State", "`", "##`", "round", "ups", "'", "##'", "when", "they", "had", "come", "out", "of", "hiding", "and", "returned", "home", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "many", "of", "the", "republican", "##s", "[unused2]", "[unused3]", "were", "arrested", "[unused4]", "[unused5]", "in", "Free", "State", "round", "ups", "when", "they", "had", "come", "out", "of", "hiding", "and", "returned", "home", "After", "this", "point", "[unused6]", "[SEP]"]]}

input 26:  {"source": "Although Knievel broke his arms , he was more distraught over a permanent injury his accident caused to the cameraman .\n"}
prediction:  {"predictions": [[1, 148, 5213, 12559, 2, 3, 2795, 4, 5, 1117, 1739, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 4, 5, 1167, 4267, 16468, 11266, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4088, 3773, 2, 3, 1129, 1117, 4216, 2416, 4, 5, 1106, 1103, 4504, 1399, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013146767392754555, -0.058684587478637695, -0.11011186987161636, -0.20018482208251953, -0.1995844841003418, -0.1995840072631836, -0.1995840072631836, -0.1995840072631836, -0.1995840072631836, -0.1995840072631836], "metadata": {"source_tokens": ["Although", "K", "##nie", "##vel", "broke", "his", "arms", ",", "he", "was", "more", "di", "##stra", "##ught", "over", "a", "permanent", "injury", "his", "accident", "caused", "to", "the", "camera", "##man", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "K", "##nie", "##vel", "[unused2]", "[unused3]", "broke", "[unused4]", "[unused5]", "his", "arms", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "more", "di", "##stra", "##ught", "[unused6]", "[SEP]", "[unused1]", "a", "permanent", "injury", "[unused2]", "[unused3]", "be", "his", "accident", "caused", "[unused4]", "[unused5]", "to", "the", "camera", "##man", "[unused6]", "[SEP]"]]}

input 27:  {"source": "Although under constant attack from kamikazes as well as fighters and dive-bombers , `` Hazelwood '' came through the invasion untouched and on the night of 25 February sank two small enemy freighters with her guns .\n"}
prediction:  {"predictions": [[1, 21021, 2615, 2, 3, 1338, 4, 5, 1194, 1103, 4923, 25135, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21021, 2615, 2, 3, 1338, 4, 5, 1194, 1103, 4923, 25135, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21021, 2615, 2, 3, 1338, 4, 5, 1194, 1103, 4923, 25135, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21021, 2615, 2, 3, 1338, 4, 5, 1194, 1103, 4923, 25135, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21021, 2615, 2, 3, 1338, 4, 5, 1194, 1103, 4923, 25135, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21021, 2615, 2, 3, 1338, 4, 5, 1194, 1103, 4923, 25135, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.053294599056243896, -0.1598273664712906, -0.18228299915790558, -0.2150006741285324, -0.25236257910728455, -0.28992852568626404, -0.2824668884277344, -0.2826404571533203, -0.2826404571533203, -0.2826404571533203], "metadata": {"source_tokens": ["Although", "under", "constant", "attack", "from", "ka", "##mi", "##ka", "##zes", "as", "well", "as", "fighters", "and", "dive", "##-", "##bo", "##mber", "##s", ",", "`", "##`", "Hazel", "##wood", "'", "##'", "came", "through", "the", "invasion", "untouched", "and", "on", "the", "night", "of", "25", "February", "sank", "two", "small", "enemy", "freight", "##ers", "with", "her", "guns", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hazel", "##wood", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "through", "the", "invasion", "untouched", "[unused6]", "[SEP]", "[unused1]", "Hazel", "##wood", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "through", "the", "invasion", "untouched", "[unused6]", "[SEP]", "[unused1]", "Hazel", "##wood", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "through", "the", "invasion", "untouched", "[unused6]", "[SEP]", "[unused1]", "Hazel", "##wood", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "through", "the", "invasion", "untouched", "[unused6]", "[SEP]", "[unused1]", "Hazel", "##wood", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "through", "the", "invasion", "untouched", "[unused6]", "[SEP]", "[unused1]", "Hazel", "##wood", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "through", "the", "invasion", "untouched", "[unused6]", "[SEP]"]]}

input 28:  {"source": "An animal that cares for its young but shows no other sociality traits is said to be `` subsocial '' .\n"}
prediction:  {"predictions": [[1, 1760, 3724, 2, 3, 16903, 4, 5, 1111, 1157, 1685, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1760, 3724, 1115, 16903, 1111, 1157, 1685, 1133, 2196, 1185, 1168, 1934, 1785, 13474, 2, 3, 1110, 4, 5, 1110, 1163, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1760, 3724, 2, 3, 1106, 1129, 4, 5, 4841, 7301, 12562, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.011571443639695644, -0.13888667523860931, -0.067205049097538, -0.0851144790649414, -0.083831787109375, -0.083831787109375, -0.083831787109375, -0.083831787109375, -0.083831787109375, -0.083831787109375], "metadata": {"source_tokens": ["An", "animal", "that", "cares", "for", "its", "young", "but", "shows", "no", "other", "social", "##ity", "traits", "is", "said", "to", "be", "`", "##`", "sub", "##so", "##cial", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "An", "animal", "[unused2]", "[unused3]", "cares", "[unused4]", "[unused5]", "for", "its", "young", "[unused6]", "[SEP]", "[unused1]", "An", "animal", "that", "cares", "for", "its", "young", "but", "shows", "no", "other", "social", "##ity", "traits", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "is", "said", "[unused6]", "[SEP]", "[unused1]", "An", "animal", "[unused2]", "[unused3]", "to", "be", "[unused4]", "[unused5]", "sub", "##so", "##cial", "[unused6]", "[SEP]"]]}

input 29:  {"source": "An original limited artist edition of 250 was published in 1989 and was an oversized fine press slip-cased book with stainless steel faced boards and digital clock inset into the front cover .\n"}
prediction:  {"predictions": [[1, 1760, 1560, 2609, 2360, 2596, 1104, 4805, 2, 3, 1108, 1502, 4, 5, 1107, 2056, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1760, 1560, 2609, 2360, 2596, 1104, 4805, 2, 3, 1108, 4, 5, 1126, 24223, 2503, 3181, 7324, 28137, 14083, 1181, 1520, 1114, 21771, 3649, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21771, 3649, 2, 3, 3544, 4, 5, 8190, 1105, 3539, 4705, 22233, 2105, 1154, 1103, 1524, 2267, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014994233846664429, -0.05345775932073593, -0.06039978191256523, -0.05400896072387695, -0.05599641799926758, -0.05599641799926758, -0.05599641799926758, -0.05599641799926758, -0.05599641799926758, -0.05599641799926758], "metadata": {"source_tokens": ["An", "original", "limited", "artist", "edition", "of", "250", "was", "published", "in", "1989", "and", "was", "an", "oversized", "fine", "press", "slip", "##-", "##case", "##d", "book", "with", "stainless", "steel", "faced", "boards", "and", "digital", "clock", "ins", "##et", "into", "the", "front", "cover", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "An", "original", "limited", "artist", "edition", "of", "250", "[unused2]", "[unused3]", "was", "published", "[unused4]", "[unused5]", "in", "1989", "[unused6]", "[SEP]", "[unused1]", "An", "original", "limited", "artist", "edition", "of", "250", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "an", "oversized", "fine", "press", "slip", "##-", "##case", "##d", "book", "with", "stainless", "steel", "[unused6]", "[SEP]", "[unused1]", "stainless", "steel", "[unused2]", "[unused3]", "faced", "[unused4]", "[unused5]", "boards", "and", "digital", "clock", "ins", "##et", "into", "the", "front", "cover", "[unused6]", "[SEP]"]]}

input 30:  {"source": "And ABS has formed a partnership with Habitat for Humanity to give a free Bible to each of its new homeowners in the United States .\n"}
prediction:  {"predictions": [[1, 20066, 2, 3, 1144, 1824, 4, 5, 170, 5210, 1114, 11679, 9208, 2980, 1111, 4243, 1785, 1106, 1660, 170, 1714, 5905, 1106, 1296, 1104, 1157, 1207, 1313, 13798, 1468, 1107, 1103, 1244, 1311, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.020092781633138657, -0.21962928771972656, -0.17722797393798828, -0.17722797393798828, -0.17722749710083008, -0.17722797393798828, -0.17722797393798828, -0.17722797393798828, -0.17722797393798828, -0.17722797393798828], "metadata": {"source_tokens": ["And", "ABS", "has", "formed", "a", "partnership", "with", "Ha", "##bit", "##at", "for", "Human", "##ity", "to", "give", "a", "free", "Bible", "to", "each", "of", "its", "new", "home", "##own", "##ers", "in", "the", "United", "States", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "ABS", "[unused2]", "[unused3]", "has", "formed", "[unused4]", "[unused5]", "a", "partnership", "with", "Ha", "##bit", "##at", "for", "Human", "##ity", "to", "give", "a", "free", "Bible", "to", "each", "of", "its", "new", "home", "##own", "##ers", "in", "the", "United", "States", "[unused6]", "[SEP]"]]}

input 31:  {"source": "And he was in Ali 's army in the Battle of Jamal and later it was Muhammad ibn Abu Bakr who escorted Aisha back to Madina .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1108, 4, 5, 1107, 4149, 112, 1116, 2306, 1107, 1103, 2651, 1104, 27440, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6710, 10452, 8158, 18757, 1377, 1197, 2, 3, 1129, 13539, 4, 5, 19294, 5480, 1171, 1106, 10779, 2983, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 6710, 10452, 8158, 18757, 1377, 1197, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.026813892647624016, -0.05673326924443245, -0.07337570935487747, -0.04484748840332031, -0.04446887969970703, -0.04446887969970703, -0.04446887969970703, -0.04446887969970703, -0.04446887969970703, -0.04446887969970703], "metadata": {"source_tokens": ["And", "he", "was", "in", "Ali", "'", "##s", "army", "in", "the", "Battle", "of", "Jamal", "and", "later", "it", "was", "Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "who", "escorted", "Ai", "##sha", "back", "to", "Mad", "##ina", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "in", "Ali", "'", "##s", "army", "in", "the", "Battle", "of", "Jamal", "[unused6]", "[SEP]", "[unused1]", "Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "[unused2]", "[unused3]", "be", "escorted", "[unused4]", "[unused5]", "Ai", "##sha", "back", "to", "Mad", "##ina", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "later", "[unused6]", "[SEP]"]]}

input 32:  {"source": "Andrea Bianco 's atlas of 1436 comprises ten leaves of vellum , measuring , in an 18th-century binding .\n"}
prediction:  {"predictions": [[1, 8326, 139, 1811, 2528, 112, 1116, 1120, 7580, 1104, 17025, 1545, 2, 3, 8302, 4, 5, 1995, 2972, 1104, 1396, 21275, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8326, 139, 1811, 2528, 112, 1116, 1120, 7580, 1104, 17025, 1545, 2, 3, 8302, 4, 5, 1995, 2972, 1104, 1396, 21275, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8326, 139, 1811, 2528, 112, 1116, 1120, 7580, 1104, 17025, 1545, 2, 3, 8302, 4, 5, 1995, 2972, 1104, 1396, 21275, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8326, 139, 1811, 2528, 112, 1116, 1120, 7580, 1104, 17025, 1545, 2, 3, 8302, 4, 5, 1995, 2972, 1104, 1396, 21275, 10099, 1107, 1126, 4186, 28137, 8298, 11366, 7861, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.011416981928050518, -0.03330479562282562, -0.05871759355068207, -0.07073015719652176, -0.26201438903808594, -0.2738509178161621, -0.2738509178161621, -0.2738509178161621, -0.2738509178161621, -0.2738509178161621], "metadata": {"source_tokens": ["Andrea", "B", "##ian", "##co", "'", "##s", "at", "##las", "of", "143", "##6", "comprises", "ten", "leaves", "of", "ve", "##llum", ",", "measuring", ",", "in", "an", "18th", "##-", "##cent", "##ury", "binding", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Andrea", "B", "##ian", "##co", "'", "##s", "at", "##las", "of", "143", "##6", "[unused2]", "[unused3]", "comprises", "[unused4]", "[unused5]", "ten", "leaves", "of", "ve", "##llum", "[unused6]", "[SEP]", "[unused1]", "Andrea", "B", "##ian", "##co", "'", "##s", "at", "##las", "of", "143", "##6", "[unused2]", "[unused3]", "comprises", "[unused4]", "[unused5]", "ten", "leaves", "of", "ve", "##llum", "[unused6]", "[SEP]", "[unused1]", "Andrea", "B", "##ian", "##co", "'", "##s", "at", "##las", "of", "143", "##6", "[unused2]", "[unused3]", "comprises", "[unused4]", "[unused5]", "ten", "leaves", "of", "ve", "##llum", "[unused6]", "[SEP]", "[unused1]", "Andrea", "B", "##ian", "##co", "'", "##s", "at", "##las", "of", "143", "##6", "[unused2]", "[unused3]", "comprises", "[unused4]", "[unused5]", "ten", "leaves", "of", "ve", "##llum", "measuring", "in", "an", "18th", "##-", "##cent", "##ury", "binding", "[unused6]", "[SEP]"]]}

input 33:  {"source": "Apartment buildings , shops , medical clinics , cinemas etc. were built in close proximity to the MAZ plant , providing plant workers with local necessities .\n"}
prediction:  {"predictions": [[1, 10342, 1880, 2275, 117, 7116, 117, 2657, 20562, 117, 27081, 3576, 28138, 2, 3, 1127, 1434, 4, 5, 1107, 1601, 10013, 1106, 1103, 9960, 5301, 2582, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10342, 1880, 2275, 117, 7116, 117, 2657, 20562, 117, 27081, 3576, 28138, 2, 3, 1127, 1434, 4, 5, 1107, 1601, 10013, 1106, 1103, 9960, 5301, 2582, 3558, 2582, 3239, 1114, 1469, 24928, 22371, 4233, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0020983219146728516, -0.06997592747211456, -0.1320033073425293, -0.1202092170715332, -0.1202092170715332, -0.1202092170715332, -0.1202096939086914, -0.1202096939086914, -0.1202096939086914, -0.1202096939086914], "metadata": {"source_tokens": ["Apart", "##ment", "buildings", ",", "shops", ",", "medical", "clinics", ",", "cinemas", "etc", "##.", "were", "built", "in", "close", "proximity", "to", "the", "MA", "##Z", "plant", ",", "providing", "plant", "workers", "with", "local", "ne", "##cess", "##ities", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Apart", "##ment", "buildings", ",", "shops", ",", "medical", "clinics", ",", "cinemas", "etc", "##.", "[unused2]", "[unused3]", "were", "built", "[unused4]", "[unused5]", "in", "close", "proximity", "to", "the", "MA", "##Z", "plant", "[unused6]", "[SEP]", "[unused1]", "Apart", "##ment", "buildings", ",", "shops", ",", "medical", "clinics", ",", "cinemas", "etc", "##.", "[unused2]", "[unused3]", "were", "built", "[unused4]", "[unused5]", "in", "close", "proximity", "to", "the", "MA", "##Z", "plant", "providing", "plant", "workers", "with", "local", "ne", "##cess", "##ities", "[unused6]", "[SEP]"]]}

input 34:  {"source": "Applications can use this service to record activity for a production system while implementations of other OSIDs can use the service to record detailed data during development , debugging , or analyzing performance .\n"}
prediction:  {"predictions": [[1, 7249, 1116, 1104, 1168, 11570, 9949, 1116, 2, 3, 1169, 1329, 4, 5, 1103, 1555, 1106, 1647, 6448, 2233, 1219, 1718, 117, 1260, 7925, 10932, 117, 1137, 23389, 2099, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20603, 2, 3, 1169, 1329, 4, 5, 1142, 1555, 1106, 1647, 3246, 1111, 170, 1707, 1449, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01619052141904831, -0.042625851929187775, -0.05232715606689453, -0.052437782287597656, -0.05243825912475586, -0.05243825912475586, -0.05243825912475586, -0.05243825912475586, -0.05243825912475586, -0.05243825912475586], "metadata": {"source_tokens": ["Applications", "can", "use", "this", "service", "to", "record", "activity", "for", "a", "production", "system", "while", "implementation", "##s", "of", "other", "OS", "##ID", "##s", "can", "use", "the", "service", "to", "record", "detailed", "data", "during", "development", ",", "de", "##bu", "##gging", ",", "or", "analyzing", "performance", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "implementation", "##s", "of", "other", "OS", "##ID", "##s", "[unused2]", "[unused3]", "can", "use", "[unused4]", "[unused5]", "the", "service", "to", "record", "detailed", "data", "during", "development", ",", "de", "##bu", "##gging", ",", "or", "analyzing", "performance", "[unused6]", "[SEP]", "[unused1]", "Applications", "[unused2]", "[unused3]", "can", "use", "[unused4]", "[unused5]", "this", "service", "to", "record", "activity", "for", "a", "production", "system", "[unused6]", "[SEP]"]]}

input 35:  {"source": "Applying this technique facilitates the connection of the center of the foot with the lower abdomen .\n"}
prediction:  {"predictions": [[1, 138, 8661, 15318, 1142, 5531, 2, 3, 11000, 1116, 4, 5, 1103, 3797, 1104, 1103, 2057, 1104, 1103, 2555, 1114, 1103, 2211, 14701, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0003791909839492291, -0.022847652435302734, -0.02190399169921875, -0.02190399169921875, -0.02190399169921875, -0.02190399169921875, -0.02190399169921875, -0.02190399169921875, -0.02190399169921875, -0.02190399169921875], "metadata": {"source_tokens": ["A", "##pp", "##lying", "this", "technique", "facilitate", "##s", "the", "connection", "of", "the", "center", "of", "the", "foot", "with", "the", "lower", "abdomen", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "##pp", "##lying", "this", "technique", "[unused2]", "[unused3]", "facilitate", "##s", "[unused4]", "[unused5]", "the", "connection", "of", "the", "center", "of", "the", "foot", "with", "the", "lower", "abdomen", "[unused6]", "[SEP]"]]}

input 36:  {"source": "As Attorney General he clashed with Daniel O'Connell when he insisted , against O'Connell 's wishes , on the appointment of Abraham Brewster as Law Adviser to the Lord Lieutenant of Ireland .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 25144, 4, 5, 1114, 2979, 152, 28131, 1658, 26823, 1165, 1119, 6744, 117, 1222, 152, 28131, 1658, 26823, 112, 1116, 8921, 117, 1113, 1103, 5516, 1104, 7752, 25673, 1112, 2601, 24930, 16641, 1197, 1106, 1103, 2188, 3897, 1104, 2270, 6, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 6744, 4, 5, 1222, 152, 28131, 1658, 26823, 112, 1116, 8921, 1113, 1103, 5516, 1104, 7752, 25673, 1112, 2601, 24930, 16641, 1197, 1106, 1103, 2188, 3897, 1104, 2270, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008028199896216393, -0.029365329071879387, -0.2869420051574707, -0.2754364013671875, -0.2754364013671875, -0.2754364013671875, -0.2754364013671875, -0.2754364013671875, -0.2754364013671875, -0.2754364013671875], "metadata": {"source_tokens": ["As", "Attorney", "General", "he", "clashed", "with", "Daniel", "O", "##'", "##C", "##onnell", "when", "he", "insisted", ",", "against", "O", "##'", "##C", "##onnell", "'", "##s", "wishes", ",", "on", "the", "appointment", "of", "Abraham", "Brewster", "as", "Law", "Ad", "##vise", "##r", "to", "the", "Lord", "Lieutenant", "of", "Ireland", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "clashed", "[unused4]", "[unused5]", "with", "Daniel", "O", "##'", "##C", "##onnell", "when", "he", "insisted", ",", "against", "O", "##'", "##C", "##onnell", "'", "##s", "wishes", ",", "on", "the", "appointment", "of", "Abraham", "Brewster", "as", "Law", "Ad", "##vise", "##r", "to", "the", "Lord", "Lieutenant", "of", "Ireland", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "insisted", "[unused4]", "[unused5]", "against", "O", "##'", "##C", "##onnell", "'", "##s", "wishes", "on", "the", "appointment", "of", "Abraham", "Brewster", "as", "Law", "Ad", "##vise", "##r", "to", "the", "Lord", "Lieutenant", "of", "Ireland", "[unused6]", "[SEP]"]]}

input 37:  {"source": "As a group , the team was enshrined into the Basketball Hall of Fame in 1959 .\n"}
prediction:  {"predictions": [[1, 1103, 1264, 2, 3, 1108, 4035, 2737, 8643, 1181, 4, 5, 1154, 1103, 6035, 1944, 1104, 4710, 1107, 3003, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-5.03334122186061e-05, -0.10084295272827148, -0.1060190200805664, -0.1060190200805664, -0.1060190200805664, -0.1060190200805664, -0.1060190200805664, -0.1060190200805664, -0.1060190200805664, -0.1060190200805664], "metadata": {"source_tokens": ["As", "a", "group", ",", "the", "team", "was", "en", "##sh", "##rine", "##d", "into", "the", "Basketball", "Hall", "of", "Fame", "in", "1959", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "team", "[unused2]", "[unused3]", "was", "en", "##sh", "##rine", "##d", "[unused4]", "[unused5]", "into", "the", "Basketball", "Hall", "of", "Fame", "in", "1959", "[unused6]", "[SEP]"]]}

input 38:  {"source": "As a result , it becomes clear that the microbe can not survive outside a narrow pH range .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 3316, 4, 5, 2330, 1115, 1103, 17599, 3962, 1169, 1136, 5195, 1796, 170, 4142, 20149, 2079, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00011140650167362764, -0.17272615432739258, -0.17817020416259766, -0.17817020416259766, -0.17816972732543945, -0.17817020416259766, -0.17817020416259766, -0.17817020416259766, -0.17817020416259766, -0.17817020416259766], "metadata": {"source_tokens": ["As", "a", "result", ",", "it", "becomes", "clear", "that", "the", "micro", "##be", "can", "not", "survive", "outside", "a", "narrow", "pH", "range", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "becomes", "[unused4]", "[unused5]", "clear", "that", "the", "micro", "##be", "can", "not", "survive", "outside", "a", "narrow", "pH", "range", "[unused6]", "[SEP]"]]}

input 39:  {"source": "As a result , the lower river had to be dredged three times in two years .\n"}
prediction:  {"predictions": [[1, 1103, 2211, 2186, 2, 3, 1106, 1129, 173, 4359, 3660, 4, 5, 1210, 1551, 1107, 1160, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0018824577564373612, -0.041492462158203125, -0.041852474212646484, -0.041852474212646484, -0.041852474212646484, -0.041852474212646484, -0.041852474212646484, -0.041852474212646484, -0.041852474212646484, -0.041852474212646484], "metadata": {"source_tokens": ["As", "a", "result", ",", "the", "lower", "river", "had", "to", "be", "d", "##red", "##ged", "three", "times", "in", "two", "years", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "lower", "river", "[unused2]", "[unused3]", "to", "be", "d", "##red", "##ged", "[unused4]", "[unused5]", "three", "times", "in", "two", "years", "[unused6]", "[SEP]"]]}

input 40:  {"source": "As early as the 15th century , the French kings sent commissioners to the provinces to inspect on royal and administrative affairs and to take necessary action .\n"}
prediction:  {"predictions": [[1, 1103, 1497, 9419, 2, 3, 1850, 4, 5, 22207, 1106, 1103, 7112, 1106, 25151, 1113, 4276, 1105, 3207, 5707, 1105, 1106, 1321, 3238, 2168, 1249, 1346, 1112, 1103, 5617, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004403094761073589, -0.13735389709472656, -0.14743804931640625, -0.14743804931640625, -0.14743804931640625, -0.14743804931640625, -0.14743804931640625, -0.14743804931640625, -0.14743804931640625, -0.14743804931640625], "metadata": {"source_tokens": ["As", "early", "as", "the", "15th", "century", ",", "the", "French", "kings", "sent", "commissioners", "to", "the", "provinces", "to", "inspect", "on", "royal", "and", "administrative", "affairs", "and", "to", "take", "necessary", "action", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "French", "kings", "[unused2]", "[unused3]", "sent", "[unused4]", "[unused5]", "commissioners", "to", "the", "provinces", "to", "inspect", "on", "royal", "and", "administrative", "affairs", "and", "to", "take", "necessary", "action", "As", "early", "as", "the", "15th", "century", "[unused6]", "[SEP]"]]}

input 41:  {"source": "As in his first novel , Armah contrasts the two worlds of materialism and moral values , corruption and dreams , two worlds of integrity and social pressure .\n"}
prediction:  {"predictions": [[1, 24446, 3354, 2, 3, 26856, 4, 5, 1103, 1160, 11308, 1104, 2578, 1863, 1105, 7279, 4718, 117, 8065, 1105, 6149, 117, 1160, 11308, 1104, 12363, 1105, 1934, 2997, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0014601291622966528, -0.1266493797302246, -0.12095928192138672, -0.12095928192138672, -0.12095928192138672, -0.12095928192138672, -0.12095928192138672, -0.12095928192138672, -0.12095928192138672, -0.12095928192138672], "metadata": {"source_tokens": ["As", "in", "his", "first", "novel", ",", "Arm", "##ah", "contrasts", "the", "two", "worlds", "of", "material", "##ism", "and", "moral", "values", ",", "corruption", "and", "dreams", ",", "two", "worlds", "of", "integrity", "and", "social", "pressure", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Arm", "##ah", "[unused2]", "[unused3]", "contrasts", "[unused4]", "[unused5]", "the", "two", "worlds", "of", "material", "##ism", "and", "moral", "values", ",", "corruption", "and", "dreams", ",", "two", "worlds", "of", "integrity", "and", "social", "pressure", "[unused6]", "[SEP]"]]}

input 42:  {"source": "As is true for all sensors , absolute accuracy of a measurement requires a functionality for calibration .\n"}
prediction:  {"predictions": [[1, 7846, 10893, 1104, 170, 11842, 2, 3, 5315, 4, 5, 170, 16354, 1111, 11019, 2646, 6766, 2116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-4.787445141118951e-05, -0.03476524353027344, -0.03532552719116211, -0.03532552719116211, -0.03532552719116211, -0.03532552719116211, -0.03532552719116211, -0.03532552719116211, -0.03532552719116211, -0.03532552719116211], "metadata": {"source_tokens": ["As", "is", "true", "for", "all", "sensors", ",", "absolute", "accuracy", "of", "a", "measurement", "requires", "a", "functionality", "for", "ca", "##li", "##bra", "##tion", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "absolute", "accuracy", "of", "a", "measurement", "[unused2]", "[unused3]", "requires", "[unused4]", "[unused5]", "a", "functionality", "for", "ca", "##li", "##bra", "##tion", "[unused6]", "[SEP]"]]}

input 43:  {"source": "As of `` A Wind in the Door '' , Sandy aspires to become a banker , on the grounds that it is practical and lucrative .\n"}
prediction:  {"predictions": [[1, 9908, 2, 3, 1112, 20082, 1116, 4, 5, 1106, 1561, 170, 15304, 1113, 1103, 4745, 1115, 1122, 1110, 6691, 1105, 23284, 1249, 1104, 138, 7943, 1107, 1103, 15087, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07540136575698853, -0.12480640411376953, -0.1116490364074707, -0.1116490364074707, -0.1116490364074707, -0.1116490364074707, -0.1116490364074707, -0.1116490364074707, -0.1116490364074707, -0.1116490364074707], "metadata": {"source_tokens": ["As", "of", "`", "##`", "A", "Wind", "in", "the", "Door", "'", "##'", ",", "Sandy", "as", "##pire", "##s", "to", "become", "a", "banker", ",", "on", "the", "grounds", "that", "it", "is", "practical", "and", "lucrative", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sandy", "[unused2]", "[unused3]", "as", "##pire", "##s", "[unused4]", "[unused5]", "to", "become", "a", "banker", "on", "the", "grounds", "that", "it", "is", "practical", "and", "lucrative", "As", "of", "A", "Wind", "in", "the", "Door", "[unused6]", "[SEP]"]]}

input 44:  {"source": "As part of several efforts to have the Gypsy Horse recognized as a breed outside the Romanichal community , a more descriptive name was sought for it , starting in the 1990s .\n"}
prediction:  {"predictions": [[1, 170, 1167, 27938, 1271, 2, 3, 1108, 4110, 4, 5, 1111, 1122, 2547, 1107, 1103, 3281, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 22153, 7429, 2, 3, 3037, 4, 5, 1112, 170, 9489, 1796, 1103, 27876, 17436, 1661, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03175203874707222, -0.030154315754771233, -0.05484294891357422, -0.0541071891784668, -0.0541071891784668, -0.0541071891784668, -0.0541071891784668, -0.0541071891784668, -0.0541071891784668, -0.0541071891784668], "metadata": {"source_tokens": ["As", "part", "of", "several", "efforts", "to", "have", "the", "Gypsy", "Horse", "recognized", "as", "a", "breed", "outside", "the", "Romani", "##chal", "community", ",", "a", "more", "descriptive", "name", "was", "sought", "for", "it", ",", "starting", "in", "the", "1990s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "more", "descriptive", "name", "[unused2]", "[unused3]", "was", "sought", "[unused4]", "[unused5]", "for", "it", "starting", "in", "the", "1990s", "[unused6]", "[SEP]", "[unused1]", "the", "Gypsy", "Horse", "[unused2]", "[unused3]", "recognized", "[unused4]", "[unused5]", "as", "a", "breed", "outside", "the", "Romani", "##chal", "community", "[unused6]", "[SEP]"]]}

input 45:  {"source": "Assisting in the recording process were Fernando Cabello and two friends of the group , Eva Dalda and Lydia Iovanne .\n"}
prediction:  {"predictions": [[1, 1249, 22398, 1158, 1107, 1103, 2730, 1965, 2, 3, 1127, 4, 5, 8834, 140, 22377, 6643, 1105, 1160, 2053, 1104, 1103, 1372, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012890024110674858, -0.2053513526916504, -0.22043800354003906, -0.22043800354003906, -0.22043800354003906, -0.22043800354003906, -0.22043800354003906, -0.22043800354003906, -0.22043800354003906, -0.22043800354003906], "metadata": {"source_tokens": ["As", "##sist", "##ing", "in", "the", "recording", "process", "were", "Fernando", "C", "##abe", "##llo", "and", "two", "friends", "of", "the", "group", ",", "Eva", "Dal", "##da", "and", "Lydia", "I", "##ova", "##nne", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "As", "##sist", "##ing", "in", "the", "recording", "process", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "Fernando", "C", "##abe", "##llo", "and", "two", "friends", "of", "the", "group", "[unused6]", "[SEP]"]]}

input 46:  {"source": "At a presentation in the Toronto Pearson International Airport hangar , Celine Dion helped the newly solvent airline debut its new image .\n"}
prediction:  {"predictions": [[1, 24664, 2568, 21322, 2, 3, 2375, 4, 5, 1103, 3599, 27624, 8694, 1963, 1157, 1207, 3077, 1335, 170, 8685, 1107, 1103, 3506, 13079, 1570, 3369, 22043, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00016805632913019508, -0.05524396896362305, -0.058513641357421875, -0.058513641357421875, -0.058513641357421875, -0.058513641357421875, -0.058513641357421875, -0.058513641357421875, -0.058513641357421875, -0.058513641357421875], "metadata": {"source_tokens": ["At", "a", "presentation", "in", "the", "Toronto", "Pearson", "International", "Airport", "hangar", ",", "Ce", "##line", "Dion", "helped", "the", "newly", "solvent", "airline", "debut", "its", "new", "image", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ce", "##line", "Dion", "[unused2]", "[unused3]", "helped", "[unused4]", "[unused5]", "the", "newly", "solvent", "airline", "debut", "its", "new", "image", "At", "a", "presentation", "in", "the", "Toronto", "Pearson", "International", "Airport", "hangar", "[unused6]", "[SEP]"]]}

input 47:  {"source": "At least 11 villagers disappeared and 8 people were killed in the ensuing tsunami , two of which are prisoners at one of the Permisan prisons .\n"}
prediction:  {"predictions": [[1, 1335, 1655, 1429, 12453, 2, 3, 4712, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 129, 1234, 2, 3, 1127, 1841, 4, 5, 1107, 1103, 14332, 24212, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1160, 1104, 1134, 2, 3, 1132, 4, 5, 5419, 1120, 1141, 1104, 1103, 14286, 15394, 1389, 20070, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.035101573914289474, -0.02323811873793602, -0.017995763570070267, -0.031604766845703125, -0.032029151916503906, -0.032029151916503906, -0.032029151916503906, -0.032029151916503906, -0.032029151916503906, -0.032029151916503906], "metadata": {"source_tokens": ["At", "least", "11", "villagers", "disappeared", "and", "8", "people", "were", "killed", "in", "the", "ensuing", "tsunami", ",", "two", "of", "which", "are", "prisoners", "at", "one", "of", "the", "Per", "##mis", "##an", "prisons", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "At", "least", "11", "villagers", "[unused2]", "[unused3]", "disappeared", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "8", "people", "[unused2]", "[unused3]", "were", "killed", "[unused4]", "[unused5]", "in", "the", "ensuing", "tsunami", "[unused6]", "[SEP]", "[unused1]", "two", "of", "which", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "prisoners", "at", "one", "of", "the", "Per", "##mis", "##an", "prisons", "[unused6]", "[SEP]"]]}

input 48:  {"source": "At no cost to the parents , these services are provided in compliance with state and federal law ; and are reasonably calculated to yield meaningful educational benefit and student progress .\n"}
prediction:  {"predictions": [[1, 1292, 1826, 2, 3, 1132, 2136, 4, 5, 1107, 14037, 1114, 1352, 1105, 2877, 1644, 1335, 1185, 2616, 1106, 1103, 2153, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1292, 2, 3, 1826, 1132, 4, 5, 17517, 10056, 1106, 10972, 17119, 4339, 5257, 1105, 2377, 5070, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0012063985923305154, -0.11624614894390106, -0.087646484375, -0.08669328689575195, -0.08669328689575195, -0.08669328689575195, -0.08669328689575195, -0.08669328689575195, -0.08669328689575195, -0.08669328689575195], "metadata": {"source_tokens": ["At", "no", "cost", "to", "the", "parents", ",", "these", "services", "are", "provided", "in", "compliance", "with", "state", "and", "federal", "law", ";", "and", "are", "reasonably", "calculated", "to", "yield", "meaningful", "educational", "benefit", "and", "student", "progress", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "these", "services", "[unused2]", "[unused3]", "are", "provided", "[unused4]", "[unused5]", "in", "compliance", "with", "state", "and", "federal", "law", "At", "no", "cost", "to", "the", "parents", "[unused6]", "[SEP]", "[unused1]", "these", "[unused2]", "[unused3]", "services", "are", "[unused4]", "[unused5]", "reasonably", "calculated", "to", "yield", "meaningful", "educational", "benefit", "and", "student", "progress", "[unused6]", "[SEP]"]]}

input 49:  {"source": "At one point , Ballard is nearly possessed , but resists when she is given a drug and discovers that the spirits are attacking them as they believe that the humans are invaders and plan to exterminate the humans on Mars .\n"}
prediction:  {"predictions": [[1, 24241, 2, 3, 9345, 1116, 4, 5, 1165, 1131, 1110, 1549, 170, 3850, 1105, 9149, 1115, 1103, 9494, 1132, 7492, 1172, 1112, 1152, 2059, 1115, 1103, 3612, 1132, 22864, 1105, 2197, 1106, 4252, 2083, 17379, 1103, 3612, 1113, 7403, 1335, 1141, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 1, 24241, 2, 3, 1110, 4, 5, 2212, 8471, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1110, 1549, 4, 5, 170, 3850, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023123012855648994, -0.17105434834957123, -0.12670181691646576, -0.1973409652709961, -0.19481372833251953, -0.19481372833251953, -0.19481372833251953, -0.19481372833251953, -0.19481372833251953, -0.19481372833251953], "metadata": {"source_tokens": ["At", "one", "point", ",", "Ballard", "is", "nearly", "possessed", ",", "but", "resist", "##s", "when", "she", "is", "given", "a", "drug", "and", "discovers", "that", "the", "spirits", "are", "attacking", "them", "as", "they", "believe", "that", "the", "humans", "are", "invaders", "and", "plan", "to", "ex", "##ter", "##minate", "the", "humans", "on", "Mars", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ballard", "[unused2]", "[unused3]", "resist", "##s", "[unused4]", "[unused5]", "when", "she", "is", "given", "a", "drug", "and", "discovers", "that", "the", "spirits", "are", "attacking", "them", "as", "they", "believe", "that", "the", "humans", "are", "invaders", "and", "plan", "to", "ex", "##ter", "##minate", "the", "humans", "on", "Mars", "At", "one", "point", "[unused6]", "[SEP]", "[unused1]", "Ballard", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "nearly", "possessed", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "is", "given", "[unused4]", "[unused5]", "a", "drug", "[unused6]", "[SEP]"]]}

input 50:  {"source": "Barbara , however , unable to leave behind her vigilante life , fought a mugger and ultimately miscarried her child .\n"}
prediction:  {"predictions": [[1, 5934, 2, 3, 3214, 4, 5, 170, 15761, 2895, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5934, 2, 3, 1940, 26996, 18888, 4, 5, 1123, 2027, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07499691098928452, -0.17342332005500793, -0.057552337646484375, -0.05864572525024414, -0.05864572525024414, -0.05864572525024414, -0.05864572525024414, -0.05864572525024414, -0.05864572525024414, -0.05864572525024414], "metadata": {"source_tokens": ["Barbara", ",", "however", ",", "unable", "to", "leave", "behind", "her", "v", "##igi", "##lante", "life", ",", "fought", "a", "mug", "##ger", "and", "ultimately", "mi", "##sca", "##rried", "her", "child", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Barbara", "[unused2]", "[unused3]", "fought", "[unused4]", "[unused5]", "a", "mug", "##ger", "[unused6]", "[SEP]", "[unused1]", "Barbara", "[unused2]", "[unused3]", "mi", "##sca", "##rried", "[unused4]", "[unused5]", "her", "child", "[unused6]", "[SEP]"]]}

input 51:  {"source": "Because Yesler Way marks the boundary between two different plats , the street grid north of Yesler does not line up with the neighborhood 's other streets , so the northern `` border '' of the district zigzags along numerous streets .\n"}
prediction:  {"predictions": [[1, 2160, 2879, 4714, 2, 3, 6216, 4, 5, 1103, 5904, 1206, 1160, 1472, 185, 16236, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2472, 8866, 1564, 1104, 2160, 2879, 2, 3, 1674, 1136, 1413, 1146, 4, 5, 1114, 1103, 4532, 112, 1116, 1168, 4324, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2472, 8866, 1564, 1104, 2160, 2879, 2, 3, 1674, 1136, 1413, 1146, 4, 5, 1114, 1103, 4532, 112, 1116, 1168, 4324, 1177, 1103, 2350, 3070, 1104, 1103, 1629, 195, 6512, 3293, 5700, 1373, 2567, 4324, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.025386659428477287, -0.014568907208740711, -0.049537837505340576, -0.04818439483642578, -0.047032833099365234, -0.047032833099365234, -0.047032833099365234, -0.047032833099365234, -0.047032833099365234, -0.047032833099365234], "metadata": {"source_tokens": ["Because", "Yes", "##ler", "Way", "marks", "the", "boundary", "between", "two", "different", "p", "##lat", "##s", ",", "the", "street", "grid", "north", "of", "Yes", "##ler", "does", "not", "line", "up", "with", "the", "neighborhood", "'", "##s", "other", "streets", ",", "so", "the", "northern", "`", "##`", "border", "'", "##'", "of", "the", "district", "z", "##ig", "##za", "##gs", "along", "numerous", "streets", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Yes", "##ler", "Way", "[unused2]", "[unused3]", "marks", "[unused4]", "[unused5]", "the", "boundary", "between", "two", "different", "p", "##lat", "##s", "[unused6]", "[SEP]", "[unused1]", "the", "street", "grid", "north", "of", "Yes", "##ler", "[unused2]", "[unused3]", "does", "not", "line", "up", "[unused4]", "[unused5]", "with", "the", "neighborhood", "'", "##s", "other", "streets", "[unused6]", "[SEP]", "[unused1]", "the", "street", "grid", "north", "of", "Yes", "##ler", "[unused2]", "[unused3]", "does", "not", "line", "up", "[unused4]", "[unused5]", "with", "the", "neighborhood", "'", "##s", "other", "streets", "so", "the", "northern", "border", "of", "the", "district", "z", "##ig", "##za", "##gs", "along", "numerous", "streets", "[unused6]", "[SEP]"]]}

input 52:  {"source": "Because of Muhammad 's role in its formation , the alliance plays a significant role in Islamic ethics .\n"}
prediction:  {"predictions": [[1, 1103, 7214, 2, 3, 2399, 4, 5, 170, 2418, 1648, 1107, 4769, 13438, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-4.944950342178345e-05, -0.024660110473632812, -0.024276256561279297, -0.024276256561279297, -0.024276256561279297, -0.024276256561279297, -0.024276256561279297, -0.024276256561279297, -0.024276256561279297, -0.024276256561279297], "metadata": {"source_tokens": ["Because", "of", "Muhammad", "'", "##s", "role", "in", "its", "formation", ",", "the", "alliance", "plays", "a", "significant", "role", "in", "Islamic", "ethics", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "alliance", "[unused2]", "[unused3]", "plays", "[unused4]", "[unused5]", "a", "significant", "role", "in", "Islamic", "ethics", "[unused6]", "[SEP]"]]}

input 53:  {"source": "Because of his talents and training , Beast can outperform any Olympic-level athlete , contorting his body and performing aerial feats gracefully .\n"}
prediction:  {"predictions": [[1, 11868, 2, 3, 1169, 1149, 3365, 13199, 4, 5, 1251, 3557, 28137, 23403, 1883, 8765, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11868, 2, 3, 1169, 1149, 3365, 13199, 4, 5, 1251, 3557, 28137, 23403, 1883, 8765, 14255, 2772, 1916, 1117, 1404, 1105, 4072, 10485, 8809, 1116, 21620, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02846558950841427, -0.06519702821969986, -0.09344196319580078, -0.09720325469970703, -0.09720325469970703, -0.09720325469970703, -0.09720325469970703, -0.09720325469970703, -0.09720325469970703, -0.09720325469970703], "metadata": {"source_tokens": ["Because", "of", "his", "talents", "and", "training", ",", "Beast", "can", "out", "##per", "##form", "any", "Olympic", "##-", "##lev", "##el", "athlete", ",", "con", "##tor", "##ting", "his", "body", "and", "performing", "aerial", "feat", "##s", "graceful", "##ly", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Beast", "[unused2]", "[unused3]", "can", "out", "##per", "##form", "[unused4]", "[unused5]", "any", "Olympic", "##-", "##lev", "##el", "athlete", "[unused6]", "[SEP]", "[unused1]", "Beast", "[unused2]", "[unused3]", "can", "out", "##per", "##form", "[unused4]", "[unused5]", "any", "Olympic", "##-", "##lev", "##el", "athlete", "con", "##tor", "##ting", "his", "body", "and", "performing", "aerial", "feat", "##s", "graceful", "##ly", "[unused6]", "[SEP]"]]}

input 54:  {"source": "Bruce 's Justice Lord counterpart was happily married to Wonder Woman as well until her Justice Lord counterpart killed him .\n"}
prediction:  {"predictions": [[1, 4767, 112, 1116, 3302, 2188, 14132, 2, 3, 1108, 11786, 1597, 4, 5, 1106, 10991, 5651, 1112, 1218, 1235, 1123, 3302, 2188, 14132, 1841, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.025934649631381035, -0.09124517440795898, -0.07470035552978516, -0.07470035552978516, -0.07470035552978516, -0.07470035552978516, -0.07470035552978516, -0.07470035552978516, -0.07470035552978516, -0.07470035552978516], "metadata": {"source_tokens": ["Bruce", "'", "##s", "Justice", "Lord", "counterpart", "was", "happily", "married", "to", "Wonder", "Woman", "as", "well", "until", "her", "Justice", "Lord", "counterpart", "killed", "him", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Bruce", "'", "##s", "Justice", "Lord", "counterpart", "[unused2]", "[unused3]", "was", "happily", "married", "[unused4]", "[unused5]", "to", "Wonder", "Woman", "as", "well", "until", "her", "Justice", "Lord", "counterpart", "killed", "him", "[unused6]", "[SEP]"]]}

input 55:  {"source": "Burnham died of heart failure at the age of 86 , on September 1 , 1947 at his home in Santa , Barbara , California .\n"}
prediction:  {"predictions": [[1, 16915, 2522, 2, 3, 1452, 4, 5, 1104, 1762, 4290, 1120, 1103, 1425, 1104, 5942, 1113, 1347, 122, 3138, 1120, 1117, 1313, 1107, 3364, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05274168774485588, -0.09138154983520508, -0.09296512603759766, -0.09296512603759766, -0.09296512603759766, -0.09296512603759766, -0.09296512603759766, -0.09296512603759766, -0.09296512603759766, -0.09296512603759766], "metadata": {"source_tokens": ["Burn", "##ham", "died", "of", "heart", "failure", "at", "the", "age", "of", "86", ",", "on", "September", "1", ",", "1947", "at", "his", "home", "in", "Santa", ",", "Barbara", ",", "California", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Burn", "##ham", "[unused2]", "[unused3]", "died", "[unused4]", "[unused5]", "of", "heart", "failure", "at", "the", "age", "of", "86", "on", "September", "1", "1947", "at", "his", "home", "in", "Santa", "[unused6]", "[SEP]"]]}

input 56:  {"source": "But this practice simply reduces government interest costs rather than truly canceling government debt , and can result in hyperinflation if used unsparingly .\n"}
prediction:  {"predictions": [[1, 1142, 2415, 2, 3, 2566, 13822, 4, 5, 1433, 2199, 4692, 1897, 1190, 5098, 19722, 1158, 1433, 6695, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1142, 2415, 2, 3, 1169, 1871, 4, 5, 1107, 177, 24312, 1394, 2087, 6840, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02436065673828125, -0.051016177982091904, -0.05063676834106445, -0.048741817474365234, -0.048741817474365234, -0.048741817474365234, -0.048741817474365234, -0.048741817474365234, -0.048741817474365234, -0.048741817474365234], "metadata": {"source_tokens": ["But", "this", "practice", "simply", "reduces", "government", "interest", "costs", "rather", "than", "truly", "cancel", "##ing", "government", "debt", ",", "and", "can", "result", "in", "h", "##yper", "##in", "##f", "##lation", "if", "used", "un", "##sp", "##aring", "##ly", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "this", "practice", "[unused2]", "[unused3]", "simply", "reduces", "[unused4]", "[unused5]", "government", "interest", "costs", "rather", "than", "truly", "cancel", "##ing", "government", "debt", "[unused6]", "[SEP]", "[unused1]", "this", "practice", "[unused2]", "[unused3]", "can", "result", "[unused4]", "[unused5]", "in", "h", "##yper", "##in", "##f", "##lation", "[unused6]", "[SEP]"]]}

input 57:  {"source": "By then , she was raising not only her own children but also her nephews , who had been orphaned by the plague .\n"}
prediction:  {"predictions": [[1, 1131, 2, 3, 1108, 5920, 4, 5, 1136, 1178, 1123, 1319, 1482, 1133, 1145, 1123, 7502, 1116, 1650, 1173, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1145, 1123, 7502, 1116, 2, 3, 1125, 1151, 25298, 1174, 4, 5, 1118, 1103, 13824, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.016173450276255608, -0.0545990876853466, -0.017092227935791016, -0.016239643096923828, -0.016239643096923828, -0.016239643096923828, -0.016239643096923828, -0.016239643096923828, -0.016239643096923828, -0.016239643096923828], "metadata": {"source_tokens": ["By", "then", ",", "she", "was", "raising", "not", "only", "her", "own", "children", "but", "also", "her", "nephew", "##s", ",", "who", "had", "been", "orphan", "##ed", "by", "the", "plague", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "she", "[unused2]", "[unused3]", "was", "raising", "[unused4]", "[unused5]", "not", "only", "her", "own", "children", "but", "also", "her", "nephew", "##s", "By", "then", "[unused6]", "[SEP]", "[unused1]", "also", "her", "nephew", "##s", "[unused2]", "[unused3]", "had", "been", "orphan", "##ed", "[unused4]", "[unused5]", "by", "the", "plague", "[unused6]", "[SEP]"]]}

input 58:  {"source": "By this point , Simpson had returned to his mansion in Brentwood and had surrendered to police .\n"}
prediction:  {"predictions": [[1, 8989, 2, 3, 1125, 1608, 4, 5, 1106, 1117, 8280, 1107, 13150, 2615, 1650, 1142, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8989, 2, 3, 1125, 10738, 4, 5, 1106, 2021, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.022361690178513527, -0.012600504793226719, -0.016893386840820312, -0.02004528045654297, -0.02004528045654297, -0.02004528045654297, -0.02004528045654297, -0.02004528045654297, -0.02004528045654297, -0.02004528045654297], "metadata": {"source_tokens": ["By", "this", "point", ",", "Simpson", "had", "returned", "to", "his", "mansion", "in", "Brent", "##wood", "and", "had", "surrendered", "to", "police", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Simpson", "[unused2]", "[unused3]", "had", "returned", "[unused4]", "[unused5]", "to", "his", "mansion", "in", "Brent", "##wood", "By", "this", "point", "[unused6]", "[SEP]", "[unused1]", "Simpson", "[unused2]", "[unused3]", "had", "surrendered", "[unused4]", "[unused5]", "to", "police", "[unused6]", "[SEP]"]]}

input 59:  {"source": "Byers states that global citizenship is a `` powerful term '' because `` people that invoke it do so to provoke and justify action , '' and encourages the attendees of his lecture to re-appropriate it in order for its meaning to have a positive purpose , based on idealistic values .\n"}
prediction:  {"predictions": [[1, 17774, 1733, 2, 3, 2231, 4, 5, 1115, 4265, 9709, 1110, 170, 169, 28152, 3110, 1858, 1272, 169, 28152, 1234, 1115, 1107, 14638, 1122, 1202, 1177, 1106, 5250, 14638, 1105, 17422, 2168, 117, 112, 28131, 1105, 17233, 1103, 23150, 1104, 1117, 10309, 1106, 1231, 28137, 11478, 1643, 12736, 3464, 102, 1, 4265, 9709, 2, 3, 1110, 4, 5, 170, 169, 28152, 3110, 1858, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4265, 9709, 2, 3, 17233, 4, 5, 1103, 23150, 1104, 1117, 10309, 1106, 1231, 28137, 11478, 1643, 12736, 3464, 1566, 1107, 1546, 1111, 1157, 2764, 1106, 1138, 170, 3112, 3007, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4265, 9709, 2, 3, 1110, 4, 5, 170, 3110, 1858, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.038391467183828354, -0.11234372109174728, -0.10974828898906708, -0.22874465584754944, -0.3114633560180664, -0.3156719207763672, -0.3156719207763672, -0.3156719207763672, -0.3156719207763672, -0.3156719207763672], "metadata": {"source_tokens": ["Bye", "##rs", "states", "that", "global", "citizenship", "is", "a", "`", "##`", "powerful", "term", "'", "##'", "because", "`", "##`", "people", "that", "in", "##voke", "it", "do", "so", "to", "pro", "##voke", "and", "justify", "action", ",", "'", "##'", "and", "encourages", "the", "attendees", "of", "his", "lecture", "to", "re", "##-", "##ap", "##p", "##rop", "##ria", "##te", "it", "in", "order", "for", "its", "meaning", "to", "have", "a", "positive", "purpose", ",", "based", "on", "ideal", "##istic", "values", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Bye", "##rs", "[unused2]", "[unused3]", "states", "[unused4]", "[unused5]", "that", "global", "citizenship", "is", "a", "`", "##`", "powerful", "term", "because", "`", "##`", "people", "that", "in", "##voke", "it", "do", "so", "to", "pro", "##voke", "and", "justify", "action", ",", "'", "##'", "and", "encourages", "the", "attendees", "of", "his", "lecture", "to", "re", "##-", "##ap", "##p", "##rop", "##ria", "[SEP]", "[unused1]", "global", "citizenship", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "`", "##`", "powerful", "term", "[unused6]", "[SEP]", "[unused1]", "global", "citizenship", "[unused2]", "[unused3]", "encourages", "[unused4]", "[unused5]", "the", "attendees", "of", "his", "lecture", "to", "re", "##-", "##ap", "##p", "##rop", "##ria", "##te", "in", "order", "for", "its", "meaning", "to", "have", "a", "positive", "purpose", "[unused6]", "[SEP]", "[unused1]", "global", "citizenship", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "powerful", "term", "[unused6]", "[SEP]"]]}

input 60:  {"source": "Carl uses the `` old magic '' to tame the Deep Crow , claiming it is not his `` first time to the rodeo . ''\n"}
prediction:  {"predictions": [[1, 4804, 2, 3, 2745, 4, 5, 1103, 169, 28152, 1385, 3974, 1106, 27629, 3263, 1103, 7786, 15252, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 1136, 4, 5, 1117, 169, 28152, 1148, 1159, 1106, 1103, 8335, 1186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4804, 2, 3, 2745, 4, 5, 1103, 169, 28152, 1385, 3974, 1106, 27629, 3263, 1103, 7786, 15252, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.059098877012729645, -0.09581685811281204, -0.17591726779937744, -0.19883251190185547, -0.20313358306884766, -0.20313358306884766, -0.20313358306884766, -0.20313358306884766, -0.20313358306884766, -0.20313358306884766], "metadata": {"source_tokens": ["Carl", "uses", "the", "`", "##`", "old", "magic", "'", "##'", "to", "ta", "##me", "the", "Deep", "Crow", ",", "claiming", "it", "is", "not", "his", "`", "##`", "first", "time", "to", "the", "rode", "##o", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Carl", "[unused2]", "[unused3]", "uses", "[unused4]", "[unused5]", "the", "`", "##`", "old", "magic", "to", "ta", "##me", "the", "Deep", "Crow", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "not", "[unused4]", "[unused5]", "his", "`", "##`", "first", "time", "to", "the", "rode", "##o", "[unused6]", "[SEP]", "[unused1]", "Carl", "[unused2]", "[unused3]", "uses", "[unused4]", "[unused5]", "the", "`", "##`", "old", "magic", "to", "ta", "##me", "the", "Deep", "Crow", "[unused6]", "[SEP]"]]}

input 61:  {"source": "Certain fractional quantum Hall phases appear to have the right properties for building a topological quantum computer .\n"}
prediction:  {"predictions": [[1, 16482, 13394, 1348, 9539, 1944, 12877, 2, 3, 2845, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16482, 13394, 1348, 9539, 1944, 12877, 2, 3, 1106, 1138, 4, 5, 1103, 1268, 4625, 1111, 1459, 170, 1499, 7542, 9539, 2775, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009412356652319431, -0.020685233175754547, -0.014648914337158203, -0.013357162475585938, -0.013357162475585938, -0.013357162475585938, -0.013357162475585938, -0.013357162475585938, -0.013357162475585938, -0.013357162475585938], "metadata": {"source_tokens": ["Certain", "fraction", "##al", "quantum", "Hall", "phases", "appear", "to", "have", "the", "right", "properties", "for", "building", "a", "top", "##ological", "quantum", "computer", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Certain", "fraction", "##al", "quantum", "Hall", "phases", "[unused2]", "[unused3]", "appear", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Certain", "fraction", "##al", "quantum", "Hall", "phases", "[unused2]", "[unused3]", "to", "have", "[unused4]", "[unused5]", "the", "right", "properties", "for", "building", "a", "top", "##ological", "quantum", "computer", "[unused6]", "[SEP]"]]}

input 62:  {"source": "Chevalier fulfilled his promise the following year by erecting a shrine dedicated to the honour of Mary under the title of `` Our Lady of the Sacred Heart '' .\n"}
prediction:  {"predictions": [[1, 26353, 2, 3, 18210, 4, 5, 1117, 4437, 1103, 1378, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 12157, 2, 3, 3256, 4, 5, 1106, 1103, 6565, 1104, 2090, 1223, 1103, 1641, 1104, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26353, 2, 3, 18210, 1117, 4437, 1118, 15685, 1158, 4, 5, 170, 12157, 3256, 1106, 1103, 6565, 1104, 2090, 1223, 1103, 1641, 1104, 3458, 2876, 1104, 1103, 11373, 4641, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06198856607079506, -0.07579727470874786, -0.07094451785087585, -0.05078554153442383, -0.050128936767578125, -0.050128936767578125, -0.050128936767578125, -0.050128936767578125, -0.050128936767578125, -0.050128936767578125], "metadata": {"source_tokens": ["Chevalier", "fulfilled", "his", "promise", "the", "following", "year", "by", "erect", "##ing", "a", "shrine", "dedicated", "to", "the", "honour", "of", "Mary", "under", "the", "title", "of", "`", "##`", "Our", "Lady", "of", "the", "Sacred", "Heart", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Chevalier", "[unused2]", "[unused3]", "fulfilled", "[unused4]", "[unused5]", "his", "promise", "the", "following", "year", "[unused6]", "[SEP]", "[unused1]", "a", "shrine", "[unused2]", "[unused3]", "dedicated", "[unused4]", "[unused5]", "to", "the", "honour", "of", "Mary", "under", "the", "title", "of", "[unused6]", "[SEP]", "[unused1]", "Chevalier", "[unused2]", "[unused3]", "fulfilled", "his", "promise", "by", "erect", "##ing", "[unused4]", "[unused5]", "a", "shrine", "dedicated", "to", "the", "honour", "of", "Mary", "under", "the", "title", "of", "Our", "Lady", "of", "the", "Sacred", "Heart", "[unused6]", "[SEP]"]]}

input 63:  {"source": "Cis-regulatory elements are sequences that control the transcription of a nearby gene .\n"}
prediction:  {"predictions": [[1, 140, 1548, 28137, 1874, 13830, 13389, 1183, 3050, 2, 3, 1132, 4, 5, 10028, 1115, 1654, 1103, 15416, 1104, 170, 2721, 5565, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00017760753689799458, -0.09763193130493164, -0.12190580368041992, -0.12190580368041992, -0.12190580368041992, -0.12190580368041992, -0.12190580368041992, -0.12190580368041992, -0.12190580368041992, -0.12190580368041992], "metadata": {"source_tokens": ["C", "##is", "##-", "##re", "##gu", "##lator", "##y", "elements", "are", "sequences", "that", "control", "the", "transcription", "of", "a", "nearby", "gene", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "C", "##is", "##-", "##re", "##gu", "##lator", "##y", "elements", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "sequences", "that", "control", "the", "transcription", "of", "a", "nearby", "gene", "[unused6]", "[SEP]"]]}

input 64:  {"source": "Citizens for Responsibility and Ethics in Washington filed an Ethics Committee complaint against Bond over his role in the ouster of Graves .\n"}
prediction:  {"predictions": [[1, 14649, 1111, 11336, 20080, 4199, 7706, 1105, 17475, 1107, 1994, 2, 3, 5770, 4, 5, 1126, 17475, 2341, 12522, 1222, 8211, 1166, 1117, 1648, 1107, 1103, 20796, 4648, 1104, 16494, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0013006384251639247, -0.05474090576171875, -0.048421382904052734, -0.048421382904052734, -0.048421382904052734, -0.048421382904052734, -0.048421382904052734, -0.048421382904052734, -0.048421382904052734, -0.048421382904052734], "metadata": {"source_tokens": ["Citizens", "for", "Re", "##sp", "##ons", "##ibility", "and", "Ethics", "in", "Washington", "filed", "an", "Ethics", "Committee", "complaint", "against", "Bond", "over", "his", "role", "in", "the", "ou", "##ster", "of", "Graves", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Citizens", "for", "Re", "##sp", "##ons", "##ibility", "and", "Ethics", "in", "Washington", "[unused2]", "[unused3]", "filed", "[unused4]", "[unused5]", "an", "Ethics", "Committee", "complaint", "against", "Bond", "over", "his", "role", "in", "the", "ou", "##ster", "of", "Graves", "[unused6]", "[SEP]"]]}

input 65:  {"source": "Combined with appropriate match pellets these rifles produce a consistent 10 ring performance , so a non-maximal result during the initial phase can be attributed to the participant .\n"}
prediction:  {"predictions": [[1, 1292, 12385, 2, 3, 3133, 4, 5, 170, 8080, 1275, 3170, 2099, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1177, 170, 1664, 28137, 22871, 8628, 1233, 1871, 1219, 1103, 3288, 4065, 2, 3, 1169, 1129, 6547, 4, 5, 1106, 1103, 14031, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05208326131105423, -0.022826289758086205, -0.06325006484985352, -0.06203889846801758, -0.06203889846801758, -0.06203889846801758, -0.06203889846801758, -0.06203889846801758, -0.06203889846801758, -0.06203889846801758], "metadata": {"source_tokens": ["Combined", "with", "appropriate", "match", "p", "##elle", "##ts", "these", "rifles", "produce", "a", "consistent", "10", "ring", "performance", ",", "so", "a", "non", "##-", "##max", "##ima", "##l", "result", "during", "the", "initial", "phase", "can", "be", "attributed", "to", "the", "participant", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "these", "rifles", "[unused2]", "[unused3]", "produce", "[unused4]", "[unused5]", "a", "consistent", "10", "ring", "performance", "[unused6]", "[SEP]", "[unused1]", "so", "a", "non", "##-", "##max", "##ima", "##l", "result", "during", "the", "initial", "phase", "[unused2]", "[unused3]", "can", "be", "attributed", "[unused4]", "[unused5]", "to", "the", "participant", "[unused6]", "[SEP]"]]}

input 66:  {"source": "Curley was the first classical organist to perform a solo organ recital at the White House , and also played before several European heads of state .\n"}
prediction:  {"predictions": [[1, 140, 27009, 2, 3, 1108, 4, 5, 1103, 1148, 4521, 19209, 1106, 3870, 170, 3444, 5677, 1231, 6617, 6163, 1120, 1103, 2061, 1585, 117, 1105, 1145, 1307, 1196, 1317, 1735, 4075, 1104, 1352, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023898832499980927, -0.0937490463256836, -0.09697771072387695, -0.09697771072387695, -0.09697771072387695, -0.09697771072387695, -0.09697771072387695, -0.09697771072387695, -0.09697771072387695, -0.09697771072387695], "metadata": {"source_tokens": ["C", "##urley", "was", "the", "first", "classical", "organist", "to", "perform", "a", "solo", "organ", "re", "##ci", "##tal", "at", "the", "White", "House", ",", "and", "also", "played", "before", "several", "European", "heads", "of", "state", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "C", "##urley", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "first", "classical", "organist", "to", "perform", "a", "solo", "organ", "re", "##ci", "##tal", "at", "the", "White", "House", ",", "and", "also", "played", "before", "several", "European", "heads", "of", "state", "[unused6]", "[SEP]"]]}

input 67:  {"source": "DC Comics held a memorial service in Manhattan 's Lower East Side , a neighborhood Eisner often visited in his work , at the Angel Orensanz Foundation on Norfolk Street .\n"}
prediction:  {"predictions": [[1, 5227, 7452, 2, 3, 1316, 4, 5, 170, 6768, 1555, 1107, 6545, 112, 1116, 5738, 1689, 6383, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4532, 2, 3, 1129, 3891, 4, 5, 1107, 1117, 1250, 1120, 1103, 5876, 2926, 5026, 1389, 1584, 2974, 1113, 7240, 1715, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 142, 1548, 2511, 2, 3, 1110, 4, 5, 1510, 1510, 3891, 1107, 1117, 1250, 1120, 1103, 5876, 2926, 5026, 1389, 1584, 2974, 1113, 7240, 1715, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005095076747238636, -0.09770110994577408, -0.13035698235034943, -0.06776046752929688, -0.06590461730957031, -0.06590461730957031, -0.06590461730957031, -0.06590461730957031, -0.06590461730957031, -0.06590461730957031], "metadata": {"source_tokens": ["DC", "Comics", "held", "a", "memorial", "service", "in", "Manhattan", "'", "##s", "Lower", "East", "Side", ",", "a", "neighborhood", "E", "##is", "##ner", "often", "visited", "in", "his", "work", ",", "at", "the", "Angel", "Or", "##ens", "##an", "##z", "Foundation", "on", "Norfolk", "Street", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "DC", "Comics", "[unused2]", "[unused3]", "held", "[unused4]", "[unused5]", "a", "memorial", "service", "in", "Manhattan", "'", "##s", "Lower", "East", "Side", "[unused6]", "[SEP]", "[unused1]", "a", "neighborhood", "[unused2]", "[unused3]", "be", "visited", "[unused4]", "[unused5]", "in", "his", "work", "at", "the", "Angel", "Or", "##ens", "##an", "##z", "Foundation", "on", "Norfolk", "Street", "[unused6]", "[SEP]", "[unused1]", "E", "##is", "##ner", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "often", "often", "visited", "in", "his", "work", "at", "the", "Angel", "Or", "##ens", "##an", "##z", "Foundation", "on", "Norfolk", "Street", "[unused6]", "[SEP]"]]}

input 68:  {"source": "Despite the below-freezing temperatures , Beuerlein was red-hot , out-dueling Brett Favre and connecting on 29 of 42 attempts , with 3 TDs and no INTs , and passing for a then franchise-record 373 yards .\n"}
prediction:  {"predictions": [[1, 4108, 10232, 18929, 2, 3, 1108, 4, 5, 1894, 28137, 12217, 1149, 28137, 21405, 1979, 12161, 143, 23140, 1874, 1105, 6755, 1113, 1853, 1104, 3565, 4021, 1114, 124, 15439, 1116, 1105, 1185, 15969, 1942, 1116, 1105, 3744, 1111, 170, 1173, 5801, 28137, 1874, 19248, 1181, 3413, 1495, 3422, 6, 102, 1, 4108, 10232, 18929, 2, 3, 1108, 4, 5, 1894, 28137, 12217, 1149, 28137, 21405, 1979, 12161, 143, 23140, 1874, 1105, 6755, 1113, 1853, 1104, 3565, 4021, 2711, 1103, 2071, 28137, 26743, 6185, 7479, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.022997643798589706, -0.06786724179983139, -0.23306608200073242, -0.23422527313232422, -0.23422527313232422, -0.23422527313232422, -0.23422527313232422, -0.23422527313232422, -0.23422527313232422, -0.23422527313232422], "metadata": {"source_tokens": ["Despite", "the", "below", "##-", "##free", "##zing", "temperatures", ",", "Be", "##uer", "##lein", "was", "red", "##-", "##hot", ",", "out", "##-", "##due", "##ling", "Brett", "F", "##av", "##re", "and", "connecting", "on", "29", "of", "42", "attempts", ",", "with", "3", "TD", "##s", "and", "no", "IN", "##T", "##s", ",", "and", "passing", "for", "a", "then", "franchise", "##-", "##re", "##cor", "##d", "37", "##3", "yards", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Be", "##uer", "##lein", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "red", "##-", "##hot", "out", "##-", "##due", "##ling", "Brett", "F", "##av", "##re", "and", "connecting", "on", "29", "of", "42", "attempts", "with", "3", "TD", "##s", "and", "no", "IN", "##T", "##s", "and", "passing", "for", "a", "then", "franchise", "##-", "##re", "##cor", "##d", "37", "##3", "yards", "[unused6]", "[SEP]", "[unused1]", "Be", "##uer", "##lein", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "red", "##-", "##hot", "out", "##-", "##due", "##ling", "Brett", "F", "##av", "##re", "and", "connecting", "on", "29", "of", "42", "attempts", "Despite", "the", "below", "##-", "##free", "##zing", "temperatures", "[unused6]", "[SEP]"]]}

input 69:  {"source": "Dodo was originally intended to have a `` common '' accent , and is portrayed this way at the end of `` The Massacre '' .\n"}
prediction:  {"predictions": [[1, 2091, 2572, 2, 3, 1110, 6313, 4, 5, 1142, 1236, 1120, 1103, 1322, 1104, 169, 28152, 1109, 20507, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2091, 2572, 2, 3, 1106, 1138, 4, 5, 170, 169, 28152, 1887, 112, 28131, 9603, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05826317518949509, -0.028030719608068466, -0.13048696517944336, -0.13196897506713867, -0.13196897506713867, -0.13196897506713867, -0.13196897506713867, -0.13196897506713867, -0.13196897506713867, -0.13196897506713867], "metadata": {"source_tokens": ["Do", "##do", "was", "originally", "intended", "to", "have", "a", "`", "##`", "common", "'", "##'", "accent", ",", "and", "is", "portrayed", "this", "way", "at", "the", "end", "of", "`", "##`", "The", "Massacre", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Do", "##do", "[unused2]", "[unused3]", "is", "portrayed", "[unused4]", "[unused5]", "this", "way", "at", "the", "end", "of", "`", "##`", "The", "Massacre", "[unused6]", "[SEP]", "[unused1]", "Do", "##do", "[unused2]", "[unused3]", "to", "have", "[unused4]", "[unused5]", "a", "`", "##`", "common", "'", "##'", "accent", "[unused6]", "[SEP]"]]}

input 70:  {"source": "Dr. Pim played for Ireland against England in 1892 , 1893 , 1894 and 1896 .\n"}
prediction:  {"predictions": [[1, 1987, 28138, 21902, 1306, 2, 3, 1307, 4, 5, 1111, 2270, 1222, 1652, 1107, 5889, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00913501437753439, -0.05122661590576172, -0.04965925216674805, -0.04965925216674805, -0.04965925216674805, -0.04965925216674805, -0.04965925216674805, -0.04965925216674805, -0.04965925216674805, -0.04965925216674805], "metadata": {"source_tokens": ["Dr", "##.", "Pi", "##m", "played", "for", "Ireland", "against", "England", "in", "1892", ",", "1893", ",", "1894", "and", "1896", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Dr", "##.", "Pi", "##m", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "for", "Ireland", "against", "England", "in", "1892", "[unused6]", "[SEP]"]]}

input 71:  {"source": "Due to the opposing nature of the two songs , they can be viewed as a debate on the opposing attitudes on love found throughout the play .\n"}
prediction:  {"predictions": [[1, 1103, 10137, 15149, 1113, 1567, 2, 3, 1276, 4, 5, 2032, 1103, 1505, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1169, 1129, 6497, 4, 5, 1112, 170, 5655, 1113, 1103, 10137, 15149, 1113, 1567, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023847507312893867, -0.004742990247905254, -0.02156829833984375, -0.021216869354248047, -0.021216869354248047, -0.021216869354248047, -0.021216869354248047, -0.021216869354248047, -0.021216869354248047, -0.021216869354248047], "metadata": {"source_tokens": ["Due", "to", "the", "opposing", "nature", "of", "the", "two", "songs", ",", "they", "can", "be", "viewed", "as", "a", "debate", "on", "the", "opposing", "attitudes", "on", "love", "found", "throughout", "the", "play", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "opposing", "attitudes", "on", "love", "[unused2]", "[unused3]", "found", "[unused4]", "[unused5]", "throughout", "the", "play", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "can", "be", "viewed", "[unused4]", "[unused5]", "as", "a", "debate", "on", "the", "opposing", "attitudes", "on", "love", "[unused6]", "[SEP]"]]}

input 72:  {"source": "Due to the transmitter location being based in Tyrone and a smaller signal wattage , it was barely hearable in the northern portions of Atlanta beyond the downtown area or even the northern reaches of Fulton or DeKalb Counties , as it was a rimshot to the southwest of the city .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 1108, 4, 5, 170, 13840, 21879, 1106, 1103, 5090, 1104, 1103, 1331, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 11991, 2450, 2, 3, 1217, 4, 5, 1359, 1107, 20314, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 3742, 2100, 1895, 1107, 1103, 2350, 8924, 1104, 5161, 2894, 1103, 5215, 1298, 1137, 1256, 1103, 2350, 5965, 1104, 18196, 1137, 3177, 2428, 1348, 1830, 12259, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06516467779874802, -0.171647310256958, -0.0273445937782526, -0.06657028198242188, -0.07031393051147461, -0.07031393051147461, -0.07031393051147461, -0.07031393051147461, -0.07031393051147461, -0.07031393051147461], "metadata": {"source_tokens": ["Due", "to", "the", "transmitter", "location", "being", "based", "in", "Tyrone", "and", "a", "smaller", "signal", "wa", "##tta", "##ge", ",", "it", "was", "barely", "hear", "##able", "in", "the", "northern", "portions", "of", "Atlanta", "beyond", "the", "downtown", "area", "or", "even", "the", "northern", "reaches", "of", "Fulton", "or", "De", "##K", "##al", "##b", "Counties", ",", "as", "it", "was", "a", "rim", "##shot", "to", "the", "southwest", "of", "the", "city", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "rim", "##shot", "to", "the", "southwest", "of", "the", "city", "[unused6]", "[SEP]", "[unused1]", "the", "transmitter", "location", "[unused2]", "[unused3]", "being", "[unused4]", "[unused5]", "based", "in", "Tyrone", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "barely", "hear", "##able", "in", "the", "northern", "portions", "of", "Atlanta", "beyond", "the", "downtown", "area", "or", "even", "the", "northern", "reaches", "of", "Fulton", "or", "De", "##K", "##al", "##b", "Counties", "[unused6]", "[SEP]"]]}

input 73:  {"source": "During the Second World War , the number of Turkish run cafes increased from 20 in 1939 to 200 in 1945 which created a demand for more Turkish Cypriot workers .\n"}
prediction:  {"predictions": [[1, 1103, 1295, 1104, 4229, 1576, 17287, 1116, 2, 3, 2569, 4, 5, 1121, 1406, 1107, 3061, 1106, 2363, 1107, 2481, 1507, 1103, 2307, 1291, 1414, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2481, 2, 3, 1687, 4, 5, 170, 4555, 1111, 1167, 4229, 20036, 3239, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02471308968961239, -0.04693733528256416, -0.18956947326660156, -0.18665838241577148, -0.18665838241577148, -0.18665838241577148, -0.18665838241577148, -0.18665838241577148, -0.18665838241577148, -0.18665838241577148], "metadata": {"source_tokens": ["During", "the", "Second", "World", "War", ",", "the", "number", "of", "Turkish", "run", "cafe", "##s", "increased", "from", "20", "in", "1939", "to", "200", "in", "1945", "which", "created", "a", "demand", "for", "more", "Turkish", "Cypriot", "workers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "number", "of", "Turkish", "run", "cafe", "##s", "[unused2]", "[unused3]", "increased", "[unused4]", "[unused5]", "from", "20", "in", "1939", "to", "200", "in", "1945", "During", "the", "Second", "World", "War", "[unused6]", "[SEP]", "[unused1]", "1945", "[unused2]", "[unused3]", "created", "[unused4]", "[unused5]", "a", "demand", "for", "more", "Turkish", "Cypriot", "workers", "[unused6]", "[SEP]"]]}

input 74:  {"source": "During the morning and evening rush hours some services run direct to/from Paddington and Reading .\n"}
prediction:  {"predictions": [[1, 1199, 1826, 2, 3, 1576, 4, 5, 2904, 1106, 28139, 2087, 16071, 19585, 24103, 1105, 8003, 1507, 1103, 2106, 1105, 3440, 6274, 2005, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.002362471306696534, -0.17989444732666016, -0.16088390350341797, -0.16088390350341797, -0.16088390350341797, -0.16088390350341797, -0.16088390350341797, -0.16088390350341797, -0.16088390350341797, -0.16088390350341797], "metadata": {"source_tokens": ["During", "the", "morning", "and", "evening", "rush", "hours", "some", "services", "run", "direct", "to", "##/", "##f", "##rom", "Pa", "##ddington", "and", "Reading", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "some", "services", "[unused2]", "[unused3]", "run", "[unused4]", "[unused5]", "direct", "to", "##/", "##f", "##rom", "Pa", "##ddington", "and", "Reading", "During", "the", "morning", "and", "evening", "rush", "hours", "[unused6]", "[SEP]"]]}

input 75:  {"source": "During the off-season the ACT Rugby Union was renamed the ACT and Southern NSW Rugby Union , and the name of the team was changed to Brumbies Rugby .\n"}
prediction:  {"predictions": [[1, 1103, 1271, 1104, 1103, 1264, 2, 3, 1108, 2014, 4, 5, 1106, 139, 5697, 16751, 5457, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 21111, 5457, 1913, 2, 3, 1108, 3286, 4, 5, 1103, 21111, 1105, 2685, 11557, 5457, 1913, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014751046895980835, -0.021770115941762924, -0.04988670349121094, -0.048679351806640625, -0.048679351806640625, -0.048679351806640625, -0.048679351806640625, -0.048679351806640625, -0.048679351806640625, -0.048679351806640625], "metadata": {"source_tokens": ["During", "the", "off", "##-", "##sea", "##son", "the", "ACT", "Rugby", "Union", "was", "renamed", "the", "ACT", "and", "Southern", "NSW", "Rugby", "Union", ",", "and", "the", "name", "of", "the", "team", "was", "changed", "to", "B", "##rum", "##bies", "Rugby", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "name", "of", "the", "team", "[unused2]", "[unused3]", "was", "changed", "[unused4]", "[unused5]", "to", "B", "##rum", "##bies", "Rugby", "[unused6]", "[SEP]", "[unused1]", "the", "ACT", "Rugby", "Union", "[unused2]", "[unused3]", "was", "renamed", "[unused4]", "[unused5]", "the", "ACT", "and", "Southern", "NSW", "Rugby", "Union", "[unused6]", "[SEP]"]]}

input 76:  {"source": "Each of the Matoran brought their Toa stone and met each other at the Great Temple .\n"}
prediction:  {"predictions": [[1, 2994, 1104, 1103, 25702, 15186, 2, 3, 1814, 4, 5, 1147, 1706, 1161, 2576, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2994, 1104, 1103, 25702, 15186, 2, 3, 1899, 4, 5, 1296, 1168, 1120, 1103, 2038, 4407, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.022052764892578125, -0.010767671279609203, -0.01879119873046875, -0.01894521713256836, -0.01894521713256836, -0.01894521713256836, -0.01894521713256836, -0.01894521713256836, -0.01894521713256836, -0.01894521713256836], "metadata": {"source_tokens": ["Each", "of", "the", "Mat", "##oran", "brought", "their", "To", "##a", "stone", "and", "met", "each", "other", "at", "the", "Great", "Temple", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Each", "of", "the", "Mat", "##oran", "[unused2]", "[unused3]", "brought", "[unused4]", "[unused5]", "their", "To", "##a", "stone", "[unused6]", "[SEP]", "[unused1]", "Each", "of", "the", "Mat", "##oran", "[unused2]", "[unused3]", "met", "[unused4]", "[unused5]", "each", "other", "at", "the", "Great", "Temple", "[unused6]", "[SEP]"]]}

input 77:  {"source": "Each time Cluemaster escapes or starts some new plan , Stephanie dons her costume again .\n"}
prediction:  {"predictions": [[1, 11952, 2, 3, 1274, 1116, 4, 5, 1123, 10220, 1254, 2994, 1159, 140, 19224, 6532, 13481, 1137, 3816, 1199, 1207, 2197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0033396880608052015, -0.05768108367919922, -0.05369997024536133, -0.05370044708251953, -0.05369997024536133, -0.05369997024536133, -0.05370044708251953, -0.05370044708251953, -0.05370044708251953, -0.05370044708251953], "metadata": {"source_tokens": ["Each", "time", "C", "##lue", "##master", "escapes", "or", "starts", "some", "new", "plan", ",", "Stephanie", "don", "##s", "her", "costume", "again", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Stephanie", "[unused2]", "[unused3]", "don", "##s", "[unused4]", "[unused5]", "her", "costume", "again", "Each", "time", "C", "##lue", "##master", "escapes", "or", "starts", "some", "new", "plan", "[unused6]", "[SEP]"]]}

input 78:  {"source": "Erotica and pornography involving sex between women have been predominantly produced by men for a male and female audience .\n"}
prediction:  {"predictions": [[1, 142, 10595, 4578, 1105, 22912, 5336, 2673, 1206, 1535, 2, 3, 1138, 1151, 8941, 1666, 4, 5, 1118, 1441, 1111, 170, 2581, 1105, 2130, 3703, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 142, 10595, 4578, 1105, 22912, 2, 3, 5336, 4, 5, 2673, 1206, 1535, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02590547315776348, -0.04484095051884651, -0.010173320770263672, -0.009798526763916016, -0.009798526763916016, -0.009798526763916016, -0.009798526763916016, -0.009798526763916016, -0.009798526763916016, -0.009798526763916016], "metadata": {"source_tokens": ["E", "##rot", "##ica", "and", "pornography", "involving", "sex", "between", "women", "have", "been", "predominantly", "produced", "by", "men", "for", "a", "male", "and", "female", "audience", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "E", "##rot", "##ica", "and", "pornography", "involving", "sex", "between", "women", "[unused2]", "[unused3]", "have", "been", "predominantly", "produced", "[unused4]", "[unused5]", "by", "men", "for", "a", "male", "and", "female", "audience", "[unused6]", "[SEP]", "[unused1]", "E", "##rot", "##ica", "and", "pornography", "[unused2]", "[unused3]", "involving", "[unused4]", "[unused5]", "sex", "between", "women", "[unused6]", "[SEP]"]]}

input 79:  {"source": "Failure to perform the duty could lead to prosecution at law and re-enslavement .\n"}
prediction:  {"predictions": [[1, 143, 11922, 3313, 1106, 3870, 1103, 4019, 2, 3, 1180, 1730, 4, 5, 1106, 12369, 1120, 1644, 1105, 1231, 28137, 5026, 9516, 14529, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-9.32400071178563e-05, -0.32665109634399414, -0.3025808334350586, -0.3025808334350586, -0.3025808334350586, -0.3025813102722168, -0.3025813102722168, -0.3025813102722168, -0.3025813102722168, -0.3025813102722168], "metadata": {"source_tokens": ["F", "##ail", "##ure", "to", "perform", "the", "duty", "could", "lead", "to", "prosecution", "at", "law", "and", "re", "##-", "##ens", "##lav", "##ement", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "F", "##ail", "##ure", "to", "perform", "the", "duty", "[unused2]", "[unused3]", "could", "lead", "[unused4]", "[unused5]", "to", "prosecution", "at", "law", "and", "re", "##-", "##ens", "##lav", "##ement", "[unused6]", "[SEP]"]]}

input 80:  {"source": "Falun Gong 's teachings are compiled from Li 's lectures , and Li holds definitional power in that belief system .\n"}
prediction:  {"predictions": [[1, 5255, 2, 3, 3486, 4, 5, 5754, 1348, 1540, 1107, 1115, 6369, 1449, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 143, 1348, 3488, 23703, 112, 1116, 12815, 2, 3, 1132, 9064, 4, 5, 1121, 5255, 112, 1116, 9548, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.030293546617031097, -0.002600187435746193, -0.005255699157714844, -0.005269050598144531, -0.005269050598144531, -0.005269050598144531, -0.005269050598144531, -0.005269050598144531, -0.005269050598144531, -0.005269050598144531], "metadata": {"source_tokens": ["F", "##al", "##un", "Gong", "'", "##s", "teachings", "are", "compiled", "from", "Li", "'", "##s", "lectures", ",", "and", "Li", "holds", "definition", "##al", "power", "in", "that", "belief", "system", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Li", "[unused2]", "[unused3]", "holds", "[unused4]", "[unused5]", "definition", "##al", "power", "in", "that", "belief", "system", "[unused6]", "[SEP]", "[unused1]", "F", "##al", "##un", "Gong", "'", "##s", "teachings", "[unused2]", "[unused3]", "are", "compiled", "[unused4]", "[unused5]", "from", "Li", "'", "##s", "lectures", "[unused6]", "[SEP]"]]}

input 81:  {"source": "Fans reacted to the news of the suspension by canceling their XM Radio subscriptions , with some fans even going as far as smashing their XM units .\n"}
prediction:  {"predictions": [[1, 16061, 1116, 2, 3, 15510, 4, 5, 1106, 1103, 2371, 1104, 1103, 8605, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1199, 3899, 2, 3, 1129, 1256, 1280, 4, 5, 1112, 1677, 1112, 24881, 1158, 1147, 161, 2107, 2338, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16061, 1116, 2, 3, 15510, 4, 5, 1106, 1103, 2371, 1104, 1103, 8605, 1118, 19722, 1158, 1147, 161, 2107, 2664, 16759, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.022850967943668365, -0.07990498095750809, -0.0707826018333435, -0.1424117088317871, -0.15954875946044922, -0.15954875946044922, -0.15954875946044922, -0.15954875946044922, -0.15954875946044922, -0.15954875946044922], "metadata": {"source_tokens": ["Fan", "##s", "reacted", "to", "the", "news", "of", "the", "suspension", "by", "cancel", "##ing", "their", "X", "##M", "Radio", "subscription", "##s", ",", "with", "some", "fans", "even", "going", "as", "far", "as", "smash", "##ing", "their", "X", "##M", "units", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Fan", "##s", "[unused2]", "[unused3]", "reacted", "[unused4]", "[unused5]", "to", "the", "news", "of", "the", "suspension", "[unused6]", "[SEP]", "[unused1]", "some", "fans", "[unused2]", "[unused3]", "be", "even", "going", "[unused4]", "[unused5]", "as", "far", "as", "smash", "##ing", "their", "X", "##M", "units", "[unused6]", "[SEP]", "[unused1]", "Fan", "##s", "[unused2]", "[unused3]", "reacted", "[unused4]", "[unused5]", "to", "the", "news", "of", "the", "suspension", "by", "cancel", "##ing", "their", "X", "##M", "Radio", "subscription", "##s", "[unused6]", "[SEP]"]]}

input 82:  {"source": "From 1909 to 1912 , the Miami Canal was dug , bypassing the rapids at the head of the North Fork .\n"}
prediction:  {"predictions": [[1, 1103, 4916, 6327, 2, 3, 1108, 8423, 4, 5, 1622, 4818, 1106, 4080, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4916, 6327, 2, 3, 13981, 1158, 4, 5, 1103, 6099, 1116, 1120, 1103, 1246, 1104, 1103, 1456, 16384, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.038623325526714325, -0.027791710570454597, -0.2388606071472168, -0.2423686981201172, -0.2423686981201172, -0.2423686981201172, -0.2423686981201172, -0.2423686981201172, -0.2423686981201172, -0.2423686981201172], "metadata": {"source_tokens": ["From", "1909", "to", "1912", ",", "the", "Miami", "Canal", "was", "dug", ",", "bypass", "##ing", "the", "rapid", "##s", "at", "the", "head", "of", "the", "North", "Fork", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Miami", "Canal", "[unused2]", "[unused3]", "was", "dug", "[unused4]", "[unused5]", "From", "1909", "to", "1912", "[unused6]", "[SEP]", "[unused1]", "the", "Miami", "Canal", "[unused2]", "[unused3]", "bypass", "##ing", "[unused4]", "[unused5]", "the", "rapid", "##s", "at", "the", "head", "of", "the", "North", "Fork", "[unused6]", "[SEP]"]]}

input 83:  {"source": "From the start of the first semester of 2010 , the University banned smoking on any of its property , including inside and outside buildings in areas that were once designated as smoking areas .\n"}
prediction:  {"predictions": [[1, 1877, 2, 3, 1127, 3574, 4, 5, 1112, 9987, 1877, 1517, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1239, 2, 3, 7548, 4, 5, 9987, 1113, 1251, 1104, 1157, 2400, 117, 1259, 1656, 1105, 1796, 2275, 1107, 1877, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1239, 2, 3, 7548, 4, 5, 9987, 1622, 1103, 1838, 1104, 1103, 1148, 14594, 1104, 1333, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023394720628857613, -0.03522859513759613, -0.05231616646051407, -0.21658945083618164, -0.2201557159423828, -0.2201557159423828, -0.2201557159423828, -0.2201557159423828, -0.2201557159423828, -0.2201557159423828], "metadata": {"source_tokens": ["From", "the", "start", "of", "the", "first", "semester", "of", "2010", ",", "the", "University", "banned", "smoking", "on", "any", "of", "its", "property", ",", "including", "inside", "and", "outside", "buildings", "in", "areas", "that", "were", "once", "designated", "as", "smoking", "areas", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "areas", "[unused2]", "[unused3]", "were", "designated", "[unused4]", "[unused5]", "as", "smoking", "areas", "once", "[unused6]", "[SEP]", "[unused1]", "the", "University", "[unused2]", "[unused3]", "banned", "[unused4]", "[unused5]", "smoking", "on", "any", "of", "its", "property", ",", "including", "inside", "and", "outside", "buildings", "in", "areas", "[unused6]", "[SEP]", "[unused1]", "the", "University", "[unused2]", "[unused3]", "banned", "[unused4]", "[unused5]", "smoking", "From", "the", "start", "of", "the", "first", "semester", "of", "2010", "[unused6]", "[SEP]"]]}

input 84:  {"source": "Furthermore , knowledge and interest pertaining to the event , as well as the level of importance , contribute to the frequency of rehearsal .\n"}
prediction:  {"predictions": [[1, 3044, 1105, 2199, 22383, 1106, 1103, 1856, 117, 1112, 1218, 1112, 1103, 1634, 1104, 4495, 2, 3, 8681, 4, 5, 1106, 1103, 5625, 1104, 20762, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007011073175817728, -0.25440359115600586, -0.2848339080810547, -0.2848339080810547, -0.2848339080810547, -0.2848339080810547, -0.2848339080810547, -0.2848339080810547, -0.2848339080810547, -0.2848339080810547], "metadata": {"source_tokens": ["Furthermore", ",", "knowledge", "and", "interest", "pertaining", "to", "the", "event", ",", "as", "well", "as", "the", "level", "of", "importance", ",", "contribute", "to", "the", "frequency", "of", "rehearsal", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "knowledge", "and", "interest", "pertaining", "to", "the", "event", ",", "as", "well", "as", "the", "level", "of", "importance", "[unused2]", "[unused3]", "contribute", "[unused4]", "[unused5]", "to", "the", "frequency", "of", "rehearsal", "[unused6]", "[SEP]"]]}

input 85:  {"source": "Gameplay is very basic ; the player must shoot constantly at a continual stream of enemies in order to reach the end of each level .\n"}
prediction:  {"predictions": [[1, 3497, 11044, 2, 3, 1110, 4, 5, 1304, 3501, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1591, 2, 3, 1538, 5211, 7480, 4, 5, 1120, 170, 14255, 6105, 4746, 5118, 1104, 6380, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1591, 2, 3, 1538, 5211, 4, 5, 7480, 1120, 170, 14255, 6105, 4746, 5118, 1104, 6380, 1107, 1546, 1106, 2519, 1103, 1322, 1104, 1296, 1634, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.011021832935512066, -0.03170424699783325, -0.049118779599666595, -0.17347431182861328, -0.17091035842895508, -0.17091035842895508, -0.17091035842895508, -0.17091035842895508, -0.17091035842895508, -0.17091035842895508], "metadata": {"source_tokens": ["Game", "##play", "is", "very", "basic", ";", "the", "player", "must", "shoot", "constantly", "at", "a", "con", "##tin", "##ual", "stream", "of", "enemies", "in", "order", "to", "reach", "the", "end", "of", "each", "level", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Game", "##play", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "very", "basic", "[unused6]", "[SEP]", "[unused1]", "the", "player", "[unused2]", "[unused3]", "must", "shoot", "constantly", "[unused4]", "[unused5]", "at", "a", "con", "##tin", "##ual", "stream", "of", "enemies", "[unused6]", "[SEP]", "[unused1]", "the", "player", "[unused2]", "[unused3]", "must", "shoot", "[unused4]", "[unused5]", "constantly", "at", "a", "con", "##tin", "##ual", "stream", "of", "enemies", "in", "order", "to", "reach", "the", "end", "of", "each", "level", "[unused6]", "[SEP]"]]}

input 86:  {"source": "Gavin Hood is a South African filmmaker , screenwriter , producer and actor , best known for writing and directing the Academy Award-winning Foreign Language Film `` Tsotsi '' .\n"}
prediction:  {"predictions": [[1, 9152, 10776, 2, 3, 1110, 4, 5, 170, 1375, 2170, 13140, 117, 11625, 117, 2451, 1105, 2811, 117, 1436, 1227, 1111, 2269, 1105, 10404, 1103, 2127, 1698, 28137, 7445, 3381, 4201, 6828, 2352, 169, 28152, 157, 7301, 2145, 1182, 112, 28131, 6, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.015968864783644676, -0.064544677734375, -0.06444215774536133, -0.06444215774536133, -0.06444215774536133, -0.06444215774536133, -0.06444215774536133, -0.06444215774536133, -0.06444215774536133, -0.06444215774536133], "metadata": {"source_tokens": ["Gavin", "Hood", "is", "a", "South", "African", "filmmaker", ",", "screenwriter", ",", "producer", "and", "actor", ",", "best", "known", "for", "writing", "and", "directing", "the", "Academy", "Award", "##-", "##win", "##ning", "Foreign", "Language", "Film", "`", "##`", "T", "##so", "##ts", "##i", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Gavin", "Hood", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "South", "African", "filmmaker", ",", "screenwriter", ",", "producer", "and", "actor", ",", "best", "known", "for", "writing", "and", "directing", "the", "Academy", "Award", "##-", "##win", "##ning", "Foreign", "Language", "Film", "`", "##`", "T", "##so", "##ts", "##i", "'", "##'", "[unused6]", "[SEP]"]]}

input 87:  {"source": "George Bluth Sr. , patriarch of the Bluth family , is the founder and former CEO of the Bluth Company which markets and builds mini-mansions among many other activities .\n"}
prediction:  {"predictions": [[1, 1667, 15223, 1582, 8731, 2, 3, 1110, 4, 5, 1103, 3249, 1105, 1393, 5058, 1104, 1103, 15223, 1582, 1881, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 15223, 1582, 1881, 2, 3, 1129, 1129, 1129, 4, 5, 27797, 1104, 28148, 1103, 15223, 1582, 1266, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 15223, 1582, 1881, 2, 3, 1129, 5809, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 15223, 1582, 1881, 2, 3, 1129, 5809, 17850, 4, 5, 8715, 28137, 14761, 5266, 1621, 1242, 1168, 2619, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01814522035419941, -0.2185669243335724, -0.14478163421154022, -0.12524069845676422, -0.044487953186035156, -0.044373512268066406, -0.04437398910522461, -0.04437398910522461, -0.04437398910522461, -0.04437398910522461], "metadata": {"source_tokens": ["George", "Blu", "##th", "Sr", "##.", ",", "patriarch", "of", "the", "Blu", "##th", "family", ",", "is", "the", "founder", "and", "former", "CEO", "of", "the", "Blu", "##th", "Company", "which", "markets", "and", "builds", "mini", "##-", "##mans", "##ions", "among", "many", "other", "activities", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "George", "Blu", "##th", "Sr", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "founder", "and", "former", "CEO", "of", "the", "Blu", "##th", "Company", "[unused6]", "[SEP]", "[unused1]", "the", "Blu", "##th", "Company", "[unused2]", "[unused3]", "be", "be", "be", "[unused4]", "[unused5]", "patriarch", "of", "##\\", "the", "Blu", "##th", "family", "[unused6]", "[SEP]", "[unused1]", "the", "Blu", "##th", "Company", "[unused2]", "[unused3]", "be", "markets", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "the", "Blu", "##th", "Company", "[unused2]", "[unused3]", "be", "markets", "builds", "[unused4]", "[unused5]", "mini", "##-", "##mans", "##ions", "among", "many", "other", "activities", "[unused6]", "[SEP]"]]}

input 88:  {"source": "Godzilla and Battra battled on the ocean floor , until they caused a rift to open between tectonic plates .\n"}
prediction:  {"predictions": [[1, 1875, 20366, 1105, 21928, 4487, 2, 3, 21600, 4, 5, 1113, 1103, 5969, 1837, 1235, 1152, 2416, 170, 25414, 1106, 1501, 1206, 21359, 26176, 1596, 7463, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 2416, 4, 5, 170, 25414, 1106, 1501, 1206, 21359, 26176, 1596, 7463, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.003055309411138296, -0.0021616092417389154, -0.0838770866394043, -0.07967329025268555, -0.07967329025268555, -0.07967329025268555, -0.07967329025268555, -0.07967329025268555, -0.07967329025268555, -0.07967329025268555], "metadata": {"source_tokens": ["God", "##zilla", "and", "Bat", "##tra", "battled", "on", "the", "ocean", "floor", ",", "until", "they", "caused", "a", "rift", "to", "open", "between", "te", "##cton", "##ic", "plates", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "God", "##zilla", "and", "Bat", "##tra", "[unused2]", "[unused3]", "battled", "[unused4]", "[unused5]", "on", "the", "ocean", "floor", "until", "they", "caused", "a", "rift", "to", "open", "between", "te", "##cton", "##ic", "plates", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "caused", "[unused4]", "[unused5]", "a", "rift", "to", "open", "between", "te", "##cton", "##ic", "plates", "[unused6]", "[SEP]"]]}

input 89:  {"source": "Good 1H NMR spectra can be acquired with 16 repeats , which takes only minutes .\n"}
prediction:  {"predictions": [[1, 1479, 19811, 2, 3, 2274, 4, 5, 1178, 1904, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2750, 122, 3048, 151, 21148, 188, 26426, 1611, 2, 3, 1169, 1129, 2888, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0010935465106740594, -0.023470977321267128, -0.10403156280517578, -0.10633039474487305, -0.10633039474487305, -0.10633039474487305, -0.10633039474487305, -0.10633039474487305, -0.10633039474487305, -0.10633039474487305], "metadata": {"source_tokens": ["Good", "1", "##H", "N", "##MR", "s", "##pect", "##ra", "can", "be", "acquired", "with", "16", "repeats", ",", "which", "takes", "only", "minutes", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "16", "repeats", "[unused2]", "[unused3]", "takes", "[unused4]", "[unused5]", "only", "minutes", "[unused6]", "[SEP]", "[unused1]", "Good", "1", "##H", "N", "##MR", "s", "##pect", "##ra", "[unused2]", "[unused3]", "can", "be", "acquired", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 90:  {"source": "HTB 's aim is for an Alpha course to be accessible to anyone who would like to attend the course , and in this way HTB seeks to spread the teachings of Christianity .\n"}
prediction:  {"predictions": [[1, 145, 1942, 2064, 112, 1116, 6457, 2, 3, 1110, 4, 5, 1111, 1126, 8461, 1736, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 145, 1942, 2064, 2, 3, 11053, 4, 5, 1106, 2819, 1103, 12815, 1104, 7522, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 145, 1942, 2064, 112, 1116, 6457, 2, 3, 1110, 4, 5, 1111, 1126, 8461, 1736, 1106, 1129, 7385, 1106, 2256, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2256, 2, 3, 1156, 1176, 1106, 4739, 4, 5, 1103, 1736, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01990252174437046, -0.10223883390426636, -0.1266505867242813, -0.1187480166554451, -0.05010032653808594, -0.04891490936279297, -0.04891490936279297, -0.04891490936279297, -0.04891490936279297, -0.04891490936279297], "metadata": {"source_tokens": ["H", "##T", "##B", "'", "##s", "aim", "is", "for", "an", "Alpha", "course", "to", "be", "accessible", "to", "anyone", "who", "would", "like", "to", "attend", "the", "course", ",", "and", "in", "this", "way", "H", "##T", "##B", "seeks", "to", "spread", "the", "teachings", "of", "Christianity", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "H", "##T", "##B", "'", "##s", "aim", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "for", "an", "Alpha", "course", "[unused6]", "[SEP]", "[unused1]", "H", "##T", "##B", "[unused2]", "[unused3]", "seeks", "[unused4]", "[unused5]", "to", "spread", "the", "teachings", "of", "Christianity", "[unused6]", "[SEP]", "[unused1]", "H", "##T", "##B", "'", "##s", "aim", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "for", "an", "Alpha", "course", "to", "be", "accessible", "to", "anyone", "[unused6]", "[SEP]", "[unused1]", "anyone", "[unused2]", "[unused3]", "would", "like", "to", "attend", "[unused4]", "[unused5]", "the", "course", "[unused6]", "[SEP]"]]}

input 91:  {"source": "Hapoel Lod played in the top division during the 1960s and 1980s , and won the State Cup in 1984 .\n"}
prediction:  {"predictions": [[1, 27227, 10605, 1181, 2, 3, 1307, 4, 5, 1107, 1103, 1499, 2417, 1219, 1103, 3266, 1105, 3011, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 27227, 10605, 1181, 2, 3, 1281, 4, 5, 1103, 1426, 1635, 1107, 2219, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008240205235779285, -0.014397015795111656, -0.01667499542236328, -0.016858577728271484, -0.016858577728271484, -0.016858577728271484, -0.016858577728271484, -0.016858577728271484, -0.016858577728271484, -0.016858577728271484], "metadata": {"source_tokens": ["Hapoel", "Lo", "##d", "played", "in", "the", "top", "division", "during", "the", "1960s", "and", "1980s", ",", "and", "won", "the", "State", "Cup", "in", "1984", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hapoel", "Lo", "##d", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "in", "the", "top", "division", "during", "the", "1960s", "and", "1980s", "[unused6]", "[SEP]", "[unused1]", "Hapoel", "Lo", "##d", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "the", "State", "Cup", "in", "1984", "[unused6]", "[SEP]"]]}

input 92:  {"source": "Having been directed to found a monastery of his order in the United States in 1873 , Fr .\n"}
prediction:  {"predictions": [[1, 13359, 119, 2, 3, 5823, 1151, 2002, 4, 5, 1106, 1276, 170, 7197, 1104, 1117, 1546, 1107, 1103, 1244, 1311, 1107, 7110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.045999787747859955, -0.0528411865234375, -0.04239225387573242, -0.04239225387573242, -0.04239225387573242, -0.04239225387573242, -0.04239225387573242, -0.04239225387573242, -0.04239225387573242, -0.04239225387573242], "metadata": {"source_tokens": ["Having", "been", "directed", "to", "found", "a", "monastery", "of", "his", "order", "in", "the", "United", "States", "in", "1873", ",", "Fr", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Fr", ".", "[unused2]", "[unused3]", "Having", "been", "directed", "[unused4]", "[unused5]", "to", "found", "a", "monastery", "of", "his", "order", "in", "the", "United", "States", "in", "1873", "[unused6]", "[SEP]"]]}

input 93:  {"source": "Hawker Pacific Aerospace is a MRO-Service company which offers landing gear and hydraulic MRO services for all major aircraft types .\n"}
prediction:  {"predictions": [[1, 28064, 1197, 2662, 19417, 2, 3, 1110, 4, 5, 170, 25827, 2346, 28137, 1708, 1200, 14301, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 25827, 2346, 28137, 1708, 1200, 14301, 1419, 2, 3, 3272, 4, 5, 4636, 6990, 1105, 16872, 25827, 2346, 1826, 1111, 1155, 1558, 2163, 3322, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014224588871002197, -0.03151695430278778, -0.026694774627685547, -0.028075218200683594, -0.028075218200683594, -0.028075218200683594, -0.028075218200683594, -0.028075218200683594, -0.028075218200683594, -0.028075218200683594], "metadata": {"source_tokens": ["Hawke", "##r", "Pacific", "Aerospace", "is", "a", "MR", "##O", "##-", "##S", "##er", "##vice", "company", "which", "offers", "landing", "gear", "and", "hydraulic", "MR", "##O", "services", "for", "all", "major", "aircraft", "types", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hawke", "##r", "Pacific", "Aerospace", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "MR", "##O", "##-", "##S", "##er", "##vice", "company", "[unused6]", "[SEP]", "[unused1]", "a", "MR", "##O", "##-", "##S", "##er", "##vice", "company", "[unused2]", "[unused3]", "offers", "[unused4]", "[unused5]", "landing", "gear", "and", "hydraulic", "MR", "##O", "services", "for", "all", "major", "aircraft", "types", "[unused6]", "[SEP]"]]}

input 94:  {"source": "He also possesses enhanced senses and can track people for great distances over open terrain and his feet are sensitive enough to detect electronic signals through solid walls and floors .\n"}
prediction:  {"predictions": [[1, 1117, 1623, 2, 3, 1132, 4, 5, 7246, 1536, 1106, 11552, 4828, 7981, 1194, 4600, 2928, 1105, 7849, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 15614, 4, 5, 9927, 9439, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1169, 1854, 4, 5, 1234, 1111, 1632, 12424, 1166, 1501, 9260, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03214690834283829, -0.09867744892835617, -0.05608034506440163, -0.0328521728515625, -0.0333247184753418, -0.0333251953125, -0.0333247184753418, -0.0333247184753418, -0.0333247184753418, -0.0333247184753418], "metadata": {"source_tokens": ["He", "also", "possesses", "enhanced", "senses", "and", "can", "track", "people", "for", "great", "distances", "over", "open", "terrain", "and", "his", "feet", "are", "sensitive", "enough", "to", "detect", "electronic", "signals", "through", "solid", "walls", "and", "floors", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "his", "feet", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "sensitive", "enough", "to", "detect", "electronic", "signals", "through", "solid", "walls", "and", "floors", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "possesses", "[unused4]", "[unused5]", "enhanced", "senses", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "can", "track", "[unused4]", "[unused5]", "people", "for", "great", "distances", "over", "open", "terrain", "[unused6]", "[SEP]"]]}

input 95:  {"source": "He also took 124 wickets , with 7 for 39 and 6 for 44 against Sargodha in 1962-63 his best bowling figures .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1261, 4, 5, 13743, 10267, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 13743, 10267, 1114, 128, 1111, 3614, 1105, 127, 1111, 3140, 1222, 17784, 17161, 14016, 1107, 2832, 28137, 1545, 1495, 1117, 1436, 11518, 3736, 2, 3, 1261, 4, 5, 13743, 10267, 1114, 128, 1111, 3614, 1105, 127, 1111, 3140, 1222, 17784, 17161, 14016, 1107, 2832, 28137, 1545, 1495, 1117, 1436, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009218389168381691, -0.05565710738301277, -0.14458227157592773, -0.10160255432128906, -0.10160255432128906, -0.10160255432128906, -0.10160255432128906, -0.10160255432128906, -0.10160255432128906, -0.10160255432128906], "metadata": {"source_tokens": ["He", "also", "took", "124", "wickets", ",", "with", "7", "for", "39", "and", "6", "for", "44", "against", "Sa", "##rgo", "##dha", "in", "1962", "##-", "##6", "##3", "his", "best", "bowling", "figures", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "124", "wickets", "[unused6]", "[SEP]", "[unused1]", "124", "wickets", "with", "7", "for", "39", "and", "6", "for", "44", "against", "Sa", "##rgo", "##dha", "in", "1962", "##-", "##6", "##3", "his", "best", "bowling", "figures", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "124", "wickets", "with", "7", "for", "39", "and", "6", "for", "44", "against", "Sa", "##rgo", "##dha", "in", "1962", "##-", "##6", "##3", "his", "best", "[SEP]"]]}

input 96:  {"source": "He appeared in that game alongside his Arsenal midfield colleague Brian Marwood , who had joined them from Sheffield Wednesday eight months earlier .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1691, 4, 5, 1107, 1115, 1342, 3338, 1117, 10503, 26599, 11864, 3579, 9751, 2615, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 10503, 26599, 11864, 2, 3, 1125, 1688, 4, 5, 1172, 1121, 8139, 9031, 2022, 1808, 2206, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027336085215210915, -0.035152241587638855, -0.04412412643432617, -0.04288625717163086, -0.04288625717163086, -0.04288625717163086, -0.04288625717163086, -0.04288625717163086, -0.04288625717163086, -0.04288625717163086], "metadata": {"source_tokens": ["He", "appeared", "in", "that", "game", "alongside", "his", "Arsenal", "midfield", "colleague", "Brian", "Mar", "##wood", ",", "who", "had", "joined", "them", "from", "Sheffield", "Wednesday", "eight", "months", "earlier", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "in", "that", "game", "alongside", "his", "Arsenal", "midfield", "colleague", "Brian", "Mar", "##wood", "[unused6]", "[SEP]", "[unused1]", "his", "Arsenal", "midfield", "colleague", "[unused2]", "[unused3]", "had", "joined", "[unused4]", "[unused5]", "them", "from", "Sheffield", "Wednesday", "eight", "months", "earlier", "[unused6]", "[SEP]"]]}

input 97:  {"source": "He defines Wild Cards as ` Low Probability , High Impact events that , were they to occur , would severely impact the human condition ' .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 12028, 4, 5, 5469, 10103, 1116, 1112, 169, 8274, 5096, 2822, 5474, 117, 1693, 13788, 1958, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1693, 13788, 1958, 2, 3, 1129, 1127, 4, 5, 1152, 1106, 4467, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1693, 13788, 1958, 2, 3, 1156, 8669, 3772, 4, 5, 1103, 1769, 3879, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.032338812947273254, -0.1145399734377861, -0.1132592111825943, -0.19646072387695312, -0.1791234016418457, -0.1791234016418457, -0.1791234016418457, -0.1791234016418457, -0.1791234016418457, -0.1791234016418457], "metadata": {"source_tokens": ["He", "defines", "Wild", "Card", "##s", "as", "`", "Low", "Pro", "##ba", "##bility", ",", "High", "Impact", "events", "that", ",", "were", "they", "to", "occur", ",", "would", "severely", "impact", "the", "human", "condition", "'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "defines", "[unused4]", "[unused5]", "Wild", "Card", "##s", "as", "`", "Low", "Pro", "##ba", "##bility", ",", "High", "Impact", "events", "[unused6]", "[SEP]", "[unused1]", "High", "Impact", "events", "[unused2]", "[unused3]", "be", "were", "[unused4]", "[unused5]", "they", "to", "occur", "[unused6]", "[SEP]", "[unused1]", "High", "Impact", "events", "[unused2]", "[unused3]", "would", "severely", "impact", "[unused4]", "[unused5]", "the", "human", "condition", "[unused6]", "[SEP]"]]}

input 98:  {"source": "He finds himself in a desert as a group of Neo Arcadians surround him , ending the game .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 4090, 4, 5, 1471, 1107, 170, 6941, 1112, 170, 1372, 1104, 14521, 18647, 21403, 2316, 16858, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1372, 1104, 14521, 18647, 21403, 2316, 2, 3, 16858, 4, 5, 1140, 3830, 1103, 1342, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017460880801081657, -0.10231395065784454, -0.07941198348999023, -0.06874799728393555, -0.06874799728393555, -0.06874799728393555, -0.06874799728393555, -0.06874799728393555, -0.06874799728393555, -0.06874799728393555], "metadata": {"source_tokens": ["He", "finds", "himself", "in", "a", "desert", "as", "a", "group", "of", "Neo", "Arc", "##adia", "##ns", "surround", "him", ",", "ending", "the", "game", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "finds", "[unused4]", "[unused5]", "himself", "in", "a", "desert", "as", "a", "group", "of", "Neo", "Arc", "##adia", "##ns", "surround", "him", "[unused6]", "[SEP]", "[unused1]", "a", "group", "of", "Neo", "Arc", "##adia", "##ns", "[unused2]", "[unused3]", "surround", "[unused4]", "[unused5]", "him", "ending", "the", "game", "[unused6]", "[SEP]"]]}

input 99:  {"source": "He had spent 11 years in jail despite having been acquitted twice .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1125, 2097, 4, 5, 1429, 1201, 1107, 7237, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014289830811321735, -0.09688472747802734, -0.09018945693969727, -0.09018945693969727, -0.09018945693969727, -0.09018945693969727, -0.09018945693969727, -0.09018945693969727, -0.09018945693969727, -0.09018945693969727], "metadata": {"source_tokens": ["He", "had", "spent", "11", "years", "in", "jail", "despite", "having", "been", "acquitted", "twice", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "had", "spent", "[unused4]", "[unused5]", "11", "years", "in", "jail", "[unused6]", "[SEP]"]]}

input 100:  {"source": "He is idolized , receiving the name of `` God '' .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1110, 17642, 2200, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 4172, 4, 5, 1103, 1271, 1104, 169, 28152, 1875, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07617472857236862, -0.049842819571495056, -0.0447840690612793, -0.042398929595947266, -0.042398929595947266, -0.042398929595947266, -0.042398929595947266, -0.042398929595947266, -0.042398929595947266, -0.042398929595947266], "metadata": {"source_tokens": ["He", "is", "idol", "##ized", ",", "receiving", "the", "name", "of", "`", "##`", "God", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "is", "idol", "##ized", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "receiving", "[unused4]", "[unused5]", "the", "name", "of", "`", "##`", "God", "[unused6]", "[SEP]"]]}

input 101:  {"source": "He left his old company , V2 records , wanting to expand his career into something bigger .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1286, 4, 5, 1117, 1385, 1419, 5277, 1106, 7380, 1117, 1578, 1154, 1380, 6706, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 1385, 1419, 2, 3, 1110, 4, 5, 159, 1477, 3002, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017212867736816406, -0.0122626768425107, -0.035710811614990234, -0.03720998764038086, -0.03720998764038086, -0.03720998764038086, -0.03720998764038086, -0.03720998764038086, -0.03720998764038086, -0.03720998764038086], "metadata": {"source_tokens": ["He", "left", "his", "old", "company", ",", "V", "##2", "records", ",", "wanting", "to", "expand", "his", "career", "into", "something", "bigger", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "his", "old", "company", "wanting", "to", "expand", "his", "career", "into", "something", "bigger", "[unused6]", "[SEP]", "[unused1]", "his", "old", "company", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "V", "##2", "records", "[unused6]", "[SEP]"]]}

input 102:  {"source": "He left only a small contingent to guard the defile , and took his entire army to destroy the plain that lay ahead of Alexander 's army .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1286, 4, 5, 1178, 170, 1353, 17286, 1106, 3542, 1103, 19353, 4759, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6188, 2, 3, 3191, 4, 5, 3075, 1104, 28137, 6188, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1261, 4, 5, 1117, 2072, 2306, 1106, 5535, 1103, 6188, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.033836524933576584, -0.21695682406425476, -0.07238304615020752, -0.07404184341430664, -0.07437562942504883, -0.07437562942504883, -0.07437562942504883, -0.07437562942504883, -0.07437562942504883, -0.07437562942504883], "metadata": {"source_tokens": ["He", "left", "only", "a", "small", "contingent", "to", "guard", "the", "def", "##ile", ",", "and", "took", "his", "entire", "army", "to", "destroy", "the", "plain", "that", "lay", "ahead", "of", "Alexander", "'", "##s", "army", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "only", "a", "small", "contingent", "to", "guard", "the", "def", "##ile", "[unused6]", "[SEP]", "[unused1]", "the", "plain", "[unused2]", "[unused3]", "lay", "[unused4]", "[unused5]", "ahead", "of", "##-", "plain", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "his", "entire", "army", "to", "destroy", "the", "plain", "[unused6]", "[SEP]"]]}

input 103:  {"source": "He lodged near the hospital at 28 St Thomas 's Street in Southwark , with other medical students , including Henry Stephens who became a famous inventor and ink magnate .\n"}
prediction:  {"predictions": [[1, 1985, 15752, 2, 3, 1245, 4, 5, 170, 2505, 12989, 1105, 12816, 12477, 21772, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 22422, 4, 5, 1485, 1103, 2704, 1120, 1743, 1457, 1819, 112, 1116, 1715, 1107, 1375, 27319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02968260832130909, -0.03536033630371094, -0.1875762939453125, -0.18413686752319336, -0.18413686752319336, -0.18413686752319336, -0.18413686752319336, -0.18413686752319336, -0.18413686752319336, -0.18413686752319336], "metadata": {"source_tokens": ["He", "lodged", "near", "the", "hospital", "at", "28", "St", "Thomas", "'", "##s", "Street", "in", "South", "##wark", ",", "with", "other", "medical", "students", ",", "including", "Henry", "Stephens", "who", "became", "a", "famous", "inventor", "and", "ink", "ma", "##gnate", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Henry", "Stephens", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "a", "famous", "inventor", "and", "ink", "ma", "##gnate", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "lodged", "[unused4]", "[unused5]", "near", "the", "hospital", "at", "28", "St", "Thomas", "'", "##s", "Street", "in", "South", "##wark", "[unused6]", "[SEP]"]]}

input 104:  {"source": "He played Perker in the 1985 adaptation of `` The Pickwick Papers '' .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1307, 4, 5, 14286, 4188, 1107, 1103, 2210, 6350, 1104, 169, 28152, 1109, 20984, 6196, 19023, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0003987550735473633, -0.027632713317871094, -0.022785186767578125, -0.022785186767578125, -0.022785186767578125, -0.022785186767578125, -0.022785186767578125, -0.022785186767578125, -0.022785186767578125, -0.022785186767578125], "metadata": {"source_tokens": ["He", "played", "Per", "##ker", "in", "the", "1985", "adaptation", "of", "`", "##`", "The", "Pick", "##wick", "Papers", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "Per", "##ker", "in", "the", "1985", "adaptation", "of", "`", "##`", "The", "Pick", "##wick", "Papers", "[unused6]", "[SEP]"]]}

input 105:  {"source": "He represented the riding of Nickel Belt in the Sudbury , Ontario area .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 2533, 4, 5, 1103, 5569, 1104, 3350, 1883, 15834, 1107, 1103, 15463, 26837, 117, 3717, 1298, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.003685068106278777, -0.01824808120727539, -0.017173290252685547, -0.017173290252685547, -0.017173290252685547, -0.017173290252685547, -0.017173290252685547, -0.017173290252685547, -0.017173290252685547, -0.017173290252685547], "metadata": {"source_tokens": ["He", "represented", "the", "riding", "of", "Nick", "##el", "Belt", "in", "the", "Su", "##dbury", ",", "Ontario", "area", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "represented", "[unused4]", "[unused5]", "the", "riding", "of", "Nick", "##el", "Belt", "in", "the", "Su", "##dbury", ",", "Ontario", "area", "[unused6]", "[SEP]"]]}

input 106:  {"source": "He talked to McGee about using his name and received permission , which is confirmed by correspondence between McGee and his family .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 5029, 4, 5, 1106, 24539, 1164, 1606, 1117, 1271, 1105, 1460, 6156, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1134, 2, 3, 1110, 3659, 4, 5, 1118, 12052, 1206, 24539, 1105, 1117, 1266, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.010212474502623081, -0.059226568788290024, -0.0622563362121582, -0.05961465835571289, -0.05961465835571289, -0.05961418151855469, -0.05961418151855469, -0.05961418151855469, -0.05961418151855469, -0.05961418151855469], "metadata": {"source_tokens": ["He", "talked", "to", "McGee", "about", "using", "his", "name", "and", "received", "permission", ",", "which", "is", "confirmed", "by", "correspondence", "between", "McGee", "and", "his", "family", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "talked", "[unused4]", "[unused5]", "to", "McGee", "about", "using", "his", "name", "and", "received", "permission", "[unused6]", "[SEP]", "[unused1]", "which", "[unused2]", "[unused3]", "is", "confirmed", "[unused4]", "[unused5]", "by", "correspondence", "between", "McGee", "and", "his", "family", "[unused6]", "[SEP]"]]}

input 107:  {"source": "He was a member of the European Convention , which drafted the text of the European Constitution that never entered into force .\n"}
prediction:  {"predictions": [[1, 1103, 1735, 5818, 2, 3, 7071, 4, 5, 1103, 3087, 1104, 1103, 1735, 5317, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1735, 5317, 2, 3, 1129, 1309, 2242, 4, 5, 1154, 2049, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023150697350502014, -0.08880586922168732, -0.24526262283325195, -0.25245189666748047, -0.25245189666748047, -0.25245189666748047, -0.25245189666748047, -0.25245189666748047, -0.25245189666748047, -0.25245189666748047], "metadata": {"source_tokens": ["He", "was", "a", "member", "of", "the", "European", "Convention", ",", "which", "drafted", "the", "text", "of", "the", "European", "Constitution", "that", "never", "entered", "into", "force", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "European", "Convention", "[unused2]", "[unused3]", "drafted", "[unused4]", "[unused5]", "the", "text", "of", "the", "European", "Constitution", "[unused6]", "[SEP]", "[unused1]", "the", "European", "Constitution", "[unused2]", "[unused3]", "be", "never", "entered", "[unused4]", "[unused5]", "into", "force", "[unused6]", "[SEP]"]]}

input 108:  {"source": "He was buried in the Abbey of the Psalms mausoleum at the Hollywood Forever Cemetery .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1108, 3126, 4, 5, 1107, 1103, 6674, 1104, 1103, 153, 11794, 4206, 27685, 1120, 1103, 4613, 11694, 5501, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-2.6941299438476562e-05, -0.053682804107666016, -0.11696147918701172, -0.11696147918701172, -0.11696147918701172, -0.11696147918701172, -0.11696147918701172, -0.11696147918701172, -0.11696147918701172, -0.11696147918701172], "metadata": {"source_tokens": ["He", "was", "buried", "in", "the", "Abbey", "of", "the", "P", "##sal", "##ms", "mausoleum", "at", "the", "Hollywood", "Forever", "Cemetery", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "was", "buried", "[unused4]", "[unused5]", "in", "the", "Abbey", "of", "the", "P", "##sal", "##ms", "mausoleum", "at", "the", "Hollywood", "Forever", "Cemetery", "[unused6]", "[SEP]"]]}

input 109:  {"source": "He was subsequently reprieved for a month , and then again for a week .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1108, 1231, 1643, 27055, 1181, 4, 5, 1111, 170, 2370, 1105, 1173, 1254, 1111, 170, 1989, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.09418635070323944, -0.14815759658813477, -0.14737510681152344, -0.14737510681152344, -0.14737510681152344, -0.14737510681152344, -0.14737462997436523, -0.14737462997436523, -0.14737462997436523, -0.14737462997436523], "metadata": {"source_tokens": ["He", "was", "subsequently", "re", "##p", "##rieve", "##d", "for", "a", "month", ",", "and", "then", "again", "for", "a", "week", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "was", "re", "##p", "##rieve", "##d", "[unused4]", "[unused5]", "for", "a", "month", "and", "then", "again", "for", "a", "week", "[unused6]", "[SEP]"]]}

input 110:  {"source": "Her image held aloft signifies the Earth , which `` hangs in the air '' .\n"}
prediction:  {"predictions": [[1, 1430, 3077, 1316, 2393, 18874, 2, 3, 2951, 9387, 4, 5, 1103, 2746, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2746, 2, 3, 19565, 4, 5, 1107, 1103, 1586, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.018125019967556, -0.04686129838228226, -0.01319122314453125, -0.013728141784667969, -0.013728141784667969, -0.013728141784667969, -0.013728141784667969, -0.013728141784667969, -0.013728141784667969, -0.013728141784667969], "metadata": {"source_tokens": ["Her", "image", "held", "al", "##oft", "sign", "##ifies", "the", "Earth", ",", "which", "`", "##`", "hangs", "in", "the", "air", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Her", "image", "held", "al", "##oft", "[unused2]", "[unused3]", "sign", "##ifies", "[unused4]", "[unused5]", "the", "Earth", "[unused6]", "[SEP]", "[unused1]", "the", "Earth", "[unused2]", "[unused3]", "hangs", "[unused4]", "[unused5]", "in", "the", "air", "[unused6]", "[SEP]"]]}

input 111:  {"source": "Hilf al-Fudul was a 7th-century alliance created by various Meccans , including the Islamic prophet Muhammad , to establish fair commercial dealing .\n"}
prediction:  {"predictions": [[1, 8790, 9654, 2393, 28137, 2271, 4867, 4654, 2, 3, 1108, 4, 5, 170, 4766, 28137, 8298, 11366, 7214, 1687, 1118, 1672, 25160, 2316, 117, 1259, 1103, 4769, 20718, 6710, 117, 1106, 4586, 4652, 2595, 6705, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008918511681258678, -0.12592840194702148, -0.1156315803527832, -0.1156315803527832, -0.1156315803527832, -0.1156320571899414, -0.1156315803527832, -0.1156315803527832, -0.1156315803527832, -0.1156315803527832], "metadata": {"source_tokens": ["Hi", "##lf", "al", "##-", "##F", "##ud", "##ul", "was", "a", "7th", "##-", "##cent", "##ury", "alliance", "created", "by", "various", "Mecca", "##ns", ",", "including", "the", "Islamic", "prophet", "Muhammad", ",", "to", "establish", "fair", "commercial", "dealing", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hi", "##lf", "al", "##-", "##F", "##ud", "##ul", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "7th", "##-", "##cent", "##ury", "alliance", "created", "by", "various", "Mecca", "##ns", ",", "including", "the", "Islamic", "prophet", "Muhammad", ",", "to", "establish", "fair", "commercial", "dealing", "[unused6]", "[SEP]"]]}

input 112:  {"source": "Historically , Aiseau was a village dedicated to agriculture , logging , but also to the industry .\n"}
prediction:  {"predictions": [[1, 19294, 24405, 2, 3, 1108, 4, 5, 170, 1491, 3256, 1106, 6487, 117, 17844, 117, 1133, 1145, 1106, 1103, 2380, 14630, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1491, 2, 3, 3256, 4, 5, 1106, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 102, 1, 19294, 2, 3, 1108, 4, 5, 170, 1491, 17844, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 19294, 2, 3, 1108, 4, 5, 170, 1491, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1491, 17844, 2, 3, 1108, 4, 5, 170, 1491, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1491, 3256, 1106, 1103, 2380, 2, 3, 3256, 4, 5, 1106, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 102, 1, 170, 1491, 2, 3, 3256, 4, 5, 1106, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 102, 1, 170, 1491, 2, 3, 3256, 4, 5, 1106, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0006764382123947144, -0.2987133264541626, -0.28823167085647583, -0.15927869081497192, -0.39955952763557434, -0.392380028963089, -0.41357874870300293, -0.2762245535850525, -0.29793834686279297, -0.33011484146118164], "metadata": {"source_tokens": ["Historically", ",", "Ai", "##seau", "was", "a", "village", "dedicated", "to", "agriculture", ",", "logging", ",", "but", "also", "to", "the", "industry", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ai", "##seau", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "village", "dedicated", "to", "agriculture", ",", "logging", ",", "but", "also", "to", "the", "industry", "Historically", "[unused6]", "[SEP]", "[unused1]", "a", "village", "[unused2]", "[unused3]", "dedicated", "[unused4]", "[unused5]", "to", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "[SEP]", "[unused1]", "Ai", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "village", "logging", "[unused6]", "[SEP]", "[unused1]", "Ai", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "village", "[unused6]", "[SEP]", "[unused1]", "a", "village", "logging", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "village", "[unused6]", "[SEP]", "[unused1]", "a", "village", "dedicated", "to", "the", "industry", "[unused2]", "[unused3]", "dedicated", "[unused4]", "[unused5]", "to", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "[SEP]", "[unused1]", "a", "village", "[unused2]", "[unused3]", "dedicated", "[unused4]", "[unused5]", "to", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "[SEP]", "[unused1]", "a", "village", "[unused2]", "[unused3]", "dedicated", "[unused4]", "[unused5]", "to", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "the", "[SEP]"]]}

input 113:  {"source": "Hoechst 33342 and 33258 are quenched by Bromodeoxyuridine , which is commonly used to detect dividing cells .\n"}
prediction:  {"predictions": [[1, 139, 16071, 13040, 10649, 9379, 10132, 2042, 2, 3, 1110, 3337, 1215, 4, 5, 1106, 11552, 18699, 3652, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9800, 11252, 2050, 23335, 23117, 1105, 3081, 17600, 1604, 2, 3, 1132, 15027, 15986, 4, 5, 1118, 139, 16071, 13040, 10649, 9379, 10132, 2042, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.022816509008407593, -0.00994037464261055, -0.010085582733154297, -0.010984420776367188, -0.010984420776367188, -0.010984420776367188, -0.010984420776367188, -0.010984420776367188, -0.010984420776367188, -0.010984420776367188], "metadata": {"source_tokens": ["Ho", "##ech", "##st", "333", "##42", "and", "33", "##25", "##8", "are", "que", "##nched", "by", "B", "##rom", "##ode", "##ox", "##yu", "##rid", "##ine", ",", "which", "is", "commonly", "used", "to", "detect", "dividing", "cells", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "B", "##rom", "##ode", "##ox", "##yu", "##rid", "##ine", "[unused2]", "[unused3]", "is", "commonly", "used", "[unused4]", "[unused5]", "to", "detect", "dividing", "cells", "[unused6]", "[SEP]", "[unused1]", "Ho", "##ech", "##st", "333", "##42", "and", "33", "##25", "##8", "[unused2]", "[unused3]", "are", "que", "##nched", "[unused4]", "[unused5]", "by", "B", "##rom", "##ode", "##ox", "##yu", "##rid", "##ine", "[unused6]", "[SEP]"]]}

input 114:  {"source": "Hofmann was a below-average high school student , but he had many hobbies including magic , electronics , chemistry , and stamp and coin collecting .\n"}
prediction:  {"predictions": [[1, 9800, 2087, 4119, 2, 3, 1108, 4, 5, 170, 2071, 28137, 18195, 2553, 1344, 1278, 2377, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1125, 4, 5, 1242, 16358, 13834, 1905, 1259, 3974, 117, 11216, 117, 8117, 117, 1105, 13182, 1105, 9584, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 13182, 1105, 9584, 2, 3, 1129, 9370, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01233462244272232, -0.01962689496576786, -0.05317048355937004, -0.021491050720214844, -0.023632526397705078, -0.023632526397705078, -0.023632526397705078, -0.023632526397705078, -0.023632526397705078, -0.023632526397705078], "metadata": {"source_tokens": ["Ho", "##f", "##mann", "was", "a", "below", "##-", "##aver", "##age", "high", "school", "student", ",", "but", "he", "had", "many", "ho", "##bb", "##ies", "including", "magic", ",", "electronics", ",", "chemistry", ",", "and", "stamp", "and", "coin", "collecting", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ho", "##f", "##mann", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "below", "##-", "##aver", "##age", "high", "school", "student", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "many", "ho", "##bb", "##ies", "including", "magic", ",", "electronics", ",", "chemistry", ",", "and", "stamp", "and", "coin", "[unused6]", "[SEP]", "[unused1]", "stamp", "and", "coin", "[unused2]", "[unused3]", "be", "collecting", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 115:  {"source": "However , after pressure campaigns from various human rights groups , BAE Systems recently stated it no longer produces land mines or cluster bombs .\n"}
prediction:  {"predictions": [[1, 12465, 2036, 6475, 2, 3, 2202, 4, 5, 1122, 1185, 2039, 6570, 1657, 7785, 1137, 10005, 10095, 1170, 2997, 7827, 1121, 1672, 1769, 2266, 2114, 3055, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 6570, 4, 5, 1657, 7785, 1137, 10005, 10095, 1185, 2039, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013469235971570015, -0.05786709487438202, -0.17170047760009766, -0.17103004455566406, -0.17103004455566406, -0.17103004455566406, -0.17103004455566406, -0.17103004455566406, -0.17103004455566406, -0.17103004455566406], "metadata": {"source_tokens": ["However", ",", "after", "pressure", "campaigns", "from", "various", "human", "rights", "groups", ",", "BA", "##E", "Systems", "recently", "stated", "it", "no", "longer", "produces", "land", "mines", "or", "cluster", "bombs", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "BA", "##E", "Systems", "[unused2]", "[unused3]", "stated", "[unused4]", "[unused5]", "it", "no", "longer", "produces", "land", "mines", "or", "cluster", "bombs", "after", "pressure", "campaigns", "from", "various", "human", "rights", "groups", "recently", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "produces", "[unused4]", "[unused5]", "land", "mines", "or", "cluster", "bombs", "no", "longer", "[unused6]", "[SEP]"]]}

input 116:  {"source": "However , comic relief sidekick `` Mike McGurk '' bears some resemblance to Tracy 's partner from the strip , Pat Patton ; Tracy 's secretary , Gwen Andrews , provides the same kind of feminine interest as Tess Trueheart ; and FBI Director Clive Anderson is the same kind of avuncular superior as Chief Brandon .\n"}
prediction:  {"predictions": [[1, 8099, 2524, 15295, 4347, 2, 3, 1110, 4, 5, 1103, 1269, 1912, 1104, 170, 25247, 26405, 5552, 7298, 1112, 2534, 8464, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4824, 3893, 1334, 27982, 2, 3, 8807, 4, 5, 1199, 14634, 1106, 10435, 112, 1116, 3547, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4824, 3893, 1334, 27982, 2, 3, 8807, 4, 5, 1199, 14634, 1106, 10435, 112, 1116, 3547, 1121, 1103, 6322, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10435, 112, 1116, 4848, 2, 3, 1129, 2790, 4, 5, 1103, 1269, 1912, 1104, 13385, 2199, 1112, 16613, 7817, 19233, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6322, 2, 3, 1129, 2790, 4, 5, 1103, 1269, 1912, 1104, 13385, 2199, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6322, 2, 3, 1129, 2790, 4, 5, 1103, 1269, 1912, 1104, 13385, 2199, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6322, 2, 3, 1129, 2790, 4, 5, 1103, 1269, 1912, 1104, 13385, 2199, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6322, 2, 3, 1129, 2790, 4, 5, 1103, 1269, 1912, 1104, 13385, 2199, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4824, 3893, 1334, 27982, 2639, 150, 1665, 2349, 2149, 1377, 2, 3, 8807, 4, 5, 1199, 14634, 6, 102, 102, 1, 1103, 6322, 2, 3, 1129, 4, 5, 7195, 19451, 6, 102, 102]], "predicted_log_probs": [-0.029228895902633667, -0.05738414451479912, -0.10893786698579788, -0.09745027869939804, -0.17041265964508057, -0.19187161326408386, -0.1978985071182251, -0.2151678055524826, -0.11621473729610443, -0.34224823117256165], "metadata": {"source_tokens": ["However", ",", "comic", "relief", "side", "##kick", "`", "##`", "Mike", "M", "##c", "##G", "##ur", "##k", "'", "##'", "bears", "some", "resemblance", "to", "Tracy", "'", "##s", "partner", "from", "the", "strip", ",", "Pat", "Patton", ";", "Tracy", "'", "##s", "secretary", ",", "Gwen", "Andrews", ",", "provides", "the", "same", "kind", "of", "feminine", "interest", "as", "Tess", "True", "##heart", ";", "and", "FBI", "Director", "Clive", "Anderson", "is", "the", "same", "kind", "of", "a", "##vu", "##nc", "##ular", "superior", "as", "Chief", "Brandon", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "FBI", "Director", "Clive", "Anderson", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "same", "kind", "of", "a", "##vu", "##nc", "##ular", "superior", "as", "Chief", "Brandon", "[unused6]", "[SEP]", "[unused1]", "comic", "relief", "side", "##kick", "[unused2]", "[unused3]", "bears", "[unused4]", "[unused5]", "some", "resemblance", "to", "Tracy", "'", "##s", "partner", "[unused6]", "[SEP]", "[unused1]", "comic", "relief", "side", "##kick", "[unused2]", "[unused3]", "bears", "[unused4]", "[unused5]", "some", "resemblance", "to", "Tracy", "'", "##s", "partner", "from", "the", "strip", "[unused6]", "[SEP]", "[unused1]", "Tracy", "'", "##s", "secretary", "[unused2]", "[unused3]", "be", "provides", "[unused4]", "[unused5]", "the", "same", "kind", "of", "feminine", "interest", "as", "Tess", "True", "##heart", "[unused6]", "[SEP]", "[unused1]", "the", "strip", "[unused2]", "[unused3]", "be", "provides", "[unused4]", "[unused5]", "the", "same", "kind", "of", "feminine", "interest", "[unused6]", "[SEP]", "[unused1]", "the", "strip", "[unused2]", "[unused3]", "be", "provides", "[unused4]", "[unused5]", "the", "same", "kind", "of", "feminine", "interest", "[unused6]", "[SEP]", "[unused1]", "the", "strip", "[unused2]", "[unused3]", "be", "provides", "[unused4]", "[unused5]", "the", "same", "kind", "of", "feminine", "interest", "[unused6]", "[SEP]", "[unused1]", "the", "strip", "[unused2]", "[unused3]", "be", "provides", "[unused4]", "[unused5]", "the", "same", "kind", "of", "feminine", "interest", "[unused6]", "[SEP]", "[unused1]", "comic", "relief", "side", "##kick", "Mike", "M", "##c", "##G", "##ur", "##k", "[unused2]", "[unused3]", "bears", "[unused4]", "[unused5]", "some", "resemblance", "[unused6]", "[SEP]", "[unused1]", "the", "strip", "[unused2]", "[unused3]", "be", "[unused4]", "[unused5]", "Pat", "Patton", "[unused6]", "[SEP]"]]}

input 117:  {"source": "However , during his rehearsal , Knievel lost control of the motorcycle and crashed into a cameraman .\n"}
prediction:  {"predictions": [[1, 148, 5213, 12559, 2, 3, 1575, 4, 5, 1654, 1104, 1103, 9580, 1219, 1117, 20762, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 148, 5213, 12559, 2, 3, 7573, 4, 5, 1154, 170, 4504, 1399, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013320392929017544, -0.02461955137550831, -0.14457225799560547, -0.13095760345458984, -0.13095760345458984, -0.13095760345458984, -0.13095760345458984, -0.13095760345458984, -0.13095760345458984, -0.13095760345458984], "metadata": {"source_tokens": ["However", ",", "during", "his", "rehearsal", ",", "K", "##nie", "##vel", "lost", "control", "of", "the", "motorcycle", "and", "crashed", "into", "a", "camera", "##man", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "K", "##nie", "##vel", "[unused2]", "[unused3]", "lost", "[unused4]", "[unused5]", "control", "of", "the", "motorcycle", "during", "his", "rehearsal", "[unused6]", "[SEP]", "[unused1]", "K", "##nie", "##vel", "[unused2]", "[unused3]", "crashed", "[unused4]", "[unused5]", "into", "a", "camera", "##man", "[unused6]", "[SEP]"]]}

input 118:  {"source": "However , it became far less safe for the Nationals from 1983 onward , and strong population growth over the last three decades has seen it progressively lose its rural territory and reduced it to a more coastal-based and urbanised division .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 1245, 4, 5, 1677, 1750, 2914, 1111, 1103, 16101, 1121, 2278, 17765, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2012, 1416, 3213, 1166, 1103, 1314, 1210, 4397, 2, 3, 1144, 1562, 4, 5, 1122, 22770, 3857, 1157, 3738, 3441, 1105, 3549, 1122, 1106, 170, 1167, 5869, 28137, 14017, 1181, 1105, 3953, 3673, 2417, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.025283051654696465, -0.024726200848817825, -0.26807308197021484, -0.26178836822509766, -0.26178836822509766, -0.26178836822509766, -0.26178836822509766, -0.26178836822509766, -0.26178836822509766, -0.26178836822509766], "metadata": {"source_tokens": ["However", ",", "it", "became", "far", "less", "safe", "for", "the", "Nationals", "from", "1983", "onward", ",", "and", "strong", "population", "growth", "over", "the", "last", "three", "decades", "has", "seen", "it", "progressively", "lose", "its", "rural", "territory", "and", "reduced", "it", "to", "a", "more", "coastal", "##-", "##base", "##d", "and", "urban", "##ised", "division", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "far", "less", "safe", "for", "the", "Nationals", "from", "1983", "onward", "[unused6]", "[SEP]", "[unused1]", "strong", "population", "growth", "over", "the", "last", "three", "decades", "[unused2]", "[unused3]", "has", "seen", "[unused4]", "[unused5]", "it", "progressively", "lose", "its", "rural", "territory", "and", "reduced", "it", "to", "a", "more", "coastal", "##-", "##base", "##d", "and", "urban", "##ised", "division", "[unused6]", "[SEP]"]]}

input 119:  {"source": "However , when the antigenicities of the seed strains and wild viruses do not match , vaccines fail to protect the vaccinees .\n"}
prediction:  {"predictions": [[1, 20034, 1116, 2, 3, 8693, 4, 5, 1106, 3244, 1103, 20034, 1279, 1165, 1103, 2848, 19438, 4233, 1104, 1103, 6478, 21116, 1105, 4098, 20942, 1202, 1136, 1801, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2848, 19438, 4233, 1104, 1103, 6478, 21116, 1105, 4098, 20942, 2, 3, 1202, 1136, 1801, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01287610549479723, -0.036399129778146744, -0.10577058792114258, -0.11188983917236328, -0.11188983917236328, -0.11188983917236328, -0.11188983917236328, -0.11188983917236328, -0.11188983917236328, -0.11188983917236328], "metadata": {"source_tokens": ["However", ",", "when", "the", "anti", "##genic", "##ities", "of", "the", "seed", "strains", "and", "wild", "viruses", "do", "not", "match", ",", "vaccine", "##s", "fail", "to", "protect", "the", "vaccine", "##es", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "vaccine", "##s", "[unused2]", "[unused3]", "fail", "[unused4]", "[unused5]", "to", "protect", "the", "vaccine", "##es", "when", "the", "anti", "##genic", "##ities", "of", "the", "seed", "strains", "and", "wild", "viruses", "do", "not", "match", "[unused6]", "[SEP]", "[unused1]", "the", "anti", "##genic", "##ities", "of", "the", "seed", "strains", "and", "wild", "viruses", "[unused2]", "[unused3]", "do", "not", "match", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 120:  {"source": "If given this data , the Germans would be able to adjust their aim and correct any shortfall .\n"}
prediction:  {"predictions": [[1, 1103, 6494, 2, 3, 1156, 1129, 4, 5, 1682, 1106, 14878, 1147, 6457, 1105, 5663, 1251, 1603, 8877, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00012515840353444219, -0.0729207992553711, -0.0710287094116211, -0.0710287094116211, -0.0710287094116211, -0.0710287094116211, -0.0710287094116211, -0.0710287094116211, -0.0710287094116211, -0.0710287094116211], "metadata": {"source_tokens": ["If", "given", "this", "data", ",", "the", "Germans", "would", "be", "able", "to", "adjust", "their", "aim", "and", "correct", "any", "short", "##fall", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Germans", "[unused2]", "[unused3]", "would", "be", "[unused4]", "[unused5]", "able", "to", "adjust", "their", "aim", "and", "correct", "any", "short", "##fall", "[unused6]", "[SEP]"]]}

input 121:  {"source": "If the second excitation pulse is sent prematurely before the relaxation is complete , the average magnetization vector still points in a nonparallel direction , giving suboptimal absorption and emission of the pulse .\n"}
prediction:  {"predictions": [[1, 1103, 1903, 24197, 2734, 9479, 2, 3, 1827, 4, 5, 1107, 170, 1664, 17482, 22096, 1233, 2447, 1253, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1248, 4252, 24214, 8561, 2, 3, 1110, 1850, 4, 5, 24505, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1248, 4252, 24214, 8561, 2, 3, 1110, 1850, 4, 5, 24505, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1248, 4252, 24214, 8561, 2, 3, 1110, 1850, 4, 5, 24505, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1248, 4252, 24214, 8561, 2, 3, 1110, 1850, 4, 5, 24505, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1248, 4252, 24214, 8561, 2, 3, 1110, 1850, 4, 5, 24505, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1248, 4252, 24214, 8561, 2, 3, 1110, 1850, 4, 5, 24505, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1248, 4252, 24214, 8561, 2, 3, 1110, 4, 5, 1103, 1248, 17482, 22096, 1233, 2447, 2368, 4841, 4184, 3121, 7435, 18099, 1105, 17744, 1104, 1103, 8561, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027065066620707512, -0.058465976268053055, -0.18696805834770203, -0.13502255082130432, -0.14717017114162445, -0.17851349711418152, -0.2462387979030609, -0.19921952486038208, -0.03365516662597656, -0.034501075744628906], "metadata": {"source_tokens": ["If", "the", "second", "ex", "##citation", "pulse", "is", "sent", "premature", "##ly", "before", "the", "relaxation", "is", "complete", ",", "the", "average", "magnet", "##ization", "vector", "still", "points", "in", "a", "non", "##par", "##alle", "##l", "direction", ",", "giving", "sub", "##op", "##ti", "##mal", "absorption", "and", "emission", "of", "the", "pulse", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "average", "magnet", "##ization", "vector", "[unused2]", "[unused3]", "points", "[unused4]", "[unused5]", "in", "a", "non", "##par", "##alle", "##l", "direction", "still", "[unused6]", "[SEP]", "[unused1]", "the", "second", "ex", "##citation", "pulse", "[unused2]", "[unused3]", "is", "sent", "[unused4]", "[unused5]", "premature", "##ly", "[unused6]", "[SEP]", "[unused1]", "the", "second", "ex", "##citation", "pulse", "[unused2]", "[unused3]", "is", "sent", "[unused4]", "[unused5]", "premature", "##ly", "[unused6]", "[SEP]", "[unused1]", "the", "second", "ex", "##citation", "pulse", "[unused2]", "[unused3]", "is", "sent", "[unused4]", "[unused5]", "premature", "##ly", "[unused6]", "[SEP]", "[unused1]", "the", "second", "ex", "##citation", "pulse", "[unused2]", "[unused3]", "is", "sent", "[unused4]", "[unused5]", "premature", "##ly", "[unused6]", "[SEP]", "[unused1]", "the", "second", "ex", "##citation", "pulse", "[unused2]", "[unused3]", "is", "sent", "[unused4]", "[unused5]", "premature", "##ly", "[unused6]", "[SEP]", "[unused1]", "the", "second", "ex", "##citation", "pulse", "[unused2]", "[unused3]", "is", "sent", "[unused4]", "[unused5]", "premature", "##ly", "[unused6]", "[SEP]", "[unused1]", "the", "second", "ex", "##citation", "pulse", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "second", "##par", "##alle", "##l", "direction", "giving", "sub", "##op", "##ti", "##mal", "absorption", "and", "emission", "of", "the", "pulse", "[unused6]", "[SEP]"]]}

input 122:  {"source": "In 1005 for example , the governor of the important Adriatic port of Dyrrhachium had surrendered the town to Basil II .\n"}
prediction:  {"predictions": [[1, 1103, 4066, 1104, 1103, 1696, 26122, 4104, 1104, 141, 12577, 1197, 2328, 4313, 1818, 2, 3, 1125, 10738, 4, 5, 1103, 1411, 1106, 16209, 1563, 1130, 1620, 1571, 1111, 1859, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01406780257821083, -0.21644830703735352, -0.18454599380493164, -0.18454599380493164, -0.18454599380493164, -0.18454599380493164, -0.18454647064208984, -0.18454647064208984, -0.18454647064208984, -0.18454647064208984], "metadata": {"source_tokens": ["In", "100", "##5", "for", "example", ",", "the", "governor", "of", "the", "important", "Adriatic", "port", "of", "D", "##yr", "##r", "##ha", "##chi", "##um", "had", "surrendered", "the", "town", "to", "Basil", "II", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "governor", "of", "the", "important", "Adriatic", "port", "of", "D", "##yr", "##r", "##ha", "##chi", "##um", "[unused2]", "[unused3]", "had", "surrendered", "[unused4]", "[unused5]", "the", "town", "to", "Basil", "II", "In", "100", "##5", "for", "example", "[unused6]", "[SEP]"]]}

input 123:  {"source": "In 1866 , he began a second term as Lord Chancellor , which ended with his death in the next year .\n"}
prediction:  {"predictions": [[1, 2188, 8861, 2, 3, 2207, 4, 5, 1114, 1117, 1473, 1107, 1103, 1397, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1310, 4, 5, 170, 1248, 1858, 1112, 2188, 8861, 1130, 7146, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.028251871466636658, -0.04027049243450165, -0.026329517364501953, -0.025890827178955078, -0.025890827178955078, -0.025890827178955078, -0.025890827178955078, -0.025890827178955078, -0.025890827178955078, -0.025890827178955078], "metadata": {"source_tokens": ["In", "1866", ",", "he", "began", "a", "second", "term", "as", "Lord", "Chancellor", ",", "which", "ended", "with", "his", "death", "in", "the", "next", "year", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Lord", "Chancellor", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "with", "his", "death", "in", "the", "next", "year", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "a", "second", "term", "as", "Lord", "Chancellor", "In", "1866", "[unused6]", "[SEP]"]]}

input 124:  {"source": "In 1911 , with Francis La Flesche , she published `` The Omaha Tribe '' .\n"}
prediction:  {"predictions": [[1, 1131, 2, 3, 1502, 4, 5, 1109, 13072, 15987, 1130, 4383, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005722318310290575, -0.18023920059204102, -0.17812490463256836, -0.17812490463256836, -0.17812490463256836, -0.17812490463256836, -0.17812490463256836, -0.17812490463256836, -0.17812490463256836, -0.17812490463256836], "metadata": {"source_tokens": ["In", "1911", ",", "with", "Francis", "La", "F", "##les", "##che", ",", "she", "published", "`", "##`", "The", "Omaha", "Tribe", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "she", "[unused2]", "[unused3]", "published", "[unused4]", "[unused5]", "The", "Omaha", "Tribe", "In", "1911", "[unused6]", "[SEP]"]]}

input 125:  {"source": "In 1926 , `` The News and Courier '' was bought by the owners of Charleston 's main evening paper , `` The Evening Post . ''\n"}
prediction:  {"predictions": [[1, 1109, 3128, 1105, 3291, 16706, 2, 3, 1108, 3306, 4, 5, 1118, 1103, 5032, 1104, 10874, 112, 1116, 1514, 3440, 2526, 1130, 4082, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10874, 112, 1116, 1514, 3440, 2526, 2, 3, 1110, 4, 5, 1109, 11718, 3799, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006806023418903351, -0.04407338425517082, -0.025152206420898438, -0.02570819854736328, -0.02570819854736328, -0.02570819854736328, -0.02570819854736328, -0.02570819854736328, -0.02570819854736328, -0.02570819854736328], "metadata": {"source_tokens": ["In", "1926", ",", "`", "##`", "The", "News", "and", "Co", "##urier", "'", "##'", "was", "bought", "by", "the", "owners", "of", "Charleston", "'", "##s", "main", "evening", "paper", ",", "`", "##`", "The", "Evening", "Post", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "News", "and", "Co", "##urier", "[unused2]", "[unused3]", "was", "bought", "[unused4]", "[unused5]", "by", "the", "owners", "of", "Charleston", "'", "##s", "main", "evening", "paper", "In", "1926", "[unused6]", "[SEP]", "[unused1]", "Charleston", "'", "##s", "main", "evening", "paper", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "The", "Evening", "Post", "[unused6]", "[SEP]"]]}

input 126:  {"source": "In 1954 , a KOMO news photographer discovered a way to develop color film in a new process that took just a few hours instead of days .\n"}
prediction:  {"predictions": [[1, 170, 1207, 1965, 2, 3, 1261, 4, 5, 1198, 170, 1374, 2005, 1939, 1104, 1552, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 148, 13041, 2346, 2371, 8152, 2, 3, 2751, 4, 5, 170, 1236, 1106, 3689, 2942, 1273, 1107, 170, 1207, 1965, 1130, 3183, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.022319385781884193, -0.014807312749326229, -0.0942072868347168, -0.09516763687133789, -0.09516763687133789, -0.09516763687133789, -0.09516763687133789, -0.09516763687133789, -0.09516763687133789, -0.09516763687133789], "metadata": {"source_tokens": ["In", "1954", ",", "a", "K", "##OM", "##O", "news", "photographer", "discovered", "a", "way", "to", "develop", "color", "film", "in", "a", "new", "process", "that", "took", "just", "a", "few", "hours", "instead", "of", "days", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "new", "process", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "just", "a", "few", "hours", "instead", "of", "days", "[unused6]", "[SEP]", "[unused1]", "a", "K", "##OM", "##O", "news", "photographer", "[unused2]", "[unused3]", "discovered", "[unused4]", "[unused5]", "a", "way", "to", "develop", "color", "film", "in", "a", "new", "process", "In", "1954", "[unused6]", "[SEP]"]]}

input 127:  {"source": "In 1964 Barrie appeared in two episodes of `` Alfred Hitchcock Presents '' .\n"}
prediction:  {"predictions": [[1, 21715, 1663, 2, 3, 1691, 4, 5, 1107, 1160, 3426, 1104, 169, 28152, 5492, 21358, 21680, 1130, 2668, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0003067879588343203, -0.03255128860473633, -0.03207111358642578, -0.03207111358642578, -0.03207111358642578, -0.03207111358642578, -0.03207111358642578, -0.03207111358642578, -0.03207111358642578, -0.03207111358642578], "metadata": {"source_tokens": ["In", "1964", "Barr", "##ie", "appeared", "in", "two", "episodes", "of", "`", "##`", "Alfred", "Hitchcock", "Presents", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Barr", "##ie", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "in", "two", "episodes", "of", "`", "##`", "Alfred", "Hitchcock", "Presents", "In", "1964", "[unused6]", "[SEP]"]]}

Batch 1 Test Time =  87.80782747268677  s
Decodertime : 0.00018525123596191406
g_f_logprobs : 0.046173810958862305
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.04611968994140625
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.04604291915893555
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.04611515998840332
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.046546220779418945
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.04605555534362793
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.0461885929107666
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.04628419876098633
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.046063899993896484
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.04603981971740723
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.04605698585510254
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.04610848426818848
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.04611539840698242
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.04606294631958008
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.04617667198181152
Decodertime : 0.000152587890625
g_f_logprobs : 0.04603409767150879
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.04604482650756836
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.0462343692779541
Decodertime : 0.00018167495727539062
g_f_logprobs : 0.04610323905944824
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.04638028144836426
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.046346187591552734
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.04618430137634277
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.04619312286376953
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.0461885929107666
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.046149253845214844
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.046225786209106445
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.04608941078186035
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.0462646484375
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.046122074127197266
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.04617595672607422
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.04615616798400879
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.04621458053588867
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.04604077339172363
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.04612088203430176
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.046132802963256836
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.04620051383972168
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.046109914779663086
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.04615330696105957
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.04611539840698242
Decodertime : 0.000171661376953125
g_f_logprobs : 0.04621076583862305
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.04613351821899414
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.04610610008239746
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.046137332916259766
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.046113014221191406
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.04606986045837402
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.04613137245178223
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.04629659652709961
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.04616832733154297
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.046201229095458984
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.046167612075805664
beam_search_time: 2.40289568901062 s
Decodertime : 0.00017690658569335938
g_f_logprobs : 0.07940530776977539
Decodertime : 0.0001728534698486328
g_f_logprobs : 0.07921385765075684
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.07938647270202637
Decodertime : 0.000152587890625
g_f_logprobs : 0.07933282852172852
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.07926559448242188
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.07947206497192383
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.07949280738830566
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.07953357696533203
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.07939314842224121
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.07961773872375488
Decodertime : 0.0001728534698486328
g_f_logprobs : 0.07950997352600098
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.07935428619384766
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.07944774627685547
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.0792088508605957
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.07936763763427734
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.07954764366149902
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.07942771911621094
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.07946157455444336
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.07983112335205078
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.0793604850769043
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.07941865921020508
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.07964253425598145
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.0795586109161377
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.07945990562438965
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.07999587059020996
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.07960844039916992
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.07956767082214355
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.07992887496948242
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.0795125961303711
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.07952880859375
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.07961797714233398
Decodertime : 0.00017309188842773438
g_f_logprobs : 0.07960820198059082
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.07959103584289551
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.07955718040466309
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.07990813255310059
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.0798499584197998
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.0798788070678711
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.07977795600891113
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.07986760139465332
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.07975339889526367
beam_search_time: 3.2582199573516846 s
Decodertime : 0.0001723766326904297
g_f_logprobs : 0.09907984733581543
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.09914898872375488
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.09935641288757324
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.0991668701171875
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.09955787658691406
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.09945368766784668
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.09944677352905273
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.0991508960723877
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.09978485107421875
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.09959769248962402
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.0994105339050293
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.0993647575378418
Decodertime : 0.0001709461212158203
g_f_logprobs : 0.09948897361755371
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.09941625595092773
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.0995781421661377
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.0994560718536377
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.0996699333190918
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.09944486618041992
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.09970450401306152
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.09912109375
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.09957385063171387
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.09928750991821289
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.09982848167419434
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.0993337631225586
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.09998369216918945
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.09955692291259766
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.09975194931030273
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.09990763664245605
Decodertime : 0.000156402587890625
g_f_logprobs : 0.09961581230163574
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.09940814971923828
Decodertime : 0.000152587890625
g_f_logprobs : 0.0996389389038086
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.09959721565246582
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.0997772216796875
Decodertime : 0.00017213821411132812
g_f_logprobs : 0.09957075119018555
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.09964728355407715
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.09949970245361328
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.09975337982177734
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.09930753707885742
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.09968233108520508
beam_search_time: 3.9553768634796143 s
Decodertime : 0.00017523765563964844
g_f_logprobs : 0.09923148155212402
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.09919476509094238
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.09961605072021484
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.09925723075866699
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.09945845603942871
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.09946465492248535
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.09932565689086914
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.09927630424499512
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.09956789016723633
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.09920287132263184
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.09991240501403809
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.0994558334350586
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.09970688819885254
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.09934234619140625
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.09964823722839355
Decodertime : 0.00017261505126953125
g_f_logprobs : 0.09937286376953125
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.0998392105102539
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.09927535057067871
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.0997319221496582
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.09930801391601562
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.09992766380310059
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.09958171844482422
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.09950518608093262
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.0993809700012207
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.0996549129486084
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.09934282302856445
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.09978294372558594
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.0994868278503418
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.09969139099121094
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.09943532943725586
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.09964966773986816
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.09937357902526855
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.09972023963928223
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.10056686401367188
Decodertime : 0.00021958351135253906
g_f_logprobs : 0.1000363826751709
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.09932255744934082
Decodertime : 0.00017118453979492188
g_f_logprobs : 0.09986209869384766
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.09934735298156738
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.09963345527648926
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.09934854507446289
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.09967970848083496
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.09917187690734863
Decodertime : 0.000152587890625
g_f_logprobs : 0.09956502914428711
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.09939312934875488
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.09978604316711426
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.09941887855529785
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.09978699684143066
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.09940528869628906
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.09964847564697266
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.09949278831481934
beam_search_time: 5.072581768035889 s
Decodertime : 0.00018262863159179688
g_f_logprobs : 0.12165427207946777
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.12131214141845703
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.12156271934509277
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.12170147895812988
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.12195205688476562
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.1217195987701416
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.12169814109802246
Decodertime : 0.00017309188842773438
g_f_logprobs : 0.12150049209594727
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.12161755561828613
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.12155675888061523
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.1219329833984375
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.12127161026000977
Decodertime : 0.00017380714416503906
g_f_logprobs : 0.12149739265441895
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.12171149253845215
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.12181639671325684
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.12172341346740723
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.12167739868164062
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.12186717987060547
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.12214422225952148
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.12181663513183594
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.12216806411743164
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.12158966064453125
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.12375211715698242
Decodertime : 0.00018596649169921875
g_f_logprobs : 0.12154865264892578
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.12219524383544922
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.12166666984558105
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.12216758728027344
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.12192606925964355
Decodertime : 0.00017213821411132812
g_f_logprobs : 0.12215328216552734
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.12168049812316895
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.12199616432189941
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.12126827239990234
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.12216377258300781
beam_search_time: 4.083235263824463 s
Decodertime : 0.00018072128295898438
g_f_logprobs : 0.1440269947052002
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.14371848106384277
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.14431285858154297
Decodertime : 0.000152587890625
g_f_logprobs : 0.14434313774108887
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.14367294311523438
Decodertime : 0.000152587890625
g_f_logprobs : 0.14365458488464355
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.14409375190734863
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.14385128021240234
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.14383387565612793
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.1438279151916504
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.14362502098083496
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.14386606216430664
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.14418292045593262
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.14412593841552734
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.14395928382873535
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.14429235458374023
Decodertime : 0.00017404556274414062
g_f_logprobs : 0.1441054344177246
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.14420604705810547
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.14418888092041016
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.14400243759155273
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.1440107822418213
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.14476466178894043
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.1438002586364746
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.14386606216430664
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.14419198036193848
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.14380097389221191
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.1442883014678955
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.14379572868347168
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.14407873153686523
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.14415693283081055
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.1441965103149414
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.144667387008667
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.14417362213134766
beam_search_time: 4.816852331161499 s
Decodertime : 0.00017380714416503906
g_f_logprobs : 0.14725327491760254
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.14724016189575195
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.1474320888519287
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.14779186248779297
Decodertime : 0.00018310546875
g_f_logprobs : 0.14688754081726074
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.14774751663208008
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.1470808982849121
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.1476287841796875
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.14702820777893066
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.14765620231628418
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.14725065231323242
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.14758753776550293
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.14708518981933594
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.14769983291625977
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.1472172737121582
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.14838409423828125
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.14736533164978027
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.1479184627532959
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.14718842506408691
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.14765024185180664
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.14721989631652832
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.14766764640808105
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.1474592685699463
beam_search_time: 3.435462474822998 s
Decodertime : 0.0001685619354248047
g_f_logprobs : 0.1633310317993164
Decodertime : 0.000164031982421875
g_f_logprobs : 0.16234135627746582
Decodertime : 0.000171661376953125
g_f_logprobs : 0.16257619857788086
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.16272234916687012
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.1625664234161377
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.16241931915283203
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.16281938552856445
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.16327428817749023
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.16292905807495117
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.1628274917602539
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.16271400451660156
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.16286706924438477
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.16303205490112305
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.16326594352722168
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.16286826133728027
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.1626598834991455
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.16296052932739258
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.1628131866455078
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.16304445266723633
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.16311240196228027
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.1629471778869629
Decodertime : 0.000152587890625
g_f_logprobs : 0.16290807723999023
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.1628577709197998
beam_search_time: 3.789855480194092 s
Decodertime : 0.0001895427703857422
g_f_logprobs : 0.17887568473815918
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.17734646797180176
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.17757821083068848
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.17815732955932617
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.17749786376953125
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.17784333229064941
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.17721247673034668
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.17812418937683105
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.17754650115966797
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.1784987449645996
Decodertime : 0.000152587890625
g_f_logprobs : 0.17717814445495605
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.17828083038330078
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.1776585578918457
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.17817997932434082
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.1777057647705078
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.17788386344909668
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.17736411094665527
beam_search_time: 3.055492639541626 s
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.186936616897583
Decodertime : 0.000152587890625
g_f_logprobs : 0.18617987632751465
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.18609070777893066
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.18605685234069824
Decodertime : 0.00017189979553222656
g_f_logprobs : 0.1870262622833252
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.18627643585205078
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.18608880043029785
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.1862502098083496
Decodertime : 0.000152587890625
g_f_logprobs : 0.18621253967285156
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.186661958694458
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.18640732765197754
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.1863863468170166
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.18633341789245605
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.18630671501159668
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.18595528602600098
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.1861410140991211
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.18655729293823242
beam_search_time: 3.200449228286743 s
input 128:  {"source": "In 1972 , he won from Yakutpura and later in 1978 , again from Charminar .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1281, 4, 5, 1121, 14680, 4786, 1204, 24790, 1224, 1107, 2406, 1254, 1121, 24705, 9019, 2983, 1197, 1130, 2388, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07111923396587372, -0.18365812301635742, -0.19017744064331055, -0.19017744064331055, -0.19017744064331055, -0.19017744064331055, -0.19017744064331055, -0.19017744064331055, -0.19017744064331055, -0.19017744064331055], "metadata": {"source_tokens": ["In", "1972", ",", "he", "won", "from", "Ya", "##ku", "##t", "##pura", "and", "later", "in", "1978", ",", "again", "from", "Cha", "##rm", "##ina", "##r", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "from", "Ya", "##ku", "##t", "##pura", "later", "in", "1978", "again", "from", "Cha", "##rm", "##ina", "##r", "In", "1972", "[unused6]", "[SEP]"]]}

input 129:  {"source": "In 1972 , researchers found metallic conductivity in the charge-transfer complex TTF-TCNQ .\n"}
prediction:  {"predictions": [[1, 6962, 2, 3, 1276, 4, 5, 13256, 5880, 6366, 1107, 1103, 2965, 28137, 4487, 2316, 6732, 2703, 157, 22169, 28137, 9481, 2249, 4880, 1130, 2388, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01149080041795969, -0.04863262176513672, -0.04574108123779297, -0.04574108123779297, -0.04574108123779297, -0.04574108123779297, -0.04574108123779297, -0.04574108123779297, -0.04574108123779297, -0.04574108123779297], "metadata": {"source_tokens": ["In", "1972", ",", "researchers", "found", "metallic", "conduct", "##ivity", "in", "the", "charge", "##-", "##tra", "##ns", "##fer", "complex", "T", "##TF", "##-", "##TC", "##N", "##Q", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "researchers", "[unused2]", "[unused3]", "found", "[unused4]", "[unused5]", "metallic", "conduct", "##ivity", "in", "the", "charge", "##-", "##tra", "##ns", "##fer", "complex", "T", "##TF", "##-", "##TC", "##N", "##Q", "In", "1972", "[unused6]", "[SEP]"]]}

input 130:  {"source": "In 1975 Barrie was directed by Lee Grant in the television movie `` For The Use Of The Hall '' as `` Charlotte '' .\n"}
prediction:  {"predictions": [[1, 21715, 1663, 2, 3, 1108, 2002, 4, 5, 1118, 2499, 4468, 1107, 1103, 1778, 2523, 1370, 1109, 11696, 2096, 1109, 1944, 1112, 5204, 1130, 2429, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04330797865986824, -0.16165590286254883, -0.16768789291381836, -0.16768789291381836, -0.16768789291381836, -0.16768789291381836, -0.16768789291381836, -0.16768789291381836, -0.16768789291381836, -0.16768789291381836], "metadata": {"source_tokens": ["In", "1975", "Barr", "##ie", "was", "directed", "by", "Lee", "Grant", "in", "the", "television", "movie", "`", "##`", "For", "The", "Use", "Of", "The", "Hall", "'", "##'", "as", "`", "##`", "Charlotte", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Barr", "##ie", "[unused2]", "[unused3]", "was", "directed", "[unused4]", "[unused5]", "by", "Lee", "Grant", "in", "the", "television", "movie", "For", "The", "Use", "Of", "The", "Hall", "as", "Charlotte", "In", "1975", "[unused6]", "[SEP]"]]}

input 131:  {"source": "In 1977 she appeared in two television films , as the mother of Lesley Ann Warren 's character in `` 79 Park Avenue '' and as Emily McPhail in `` Tell Me My Name '' .\n"}
prediction:  {"predictions": [[1, 1131, 2, 3, 1691, 4, 5, 1107, 1160, 1778, 2441, 1112, 1103, 1534, 1104, 26801, 5083, 5407, 112, 1116, 1959, 1107, 5899, 1670, 3194, 1105, 1112, 5590, 150, 1665, 2101, 10390, 1233, 1107, 4630, 2508, 1422, 10208, 1130, 2449, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04304688423871994, -0.07015275955200195, -0.0706791877746582, -0.0706791877746582, -0.0706791877746582, -0.0706791877746582, -0.0706791877746582, -0.0706791877746582, -0.0706791877746582, -0.0706791877746582], "metadata": {"source_tokens": ["In", "1977", "she", "appeared", "in", "two", "television", "films", ",", "as", "the", "mother", "of", "Lesley", "Ann", "Warren", "'", "##s", "character", "in", "`", "##`", "79", "Park", "Avenue", "'", "##'", "and", "as", "Emily", "M", "##c", "##P", "##hai", "##l", "in", "`", "##`", "Tell", "Me", "My", "Name", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "she", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "in", "two", "television", "films", "as", "the", "mother", "of", "Lesley", "Ann", "Warren", "'", "##s", "character", "in", "79", "Park", "Avenue", "and", "as", "Emily", "M", "##c", "##P", "##hai", "##l", "in", "Tell", "Me", "My", "Name", "In", "1977", "[unused6]", "[SEP]"]]}

input 132:  {"source": "In 1987 , Rodan became president of the American Society for Bone and Mineral Research .\n"}
prediction:  {"predictions": [[1, 11945, 1389, 2, 3, 1245, 4, 5, 2084, 1104, 1103, 1237, 2015, 1111, 17722, 1105, 9139, 4412, 2713, 1130, 2164, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0004213581851217896, -0.0616755485534668, -0.0686802864074707, -0.0686802864074707, -0.0686802864074707, -0.0686802864074707, -0.0686802864074707, -0.0686802864074707, -0.0686802864074707, -0.0686802864074707], "metadata": {"source_tokens": ["In", "1987", ",", "Rod", "##an", "became", "president", "of", "the", "American", "Society", "for", "Bone", "and", "Mine", "##ral", "Research", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rod", "##an", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "president", "of", "the", "American", "Society", "for", "Bone", "and", "Mine", "##ral", "Research", "In", "1987", "[unused6]", "[SEP]"]]}

input 133:  {"source": "In 1990 Kelsang Gyatso became also outspoken against the Geshe Studies Programme , and `` made the pursuit of his new programmes compulsory . ''\n"}
prediction:  {"predictions": [[1, 26835, 3447, 4993, 144, 2315, 2145, 1186, 2, 3, 1245, 1145, 4, 5, 25304, 1222, 1103, 144, 10654, 1162, 3829, 11512, 1130, 1997, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 3447, 4993, 144, 2315, 2145, 1186, 2, 3, 1189, 4, 5, 1103, 9542, 1104, 1117, 1207, 8473, 16472, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012185757048428059, -0.05920078605413437, -0.18578672409057617, -0.18372106552124023, -0.18372106552124023, -0.18372106552124023, -0.18372106552124023, -0.18372106552124023, -0.18372106552124023, -0.18372154235839844], "metadata": {"source_tokens": ["In", "1990", "Ke", "##ls", "##ang", "G", "##ya", "##ts", "##o", "became", "also", "outspoken", "against", "the", "G", "##esh", "##e", "Studies", "Programme", ",", "and", "`", "##`", "made", "the", "pursuit", "of", "his", "new", "programmes", "compulsory", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ke", "##ls", "##ang", "G", "##ya", "##ts", "##o", "[unused2]", "[unused3]", "became", "also", "[unused4]", "[unused5]", "outspoken", "against", "the", "G", "##esh", "##e", "Studies", "Programme", "In", "1990", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ls", "##ang", "G", "##ya", "##ts", "##o", "[unused2]", "[unused3]", "made", "[unused4]", "[unused5]", "the", "pursuit", "of", "his", "new", "programmes", "compulsory", "[unused6]", "[SEP]"]]}

input 134:  {"source": "In 2004 the Brumbies finished at the top of the Super 12 table , six points clear of the next best team .\n"}
prediction:  {"predictions": [[1, 1103, 139, 5697, 16751, 2, 3, 1845, 4, 5, 1120, 1103, 1499, 1104, 1103, 3198, 1367, 1952, 1130, 1516, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 139, 5697, 16751, 2, 3, 1845, 4, 5, 1120, 1103, 1499, 1104, 1103, 3198, 1367, 1952, 1565, 1827, 2330, 1104, 1103, 1397, 1436, 1264, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03665700927376747, -0.03512871265411377, -0.1865401268005371, -0.17838144302368164, -0.17838144302368164, -0.17838144302368164, -0.17838144302368164, -0.17838144302368164, -0.17838144302368164, -0.17838191986083984], "metadata": {"source_tokens": ["In", "2004", "the", "B", "##rum", "##bies", "finished", "at", "the", "top", "of", "the", "Super", "12", "table", ",", "six", "points", "clear", "of", "the", "next", "best", "team", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "B", "##rum", "##bies", "[unused2]", "[unused3]", "finished", "[unused4]", "[unused5]", "at", "the", "top", "of", "the", "Super", "12", "table", "In", "2004", "[unused6]", "[SEP]", "[unused1]", "the", "B", "##rum", "##bies", "[unused2]", "[unused3]", "finished", "[unused4]", "[unused5]", "at", "the", "top", "of", "the", "Super", "12", "table", "six", "points", "clear", "of", "the", "next", "best", "team", "[unused6]", "[SEP]"]]}

input 135:  {"source": "In 2006 they applied for National League Three , finishing in 5th place and qualifying for the play-offs , where they lost to St Albans Centurions .\n"}
prediction:  {"predictions": [[1, 1152, 2, 3, 3666, 4, 5, 1111, 1305, 1453, 2677, 1130, 1386, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1575, 4, 5, 1106, 1457, 24005, 2316, 24664, 2227, 27178, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 3666, 4, 5, 1111, 1305, 1453, 2677, 4416, 1107, 4025, 1282, 1105, 6045, 1111, 1103, 1505, 28137, 18438, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004975251387804747, -0.02242373488843441, -0.038038428872823715, -0.14028024673461914, -0.13912343978881836, -0.13912343978881836, -0.13912343978881836, -0.13912343978881836, -0.13912343978881836, -0.13912391662597656], "metadata": {"source_tokens": ["In", "2006", "they", "applied", "for", "National", "League", "Three", ",", "finishing", "in", "5th", "place", "and", "qualifying", "for", "the", "play", "##-", "##offs", ",", "where", "they", "lost", "to", "St", "Alba", "##ns", "Ce", "##nt", "##urion", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "they", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "for", "National", "League", "Three", "In", "2006", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "lost", "[unused4]", "[unused5]", "to", "St", "Alba", "##ns", "Ce", "##nt", "##urion", "##s", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "for", "National", "League", "Three", "finishing", "in", "5th", "place", "and", "qualifying", "for", "the", "play", "##-", "##offs", "[unused6]", "[SEP]"]]}

input 136:  {"source": "In 2007 , Sun announced `` Project Indiana '' with several goals , including providing an open source binary distribution of the OpenSolaris project , replacing SXDE .\n"}
prediction:  {"predictions": [[1, 3477, 2, 3, 1717, 4, 5, 4042, 4456, 1114, 1317, 2513, 1259, 3558, 1126, 1501, 2674, 13480, 3735, 1104, 1103, 3353, 1708, 21459, 1548, 1933, 5861, 156, 3190, 20427, 1130, 1384, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05071017146110535, -0.0456538200378418, -0.04419851303100586, -0.04419851303100586, -0.04419851303100586, -0.04419851303100586, -0.04419851303100586, -0.04419851303100586, -0.04419851303100586, -0.04419851303100586], "metadata": {"source_tokens": ["In", "2007", ",", "Sun", "announced", "`", "##`", "Project", "Indiana", "'", "##'", "with", "several", "goals", ",", "including", "providing", "an", "open", "source", "binary", "distribution", "of", "the", "Open", "##S", "##olar", "##is", "project", ",", "replacing", "S", "##X", "##DE", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sun", "[unused2]", "[unused3]", "announced", "[unused4]", "[unused5]", "Project", "Indiana", "with", "several", "goals", "including", "providing", "an", "open", "source", "binary", "distribution", "of", "the", "Open", "##S", "##olar", "##is", "project", "replacing", "S", "##X", "##DE", "In", "2007", "[unused6]", "[SEP]"]]}

input 137:  {"source": "In 2010 , scam websites co-opted a photograph of her to promote health treatments , the ubiquitous `` 1 weird old tip '' belly fat diets , and penny auctions , unauthorized usage of which Theuriau was initially unaware .\n"}
prediction:  {"predictions": [[1, 188, 24282, 12045, 2, 3, 1884, 28137, 4184, 1906, 4, 5, 170, 10110, 1104, 1123, 1106, 4609, 2332, 14115, 1130, 1333, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 10110, 1104, 1123, 2, 3, 1106, 4609, 4, 5, 2332, 14115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 19700, 1358, 2, 3, 1108, 4, 5, 2786, 11987, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.046084847301244736, -0.11204173415899277, -0.04779433459043503, -0.1692500114440918, -0.16633033752441406, -0.16633033752441406, -0.16633033752441406, -0.16633033752441406, -0.16633033752441406, -0.16633033752441406], "metadata": {"source_tokens": ["In", "2010", ",", "s", "##cam", "websites", "co", "##-", "##op", "##ted", "a", "photograph", "of", "her", "to", "promote", "health", "treatments", ",", "the", "u", "##bi", "##quito", "##us", "`", "##`", "1", "weird", "old", "tip", "'", "##'", "belly", "fat", "diet", "##s", ",", "and", "penny", "auction", "##s", ",", "un", "##aut", "##hor", "##ized", "usage", "of", "which", "The", "##uria", "##u", "was", "initially", "unaware", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "s", "##cam", "websites", "[unused2]", "[unused3]", "co", "##-", "##op", "##ted", "[unused4]", "[unused5]", "a", "photograph", "of", "her", "to", "promote", "health", "treatments", "In", "2010", "[unused6]", "[SEP]", "[unused1]", "a", "photograph", "of", "her", "[unused2]", "[unused3]", "to", "promote", "[unused4]", "[unused5]", "health", "treatments", "[unused6]", "[SEP]", "[unused1]", "The", "##uria", "##u", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "initially", "unaware", "[unused6]", "[SEP]"]]}

input 138:  {"source": "In 2011 , major vendors launched several consumer-oriented motherboards using the Intel 6-series LGA 1155 chipset and AMD 9 Series AM3 + chipsets with UEFI .\n"}
prediction:  {"predictions": [[1, 1558, 19086, 2, 3, 2536, 4, 5, 1317, 8440, 28137, 9012, 22666, 1534, 13005, 1606, 1103, 15397, 127, 28137, 6906, 1905, 149, 10583, 10520, 1571, 13228, 2105, 1105, 6586, 2137, 130, 2768, 6586, 1495, 116, 13228, 6248, 1114, 158, 14663, 2240, 1130, 1349, 6, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007312403991818428, -0.18771982192993164, -0.18523073196411133, -0.18523073196411133, -0.18523120880126953, -0.18523073196411133, -0.18523073196411133, -0.18523073196411133, -0.18523073196411133, -0.18523073196411133], "metadata": {"source_tokens": ["In", "2011", ",", "major", "vendors", "launched", "several", "consumer", "##-", "##ori", "##ented", "mother", "##boards", "using", "the", "Intel", "6", "##-", "##ser", "##ies", "L", "##GA", "115", "##5", "chips", "##et", "and", "AM", "##D", "9", "Series", "AM", "##3", "+", "chips", "##ets", "with", "U", "##EF", "##I", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "major", "vendors", "[unused2]", "[unused3]", "launched", "[unused4]", "[unused5]", "several", "consumer", "##-", "##ori", "##ented", "mother", "##boards", "using", "the", "Intel", "6", "##-", "##ser", "##ies", "L", "##GA", "115", "##5", "chips", "##et", "and", "AM", "##D", "9", "Series", "AM", "##3", "+", "chips", "##ets", "with", "U", "##EF", "##I", "In", "2011", "[unused6]", "[SEP]"]]}

input 139:  {"source": "In 2012 , Bloomberg Businessweek voted San Francisco as America 's Best City .\n"}
prediction:  {"predictions": [[1, 25638, 3518, 21394, 2, 3, 4751, 4, 5, 1727, 2948, 1112, 1738, 112, 1116, 1798, 1392, 1130, 1368, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0005941845010966063, -0.028560638427734375, -0.02761697769165039, -0.02761697769165039, -0.02761697769165039, -0.02761697769165039, -0.02761697769165039, -0.02761697769165039, -0.02761697769165039, -0.02761697769165039], "metadata": {"source_tokens": ["In", "2012", ",", "Bloomberg", "Business", "##week", "voted", "San", "Francisco", "as", "America", "'", "##s", "Best", "City", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Bloomberg", "Business", "##week", "[unused2]", "[unused3]", "voted", "[unused4]", "[unused5]", "San", "Francisco", "as", "America", "'", "##s", "Best", "City", "In", "2012", "[unused6]", "[SEP]"]]}

input 140:  {"source": "In 54 BC , Marcus Perperna is mentioned as one of the consulars who bore testimony on behalf of Marcus Aemilius Scaurus at his trial .\n"}
prediction:  {"predictions": [[1, 6042, 14286, 3365, 1605, 2, 3, 1110, 3025, 4, 5, 1112, 1141, 1104, 1103, 17004, 7666, 1130, 4335, 3823, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 17004, 7666, 2, 3, 8475, 4, 5, 11405, 1113, 6261, 1104, 6042, 138, 5521, 18575, 1361, 20452, 19664, 1120, 1117, 3443, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.030154120177030563, -0.009739523753523827, -0.019694805145263672, -0.019367694854736328, -0.019367694854736328, -0.019367694854736328, -0.019367694854736328, -0.019367694854736328, -0.019367694854736328, -0.019367694854736328], "metadata": {"source_tokens": ["In", "54", "BC", ",", "Marcus", "Per", "##per", "##na", "is", "mentioned", "as", "one", "of", "the", "consul", "##ars", "who", "bore", "testimony", "on", "behalf", "of", "Marcus", "A", "##em", "##ili", "##us", "Sc", "##aurus", "at", "his", "trial", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Marcus", "Per", "##per", "##na", "[unused2]", "[unused3]", "is", "mentioned", "[unused4]", "[unused5]", "as", "one", "of", "the", "consul", "##ars", "In", "54", "BC", "[unused6]", "[SEP]", "[unused1]", "the", "consul", "##ars", "[unused2]", "[unused3]", "bore", "[unused4]", "[unused5]", "testimony", "on", "behalf", "of", "Marcus", "A", "##em", "##ili", "##us", "Sc", "##aurus", "at", "his", "trial", "[unused6]", "[SEP]"]]}

input 141:  {"source": "In Canada , there are two organizations that regulate university and collegiate athletics .\n"}
prediction:  {"predictions": [[1, 1160, 3722, 2, 3, 16146, 4, 5, 2755, 1105, 14532, 11645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0006276539643295109, -0.26423120498657227, -0.26204490661621094, -0.26204490661621094, -0.26204490661621094, -0.26204490661621094, -0.26204490661621094, -0.26204490661621094, -0.26204490661621094, -0.26204490661621094], "metadata": {"source_tokens": ["In", "Canada", ",", "there", "are", "two", "organizations", "that", "regulate", "university", "and", "collegiate", "athletics", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "two", "organizations", "[unused2]", "[unused3]", "regulate", "[unused4]", "[unused5]", "university", "and", "collegiate", "athletics", "[unused6]", "[SEP]"]]}

input 142:  {"source": "In French , `` droit '' can mean `` the whole body of the Law '' , as in the motto `` dieu et mon droit , '' which is to say `` God and my whole body of Law . ''\n"}
prediction:  {"predictions": [[1, 173, 21418, 1204, 2, 3, 1169, 1928, 4, 5, 1103, 2006, 1404, 1104, 1103, 2601, 1130, 1497, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 13658, 169, 28152, 19863, 173, 21418, 1204, 2, 3, 1110, 4, 5, 1106, 1474, 169, 28152, 1875, 1105, 1139, 2006, 1404, 1104, 2601, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.020702462643384933, -0.09244609624147415, -0.11698150634765625, -0.11830568313598633, -0.11830568313598633, -0.11830568313598633, -0.11830568313598633, -0.11830568313598633, -0.11830568313598633, -0.11830568313598633], "metadata": {"source_tokens": ["In", "French", ",", "`", "##`", "d", "##roi", "##t", "'", "##'", "can", "mean", "`", "##`", "the", "whole", "body", "of", "the", "Law", "'", "##'", ",", "as", "in", "the", "motto", "`", "##`", "die", "##u", "et", "mon", "d", "##roi", "##t", ",", "'", "##'", "which", "is", "to", "say", "`", "##`", "God", "and", "my", "whole", "body", "of", "Law", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "d", "##roi", "##t", "[unused2]", "[unused3]", "can", "mean", "[unused4]", "[unused5]", "the", "whole", "body", "of", "the", "Law", "In", "French", "[unused6]", "[SEP]", "[unused1]", "the", "motto", "`", "##`", "mon", "d", "##roi", "##t", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "to", "say", "`", "##`", "God", "and", "my", "whole", "body", "of", "Law", "[unused6]", "[SEP]"]]}

input 143:  {"source": "In Jewish Hebrew , the Samaritans are called `` Shomronim '' , while in Samaritan Hebrew they call themselves `` Shamerim '' .\n"}
prediction:  {"predictions": [[1, 1152, 2, 3, 1840, 4, 5, 2310, 156, 25948, 10205, 1107, 2687, 7710, 5108, 6235, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2687, 7710, 5108, 1116, 2, 3, 1132, 1270, 4, 5, 156, 25453, 3484, 4060, 1130, 2778, 6235, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.043974731117486954, -0.027676770463585854, -0.1210789680480957, -0.11468172073364258, -0.11468219757080078, -0.11468172073364258, -0.11468219757080078, -0.11468172073364258, -0.11468219757080078, -0.11468219757080078], "metadata": {"source_tokens": ["In", "Jewish", "Hebrew", ",", "the", "Sam", "##ari", "##tan", "##s", "are", "called", "`", "##`", "S", "##hom", "##ron", "##im", "'", "##'", ",", "while", "in", "Sam", "##ari", "##tan", "Hebrew", "they", "call", "themselves", "`", "##`", "S", "##hame", "##rim", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "they", "[unused2]", "[unused3]", "call", "[unused4]", "[unused5]", "themselves", "S", "##hame", "##rim", "in", "Sam", "##ari", "##tan", "Hebrew", "[unused6]", "[SEP]", "[unused1]", "the", "Sam", "##ari", "##tan", "##s", "[unused2]", "[unused3]", "are", "called", "[unused4]", "[unused5]", "S", "##hom", "##ron", "##im", "In", "Jewish", "Hebrew", "[unused6]", "[SEP]"]]}

input 144:  {"source": "In Jewish belief , its fulfilment will be revealed in the cumulation of Creation , in the era of resurrection , in the physical World .\n"}
prediction:  {"predictions": [[1, 1157, 175, 19284, 2723, 1880, 2, 3, 1209, 1129, 3090, 4, 5, 1107, 1103, 16040, 6856, 1104, 19470, 1107, 1103, 3386, 1104, 26926, 1107, 1103, 2952, 1291, 1130, 2778, 6369, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012368369847536087, -0.13380765914916992, -0.13710975646972656, -0.13710975646972656, -0.13710975646972656, -0.13710975646972656, -0.13710975646972656, -0.13710975646972656, -0.13710975646972656, -0.13710975646972656], "metadata": {"source_tokens": ["In", "Jewish", "belief", ",", "its", "f", "##ulf", "##il", "##ment", "will", "be", "revealed", "in", "the", "cum", "##ulation", "of", "Creation", ",", "in", "the", "era", "of", "resurrection", ",", "in", "the", "physical", "World", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "its", "f", "##ulf", "##il", "##ment", "[unused2]", "[unused3]", "will", "be", "revealed", "[unused4]", "[unused5]", "in", "the", "cum", "##ulation", "of", "Creation", "in", "the", "era", "of", "resurrection", "in", "the", "physical", "World", "In", "Jewish", "belief", "[unused6]", "[SEP]"]]}

input 145:  {"source": "In June , Nasser took control of the interior ministry post from Naguib loyalist Sulayman Hafez , and pressured Naguib to conclude the abolition of the monarchy .\n"}
prediction:  {"predictions": [[1, 11896, 14607, 2, 3, 1261, 4, 5, 1654, 1104, 1103, 4604, 8382, 2112, 1121, 11896, 13830, 13292, 9125, 1776, 27040, 25939, 11679, 8124, 1584, 1130, 1340, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11896, 14607, 2, 3, 2997, 1181, 4, 5, 11896, 13830, 13292, 1106, 17581, 1103, 18304, 1104, 1103, 14358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00854539591819048, -0.010952365584671497, -0.06413412094116211, -0.06254386901855469, -0.06254386901855469, -0.06254386901855469, -0.06254386901855469, -0.06254386901855469, -0.06254386901855469, -0.06254386901855469], "metadata": {"source_tokens": ["In", "June", ",", "Na", "##sser", "took", "control", "of", "the", "interior", "ministry", "post", "from", "Na", "##gu", "##ib", "loyal", "##ist", "Sul", "##ayman", "Ha", "##fe", "##z", ",", "and", "pressure", "##d", "Na", "##gu", "##ib", "to", "conclude", "the", "abolition", "of", "the", "monarchy", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "control", "of", "the", "interior", "ministry", "post", "from", "Na", "##gu", "##ib", "loyal", "##ist", "Sul", "##ayman", "Ha", "##fe", "##z", "In", "June", "[unused6]", "[SEP]", "[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "pressure", "##d", "[unused4]", "[unused5]", "Na", "##gu", "##ib", "to", "conclude", "the", "abolition", "of", "the", "monarchy", "[unused6]", "[SEP]"]]}

input 146:  {"source": "In October 2009 it was confirmed that the Byrom Street cutting was a hitching and unhitching point for trains being cable hauled to Edge Hill via the Victoria Tunnel .\n"}
prediction:  {"predictions": [[1, 1103, 1650, 16071, 1715, 5910, 2, 3, 1108, 4, 5, 170, 1855, 7520, 1105, 8362, 17481, 7520, 1553, 1111, 3918, 1217, 6095, 13486, 1106, 10403, 2404, 2258, 1103, 3006, 12872, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 3659, 4, 5, 1115, 1103, 1650, 16071, 1715, 5910, 1108, 170, 1855, 7520, 1105, 8362, 17481, 7520, 1553, 1111, 3918, 1217, 6095, 13486, 1106, 10403, 2404, 2258, 1103, 3006, 12872, 1130, 1357, 1371, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023791883140802383, -0.05110929161310196, -0.08298921585083008, -0.07668495178222656, -0.07668495178222656, -0.07668495178222656, -0.07668495178222656, -0.07668495178222656, -0.07668495178222656, -0.07668495178222656], "metadata": {"source_tokens": ["In", "October", "2009", "it", "was", "confirmed", "that", "the", "By", "##rom", "Street", "cutting", "was", "a", "hit", "##ching", "and", "un", "##hit", "##ching", "point", "for", "trains", "being", "cable", "hauled", "to", "Edge", "Hill", "via", "the", "Victoria", "Tunnel", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "By", "##rom", "Street", "cutting", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "hit", "##ching", "and", "un", "##hit", "##ching", "point", "for", "trains", "being", "cable", "hauled", "to", "Edge", "Hill", "via", "the", "Victoria", "Tunnel", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "confirmed", "[unused4]", "[unused5]", "that", "the", "By", "##rom", "Street", "cutting", "was", "a", "hit", "##ching", "and", "un", "##hit", "##ching", "point", "for", "trains", "being", "cable", "hauled", "to", "Edge", "Hill", "via", "the", "Victoria", "Tunnel", "In", "October", "2009", "[unused6]", "[SEP]"]]}

input 147:  {"source": "In September 1941 , she joined the Women 's Auxiliary Air Force , working at the Department of the Chief of Air Staff as Assistant Section Officer for Intelligence duties , before being posted in July 1942 to Moreton-in-Marsh , where she was promoted to Section officer .\n"}
prediction:  {"predictions": [[1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1196, 1217, 6310, 1107, 1351, 2889, 1106, 3046, 1633, 28137, 1394, 28137, 2107, 7666, 1324, 1130, 1347, 3018, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1108, 3082, 4, 5, 1106, 6177, 2575, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1684, 1120, 1103, 1951, 1104, 1103, 2534, 1104, 1806, 5949, 1112, 5414, 6177, 4124, 1111, 7829, 5078, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1684, 1120, 1103, 1951, 1104, 1103, 2534, 1104, 1806, 5949, 1112, 5414, 6177, 4124, 1111, 7829, 5078, 1196, 1217, 6310, 1107, 1351, 2889, 1106, 3046, 1633, 28137, 1394, 28137, 2107, 7666, 1324, 1187, 1131, 1108, 3082, 102, 1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1684, 1120, 1103, 1951, 1104, 1103, 2534, 1104, 1806, 5949, 1112, 5414, 6177, 4124, 1111, 7829, 5078, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03312478959560394, -0.04213560372591019, -0.05131380632519722, -0.07048937678337097, -0.09964951127767563, -0.19913673400878906, -0.20295333862304688, -0.20295381546020508, -0.20295381546020508, -0.20295381546020508], "metadata": {"source_tokens": ["In", "September", "1941", ",", "she", "joined", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", ",", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", ",", "before", "being", "posted", "in", "July", "1942", "to", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", ",", "where", "she", "was", "promoted", "to", "Section", "officer", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "before", "being", "posted", "in", "July", "1942", "to", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", "In", "September", "1941", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "was", "promoted", "[unused4]", "[unused5]", "to", "Section", "officer", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", "before", "being", "posted", "in", "July", "1942", "to", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", "where", "she", "was", "promoted", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", "[unused6]", "[SEP]"]]}

input 148:  {"source": "In Van Howe 's study , all cases of meatal stenosis were among circumcised boys .\n"}
prediction:  {"predictions": [[1, 1155, 2740, 1104, 6092, 1348, 188, 5208, 11776, 2, 3, 1127, 4, 5, 1621, 172, 3161, 19172, 14636, 1181, 3287, 1130, 3605, 13724, 112, 1116, 2025, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00010036188905360177, -0.14476823806762695, -0.14431190490722656, -0.14431190490722656, -0.14431238174438477, -0.14431238174438477, -0.14431238174438477, -0.14431238174438477, -0.14431238174438477, -0.14431238174438477], "metadata": {"source_tokens": ["In", "Van", "Howe", "'", "##s", "study", ",", "all", "cases", "of", "meat", "##al", "s", "##ten", "##osis", "were", "among", "c", "##ir", "##cum", "##cise", "##d", "boys", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "all", "cases", "of", "meat", "##al", "s", "##ten", "##osis", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "among", "c", "##ir", "##cum", "##cise", "##d", "boys", "In", "Van", "Howe", "'", "##s", "study", "[unused6]", "[SEP]"]]}

input 149:  {"source": "In `` The Andromeda Strain '' , Michael Crichton 's first novel published under his real name , only two people exposed to a pathogenic extraterrestrial microbe survive .\n"}
prediction:  {"predictions": [[1, 1178, 1160, 1234, 2, 3, 5490, 4, 5, 1106, 170, 3507, 17960, 3908, 2083, 14201, 13119, 17599, 3962, 5195, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1847, 140, 10886, 1633, 112, 1116, 1148, 2281, 2, 3, 1502, 4, 5, 1223, 1117, 1842, 1271, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05502501502633095, -0.005982565693557262, -0.057282447814941406, -0.05626487731933594, -0.05626487731933594, -0.05626487731933594, -0.05626487731933594, -0.05626487731933594, -0.05626487731933594, -0.05626487731933594], "metadata": {"source_tokens": ["In", "`", "##`", "The", "And", "##rome", "##da", "St", "##rain", "'", "##'", ",", "Michael", "C", "##rich", "##ton", "'", "##s", "first", "novel", "published", "under", "his", "real", "name", ",", "only", "two", "people", "exposed", "to", "a", "path", "##ogenic", "extra", "##ter", "##rest", "##rial", "micro", "##be", "survive", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "only", "two", "people", "[unused2]", "[unused3]", "exposed", "[unused4]", "[unused5]", "to", "a", "path", "##ogenic", "extra", "##ter", "##rest", "##rial", "micro", "##be", "survive", "[unused6]", "[SEP]", "[unused1]", "Michael", "C", "##rich", "##ton", "'", "##s", "first", "novel", "[unused2]", "[unused3]", "published", "[unused4]", "[unused5]", "under", "his", "real", "name", "[unused6]", "[SEP]"]]}

input 150:  {"source": "In a news post , Holkins stated that he reserved the right to bring Carl back any time Krahulik goes to France .\n"}
prediction:  {"predictions": [[1, 9800, 10493, 4935, 2, 3, 2202, 4, 5, 1115, 1119, 9142, 1103, 1268, 1106, 2498, 4804, 1171, 1251, 1159, 148, 10659, 15818, 1377, 2947, 1106, 1699, 1130, 170, 2371, 2112, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 9142, 4, 5, 1103, 1268, 1106, 2498, 4804, 1171, 1251, 1159, 148, 10659, 15818, 1377, 2947, 1106, 1699, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.030572371557354927, -0.03909065201878548, -0.06113386154174805, -0.05288076400756836, -0.05288076400756836, -0.05288076400756836, -0.05288076400756836, -0.05288076400756836, -0.05288076400756836, -0.05288076400756836], "metadata": {"source_tokens": ["In", "a", "news", "post", ",", "Ho", "##lk", "##ins", "stated", "that", "he", "reserved", "the", "right", "to", "bring", "Carl", "back", "any", "time", "K", "##rah", "##uli", "##k", "goes", "to", "France", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ho", "##lk", "##ins", "[unused2]", "[unused3]", "stated", "[unused4]", "[unused5]", "that", "he", "reserved", "the", "right", "to", "bring", "Carl", "back", "any", "time", "K", "##rah", "##uli", "##k", "goes", "to", "France", "In", "a", "news", "post", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "reserved", "[unused4]", "[unused5]", "the", "right", "to", "bring", "Carl", "back", "any", "time", "K", "##rah", "##uli", "##k", "goes", "to", "France", "[unused6]", "[SEP]"]]}

input 151:  {"source": "In a typical case of substrate interference , a Language A occupies a given territory and another Language B arrives in the same territory .\n"}
prediction:  {"predictions": [[1, 1330, 6828, 139, 2, 3, 8121, 4, 5, 1107, 1103, 1269, 3441, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 6828, 138, 2, 3, 14679, 4, 5, 170, 1549, 3441, 1130, 170, 4701, 1692, 1104, 17498, 11364, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03361959382891655, -0.023338641971349716, -0.019006729125976562, -0.01708364486694336, -0.01708364486694336, -0.01708364486694336, -0.01708364486694336, -0.01708364486694336, -0.01708364486694336, -0.01708364486694336], "metadata": {"source_tokens": ["In", "a", "typical", "case", "of", "substrate", "interference", ",", "a", "Language", "A", "occupies", "a", "given", "territory", "and", "another", "Language", "B", "arrives", "in", "the", "same", "territory", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "another", "Language", "B", "[unused2]", "[unused3]", "arrives", "[unused4]", "[unused5]", "in", "the", "same", "territory", "[unused6]", "[SEP]", "[unused1]", "a", "Language", "A", "[unused2]", "[unused3]", "occupies", "[unused4]", "[unused5]", "a", "given", "territory", "In", "a", "typical", "case", "of", "substrate", "interference", "[unused6]", "[SEP]"]]}

input 152:  {"source": "In addition , as John Cecil Masterman , chairman of the Twenty Committee , commented , `` If , for example , St Paul 's Cathedral were hit , it was useless and harmful to report that the bomb had descended upon a cinema in Islington , since the truth would inevitably get through to Germany ... ''\n"}
prediction:  {"predictions": [[1, 1287, 12091, 3257, 1399, 2, 3, 1110, 3931, 1104, 4, 5, 1103, 7714, 2341, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 12277, 1105, 19403, 1106, 2592, 1115, 1103, 5985, 1125, 9026, 1852, 170, 7678, 1107, 2181, 21103, 117, 1290, 1103, 3062, 1156, 25315, 1243, 1194, 1106, 1860, 6, 102, 102, 102, 102, 102, 102, 102, 1, 1457, 1795, 112, 1116, 5761, 2, 3, 1127, 1855, 1104, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1287, 12091, 3257, 1399, 2, 3, 1110, 4, 5, 3931, 1104, 1103, 7714, 2341, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1287, 12091, 3257, 1399, 2, 3, 1110, 4, 5, 3931, 1104, 1103, 7714, 2341, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1287, 12091, 3257, 1399, 2, 3, 1110, 4, 5, 3931, 1104, 1103, 7714, 2341, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3062, 2, 3, 1156, 25315, 1243, 4, 5, 1194, 1106, 1860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1287, 12091, 3257, 1399, 2, 3, 1110, 4, 5, 3931, 1104, 1103, 7714, 2341, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1287, 12091, 3257, 1399, 2, 3, 1110, 4, 5, 3931, 1104, 1103, 7714, 2341, 6, 102, 102, 1, 1287, 12091, 3257, 1399, 2, 3, 1110, 4, 5, 3931, 1104, 1103, 7714, 2341, 6, 102, 102]], "predicted_log_probs": [-0.061560433357954025, -0.08722779899835587, -0.14979496598243713, -0.12852489948272705, -0.13911060988903046, -0.14812257885932922, -0.14507029950618744, -0.1566183716058731, -0.1577984243631363, -0.1602596640586853], "metadata": {"source_tokens": ["In", "addition", ",", "as", "John", "Cecil", "Master", "##man", ",", "chairman", "of", "the", "Twenty", "Committee", ",", "commented", ",", "`", "##`", "If", ",", "for", "example", ",", "St", "Paul", "'", "##s", "Cathedral", "were", "hit", ",", "it", "was", "useless", "and", "harmful", "to", "report", "that", "the", "bomb", "had", "descended", "upon", "a", "cinema", "in", "Is", "##lington", ",", "since", "the", "truth", "would", "inevitably", "get", "through", "to", "Germany", "...", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "John", "Cecil", "Master", "##man", "[unused2]", "[unused3]", "is", "chairman", "of", "[unused4]", "[unused5]", "the", "Twenty", "Committee", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "useless", "and", "harmful", "to", "report", "that", "the", "bomb", "had", "descended", "upon", "a", "cinema", "in", "Is", "##lington", ",", "since", "the", "truth", "would", "inevitably", "get", "through", "to", "Germany", "[unused6]", "[SEP]", "[unused1]", "St", "Paul", "'", "##s", "Cathedral", "[unused2]", "[unused3]", "were", "hit", "of", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "John", "Cecil", "Master", "##man", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "chairman", "of", "the", "Twenty", "Committee", "[unused6]", "[SEP]", "[unused1]", "John", "Cecil", "Master", "##man", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "chairman", "of", "the", "Twenty", "Committee", "[unused6]", "[SEP]", "[unused1]", "John", "Cecil", "Master", "##man", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "chairman", "of", "the", "Twenty", "Committee", "[unused6]", "[SEP]", "[unused1]", "the", "truth", "[unused2]", "[unused3]", "would", "inevitably", "get", "[unused4]", "[unused5]", "through", "to", "Germany", "[unused6]", "[SEP]", "[unused1]", "John", "Cecil", "Master", "##man", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "chairman", "of", "the", "Twenty", "Committee", "[unused6]", "[SEP]", "[unused1]", "John", "Cecil", "Master", "##man", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "chairman", "of", "the", "Twenty", "Committee", "[unused6]", "[SEP]", "[unused1]", "John", "Cecil", "Master", "##man", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "chairman", "of", "the", "Twenty", "Committee", "[unused6]", "[SEP]"]]}

input 153:  {"source": "In athletics , Boston College left the Big East Conference and joined the Atlantic Coast Conference on July 1 , 2005 .\n"}
prediction:  {"predictions": [[1, 2859, 1531, 2, 3, 1286, 4, 5, 1103, 2562, 1689, 3047, 1130, 11645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2859, 1531, 2, 3, 1688, 4, 5, 1103, 3608, 3331, 3047, 1113, 1351, 122, 117, 1478, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.011639013886451721, -0.02587670087814331, -0.11905860900878906, -0.11661148071289062, -0.11661148071289062, -0.11661148071289062, -0.11661148071289062, -0.11661148071289062, -0.11661148071289062, -0.11661148071289062], "metadata": {"source_tokens": ["In", "athletics", ",", "Boston", "College", "left", "the", "Big", "East", "Conference", "and", "joined", "the", "Atlantic", "Coast", "Conference", "on", "July", "1", ",", "2005", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Boston", "College", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "the", "Big", "East", "Conference", "In", "athletics", "[unused6]", "[SEP]", "[unused1]", "Boston", "College", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Atlantic", "Coast", "Conference", "on", "July", "1", ",", "2005", "[unused6]", "[SEP]"]]}

input 154:  {"source": "In both cases this specialized function replaces the basic rifleman position in the fireteam .\n"}
prediction:  {"predictions": [[1, 1142, 7623, 3053, 2, 3, 22974, 4, 5, 1103, 3501, 6658, 1399, 1700, 1107, 1103, 1783, 1566, 2312, 1130, 1241, 2740, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0002673467097338289, -0.040006160736083984, -0.04175138473510742, -0.04175138473510742, -0.04175138473510742, -0.04175138473510742, -0.04175138473510742, -0.04175138473510742, -0.04175138473510742, -0.04175138473510742], "metadata": {"source_tokens": ["In", "both", "cases", "this", "specialized", "function", "replaces", "the", "basic", "rifle", "##man", "position", "in", "the", "fire", "##te", "##am", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "this", "specialized", "function", "[unused2]", "[unused3]", "replaces", "[unused4]", "[unused5]", "the", "basic", "rifle", "##man", "position", "in", "the", "fire", "##te", "##am", "In", "both", "cases", "[unused6]", "[SEP]"]]}

input 155:  {"source": "In fact , Condon , after seeing Hauptmann in a lineup at New York Police Department Greenwich Street Station told FBI Special Agent Turrou that Hauptmann was not `` John , '' the man to whom Condon claimed he passed the ransom money to in St. Raymond 's Cemetery .\n"}
prediction:  {"predictions": [[1, 16752, 3842, 2, 3, 2694, 4, 5, 1119, 2085, 1103, 25057, 1948, 1106, 1107, 1457, 28138, 7139, 112, 1116, 5501, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16752, 3842, 2, 3, 1500, 4, 5, 8099, 3139, 9341, 17037, 13656, 1358, 1115, 11679, 4455, 21544, 1179, 1108, 1136, 169, 28152, 1287, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16752, 3842, 2, 3, 1170, 3195, 4, 5, 11679, 4455, 21544, 1179, 1107, 170, 10545, 1120, 1203, 1365, 3284, 1951, 14323, 1715, 2874, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16752, 3842, 2, 3, 2694, 4, 5, 1119, 2085, 1103, 25057, 1948, 1106, 1107, 1457, 28138, 7139, 112, 1116, 5501, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16752, 3842, 2, 3, 1500, 4, 5, 8099, 3139, 9341, 17037, 13656, 1358, 1115, 11679, 4455, 21544, 1179, 1108, 1136, 1287, 1103, 1299, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01576630026102066, -0.09817714244127274, -0.05547984689474106, -0.08523678779602051, -0.1667545735836029, -0.2809481620788574, -0.30385875701904297, -0.30385875701904297, -0.30385875701904297, -0.30385875701904297], "metadata": {"source_tokens": ["In", "fact", ",", "Con", "##don", ",", "after", "seeing", "Ha", "##up", "##tman", "##n", "in", "a", "lineup", "at", "New", "York", "Police", "Department", "Greenwich", "Street", "Station", "told", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "`", "##`", "John", ",", "'", "##'", "the", "man", "to", "whom", "Con", "##don", "claimed", "he", "passed", "the", "ransom", "money", "to", "in", "St", "##.", "Raymond", "'", "##s", "Cemetery", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Con", "##don", "[unused2]", "[unused3]", "claimed", "[unused4]", "[unused5]", "he", "passed", "the", "ransom", "money", "to", "in", "St", "##.", "Raymond", "'", "##s", "Cemetery", "[unused6]", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "`", "##`", "John", "[unused6]", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "after", "seeing", "[unused4]", "[unused5]", "Ha", "##up", "##tman", "##n", "in", "a", "lineup", "at", "New", "York", "Police", "Department", "Greenwich", "Street", "Station", "[unused6]", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "claimed", "[unused4]", "[unused5]", "he", "passed", "the", "ransom", "money", "to", "in", "St", "##.", "Raymond", "'", "##s", "Cemetery", "[unused6]", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "John", "the", "man", "[unused6]", "[SEP]"]]}

input 156:  {"source": "In its first six months , RCPO concluded 858 cases convictions in 88 % of cases .\n"}
prediction:  {"predictions": [[1, 25157, 23329, 2, 3, 4803, 4, 5, 4859, 1604, 2740, 22978, 1107, 5385, 110, 1104, 2740, 1130, 1157, 1148, 1565, 1808, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.003887653350830078, -0.17409992218017578, -0.16765737533569336, -0.16765737533569336, -0.16765737533569336, -0.16765737533569336, -0.16765737533569336, -0.16765737533569336, -0.16765737533569336, -0.16765737533569336], "metadata": {"source_tokens": ["In", "its", "first", "six", "months", ",", "RC", "##PO", "concluded", "85", "##8", "cases", "convictions", "in", "88", "%", "of", "cases", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "RC", "##PO", "[unused2]", "[unused3]", "concluded", "[unused4]", "[unused5]", "85", "##8", "cases", "convictions", "in", "88", "%", "of", "cases", "In", "its", "first", "six", "months", "[unused6]", "[SEP]"]]}

input 157:  {"source": "In modern classifications , it is often treated as a subfamily of the Glyphipterigidae family .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 1110, 5165, 4, 5, 1112, 170, 11548, 1104, 1103, 144, 1193, 27008, 6451, 9866, 5389, 5598, 1266, 1130, 2030, 5393, 1116, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 5165, 4, 5, 1112, 170, 11548, 1104, 1103, 144, 1193, 27008, 6451, 9866, 5389, 5598, 5598, 1266, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0010365673806518316, -0.10141858458518982, -0.21460247039794922, -0.22646474838256836, -0.22646474838256836, -0.22646474838256836, -0.22646474838256836, -0.22646474838256836, -0.22646474838256836, -0.22646474838256836], "metadata": {"source_tokens": ["In", "modern", "classification", "##s", ",", "it", "is", "often", "treated", "as", "a", "subfamily", "of", "the", "G", "##ly", "##phi", "##pt", "##eri", "##gi", "##dae", "family", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "is", "treated", "[unused4]", "[unused5]", "as", "a", "subfamily", "of", "the", "G", "##ly", "##phi", "##pt", "##eri", "##gi", "##dae", "family", "In", "modern", "classification", "##s", "often", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "treated", "[unused4]", "[unused5]", "as", "a", "subfamily", "of", "the", "G", "##ly", "##phi", "##pt", "##eri", "##gi", "##dae", "##dae", "family", "[unused6]", "[SEP]"]]}

input 158:  {"source": "In more recent years , this policy has apparently relaxed somewhat .\n"}
prediction:  {"predictions": [[1, 1142, 2818, 2, 3, 1144, 4547, 8000, 4, 5, 4742, 1130, 1167, 2793, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0025174617767333984, -0.05541229248046875, -0.05378150939941406, -0.05378150939941406, -0.05378150939941406, -0.05378150939941406, -0.05378150939941406, -0.05378150939941406, -0.05378150939941406, -0.05378150939941406], "metadata": {"source_tokens": ["In", "more", "recent", "years", ",", "this", "policy", "has", "apparently", "relaxed", "somewhat", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "this", "policy", "[unused2]", "[unused3]", "has", "apparently", "relaxed", "[unused4]", "[unused5]", "somewhat", "In", "more", "recent", "years", "[unused6]", "[SEP]"]]}

input 159:  {"source": "In order to support planned TRAX expansion , UTA ordered 77 Siemens S70 light rail vehicles from Siemens AG .\n"}
prediction:  {"predictions": [[1, 158, 9159, 2, 3, 2802, 4, 5, 5581, 24824, 156, 20829, 1609, 4356, 4011, 1121, 24824, 14731, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0003826141473837197, -0.05076742172241211, -0.0549006462097168, -0.0549006462097168, -0.0549006462097168, -0.0549006462097168, -0.0549006462097168, -0.0549006462097168, -0.0549006462097168, -0.0549006462097168], "metadata": {"source_tokens": ["In", "order", "to", "support", "planned", "T", "##RA", "##X", "expansion", ",", "U", "##TA", "ordered", "77", "Siemens", "S", "##70", "light", "rail", "vehicles", "from", "Siemens", "AG", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "U", "##TA", "[unused2]", "[unused3]", "ordered", "[unused4]", "[unused5]", "77", "Siemens", "S", "##70", "light", "rail", "vehicles", "from", "Siemens", "AG", "[unused6]", "[SEP]"]]}

input 160:  {"source": "In particular , Cyprinidae of southwestern North America have been severely affected ; a considerable number went entirely extinct after settlement by Europeans .\n"}
prediction:  {"predictions": [[1, 170, 5602, 1295, 2, 3, 1355, 4, 5, 3665, 8256, 1170, 3433, 1118, 13810, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 27688, 1643, 19764, 5598, 1104, 10231, 1456, 1738, 2, 3, 1138, 1151, 8669, 4634, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.038091324269771576, -0.004296346567571163, -0.1171731948852539, -0.12163162231445312, -0.12163162231445312, -0.12163162231445312, -0.12163162231445312, -0.12163162231445312, -0.12163162231445312, -0.12163162231445312], "metadata": {"source_tokens": ["In", "particular", ",", "Cy", "##p", "##rini", "##dae", "of", "southwestern", "North", "America", "have", "been", "severely", "affected", ";", "a", "considerable", "number", "went", "entirely", "extinct", "after", "settlement", "by", "Europeans", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "considerable", "number", "[unused2]", "[unused3]", "went", "[unused4]", "[unused5]", "entirely", "extinct", "after", "settlement", "by", "Europeans", "[unused6]", "[SEP]", "[unused1]", "Cy", "##p", "##rini", "##dae", "of", "southwestern", "North", "America", "[unused2]", "[unused3]", "have", "been", "severely", "affected", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 161:  {"source": "In the 1901 election , after which the Oppositionists under George Leake were able to form a minority government , Frank Wilson , formerly the member for Canning , won the seat .\n"}
prediction:  {"predictions": [[1, 2748, 3425, 2, 3, 1281, 4, 5, 1103, 1946, 1130, 1103, 5064, 1728, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 16475, 3681, 1223, 1667, 12958, 2391, 2, 3, 1127, 4, 5, 1682, 1106, 1532, 170, 7309, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2748, 3425, 2, 3, 1110, 4, 5, 3147, 1103, 1420, 1111, 2825, 3381, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.030190877616405487, -0.035514671355485916, -0.027172591537237167, -0.06034088134765625, -0.05931234359741211, -0.05931234359741211, -0.05931234359741211, -0.05931234359741211, -0.05931234359741211, -0.05931234359741211], "metadata": {"source_tokens": ["In", "the", "1901", "election", ",", "after", "which", "the", "Opposition", "##ists", "under", "George", "Lea", "##ke", "were", "able", "to", "form", "a", "minority", "government", ",", "Frank", "Wilson", ",", "formerly", "the", "member", "for", "Can", "##ning", ",", "won", "the", "seat", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Frank", "Wilson", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "the", "seat", "In", "the", "1901", "election", "[unused6]", "[SEP]", "[unused1]", "the", "Opposition", "##ists", "under", "George", "Lea", "##ke", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "able", "to", "form", "a", "minority", "government", "[unused6]", "[SEP]", "[unused1]", "Frank", "Wilson", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "formerly", "the", "member", "for", "Can", "##ning", "[unused6]", "[SEP]"]]}

input 162:  {"source": "In the 1960s and 70s most of Kabul 's economy depended on tourism .\n"}
prediction:  {"predictions": [[1, 1211, 1104, 23321, 112, 1116, 4190, 2, 3, 18520, 4, 5, 1113, 8668, 1130, 1103, 3266, 1105, 19025, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0009417590918019414, -0.02840566635131836, -0.02794170379638672, -0.02794170379638672, -0.02794170379638672, -0.02794170379638672, -0.02794170379638672, -0.02794170379638672, -0.02794170379638672, -0.02794170379638672], "metadata": {"source_tokens": ["In", "the", "1960s", "and", "70s", "most", "of", "Kabul", "'", "##s", "economy", "depended", "on", "tourism", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "most", "of", "Kabul", "'", "##s", "economy", "[unused2]", "[unused3]", "depended", "[unused4]", "[unused5]", "on", "tourism", "In", "the", "1960s", "and", "70s", "[unused6]", "[SEP]"]]}

input 163:  {"source": "In the 1986 television series `` War and Remembrance '' , Johns took the role of the senior Nazi SS officer Adolf Eichmann .\n"}
prediction:  {"predictions": [[1, 11673, 2, 3, 1261, 4, 5, 1103, 1648, 1104, 1103, 2682, 5755, 6663, 2575, 1130, 1103, 2177, 1778, 1326, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006614831276237965, -0.19457435607910156, -0.19596433639526367, -0.19596433639526367, -0.19596433639526367, -0.19596433639526367, -0.19596433639526367, -0.19596433639526367, -0.19596433639526367, -0.19596433639526367], "metadata": {"source_tokens": ["In", "the", "1986", "television", "series", "`", "##`", "War", "and", "Re", "##membrance", "'", "##'", ",", "Johns", "took", "the", "role", "of", "the", "senior", "Nazi", "SS", "officer", "Adolf", "E", "##ich", "##mann", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Johns", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "the", "role", "of", "the", "senior", "Nazi", "SS", "officer", "In", "the", "1986", "television", "series", "[unused6]", "[SEP]"]]}

input 164:  {"source": "In the Civil War , he advocated strong prosecution of the Union War effort , the end of slavery , and civil rights for freed African Americans .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 11971, 4, 5, 2012, 12369, 1104, 1103, 1913, 1414, 3098, 1130, 1103, 3145, 1414, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 11971, 4, 5, 2012, 12369, 1104, 1103, 1913, 1414, 3098, 1103, 1322, 1104, 9401, 1105, 2987, 2266, 1111, 11485, 2170, 4038, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02841571532189846, -0.028336025774478912, -0.2223958969116211, -0.22587823867797852, -0.22587871551513672, -0.22587871551513672, -0.22587871551513672, -0.22587871551513672, -0.22587871551513672, -0.22587871551513672], "metadata": {"source_tokens": ["In", "the", "Civil", "War", ",", "he", "advocated", "strong", "prosecution", "of", "the", "Union", "War", "effort", ",", "the", "end", "of", "slavery", ",", "and", "civil", "rights", "for", "freed", "African", "Americans", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "advocated", "[unused4]", "[unused5]", "strong", "prosecution", "of", "the", "Union", "War", "effort", "In", "the", "Civil", "War", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "advocated", "[unused4]", "[unused5]", "strong", "prosecution", "of", "the", "Union", "War", "effort", "the", "end", "of", "slavery", "and", "civil", "rights", "for", "freed", "African", "Americans", "[unused6]", "[SEP]"]]}

input 165:  {"source": "In the Crimean War , the 5th Dragoon Guards formed part of the Heavy Cavalry Brigade and was sent to the Black Sea in 1854 .\n"}
prediction:  {"predictions": [[1, 1103, 4025, 1987, 19308, 1320, 9696, 2, 3, 1824, 4, 5, 1226, 1104, 1103, 10580, 9312, 4292, 1130, 1103, 22442, 1414, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4025, 1987, 19308, 1320, 9696, 2, 3, 1108, 1850, 4, 5, 1106, 1103, 2117, 3017, 1107, 8023, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00708847725763917, -0.016139207407832146, -0.12681865692138672, -0.12227201461791992, -0.12227201461791992, -0.12227153778076172, -0.12227201461791992, -0.12227201461791992, -0.12227201461791992, -0.12227201461791992], "metadata": {"source_tokens": ["In", "the", "Crimean", "War", ",", "the", "5th", "Dr", "##ago", "##on", "Guards", "formed", "part", "of", "the", "Heavy", "Cavalry", "Brigade", "and", "was", "sent", "to", "the", "Black", "Sea", "in", "1854", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "5th", "Dr", "##ago", "##on", "Guards", "[unused2]", "[unused3]", "formed", "[unused4]", "[unused5]", "part", "of", "the", "Heavy", "Cavalry", "Brigade", "In", "the", "Crimean", "War", "[unused6]", "[SEP]", "[unused1]", "the", "5th", "Dr", "##ago", "##on", "Guards", "[unused2]", "[unused3]", "was", "sent", "[unused4]", "[unused5]", "to", "the", "Black", "Sea", "in", "1854", "[unused6]", "[SEP]"]]}

input 166:  {"source": "In the early 19th century the Welsh Methodists broke away from the Anglican church and established their own denomination , now the Presbyterian Church of Wales .\n"}
prediction:  {"predictions": [[1, 1103, 5447, 8580, 1116, 2, 3, 1628, 4, 5, 1147, 1319, 20493, 1130, 1103, 1346, 2835, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 5447, 8580, 1116, 2, 3, 2795, 4, 5, 1283, 1121, 1103, 9137, 1749, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027773480862379074, -0.05064089596271515, -0.3326840400695801, -0.34381103515625, -0.34381103515625, -0.34381103515625, -0.34381103515625, -0.34381103515625, -0.34381103515625, -0.34381103515625], "metadata": {"source_tokens": ["In", "the", "early", "19th", "century", "the", "Welsh", "Methodist", "##s", "broke", "away", "from", "the", "Anglican", "church", "and", "established", "their", "own", "denomination", ",", "now", "the", "Presbyterian", "Church", "of", "Wales", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Welsh", "Methodist", "##s", "[unused2]", "[unused3]", "established", "[unused4]", "[unused5]", "their", "own", "denomination", "In", "the", "early", "19th", "century", "[unused6]", "[SEP]", "[unused1]", "the", "Welsh", "Methodist", "##s", "[unused2]", "[unused3]", "broke", "[unused4]", "[unused5]", "away", "from", "the", "Anglican", "church", "[unused6]", "[SEP]"]]}

input 167:  {"source": "In the north and east inhabitants speak Bumthangkha , and in the extreme southeast Khengkha is spoken .\n"}
prediction:  {"predictions": [[1, 148, 10436, 1403, 14457, 2, 3, 1110, 4606, 4, 5, 1107, 1103, 6122, 5038, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4131, 2, 3, 2936, 4, 5, 139, 1818, 22252, 1403, 14457, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007423702627420425, -0.07973287999629974, -0.06437444686889648, -0.06362676620483398, -0.06362676620483398, -0.06362676620483398, -0.06362676620483398, -0.06362676620483398, -0.06362676620483398, -0.06362676620483398], "metadata": {"source_tokens": ["In", "the", "north", "and", "east", "inhabitants", "speak", "B", "##um", "##than", "##g", "##kha", ",", "and", "in", "the", "extreme", "southeast", "K", "##hen", "##g", "##kha", "is", "spoken", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "K", "##hen", "##g", "##kha", "[unused2]", "[unused3]", "is", "spoken", "[unused4]", "[unused5]", "in", "the", "extreme", "southeast", "[unused6]", "[SEP]", "[unused1]", "inhabitants", "[unused2]", "[unused3]", "speak", "[unused4]", "[unused5]", "B", "##um", "##than", "##g", "##kha", "[unused6]", "[SEP]"]]}

input 168:  {"source": "In the winter of 1976 , Knievel was scheduled for a major jump in Chicago , Illinois .\n"}
prediction:  {"predictions": [[1, 148, 5213, 12559, 2, 3, 1108, 4533, 4, 5, 1111, 170, 1558, 5152, 1107, 2290, 1130, 1103, 3701, 1104, 2402, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0011389151914045215, -0.09586620330810547, -0.09627723693847656, -0.09627723693847656, -0.09627723693847656, -0.09627723693847656, -0.09627723693847656, -0.09627723693847656, -0.09627723693847656, -0.09627723693847656], "metadata": {"source_tokens": ["In", "the", "winter", "of", "1976", ",", "K", "##nie", "##vel", "was", "scheduled", "for", "a", "major", "jump", "in", "Chicago", ",", "Illinois", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "K", "##nie", "##vel", "[unused2]", "[unused3]", "was", "scheduled", "[unused4]", "[unused5]", "for", "a", "major", "jump", "in", "Chicago", "In", "the", "winter", "of", "1976", "[unused6]", "[SEP]"]]}

input 169:  {"source": "In this explanation the purpose of Creation is that `` God desired a dwelling place in the lower realms '' - it is man who transforms the mundane , lowest World into an abode for God 's essence .\n"}
prediction:  {"predictions": [[1, 1103, 3007, 1104, 19470, 2, 3, 1110, 4, 5, 1115, 169, 28152, 1875, 8759, 170, 13835, 1282, 1107, 1103, 2211, 9695, 1116, 112, 28131, 118, 1122, 1110, 1299, 1130, 1142, 7108, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 4, 5, 1299, 1150, 24573, 1103, 182, 22902, 1673, 117, 6905, 1291, 1154, 1126, 170, 4043, 2007, 1111, 1875, 112, 1116, 12661, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1875, 2, 3, 8759, 4, 5, 170, 13835, 1282, 1107, 1103, 2211, 9695, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.029161198064684868, -0.05641799047589302, -0.06523774564266205, -0.16553401947021484, -0.16354799270629883, -0.16354799270629883, -0.16354799270629883, -0.16354751586914062, -0.16354751586914062, -0.16354799270629883], "metadata": {"source_tokens": ["In", "this", "explanation", "the", "purpose", "of", "Creation", "is", "that", "`", "##`", "God", "desired", "a", "dwelling", "place", "in", "the", "lower", "realm", "##s", "'", "##'", "-", "it", "is", "man", "who", "transforms", "the", "m", "##unda", "##ne", ",", "lowest", "World", "into", "an", "a", "##bo", "##de", "for", "God", "'", "##s", "essence", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "purpose", "of", "Creation", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "that", "`", "##`", "God", "desired", "a", "dwelling", "place", "in", "the", "lower", "realm", "##s", "'", "##'", "-", "it", "is", "man", "In", "this", "explanation", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "man", "who", "transforms", "the", "m", "##unda", "##ne", ",", "lowest", "World", "into", "an", "a", "##bo", "##de", "for", "God", "'", "##s", "essence", "[unused6]", "[SEP]", "[unused1]", "God", "[unused2]", "[unused3]", "desired", "[unused4]", "[unused5]", "a", "dwelling", "place", "in", "the", "lower", "realm", "##s", "[unused6]", "[SEP]"]]}

input 170:  {"source": "In those years , he began to collaborate with some newspapers .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1310, 4, 5, 1106, 23200, 1114, 1199, 6195, 1130, 1343, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0007962619420140982, -0.055953025817871094, -0.055588722229003906, -0.055588722229003906, -0.055588722229003906, -0.055588722229003906, -0.055588722229003906, -0.055588722229003906, -0.055588722229003906, -0.055588722229003906], "metadata": {"source_tokens": ["In", "those", "years", ",", "he", "began", "to", "collaborate", "with", "some", "newspapers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "to", "collaborate", "with", "some", "newspapers", "In", "those", "years", "[unused6]", "[SEP]"]]}

input 171:  {"source": "Initially flying the A-4B Skyhawk , the squadron later transitioned to the A-4L Skyhawk .\n"}
prediction:  {"predictions": [[1, 1103, 5780, 2, 3, 26974, 4, 5, 1106, 1103, 138, 28137, 1527, 2162, 5751, 19952, 7245, 3754, 1103, 138, 28137, 1527, 2064, 5751, 19952, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0006299657397903502, -0.05113697052001953, -0.05052661895751953, -0.05052661895751953, -0.05052661895751953, -0.05052661895751953, -0.05052661895751953, -0.05052661895751953, -0.05052661895751953, -0.05052661895751953], "metadata": {"source_tokens": ["Initially", "flying", "the", "A", "##-", "##4", "##B", "Sky", "##hawk", ",", "the", "squadron", "later", "transitioned", "to", "the", "A", "##-", "##4", "##L", "Sky", "##hawk", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "squadron", "[unused2]", "[unused3]", "transitioned", "[unused4]", "[unused5]", "to", "the", "A", "##-", "##4", "##L", "Sky", "##hawk", "Initially", "flying", "the", "A", "##-", "##4", "##B", "Sky", "##hawk", "later", "[unused6]", "[SEP]"]]}

input 172:  {"source": "Initially his chances of surviving were thought to be no better than 50-50 .\n"}
prediction:  {"predictions": [[1, 1117, 9820, 1104, 5932, 2, 3, 1106, 1129, 4, 5, 1185, 1618, 1190, 1851, 28137, 11049, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017082609236240387, -0.12711238861083984, -0.1147761344909668, -0.1147761344909668, -0.1147761344909668, -0.1147761344909668, -0.1147761344909668, -0.1147761344909668, -0.1147761344909668, -0.1147761344909668], "metadata": {"source_tokens": ["Initially", "his", "chances", "of", "surviving", "were", "thought", "to", "be", "no", "better", "than", "50", "##-", "##50", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "his", "chances", "of", "surviving", "[unused2]", "[unused3]", "to", "be", "[unused4]", "[unused5]", "no", "better", "than", "50", "##-", "##50", "[unused6]", "[SEP]"]]}

input 173:  {"source": "It has long hind legs and a long , slender , scaly tail that it uses to communicate by making drumming noises .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1144, 4, 5, 1263, 24856, 2584, 1105, 170, 1263, 117, 11226, 117, 188, 7867, 1183, 5287, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1263, 117, 11226, 117, 188, 7867, 1183, 5287, 2, 3, 2745, 4, 5, 1122, 2745, 1106, 10621, 1118, 1543, 27025, 16256, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012622199021279812, -0.11538457870483398, -0.08860111236572266, -0.087188720703125, -0.087188720703125, -0.087188720703125, -0.087188720703125, -0.087188720703125, -0.087188720703125, -0.087188720703125], "metadata": {"source_tokens": ["It", "has", "long", "hind", "legs", "and", "a", "long", ",", "slender", ",", "s", "##cal", "##y", "tail", "that", "it", "uses", "to", "communicate", "by", "making", "drumming", "noises", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "long", "hind", "legs", "and", "a", "long", ",", "slender", ",", "s", "##cal", "##y", "tail", "[unused6]", "[SEP]", "[unused1]", "a", "long", ",", "slender", ",", "s", "##cal", "##y", "tail", "[unused2]", "[unused3]", "uses", "[unused4]", "[unused5]", "it", "uses", "to", "communicate", "by", "making", "drumming", "noises", "[unused6]", "[SEP]"]]}

input 174:  {"source": "It is essentially the same as the dialect spoken in Xiamen , and is unintelligible with Standard Chinese .\n"}
prediction:  {"predictions": [[1, 1103, 9222, 2, 3, 4606, 4, 5, 1107, 20802, 16470, 1179, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1110, 4, 5, 7588, 1103, 1269, 1112, 1103, 9222, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1110, 4, 5, 8362, 10879, 12164, 12192, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02245325781404972, -0.11716918647289276, -0.058434441685676575, -0.3372025489807129, -0.3415679931640625, -0.3415675163269043, -0.3415679931640625, -0.3415679931640625, -0.3415679931640625, -0.3415679931640625], "metadata": {"source_tokens": ["It", "is", "essentially", "the", "same", "as", "the", "dialect", "spoken", "in", "Xi", "##ame", "##n", ",", "and", "is", "un", "##int", "##elli", "##gible", "with", "Standard", "Chinese", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "dialect", "[unused2]", "[unused3]", "spoken", "[unused4]", "[unused5]", "in", "Xi", "##ame", "##n", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "essentially", "the", "same", "as", "the", "dialect", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "un", "##int", "##elli", "##gible", "[unused6]", "[SEP]"]]}

input 175:  {"source": "It is not really passable , and must be done on foot if attempted .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1110, 1136, 4, 5, 1541, 2789, 1895, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1538, 1129, 1694, 4, 5, 1113, 2555, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02495231106877327, -0.06922073662281036, -0.04467344284057617, -0.0443572998046875, -0.0443572998046875, -0.0443572998046875, -0.0443572998046875, -0.0443572998046875, -0.0443572998046875, -0.0443572998046875], "metadata": {"source_tokens": ["It", "is", "not", "really", "pass", "##able", ",", "and", "must", "be", "done", "on", "foot", "if", "attempted", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "is", "not", "[unused4]", "[unused5]", "really", "pass", "##able", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "must", "be", "done", "[unused4]", "[unused5]", "on", "foot", "[unused6]", "[SEP]"]]}

input 176:  {"source": "It is part of the Surrey Hills Area of Outstanding Beauty and situated on the Green Sand Way .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1110, 4, 5, 1226, 1104, 1103, 9757, 5377, 3894, 1104, 7196, 10764, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 3629, 4, 5, 1113, 1103, 2565, 16377, 4714, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0025344688910990953, -0.06408442556858063, -0.009457111358642578, -0.010027885437011719, -0.010027885437011719, -0.010027885437011719, -0.010027885437011719, -0.010027885437011719, -0.010027885437011719, -0.010027885437011719], "metadata": {"source_tokens": ["It", "is", "part", "of", "the", "Surrey", "Hills", "Area", "of", "Outstanding", "Beauty", "and", "situated", "on", "the", "Green", "Sand", "Way", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "part", "of", "the", "Surrey", "Hills", "Area", "of", "Outstanding", "Beauty", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "situated", "[unused4]", "[unused5]", "on", "the", "Green", "Sand", "Way", "[unused6]", "[SEP]"]]}

input 177:  {"source": "It should be noted that these numbers are inclusive of any of the childminders own children .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1431, 1129, 2382, 4, 5, 1115, 1292, 2849, 1132, 21783, 1104, 1251, 1104, 1103, 2027, 22448, 1468, 1319, 1482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1292, 2849, 2, 3, 1132, 4, 5, 21783, 1104, 1251, 1104, 1103, 2027, 22448, 1468, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00032283307518810034, -0.30143070220947266, -0.04401479288935661, -0.036646366119384766, -0.03951883316040039, -0.03951883316040039, -0.03951883316040039, -0.03951883316040039, -0.03951883316040039, -0.03951883316040039], "metadata": {"source_tokens": ["It", "should", "be", "noted", "that", "these", "numbers", "are", "inclusive", "of", "any", "of", "the", "child", "##mind", "##ers", "own", "children", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "should", "be", "noted", "[unused4]", "[unused5]", "that", "these", "numbers", "are", "inclusive", "of", "any", "of", "the", "child", "##mind", "##ers", "own", "children", "[unused6]", "[SEP]"]]}

input 178:  {"source": "It was chosen in 1901 because it was a triangulation station at the junction of the trancontinental triangulation arc of 1899 on the 39th parallel north and the triangulation arc along the 98th meridian west that was near the geographic center of the contiguous United States .\n"}
prediction:  {"predictions": [[1, 1103, 5103, 1582, 1143, 10132, 1811, 1745, 2, 3, 1108, 4, 5, 1485, 1103, 13351, 2057, 1104, 1103, 14255, 3121, 22928, 1244, 1311, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1108, 3468, 4, 5, 1107, 5064, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1108, 3468, 4, 5, 1107, 5064, 1272, 1122, 1108, 170, 189, 5476, 13830, 6840, 1466, 1120, 1103, 6698, 1104, 1103, 189, 4047, 25442, 1348, 189, 5476, 13830, 6840, 10591, 6, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 170, 189, 5476, 13830, 6840, 1466, 1120, 1103, 6698, 1104, 1103, 189, 4047, 25442, 1348, 189, 5476, 13830, 6840, 10591, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 170, 189, 5476, 13830, 6840, 1466, 1120, 1103, 6698, 1104, 1103, 189, 4047, 25442, 1348, 189, 5476, 13830, 6840, 10591, 6, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008491959422826767, -0.1037924587726593, -0.0737006887793541, -0.04539524018764496, -0.08870743215084076, -0.10767078399658203, -0.10847282409667969, -0.10847282409667969, -0.10847282409667969, -0.10847282409667969], "metadata": {"source_tokens": ["It", "was", "chosen", "in", "1901", "because", "it", "was", "a", "t", "##rian", "##gu", "##lation", "station", "at", "the", "junction", "of", "the", "t", "##ran", "##continent", "##al", "t", "##rian", "##gu", "##lation", "arc", "of", "1899", "on", "the", "39th", "parallel", "north", "and", "the", "t", "##rian", "##gu", "##lation", "arc", "along", "the", "98", "##th", "me", "##rid", "##ian", "west", "that", "was", "near", "the", "geographic", "center", "of", "the", "con", "##ti", "##guous", "United", "States", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "98", "##th", "me", "##rid", "##ian", "west", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "near", "the", "geographic", "center", "of", "the", "con", "##ti", "##guous", "United", "States", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "was", "chosen", "[unused4]", "[unused5]", "in", "1901", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "was", "chosen", "[unused4]", "[unused5]", "in", "1901", "because", "it", "was", "a", "t", "##rian", "##gu", "##lation", "station", "at", "the", "junction", "of", "the", "t", "##ran", "##continent", "##al", "t", "##rian", "##gu", "##lation", "arc", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "t", "##rian", "##gu", "##lation", "station", "at", "the", "junction", "of", "the", "t", "##ran", "##continent", "##al", "t", "##rian", "##gu", "##lation", "arc", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "t", "##rian", "##gu", "##lation", "station", "at", "the", "junction", "of", "the", "t", "##ran", "##continent", "##al", "t", "##rian", "##gu", "##lation", "arc", "[unused6]", "[SEP]"]]}

input 179:  {"source": "It was named for Gen. Eleazer Wheelock Ripley , an officer in the War of 1812 , who was mainly remembered for the Battle of Lundy 's Lane and the Siege of Fort Erie , in 1814 .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1108, 1417, 4, 5, 1111, 9198, 28138, 2896, 4490, 6198, 19754, 5559, 155, 9717, 1926, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9198, 28138, 2896, 4490, 6198, 19754, 5559, 155, 9717, 1926, 2, 3, 1110, 4, 5, 1126, 2575, 1107, 1103, 1414, 1104, 9601, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9198, 28138, 2896, 4490, 6198, 19754, 5559, 155, 9717, 1926, 2, 3, 1129, 1150, 1108, 2871, 3801, 4, 5, 1111, 1103, 2651, 1104, 24232, 1183, 112, 1116, 5319, 1105, 1103, 14214, 1104, 3144, 13717, 1107, 10943, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.015838129445910454, -0.0320550836622715, -0.09647054970264435, -0.07019567489624023, -0.0686650276184082, -0.0686650276184082, -0.0686655044555664, -0.0686655044555664, -0.0686650276184082, -0.0686650276184082], "metadata": {"source_tokens": ["It", "was", "named", "for", "Gen", "##.", "El", "##ea", "##zer", "Wheel", "##ock", "R", "##ip", "##ley", ",", "an", "officer", "in", "the", "War", "of", "1812", ",", "who", "was", "mainly", "remembered", "for", "the", "Battle", "of", "Lund", "##y", "'", "##s", "Lane", "and", "the", "Siege", "of", "Fort", "Erie", ",", "in", "1814", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "was", "named", "[unused4]", "[unused5]", "for", "Gen", "##.", "El", "##ea", "##zer", "Wheel", "##ock", "R", "##ip", "##ley", "[unused6]", "[SEP]", "[unused1]", "Gen", "##.", "El", "##ea", "##zer", "Wheel", "##ock", "R", "##ip", "##ley", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "officer", "in", "the", "War", "of", "1812", "[unused6]", "[SEP]", "[unused1]", "Gen", "##.", "El", "##ea", "##zer", "Wheel", "##ock", "R", "##ip", "##ley", "[unused2]", "[unused3]", "be", "who", "was", "mainly", "remembered", "[unused4]", "[unused5]", "for", "the", "Battle", "of", "Lund", "##y", "'", "##s", "Lane", "and", "the", "Siege", "of", "Fort", "Erie", "in", "1814", "[unused6]", "[SEP]"]]}

input 180:  {"source": "It was originally aimed at mature entrants to the teaching profession , who could not afford to give up work and undertake a traditional method of teacher training such as the PGCE .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1108, 5850, 4, 5, 1120, 9881, 4035, 4487, 5240, 1106, 1103, 3679, 9545, 2034, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3679, 9545, 2, 3, 1180, 1136, 8658, 4, 5, 1106, 1660, 1146, 1250, 1105, 17778, 170, 2361, 3442, 1104, 3218, 2013, 1216, 1112, 1103, 153, 13478, 2036, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03337924927473068, -0.024597983807325363, -0.0644989013671875, -0.06382083892822266, -0.06382083892822266, -0.06382083892822266, -0.06382083892822266, -0.06382083892822266, -0.06382083892822266, -0.06382083892822266], "metadata": {"source_tokens": ["It", "was", "originally", "aimed", "at", "mature", "en", "##tra", "##nts", "to", "the", "teaching", "profession", ",", "who", "could", "not", "afford", "to", "give", "up", "work", "and", "undertake", "a", "traditional", "method", "of", "teacher", "training", "such", "as", "the", "P", "##GC", "##E", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "was", "aimed", "[unused4]", "[unused5]", "at", "mature", "en", "##tra", "##nts", "to", "the", "teaching", "profession", "originally", "[unused6]", "[SEP]", "[unused1]", "the", "teaching", "profession", "[unused2]", "[unused3]", "could", "not", "afford", "[unused4]", "[unused5]", "to", "give", "up", "work", "and", "undertake", "a", "traditional", "method", "of", "teacher", "training", "such", "as", "the", "P", "##GC", "##E", "[unused6]", "[SEP]"]]}

input 181:  {"source": "Its cultivation even declined in favour of the Asian species , which was introduced to East Africa early in the common era and spread westward .\n"}
prediction:  {"predictions": [[1, 2098, 13958, 2, 3, 1256, 5799, 4, 5, 1107, 7511, 1104, 1103, 3141, 1530, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3141, 1530, 2, 3, 1108, 2234, 4, 5, 1106, 1689, 2201, 1346, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3141, 1530, 2, 3, 1108, 2234, 4, 5, 1106, 1689, 2201, 1346, 1107, 1103, 1887, 3386, 1105, 2819, 17222, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.039159249514341354, -0.04974539577960968, -0.09815337508916855, -0.045468807220458984, -0.05463600158691406, -0.05463600158691406, -0.05463600158691406, -0.05463600158691406, -0.05463600158691406, -0.05463600158691406], "metadata": {"source_tokens": ["Its", "cultivation", "even", "declined", "in", "favour", "of", "the", "Asian", "species", ",", "which", "was", "introduced", "to", "East", "Africa", "early", "in", "the", "common", "era", "and", "spread", "westward", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Its", "cultivation", "[unused2]", "[unused3]", "even", "declined", "[unused4]", "[unused5]", "in", "favour", "of", "the", "Asian", "species", "[unused6]", "[SEP]", "[unused1]", "the", "Asian", "species", "[unused2]", "[unused3]", "was", "introduced", "[unused4]", "[unused5]", "to", "East", "Africa", "early", "[unused6]", "[SEP]", "[unused1]", "the", "Asian", "species", "[unused2]", "[unused3]", "was", "introduced", "[unused4]", "[unused5]", "to", "East", "Africa", "early", "in", "the", "common", "era", "and", "spread", "westward", "[unused6]", "[SEP]"]]}

input 182:  {"source": "JAL introduced jet service on the Fukuoka-Tokyo route in 1961 .\n"}
prediction:  {"predictions": [[1, 147, 12507, 2, 3, 2234, 4, 5, 8319, 1555, 1113, 1103, 14763, 4786, 9865, 28137, 1942, 5926, 7490, 2438, 1107, 2920, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-6.500879680970684e-05, -0.02520132064819336, -0.02350902557373047, -0.02350902557373047, -0.02350902557373047, -0.02350902557373047, -0.02350902557373047, -0.02350902557373047, -0.02350902557373047, -0.02350902557373047], "metadata": {"source_tokens": ["J", "##AL", "introduced", "jet", "service", "on", "the", "Fu", "##ku", "##oka", "##-", "##T", "##ok", "##yo", "route", "in", "1961", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "J", "##AL", "[unused2]", "[unused3]", "introduced", "[unused4]", "[unused5]", "jet", "service", "on", "the", "Fu", "##ku", "##oka", "##-", "##T", "##ok", "##yo", "route", "in", "1961", "[unused6]", "[SEP]"]]}

input 183:  {"source": "James Arthur Hogue is a US impostor who most famously entered Princeton University by posing as a self-taught orphan .\n"}
prediction:  {"predictions": [[1, 1600, 3456, 9800, 7222, 2, 3, 1110, 4, 5, 170, 1646, 24034, 15540, 1766, 1150, 1211, 20025, 2242, 8845, 1239, 1118, 23614, 1112, 170, 2191, 28137, 1777, 11266, 25298, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1646, 24034, 15540, 1766, 2, 3, 1211, 20025, 2242, 4, 5, 8845, 1239, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.020860489457845688, -0.05383838713169098, -0.0722036361694336, -0.08174848556518555, -0.08174848556518555, -0.08174848556518555, -0.08174848556518555, -0.08174848556518555, -0.08174848556518555, -0.08174848556518555], "metadata": {"source_tokens": ["James", "Arthur", "Ho", "##gue", "is", "a", "US", "imp", "##ost", "##or", "who", "most", "famously", "entered", "Princeton", "University", "by", "posing", "as", "a", "self", "##-", "##ta", "##ught", "orphan", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "James", "Arthur", "Ho", "##gue", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "US", "imp", "##ost", "##or", "who", "most", "famously", "entered", "Princeton", "University", "by", "posing", "as", "a", "self", "##-", "##ta", "##ught", "orphan", "[unused6]", "[SEP]", "[unused1]", "a", "US", "imp", "##ost", "##or", "[unused2]", "[unused3]", "most", "famously", "entered", "[unused4]", "[unused5]", "Princeton", "University", "[unused6]", "[SEP]"]]}

input 184:  {"source": "John Stewart and Guy Gardner brought down New Warworld and the Yellow Central Power Battery , which were detonated next to the Anti-Monitor , and contained by a shield created by hundreds of Green Lanterns to contain the explosion ; even this was not enough to kill him .\n"}
prediction:  {"predictions": [[1, 1287, 5272, 1105, 6173, 11817, 2, 3, 1814, 1205, 4, 5, 1203, 1414, 13070, 1105, 1103, 8278, 1970, 3794, 11537, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 8278, 1970, 3794, 11537, 2, 3, 1127, 1260, 1633, 2913, 4, 5, 1397, 1106, 1103, 8329, 28137, 2107, 11153, 2772, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1256, 1142, 2, 3, 1108, 1136, 4, 5, 1536, 1106, 2311, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 7292, 2, 3, 1129, 1687, 4, 5, 1118, 5229, 1104, 2565, 23999, 1116, 1106, 4651, 1103, 7552, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0447392575442791, -0.07711364328861237, -0.08415215462446213, -0.09409821033477783, -0.11492490768432617, -0.12194967269897461, -0.12195014953613281, -0.12194967269897461, -0.12194967269897461, -0.12194967269897461], "metadata": {"source_tokens": ["John", "Stewart", "and", "Guy", "Gardner", "brought", "down", "New", "War", "##world", "and", "the", "Yellow", "Central", "Power", "Battery", ",", "which", "were", "de", "##ton", "##ated", "next", "to", "the", "Anti", "##-", "##M", "##oni", "##tor", ",", "and", "contained", "by", "a", "shield", "created", "by", "hundreds", "of", "Green", "Lantern", "##s", "to", "contain", "the", "explosion", ";", "even", "this", "was", "not", "enough", "to", "kill", "him", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "John", "Stewart", "and", "Guy", "Gardner", "[unused2]", "[unused3]", "brought", "down", "[unused4]", "[unused5]", "New", "War", "##world", "and", "the", "Yellow", "Central", "Power", "Battery", "[unused6]", "[SEP]", "[unused1]", "the", "Yellow", "Central", "Power", "Battery", "[unused2]", "[unused3]", "were", "de", "##ton", "##ated", "[unused4]", "[unused5]", "next", "to", "the", "Anti", "##-", "##M", "##oni", "##tor", "[unused6]", "[SEP]", "[unused1]", "even", "this", "[unused2]", "[unused3]", "was", "not", "[unused4]", "[unused5]", "enough", "to", "kill", "him", "[unused6]", "[SEP]", "[unused1]", "a", "shield", "[unused2]", "[unused3]", "be", "created", "[unused4]", "[unused5]", "by", "hundreds", "of", "Green", "Lantern", "##s", "to", "contain", "the", "explosion", "[unused6]", "[SEP]"]]}

input 185:  {"source": "Johns also appeared as an Imperial Officer in the 1980 `` Star Wars sequel '' , `` The Empire Strikes Back '' .\n"}
prediction:  {"predictions": [[1, 11673, 2, 3, 1691, 4, 5, 1112, 1126, 4849, 4124, 1107, 1103, 2253, 169, 28152, 2537, 6238, 8047, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2813, 2, 3, 15425, 1116, 4, 5, 4388, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01904875412583351, -0.05226945877075195, -0.042049407958984375, -0.04266548156738281, -0.04266548156738281, -0.04266548156738281, -0.04266548156738281, -0.04266548156738281, -0.04266548156738281, -0.04266548156738281], "metadata": {"source_tokens": ["Johns", "also", "appeared", "as", "an", "Imperial", "Officer", "in", "the", "1980", "`", "##`", "Star", "Wars", "sequel", "'", "##'", ",", "`", "##`", "The", "Empire", "Strike", "##s", "Back", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Johns", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "as", "an", "Imperial", "Officer", "in", "the", "1980", "`", "##`", "Star", "Wars", "sequel", "[unused6]", "[SEP]", "[unused1]", "The", "Empire", "[unused2]", "[unused3]", "Strike", "##s", "[unused4]", "[unused5]", "Back", "[unused6]", "[SEP]"]]}

input 186:  {"source": "Keats 's long and expensive medical training with Hammond and at Guy 's Hospital led his family to assume he would pursue a lifelong career in medicine , assuring financial security , and it seems that at this point Keats had a genuine desire to become a doctor .\n"}
prediction:  {"predictions": [[1, 26835, 9971, 112, 1116, 1263, 1105, 5865, 2657, 2013, 1114, 11425, 1105, 1120, 6173, 112, 1116, 3355, 2, 3, 1521, 4, 5, 1117, 1266, 1106, 7568, 1119, 1156, 6799, 170, 14497, 1578, 1107, 5182, 117, 3919, 6660, 2798, 2699, 117, 1105, 1122, 3093, 1115, 1120, 1142, 1553, 26835, 9971, 102, 1, 1117, 1266, 2, 3, 1106, 7568, 4, 5, 1119, 1156, 6799, 170, 14497, 1578, 1107, 5182, 3919, 6660, 2798, 2699, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 9971, 2, 3, 1125, 4, 5, 170, 10416, 4232, 1106, 1561, 170, 3995, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023501133546233177, -0.0686381608247757, -0.05545319616794586, -0.32602453231811523, -0.3177328109741211, -0.3177328109741211, -0.3177328109741211, -0.3177328109741211, -0.3177328109741211, -0.3177328109741211], "metadata": {"source_tokens": ["Ke", "##ats", "'", "##s", "long", "and", "expensive", "medical", "training", "with", "Hammond", "and", "at", "Guy", "'", "##s", "Hospital", "led", "his", "family", "to", "assume", "he", "would", "pursue", "a", "lifelong", "career", "in", "medicine", ",", "ass", "##uring", "financial", "security", ",", "and", "it", "seems", "that", "at", "this", "point", "Ke", "##ats", "had", "a", "genuine", "desire", "to", "become", "a", "doctor", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ke", "##ats", "'", "##s", "long", "and", "expensive", "medical", "training", "with", "Hammond", "and", "at", "Guy", "'", "##s", "Hospital", "[unused2]", "[unused3]", "led", "[unused4]", "[unused5]", "his", "family", "to", "assume", "he", "would", "pursue", "a", "lifelong", "career", "in", "medicine", ",", "ass", "##uring", "financial", "security", ",", "and", "it", "seems", "that", "at", "this", "point", "Ke", "##ats", "[SEP]", "[unused1]", "his", "family", "[unused2]", "[unused3]", "to", "assume", "[unused4]", "[unused5]", "he", "would", "pursue", "a", "lifelong", "career", "in", "medicine", "ass", "##uring", "financial", "security", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ats", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "genuine", "desire", "to", "become", "a", "doctor", "[unused6]", "[SEP]"]]}

input 187:  {"source": "Keibler then asked for time off to appear on `` Dancing with the Stars '' .\n"}
prediction:  {"predictions": [[1, 26835, 5225, 1197, 2, 3, 1455, 4, 5, 1111, 1159, 1228, 1106, 2845, 1113, 169, 28152, 13234, 1114, 1103, 6200, 1173, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008394320495426655, -0.06774616241455078, -0.07713794708251953, -0.07713794708251953, -0.07713794708251953, -0.07713794708251953, -0.07713794708251953, -0.07713794708251953, -0.07713794708251953, -0.07713794708251953], "metadata": {"source_tokens": ["Ke", "##ible", "##r", "then", "asked", "for", "time", "off", "to", "appear", "on", "`", "##`", "Dancing", "with", "the", "Stars", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ke", "##ible", "##r", "[unused2]", "[unused3]", "asked", "[unused4]", "[unused5]", "for", "time", "off", "to", "appear", "on", "`", "##`", "Dancing", "with", "the", "Stars", "then", "[unused6]", "[SEP]"]]}

input 188:  {"source": "Kim graduated from Ballard High School in Louisville , Kentucky , in 1989 and from Oberlin College in Ohio in 1993 where he double-majored in Government and English and played for the varsity lacrosse team .\n"}
prediction:  {"predictions": [[1, 4246, 2, 3, 3024, 4, 5, 1121, 24241, 1693, 1323, 1107, 11595, 1107, 2056, 1105, 1121, 152, 3169, 2836, 1531, 1107, 3197, 1107, 1949, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1307, 4, 5, 1111, 1103, 17611, 21135, 1264, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 2702, 28137, 1918, 5077, 4359, 4, 5, 1107, 2384, 1105, 1483, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04550914466381073, -0.016190936788916588, -0.01912195235490799, -0.1213846206665039, -0.11497974395751953, -0.11497974395751953, -0.11497974395751953, -0.11497974395751953, -0.11497974395751953, -0.11497974395751953], "metadata": {"source_tokens": ["Kim", "graduated", "from", "Ballard", "High", "School", "in", "Louisville", ",", "Kentucky", ",", "in", "1989", "and", "from", "O", "##ber", "##lin", "College", "in", "Ohio", "in", "1993", "where", "he", "double", "##-", "##ma", "##jo", "##red", "in", "Government", "and", "English", "and", "played", "for", "the", "varsity", "lacrosse", "team", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Kim", "[unused2]", "[unused3]", "graduated", "[unused4]", "[unused5]", "from", "Ballard", "High", "School", "in", "Louisville", "in", "1989", "and", "from", "O", "##ber", "##lin", "College", "in", "Ohio", "in", "1993", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "for", "the", "varsity", "lacrosse", "team", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "double", "##-", "##ma", "##jo", "##red", "[unused4]", "[unused5]", "in", "Government", "and", "English", "[unused6]", "[SEP]"]]}

input 189:  {"source": "Kostabi 's other releases include : `` Songs For Sumera '' , `` New Alliance '' and `` The Spectre Of Modernism '' .\n"}
prediction:  {"predictions": [[1, 19892, 8419, 5567, 112, 1116, 1168, 6596, 2, 3, 1511, 4, 5, 6080, 1370, 15463, 4027, 1161, 112, 28131, 117, 169, 28152, 1203, 5643, 112, 28131, 1105, 169, 28152, 1109, 156, 26426, 1874, 2096, 4825, 1863, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01110471785068512, -0.02425670623779297, -0.023946285247802734, -0.023946285247802734, -0.023946285247802734, -0.023946285247802734, -0.023946285247802734, -0.023946285247802734, -0.023946285247802734, -0.023946285247802734], "metadata": {"source_tokens": ["Ko", "##sta", "##bi", "'", "##s", "other", "releases", "include", ":", "`", "##`", "Songs", "For", "Su", "##mer", "##a", "'", "##'", ",", "`", "##`", "New", "Alliance", "'", "##'", "and", "`", "##`", "The", "S", "##pect", "##re", "Of", "Modern", "##ism", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ko", "##sta", "##bi", "'", "##s", "other", "releases", "[unused2]", "[unused3]", "include", "[unused4]", "[unused5]", "Songs", "For", "Su", "##mer", "##a", "'", "##'", ",", "`", "##`", "New", "Alliance", "'", "##'", "and", "`", "##`", "The", "S", "##pect", "##re", "Of", "Modern", "##ism", "[unused6]", "[SEP]"]]}

input 190:  {"source": "Langford kept Walcott at a distance with his longer reach and used his footwork to evade all of Walcott 's attacks .\n"}
prediction:  {"predictions": [[1, 12431, 2821, 2, 3, 1215, 4, 5, 1117, 2555, 5361, 1106, 174, 27923, 1155, 1104, 160, 1348, 11627, 112, 1116, 3690, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12431, 2821, 2, 3, 2023, 4, 5, 160, 1348, 11627, 1120, 170, 2462, 1114, 1117, 2039, 2519, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02777266502380371, -0.015843674540519714, -0.07337713241577148, -0.07197856903076172, -0.07197856903076172, -0.07197856903076172, -0.07197856903076172, -0.07197856903076172, -0.07197856903076172, -0.07197856903076172], "metadata": {"source_tokens": ["Lang", "##ford", "kept", "W", "##al", "##cott", "at", "a", "distance", "with", "his", "longer", "reach", "and", "used", "his", "foot", "##work", "to", "e", "##vade", "all", "of", "W", "##al", "##cott", "'", "##s", "attacks", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Lang", "##ford", "[unused2]", "[unused3]", "used", "[unused4]", "[unused5]", "his", "foot", "##work", "to", "e", "##vade", "all", "of", "W", "##al", "##cott", "'", "##s", "attacks", "[unused6]", "[SEP]", "[unused1]", "Lang", "##ford", "[unused2]", "[unused3]", "kept", "[unused4]", "[unused5]", "W", "##al", "##cott", "at", "a", "distance", "with", "his", "longer", "reach", "[unused6]", "[SEP]"]]}

input 191:  {"source": "Language B then begins to supplant language A : the speakers of Language A abandon their own language in favor of the other language , generally because they believe that it will help them achieve certain goals within government , the workplace , and in social settings .\n"}
prediction:  {"predictions": [[1, 6828, 139, 2, 3, 3471, 4, 5, 1106, 28117, 8661, 9180, 1846, 138, 1173, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 7417, 1104, 6828, 138, 2, 3, 11092, 4, 5, 1147, 1319, 1846, 1107, 5010, 1104, 1103, 1168, 1846, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 2059, 4, 5, 1115, 1122, 1209, 1494, 1172, 5515, 2218, 2513, 1439, 1433, 117, 1103, 19328, 117, 1105, 1107, 1934, 11106, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06475798040628433, -0.03627723827958107, -0.05956120789051056, -0.07631969451904297, -0.07483482360839844, -0.07483482360839844, -0.07483482360839844, -0.07483482360839844, -0.07483482360839844, -0.07483482360839844], "metadata": {"source_tokens": ["Language", "B", "then", "begins", "to", "su", "##pp", "##lant", "language", "A", ":", "the", "speakers", "of", "Language", "A", "abandon", "their", "own", "language", "in", "favor", "of", "the", "other", "language", ",", "generally", "because", "they", "believe", "that", "it", "will", "help", "them", "achieve", "certain", "goals", "within", "government", ",", "the", "workplace", ",", "and", "in", "social", "settings", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Language", "B", "[unused2]", "[unused3]", "begins", "[unused4]", "[unused5]", "to", "su", "##pp", "##lant", "language", "A", "then", "[unused6]", "[SEP]", "[unused1]", "the", "speakers", "of", "Language", "A", "[unused2]", "[unused3]", "abandon", "[unused4]", "[unused5]", "their", "own", "language", "in", "favor", "of", "the", "other", "language", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "believe", "[unused4]", "[unused5]", "that", "it", "will", "help", "them", "achieve", "certain", "goals", "within", "government", ",", "the", "workplace", ",", "and", "in", "social", "settings", "[unused6]", "[SEP]"]]}

input 192:  {"source": "Lemmy believes that if Will Reid Dick had not been there , they could have worked through the problems , but ended up exchanging a few words and Clarke left the studio .\n"}
prediction:  {"predictions": [[1, 3180, 16211, 2, 3, 6616, 4, 5, 1115, 1191, 3100, 8721, 6416, 1125, 1136, 1151, 1175, 117, 1152, 1180, 1138, 1589, 1194, 1103, 2645, 117, 1133, 2207, 1146, 4252, 23286, 170, 1374, 1734, 1105, 7949, 1286, 1103, 2362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1180, 1138, 1589, 4, 5, 1194, 1103, 2645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.002185135381296277, -0.07170788198709488, -0.08161163330078125, -0.0798196792602539, -0.0798196792602539, -0.0798196792602539, -0.0798196792602539, -0.0798196792602539, -0.0798196792602539, -0.0798196792602539], "metadata": {"source_tokens": ["Le", "##mmy", "believes", "that", "if", "Will", "Reid", "Dick", "had", "not", "been", "there", ",", "they", "could", "have", "worked", "through", "the", "problems", ",", "but", "ended", "up", "ex", "##changing", "a", "few", "words", "and", "Clarke", "left", "the", "studio", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Le", "##mmy", "[unused2]", "[unused3]", "believes", "[unused4]", "[unused5]", "that", "if", "Will", "Reid", "Dick", "had", "not", "been", "there", ",", "they", "could", "have", "worked", "through", "the", "problems", ",", "but", "ended", "up", "ex", "##changing", "a", "few", "words", "and", "Clarke", "left", "the", "studio", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "could", "have", "worked", "[unused4]", "[unused5]", "through", "the", "problems", "[unused6]", "[SEP]"]]}

input 193:  {"source": "Lens subluxation is also seen in dogs and is characterized by a partial displacement of the lens .\n"}
prediction:  {"predictions": [[1, 22824, 1116, 4841, 24796, 1891, 2, 3, 1110, 1145, 1562, 4, 5, 1107, 6363, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 22824, 1116, 4841, 24796, 1891, 2, 3, 1110, 6858, 4, 5, 1118, 170, 7597, 15167, 1104, 1103, 11039, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.039456747472286224, -0.034199170768260956, -0.009868621826171875, -0.009647369384765625, -0.009647369384765625, -0.009647369384765625, -0.009647369384765625, -0.009647369384765625, -0.009647369384765625, -0.009647369384765625], "metadata": {"source_tokens": ["Len", "##s", "sub", "##lux", "##ation", "is", "also", "seen", "in", "dogs", "and", "is", "characterized", "by", "a", "partial", "displacement", "of", "the", "lens", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Len", "##s", "sub", "##lux", "##ation", "[unused2]", "[unused3]", "is", "also", "seen", "[unused4]", "[unused5]", "in", "dogs", "[unused6]", "[SEP]", "[unused1]", "Len", "##s", "sub", "##lux", "##ation", "[unused2]", "[unused3]", "is", "characterized", "[unused4]", "[unused5]", "by", "a", "partial", "displacement", "of", "the", "lens", "[unused6]", "[SEP]"]]}

input 194:  {"source": "Li Hongzhi began his public teachings of Falun Gong on 13 May 1992 in Changchun , and subsequently gave lectures and taught Falun Gong exercises across China .\n"}
prediction:  {"predictions": [[1, 5255, 3475, 23239, 2, 3, 1310, 4, 5, 1117, 1470, 12815, 1104, 143, 1348, 3488, 23703, 1113, 1492, 1318, 1924, 1107, 11497, 17143, 1179, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5255, 3475, 23239, 2, 3, 1522, 4, 5, 9548, 1105, 3188, 143, 1348, 3488, 23703, 11536, 1506, 1975, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005662277806550264, -0.0975768193602562, -0.10127496719360352, -0.09923458099365234, -0.09923458099365234, -0.09923458099365234, -0.09923458099365234, -0.09923458099365234, -0.09923458099365234, -0.09923458099365234], "metadata": {"source_tokens": ["Li", "Hong", "##zhi", "began", "his", "public", "teachings", "of", "F", "##al", "##un", "Gong", "on", "13", "May", "1992", "in", "Chang", "##chu", "##n", ",", "and", "subsequently", "gave", "lectures", "and", "taught", "F", "##al", "##un", "Gong", "exercises", "across", "China", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Li", "Hong", "##zhi", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "his", "public", "teachings", "of", "F", "##al", "##un", "Gong", "on", "13", "May", "1992", "in", "Chang", "##chu", "##n", "[unused6]", "[SEP]", "[unused1]", "Li", "Hong", "##zhi", "[unused2]", "[unused3]", "gave", "[unused4]", "[unused5]", "lectures", "and", "taught", "F", "##al", "##un", "Gong", "exercises", "across", "China", "[unused6]", "[SEP]"]]}

input 195:  {"source": "Like other BBC content of the mid-1990s , it often lampooned the low-budget quality of satellite television available in the UK at the time .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 11140, 6931, 1174, 4, 5, 1103, 1822, 28137, 7925, 8484, 1204, 3068, 1104, 5989, 1778, 1907, 1107, 1103, 1993, 1120, 1103, 1159, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005554462783038616, -0.25960874557495117, -0.20293521881103516, -0.20293521881103516, -0.20293521881103516, -0.20293521881103516, -0.20293521881103516, -0.20293521881103516, -0.20293521881103516, -0.20293521881103516], "metadata": {"source_tokens": ["Like", "other", "BBC", "content", "of", "the", "mid", "##-", "##19", "##90", "##s", ",", "it", "often", "lamp", "##oon", "##ed", "the", "low", "##-", "##bu", "##dge", "##t", "quality", "of", "satellite", "television", "available", "in", "the", "UK", "at", "the", "time", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "lamp", "##oon", "##ed", "[unused4]", "[unused5]", "the", "low", "##-", "##bu", "##dge", "##t", "quality", "of", "satellite", "television", "available", "in", "the", "UK", "at", "the", "time", "often", "[unused6]", "[SEP]"]]}

input 196:  {"source": "Luke Robert Ravenstahl is an American politician who served as the 59th Mayor of Pittsburgh from 2006 until 2014 .\n"}
prediction:  {"predictions": [[1, 4599, 1823, 21848, 24401, 1233, 2, 3, 1110, 4, 5, 1126, 1237, 2931, 1150, 1462, 1112, 1103, 4589, 1582, 4643, 1104, 5610, 1121, 1386, 1235, 1387, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00032379297772422433, -0.05713939666748047, -0.054795265197753906, -0.054795265197753906, -0.054795265197753906, -0.054795265197753906, -0.054795265197753906, -0.054795265197753906, -0.054795265197753906, -0.054795265197753906], "metadata": {"source_tokens": ["Luke", "Robert", "Ravens", "##tah", "##l", "is", "an", "American", "politician", "who", "served", "as", "the", "59", "##th", "Mayor", "of", "Pittsburgh", "from", "2006", "until", "2014", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Luke", "Robert", "Ravens", "##tah", "##l", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "American", "politician", "who", "served", "as", "the", "59", "##th", "Mayor", "of", "Pittsburgh", "from", "2006", "until", "2014", "[unused6]", "[SEP]"]]}

input 197:  {"source": "Males had a median income of $ 28,750 versus $ 16,250 for females .\n"}
prediction:  {"predictions": [[1, 7689, 2, 3, 1125, 4, 5, 170, 3151, 2467, 1104, 109, 1743, 28136, 26253, 1568, 6055, 109, 1479, 28136, 17600, 1568, 1111, 3032, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-1.742748099786695e-05, -0.043166160583496094, -0.03888416290283203, -0.03888416290283203, -0.03888416290283203, -0.03888416290283203, -0.03888416290283203, -0.03888416290283203, -0.03888416290283203, -0.03888416290283203], "metadata": {"source_tokens": ["Males", "had", "a", "median", "income", "of", "$", "28", "##,", "##75", "##0", "versus", "$", "16", "##,", "##25", "##0", "for", "females", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Males", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "median", "income", "of", "$", "28", "##,", "##75", "##0", "versus", "$", "16", "##,", "##25", "##0", "for", "females", "[unused6]", "[SEP]"]]}

input 198:  {"source": "Males had a median income of $ 36,016 versus $ 32,679 for females .\n"}
prediction:  {"predictions": [[1, 7689, 2, 3, 1125, 4, 5, 170, 3151, 2467, 1104, 109, 3164, 28136, 24400, 1545, 6055, 109, 2724, 28136, 1545, 1559, 1580, 1111, 3032, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-1.7762184143066406e-05, -0.020853042602539062, -0.019632339477539062, -0.019632339477539062, -0.019632339477539062, -0.019632339477539062, -0.019632339477539062, -0.019632339477539062, -0.019632339477539062, -0.019632339477539062], "metadata": {"source_tokens": ["Males", "had", "a", "median", "income", "of", "$", "36", "##,", "##01", "##6", "versus", "$", "32", "##,", "##6", "##7", "##9", "for", "females", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Males", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "median", "income", "of", "$", "36", "##,", "##01", "##6", "versus", "$", "32", "##,", "##6", "##7", "##9", "for", "females", "[unused6]", "[SEP]"]]}

input 199:  {"source": "Many are surgically removed for aesthetics and relief of psychosocial burden , but larger ones are also excised for prevention of cancer , although the benefit is impossible to assess for any individual patient .\n"}
prediction:  {"predictions": [[1, 1103, 5257, 2, 3, 1110, 4, 5, 4763, 1106, 15187, 1111, 1251, 2510, 5351, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2610, 3200, 2, 3, 1132, 4, 5, 1145, 4252, 14636, 1181, 1111, 13347, 1104, 4182, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2408, 2, 3, 1132, 13467, 1193, 2856, 4, 5, 1111, 27456, 1105, 3893, 1104, 15604, 21155, 22354, 12562, 11904, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0444665364921093, -0.06514216959476471, -0.012622504495084286, -0.026694297790527344, -0.027250289916992188, -0.027250289916992188, -0.027250289916992188, -0.027249813079833984, -0.027249813079833984, -0.027250289916992188], "metadata": {"source_tokens": ["Many", "are", "surgical", "##ly", "removed", "for", "aesthetics", "and", "relief", "of", "ps", "##ych", "##oso", "##cial", "burden", ",", "but", "larger", "ones", "are", "also", "ex", "##cise", "##d", "for", "prevention", "of", "cancer", ",", "although", "the", "benefit", "is", "impossible", "to", "assess", "for", "any", "individual", "patient", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "benefit", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "impossible", "to", "assess", "for", "any", "individual", "patient", "[unused6]", "[SEP]", "[unused1]", "larger", "ones", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "also", "ex", "##cise", "##d", "for", "prevention", "of", "cancer", "[unused6]", "[SEP]", "[unused1]", "Many", "[unused2]", "[unused3]", "are", "surgical", "##ly", "removed", "[unused4]", "[unused5]", "for", "aesthetics", "and", "relief", "of", "ps", "##ych", "##oso", "##cial", "burden", "[unused6]", "[SEP]"]]}

input 200:  {"source": "Many overseas Chinese whose ancestors came from the Quanzhou area , especially those in Southeast Asia , often speak mainly Hokkien at home .\n"}
prediction:  {"predictions": [[1, 2408, 7474, 1922, 2, 3, 2936, 4, 5, 2871, 9800, 1377, 11334, 1179, 1120, 1313, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2408, 7474, 1922, 2, 3, 1338, 4, 5, 1121, 1103, 154, 8734, 10753, 1298, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.060411352664232254, -0.03666282445192337, -0.09346437454223633, -0.0954899787902832, -0.0954899787902832, -0.0954899787902832, -0.0954899787902832, -0.0954899787902832, -0.0954899787902832, -0.0954899787902832], "metadata": {"source_tokens": ["Many", "overseas", "Chinese", "whose", "ancestors", "came", "from", "the", "Q", "##uan", "##zhou", "area", ",", "especially", "those", "in", "Southeast", "Asia", ",", "often", "speak", "mainly", "Ho", "##k", "##kie", "##n", "at", "home", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Many", "overseas", "Chinese", "[unused2]", "[unused3]", "speak", "[unused4]", "[unused5]", "mainly", "Ho", "##k", "##kie", "##n", "at", "home", "often", "[unused6]", "[SEP]", "[unused1]", "Many", "overseas", "Chinese", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "from", "the", "Q", "##uan", "##zhou", "area", "[unused6]", "[SEP]"]]}

input 201:  {"source": "Meanwhile , the Mason City Division continued to operate as usual .\n"}
prediction:  {"predictions": [[1, 1103, 6287, 1392, 1784, 2, 3, 1598, 4, 5, 1106, 4732, 1112, 4400, 5459, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02796139381825924, -0.10287857055664062, -0.10048580169677734, -0.10048580169677734, -0.10048580169677734, -0.10048580169677734, -0.10048580169677734, -0.10048580169677734, -0.10048580169677734, -0.10048580169677734], "metadata": {"source_tokens": ["Meanwhile", ",", "the", "Mason", "City", "Division", "continued", "to", "operate", "as", "usual", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Mason", "City", "Division", "[unused2]", "[unused3]", "continued", "[unused4]", "[unused5]", "to", "operate", "as", "usual", "Meanwhile", "[unused6]", "[SEP]"]]}

input 202:  {"source": "Models , taking into account the size and room number of the barrack blocks in the Gorgan Wall forts and likely occupation density , produce figures between 15,000 and 36,000 soldiers .\n"}
prediction:  {"predictions": [[1, 24025, 117, 1781, 1154, 3300, 1103, 2060, 1105, 1395, 1295, 1104, 1103, 2927, 21580, 5511, 1107, 1103, 3414, 21061, 6250, 17725, 1105, 2620, 5846, 3476, 2, 3, 3133, 4, 5, 3736, 1206, 1405, 28136, 7629, 1568, 1105, 3164, 28136, 7629, 1568, 2803, 6, 102, 102, 102, 102, 102, 102, 102, 1, 24025, 2, 3, 1781, 4, 5, 1154, 3300, 1103, 2060, 1105, 1395, 1295, 1104, 1103, 2927, 21580, 5511, 1107, 1103, 3414, 21061, 6250, 17725, 1105, 2620, 5846, 3476, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01191415823996067, -0.06865178793668747, -0.04361104965209961, -0.043514251708984375, -0.043514251708984375, -0.043514251708984375, -0.043514251708984375, -0.043514251708984375, -0.043514251708984375, -0.043514251708984375], "metadata": {"source_tokens": ["Models", ",", "taking", "into", "account", "the", "size", "and", "room", "number", "of", "the", "bar", "##rack", "blocks", "in", "the", "Go", "##rgan", "Wall", "forts", "and", "likely", "occupation", "density", ",", "produce", "figures", "between", "15", "##,", "##00", "##0", "and", "36", "##,", "##00", "##0", "soldiers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Models", ",", "taking", "into", "account", "the", "size", "and", "room", "number", "of", "the", "bar", "##rack", "blocks", "in", "the", "Go", "##rgan", "Wall", "forts", "and", "likely", "occupation", "density", "[unused2]", "[unused3]", "produce", "[unused4]", "[unused5]", "figures", "between", "15", "##,", "##00", "##0", "and", "36", "##,", "##00", "##0", "soldiers", "[unused6]", "[SEP]", "[unused1]", "Models", "[unused2]", "[unused3]", "taking", "[unused4]", "[unused5]", "into", "account", "the", "size", "and", "room", "number", "of", "the", "bar", "##rack", "blocks", "in", "the", "Go", "##rgan", "Wall", "forts", "and", "likely", "occupation", "density", "[unused6]", "[SEP]"]]}

input 203:  {"source": "Modern educational methods were more widely spread throughout the Empire , and the country embarked on a development scheme and plans for modernization , tempered by Ethiopian traditions , and within the framework of the ancient monarchical structure of the state .\n"}
prediction:  {"predictions": [[1, 4825, 4339, 4069, 2, 3, 1127, 4, 5, 1167, 3409, 2819, 2032, 1103, 2813, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1583, 2, 3, 11322, 4, 5, 1113, 170, 1718, 5471, 1105, 2714, 1111, 25145, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25145, 2, 3, 26030, 4, 5, 1118, 15845, 7181, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04344596713781357, -0.01549835130572319, -0.1007143035531044, -0.060394287109375, -0.06058835983276367, -0.06058835983276367, -0.06058835983276367, -0.06058835983276367, -0.06058835983276367, -0.06058835983276367], "metadata": {"source_tokens": ["Modern", "educational", "methods", "were", "more", "widely", "spread", "throughout", "the", "Empire", ",", "and", "the", "country", "embarked", "on", "a", "development", "scheme", "and", "plans", "for", "modernization", ",", "tempered", "by", "Ethiopian", "traditions", ",", "and", "within", "the", "framework", "of", "the", "ancient", "monarch", "##ical", "structure", "of", "the", "state", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Modern", "educational", "methods", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "more", "widely", "spread", "throughout", "the", "Empire", "[unused6]", "[SEP]", "[unused1]", "the", "country", "[unused2]", "[unused3]", "embarked", "[unused4]", "[unused5]", "on", "a", "development", "scheme", "and", "plans", "for", "modernization", "[unused6]", "[SEP]", "[unused1]", "modernization", "[unused2]", "[unused3]", "tempered", "[unused4]", "[unused5]", "by", "Ethiopian", "traditions", "[unused6]", "[SEP]"]]}

input 204:  {"source": "Modernity has been blended without sacrificing on the traditional Buddhist ethos .\n"}
prediction:  {"predictions": [[1, 4825, 1785, 2, 3, 1144, 1151, 22357, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4825, 1785, 2, 3, 1144, 4, 5, 1151, 22357, 1443, 21718, 1665, 2047, 21361, 1158, 1113, 1103, 2361, 7558, 3084, 15342, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0017593702068552375, -0.07543422281742096, -0.01332998275756836, -0.012816429138183594, -0.012816429138183594, -0.012816429138183594, -0.012816429138183594, -0.012816429138183594, -0.012816429138183594, -0.012816429138183594], "metadata": {"source_tokens": ["Modern", "##ity", "has", "been", "blended", "without", "sa", "##c", "##ri", "##fic", "##ing", "on", "the", "traditional", "Buddhist", "et", "##hos", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Modern", "##ity", "[unused2]", "[unused3]", "has", "been", "blended", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Modern", "##ity", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "been", "blended", "without", "sa", "##c", "##ri", "##fic", "##ing", "on", "the", "traditional", "Buddhist", "et", "##hos", "[unused6]", "[SEP]"]]}

input 205:  {"source": "Modification of the river began in earnest with the arrival of the Florida East Coast Railway in Miami in 1896 .\n"}
prediction:  {"predictions": [[1, 12556, 3309, 11531, 1104, 1103, 2186, 2, 3, 1310, 4, 5, 1107, 21304, 1114, 1103, 4870, 1104, 1103, 2631, 1689, 3331, 2847, 1107, 4916, 1107, 5645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0007616199436597526, -0.029132843017578125, -0.024682998657226562, -0.024682998657226562, -0.024682998657226562, -0.024682998657226562, -0.024683475494384766, -0.024682998657226562, -0.024682998657226562, -0.024682998657226562], "metadata": {"source_tokens": ["Mo", "##di", "##fication", "of", "the", "river", "began", "in", "earnest", "with", "the", "arrival", "of", "the", "Florida", "East", "Coast", "Railway", "in", "Miami", "in", "1896", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mo", "##di", "##fication", "of", "the", "river", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "in", "earnest", "with", "the", "arrival", "of", "the", "Florida", "East", "Coast", "Railway", "in", "Miami", "in", "1896", "[unused6]", "[SEP]"]]}

input 206:  {"source": "Moore briefly dropped Marciano in the second round , but Marciano recovered and knocked Moore down five times , knocking him out in the ninth to retain the belt .\n"}
prediction:  {"predictions": [[1, 4673, 2, 3, 2434, 4, 5, 25663, 2728, 1107, 1103, 1248, 1668, 4016, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25663, 2728, 2, 3, 6011, 4, 5, 4673, 1205, 1421, 1551, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25663, 2728, 2, 3, 6203, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05281646177172661, -0.1082020029425621, -0.05028956010937691, -0.30092668533325195, -0.3096427917480469, -0.3096427917480469, -0.3096427917480469, -0.3096427917480469, -0.3096427917480469, -0.3096427917480469], "metadata": {"source_tokens": ["Moore", "briefly", "dropped", "Marcia", "##no", "in", "the", "second", "round", ",", "but", "Marcia", "##no", "recovered", "and", "knocked", "Moore", "down", "five", "times", ",", "knocking", "him", "out", "in", "the", "ninth", "to", "retain", "the", "belt", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Moore", "[unused2]", "[unused3]", "dropped", "[unused4]", "[unused5]", "Marcia", "##no", "in", "the", "second", "round", "briefly", "[unused6]", "[SEP]", "[unused1]", "Marcia", "##no", "[unused2]", "[unused3]", "knocked", "[unused4]", "[unused5]", "Moore", "down", "five", "times", "[unused6]", "[SEP]", "[unused1]", "Marcia", "##no", "[unused2]", "[unused3]", "recovered", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 207:  {"source": "Much of the station remains in the disused subway but there is no public access .\n"}
prediction:  {"predictions": [[1, 6335, 1104, 1103, 1466, 2, 3, 2606, 4, 5, 1107, 1103, 4267, 26097, 14790, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1185, 1470, 2469, 2, 3, 1110, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0026635562535375357, -0.05883628502488136, -0.03463411331176758, -0.0374751091003418, -0.0374751091003418, -0.0374751091003418, -0.0374751091003418, -0.0374751091003418, -0.0374751091003418, -0.0374751091003418], "metadata": {"source_tokens": ["Much", "of", "the", "station", "remains", "in", "the", "di", "##sused", "subway", "but", "there", "is", "no", "public", "access", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Much", "of", "the", "station", "[unused2]", "[unused3]", "remains", "[unused4]", "[unused5]", "in", "the", "di", "##sused", "subway", "[unused6]", "[SEP]", "[unused1]", "no", "public", "access", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 208:  {"source": "Muhammad ibn Abu Bakr was a pious Muslim who supported the Imam of his time , Ali ibn Abi Talib , even though his sister Aisha opposed ` Ali in the battle of Jamal , Ibn Abu Bakr was faithful to his stepfather .\n"}
prediction:  {"predictions": [[1, 6710, 10452, 8158, 18757, 1377, 1197, 2, 3, 1108, 4, 5, 170, 185, 4179, 4360, 1150, 2726, 1103, 21765, 1104, 1117, 1159, 117, 4149, 10452, 138, 5567, 22515, 2646, 1830, 117, 1256, 1463, 1117, 2104, 19294, 5480, 4151, 169, 1256, 1463, 1117, 2104, 19294, 5480, 4151, 169, 1256, 1463, 102, 1, 14340, 8158, 18757, 1377, 1197, 2, 3, 1108, 4, 5, 12969, 1106, 1117, 24133, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 2104, 19294, 5480, 2, 3, 4151, 4, 5, 4149, 1107, 1103, 2321, 1104, 27440, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.060292311012744904, -0.058715272694826126, -0.07209937274456024, -0.10097360610961914, -0.10073375701904297, -0.10073375701904297, -0.10073375701904297, -0.10073375701904297, -0.10073375701904297, -0.10073375701904297], "metadata": {"source_tokens": ["Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "was", "a", "p", "##ious", "Muslim", "who", "supported", "the", "Imam", "of", "his", "time", ",", "Ali", "ibn", "A", "##bi", "Ta", "##li", "##b", ",", "even", "though", "his", "sister", "Ai", "##sha", "opposed", "`", "Ali", "in", "the", "battle", "of", "Jamal", ",", "Ibn", "Abu", "Ba", "##k", "##r", "was", "faithful", "to", "his", "stepfather", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "p", "##ious", "Muslim", "who", "supported", "the", "Imam", "of", "his", "time", ",", "Ali", "ibn", "A", "##bi", "Ta", "##li", "##b", ",", "even", "though", "his", "sister", "Ai", "##sha", "opposed", "`", "even", "though", "his", "sister", "Ai", "##sha", "opposed", "`", "even", "though", "[SEP]", "[unused1]", "Ibn", "Abu", "Ba", "##k", "##r", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "faithful", "to", "his", "stepfather", "[unused6]", "[SEP]", "[unused1]", "his", "sister", "Ai", "##sha", "[unused2]", "[unused3]", "opposed", "[unused4]", "[unused5]", "Ali", "in", "the", "battle", "of", "Jamal", "[unused6]", "[SEP]"]]}

input 209:  {"source": "Names like John Berks , Gary Edwards , Frank Sanders , Robin Alexander , Darryl Jooste , George Wayne and David Gresham all started out at LM Radio before moving to other stations such as Swazi Music Radio , Radio 702 , Springbok Radio and other SABC stations , 2JJ and Capital 604 .\n"}
prediction:  {"predictions": [[1, 13313, 1176, 1287, 4108, 18416, 117, 4926, 6847, 117, 2748, 12195, 117, 5981, 2792, 117, 25389, 8125, 15540, 1162, 117, 1667, 5489, 1105, 1681, 144, 21298, 2312, 2, 3, 1408, 1149, 4, 5, 1120, 149, 2107, 2664, 1196, 2232, 1106, 1168, 2930, 1216, 1112, 156, 3624, 5303, 1953, 2664, 102, 1, 13313, 1176, 1287, 4108, 18416, 4926, 6847, 25389, 8125, 15540, 1162, 1667, 5489, 1105, 1681, 144, 21298, 2312, 2, 3, 1408, 1149, 4, 5, 1120, 149, 2107, 2664, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017857659608125687, -0.1345643699169159, -0.19637203216552734, -0.2045001983642578, -0.2045001983642578, -0.2045001983642578, -0.2045001983642578, -0.2045001983642578, -0.20450067520141602, -0.20450067520141602], "metadata": {"source_tokens": ["Names", "like", "John", "Be", "##rks", ",", "Gary", "Edwards", ",", "Frank", "Sanders", ",", "Robin", "Alexander", ",", "Darryl", "Jo", "##ost", "##e", ",", "George", "Wayne", "and", "David", "G", "##resh", "##am", "all", "started", "out", "at", "L", "##M", "Radio", "before", "moving", "to", "other", "stations", "such", "as", "S", "##wa", "##zi", "Music", "Radio", ",", "Radio", "70", "##2", ",", "Spring", "##bo", "##k", "Radio", "and", "other", "SA", "##BC", "stations", ",", "2", "##J", "##J", "and", "Capital", "60", "##4", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Names", "like", "John", "Be", "##rks", ",", "Gary", "Edwards", ",", "Frank", "Sanders", ",", "Robin", "Alexander", ",", "Darryl", "Jo", "##ost", "##e", ",", "George", "Wayne", "and", "David", "G", "##resh", "##am", "[unused2]", "[unused3]", "started", "out", "[unused4]", "[unused5]", "at", "L", "##M", "Radio", "before", "moving", "to", "other", "stations", "such", "as", "S", "##wa", "##zi", "Music", "Radio", "[SEP]", "[unused1]", "Names", "like", "John", "Be", "##rks", "Gary", "Edwards", "Darryl", "Jo", "##ost", "##e", "George", "Wayne", "and", "David", "G", "##resh", "##am", "[unused2]", "[unused3]", "started", "out", "[unused4]", "[unused5]", "at", "L", "##M", "Radio", "[unused6]", "[SEP]"]]}

input 210:  {"source": "Newhan split the season between Triple-A Round Rock , where he hit .308 .\n"}
prediction:  {"predictions": [[1, 1203, 3822, 2, 3, 3325, 4, 5, 1103, 1265, 1206, 9457, 28137, 1592, 4200, 2977, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1855, 4, 5, 119, 13144, 1604, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.011575911194086075, -0.005393663886934519, -0.03579092025756836, -0.03786277770996094, -0.03786277770996094, -0.03786277770996094, -0.03786277770996094, -0.03786277770996094, -0.03786277770996094, -0.03786277770996094], "metadata": {"source_tokens": ["New", "##han", "split", "the", "season", "between", "Triple", "##-", "##A", "Round", "Rock", ",", "where", "he", "hit", ".", "##30", "##8", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "New", "##han", "[unused2]", "[unused3]", "split", "[unused4]", "[unused5]", "the", "season", "between", "Triple", "##-", "##A", "Round", "Rock", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "hit", "[unused4]", "[unused5]", ".", "##30", "##8", "[unused6]", "[SEP]"]]}

input 211:  {"source": "Next morning , the race left the city on the way to the Pyrenees and stopped in the suburb of Gradignan , in the university area of La House .\n"}
prediction:  {"predictions": [[1, 1103, 1886, 2, 3, 1286, 4, 5, 1103, 1331, 1113, 1103, 1236, 1106, 1103, 153, 10930, 27075, 5893, 2106, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1886, 2, 3, 2141, 4, 5, 1107, 1103, 7144, 1104, 144, 9871, 11368, 1389, 1107, 1103, 2755, 1298, 1104, 2001, 1585, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013690219260752201, -0.03447549790143967, -0.11324262619018555, -0.10915899276733398, -0.10915851593017578, -0.10915851593017578, -0.10915851593017578, -0.10915851593017578, -0.10915851593017578, -0.10915899276733398], "metadata": {"source_tokens": ["Next", "morning", ",", "the", "race", "left", "the", "city", "on", "the", "way", "to", "the", "P", "##yre", "##nees", "and", "stopped", "in", "the", "suburb", "of", "G", "##rad", "##ign", "##an", ",", "in", "the", "university", "area", "of", "La", "House", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "race", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "the", "city", "on", "the", "way", "to", "the", "P", "##yre", "##nees", "Next", "morning", "[unused6]", "[SEP]", "[unused1]", "the", "race", "[unused2]", "[unused3]", "stopped", "[unused4]", "[unused5]", "in", "the", "suburb", "of", "G", "##rad", "##ign", "##an", "in", "the", "university", "area", "of", "La", "House", "[unused6]", "[SEP]"]]}

input 212:  {"source": "No announcement from UTV was made about the decision to close the station earlier than planned .\n"}
prediction:  {"predictions": [[1, 1302, 8679, 1121, 158, 7073, 2, 3, 1108, 1189, 4, 5, 1164, 1103, 2383, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2383, 2, 3, 1106, 1601, 4, 5, 1103, 1466, 2206, 1190, 2919, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01580507680773735, -0.10598315298557281, -0.12147665023803711, -0.12747907638549805, -0.12747907638549805, -0.12747955322265625, -0.12747907638549805, -0.12747907638549805, -0.12747955322265625, -0.12747907638549805], "metadata": {"source_tokens": ["No", "announcement", "from", "U", "##TV", "was", "made", "about", "the", "decision", "to", "close", "the", "station", "earlier", "than", "planned", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "No", "announcement", "from", "U", "##TV", "[unused2]", "[unused3]", "was", "made", "[unused4]", "[unused5]", "about", "the", "decision", "[unused6]", "[SEP]", "[unused1]", "the", "decision", "[unused2]", "[unused3]", "to", "close", "[unused4]", "[unused5]", "the", "station", "earlier", "than", "planned", "[unused6]", "[SEP]"]]}

input 213:  {"source": "Noatak has a gravel public airstrip and is primarily reached by air .\n"}
prediction:  {"predictions": [[1, 1302, 6575, 1377, 2, 3, 1144, 4, 5, 170, 11898, 1470, 15692, 19091, 1643, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1302, 6575, 1377, 2, 3, 1110, 3120, 1680, 4, 5, 1118, 1586, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.003675271524116397, -0.023607218638062477, -0.011590003967285156, -0.012096881866455078, -0.012096881866455078, -0.012096881866455078, -0.012096881866455078, -0.012096881866455078, -0.012096881866455078, -0.012096881866455078], "metadata": {"source_tokens": ["No", "##ata", "##k", "has", "a", "gravel", "public", "airs", "##tri", "##p", "and", "is", "primarily", "reached", "by", "air", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "No", "##ata", "##k", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "a", "gravel", "public", "airs", "##tri", "##p", "[unused6]", "[SEP]", "[unused1]", "No", "##ata", "##k", "[unused2]", "[unused3]", "is", "primarily", "reached", "[unused4]", "[unused5]", "by", "air", "[unused6]", "[SEP]"]]}

input 214:  {"source": "Not everyone completely trusted Vakama 's vision - Matau was particularly frustrated at following what he considered the delusions of a `` fire-spitter '' - but with nothing else to go on they decided to track the Matoran down .\n"}
prediction:  {"predictions": [[1, 1152, 2, 3, 1879, 4, 5, 1106, 1854, 1103, 25702, 15186, 1205, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 28044, 1358, 2, 3, 1108, 4, 5, 2521, 11010, 1120, 1378, 1184, 1119, 1737, 1103, 3687, 27262, 1104, 170, 169, 28152, 1783, 28137, 20080, 25608, 1197, 112, 28131, 118, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 28044, 2490, 2, 3, 1129, 9373, 4, 5, 159, 11747, 1918, 112, 1116, 4152, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 28044, 2490, 2, 3, 1108, 4, 5, 11010, 1120, 1378, 1184, 1119, 1737, 1103, 3687, 27262, 1104, 170, 169, 28152, 1783, 28137, 20080, 25608, 1197, 112, 28131, 118, 1133, 1114, 1720, 1950, 1106, 1301, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07908990979194641, -0.04982786625623703, -0.15520693361759186, -0.2187279313802719, -0.2551259994506836, -0.259549617767334, -0.2595500946044922, -0.259549617767334, -0.2595500946044922, -0.2595500946044922], "metadata": {"source_tokens": ["Not", "everyone", "completely", "trusted", "V", "##aka", "##ma", "'", "##s", "vision", "-", "Mata", "##u", "was", "particularly", "frustrated", "at", "following", "what", "he", "considered", "the", "del", "##usions", "of", "a", "`", "##`", "fire", "##-", "##sp", "##itte", "##r", "'", "##'", "-", "but", "with", "nothing", "else", "to", "go", "on", "they", "decided", "to", "track", "the", "Mat", "##oran", "down", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "they", "[unused2]", "[unused3]", "decided", "[unused4]", "[unused5]", "to", "track", "the", "Mat", "##oran", "down", "[unused6]", "[SEP]", "[unused1]", "Mata", "##u", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "particularly", "frustrated", "at", "following", "what", "he", "considered", "the", "del", "##usions", "of", "a", "`", "##`", "fire", "##-", "##sp", "##itte", "##r", "'", "##'", "-", "[unused6]", "[SEP]", "[unused1]", "Mata", "everyone", "[unused2]", "[unused3]", "be", "trusted", "[unused4]", "[unused5]", "V", "##aka", "##ma", "'", "##s", "vision", "[unused6]", "[SEP]", "[unused1]", "Mata", "everyone", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "frustrated", "at", "following", "what", "he", "considered", "the", "del", "##usions", "of", "a", "`", "##`", "fire", "##-", "##sp", "##itte", "##r", "'", "##'", "-", "but", "with", "nothing", "else", "to", "go", "[unused6]", "[SEP]"]]}

input 215:  {"source": "Nothing is known for certain about his life before about 1580 , but contemporary or near-contemporary accounts suggest that he was brought up as a member of the Church of Scotland , spent some time in Argyll before leaving for the Continent , and was converted to Catholicism in Spain .\n"}
prediction:  {"predictions": [[1, 3793, 1137, 1485, 28137, 7235, 18408, 18876, 3113, 5756, 2, 3, 5996, 4, 5, 1115, 1119, 1108, 1814, 1146, 1112, 170, 1420, 1104, 1103, 1722, 1104, 3030, 117, 2097, 1199, 1159, 1107, 138, 17292, 2339, 1196, 2128, 1111, 1103, 16752, 24123, 117, 1105, 1108, 4213, 1106, 17164, 1107, 2722, 102, 1, 4302, 2, 3, 1110, 4, 5, 1111, 2218, 1164, 1117, 1297, 1196, 1164, 18960, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 4, 5, 1199, 1159, 1107, 138, 17292, 2339, 1196, 2128, 1111, 1103, 16752, 24123, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1814, 1146, 4, 5, 1112, 170, 1420, 1104, 1103, 1722, 1104, 3030, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 4213, 4, 5, 1106, 17164, 1107, 2722, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.032107364386320114, -0.13877828419208527, -0.14460895955562592, -0.10574832558631897, -0.1279466301202774, -0.32267332077026367, -0.3193998336791992, -0.3194003105163574, -0.3193998336791992, -0.3194003105163574], "metadata": {"source_tokens": ["Nothing", "is", "known", "for", "certain", "about", "his", "life", "before", "about", "158", "##0", ",", "but", "contemporary", "or", "near", "##-", "##con", "##tem", "##por", "##ary", "accounts", "suggest", "that", "he", "was", "brought", "up", "as", "a", "member", "of", "the", "Church", "of", "Scotland", ",", "spent", "some", "time", "in", "A", "##rgy", "##ll", "before", "leaving", "for", "the", "Con", "##tinent", ",", "and", "was", "converted", "to", "Catholicism", "in", "Spain", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "contemporary", "or", "near", "##-", "##con", "##tem", "##por", "##ary", "accounts", "[unused2]", "[unused3]", "suggest", "[unused4]", "[unused5]", "that", "he", "was", "brought", "up", "as", "a", "member", "of", "the", "Church", "of", "Scotland", ",", "spent", "some", "time", "in", "A", "##rgy", "##ll", "before", "leaving", "for", "the", "Con", "##tinent", ",", "and", "was", "converted", "to", "Catholicism", "in", "Spain", "[SEP]", "[unused1]", "Nothing", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "for", "certain", "about", "his", "life", "before", "about", "158", "##0", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "some", "time", "in", "A", "##rgy", "##ll", "before", "leaving", "for", "the", "Con", "##tinent", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "brought", "up", "[unused4]", "[unused5]", "as", "a", "member", "of", "the", "Church", "of", "Scotland", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "converted", "[unused4]", "[unused5]", "to", "Catholicism", "in", "Spain", "[unused6]", "[SEP]"]]}

input 216:  {"source": "Obviously the epilogue was not an afterthought supplied too late for the English edition , for it is referred to in `` The Castaway '' : `` in the sequel of the narrative , it will then be seen what like abandonment befell myself . ''\n"}
prediction:  {"predictions": [[1, 1103, 174, 8508, 12733, 2, 3, 1108, 1136, 4, 5, 1126, 1170, 1582, 26960, 7694, 1315, 1523, 1111, 1103, 1483, 2596, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 2752, 4, 5, 1106, 1107, 1109, 21452, 7138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 2752, 4, 5, 1106, 1107, 1109, 21452, 7138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1209, 1129, 1562, 4, 5, 1184, 1176, 25356, 1129, 27610, 1991, 1107, 1103, 8047, 1104, 1103, 8195, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.045790791511535645, -0.05648596212267876, -0.13190138339996338, -0.09029658883810043, -0.20363283157348633, -0.2064228057861328, -0.2064228057861328, -0.2064228057861328, -0.2064228057861328, -0.2064228057861328], "metadata": {"source_tokens": ["Obviously", "the", "e", "##pi", "##logue", "was", "not", "an", "after", "##th", "##ought", "supplied", "too", "late", "for", "the", "English", "edition", ",", "for", "it", "is", "referred", "to", "in", "`", "##`", "The", "Cast", "##away", "'", "##'", ":", "`", "##`", "in", "the", "sequel", "of", "the", "narrative", ",", "it", "will", "then", "be", "seen", "what", "like", "abandonment", "be", "##fell", "myself", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "e", "##pi", "##logue", "[unused2]", "[unused3]", "was", "not", "[unused4]", "[unused5]", "an", "after", "##th", "##ought", "supplied", "too", "late", "for", "the", "English", "edition", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "referred", "[unused4]", "[unused5]", "to", "in", "The", "Cast", "##away", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "referred", "[unused4]", "[unused5]", "to", "in", "The", "Cast", "##away", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "will", "be", "seen", "[unused4]", "[unused5]", "what", "like", "abandonment", "be", "##fell", "myself", "in", "the", "sequel", "of", "the", "narrative", "[unused6]", "[SEP]"]]}

input 217:  {"source": "Of the rest of the population , there was 1 individual who belonged to the Christian Catholic faith .\n"}
prediction:  {"predictions": [[1, 122, 2510, 2, 3, 5609, 4, 5, 1106, 1103, 2131, 2336, 5228, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00027669270639307797, -0.16221952438354492, -0.16200923919677734, -0.16200923919677734, -0.16200923919677734, -0.16200923919677734, -0.16200923919677734, -0.16200923919677734, -0.16200923919677734, -0.16200923919677734], "metadata": {"source_tokens": ["Of", "the", "rest", "of", "the", "population", ",", "there", "was", "1", "individual", "who", "belonged", "to", "the", "Christian", "Catholic", "faith", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "1", "individual", "[unused2]", "[unused3]", "belonged", "[unused4]", "[unused5]", "to", "the", "Christian", "Catholic", "faith", "[unused6]", "[SEP]"]]}

input 218:  {"source": "On 16 June 1944 , British double agent `` Garbo '' was requested by his German controllers to give information on the sites and times of V-1 impacts , with similar requests made to the other German agents in Britain , `` Brutus '' and `` Tate '' .\n"}
prediction:  {"predictions": [[1, 1418, 2702, 3677, 144, 1813, 4043, 2, 3, 1108, 6792, 4, 5, 1118, 1117, 1528, 25747, 1106, 1660, 1869, 1113, 1103, 3911, 1105, 1551, 1104, 159, 28137, 1475, 15791, 1114, 1861, 11458, 1189, 1106, 1103, 1168, 1528, 5789, 1107, 2855, 1212, 1479, 1340, 2782, 6, 102, 102, 102, 102, 102, 1, 1861, 11458, 2, 3, 1129, 1189, 4, 5, 1106, 1103, 1168, 1528, 5789, 1107, 2855, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.032970163971185684, -0.10575561970472336, -0.10629749298095703, -0.1098175048828125, -0.1098175048828125, -0.1098175048828125, -0.1098175048828125, -0.1098175048828125, -0.1098175048828125, -0.1098175048828125], "metadata": {"source_tokens": ["On", "16", "June", "1944", ",", "British", "double", "agent", "`", "##`", "G", "##ar", "##bo", "'", "##'", "was", "requested", "by", "his", "German", "controllers", "to", "give", "information", "on", "the", "sites", "and", "times", "of", "V", "##-", "##1", "impacts", ",", "with", "similar", "requests", "made", "to", "the", "other", "German", "agents", "in", "Britain", ",", "`", "##`", "B", "##ru", "##tus", "'", "##'", "and", "`", "##`", "Tate", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "British", "double", "agent", "G", "##ar", "##bo", "[unused2]", "[unused3]", "was", "requested", "[unused4]", "[unused5]", "by", "his", "German", "controllers", "to", "give", "information", "on", "the", "sites", "and", "times", "of", "V", "##-", "##1", "impacts", "with", "similar", "requests", "made", "to", "the", "other", "German", "agents", "in", "Britain", "On", "16", "June", "1944", "[unused6]", "[SEP]", "[unused1]", "similar", "requests", "[unused2]", "[unused3]", "be", "made", "[unused4]", "[unused5]", "to", "the", "other", "German", "agents", "in", "Britain", "[unused6]", "[SEP]"]]}

input 219:  {"source": "On May 13 , 2010 , Yost was named manager of the Kansas City Royals , replacing Trey Hillman .\n"}
prediction:  {"predictions": [[1, 14941, 2050, 2, 3, 1108, 1417, 4, 5, 2618, 1104, 1103, 4312, 1392, 17692, 1212, 1318, 1492, 117, 1333, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 14941, 2050, 2, 3, 1108, 4, 5, 2618, 1104, 1103, 4312, 1392, 17692, 5861, 15558, 2404, 1399, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04384905472397804, -0.095550037920475, -0.10152912139892578, -0.09887456893920898, -0.09887456893920898, -0.09887456893920898, -0.09887456893920898, -0.09887456893920898, -0.09887456893920898, -0.09887456893920898], "metadata": {"source_tokens": ["On", "May", "13", ",", "2010", ",", "Yo", "##st", "was", "named", "manager", "of", "the", "Kansas", "City", "Royals", ",", "replacing", "Trey", "Hill", "##man", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Yo", "##st", "[unused2]", "[unused3]", "was", "named", "[unused4]", "[unused5]", "manager", "of", "the", "Kansas", "City", "Royals", "On", "May", "13", ",", "2010", "[unused6]", "[SEP]", "[unused1]", "Yo", "##st", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "manager", "of", "the", "Kansas", "City", "Royals", "replacing", "Trey", "Hill", "##man", "[unused6]", "[SEP]"]]}

input 220:  {"source": "On May 15 , 2007 , XM suspended Opie & Anthony for 30 days , in response to a broadcast featuring a homeless man who wandered into the studio .\n"}
prediction:  {"predictions": [[1, 161, 2107, 2, 3, 6232, 4, 5, 9126, 1663, 111, 4140, 1111, 1476, 1552, 1212, 1318, 1405, 117, 1384, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 3012, 2, 3, 3022, 4, 5, 170, 12501, 1299, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 12501, 1299, 2, 3, 1129, 13668, 4, 5, 1154, 1103, 2362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07021547108888626, -0.09393595904111862, -0.04705190286040306, -0.14970827102661133, -0.14872217178344727, -0.14872217178344727, -0.14872217178344727, -0.14872217178344727, -0.14872217178344727, -0.14872217178344727], "metadata": {"source_tokens": ["On", "May", "15", ",", "2007", ",", "X", "##M", "suspended", "Op", "##ie", "&", "Anthony", "for", "30", "days", ",", "in", "response", "to", "a", "broadcast", "featuring", "a", "homeless", "man", "who", "wandered", "into", "the", "studio", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "X", "##M", "[unused2]", "[unused3]", "suspended", "[unused4]", "[unused5]", "Op", "##ie", "&", "Anthony", "for", "30", "days", "On", "May", "15", ",", "2007", "[unused6]", "[SEP]", "[unused1]", "a", "broadcast", "[unused2]", "[unused3]", "featuring", "[unused4]", "[unused5]", "a", "homeless", "man", "[unused6]", "[SEP]", "[unused1]", "a", "homeless", "man", "[unused2]", "[unused3]", "be", "wandered", "[unused4]", "[unused5]", "into", "the", "studio", "[unused6]", "[SEP]"]]}

input 221:  {"source": "On November 2 , 2005 , Brown ended his contract early and left the federal government .\n"}
prediction:  {"predictions": [[1, 2671, 2, 3, 2207, 4, 5, 1117, 2329, 1346, 1212, 1379, 123, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2671, 2, 3, 1286, 4, 5, 1103, 2877, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03603731840848923, -0.017591968178749084, -0.13361120223999023, -0.1314239501953125, -0.1314239501953125, -0.1314239501953125, -0.1314239501953125, -0.1314239501953125, -0.1314239501953125, -0.1314239501953125], "metadata": {"source_tokens": ["On", "November", "2", ",", "2005", ",", "Brown", "ended", "his", "contract", "early", "and", "left", "the", "federal", "government", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Brown", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "his", "contract", "early", "On", "November", "2", "[unused6]", "[SEP]", "[unused1]", "Brown", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "the", "federal", "government", "[unused6]", "[SEP]"]]}

input 222:  {"source": "One candidate is a wreck at the western end of Manitoulin Island in Lake Huron , with another wreck near Escanaba , Michigan , also proposed .\n"}
prediction:  {"predictions": [[1, 1448, 3234, 2, 3, 1110, 4, 5, 170, 13573, 1120, 1103, 2466, 1322, 1104, 2268, 8383, 19001, 2054, 1107, 2161, 24289, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 142, 26996, 1605, 2822, 2, 3, 1110, 4, 5, 3312, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1330, 13573, 1485, 142, 26996, 1605, 2822, 2, 3, 1110, 3000, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027928432449698448, -0.1040024384856224, -0.1741168051958084, -0.07057857513427734, -0.07152271270751953, -0.07152271270751953, -0.07152271270751953, -0.07152271270751953, -0.07152271270751953, -0.07152271270751953], "metadata": {"source_tokens": ["One", "candidate", "is", "a", "wreck", "at", "the", "western", "end", "of", "Man", "##ito", "##ulin", "Island", "in", "Lake", "Huron", ",", "with", "another", "wreck", "near", "E", "##sca", "##na", "##ba", ",", "Michigan", ",", "also", "proposed", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "One", "candidate", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "wreck", "at", "the", "western", "end", "of", "Man", "##ito", "##ulin", "Island", "in", "Lake", "Huron", "[unused6]", "[SEP]", "[unused1]", "E", "##sca", "##na", "##ba", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Michigan", "[unused6]", "[SEP]", "[unused1]", "another", "wreck", "near", "E", "##sca", "##na", "##ba", "[unused2]", "[unused3]", "is", "proposed", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 223:  {"source": "One example could be `` Time '' , the fifth song from Pink Floyd 's 1973 album `` The Dark Side Of The Moon '' , which contains a reprise of `` Breathe '' , the first song of the same album .\n"}
prediction:  {"predictions": [[1, 1448, 1859, 2, 3, 1180, 1129, 4, 5, 2614, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3049, 1461, 1121, 10763, 12450, 112, 1116, 2478, 1312, 2, 3, 2515, 4, 5, 170, 1231, 16874, 1104, 169, 28152, 139, 18709, 1162, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.09789832681417465, -0.05936439707875252, -0.07415771484375, -0.07832002639770508, -0.07832002639770508, -0.07832002639770508, -0.07832002639770508, -0.07832002639770508, -0.07832002639770508, -0.07832002639770508], "metadata": {"source_tokens": ["One", "example", "could", "be", "`", "##`", "Time", "'", "##'", ",", "the", "fifth", "song", "from", "Pink", "Floyd", "'", "##s", "1973", "album", "`", "##`", "The", "Dark", "Side", "Of", "The", "Moon", "'", "##'", ",", "which", "contains", "a", "re", "##prise", "of", "`", "##`", "B", "##reath", "##e", "'", "##'", ",", "the", "first", "song", "of", "the", "same", "album", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "One", "example", "[unused2]", "[unused3]", "could", "be", "[unused4]", "[unused5]", "Time", "[unused6]", "[SEP]", "[unused1]", "the", "fifth", "song", "from", "Pink", "Floyd", "'", "##s", "1973", "album", "[unused2]", "[unused3]", "contains", "[unused4]", "[unused5]", "a", "re", "##prise", "of", "`", "##`", "B", "##reath", "##e", "[unused6]", "[SEP]"]]}

input 224:  {"source": "Only Ballard and Williams are left after Sergeant Jericho and the other officers , along with the two train operators , are killed when they try to finish the fight .\n"}
prediction:  {"predictions": [[1, 2809, 24241, 1105, 2902, 2, 3, 1132, 1286, 4, 5, 1170, 7908, 18545, 1105, 1103, 1168, 3099, 117, 1373, 1114, 1103, 1160, 2669, 9298, 117, 1132, 1841, 1165, 1152, 2222, 1106, 3146, 1103, 2147, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7908, 18545, 1105, 1103, 1168, 3099, 2, 3, 1132, 1841, 4, 5, 1165, 1152, 2222, 1106, 3146, 1103, 2147, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00982067920267582, -0.06769178062677383, -0.10375499725341797, -0.09462785720825195, -0.09462785720825195, -0.09462785720825195, -0.09462785720825195, -0.09462785720825195, -0.09462785720825195, -0.09462785720825195], "metadata": {"source_tokens": ["Only", "Ballard", "and", "Williams", "are", "left", "after", "Sergeant", "Jericho", "and", "the", "other", "officers", ",", "along", "with", "the", "two", "train", "operators", ",", "are", "killed", "when", "they", "try", "to", "finish", "the", "fight", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Only", "Ballard", "and", "Williams", "[unused2]", "[unused3]", "are", "left", "[unused4]", "[unused5]", "after", "Sergeant", "Jericho", "and", "the", "other", "officers", ",", "along", "with", "the", "two", "train", "operators", ",", "are", "killed", "when", "they", "try", "to", "finish", "the", "fight", "[unused6]", "[SEP]", "[unused1]", "Sergeant", "Jericho", "and", "the", "other", "officers", "[unused2]", "[unused3]", "are", "killed", "[unused4]", "[unused5]", "when", "they", "try", "to", "finish", "the", "fight", "[unused6]", "[SEP]"]]}

input 225:  {"source": "Opponents of religious freedom sometimes referred to it as `` Rogue 's Island '' , and Cotton Mather called it `` the sewer of New England . ''\n"}
prediction:  {"predictions": [[1, 12871, 15112, 1200, 2, 3, 1270, 4, 5, 1122, 1103, 27635, 1104, 1203, 1652, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9126, 25387, 1104, 2689, 4438, 2, 3, 2752, 4, 5, 1106, 1122, 1112, 169, 28152, 20481, 112, 1116, 2054, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0380437858402729, -0.03163322061300278, -0.14263439178466797, -0.1389636993408203, -0.13896417617797852, -0.1389636993408203, -0.13896417617797852, -0.1389636993408203, -0.13896417617797852, -0.1389636993408203], "metadata": {"source_tokens": ["Op", "##ponents", "of", "religious", "freedom", "sometimes", "referred", "to", "it", "as", "`", "##`", "Rogue", "'", "##s", "Island", "'", "##'", ",", "and", "Cotton", "Math", "##er", "called", "it", "`", "##`", "the", "sewer", "of", "New", "England", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Cotton", "Math", "##er", "[unused2]", "[unused3]", "called", "[unused4]", "[unused5]", "it", "the", "sewer", "of", "New", "England", "[unused6]", "[SEP]", "[unused1]", "Op", "##ponents", "of", "religious", "freedom", "[unused2]", "[unused3]", "referred", "[unused4]", "[unused5]", "to", "it", "as", "`", "##`", "Rogue", "'", "##s", "Island", "[unused6]", "[SEP]"]]}

input 226:  {"source": "Originally , Hank McCoy retains the basic features of a normal human alongside a generally simian physiology equivalent to that of a Great Ape .\n"}
prediction:  {"predictions": [[1, 8902, 17061, 2, 3, 15208, 4, 5, 1103, 3501, 1956, 1104, 170, 2999, 1769, 3338, 170, 2412, 27466, 19111, 25445, 4976, 1106, 1115, 1104, 170, 2038, 138, 3186, 5798, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00045835599303245544, -0.26639223098754883, -0.2808089256286621, -0.2808089256286621, -0.2808094024658203, -0.2808094024658203, -0.2808094024658203, -0.2808094024658203, -0.2808094024658203, -0.2808094024658203], "metadata": {"source_tokens": ["Originally", ",", "Hank", "McCoy", "retains", "the", "basic", "features", "of", "a", "normal", "human", "alongside", "a", "generally", "si", "##mian", "physiology", "equivalent", "to", "that", "of", "a", "Great", "A", "##pe", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hank", "McCoy", "[unused2]", "[unused3]", "retains", "[unused4]", "[unused5]", "the", "basic", "features", "of", "a", "normal", "human", "alongside", "a", "generally", "si", "##mian", "physiology", "equivalent", "to", "that", "of", "a", "Great", "A", "##pe", "Originally", "[unused6]", "[SEP]"]]}

input 227:  {"source": "Other signs of lens subluxation include mild conjunctival redness , vitreous humour degeneration , prolapse of the vitreous into the anterior chamber , and an increase or decrease of anterior chamber depth .\n"}
prediction:  {"predictions": [[1, 2189, 5300, 1104, 11039, 4841, 24796, 1891, 2, 3, 1511, 4, 5, 10496, 14255, 20327, 15895, 1894, 1757, 117, 191, 2875, 1874, 2285, 19311, 1260, 27054, 6108, 117, 5250, 16046, 2217, 1104, 1103, 191, 2875, 1874, 2285, 1154, 1103, 16557, 5383, 117, 1105, 1126, 2773, 1137, 9711, 1104, 16557, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.010083666071295738, -0.04887533187866211, -0.054574012756347656, -0.054574012756347656, -0.054574012756347656, -0.054574012756347656, -0.054574012756347656, -0.054574012756347656, -0.054574012756347656, -0.054574012756347656], "metadata": {"source_tokens": ["Other", "signs", "of", "lens", "sub", "##lux", "##ation", "include", "mild", "con", "##junct", "##ival", "red", "##ness", ",", "v", "##it", "##re", "##ous", "humour", "de", "##gene", "##ration", ",", "pro", "##lap", "##se", "of", "the", "v", "##it", "##re", "##ous", "into", "the", "anterior", "chamber", ",", "and", "an", "increase", "or", "decrease", "of", "anterior", "chamber", "depth", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Other", "signs", "of", "lens", "sub", "##lux", "##ation", "[unused2]", "[unused3]", "include", "[unused4]", "[unused5]", "mild", "con", "##junct", "##ival", "red", "##ness", ",", "v", "##it", "##re", "##ous", "humour", "de", "##gene", "##ration", ",", "pro", "##lap", "##se", "of", "the", "v", "##it", "##re", "##ous", "into", "the", "anterior", "chamber", ",", "and", "an", "increase", "or", "decrease", "of", "anterior", "[SEP]"]]}

input 228:  {"source": "Pakistan Chrome Mines Ltd. is a mining company incorporated in the Islamic Republic of Pakistan .\n"}
prediction:  {"predictions": [[1, 3658, 20394, 11457, 18946, 4492, 28138, 2, 3, 1110, 4, 5, 170, 5463, 1419, 4572, 1107, 1103, 4769, 2250, 1104, 3658, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00134243571665138, -0.007677555084228516, -0.007237434387207031, -0.007237434387207031, -0.007237434387207031, -0.007237434387207031, -0.007237434387207031, -0.007237434387207031, -0.007237434387207031, -0.007237434387207031], "metadata": {"source_tokens": ["Pakistan", "Ch", "##rome", "Mines", "Ltd", "##.", "is", "a", "mining", "company", "incorporated", "in", "the", "Islamic", "Republic", "of", "Pakistan", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pakistan", "Ch", "##rome", "Mines", "Ltd", "##.", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "mining", "company", "incorporated", "in", "the", "Islamic", "Republic", "of", "Pakistan", "[unused6]", "[SEP]"]]}

input 229:  {"source": "Parental investment is any expenditure of resources to benefit one offspring .\n"}
prediction:  {"predictions": [[1, 19585, 17759, 1348, 5151, 2, 3, 1110, 4, 5, 1251, 24106, 1104, 3979, 1106, 5257, 1141, 14416, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012562459334731102, -0.015697956085205078, -0.015604019165039062, -0.015604019165039062, -0.015604019165039062, -0.015604019165039062, -0.015604019165039062, -0.015604019165039062, -0.015604019165039062, -0.015604019165039062], "metadata": {"source_tokens": ["Pa", "##rent", "##al", "investment", "is", "any", "expenditure", "of", "resources", "to", "benefit", "one", "offspring", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pa", "##rent", "##al", "investment", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "any", "expenditure", "of", "resources", "to", "benefit", "one", "offspring", "[unused6]", "[SEP]"]]}

input 230:  {"source": "Piffaro generally performs a concert series of four to five concerts a year in Philadelphia , in addition to touring throughout the United States , Canada , Europe and elsewhere .\n"}
prediction:  {"predictions": [[1, 21902, 3101, 14452, 2, 3, 2412, 10383, 4, 5, 170, 3838, 1326, 1104, 1300, 1106, 1421, 6460, 170, 1214, 1107, 3562, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21902, 3101, 14452, 2, 3, 10383, 4, 5, 170, 3838, 1326, 1104, 1300, 1106, 1421, 6460, 170, 1214, 1107, 1901, 1106, 7048, 2032, 1103, 1244, 1311, 117, 1803, 117, 1980, 1105, 6890, 6, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005125934723764658, -0.09581024199724197, -0.10869312286376953, -0.11302375793457031, -0.11302375793457031, -0.11302375793457031, -0.11302375793457031, -0.11302375793457031, -0.11302375793457031, -0.11302375793457031], "metadata": {"source_tokens": ["Pi", "##ff", "##aro", "generally", "performs", "a", "concert", "series", "of", "four", "to", "five", "concerts", "a", "year", "in", "Philadelphia", ",", "in", "addition", "to", "touring", "throughout", "the", "United", "States", ",", "Canada", ",", "Europe", "and", "elsewhere", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pi", "##ff", "##aro", "[unused2]", "[unused3]", "generally", "performs", "[unused4]", "[unused5]", "a", "concert", "series", "of", "four", "to", "five", "concerts", "a", "year", "in", "Philadelphia", "[unused6]", "[SEP]", "[unused1]", "Pi", "##ff", "##aro", "[unused2]", "[unused3]", "performs", "[unused4]", "[unused5]", "a", "concert", "series", "of", "four", "to", "five", "concerts", "a", "year", "in", "addition", "to", "touring", "throughout", "the", "United", "States", ",", "Canada", ",", "Europe", "and", "elsewhere", "[unused6]", "[SEP]"]]}

input 231:  {"source": "Plants have been planted marking parts of the foundations of the castle , so the positions of some of the buildings can still be inferred .\n"}
prediction:  {"predictions": [[1, 1103, 3638, 1104, 1199, 1104, 1103, 2275, 2, 3, 1169, 1129, 1107, 26025, 4, 5, 1253, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25880, 2, 3, 1138, 1151, 8100, 4, 5, 10079, 2192, 1104, 1103, 11217, 1104, 1103, 3804, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.026424389332532883, -0.054892897605895996, -0.029646873474121094, -0.03131580352783203, -0.03131580352783203, -0.03131580352783203, -0.03131580352783203, -0.03131580352783203, -0.03131580352783203, -0.03131580352783203], "metadata": {"source_tokens": ["Plants", "have", "been", "planted", "marking", "parts", "of", "the", "foundations", "of", "the", "castle", ",", "so", "the", "positions", "of", "some", "of", "the", "buildings", "can", "still", "be", "in", "##ferred", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "positions", "of", "some", "of", "the", "buildings", "[unused2]", "[unused3]", "can", "be", "in", "##ferred", "[unused4]", "[unused5]", "still", "[unused6]", "[SEP]", "[unused1]", "Plants", "[unused2]", "[unused3]", "have", "been", "planted", "[unused4]", "[unused5]", "marking", "parts", "of", "the", "foundations", "of", "the", "castle", "[unused6]", "[SEP]"]]}

input 232:  {"source": "Prior to the 2012 season , the Royals signed Yost to a contract extension through the 2013 season .\n"}
prediction:  {"predictions": [[1, 1103, 17692, 2, 3, 1878, 4, 5, 14941, 2050, 1106, 170, 2329, 4973, 1194, 1103, 1381, 1265, 4602, 1106, 1103, 1368, 1265, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0004181385156698525, -0.26680517196655273, -0.26662302017211914, -0.26662302017211914, -0.26662302017211914, -0.26662302017211914, -0.26662302017211914, -0.26662302017211914, -0.26662302017211914, -0.26662302017211914], "metadata": {"source_tokens": ["Prior", "to", "the", "2012", "season", ",", "the", "Royals", "signed", "Yo", "##st", "to", "a", "contract", "extension", "through", "the", "2013", "season", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Royals", "[unused2]", "[unused3]", "signed", "[unused4]", "[unused5]", "Yo", "##st", "to", "a", "contract", "extension", "through", "the", "2013", "season", "Prior", "to", "the", "2012", "season", "[unused6]", "[SEP]"]]}

input 233:  {"source": "Prior to the Playmaker tool , the Player could only call one of four available `` hot routes . ''\n"}
prediction:  {"predictions": [[1, 1103, 5348, 2, 3, 1180, 1178, 1840, 4, 5, 1141, 1104, 1300, 1907, 169, 28152, 2633, 5441, 4602, 1106, 1103, 6060, 8085, 6806, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 5348, 2, 3, 1180, 1840, 4, 5, 1141, 1104, 1103, 6060, 8085, 6806, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0006427718908526003, -0.11026034504175186, -0.22127485275268555, -0.2029280662536621, -0.2029280662536621, -0.2029275894165039, -0.2029280662536621, -0.2029280662536621, -0.2029280662536621, -0.2029280662536621], "metadata": {"source_tokens": ["Prior", "to", "the", "Play", "##maker", "tool", ",", "the", "Player", "could", "only", "call", "one", "of", "four", "available", "`", "##`", "hot", "routes", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Player", "[unused2]", "[unused3]", "could", "only", "call", "[unused4]", "[unused5]", "one", "of", "four", "available", "`", "##`", "hot", "routes", "Prior", "to", "the", "Play", "##maker", "tool", "[unused6]", "[SEP]", "[unused1]", "the", "Player", "[unused2]", "[unused3]", "could", "call", "[unused4]", "[unused5]", "one", "of", "the", "Play", "##maker", "tool", "[unused6]", "[SEP]"]]}

input 234:  {"source": "Proliferative nodules are usually biopsied and are regularly but not systematically found to be benign .\n"}
prediction:  {"predictions": [[1, 5096, 14430, 15306, 6873, 11806, 2, 3, 1132, 4, 5, 4857, 1133, 1136, 25923, 1276, 1106, 1129, 26181, 11368, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5096, 14430, 15306, 6873, 11806, 2, 3, 1132, 4, 5, 1932, 25128, 3491, 4830, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.050765298306941986, -0.045016612857580185, -0.05560779571533203, -0.05539274215698242, -0.05539274215698242, -0.05539274215698242, -0.05539274215698242, -0.05539274215698242, -0.05539274215698242, -0.05539274215698242], "metadata": {"source_tokens": ["Pro", "##life", "##rative", "nod", "##ules", "are", "usually", "bio", "##ps", "##ied", "and", "are", "regularly", "but", "not", "systematically", "found", "to", "be", "ben", "##ign", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pro", "##life", "##rative", "nod", "##ules", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "regularly", "but", "not", "systematically", "found", "to", "be", "ben", "##ign", "[unused6]", "[SEP]", "[unused1]", "Pro", "##life", "##rative", "nod", "##ules", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "usually", "bio", "##ps", "##ied", "[unused6]", "[SEP]"]]}

input 235:  {"source": "RedHat engineers identified problems with ProPolice though , and in 2005 re-implemented stack-smashing protection for inclusion in GCC 4.1 .\n"}
prediction:  {"predictions": [[1, 2156, 3048, 2980, 9067, 2, 3, 3626, 4, 5, 2645, 1114, 5096, 2101, 14987, 1162, 1463, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1231, 28137, 4060, 7136, 24674, 10926, 28137, 24557, 12802, 3636, 2, 3, 1129, 1111, 10838, 1107, 144, 12096, 125, 28138, 1475, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027874493971467018, -0.13088084757328033, -0.09081315994262695, -0.09431028366088867, -0.09431028366088867, -0.09431028366088867, -0.09431028366088867, -0.09431028366088867, -0.09431028366088867, -0.09431028366088867], "metadata": {"source_tokens": ["Red", "##H", "##at", "engineers", "identified", "problems", "with", "Pro", "##P", "##olic", "##e", "though", ",", "and", "in", "2005", "re", "##-", "##im", "##ple", "##mented", "stack", "##-", "##sma", "##shing", "protection", "for", "inclusion", "in", "G", "##CC", "4", "##.", "##1", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Red", "##H", "##at", "engineers", "[unused2]", "[unused3]", "identified", "[unused4]", "[unused5]", "problems", "with", "Pro", "##P", "##olic", "##e", "though", "[unused6]", "[SEP]", "[unused1]", "re", "##-", "##im", "##ple", "##mented", "stack", "##-", "##sma", "##shing", "protection", "[unused2]", "[unused3]", "be", "for", "inclusion", "in", "G", "##CC", "4", "##.", "##1", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 236:  {"source": "Reptiles identified during surveys include marbled geckos on both island groups while the following are limited to the main island in the Northern group - four-toed earless skink , bull skinks and western brown snakes .\n"}
prediction:  {"predictions": [[1, 20777, 23677, 1116, 2, 3, 3626, 4, 5, 1219, 13634, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20777, 23677, 1116, 3626, 1219, 13634, 2, 3, 1511, 4, 5, 8004, 1181, 176, 14021, 2155, 1113, 1241, 2248, 2114, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1378, 2, 3, 1132, 2609, 4, 5, 1106, 1103, 1514, 2248, 1107, 1103, 2579, 1372, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013277494348585606, -0.07606110721826553, -0.07906462997198105, -0.12767267227172852, -0.13387012481689453, -0.13387012481689453, -0.13387012481689453, -0.13387060165405273, -0.13387012481689453, -0.13387012481689453], "metadata": {"source_tokens": ["Rep", "##tile", "##s", "identified", "during", "surveys", "include", "marble", "##d", "g", "##eck", "##os", "on", "both", "island", "groups", "while", "the", "following", "are", "limited", "to", "the", "main", "island", "in", "the", "Northern", "group", "-", "four", "##-", "##to", "##ed", "earl", "##ess", "skin", "##k", ",", "bull", "skin", "##ks", "and", "western", "brown", "snakes", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rep", "##tile", "##s", "[unused2]", "[unused3]", "identified", "[unused4]", "[unused5]", "during", "surveys", "[unused6]", "[SEP]", "[unused1]", "Rep", "##tile", "##s", "identified", "during", "surveys", "[unused2]", "[unused3]", "include", "[unused4]", "[unused5]", "marble", "##d", "g", "##eck", "##os", "on", "both", "island", "groups", "[unused6]", "[SEP]", "[unused1]", "the", "following", "[unused2]", "[unused3]", "are", "limited", "[unused4]", "[unused5]", "to", "the", "main", "island", "in", "the", "Northern", "group", "[unused6]", "[SEP]"]]}

input 237:  {"source": "Results like these indicate acoustic mimicry complexes , both Batesian and Mullerian , may be widespread in the auditory world .\n"}
prediction:  {"predictions": [[1, 16005, 1176, 1292, 2, 3, 5057, 4, 5, 6659, 27180, 1616, 16575, 117, 1241, 11197, 1811, 1105, 27418, 1811, 117, 1336, 1129, 6506, 1107, 1103, 23097, 4649, 1362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00353232235647738, -0.13094329833984375, -0.12638235092163086, -0.12638235092163086, -0.12638235092163086, -0.12638235092163086, -0.12638235092163086, -0.12638235092163086, -0.12638235092163086, -0.12638235092163086], "metadata": {"source_tokens": ["Results", "like", "these", "indicate", "acoustic", "mimic", "##ry", "complexes", ",", "both", "Bates", "##ian", "and", "Muller", "##ian", ",", "may", "be", "widespread", "in", "the", "audit", "##ory", "world", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Results", "like", "these", "[unused2]", "[unused3]", "indicate", "[unused4]", "[unused5]", "acoustic", "mimic", "##ry", "complexes", ",", "both", "Bates", "##ian", "and", "Muller", "##ian", ",", "may", "be", "widespread", "in", "the", "audit", "##ory", "world", "[unused6]", "[SEP]"]]}

input 238:  {"source": "Returning home , Ballard delivers her report , which her superiors refuse to believe .\n"}
prediction:  {"predictions": [[1, 24241, 2, 3, 19603, 4, 5, 1123, 2592, 117, 1134, 1123, 26917, 10250, 1106, 2059, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0066704219207167625, -0.034859657287597656, -0.03526020050048828, -0.03526020050048828, -0.03526020050048828, -0.03526020050048828, -0.03526020050048828, -0.03526020050048828, -0.03526020050048828, -0.03526020050048828], "metadata": {"source_tokens": ["Returning", "home", ",", "Ballard", "delivers", "her", "report", ",", "which", "her", "superiors", "refuse", "to", "believe", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ballard", "[unused2]", "[unused3]", "delivers", "[unused4]", "[unused5]", "her", "report", ",", "which", "her", "superiors", "refuse", "to", "believe", "[unused6]", "[SEP]"]]}

input 239:  {"source": "Robert Charles `` Jack '' Russell , MBE , is a retired English international cricketer , now known for his abilities as an artist , as a cricket wicketkeeping coach , and a football goalkeeping coach .\n"}
prediction:  {"predictions": [[1, 1823, 1889, 169, 28152, 2132, 112, 28131, 5023, 2, 3, 1110, 4, 5, 170, 2623, 1483, 1835, 9469, 117, 1208, 1227, 1111, 1117, 7134, 1112, 1126, 2360, 117, 1112, 170, 5428, 13386, 14692, 2154, 117, 1105, 170, 1709, 2273, 14692, 2154, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 2623, 1483, 1835, 9469, 2, 3, 1227, 4, 5, 1111, 1117, 7134, 1112, 1126, 2360, 1208, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006981112528592348, -0.10981333255767822, -0.09359121322631836, -0.08933067321777344, -0.08933067321777344, -0.08933067321777344, -0.08933067321777344, -0.08933067321777344, -0.08933067321777344, -0.08933067321777344], "metadata": {"source_tokens": ["Robert", "Charles", "`", "##`", "Jack", "'", "##'", "Russell", ",", "MBE", ",", "is", "a", "retired", "English", "international", "cricketer", ",", "now", "known", "for", "his", "abilities", "as", "an", "artist", ",", "as", "a", "cricket", "wicket", "##keeping", "coach", ",", "and", "a", "football", "goal", "##keeping", "coach", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Robert", "Charles", "`", "##`", "Jack", "'", "##'", "Russell", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "retired", "English", "international", "cricketer", ",", "now", "known", "for", "his", "abilities", "as", "an", "artist", ",", "as", "a", "cricket", "wicket", "##keeping", "coach", ",", "and", "a", "football", "goal", "##keeping", "coach", "[unused6]", "[SEP]", "[unused1]", "a", "retired", "English", "international", "cricketer", "[unused2]", "[unused3]", "known", "[unused4]", "[unused5]", "for", "his", "abilities", "as", "an", "artist", "now", "[unused6]", "[SEP]"]]}

input 240:  {"source": "Rosen argues that one of the most important provisions of the Constitution in Exile is limitations on the interstate commerce clause , which were undermined by the Supreme Court 's `` expansive interpretation of Congress 's power to regulate interstate commerce ... extended to include any activities that might affect commerce indirectly '' during the New Deal .\n"}
prediction:  {"predictions": [[1, 24580, 2, 3, 8935, 4, 5, 1115, 1141, 1104, 1103, 1211, 1696, 8939, 1104, 1103, 5317, 1107, 16409, 4759, 1110, 13004, 1113, 1103, 20905, 10678, 13620, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 20905, 10678, 13620, 2, 3, 1127, 1223, 4, 5, 1118, 1103, 3732, 2031, 112, 1116, 169, 28152, 4252, 10224, 8788, 7628, 1104, 2757, 112, 1116, 1540, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1141, 1104, 1103, 1211, 1696, 8939, 1104, 1103, 5317, 1107, 16409, 4759, 2, 3, 1110, 4, 5, 13004, 1113, 1103, 20905, 10678, 13620, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1141, 1104, 1103, 1211, 1696, 8939, 1104, 1103, 5317, 1107, 16409, 4759, 2, 3, 1110, 4, 5, 13004, 1113, 1103, 20905, 10678, 13620, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 20905, 10678, 13620, 2, 3, 1129, 2925, 4, 5, 1106, 1511, 1251, 2619, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 20905, 10678, 13620, 2, 3, 1127, 1223, 15842, 4, 5, 1118, 1103, 3732, 2031, 112, 1116, 4252, 10224, 8788, 7628, 1104, 2757, 112, 1116, 1540, 1106, 16146, 20905, 10678, 6, 102, 102, 1, 1141, 1104, 1103, 1211, 1696, 8939, 1104, 1103, 5317, 1107, 16409, 4759, 1110, 13004, 2, 3, 1110, 4, 5, 13004, 6, 102, 102, 1, 1141, 1104, 1103, 1211, 1696, 8939, 1104, 1103, 5317, 1107, 16409, 4759, 1110, 13004, 2, 3, 1110, 4, 5, 13004, 6, 102, 102, 1, 1103, 20905, 10678, 13620, 2, 3, 1110, 4, 5, 13004, 6, 102, 102, 102, 102, 102, 102, 1, 1103, 20905, 10678, 13620, 2, 3, 1110, 4, 5, 13004, 6, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013256404548883438, -0.112066850066185, -0.029239578172564507, -0.09052284806966782, -0.22463463246822357, -0.1201227679848671, -0.195065438747406, -0.2271818071603775, -0.3324025273323059, -0.32681068778038025], "metadata": {"source_tokens": ["Rosen", "argues", "that", "one", "of", "the", "most", "important", "provisions", "of", "the", "Constitution", "in", "Ex", "##ile", "is", "limitations", "on", "the", "interstate", "commerce", "clause", ",", "which", "were", "under", "##mined", "by", "the", "Supreme", "Court", "'", "##s", "`", "##`", "ex", "##pan", "##sive", "interpretation", "of", "Congress", "'", "##s", "power", "to", "regulate", "interstate", "commerce", "...", "extended", "to", "include", "any", "activities", "that", "might", "affect", "commerce", "indirectly", "'", "##'", "during", "the", "New", "Deal", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rosen", "[unused2]", "[unused3]", "argues", "[unused4]", "[unused5]", "that", "one", "of", "the", "most", "important", "provisions", "of", "the", "Constitution", "in", "Ex", "##ile", "is", "limitations", "on", "the", "interstate", "commerce", "clause", "[unused6]", "[SEP]", "[unused1]", "the", "interstate", "commerce", "clause", "[unused2]", "[unused3]", "were", "under", "[unused4]", "[unused5]", "by", "the", "Supreme", "Court", "'", "##s", "`", "##`", "ex", "##pan", "##sive", "interpretation", "of", "Congress", "'", "##s", "power", "[unused6]", "[SEP]", "[unused1]", "one", "of", "the", "most", "important", "provisions", "of", "the", "Constitution", "in", "Ex", "##ile", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "limitations", "on", "the", "interstate", "commerce", "clause", "[unused6]", "[SEP]", "[unused1]", "one", "of", "the", "most", "important", "provisions", "of", "the", "Constitution", "in", "Ex", "##ile", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "limitations", "on", "the", "interstate", "commerce", "clause", "[unused6]", "[SEP]", "[unused1]", "the", "interstate", "commerce", "clause", "[unused2]", "[unused3]", "be", "extended", "[unused4]", "[unused5]", "to", "include", "any", "activities", "[unused6]", "[SEP]", "[unused1]", "the", "interstate", "commerce", "clause", "[unused2]", "[unused3]", "were", "under", "##mined", "[unused4]", "[unused5]", "by", "the", "Supreme", "Court", "'", "##s", "ex", "##pan", "##sive", "interpretation", "of", "Congress", "'", "##s", "power", "to", "regulate", "interstate", "commerce", "[unused6]", "[SEP]", "[unused1]", "one", "of", "the", "most", "important", "provisions", "of", "the", "Constitution", "in", "Ex", "##ile", "is", "limitations", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "limitations", "[unused6]", "[SEP]", "[unused1]", "one", "of", "the", "most", "important", "provisions", "of", "the", "Constitution", "in", "Ex", "##ile", "is", "limitations", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "limitations", "[unused6]", "[SEP]", "[unused1]", "the", "interstate", "commerce", "clause", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "limitations", "[unused6]", "[SEP]", "[unused1]", "the", "interstate", "commerce", "clause", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "limitations", "[unused6]", "[SEP]"]]}

input 241:  {"source": "San Francisco 's diversity of cultures along with its eccentricities are so great that they have greatly influenced the country and the world at large over the years .\n"}
prediction:  {"predictions": [[1, 1727, 2948, 112, 1116, 9531, 1104, 8708, 1373, 1114, 1157, 20276, 4233, 2, 3, 1132, 4, 5, 1177, 1632, 1115, 1152, 1138, 5958, 4401, 1103, 1583, 1105, 1103, 1362, 1120, 1415, 1166, 1103, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1138, 4401, 4, 5, 1103, 1583, 1105, 1103, 1362, 1120, 1415, 1166, 1103, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012245547957718372, -0.03173796087503433, -0.18173456192016602, -0.17731428146362305, -0.17731380462646484, -0.17731380462646484, -0.17731380462646484, -0.17731428146362305, -0.17731380462646484, -0.17731380462646484], "metadata": {"source_tokens": ["San", "Francisco", "'", "##s", "diversity", "of", "cultures", "along", "with", "its", "eccentric", "##ities", "are", "so", "great", "that", "they", "have", "greatly", "influenced", "the", "country", "and", "the", "world", "at", "large", "over", "the", "years", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "San", "Francisco", "'", "##s", "diversity", "of", "cultures", "along", "with", "its", "eccentric", "##ities", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "so", "great", "that", "they", "have", "greatly", "influenced", "the", "country", "and", "the", "world", "at", "large", "over", "the", "years", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "have", "influenced", "[unused4]", "[unused5]", "the", "country", "and", "the", "world", "at", "large", "over", "the", "years", "[unused6]", "[SEP]"]]}

input 242:  {"source": "Scarpetta returns to Virginia in `` Trace '' , convincing herself that she was fired from her position , at the request of her replacement , Dr. Joel Marcus .\n"}
prediction:  {"predictions": [[1, 20452, 1813, 12924, 1777, 2, 3, 5166, 4, 5, 1106, 2550, 1107, 22681, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20452, 1813, 12924, 1777, 2, 3, 13870, 4, 5, 1941, 1115, 1131, 1108, 4294, 1121, 1123, 1700, 117, 1120, 1103, 4566, 1104, 1123, 5627, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1108, 4294, 4, 5, 1121, 1123, 1700, 1120, 1103, 4566, 1104, 1123, 5627, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.083375945687294, -0.06799525767564774, -0.09712183475494385, -0.23119115829467773, -0.2274031639099121, -0.2274031639099121, -0.2274031639099121, -0.2274026870727539, -0.2274031639099121, -0.2274031639099121], "metadata": {"source_tokens": ["Sc", "##ar", "##pet", "##ta", "returns", "to", "Virginia", "in", "`", "##`", "Trace", "'", "##'", ",", "convincing", "herself", "that", "she", "was", "fired", "from", "her", "position", ",", "at", "the", "request", "of", "her", "replacement", ",", "Dr", "##.", "Joel", "Marcus", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sc", "##ar", "##pet", "##ta", "[unused2]", "[unused3]", "returns", "[unused4]", "[unused5]", "to", "Virginia", "in", "Trace", "[unused6]", "[SEP]", "[unused1]", "Sc", "##ar", "##pet", "##ta", "[unused2]", "[unused3]", "convincing", "[unused4]", "[unused5]", "herself", "that", "she", "was", "fired", "from", "her", "position", ",", "at", "the", "request", "of", "her", "replacement", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "was", "fired", "[unused4]", "[unused5]", "from", "her", "position", "at", "the", "request", "of", "her", "replacement", "[unused6]", "[SEP]"]]}

input 243:  {"source": "Several isomers of octene are known , depending on the position and the geometry of the double bond in the carbon chain .\n"}
prediction:  {"predictions": [[1, 3728, 1110, 23806, 1116, 1104, 184, 5822, 7582, 2, 3, 1132, 1227, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3728, 1110, 23806, 1116, 1104, 184, 5822, 7582, 2, 3, 5763, 4, 5, 1113, 1103, 1700, 1105, 1103, 12053, 1104, 1103, 2702, 7069, 1107, 1103, 6302, 4129, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.038798052817583084, -0.020272009074687958, -0.10672807693481445, -0.1020050048828125, -0.1020050048828125, -0.1020050048828125, -0.1020050048828125, -0.1020050048828125, -0.1020050048828125, -0.1020050048828125], "metadata": {"source_tokens": ["Several", "is", "##omer", "##s", "of", "o", "##ct", "##ene", "are", "known", ",", "depending", "on", "the", "position", "and", "the", "geometry", "of", "the", "double", "bond", "in", "the", "carbon", "chain", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Several", "is", "##omer", "##s", "of", "o", "##ct", "##ene", "[unused2]", "[unused3]", "are", "known", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Several", "is", "##omer", "##s", "of", "o", "##ct", "##ene", "[unused2]", "[unused3]", "depending", "[unused4]", "[unused5]", "on", "the", "position", "and", "the", "geometry", "of", "the", "double", "bond", "in", "the", "carbon", "chain", "[unused6]", "[SEP]"]]}

input 244:  {"source": "She died in October 1915 of a heart attack .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 1452, 4, 5, 1107, 1357, 4135, 1104, 170, 1762, 2035, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1153, 2, 3, 1452, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00016576796770095825, -0.012100103311240673, -0.05325794219970703, -0.05461597442626953, -0.05461597442626953, -0.05461597442626953, -0.05461597442626953, -0.05461597442626953, -0.05461597442626953, -0.05461597442626953], "metadata": {"source_tokens": ["She", "died", "in", "October", "1915", "of", "a", "heart", "attack", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "died", "[unused4]", "[unused5]", "in", "October", "1915", "of", "a", "heart", "attack", "[unused6]", "[SEP]", "[unused1]", "She", "[unused2]", "[unused3]", "died", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 245:  {"source": "She provided an audio commentary for the episode on the DVD release of the show 's third series alongside David Tennant .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 2136, 4, 5, 1126, 6056, 9068, 1111, 1103, 2004, 1113, 1103, 4173, 1836, 1104, 1103, 1437, 112, 1116, 1503, 1326, 3338, 1681, 5157, 14618, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-9.193817822961137e-05, -0.07868623733520508, -0.07917308807373047, -0.07917308807373047, -0.07917308807373047, -0.07917308807373047, -0.07917308807373047, -0.07917308807373047, -0.07917308807373047, -0.07917308807373047], "metadata": {"source_tokens": ["She", "provided", "an", "audio", "commentary", "for", "the", "episode", "on", "the", "DVD", "release", "of", "the", "show", "'", "##s", "third", "series", "alongside", "David", "Ten", "##nant", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "provided", "[unused4]", "[unused5]", "an", "audio", "commentary", "for", "the", "episode", "on", "the", "DVD", "release", "of", "the", "show", "'", "##s", "third", "series", "alongside", "David", "Ten", "##nant", "[unused6]", "[SEP]"]]}

input 246:  {"source": "She published more than 15 research publications , including International Journals , International Conferences , National Conferences , workshops and seminars .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 1502, 4, 5, 1167, 1190, 1405, 1844, 5873, 117, 1259, 1570, 3603, 1116, 117, 1570, 3047, 1116, 117, 1305, 3047, 1116, 117, 10158, 1105, 19898, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0004433979047462344, -0.0333409309387207, -0.03461742401123047, -0.03461742401123047, -0.03461742401123047, -0.03461742401123047, -0.03461742401123047, -0.03461742401123047, -0.03461742401123047, -0.03461742401123047], "metadata": {"source_tokens": ["She", "published", "more", "than", "15", "research", "publications", ",", "including", "International", "Journal", "##s", ",", "International", "Conference", "##s", ",", "National", "Conference", "##s", ",", "workshops", "and", "seminars", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "published", "[unused4]", "[unused5]", "more", "than", "15", "research", "publications", ",", "including", "International", "Journal", "##s", ",", "International", "Conference", "##s", ",", "National", "Conference", "##s", ",", "workshops", "and", "seminars", "[unused6]", "[SEP]"]]}

input 247:  {"source": "She returned to that Thames River base 9 February 1931 and for the remainder of the decade served as a training ship primarily for the Submarine School at New London and occasionally for NROTC units in the southern New England area .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 1608, 4, 5, 1106, 1115, 11055, 1595, 2259, 130, 1428, 3916, 1105, 1111, 1103, 6311, 1104, 1103, 4967, 1462, 1112, 170, 2013, 2062, 3120, 1111, 1103, 26399, 1323, 1120, 1203, 1498, 1105, 5411, 1111, 151, 21564, 9481, 2338, 1107, 1103, 2359, 1203, 1652, 1298, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.018798058852553368, -0.31954526901245117, -0.28157520294189453, -0.28157520294189453, -0.28157520294189453, -0.28157520294189453, -0.28157520294189453, -0.28157520294189453, -0.28157520294189453, -0.28157520294189453], "metadata": {"source_tokens": ["She", "returned", "to", "that", "Thames", "River", "base", "9", "February", "1931", "and", "for", "the", "remainder", "of", "the", "decade", "served", "as", "a", "training", "ship", "primarily", "for", "the", "Submarine", "School", "at", "New", "London", "and", "occasionally", "for", "N", "##RO", "##TC", "units", "in", "the", "southern", "New", "England", "area", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "returned", "[unused4]", "[unused5]", "to", "that", "Thames", "River", "base", "9", "February", "1931", "and", "for", "the", "remainder", "of", "the", "decade", "served", "as", "a", "training", "ship", "primarily", "for", "the", "Submarine", "School", "at", "New", "London", "and", "occasionally", "for", "N", "##RO", "##TC", "units", "in", "the", "southern", "New", "England", "area", "[unused6]", "[SEP]"]]}

input 248:  {"source": "She was ordered to be rebuilt on 9 March 1724 , and was taken in hand at Deptford Dockyard by Master Shipwright Richard Stacey .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 1108, 2802, 4, 5, 1106, 1129, 6669, 1113, 130, 1345, 19639, 1527, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1153, 2, 3, 1108, 1678, 4, 5, 1107, 1289, 1120, 3177, 6451, 2821, 20115, 8624, 1118, 3257, 12863, 12723, 2055, 21807, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.010624666698276997, -0.011103578843176365, -0.01923370361328125, -0.019539356231689453, -0.019539356231689453, -0.019539356231689453, -0.019539356231689453, -0.019539356231689453, -0.019539356231689453, -0.019539356231689453], "metadata": {"source_tokens": ["She", "was", "ordered", "to", "be", "rebuilt", "on", "9", "March", "172", "##4", ",", "and", "was", "taken", "in", "hand", "at", "De", "##pt", "##ford", "Dock", "##yard", "by", "Master", "Ship", "##wright", "Richard", "Stacey", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "was", "ordered", "[unused4]", "[unused5]", "to", "be", "rebuilt", "on", "9", "March", "172", "##4", "[unused6]", "[SEP]", "[unused1]", "She", "[unused2]", "[unused3]", "was", "taken", "[unused4]", "[unused5]", "in", "hand", "at", "De", "##pt", "##ford", "Dock", "##yard", "by", "Master", "Ship", "##wright", "Richard", "Stacey", "[unused6]", "[SEP]"]]}

input 249:  {"source": "Shea was born on September 5 , 1900 in San Francisco , California .\n"}
prediction:  {"predictions": [[1, 18352, 2, 3, 1108, 1255, 4, 5, 1113, 1347, 126, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.044795989990234375, -0.13139629364013672, -0.12589120864868164, -0.12589120864868164, -0.12589120864868164, -0.12589120864868164, -0.12589120864868164, -0.12589120864868164, -0.12589120864868164, -0.12589120864868164], "metadata": {"source_tokens": ["Shea", "was", "born", "on", "September", "5", ",", "1900", "in", "San", "Francisco", ",", "California", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Shea", "[unused2]", "[unused3]", "was", "born", "[unused4]", "[unused5]", "on", "September", "5", "[unused6]", "[SEP]"]]}

input 250:  {"source": "Since joining the competition in 1908 , Richmond has won ten premierships , the most recent victory being in 1980 .\n"}
prediction:  {"predictions": [[1, 1103, 1211, 2793, 2681, 2, 3, 1217, 4, 5, 1107, 2253, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6110, 2, 3, 1144, 1281, 4, 5, 1995, 18262, 1116, 1967, 4577, 1103, 2208, 1107, 4536, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04666789993643761, -0.03958522528409958, -0.2402205467224121, -0.23333120346069336, -0.23333120346069336, -0.23333120346069336, -0.23333120346069336, -0.23333120346069336, -0.23333120346069336, -0.23333120346069336], "metadata": {"source_tokens": ["Since", "joining", "the", "competition", "in", "1908", ",", "Richmond", "has", "won", "ten", "premiership", "##s", ",", "the", "most", "recent", "victory", "being", "in", "1980", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "most", "recent", "victory", "[unused2]", "[unused3]", "being", "[unused4]", "[unused5]", "in", "1980", "[unused6]", "[SEP]", "[unused1]", "Richmond", "[unused2]", "[unused3]", "has", "won", "[unused4]", "[unused5]", "ten", "premiership", "##s", "Since", "joining", "the", "competition", "in", "1908", "[unused6]", "[SEP]"]]}

input 251:  {"source": "Sometimes extra payments were specified by which a freed slave could liberate himself from these residual duties .\n"}
prediction:  {"predictions": [[1, 3908, 10772, 2, 3, 1127, 9467, 4, 5, 1118, 1134, 170, 11485, 6748, 1180, 181, 24851, 2193, 1471, 1121, 1292, 25399, 5078, 5875, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 11485, 6748, 2, 3, 1180, 181, 24851, 2193, 4, 5, 1471, 1121, 1292, 25399, 5078, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.016976283863186836, -0.04893225058913231, -0.09700536727905273, -0.09032678604125977, -0.09032678604125977, -0.09032678604125977, -0.09032678604125977, -0.09032678604125977, -0.09032678604125977, -0.09032678604125977], "metadata": {"source_tokens": ["Sometimes", "extra", "payments", "were", "specified", "by", "which", "a", "freed", "slave", "could", "l", "##iber", "##ate", "himself", "from", "these", "residual", "duties", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "extra", "payments", "[unused2]", "[unused3]", "were", "specified", "[unused4]", "[unused5]", "by", "which", "a", "freed", "slave", "could", "l", "##iber", "##ate", "himself", "from", "these", "residual", "duties", "Sometimes", "[unused6]", "[SEP]", "[unused1]", "a", "freed", "slave", "[unused2]", "[unused3]", "could", "l", "##iber", "##ate", "[unused4]", "[unused5]", "himself", "from", "these", "residual", "duties", "[unused6]", "[SEP]"]]}

input 252:  {"source": "Specifically , knowledge and interest in the event affects the level of personal importance for the individual , which also affects the individual 's level of emotional arousal .\n"}
prediction:  {"predictions": [[1, 1103, 2510, 2, 3, 13974, 4, 5, 1103, 2510, 112, 1116, 1634, 1104, 6438, 21019, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3044, 1105, 2199, 1107, 1103, 1856, 2, 3, 13974, 4, 5, 1103, 1634, 1104, 2357, 4495, 1111, 1103, 2510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05530063807964325, -0.009072021581232548, -0.05581378936767578, -0.0552830696105957, -0.0552830696105957, -0.0552830696105957, -0.0552830696105957, -0.0552830696105957, -0.0552830696105957, -0.0552830696105957], "metadata": {"source_tokens": ["Specifically", ",", "knowledge", "and", "interest", "in", "the", "event", "affects", "the", "level", "of", "personal", "importance", "for", "the", "individual", ",", "which", "also", "affects", "the", "individual", "'", "##s", "level", "of", "emotional", "arousal", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "individual", "[unused2]", "[unused3]", "affects", "[unused4]", "[unused5]", "the", "individual", "'", "##s", "level", "of", "emotional", "arousal", "[unused6]", "[SEP]", "[unused1]", "knowledge", "and", "interest", "in", "the", "event", "[unused2]", "[unused3]", "affects", "[unused4]", "[unused5]", "the", "level", "of", "personal", "importance", "for", "the", "individual", "[unused6]", "[SEP]"]]}

input 253:  {"source": "Spennymoor Town F.C. are the main local football team and won the FA Carlsberg Vase , after winning 2-1 in the final at Wembley Stadium against Tunbridge Wells in May 2013 .\n"}
prediction:  {"predictions": [[1, 156, 11741, 3382, 19216, 2779, 143, 28138, 1658, 28138, 2, 3, 1132, 4, 5, 1103, 1514, 1469, 1709, 1264, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 156, 11741, 3382, 19216, 2779, 143, 28138, 1658, 28138, 2, 3, 1281, 4, 5, 1103, 6820, 4804, 19945, 159, 6530, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 156, 11741, 3382, 19216, 2779, 143, 28138, 1658, 28138, 2, 3, 1281, 4, 5, 1103, 6820, 4804, 19945, 159, 6530, 1170, 2183, 123, 28137, 1475, 1107, 1103, 1509, 1120, 17593, 3339, 1222, 17037, 24416, 7909, 1107, 1318, 1381, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012683234177529812, -0.046692851930856705, -0.34355831146240234, -0.06274502724409103, -0.056360721588134766, -0.05886983871459961, -0.05886983871459961, -0.058869361877441406, -0.058869361877441406, -0.05886983871459961], "metadata": {"source_tokens": ["S", "##pen", "##ny", "##moor", "Town", "F", "##.", "##C", "##.", "are", "the", "main", "local", "football", "team", "and", "won", "the", "FA", "Carl", "##sberg", "V", "##ase", ",", "after", "winning", "2", "##-", "##1", "in", "the", "final", "at", "Wembley", "Stadium", "against", "Tu", "##nbridge", "Wells", "in", "May", "2013", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "S", "##pen", "##ny", "##moor", "Town", "F", "##.", "##C", "##.", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "the", "main", "local", "football", "team", "[unused6]", "[SEP]", "[unused1]", "S", "##pen", "##ny", "##moor", "Town", "F", "##.", "##C", "##.", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "the", "FA", "Carl", "##sberg", "V", "##ase", "[unused6]", "[SEP]"]]}

input 254:  {"source": "Sukhum functioned as the capital of the `` Union treaty '' Abkhaz Soviet Socialist Republic associated with the Georgian SSR from 1921 until 1931 , when it became the capital of the Abkhazian Autonomous Soviet Socialist Republic within the Georgian SSR .\n"}
prediction:  {"predictions": [[1, 15463, 9862, 1818, 2, 3, 22937, 4, 5, 1112, 1103, 2364, 1104, 1103, 169, 28152, 1913, 7274, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2364, 1104, 1103, 169, 28152, 1913, 7274, 112, 28131, 138, 1830, 14457, 1584, 2461, 7365, 2250, 2, 3, 2628, 4, 5, 1114, 1103, 8832, 22916, 1121, 4085, 1235, 3916, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1245, 4, 5, 1103, 2364, 1104, 1103, 138, 1830, 14457, 12432, 1179, 16742, 2461, 7365, 2250, 1439, 1103, 8832, 22916, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05012958124279976, -0.10934172570705414, -0.039930444210767746, -0.05968332290649414, -0.057847023010253906, -0.057847023010253906, -0.057847023010253906, -0.057847023010253906, -0.057847023010253906, -0.057847023010253906], "metadata": {"source_tokens": ["Su", "##kh", "##um", "functioned", "as", "the", "capital", "of", "the", "`", "##`", "Union", "treaty", "'", "##'", "A", "##b", "##kha", "##z", "Soviet", "Socialist", "Republic", "associated", "with", "the", "Georgian", "SSR", "from", "1921", "until", "1931", ",", "when", "it", "became", "the", "capital", "of", "the", "A", "##b", "##kha", "##zia", "##n", "Autonomous", "Soviet", "Socialist", "Republic", "within", "the", "Georgian", "SSR", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Su", "##kh", "##um", "[unused2]", "[unused3]", "functioned", "[unused4]", "[unused5]", "as", "the", "capital", "of", "the", "`", "##`", "Union", "treaty", "[unused6]", "[SEP]", "[unused1]", "the", "capital", "of", "the", "`", "##`", "Union", "treaty", "'", "##'", "A", "##b", "##kha", "##z", "Soviet", "Socialist", "Republic", "[unused2]", "[unused3]", "associated", "[unused4]", "[unused5]", "with", "the", "Georgian", "SSR", "from", "1921", "until", "1931", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "the", "capital", "of", "the", "A", "##b", "##kha", "##zia", "##n", "Autonomous", "Soviet", "Socialist", "Republic", "within", "the", "Georgian", "SSR", "[unused6]", "[SEP]"]]}

input 255:  {"source": "Superboy-Prime , seeing an opportunity to defeat the now-weakened Anti-Monitor , flew through the Anti-Monitor 's chest and hurled his shattered body into space .\n"}
prediction:  {"predictions": [[1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 4843, 4, 5, 1194, 1103, 8329, 28137, 2107, 11153, 2772, 112, 1116, 2229, 1105, 27060, 1117, 11670, 1404, 1154, 2000, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 3195, 4, 5, 1126, 3767, 1106, 3326, 1103, 1208, 28137, 7921, 9899, 3540, 8329, 28137, 2107, 11153, 2772, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.047958794981241226, -0.02023802511394024, -0.042883872985839844, -0.042308807373046875, -0.042308807373046875, -0.042308807373046875, -0.042308807373046875, -0.042308807373046875, -0.042308807373046875, -0.042308807373046875], "metadata": {"source_tokens": ["Super", "##boy", "##-", "##P", "##rim", "##e", ",", "seeing", "an", "opportunity", "to", "defeat", "the", "now", "##-", "##we", "##ake", "##ned", "Anti", "##-", "##M", "##oni", "##tor", ",", "flew", "through", "the", "Anti", "##-", "##M", "##oni", "##tor", "'", "##s", "chest", "and", "hurled", "his", "shattered", "body", "into", "space", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "flew", "[unused4]", "[unused5]", "through", "the", "Anti", "##-", "##M", "##oni", "##tor", "'", "##s", "chest", "and", "hurled", "his", "shattered", "body", "into", "space", "[unused6]", "[SEP]", "[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "seeing", "[unused4]", "[unused5]", "an", "opportunity", "to", "defeat", "the", "now", "##-", "##we", "##ake", "##ned", "Anti", "##-", "##M", "##oni", "##tor", "[unused6]", "[SEP]"]]}

Batch 2 Test Time =  42.78287172317505  s
Decodertime : 0.00017380714416503906
g_f_logprobs : 0.04289579391479492
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.04288959503173828
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.042836904525756836
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.042894840240478516
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.042923688888549805
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.04296398162841797
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.04291510581970215
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.0429234504699707
Decodertime : 0.00017261505126953125
g_f_logprobs : 0.0428462028503418
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.04292559623718262
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.042833805084228516
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.042938947677612305
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.04291272163391113
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.042908668518066406
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.042916059494018555
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.04299473762512207
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.04301857948303223
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.04290771484375
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.042940378189086914
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.042936086654663086
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.04295969009399414
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.042951345443725586
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.04299592971801758
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.04320168495178223
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.04285025596618652
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.04300284385681152
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.04296278953552246
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.04293203353881836
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.04302668571472168
Decodertime : 0.00017142295837402344
g_f_logprobs : 0.04304766654968262
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.04293346405029297
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.04295992851257324
Decodertime : 0.000152587890625
g_f_logprobs : 0.04293346405029297
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.04288768768310547
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.04288077354431152
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.04317665100097656
Decodertime : 0.00016021728515625
g_f_logprobs : 0.04293012619018555
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.0429234504699707
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.04296994209289551
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.042955875396728516
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.042932987213134766
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.04304814338684082
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.04303312301635742
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.04302859306335449
Decodertime : 0.000152587890625
g_f_logprobs : 0.04296755790710449
Decodertime : 0.000152587890625
g_f_logprobs : 0.04308819770812988
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.04297447204589844
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.04303288459777832
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.04315686225891113
Decodertime : 0.000152587890625
g_f_logprobs : 0.04314017295837402
beam_search_time: 2.2432382106781006 s
Decodertime : 0.00018858909606933594
g_f_logprobs : 0.07031822204589844
Decodertime : 0.000164031982421875
g_f_logprobs : 0.07025480270385742
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.07039427757263184
Decodertime : 0.0001766681671142578
g_f_logprobs : 0.07037711143493652
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.07043719291687012
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.07031130790710449
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.07027578353881836
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.07052898406982422
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.07029485702514648
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.07029342651367188
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.07033324241638184
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.0706026554107666
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.07047080993652344
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.07061004638671875
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.07056212425231934
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.07019209861755371
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.0703134536743164
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.07020115852355957
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.07035040855407715
Decodertime : 0.000152587890625
g_f_logprobs : 0.07038068771362305
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.07040715217590332
Decodertime : 0.00017309188842773438
g_f_logprobs : 0.07052183151245117
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.07030367851257324
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.07036995887756348
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.07029008865356445
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.07032179832458496
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.0703725814819336
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.07054328918457031
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.07055330276489258
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.07034087181091309
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.07081055641174316
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.07039070129394531
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.07038593292236328
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.07030463218688965
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.07043719291687012
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.07046222686767578
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.07041764259338379
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.07057642936706543
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.07047319412231445
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.07015728950500488
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.07047247886657715
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.07042622566223145
Decodertime : 0.00017213821411132812
g_f_logprobs : 0.07021665573120117
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.07067418098449707
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.07055163383483887
Decodertime : 0.000152587890625
g_f_logprobs : 0.07050871849060059
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.07062077522277832
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.07038307189941406
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.07046127319335938
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.07036852836608887
beam_search_time: 3.615666389465332 s
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.08570289611816406
Decodertime : 0.0001678466796875
g_f_logprobs : 0.08546185493469238
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.08604097366333008
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.08588004112243652
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.08556008338928223
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.08581995964050293
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.08561563491821289
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.08529996871948242
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.0858149528503418
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.0857086181640625
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.08572053909301758
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.08586311340332031
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.08572244644165039
Decodertime : 0.00017142295837402344
g_f_logprobs : 0.08569860458374023
Decodertime : 0.000152587890625
g_f_logprobs : 0.08562111854553223
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.08562397956848145
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.08576822280883789
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.08568310737609863
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.08580851554870605
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.0858461856842041
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.08584952354431152
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.0859067440032959
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.08576774597167969
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.08578348159790039
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.0858449935913086
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.0857396125793457
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.08577156066894531
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.08577799797058105
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.08571338653564453
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.08577871322631836
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.08568120002746582
beam_search_time: 2.716817617416382 s
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.10312485694885254
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.10310935974121094
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.10307812690734863
Decodertime : 0.00017309188842773438
g_f_logprobs : 0.10305571556091309
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.1036829948425293
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10311484336853027
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.1032419204711914
Decodertime : 0.000152587890625
g_f_logprobs : 0.10326051712036133
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.10316896438598633
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.10314393043518066
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.10312509536743164
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.10302019119262695
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.10294556617736816
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.10320520401000977
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.10303068161010742
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.10312891006469727
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.1031036376953125
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.10324811935424805
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.10352039337158203
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.1029961109161377
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.10294413566589355
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10306358337402344
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.10311460494995117
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.10308551788330078
Decodertime : 0.00017142295837402344
g_f_logprobs : 0.1028895378112793
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.10330653190612793
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10329198837280273
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.10352873802185059
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.10361862182617188
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.10370278358459473
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.10355424880981445
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.10362434387207031
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10370683670043945
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.10367202758789062
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.10358572006225586
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.10380697250366211
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.10366082191467285
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.10357308387756348
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10354447364807129
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.10376858711242676
beam_search_time: 4.208557367324829 s
Decodertime : 0.00016689300537109375
g_f_logprobs : 0.10453438758850098
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.10451698303222656
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.10445070266723633
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.10469651222229004
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.10465455055236816
Decodertime : 0.00017690658569335938
g_f_logprobs : 0.10432171821594238
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.10460615158081055
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.10461688041687012
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.10458850860595703
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.1044919490814209
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.10465335845947266
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.10440397262573242
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.10462021827697754
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10431432723999023
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10457491874694824
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.10474729537963867
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.10463595390319824
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.10452747344970703
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.10482668876647949
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.10447120666503906
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.10460114479064941
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10548233985900879
Decodertime : 0.00022721290588378906
g_f_logprobs : 0.10463786125183105
Decodertime : 0.000152587890625
g_f_logprobs : 0.1046135425567627
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10473227500915527
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.10447192192077637
Decodertime : 0.00017261505126953125
g_f_logprobs : 0.10458564758300781
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10455513000488281
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.10461068153381348
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.1046149730682373
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.10486626625061035
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10459041595458984
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.10441446304321289
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.10444235801696777
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.10493230819702148
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.10481452941894531
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10495519638061523
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10473418235778809
Decodertime : 0.000152587890625
g_f_logprobs : 0.10459375381469727
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.10469269752502441
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10481715202331543
Decodertime : 0.000152587890625
g_f_logprobs : 0.10475516319274902
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.10498213768005371
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.10455727577209473
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.10471582412719727
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.1046910285949707
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.10472273826599121
Decodertime : 0.0001735687255859375
g_f_logprobs : 0.10461783409118652
Decodertime : 0.000152587890625
g_f_logprobs : 0.1048431396484375
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.10449957847595215
beam_search_time: 5.327970027923584 s
Decodertime : 0.00017380714416503906
g_f_logprobs : 0.13239455223083496
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.13145709037780762
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.1319715976715088
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.13219308853149414
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.1315479278564453
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.13153648376464844
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.13147187232971191
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.13179278373718262
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.13161635398864746
Decodertime : 0.000152587890625
g_f_logprobs : 0.13179922103881836
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.13322210311889648
Decodertime : 0.00018596649169921875
g_f_logprobs : 0.13179445266723633
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.13167572021484375
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.13194966316223145
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.13240361213684082
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.1318378448486328
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.13192200660705566
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.1318507194519043
Decodertime : 0.0001709461212158203
g_f_logprobs : 0.13146018981933594
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.13204479217529297
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.13167357444763184
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.13178396224975586
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.13181686401367188
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.13190865516662598
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.13176441192626953
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.13203787803649902
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.13181209564208984
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.13218259811401367
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.13193297386169434
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.1319255828857422
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.1319715976715088
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.1318511962890625
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.13193964958190918
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.13206124305725098
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.1318645477294922
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.13193678855895996
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.1319284439086914
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.1319866180419922
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.13181185722351074
Decodertime : 0.0001747608184814453
g_f_logprobs : 0.1319293975830078
Decodertime : 0.00016021728515625
g_f_logprobs : 0.13169527053833008
beam_search_time: 5.486198902130127 s
Decodertime : 0.00017523765563964844
g_f_logprobs : 0.15300321578979492
Decodertime : 0.00016999244689941406
g_f_logprobs : 0.1533799171447754
Decodertime : 0.0001709461212158203
g_f_logprobs : 0.15303349494934082
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.15317296981811523
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.1531982421875
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.15285897254943848
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.152923583984375
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.15280747413635254
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.1531667709350586
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.1528770923614502
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.15297937393188477
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.15281176567077637
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.1530437469482422
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.15326237678527832
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.1527700424194336
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.15303826332092285
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.15292072296142578
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.1531822681427002
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.15314745903015137
Decodertime : 0.00017976760864257812
g_f_logprobs : 0.1526775360107422
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.1532137393951416
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.1528911590576172
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.1531691551208496
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.15303611755371094
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.15364336967468262
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.15321111679077148
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.15311598777770996
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.15322279930114746
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.15299081802368164
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.15285253524780273
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.15283513069152832
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.15332555770874023
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.15277719497680664
Decodertime : 0.000152587890625
g_f_logprobs : 0.15276741981506348
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.15305233001708984
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.1529526710510254
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.15289640426635742
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.1530160903930664
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.15322279930114746
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.1529219150543213
Decodertime : 0.00016999244689941406
g_f_logprobs : 0.15286779403686523
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.15301728248596191
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.15287137031555176
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.1530604362487793
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.15325093269348145
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.1532459259033203
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.15294885635375977
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.1530919075012207
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.15292000770568848
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.15304160118103027
beam_search_time: 7.747582912445068 s
Decodertime : 0.0001685619354248047
g_f_logprobs : 0.16193079948425293
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.16167330741882324
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.16189193725585938
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.16162633895874023
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.1614985466003418
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.16154241561889648
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.1614844799041748
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.1616833209991455
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.1616215705871582
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.1615886688232422
Decodertime : 0.000148773193359375
g_f_logprobs : 0.1616652011871338
Decodertime : 0.00017023086547851562
g_f_logprobs : 0.161881685256958
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.16153812408447266
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.16145038604736328
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.16176152229309082
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.16136717796325684
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.16144967079162598
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.16165804862976074
Decodertime : 0.000152587890625
g_f_logprobs : 0.16167736053466797
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.16157054901123047
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.1620652675628662
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.16156220436096191
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.16172456741333008
Decodertime : 0.00014829635620117188
g_f_logprobs : 0.16156721115112305
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.16135811805725098
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.16142535209655762
Decodertime : 0.000152587890625
g_f_logprobs : 0.16174674034118652
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.16150164604187012
Decodertime : 0.000152587890625
g_f_logprobs : 0.16170859336853027
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.16202092170715332
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.16168808937072754
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.16156435012817383
Decodertime : 0.00017523765563964844
g_f_logprobs : 0.16158175468444824
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.1618642807006836
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.16159868240356445
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.16184473037719727
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.1615147590637207
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.16150355339050293
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.16152119636535645
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.16151094436645508
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.16127634048461914
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.1617422103881836
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.16175603866577148
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.161696195602417
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.16217827796936035
Decodertime : 0.000152587890625
g_f_logprobs : 0.16164278984069824
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.16159939765930176
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.16167545318603516
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.1614835262298584
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.16140460968017578
beam_search_time: 8.177587747573853 s
Decodertime : 0.00017333030700683594
g_f_logprobs : 0.18588781356811523
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.18518590927124023
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.1853773593902588
Decodertime : 0.0001723766326904297
g_f_logprobs : 0.18505597114562988
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.18485426902770996
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.18539762496948242
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.18532061576843262
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.1851205825805664
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.18547534942626953
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.18523740768432617
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.1850271224975586
beam_search_time: 2.059035301208496 s
Decodertime : 0.00017833709716796875
g_f_logprobs : 0.18559741973876953
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.18488264083862305
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.1851027011871338
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.18481659889221191
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.18510222434997559
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.1847703456878662
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.1851658821105957
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.18490362167358398
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.18517613410949707
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.18522262573242188
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.18489766120910645
beam_search_time: 2.0567750930786133 s
input 256:  {"source": "Swinburne moves in his writing program from the philosophical to the theological , building his case rigorously .\n"}
prediction:  {"predictions": [[1, 156, 7445, 26980, 2, 3, 5279, 4, 5, 1107, 1117, 2269, 1788, 1121, 1103, 11388, 1106, 1103, 14757, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 156, 7445, 26980, 2, 3, 5279, 4, 5, 1107, 1117, 2269, 1788, 1459, 1117, 1692, 22112, 1193, 22112, 1193, 22112, 1193, 22112, 1193, 22112, 1193, 22112, 1193, 22112, 1193, 22112, 1193, 22112, 1193, 22112, 1193, 22112, 1193, 22112, 1193, 22112, 1193, 22112, 1193, 6, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0035125981085002422, -0.20855049788951874, -0.07001304626464844, -0.06908369064331055, -0.06908369064331055, -0.06908369064331055, -0.06908369064331055, -0.06908369064331055, -0.06908369064331055, -0.06908369064331055], "metadata": {"source_tokens": ["S", "##win", "##burne", "moves", "in", "his", "writing", "program", "from", "the", "philosophical", "to", "the", "theological", ",", "building", "his", "case", "rigorous", "##ly", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "S", "##win", "##burne", "[unused2]", "[unused3]", "moves", "[unused4]", "[unused5]", "in", "his", "writing", "program", "from", "the", "philosophical", "to", "the", "theological", "[unused6]", "[SEP]", "[unused1]", "S", "##win", "##burne", "[unused2]", "[unused3]", "moves", "[unused4]", "[unused5]", "in", "his", "writing", "program", "building", "his", "case", "rigorous", "##ly", "rigorous", "##ly", "rigorous", "##ly", "rigorous", "##ly", "rigorous", "##ly", "rigorous", "##ly", "rigorous", "##ly", "rigorous", "##ly", "rigorous", "##ly", "rigorous", "##ly", "rigorous", "##ly", "rigorous", "##ly", "rigorous", "##ly", "rigorous", "##ly", "[unused6]", "[SEP]"]]}

input 257:  {"source": "Team Racing is a NASCAR Craftsman Truck Series team .\n"}
prediction:  {"predictions": [[1, 2649, 6770, 2, 3, 1110, 4, 5, 170, 11924, 26460, 1399, 19965, 2768, 1264, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-6.697458593407646e-05, -0.03853654861450195, -0.033948421478271484, -0.033948421478271484, -0.033948421478271484, -0.033948421478271484, -0.033948421478271484, -0.033948421478271484, -0.033948421478271484, -0.033948421478271484], "metadata": {"source_tokens": ["Team", "Racing", "is", "a", "NASCAR", "Crafts", "##man", "Truck", "Series", "team", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Team", "Racing", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "NASCAR", "Crafts", "##man", "Truck", "Series", "team", "[unused6]", "[SEP]"]]}

input 258:  {"source": "That same year saw an outbreak of plague in Venice , one that lasted two years and caused Franco to leave the city and to lose many of her possessions .\n"}
prediction:  {"predictions": [[1, 1337, 1269, 1214, 2, 3, 1486, 4, 5, 1126, 8010, 1104, 13824, 1107, 7433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1141, 2, 3, 5695, 4, 5, 1160, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1141, 2, 3, 2416, 4, 5, 9063, 1106, 1817, 1103, 1331, 1105, 1106, 3857, 1242, 1104, 1123, 14264, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.021276691928505898, -0.0704735815525055, -0.05964573100209236, -0.027524471282958984, -0.0280914306640625, -0.0280914306640625, -0.0280914306640625, -0.0280914306640625, -0.0280914306640625, -0.0280914306640625], "metadata": {"source_tokens": ["That", "same", "year", "saw", "an", "outbreak", "of", "plague", "in", "Venice", ",", "one", "that", "lasted", "two", "years", "and", "caused", "Franco", "to", "leave", "the", "city", "and", "to", "lose", "many", "of", "her", "possessions", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "That", "same", "year", "[unused2]", "[unused3]", "saw", "[unused4]", "[unused5]", "an", "outbreak", "of", "plague", "in", "Venice", "[unused6]", "[SEP]", "[unused1]", "one", "[unused2]", "[unused3]", "lasted", "[unused4]", "[unused5]", "two", "years", "[unused6]", "[SEP]", "[unused1]", "one", "[unused2]", "[unused3]", "caused", "[unused4]", "[unused5]", "Franco", "to", "leave", "the", "city", "and", "to", "lose", "many", "of", "her", "possessions", "[unused6]", "[SEP]"]]}

input 259:  {"source": "The 2nd Battalion of the 13th Light Infantry was raised at Winchester in January 1858 .\n"}
prediction:  {"predictions": [[1, 1109, 2518, 4244, 1104, 1103, 5435, 3935, 4155, 2, 3, 1108, 2120, 4, 5, 1120, 13043, 1107, 1356, 8109, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-2.8003345505567268e-05, -0.021830081939697266, -0.021734237670898438, -0.021734237670898438, -0.021734237670898438, -0.021734237670898438, -0.021734237670898438, -0.021734237670898438, -0.021734237670898438, -0.021734237670898438], "metadata": {"source_tokens": ["The", "2nd", "Battalion", "of", "the", "13th", "Light", "Infantry", "was", "raised", "at", "Winchester", "in", "January", "1858", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "2nd", "Battalion", "of", "the", "13th", "Light", "Infantry", "[unused2]", "[unused3]", "was", "raised", "[unused4]", "[unused5]", "at", "Winchester", "in", "January", "1858", "[unused6]", "[SEP]"]]}

input 260:  {"source": "The Acrolepiidae family of moths are also known as False Diamondback moths .\n"}
prediction:  {"predictions": [[1, 1109, 138, 1665, 13166, 8043, 19793, 1266, 1104, 16297, 2, 3, 1132, 1227, 4, 5, 1112, 143, 7264, 1162, 8549, 4197, 16297, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0057305144146084785, -0.010813713073730469, -0.010193824768066406, -0.010193824768066406, -0.010193824768066406, -0.010193824768066406, -0.010193824768066406, -0.010193824768066406, -0.010193824768066406, -0.010193824768066406], "metadata": {"source_tokens": ["The", "A", "##c", "##rol", "##ep", "##iidae", "family", "of", "moths", "are", "also", "known", "as", "F", "##als", "##e", "Diamond", "##back", "moths", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "A", "##c", "##rol", "##ep", "##iidae", "family", "of", "moths", "[unused2]", "[unused3]", "are", "known", "[unused4]", "[unused5]", "as", "F", "##als", "##e", "Diamond", "##back", "moths", "[unused6]", "[SEP]"]]}

input 261:  {"source": "The Alarm are an alternative rock/new wave band that formed in Rhyl , North Wales , in 1981 .\n"}
prediction:  {"predictions": [[1, 1109, 2586, 20350, 2, 3, 1132, 4, 5, 1126, 4174, 2067, 28139, 1673, 2246, 4003, 1467, 1115, 1824, 1107, 155, 18873, 117, 1456, 2717, 117, 1107, 2358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.003446304937824607, -0.06357097625732422, -0.06348705291748047, -0.06348752975463867, -0.06348705291748047, -0.06348752975463867, -0.06348752975463867, -0.06348705291748047, -0.06348752975463867, -0.06348752975463867], "metadata": {"source_tokens": ["The", "Al", "##arm", "are", "an", "alternative", "rock", "##/", "##ne", "##w", "wave", "band", "that", "formed", "in", "R", "##hyl", ",", "North", "Wales", ",", "in", "1981", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Al", "##arm", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "an", "alternative", "rock", "##/", "##ne", "##w", "wave", "band", "that", "formed", "in", "R", "##hyl", ",", "North", "Wales", ",", "in", "1981", "[unused6]", "[SEP]"]]}

input 262:  {"source": "The Bourbons built additional reception rooms and reconstructed the Sala d'Ercole , named for its frescos depicted the mythological hero , Hercules .\n"}
prediction:  {"predictions": [[1, 1109, 19247, 1116, 2, 3, 1434, 4, 5, 2509, 7602, 4045, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 24596, 6485, 2, 3, 1110, 4, 5, 1103, 24596, 6485, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 18613, 1161, 173, 28131, 2036, 19878, 9016, 2, 3, 1129, 1417, 4, 5, 1111, 1157, 175, 4894, 13538, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 19247, 1116, 2, 3, 15755, 4, 5, 1103, 18613, 1161, 173, 28131, 2036, 19878, 9016, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.018420765176415443, -0.15135765075683594, -0.08842981606721878, -0.07834436744451523, -0.09793663024902344, -0.09435415267944336, -0.09435415267944336, -0.09435415267944336, -0.09435415267944336, -0.09435415267944336], "metadata": {"source_tokens": ["The", "Bourbon", "##s", "built", "additional", "reception", "rooms", "and", "reconstructed", "the", "Sal", "##a", "d", "##'", "##E", "##rc", "##ole", ",", "named", "for", "its", "f", "##res", "##cos", "depicted", "the", "mythological", "hero", ",", "Hercules", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Bourbon", "##s", "[unused2]", "[unused3]", "built", "[unused4]", "[unused5]", "additional", "reception", "rooms", "[unused6]", "[SEP]", "[unused1]", "the", "mythological", "hero", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "mythological", "hero", "[unused6]", "[SEP]", "[unused1]", "the", "Sal", "##a", "d", "##'", "##E", "##rc", "##ole", "[unused2]", "[unused3]", "be", "named", "[unused4]", "[unused5]", "for", "its", "f", "##res", "##cos", "[unused6]", "[SEP]", "[unused1]", "The", "Bourbon", "##s", "[unused2]", "[unused3]", "reconstructed", "[unused4]", "[unused5]", "the", "Sal", "##a", "d", "##'", "##E", "##rc", "##ole", "[unused6]", "[SEP]"]]}

input 263:  {"source": "The Bureau of Alcohol , Tobacco , Firearms and Explosives , formed in 1886 , is a federal law enforcement organization within the United States Department of Justice .\n"}
prediction:  {"predictions": [[1, 1109, 4447, 1104, 2586, 2528, 14084, 117, 25159, 117, 4266, 20350, 1116, 1105, 16409, 1643, 8867, 11355, 2, 3, 1110, 4, 5, 170, 2877, 1644, 7742, 2369, 1439, 1103, 1244, 1311, 1951, 1104, 3302, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4447, 1104, 2586, 2528, 14084, 117, 25159, 117, 4266, 20350, 1116, 1105, 16409, 1643, 8867, 11355, 2, 3, 1824, 4, 5, 1107, 6332, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014898883178830147, -0.03727935999631882, -0.03870677947998047, -0.038218021392822266, -0.038218021392822266, -0.038218021392822266, -0.038218021392822266, -0.038218021392822266, -0.038218021392822266, -0.038218021392822266], "metadata": {"source_tokens": ["The", "Bureau", "of", "Al", "##co", "##hol", ",", "Tobacco", ",", "Fire", "##arm", "##s", "and", "Ex", "##p", "##los", "##ives", ",", "formed", "in", "1886", ",", "is", "a", "federal", "law", "enforcement", "organization", "within", "the", "United", "States", "Department", "of", "Justice", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Bureau", "of", "Al", "##co", "##hol", ",", "Tobacco", ",", "Fire", "##arm", "##s", "and", "Ex", "##p", "##los", "##ives", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "federal", "law", "enforcement", "organization", "within", "the", "United", "States", "Department", "of", "Justice", "[unused6]", "[SEP]", "[unused1]", "The", "Bureau", "of", "Al", "##co", "##hol", ",", "Tobacco", ",", "Fire", "##arm", "##s", "and", "Ex", "##p", "##los", "##ives", "[unused2]", "[unused3]", "formed", "[unused4]", "[unused5]", "in", "1886", "[unused6]", "[SEP]"]]}

input 264:  {"source": "The CRZ was organized by the Nepal and Indian members of the Naxalite movement , in a meeting at Siliguri in the Indian State of West Bengal during August 2001 .\n"}
prediction:  {"predictions": [[1, 1109, 15531, 5301, 2, 3, 1108, 3366, 4, 5, 1118, 1103, 7795, 1105, 1890, 1484, 1104, 1103, 11896, 20192, 21998, 2230, 1107, 170, 2309, 1120, 14159, 2646, 13830, 2047, 1107, 1103, 1890, 1426, 1104, 1537, 7756, 1219, 1360, 1630, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0105034364387393, -0.11257362365722656, -0.09506511688232422, -0.09506511688232422, -0.09506511688232422, -0.09506511688232422, -0.09506511688232422, -0.09506511688232422, -0.09506511688232422, -0.09506511688232422], "metadata": {"source_tokens": ["The", "CR", "##Z", "was", "organized", "by", "the", "Nepal", "and", "Indian", "members", "of", "the", "Na", "##xa", "##lite", "movement", ",", "in", "a", "meeting", "at", "Si", "##li", "##gu", "##ri", "in", "the", "Indian", "State", "of", "West", "Bengal", "during", "August", "2001", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "CR", "##Z", "[unused2]", "[unused3]", "was", "organized", "[unused4]", "[unused5]", "by", "the", "Nepal", "and", "Indian", "members", "of", "the", "Na", "##xa", "##lite", "movement", "in", "a", "meeting", "at", "Si", "##li", "##gu", "##ri", "in", "the", "Indian", "State", "of", "West", "Bengal", "during", "August", "2001", "[unused6]", "[SEP]"]]}

input 265:  {"source": "The Charles City equipment was transferred to Mason City to replace equipment burned in the November 24 , 1967 shop fire .\n"}
prediction:  {"predictions": [[1, 3204, 2, 3, 4562, 4, 5, 1107, 1103, 1379, 1572, 117, 2573, 4130, 1783, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1889, 1392, 3204, 2, 3, 1108, 3175, 4, 5, 1106, 6287, 1392, 1106, 4971, 3204, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.031262435019016266, -0.03484107181429863, -0.015249252319335938, -0.015038490295410156, -0.015038490295410156, -0.015038490295410156, -0.015038490295410156, -0.015038490295410156, -0.015038490295410156, -0.015038490295410156], "metadata": {"source_tokens": ["The", "Charles", "City", "equipment", "was", "transferred", "to", "Mason", "City", "to", "replace", "equipment", "burned", "in", "the", "November", "24", ",", "1967", "shop", "fire", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "equipment", "[unused2]", "[unused3]", "burned", "[unused4]", "[unused5]", "in", "the", "November", "24", ",", "1967", "shop", "fire", "[unused6]", "[SEP]", "[unused1]", "The", "Charles", "City", "equipment", "[unused2]", "[unused3]", "was", "transferred", "[unused4]", "[unused5]", "to", "Mason", "City", "to", "replace", "equipment", "[unused6]", "[SEP]"]]}

input 266:  {"source": "The Hamburg Concathedral with chapterhouse and capitular residential courts formed a `` Cathedral Immunity District '' of the Prince-Archbishopric of Bremen too .\n"}
prediction:  {"predictions": [[1, 1109, 8339, 16752, 12650, 8961, 4412, 1114, 6073, 3255, 1105, 6707, 2875, 5552, 5198, 5333, 2, 3, 1824, 4, 5, 170, 169, 28152, 5761, 146, 6262, 22534, 1574, 112, 28131, 1104, 1103, 2558, 28137, 1592, 10340, 26652, 4184, 4907, 1104, 17339, 6, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.021019821986556053, -0.10494041442871094, -0.11501121520996094, -0.11501121520996094, -0.11501121520996094, -0.11501121520996094, -0.11501121520996094, -0.11501121520996094, -0.11501121520996094, -0.11501121520996094], "metadata": {"source_tokens": ["The", "Hamburg", "Con", "##cat", "##hed", "##ral", "with", "chapter", "##house", "and", "cap", "##it", "##ular", "residential", "courts", "formed", "a", "`", "##`", "Cathedral", "I", "##mm", "##unity", "District", "'", "##'", "of", "the", "Prince", "##-", "##A", "##rch", "##bish", "##op", "##ric", "of", "Bremen", "too", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Hamburg", "Con", "##cat", "##hed", "##ral", "with", "chapter", "##house", "and", "cap", "##it", "##ular", "residential", "courts", "[unused2]", "[unused3]", "formed", "[unused4]", "[unused5]", "a", "`", "##`", "Cathedral", "I", "##mm", "##unity", "District", "'", "##'", "of", "the", "Prince", "##-", "##A", "##rch", "##bish", "##op", "##ric", "of", "Bremen", "[unused6]", "[SEP]"]]}

input 267:  {"source": "The Main Street Tunnel , located in Welland , Ontario , Canada , is an underwater tunnel , carrying Niagara Road 27 and the unsigned designation of Highway 7146 under the Welland Canal .\n"}
prediction:  {"predictions": [[1, 1109, 4304, 1715, 12872, 2, 3, 1388, 4, 5, 1107, 2119, 5709, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4304, 1715, 12872, 2, 3, 1110, 4, 5, 1126, 13082, 5280, 117, 4004, 16351, 1914, 1765, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.003787096356973052, -0.1417386829853058, -0.17644214630126953, -0.21127796173095703, -0.21127796173095703, -0.21127796173095703, -0.21127796173095703, -0.21127796173095703, -0.21127796173095703, -0.21127796173095703], "metadata": {"source_tokens": ["The", "Main", "Street", "Tunnel", ",", "located", "in", "Well", "##and", ",", "Ontario", ",", "Canada", ",", "is", "an", "underwater", "tunnel", ",", "carrying", "Niagara", "Road", "27", "and", "the", "un", "##signed", "designation", "of", "Highway", "71", "##46", "under", "the", "Well", "##and", "Canal", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Main", "Street", "Tunnel", "[unused2]", "[unused3]", "located", "[unused4]", "[unused5]", "in", "Well", "##and", "[unused6]", "[SEP]", "[unused1]", "The", "Main", "Street", "Tunnel", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "underwater", "tunnel", ",", "carrying", "Niagara", "Road", "27", "[unused6]", "[SEP]"]]}

input 268:  {"source": "The Nadvorna dynasty is notable inasmuch as many of its descendants become rebbes .\n"}
prediction:  {"predictions": [[1, 1109, 11896, 1181, 12198, 1605, 6107, 2, 3, 1110, 4, 5, 3385, 1107, 2225, 13601, 1732, 1112, 1242, 1104, 1157, 8395, 1561, 1231, 20584, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005783557891845703, -0.2810635566711426, -0.2771439552307129, -0.2771434783935547, -0.2771434783935547, -0.2771434783935547, -0.2771434783935547, -0.2771434783935547, -0.2771434783935547, -0.2771434783935547], "metadata": {"source_tokens": ["The", "Na", "##d", "##vor", "##na", "dynasty", "is", "notable", "in", "##as", "##mu", "##ch", "as", "many", "of", "its", "descendants", "become", "re", "##bbe", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Na", "##d", "##vor", "##na", "dynasty", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "notable", "in", "##as", "##mu", "##ch", "as", "many", "of", "its", "descendants", "become", "re", "##bbe", "##s", "[unused6]", "[SEP]"]]}

input 269:  {"source": "The PAC bulletins were widely distributed at these meetings .\n"}
prediction:  {"predictions": [[1, 1109, 8544, 1658, 8417, 4935, 2, 3, 1127, 3409, 4901, 4, 5, 1120, 1292, 5845, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-2.288818359375e-05, -0.028879165649414062, -0.02662038803100586, -0.02662038803100586, -0.02662038803100586, -0.02662038803100586, -0.02662038803100586, -0.02662038803100586, -0.02662038803100586, -0.02662038803100586], "metadata": {"source_tokens": ["The", "PA", "##C", "bullet", "##ins", "were", "widely", "distributed", "at", "these", "meetings", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "PA", "##C", "bullet", "##ins", "[unused2]", "[unused3]", "were", "widely", "distributed", "[unused4]", "[unused5]", "at", "these", "meetings", "[unused6]", "[SEP]"]]}

input 270:  {"source": "The Persian contingent that was supposed to guard the defile soon abandoned it , and Alexander passed through without any problems .\n"}
prediction:  {"predictions": [[1, 1109, 3886, 17286, 2, 3, 1108, 3155, 4, 5, 1106, 3542, 1103, 19353, 4759, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 3886, 17286, 1115, 1108, 3155, 1106, 3542, 1103, 19353, 4759, 2, 3, 3928, 4, 5, 1122, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2792, 2, 3, 2085, 1194, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04677604138851166, -0.07358254492282867, -0.11895690858364105, -0.04562854766845703, -0.04419898986816406, -0.04419898986816406, -0.04419898986816406, -0.04419898986816406, -0.04419898986816406, -0.04419898986816406], "metadata": {"source_tokens": ["The", "Persian", "contingent", "that", "was", "supposed", "to", "guard", "the", "def", "##ile", "soon", "abandoned", "it", ",", "and", "Alexander", "passed", "through", "without", "any", "problems", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Persian", "contingent", "[unused2]", "[unused3]", "was", "supposed", "[unused4]", "[unused5]", "to", "guard", "the", "def", "##ile", "[unused6]", "[SEP]", "[unused1]", "The", "Persian", "contingent", "that", "was", "supposed", "to", "guard", "the", "def", "##ile", "[unused2]", "[unused3]", "abandoned", "[unused4]", "[unused5]", "it", "[unused6]", "[SEP]", "[unused1]", "Alexander", "[unused2]", "[unused3]", "passed", "through", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 271:  {"source": "The Rev. William Alfred Quayle was honored by his alma mater , Baker University , with the degrees Litt.D .\n"}
prediction:  {"predictions": [[1, 1109, 6750, 28138, 1613, 5492, 154, 19925, 1513, 2, 3, 1108, 8817, 4, 5, 1118, 1117, 24095, 23662, 1114, 1103, 4842, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 24095, 23662, 2, 3, 1110, 4, 5, 5779, 1239, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.054642897099256516, -0.01912807486951351, -0.14174222946166992, -0.13644123077392578, -0.13644123077392578, -0.13644123077392578, -0.13644123077392578, -0.13644123077392578, -0.13644123077392578, -0.13644123077392578], "metadata": {"source_tokens": ["The", "Rev", "##.", "William", "Alfred", "Q", "##uay", "##le", "was", "honored", "by", "his", "alma", "mater", ",", "Baker", "University", ",", "with", "the", "degrees", "Li", "##tt", "##.", "##D", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Rev", "##.", "William", "Alfred", "Q", "##uay", "##le", "[unused2]", "[unused3]", "was", "honored", "[unused4]", "[unused5]", "by", "his", "alma", "mater", "with", "the", "degrees", "[unused6]", "[SEP]", "[unused1]", "his", "alma", "mater", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Baker", "University", "[unused6]", "[SEP]"]]}

input 272:  {"source": "The River Stour Trust , formed in 1968 , has its headquarters in Sudbury , and a purpose built Visitor Centre located at Cornard Lock .\n"}
prediction:  {"predictions": [[1, 1109, 1595, 1457, 6334, 4623, 2, 3, 1824, 4, 5, 1107, 2477, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1595, 1457, 6334, 4623, 2, 3, 1144, 4, 5, 1157, 3834, 1107, 15463, 26837, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 3007, 1434, 159, 26868, 2772, 2961, 2, 3, 1129, 1388, 4, 5, 1120, 3291, 11782, 2956, 18292, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017129389569163322, -0.0470426045358181, -0.05101022124290466, -0.028688907623291016, -0.02808856964111328, -0.02808856964111328, -0.02808856964111328, -0.02808856964111328, -0.02808856964111328, -0.02808856964111328], "metadata": {"source_tokens": ["The", "River", "St", "##our", "Trust", ",", "formed", "in", "1968", ",", "has", "its", "headquarters", "in", "Su", "##dbury", ",", "and", "a", "purpose", "built", "V", "##isi", "##tor", "Centre", "located", "at", "Co", "##rna", "##rd", "Lock", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "River", "St", "##our", "Trust", "[unused2]", "[unused3]", "formed", "[unused4]", "[unused5]", "in", "1968", "[unused6]", "[SEP]", "[unused1]", "The", "River", "St", "##our", "Trust", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "its", "headquarters", "in", "Su", "##dbury", "[unused6]", "[SEP]", "[unused1]", "a", "purpose", "built", "V", "##isi", "##tor", "Centre", "[unused2]", "[unused3]", "be", "located", "[unused4]", "[unused5]", "at", "Co", "##rna", "##rd", "Lock", "[unused6]", "[SEP]"]]}

input 273:  {"source": "The SAS killed a total of 14 Provisional Irish Republican Army and Irish National Liberation Army members at these locations .\n"}
prediction:  {"predictions": [[1, 1109, 25828, 2, 3, 1841, 4, 5, 170, 1703, 1104, 1489, 18639, 2600, 3215, 1740, 1105, 2600, 1305, 10912, 1740, 1484, 1120, 1292, 4541, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00022060783521737903, -0.01436614990234375, -0.014302253723144531, -0.014302253723144531, -0.014302253723144531, -0.014302253723144531, -0.014302253723144531, -0.014302253723144531, -0.014302253723144531, -0.014302253723144531], "metadata": {"source_tokens": ["The", "SAS", "killed", "a", "total", "of", "14", "Provisional", "Irish", "Republican", "Army", "and", "Irish", "National", "Liberation", "Army", "members", "at", "these", "locations", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "SAS", "[unused2]", "[unused3]", "killed", "[unused4]", "[unused5]", "a", "total", "of", "14", "Provisional", "Irish", "Republican", "Army", "and", "Irish", "National", "Liberation", "Army", "members", "at", "these", "locations", "[unused6]", "[SEP]"]]}

input 274:  {"source": "The Steinbrenner family added a monument to Monument Park on September 20 , 2010 to honor Steinbrenner .\n"}
prediction:  {"predictions": [[1, 1109, 14981, 9730, 27106, 1266, 2, 3, 1896, 4, 5, 170, 7020, 1106, 12267, 1670, 1113, 1347, 1406, 1106, 3874, 14981, 9730, 27106, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014047975651919842, -0.10040521621704102, -0.09006643295288086, -0.09006595611572266, -0.09006595611572266, -0.09006643295288086, -0.09006643295288086, -0.09006643295288086, -0.09006643295288086, -0.09006643295288086], "metadata": {"source_tokens": ["The", "Stein", "##bre", "##nner", "family", "added", "a", "monument", "to", "Monument", "Park", "on", "September", "20", ",", "2010", "to", "honor", "Stein", "##bre", "##nner", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Stein", "##bre", "##nner", "family", "[unused2]", "[unused3]", "added", "[unused4]", "[unused5]", "a", "monument", "to", "Monument", "Park", "on", "September", "20", "to", "honor", "Stein", "##bre", "##nner", "[unused6]", "[SEP]"]]}

input 275:  {"source": "The Summer Programs Office runs these programs , and many Wardlaw-Hartridge Students attend camp or classes over the summer .\n"}
prediction:  {"predictions": [[1, 1109, 2659, 18555, 3060, 2, 3, 2326, 4, 5, 1292, 2648, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1242, 5661, 9598, 28137, 3048, 9349, 8044, 2, 3, 4739, 4, 5, 3227, 1137, 3553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1242, 5661, 9598, 28137, 3048, 9349, 8044, 6510, 2, 3, 4739, 4, 5, 3227, 1137, 3553, 1166, 1103, 2247, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027334485203027725, -0.04109189286828041, -0.02597665786743164, -0.014431476593017578, -0.014263629913330078, -0.014263629913330078, -0.014263629913330078, -0.014263629913330078, -0.014263629913330078, -0.014263629913330078], "metadata": {"source_tokens": ["The", "Summer", "Programs", "Office", "runs", "these", "programs", ",", "and", "many", "Ward", "##law", "##-", "##H", "##art", "##ridge", "Students", "attend", "camp", "or", "classes", "over", "the", "summer", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Summer", "Programs", "Office", "[unused2]", "[unused3]", "runs", "[unused4]", "[unused5]", "these", "programs", "[unused6]", "[SEP]", "[unused1]", "many", "Ward", "##law", "##-", "##H", "##art", "##ridge", "[unused2]", "[unused3]", "attend", "[unused4]", "[unused5]", "camp", "or", "classes", "[unused6]", "[SEP]", "[unused1]", "many", "Ward", "##law", "##-", "##H", "##art", "##ridge", "Students", "[unused2]", "[unused3]", "attend", "[unused4]", "[unused5]", "camp", "or", "classes", "over", "the", "summer", "[unused6]", "[SEP]"]]}

input 276:  {"source": "The Triple-A Baseball National Championship Game was established in 2006 .\n"}
prediction:  {"predictions": [[1, 1109, 9457, 28137, 1592, 5079, 1305, 1935, 3497, 2, 3, 1108, 1628, 4, 5, 1107, 1386, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-2.4293598471558653e-05, -0.021994590759277344, -0.021020889282226562, -0.021020889282226562, -0.021020889282226562, -0.021020889282226562, -0.021020889282226562, -0.021020889282226562, -0.021020889282226562, -0.021020889282226562], "metadata": {"source_tokens": ["The", "Triple", "##-", "##A", "Baseball", "National", "Championship", "Game", "was", "established", "in", "2006", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Triple", "##-", "##A", "Baseball", "National", "Championship", "Game", "[unused2]", "[unused3]", "was", "established", "[unused4]", "[unused5]", "in", "2006", "[unused6]", "[SEP]"]]}

input 277:  {"source": "The Venezuelan government required that all private television stations dedicate at least 25 % of their airtime to programs created by community groups , non-profits , and other independent producers .\n"}
prediction:  {"predictions": [[1, 2648, 2, 3, 1687, 4, 5, 1118, 1661, 2114, 117, 1664, 28137, 1643, 2180, 14067, 1116, 117, 1105, 1168, 2457, 6419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1155, 2029, 1778, 2930, 2, 3, 1260, 12892, 4, 5, 1120, 1655, 1512, 110, 1104, 1147, 1586, 4974, 1106, 2648, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.030600860714912415, -0.0779084786772728, -0.22435855865478516, -0.23542404174804688, -0.23542404174804688, -0.23542404174804688, -0.23542451858520508, -0.23542451858520508, -0.23542404174804688, -0.23542404174804688], "metadata": {"source_tokens": ["The", "Venezuelan", "government", "required", "that", "all", "private", "television", "stations", "de", "##dicate", "at", "least", "25", "%", "of", "their", "air", "##time", "to", "programs", "created", "by", "community", "groups", ",", "non", "##-", "##p", "##ro", "##fit", "##s", ",", "and", "other", "independent", "producers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "programs", "[unused2]", "[unused3]", "created", "[unused4]", "[unused5]", "by", "community", "groups", ",", "non", "##-", "##p", "##ro", "##fit", "##s", ",", "and", "other", "independent", "producers", "[unused6]", "[SEP]", "[unused1]", "all", "private", "television", "stations", "[unused2]", "[unused3]", "de", "##dicate", "[unused4]", "[unused5]", "at", "least", "25", "%", "of", "their", "air", "##time", "to", "programs", "[unused6]", "[SEP]"]]}

input 278:  {"source": "The Wilbur Cross Highway formerly ended in Sturbridge ; locals sometimes call Haynes Street and portions of Mashapaug Road `` Old Route 15 '' .\n"}
prediction:  {"predictions": [[1, 1109, 160, 2723, 19364, 3156, 3580, 2, 3, 2207, 4, 5, 1107, 1457, 2149, 6152, 3147, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10953, 2, 3, 1840, 4, 5, 24098, 1715, 1105, 8924, 1104, 7085, 5480, 4163, 9610, 1914, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02584225870668888, -0.03984501585364342, -0.2324686050415039, -0.23561620712280273, -0.23561573028564453, -0.23561573028564453, -0.23561573028564453, -0.23561573028564453, -0.23561573028564453, -0.23561573028564453], "metadata": {"source_tokens": ["The", "W", "##il", "##bur", "Cross", "Highway", "formerly", "ended", "in", "St", "##ur", "##bridge", ";", "locals", "sometimes", "call", "Haynes", "Street", "and", "portions", "of", "Ma", "##sha", "##pa", "##ug", "Road", "`", "##`", "Old", "Route", "15", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "W", "##il", "##bur", "Cross", "Highway", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "in", "St", "##ur", "##bridge", "formerly", "[unused6]", "[SEP]", "[unused1]", "locals", "[unused2]", "[unused3]", "call", "[unused4]", "[unused5]", "Haynes", "Street", "and", "portions", "of", "Ma", "##sha", "##pa", "##ug", "Road", "[unused6]", "[SEP]"]]}

input 279:  {"source": "The `` Charleston Courier , '' founded in 1803 , and `` Charleston Daily News , '' founded in 1865 , merged to form the `` News and Courier '' in 1873 .\n"}
prediction:  {"predictions": [[1, 10874, 5732, 3128, 2, 3, 1771, 4, 5, 1107, 6127, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10874, 5732, 3128, 2, 3, 1129, 4564, 4, 5, 1106, 1532, 1103, 3128, 1105, 3291, 16706, 1107, 7110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.051573336124420166, -0.050616949796676636, -0.06037712097167969, -0.05698442459106445, -0.05698442459106445, -0.05698442459106445, -0.05698442459106445, -0.05698442459106445, -0.05698442459106445, -0.05698442459106445], "metadata": {"source_tokens": ["The", "`", "##`", "Charleston", "Co", "##urier", ",", "'", "##'", "founded", "in", "1803", ",", "and", "`", "##`", "Charleston", "Daily", "News", ",", "'", "##'", "founded", "in", "1865", ",", "merged", "to", "form", "the", "`", "##`", "News", "and", "Co", "##urier", "'", "##'", "in", "1873", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Charleston", "Daily", "News", "[unused2]", "[unused3]", "founded", "[unused4]", "[unused5]", "in", "1865", "[unused6]", "[SEP]", "[unused1]", "Charleston", "Daily", "News", "[unused2]", "[unused3]", "be", "merged", "[unused4]", "[unused5]", "to", "form", "the", "News", "and", "Co", "##urier", "in", "1873", "[unused6]", "[SEP]"]]}

input 280:  {"source": "The album , produced by Roy Thomas Baker , was promoted with American and European tours .\n"}
prediction:  {"predictions": [[1, 1109, 1312, 2, 3, 1666, 4, 5, 1118, 5396, 1819, 5779, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1312, 117, 1666, 1118, 5396, 1819, 5779, 2, 3, 1108, 3082, 4, 5, 1114, 1237, 1105, 1735, 8398, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-8.147103653755039e-05, -0.02416166476905346, -0.034769535064697266, -0.03247880935668945, -0.03247833251953125, -0.03247880935668945, -0.03247880935668945, -0.03247880935668945, -0.03247880935668945, -0.03247880935668945], "metadata": {"source_tokens": ["The", "album", ",", "produced", "by", "Roy", "Thomas", "Baker", ",", "was", "promoted", "with", "American", "and", "European", "tours", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "album", "[unused2]", "[unused3]", "produced", "[unused4]", "[unused5]", "by", "Roy", "Thomas", "Baker", "[unused6]", "[SEP]", "[unused1]", "The", "album", ",", "produced", "by", "Roy", "Thomas", "Baker", "[unused2]", "[unused3]", "was", "promoted", "[unused4]", "[unused5]", "with", "American", "and", "European", "tours", "[unused6]", "[SEP]"]]}

input 281:  {"source": "The band also confirmed that the album would be self-released .\n"}
prediction:  {"predictions": [[1, 1109, 1467, 2, 3, 3659, 4, 5, 1115, 1103, 1312, 1156, 1129, 2191, 28137, 9261, 23860, 1181, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0019561767112463713, -0.028603553771972656, -0.021817684173583984, -0.021817684173583984, -0.021817684173583984, -0.021817684173583984, -0.021817684173583984, -0.021817684173583984, -0.021817684173583984, -0.021817684173583984], "metadata": {"source_tokens": ["The", "band", "also", "confirmed", "that", "the", "album", "would", "be", "self", "##-", "##rel", "##ease", "##d", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "band", "[unused2]", "[unused3]", "confirmed", "[unused4]", "[unused5]", "that", "the", "album", "would", "be", "self", "##-", "##rel", "##ease", "##d", "[unused6]", "[SEP]"]]}

input 282:  {"source": "The canal was dammed off from the river for most of the construction period .\n"}
prediction:  {"predictions": [[1, 1109, 7684, 2, 3, 1108, 6961, 4611, 1228, 4, 5, 1121, 1103, 2186, 1111, 1211, 1104, 1103, 2058, 1669, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0027042736764997244, -0.016510009765625, -0.016099929809570312, -0.016099929809570312, -0.016099929809570312, -0.016099929809570312, -0.016099929809570312, -0.016100406646728516, -0.016099929809570312, -0.016099929809570312], "metadata": {"source_tokens": ["The", "canal", "was", "dam", "##med", "off", "from", "the", "river", "for", "most", "of", "the", "construction", "period", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "canal", "[unused2]", "[unused3]", "was", "dam", "##med", "off", "[unused4]", "[unused5]", "from", "the", "river", "for", "most", "of", "the", "construction", "period", "[unused6]", "[SEP]"]]}

input 283:  {"source": "The car used in `` Stealth '' was a band member 's car , and recorded just outside the studio in the parking lot .\n"}
prediction:  {"predictions": [[1, 1109, 1610, 2, 3, 1215, 4, 5, 1107, 169, 28152, 1457, 13003, 1582, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1610, 1215, 1107, 28148, 1215, 1107, 28148, 1215, 1107, 28148, 1215, 1107, 28148, 1215, 1107, 28148, 1215, 1107, 28148, 1215, 1107, 28148, 1215, 1107, 28148, 1215, 1107, 28148, 1215, 1107, 28148, 1215, 1107, 28148, 1215, 1107, 28148, 1215, 1107, 28148, 1215, 1107, 28148, 1215, 1107, 28148, 1215, 1107, 102, 1, 1109, 1610, 1215, 1107, 28148, 2, 3, 1108, 4, 5, 170, 1467, 1420, 112, 1116, 1610, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012324213981628418, -0.9011384844779968, -0.1962357759475708, -0.04986095428466797, -0.05089139938354492, -0.05089139938354492, -0.05089139938354492, -0.05089139938354492, -0.05089139938354492, -0.05089139938354492], "metadata": {"source_tokens": ["The", "car", "used", "in", "`", "##`", "St", "##eal", "##th", "'", "##'", "was", "a", "band", "member", "'", "##s", "car", ",", "and", "recorded", "just", "outside", "the", "studio", "in", "the", "parking", "lot", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "car", "[unused2]", "[unused3]", "used", "[unused4]", "[unused5]", "in", "`", "##`", "St", "##eal", "##th", "[unused6]", "[SEP]", "[unused1]", "The", "car", "used", "in", "##\\", "used", "in", "##\\", "used", "in", "##\\", "used", "in", "##\\", "used", "in", "##\\", "used", "in", "##\\", "used", "in", "##\\", "used", "in", "##\\", "used", "in", "##\\", "used", "in", "##\\", "used", "in", "##\\", "used", "in", "##\\", "used", "in", "##\\", "used", "in", "##\\", "used", "in", "##\\", "used", "in", "[SEP]", "[unused1]", "The", "car", "used", "in", "##\\", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "band", "member", "'", "##s", "car", "[unused6]", "[SEP]"]]}

input 284:  {"source": "The city was founded by the Western Town Lot Company in 1880 , and originally named Nordland , with the platted streets given Norwegian names .\n"}
prediction:  {"predictions": [[1, 1109, 1331, 2, 3, 1108, 1771, 4, 5, 1118, 1103, 2102, 2779, 19804, 1881, 1107, 6148, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1331, 2, 3, 1417, 4, 5, 14782, 1931, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 185, 23524, 1174, 4324, 2, 3, 1549, 4, 5, 4236, 2666, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03854259103536606, -0.05760492384433746, -0.06632960587739944, -0.09979772567749023, -0.09864330291748047, -0.09864330291748047, -0.09864330291748047, -0.09864330291748047, -0.09864330291748047, -0.09864330291748047], "metadata": {"source_tokens": ["The", "city", "was", "founded", "by", "the", "Western", "Town", "Lot", "Company", "in", "1880", ",", "and", "originally", "named", "Nord", "##land", ",", "with", "the", "p", "##latt", "##ed", "streets", "given", "Norwegian", "names", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "city", "[unused2]", "[unused3]", "was", "founded", "[unused4]", "[unused5]", "by", "the", "Western", "Town", "Lot", "Company", "in", "1880", "[unused6]", "[SEP]", "[unused1]", "The", "city", "[unused2]", "[unused3]", "named", "[unused4]", "[unused5]", "Nord", "##land", "[unused6]", "[SEP]", "[unused1]", "the", "p", "##latt", "##ed", "streets", "[unused2]", "[unused3]", "given", "[unused4]", "[unused5]", "Norwegian", "names", "[unused6]", "[SEP]"]]}

input 285:  {"source": "The closest Watson ever got was when Republicans had 12 seats in the State House in 2003 .\n"}
prediction:  {"predictions": [[1, 1109, 7064, 7422, 1518, 1400, 2, 3, 1108, 4, 5, 1165, 11115, 1125, 1367, 3474, 1107, 1103, 1426, 1585, 1107, 1581, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0503799133002758, -0.2174358367919922, -0.22883987426757812, -0.22883892059326172, -0.22883892059326172, -0.22883939743041992, -0.22883939743041992, -0.22883892059326172, -0.22883892059326172, -0.22883892059326172], "metadata": {"source_tokens": ["The", "closest", "Watson", "ever", "got", "was", "when", "Republicans", "had", "12", "seats", "in", "the", "State", "House", "in", "2003", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "closest", "Watson", "ever", "got", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "when", "Republicans", "had", "12", "seats", "in", "the", "State", "House", "in", "2003", "[unused6]", "[SEP]"]]}

input 286:  {"source": "The community is served by the United States Postal Service Hinsdale Post Office .\n"}
prediction:  {"predictions": [[1, 1109, 1661, 2, 3, 1110, 1462, 4, 5, 1118, 1103, 1244, 1311, 20976, 2516, 8790, 2316, 4319, 3799, 3060, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-4.013560101157054e-05, -0.024631023406982422, -0.02308034896850586, -0.02308034896850586, -0.02308034896850586, -0.02308034896850586, -0.02308034896850586, -0.02308034896850586, -0.02308034896850586, -0.02308034896850586], "metadata": {"source_tokens": ["The", "community", "is", "served", "by", "the", "United", "States", "Postal", "Service", "Hi", "##ns", "##dale", "Post", "Office", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "community", "[unused2]", "[unused3]", "is", "served", "[unused4]", "[unused5]", "by", "the", "United", "States", "Postal", "Service", "Hi", "##ns", "##dale", "Post", "Office", "[unused6]", "[SEP]"]]}

input 287:  {"source": "The dialects they speak are similar but have different intonations .\n"}
prediction:  {"predictions": [[1, 1109, 12336, 1152, 2936, 2, 3, 1132, 4, 5, 1861, 1133, 1138, 1472, 1154, 9199, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 12336, 2, 3, 2936, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.034645985811948776, -0.10554168373346329, -0.05564165115356445, -0.058084964752197266, -0.058084964752197266, -0.058084964752197266, -0.058084964752197266, -0.058084964752197266, -0.058084964752197266, -0.058084964752197266], "metadata": {"source_tokens": ["The", "dialects", "they", "speak", "are", "similar", "but", "have", "different", "into", "##nation", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "dialects", "they", "speak", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "similar", "but", "have", "different", "into", "##nation", "##s", "[unused6]", "[SEP]", "[unused1]", "The", "dialects", "[unused2]", "[unused3]", "speak", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 288:  {"source": "The diocese was originally erected as the Prefecture Apostolic of Hpyeng-yang on 17 March 1927 , and renamed as the Prefecture Apostolic of Peng-yang on 17 March 1929 .\n"}
prediction:  {"predictions": [[1, 1109, 9856, 2, 3, 3286, 4, 5, 1112, 1103, 8197, 14220, 1104, 23544, 1403, 28137, 13490, 1113, 1542, 1345, 3762, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 9856, 2, 3, 1108, 6517, 4, 5, 1112, 1103, 8197, 14220, 1104, 145, 5005, 14429, 28137, 13490, 1113, 1542, 1345, 3951, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04257706552743912, -0.12709730863571167, -0.14441728591918945, -0.13537931442260742, -0.13537931442260742, -0.13537931442260742, -0.13537931442260742, -0.13537931442260742, -0.13537931442260742, -0.13537931442260742], "metadata": {"source_tokens": ["The", "diocese", "was", "originally", "erected", "as", "the", "Prefecture", "Apostolic", "of", "H", "##py", "##eng", "##-", "##yang", "on", "17", "March", "1927", ",", "and", "renamed", "as", "the", "Prefecture", "Apostolic", "of", "Pen", "##g", "##-", "##yang", "on", "17", "March", "1929", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "diocese", "[unused2]", "[unused3]", "renamed", "[unused4]", "[unused5]", "as", "the", "Prefecture", "Apostolic", "of", "Pen", "##g", "##-", "##yang", "on", "17", "March", "1929", "[unused6]", "[SEP]", "[unused1]", "The", "diocese", "[unused2]", "[unused3]", "was", "erected", "[unused4]", "[unused5]", "as", "the", "Prefecture", "Apostolic", "of", "H", "##py", "##eng", "##-", "##yang", "on", "17", "March", "1927", "[unused6]", "[SEP]"]]}

input 289:  {"source": "The economy of Ostrov is based on food , electronic , and textile industries .\n"}
prediction:  {"predictions": [[1, 1109, 4190, 1104, 152, 21216, 1964, 2, 3, 1110, 1359, 4, 5, 1113, 2094, 117, 4828, 117, 1105, 14817, 7519, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-4.594222264131531e-05, -0.04015207290649414, -0.03780508041381836, -0.03780508041381836, -0.037804603576660156, -0.03780508041381836, -0.03780508041381836, -0.03780508041381836, -0.037804603576660156, -0.037804603576660156], "metadata": {"source_tokens": ["The", "economy", "of", "O", "##stro", "##v", "is", "based", "on", "food", ",", "electronic", ",", "and", "textile", "industries", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "economy", "of", "O", "##stro", "##v", "[unused2]", "[unused3]", "is", "based", "[unused4]", "[unused5]", "on", "food", ",", "electronic", ",", "and", "textile", "industries", "[unused6]", "[SEP]"]]}

input 290:  {"source": "The engine had twin turbochargers , and produced an advertised at 5700 rpm and of torque on 8 lbs of boost .\n"}
prediction:  {"predictions": [[1, 1109, 2395, 2, 3, 1125, 4, 5, 5930, 189, 2149, 4043, 7147, 26206, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2395, 2, 3, 1666, 4, 5, 1126, 18428, 1120, 28081, 1568, 14804, 1105, 1104, 18756, 1113, 129, 24119, 1104, 14112, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0017676634015515447, -0.019017571583390236, -0.04706287384033203, -0.051525115966796875, -0.051525115966796875, -0.051525115966796875, -0.051525115966796875, -0.051525115966796875, -0.051525115966796875, -0.051525115966796875], "metadata": {"source_tokens": ["The", "engine", "had", "twin", "t", "##ur", "##bo", "##cha", "##rger", "##s", ",", "and", "produced", "an", "advertised", "at", "570", "##0", "rpm", "and", "of", "torque", "on", "8", "lbs", "of", "boost", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "engine", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "twin", "t", "##ur", "##bo", "##cha", "##rger", "##s", "[unused6]", "[SEP]", "[unused1]", "The", "engine", "[unused2]", "[unused3]", "produced", "[unused4]", "[unused5]", "an", "advertised", "at", "570", "##0", "rpm", "and", "of", "torque", "on", "8", "lbs", "of", "boost", "[unused6]", "[SEP]"]]}

input 291:  {"source": "The ensemble also has extensive recordings with Deutsche Grammophon , Dorian Recordings , Newport Classic , Navona Records , and under their own label .\n"}
prediction:  {"predictions": [[1, 1109, 9525, 2, 3, 1144, 4, 5, 4154, 5982, 1114, 12054, 19891, 3702, 21250, 117, 17130, 13111, 117, 9168, 6667, 117, 11896, 19988, 1161, 2151, 117, 1105, 1223, 1147, 1319, 3107, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.001317690359428525, -0.03264760971069336, -0.0336604118347168, -0.0336604118347168, -0.0336604118347168, -0.0336604118347168, -0.0336604118347168, -0.0336604118347168, -0.0336604118347168, -0.0336604118347168], "metadata": {"source_tokens": ["The", "ensemble", "also", "has", "extensive", "recordings", "with", "Deutsche", "Gram", "##mo", "##phon", ",", "Dorian", "Recordings", ",", "Newport", "Classic", ",", "Na", "##von", "##a", "Records", ",", "and", "under", "their", "own", "label", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "ensemble", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "extensive", "recordings", "with", "Deutsche", "Gram", "##mo", "##phon", ",", "Dorian", "Recordings", ",", "Newport", "Classic", ",", "Na", "##von", "##a", "Records", ",", "and", "under", "their", "own", "label", "[unused6]", "[SEP]"]]}

input 292:  {"source": "The establishment of a museum had first been planned in 1821 by the Philosophical Society of Australasia , and although specimens were collected , the Society folded in 1822 .\n"}
prediction:  {"predictions": [[1, 9985, 2, 3, 1127, 4465, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2015, 2, 3, 6443, 4, 5, 1107, 12439, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4544, 1104, 170, 3480, 2, 3, 1125, 1151, 2919, 4, 5, 1107, 11749, 1118, 1103, 24515, 2015, 1104, 27758, 16468, 22992, 6, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0641811341047287, -0.040912430733442307, -0.013313203118741512, -0.07149648666381836, -0.0695791244506836, -0.0695791244506836, -0.0695791244506836, -0.0695791244506836, -0.0695791244506836, -0.0695791244506836], "metadata": {"source_tokens": ["The", "establishment", "of", "a", "museum", "had", "first", "been", "planned", "in", "1821", "by", "the", "Philosophical", "Society", "of", "Au", "##stra", "##lasia", ",", "and", "although", "specimens", "were", "collected", ",", "the", "Society", "folded", "in", "1822", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "specimens", "[unused2]", "[unused3]", "were", "collected", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "the", "Society", "[unused2]", "[unused3]", "folded", "[unused4]", "[unused5]", "in", "1822", "[unused6]", "[SEP]", "[unused1]", "The", "establishment", "of", "a", "museum", "[unused2]", "[unused3]", "had", "been", "planned", "[unused4]", "[unused5]", "in", "1821", "by", "the", "Philosophical", "Society", "of", "Au", "##stra", "##lasia", "[unused6]", "[SEP]"]]}

input 293:  {"source": "The extension of the University Library can be found on the second floor , and parking for 120 cars on the third to sixth floors .\n"}
prediction:  {"predictions": [[1, 1109, 4973, 1104, 1103, 1239, 3371, 2, 3, 1169, 1129, 1276, 4, 5, 1113, 1103, 1248, 1837, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4973, 1104, 1103, 1239, 3371, 2, 3, 5030, 5030, 5030, 4, 5, 1111, 5356, 3079, 1113, 1103, 1503, 1106, 3971, 7849, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0056858062744140625, -0.14004895091056824, -0.01815509796142578, -0.018077850341796875, -0.018077850341796875, -0.018077850341796875, -0.018077850341796875, -0.018077850341796875, -0.018077850341796875, -0.018077850341796875], "metadata": {"source_tokens": ["The", "extension", "of", "the", "University", "Library", "can", "be", "found", "on", "the", "second", "floor", ",", "and", "parking", "for", "120", "cars", "on", "the", "third", "to", "sixth", "floors", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "extension", "of", "the", "University", "Library", "[unused2]", "[unused3]", "can", "be", "found", "[unused4]", "[unused5]", "on", "the", "second", "floor", "[unused6]", "[SEP]", "[unused1]", "The", "extension", "of", "the", "University", "Library", "[unused2]", "[unused3]", "parking", "parking", "parking", "[unused4]", "[unused5]", "for", "120", "cars", "on", "the", "third", "to", "sixth", "floors", "[unused6]", "[SEP]"]]}

input 294:  {"source": "The external gauge is usually readable directly , and most also incorporate an electronic sender to operate a fuel gauge on the dashboard .\n"}
prediction:  {"predictions": [[1, 1109, 6298, 7405, 2, 3, 1110, 4, 5, 1932, 2373, 1895, 2626, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1126, 4828, 3952, 1200, 2, 3, 1129, 1106, 4732, 4, 5, 170, 4251, 7405, 1113, 1103, 16605, 4015, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.022539013996720314, -0.07936717569828033, -0.0590052604675293, -0.05937623977661133, -0.05937623977661133, -0.05937623977661133, -0.05937623977661133, -0.05937623977661133, -0.05937623977661133, -0.05937623977661133], "metadata": {"source_tokens": ["The", "external", "gauge", "is", "usually", "read", "##able", "directly", ",", "and", "most", "also", "incorporate", "an", "electronic", "send", "##er", "to", "operate", "a", "fuel", "gauge", "on", "the", "dash", "##board", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "external", "gauge", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "usually", "read", "##able", "directly", "[unused6]", "[SEP]", "[unused1]", "an", "electronic", "send", "##er", "[unused2]", "[unused3]", "be", "to", "operate", "[unused4]", "[unused5]", "a", "fuel", "gauge", "on", "the", "dash", "##board", "[unused6]", "[SEP]"]]}

input 295:  {"source": "The failure of 1st Armored to arrive intact and deploy as a single entity would have important consequences in later action against German forces in Tunisia .\n"}
prediction:  {"predictions": [[1, 1109, 4290, 1104, 2198, 22665, 1106, 6657, 9964, 1105, 23660, 1112, 170, 1423, 9127, 2, 3, 1156, 1138, 4, 5, 1696, 8421, 1107, 1224, 2168, 1222, 1528, 2088, 1107, 13772, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4290, 1104, 2198, 22665, 2, 3, 1106, 6657, 4, 5, 9964, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008205348625779152, -0.0665976032614708, -0.03147459030151367, -0.03225564956665039, -0.03225564956665039, -0.03225564956665039, -0.03225564956665039, -0.03225564956665039, -0.03225564956665039, -0.03225564956665039], "metadata": {"source_tokens": ["The", "failure", "of", "1st", "Armored", "to", "arrive", "intact", "and", "deploy", "as", "a", "single", "entity", "would", "have", "important", "consequences", "in", "later", "action", "against", "German", "forces", "in", "Tunisia", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "failure", "of", "1st", "Armored", "to", "arrive", "intact", "and", "deploy", "as", "a", "single", "entity", "[unused2]", "[unused3]", "would", "have", "[unused4]", "[unused5]", "important", "consequences", "in", "later", "action", "against", "German", "forces", "in", "Tunisia", "[unused6]", "[SEP]", "[unused1]", "The", "failure", "of", "1st", "Armored", "[unused2]", "[unused3]", "to", "arrive", "[unused4]", "[unused5]", "intact", "[unused6]", "[SEP]"]]}

input 296:  {"source": "The field at the Lake Elsinore Diamond is named the Pete Lehr Field .\n"}
prediction:  {"predictions": [[1, 1109, 1768, 1120, 1103, 2161, 2896, 10606, 4474, 8549, 2, 3, 1110, 1417, 4, 5, 1103, 6377, 3180, 8167, 3479, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-3.871710578096099e-05, -0.022833824157714844, -0.02219867706298828, -0.02219867706298828, -0.02219867706298828, -0.02219867706298828, -0.02219867706298828, -0.02219867706298828, -0.02219867706298828, -0.02219867706298828], "metadata": {"source_tokens": ["The", "field", "at", "the", "Lake", "El", "##sin", "##ore", "Diamond", "is", "named", "the", "Pete", "Le", "##hr", "Field", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "field", "at", "the", "Lake", "El", "##sin", "##ore", "Diamond", "[unused2]", "[unused3]", "is", "named", "[unused4]", "[unused5]", "the", "Pete", "Le", "##hr", "Field", "[unused6]", "[SEP]"]]}

input 297:  {"source": "The first comes from when Sweden 's Royal Couple lived there during the 1992 Barcelona Summer Olympics .\n"}
prediction:  {"predictions": [[1, 1109, 1148, 2, 3, 2502, 4, 5, 1121, 1165, 3865, 112, 1116, 1787, 3291, 4455, 1513, 2077, 1175, 1219, 1103, 1924, 7120, 2659, 2932, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3865, 112, 1116, 1787, 3291, 4455, 1513, 2, 3, 2077, 4, 5, 1175, 1219, 1103, 1924, 7120, 2659, 2932, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02195131778717041, -0.020610453560948372, -0.013834953308105469, -0.01367950439453125, -0.01367950439453125, -0.01367950439453125, -0.01367950439453125, -0.01367950439453125, -0.01367950439453125, -0.01367950439453125], "metadata": {"source_tokens": ["The", "first", "comes", "from", "when", "Sweden", "'", "##s", "Royal", "Co", "##up", "##le", "lived", "there", "during", "the", "1992", "Barcelona", "Summer", "Olympics", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "first", "[unused2]", "[unused3]", "comes", "[unused4]", "[unused5]", "from", "when", "Sweden", "'", "##s", "Royal", "Co", "##up", "##le", "lived", "there", "during", "the", "1992", "Barcelona", "Summer", "Olympics", "[unused6]", "[SEP]", "[unused1]", "Sweden", "'", "##s", "Royal", "Co", "##up", "##le", "[unused2]", "[unused3]", "lived", "[unused4]", "[unused5]", "there", "during", "the", "1992", "Barcelona", "Summer", "Olympics", "[unused6]", "[SEP]"]]}

input 298:  {"source": "The first five laps would be added to the second part of the race and the overall result would be decided on aggregate .\n"}
prediction:  {"predictions": [[1, 1109, 1148, 1421, 11033, 2, 3, 1156, 1129, 1896, 4, 5, 1106, 1103, 1248, 1226, 1104, 1103, 1886, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2905, 1871, 2, 3, 1156, 1129, 1879, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2905, 1871, 2, 3, 1156, 1129, 1879, 4, 5, 1113, 9453, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.044461242854595184, -0.047967247664928436, -0.06662397086620331, -0.045590877532958984, -0.04317188262939453, -0.04317140579223633, -0.04317188262939453, -0.04317188262939453, -0.04317188262939453, -0.04317188262939453], "metadata": {"source_tokens": ["The", "first", "five", "laps", "would", "be", "added", "to", "the", "second", "part", "of", "the", "race", "and", "the", "overall", "result", "would", "be", "decided", "on", "aggregate", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "first", "five", "laps", "[unused2]", "[unused3]", "would", "be", "added", "[unused4]", "[unused5]", "to", "the", "second", "part", "of", "the", "race", "[unused6]", "[SEP]", "[unused1]", "the", "overall", "result", "[unused2]", "[unused3]", "would", "be", "decided", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "the", "overall", "result", "[unused2]", "[unused3]", "would", "be", "decided", "[unused4]", "[unused5]", "on", "aggregate", "[unused6]", "[SEP]"]]}

input 299:  {"source": "The first library in Huntington Beach opened in 1909 and has since evolved to a five location library system : Central , Main Street , Oak View , Helen Murphy , and Banning .\n"}
prediction:  {"predictions": [[1, 1109, 1148, 3340, 1107, 17390, 3808, 2, 3, 1533, 4, 5, 1107, 4818, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1148, 3340, 1107, 17390, 3808, 2, 3, 1144, 7601, 4, 5, 1106, 170, 1421, 2450, 3340, 1449, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006707668304443359, -0.038699813187122345, -0.14889240264892578, -0.1509413719177246, -0.1509413719177246, -0.1509413719177246, -0.1509413719177246, -0.1509413719177246, -0.1509413719177246, -0.1509413719177246], "metadata": {"source_tokens": ["The", "first", "library", "in", "Huntington", "Beach", "opened", "in", "1909", "and", "has", "since", "evolved", "to", "a", "five", "location", "library", "system", ":", "Central", ",", "Main", "Street", ",", "Oak", "View", ",", "Helen", "Murphy", ",", "and", "Ban", "##ning", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "first", "library", "in", "Huntington", "Beach", "[unused2]", "[unused3]", "opened", "[unused4]", "[unused5]", "in", "1909", "[unused6]", "[SEP]", "[unused1]", "The", "first", "library", "in", "Huntington", "Beach", "[unused2]", "[unused3]", "has", "evolved", "[unused4]", "[unused5]", "to", "a", "five", "location", "library", "system", "[unused6]", "[SEP]"]]}

input 300:  {"source": "The following tour featured extensive dates in East Asia , where the group played Tokyo , Osaka , Fukuoka , and Southeast Asia including Jakarta , Manila as well as Singapore and Guam .\n"}
prediction:  {"predictions": [[1, 1109, 1378, 2465, 2, 3, 2081, 4, 5, 4154, 4595, 1107, 1689, 3165, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1372, 2, 3, 1307, 4, 5, 4839, 117, 13586, 117, 14763, 4786, 9865, 117, 1105, 8348, 3165, 1259, 15032, 117, 9002, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013288483023643494, -0.030081119388341904, -0.11574983596801758, -0.10090446472167969, -0.10090446472167969, -0.10090494155883789, -0.10090446472167969, -0.10090494155883789, -0.10090494155883789, -0.10090494155883789], "metadata": {"source_tokens": ["The", "following", "tour", "featured", "extensive", "dates", "in", "East", "Asia", ",", "where", "the", "group", "played", "Tokyo", ",", "Osaka", ",", "Fu", "##ku", "##oka", ",", "and", "Southeast", "Asia", "including", "Jakarta", ",", "Manila", "as", "well", "as", "Singapore", "and", "Guam", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "following", "tour", "[unused2]", "[unused3]", "featured", "[unused4]", "[unused5]", "extensive", "dates", "in", "East", "Asia", "[unused6]", "[SEP]", "[unused1]", "the", "group", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "Tokyo", ",", "Osaka", ",", "Fu", "##ku", "##oka", ",", "and", "Southeast", "Asia", "including", "Jakarta", ",", "Manila", "[unused6]", "[SEP]"]]}

input 301:  {"source": "The founder had pledged himself to honour the Blessed Virgin in a special manner .\n"}
prediction:  {"predictions": [[1, 1109, 3249, 2, 3, 1125, 18215, 4, 5, 1471, 1106, 6565, 1103, 16850, 6567, 1107, 170, 1957, 4758, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0013026453088968992, -0.02107524871826172, -0.020446300506591797, -0.020446300506591797, -0.020446300506591797, -0.020446300506591797, -0.020446300506591797, -0.020446300506591797, -0.020446300506591797, -0.020446300506591797], "metadata": {"source_tokens": ["The", "founder", "had", "pledged", "himself", "to", "honour", "the", "Blessed", "Virgin", "in", "a", "special", "manner", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "founder", "[unused2]", "[unused3]", "had", "pledged", "[unused4]", "[unused5]", "himself", "to", "honour", "the", "Blessed", "Virgin", "in", "a", "special", "manner", "[unused6]", "[SEP]"]]}

input 302:  {"source": "The fundraiser was successful , and the trip occurred from June through September of 2014 .\n"}
prediction:  {"predictions": [[1, 1109, 5841, 27014, 2, 3, 1108, 4, 5, 2265, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3868, 2, 3, 3296, 4, 5, 1121, 1340, 1194, 1347, 1104, 1387, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0461629219353199, -0.03385000675916672, -0.011594295501708984, -0.010851383209228516, -0.010851383209228516, -0.010851383209228516, -0.010851383209228516, -0.010851383209228516, -0.010851383209228516, -0.010851383209228516], "metadata": {"source_tokens": ["The", "fund", "##raiser", "was", "successful", ",", "and", "the", "trip", "occurred", "from", "June", "through", "September", "of", "2014", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "fund", "##raiser", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "successful", "[unused6]", "[SEP]", "[unused1]", "the", "trip", "[unused2]", "[unused3]", "occurred", "[unused4]", "[unused5]", "from", "June", "through", "September", "of", "2014", "[unused6]", "[SEP]"]]}

input 303:  {"source": "The fuselage had an oval cross-section and housed a water-cooled inverted-V V-12 engine .\n"}
prediction:  {"predictions": [[1, 1109, 13959, 2, 3, 1125, 4, 5, 1126, 13102, 2771, 28137, 25461, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 13959, 2, 3, 6960, 4, 5, 170, 1447, 28137, 2528, 9016, 1181, 22996, 28137, 2559, 159, 28137, 11964, 2395, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007336680311709642, -0.03274449706077576, -0.007928848266601562, -0.007256507873535156, -0.007256507873535156, -0.007256507873535156, -0.007256507873535156, -0.007256507873535156, -0.007256507873535156, -0.007256507873535156], "metadata": {"source_tokens": ["The", "fuselage", "had", "an", "oval", "cross", "##-", "##section", "and", "housed", "a", "water", "##-", "##co", "##ole", "##d", "inverted", "##-", "##V", "V", "##-", "##12", "engine", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "fuselage", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "an", "oval", "cross", "##-", "##section", "[unused6]", "[SEP]", "[unused1]", "The", "fuselage", "[unused2]", "[unused3]", "housed", "[unused4]", "[unused5]", "a", "water", "##-", "##co", "##ole", "##d", "inverted", "##-", "##V", "V", "##-", "##12", "engine", "[unused6]", "[SEP]"]]}

input 304:  {"source": "The gauge sender is usually a magnetically coupled arrangement , with a float arm inside the tank rotating a magnet , which rotates an external gauge .\n"}
prediction:  {"predictions": [[1, 1109, 7405, 3952, 1200, 2, 3, 1110, 4, 5, 1932, 170, 8364, 2716, 11646, 6204, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 15666, 1981, 1656, 1103, 4890, 2, 3, 14362, 4, 5, 170, 24197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 24197, 2, 3, 1129, 27905, 1116, 4, 5, 1126, 6298, 7405, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.022120939567685127, -0.09471764415502548, -0.060525231063365936, -0.15523386001586914, -0.14848756790161133, -0.14848804473876953, -0.14848756790161133, -0.14848756790161133, -0.14848756790161133, -0.14848756790161133], "metadata": {"source_tokens": ["The", "gauge", "send", "##er", "is", "usually", "a", "magnetic", "##ally", "coupled", "arrangement", ",", "with", "a", "float", "arm", "inside", "the", "tank", "rotating", "a", "magnet", ",", "which", "rotate", "##s", "an", "external", "gauge", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "gauge", "send", "##er", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "usually", "a", "magnetic", "##ally", "coupled", "arrangement", "[unused6]", "[SEP]", "[unused1]", "a", "float", "arm", "inside", "the", "tank", "[unused2]", "[unused3]", "rotating", "[unused4]", "[unused5]", "a", "magnet", "[unused6]", "[SEP]", "[unused1]", "a", "magnet", "[unused2]", "[unused3]", "be", "rotate", "##s", "[unused4]", "[unused5]", "an", "external", "gauge", "[unused6]", "[SEP]"]]}

input 305:  {"source": "The insurer sponsored the golf tournament known as the New Orleans Open beginning in 1981 .\n"}
prediction:  {"predictions": [[1, 1109, 22233, 26616, 2, 3, 5988, 4, 5, 1103, 7135, 2348, 1227, 1112, 1103, 1203, 5705, 3353, 2150, 1107, 2358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.001893478911370039, -0.1755380630493164, -0.19510746002197266, -0.19510555267333984, -0.19510602951049805, -0.19510555267333984, -0.19510555267333984, -0.19510555267333984, -0.19510507583618164, -0.19510507583618164], "metadata": {"source_tokens": ["The", "ins", "##urer", "sponsored", "the", "golf", "tournament", "known", "as", "the", "New", "Orleans", "Open", "beginning", "in", "1981", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "ins", "##urer", "[unused2]", "[unused3]", "sponsored", "[unused4]", "[unused5]", "the", "golf", "tournament", "known", "as", "the", "New", "Orleans", "Open", "beginning", "in", "1981", "[unused6]", "[SEP]"]]}

input 306:  {"source": "The lodge is open from mid-May to mid-October , with two weeks starting in the end of August reserved for the Dartmouth First-Year Trips .\n"}
prediction:  {"predictions": [[1, 1109, 14433, 2, 3, 1110, 4, 5, 1501, 1121, 2286, 28137, 2107, 4164, 1106, 2286, 28137, 2346, 5822, 21367, 1197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1160, 2277, 2547, 1107, 1103, 1322, 1104, 1360, 2, 3, 9142, 4, 5, 1111, 1103, 18069, 1752, 28137, 3663, 19386, 18752, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01339437160640955, -0.03921287879347801, -0.08493518829345703, -0.08197355270385742, -0.08197355270385742, -0.08197355270385742, -0.08197355270385742, -0.08197355270385742, -0.08197355270385742, -0.08197355270385742], "metadata": {"source_tokens": ["The", "lodge", "is", "open", "from", "mid", "##-", "##M", "##ay", "to", "mid", "##-", "##O", "##ct", "##obe", "##r", ",", "with", "two", "weeks", "starting", "in", "the", "end", "of", "August", "reserved", "for", "the", "Dartmouth", "First", "##-", "##Y", "##ear", "Trip", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "lodge", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "open", "from", "mid", "##-", "##M", "##ay", "to", "mid", "##-", "##O", "##ct", "##obe", "##r", "[unused6]", "[SEP]", "[unused1]", "two", "weeks", "starting", "in", "the", "end", "of", "August", "[unused2]", "[unused3]", "reserved", "[unused4]", "[unused5]", "for", "the", "Dartmouth", "First", "##-", "##Y", "##ear", "Trip", "##s", "[unused6]", "[SEP]"]]}

input 307:  {"source": "The opening credits sequence for the collection was directed by Hanada Daizaburo .\n"}
prediction:  {"predictions": [[1, 1109, 2280, 6459, 4954, 1111, 1103, 2436, 2, 3, 1108, 2002, 4, 5, 1118, 7699, 7971, 23084, 3293, 19364, 1186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00044607080053538084, -0.012198925018310547, -0.012233257293701172, -0.012233257293701172, -0.012233257293701172, -0.012233257293701172, -0.012233257293701172, -0.012233257293701172, -0.012233257293701172, -0.012233257293701172], "metadata": {"source_tokens": ["The", "opening", "credits", "sequence", "for", "the", "collection", "was", "directed", "by", "Han", "##ada", "Dai", "##za", "##bur", "##o", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "opening", "credits", "sequence", "for", "the", "collection", "[unused2]", "[unused3]", "was", "directed", "[unused4]", "[unused5]", "by", "Han", "##ada", "Dai", "##za", "##bur", "##o", "[unused6]", "[SEP]"]]}

input 308:  {"source": "The permanent members are the provost , the Carl H. Pforzheimer University Professor and the deans or designees from the following Schools : the Faculty of Arts and Sciences , Harvard Business School , Harvard Law School and Harvard Medical School .\n"}
prediction:  {"predictions": [[1, 1109, 4088, 1484, 2, 3, 1132, 4, 5, 1103, 5250, 22287, 1204, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4088, 1484, 2, 3, 1132, 4, 5, 1103, 5250, 22287, 1204, 117, 1103, 4804, 145, 28138, 153, 14467, 11819, 19263, 1239, 2986, 1105, 1103, 14445, 1116, 1137, 1902, 8870, 1121, 1103, 1378, 5722, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017509160563349724, -0.05928843095898628, -0.0831451416015625, -0.0874166488647461, -0.0874166488647461, -0.0874166488647461, -0.0874166488647461, -0.0874166488647461, -0.0874166488647461, -0.0874166488647461], "metadata": {"source_tokens": ["The", "permanent", "members", "are", "the", "pro", "##vos", "##t", ",", "the", "Carl", "H", "##.", "P", "##fo", "##rz", "##heimer", "University", "Professor", "and", "the", "dean", "##s", "or", "design", "##ees", "from", "the", "following", "Schools", ":", "the", "Faculty", "of", "Arts", "and", "Sciences", ",", "Harvard", "Business", "School", ",", "Harvard", "Law", "School", "and", "Harvard", "Medical", "School", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "permanent", "members", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "the", "pro", "##vos", "##t", "[unused6]", "[SEP]", "[unused1]", "The", "permanent", "members", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "the", "pro", "##vos", "##t", ",", "the", "Carl", "H", "##.", "P", "##fo", "##rz", "##heimer", "University", "Professor", "and", "the", "dean", "##s", "or", "design", "##ees", "from", "the", "following", "Schools", "[unused6]", "[SEP]"]]}

input 309:  {"source": "The pillars in a line on its both sides are according to Doric or Greek style and their decorations are according to the Meenakshi Temple at Madurai in Tamil Nadu .\n"}
prediction:  {"predictions": [[1, 1109, 15592, 1107, 170, 1413, 1113, 1157, 1241, 3091, 2, 3, 1132, 4, 5, 2452, 1106, 2091, 4907, 1137, 2414, 1947, 1105, 1147, 15707, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1147, 15707, 2, 3, 1132, 2452, 4, 5, 1106, 1103, 2508, 7076, 4616, 3031, 4407, 1120, 10779, 17319, 1107, 5344, 10657, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.036836035549640656, -0.04605754837393761, -0.06337213516235352, -0.06365680694580078, -0.06365728378295898, -0.06365728378295898, -0.06365728378295898, -0.06365728378295898, -0.06365728378295898, -0.06365728378295898], "metadata": {"source_tokens": ["The", "pillars", "in", "a", "line", "on", "its", "both", "sides", "are", "according", "to", "Do", "##ric", "or", "Greek", "style", "and", "their", "decorations", "are", "according", "to", "the", "Me", "##ena", "##ks", "##hi", "Temple", "at", "Mad", "##urai", "in", "Tamil", "Nadu", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "pillars", "in", "a", "line", "on", "its", "both", "sides", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "according", "to", "Do", "##ric", "or", "Greek", "style", "and", "their", "decorations", "[unused6]", "[SEP]", "[unused1]", "their", "decorations", "[unused2]", "[unused3]", "are", "according", "[unused4]", "[unused5]", "to", "the", "Me", "##ena", "##ks", "##hi", "Temple", "at", "Mad", "##urai", "in", "Tamil", "Nadu", "[unused6]", "[SEP]"]]}

input 310:  {"source": "The race is in mixed eights , and usually held in late February / early March .\n"}
prediction:  {"predictions": [[1, 1109, 1886, 2, 3, 1110, 4, 5, 1107, 3216, 2022, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1886, 2, 3, 1316, 4, 5, 1107, 1523, 1428, 120, 1346, 1345, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.003588037798181176, -0.09194199740886688, -0.0702505111694336, -0.07082414627075195, -0.07082414627075195, -0.07082414627075195, -0.07082414627075195, -0.07082414627075195, -0.07082414627075195, -0.07082414627075195], "metadata": {"source_tokens": ["The", "race", "is", "in", "mixed", "eight", "##s", ",", "and", "usually", "held", "in", "late", "February", "/", "early", "March", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "race", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "in", "mixed", "eight", "##s", "[unused6]", "[SEP]", "[unused1]", "The", "race", "[unused2]", "[unused3]", "held", "[unused4]", "[unused5]", "in", "late", "February", "/", "early", "March", "[unused6]", "[SEP]"]]}

input 311:  {"source": "The rapids at the head of the South Fork were removed in 1908 .\n"}
prediction:  {"predictions": [[1, 1109, 6099, 1116, 1120, 1103, 1246, 1104, 1103, 1375, 16384, 2, 3, 1127, 2856, 4, 5, 1107, 4536, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-2.2786003682995215e-05, -0.015057563781738281, -0.01402425765991211, -0.01402425765991211, -0.01402425765991211, -0.01402425765991211, -0.01402425765991211, -0.01402425765991211, -0.01402425765991211, -0.01402425765991211], "metadata": {"source_tokens": ["The", "rapid", "##s", "at", "the", "head", "of", "the", "South", "Fork", "were", "removed", "in", "1908", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "rapid", "##s", "at", "the", "head", "of", "the", "South", "Fork", "[unused2]", "[unused3]", "were", "removed", "[unused4]", "[unused5]", "in", "1908", "[unused6]", "[SEP]"]]}

input 312:  {"source": "The redesigned 2006 Ram SRT-10 came in Mineral Gray Metallic , Inferno Red , and Brilliant Black Crystal Clear Coat .\n"}
prediction:  {"predictions": [[1, 1109, 18382, 1386, 11447, 5833, 1942, 28137, 10424, 2, 3, 1338, 4, 5, 1107, 9139, 4412, 4823, 9953, 8031, 117, 1130, 24215, 2156, 117, 1105, 139, 11071, 13789, 2117, 9048, 15458, 3291, 2980, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004513026215136051, -0.014959335327148438, -0.014307022094726562, -0.014307022094726562, -0.014307022094726562, -0.014307022094726562, -0.014307022094726562, -0.014307022094726562, -0.014307022094726562, -0.014307022094726562], "metadata": {"source_tokens": ["The", "redesigned", "2006", "Ram", "SR", "##T", "##-", "##10", "came", "in", "Mine", "##ral", "Gray", "Metal", "##lic", ",", "In", "##ferno", "Red", ",", "and", "B", "##rill", "##iant", "Black", "Crystal", "Clear", "Co", "##at", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "redesigned", "2006", "Ram", "SR", "##T", "##-", "##10", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "in", "Mine", "##ral", "Gray", "Metal", "##lic", ",", "In", "##ferno", "Red", ",", "and", "B", "##rill", "##iant", "Black", "Crystal", "Clear", "Co", "##at", "[unused6]", "[SEP]"]]}

input 313:  {"source": "The residue can be reprocessed for more dripping and strained through a cheesecloth lined sieve as an ingredient for a fine beef stock .\n"}
prediction:  {"predictions": [[1, 1109, 24456, 2, 3, 1169, 1129, 1231, 1643, 2180, 22371, 1174, 4, 5, 1111, 1167, 15224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 24456, 2, 3, 12448, 4, 5, 1194, 170, 9553, 25940, 7265, 27466, 19907, 1112, 1126, 24799, 1111, 170, 2503, 14413, 4482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.028744522482156754, -0.05321138724684715, -0.01908111572265625, -0.01917552947998047, -0.01917552947998047, -0.01917552947998047, -0.01917552947998047, -0.01917552947998047, -0.01917552947998047, -0.01917552947998047], "metadata": {"source_tokens": ["The", "residue", "can", "be", "re", "##p", "##ro", "##cess", "##ed", "for", "more", "dripping", "and", "strained", "through", "a", "cheese", "##cloth", "lined", "si", "##eve", "as", "an", "ingredient", "for", "a", "fine", "beef", "stock", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "residue", "[unused2]", "[unused3]", "can", "be", "re", "##p", "##ro", "##cess", "##ed", "[unused4]", "[unused5]", "for", "more", "dripping", "[unused6]", "[SEP]", "[unused1]", "The", "residue", "[unused2]", "[unused3]", "strained", "[unused4]", "[unused5]", "through", "a", "cheese", "##cloth", "lined", "si", "##eve", "as", "an", "ingredient", "for", "a", "fine", "beef", "stock", "[unused6]", "[SEP]"]]}

input 314:  {"source": "The rest of the group reach a small shop , where Brady attempts to phone the Sheriff , but the crocodile breaks through a wall and devours Annabelle .\n"}
prediction:  {"predictions": [[1, 1109, 1832, 1104, 1103, 1372, 2, 3, 2519, 4, 5, 170, 1353, 4130, 117, 1187, 10004, 4021, 1106, 2179, 1103, 8133, 117, 1133, 1103, 172, 24198, 7610, 1194, 170, 2095, 1105, 1260, 17532, 1116, 28016, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 172, 24198, 2, 3, 1129, 7610, 4, 5, 1194, 170, 2095, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10004, 2, 3, 4021, 1106, 2179, 4, 5, 1103, 8133, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05120302364230156, -0.19820599257946014, -0.12373561412096024, -0.11977720260620117, -0.11877965927124023, -0.11877965927124023, -0.11877965927124023, -0.11877965927124023, -0.11877965927124023, -0.11877965927124023], "metadata": {"source_tokens": ["The", "rest", "of", "the", "group", "reach", "a", "small", "shop", ",", "where", "Brady", "attempts", "to", "phone", "the", "Sheriff", ",", "but", "the", "c", "##rocodile", "breaks", "through", "a", "wall", "and", "de", "##vour", "##s", "Annabelle", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "rest", "of", "the", "group", "[unused2]", "[unused3]", "reach", "[unused4]", "[unused5]", "a", "small", "shop", ",", "where", "Brady", "attempts", "to", "phone", "the", "Sheriff", ",", "but", "the", "c", "##rocodile", "breaks", "through", "a", "wall", "and", "de", "##vour", "##s", "Annabelle", "[unused6]", "[SEP]", "[unused1]", "the", "c", "##rocodile", "[unused2]", "[unused3]", "be", "breaks", "[unused4]", "[unused5]", "through", "a", "wall", "[unused6]", "[SEP]", "[unused1]", "Brady", "[unused2]", "[unused3]", "attempts", "to", "phone", "[unused4]", "[unused5]", "the", "Sheriff", "[unused6]", "[SEP]"]]}

input 315:  {"source": "The restrictions against eating meat and drinking wine , besides reducing a person 's pleasure , recall the cessation of the `` Korban Tamid '' and the `` Nesach Hayayin '' on the Temple Altar with the destruction of the Temple .\n"}
prediction:  {"predictions": [[1, 1109, 9118, 1222, 5497, 6092, 1105, 5464, 4077, 2, 3, 9148, 4, 5, 1103, 172, 5800, 1891, 1104, 1103, 169, 28152, 19892, 23092, 22876, 2386, 112, 28131, 1105, 1103, 169, 28152, 151, 1279, 7291, 16164, 4164, 1394, 112, 28131, 1113, 1103, 4407, 14983, 1813, 1114, 1103, 5915, 1104, 1103, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006462759803980589, -0.15828180313110352, -0.12286853790283203, -0.12286901473999023, -0.12286901473999023, -0.12286901473999023, -0.12286901473999023, -0.12286901473999023, -0.12286901473999023, -0.12286901473999023], "metadata": {"source_tokens": ["The", "restrictions", "against", "eating", "meat", "and", "drinking", "wine", ",", "besides", "reducing", "a", "person", "'", "##s", "pleasure", ",", "recall", "the", "c", "##ess", "##ation", "of", "the", "`", "##`", "Ko", "##rban", "Tam", "##id", "'", "##'", "and", "the", "`", "##`", "N", "##es", "##ach", "Hay", "##ay", "##in", "'", "##'", "on", "the", "Temple", "Alt", "##ar", "with", "the", "destruction", "of", "the", "Temple", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "restrictions", "against", "eating", "meat", "and", "drinking", "wine", "[unused2]", "[unused3]", "recall", "[unused4]", "[unused5]", "the", "c", "##ess", "##ation", "of", "the", "`", "##`", "Ko", "##rban", "Tam", "##id", "'", "##'", "and", "the", "`", "##`", "N", "##es", "##ach", "Hay", "##ay", "##in", "'", "##'", "on", "the", "Temple", "Alt", "##ar", "with", "the", "destruction", "of", "the", "[SEP]"]]}

input 316:  {"source": "The riders climbed off and began walking , shouting protests in general and in particular abuse at the race doctor , Pierre Dumas , whom some demanded should also take a test to see if he 'd been drinking wine or taking aspirin to make his own job easier .\n"}
prediction:  {"predictions": [[1, 1109, 9958, 2, 3, 5998, 1228, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1886, 3995, 2, 3, 1129, 2292, 1129, 1199, 5648, 4, 5, 1431, 1145, 1321, 170, 2774, 1106, 1267, 1191, 1119, 112, 1181, 112, 1181, 112, 1181, 1151, 4077, 1137, 1781, 1112, 8508, 4854, 1106, 1294, 1117, 1319, 2261, 5477, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1886, 3995, 2, 3, 1110, 4, 5, 4855, 12786, 7941, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1199, 5648, 2, 3, 1129, 5648, 4, 5, 2292, 1199, 5648, 1431, 1145, 1321, 170, 2774, 1106, 1267, 1191, 1119, 112, 1181, 112, 1181, 112, 1181, 1137, 1781, 1112, 8508, 4854, 1106, 1294, 1117, 1319, 2261, 5477, 6, 102, 102, 1, 1199, 2, 3, 5648, 4, 5, 2292, 1199, 5648, 1431, 1145, 1321, 170, 2774, 1106, 1267, 1191, 1119, 112, 1181, 112, 1181, 1137, 1781, 1112, 8508, 4854, 1106, 1294, 1117, 1319, 2261, 5477, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1199, 2, 3, 5648, 4, 5, 2292, 1199, 5648, 1431, 1145, 1321, 170, 2774, 1106, 1267, 1191, 1119, 112, 1181, 112, 1181, 1137, 1781, 1112, 8508, 4854, 1106, 1294, 1117, 1319, 2261, 5477, 6, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1886, 3995, 2, 3, 1110, 4, 5, 4855, 12786, 7941, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1886, 3995, 2, 3, 1310, 4, 5, 3179, 117, 11500, 7853, 1107, 1704, 1105, 1107, 2440, 6704, 1120, 1103, 1886, 3995, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.1065472662448883, -0.25211235880851746, -0.10722589492797852, -0.2546185255050659, -0.19753995537757874, -0.21118545532226562, -0.29596829414367676, -0.1850919872522354, -0.09547185897827148, -0.10037040710449219], "metadata": {"source_tokens": ["The", "riders", "climbed", "off", "and", "began", "walking", ",", "shouting", "protests", "in", "general", "and", "in", "particular", "abuse", "at", "the", "race", "doctor", ",", "Pierre", "Du", "##mas", ",", "whom", "some", "demanded", "should", "also", "take", "a", "test", "to", "see", "if", "he", "'", "##d", "been", "drinking", "wine", "or", "taking", "as", "##pi", "##rin", "to", "make", "his", "own", "job", "easier", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "riders", "[unused2]", "[unused3]", "climbed", "off", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "the", "race", "doctor", "[unused2]", "[unused3]", "be", "whom", "be", "some", "demanded", "[unused4]", "[unused5]", "should", "also", "take", "a", "test", "to", "see", "if", "he", "'", "##d", "'", "##d", "'", "##d", "been", "wine", "or", "taking", "as", "##pi", "##rin", "to", "make", "his", "own", "job", "easier", "[unused6]", "[SEP]", "[unused1]", "the", "race", "doctor", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Pierre", "Du", "##mas", "[unused6]", "[SEP]", "[unused1]", "some", "demanded", "[unused2]", "[unused3]", "be", "demanded", "[unused4]", "[unused5]", "whom", "some", "demanded", "should", "also", "take", "a", "test", "to", "see", "if", "he", "'", "##d", "'", "##d", "'", "##d", "or", "taking", "as", "##pi", "##rin", "to", "make", "his", "own", "job", "easier", "[unused6]", "[SEP]", "[unused1]", "some", "[unused2]", "[unused3]", "demanded", "[unused4]", "[unused5]", "whom", "some", "demanded", "should", "also", "take", "a", "test", "to", "see", "if", "he", "'", "##d", "'", "##d", "or", "taking", "as", "##pi", "##rin", "to", "make", "his", "own", "job", "easier", "[unused6]", "[SEP]", "[unused1]", "some", "[unused2]", "[unused3]", "demanded", "[unused4]", "[unused5]", "whom", "some", "demanded", "should", "also", "take", "a", "test", "to", "see", "if", "he", "'", "##d", "'", "##d", "or", "taking", "as", "##pi", "##rin", "to", "make", "his", "own", "job", "easier", "[unused6]", "[SEP]", "[unused1]", "The", "race", "doctor", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Pierre", "Du", "##mas", "[unused6]", "[SEP]", "[unused1]", "The", "race", "doctor", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "walking", ",", "shouting", "protests", "in", "general", "and", "in", "particular", "abuse", "at", "the", "race", "doctor", "[unused6]", "[SEP]"]]}

input 317:  {"source": "The second was named after former US President George H. W. Bush stayed aboard in November 1995 .\n"}
prediction:  {"predictions": [[1, 1109, 1248, 2, 3, 1108, 1417, 4, 5, 1170, 1393, 1646, 1697, 1667, 145, 28138, 160, 28138, 6096, 3523, 7161, 1107, 1379, 1876, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1667, 145, 28138, 160, 28138, 6096, 2, 3, 1110, 1697, 1104, 4, 5, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0003951879625674337, -0.11049117892980576, -0.03821420669555664, -0.03715991973876953, -0.03715944290161133, -0.03715991973876953, -0.03715991973876953, -0.03715991973876953, -0.03715944290161133, -0.03715944290161133], "metadata": {"source_tokens": ["The", "second", "was", "named", "after", "former", "US", "President", "George", "H", "##.", "W", "##.", "Bush", "stayed", "aboard", "in", "November", "1995", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "second", "[unused2]", "[unused3]", "was", "named", "[unused4]", "[unused5]", "after", "former", "US", "President", "George", "H", "##.", "W", "##.", "Bush", "stayed", "aboard", "in", "November", "1995", "[unused6]", "[SEP]", "[unused1]", "George", "H", "##.", "W", "##.", "Bush", "[unused2]", "[unused3]", "is", "President", "of", "[unused4]", "[unused5]", "him", "[unused6]", "[SEP]"]]}

input 318:  {"source": "The second was titled `` Consider Her Ways '' and also starred Barrie as the lead named Jane Waterleigh .\n"}
prediction:  {"predictions": [[1, 1103, 1730, 2, 3, 1417, 4, 5, 4074, 4434, 12185, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1248, 2, 3, 4950, 4, 5, 21715, 1663, 1112, 1103, 1730, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.029307879507541656, -0.06371141225099564, -0.07715892791748047, -0.0804896354675293, -0.0804896354675293, -0.0804896354675293, -0.0804896354675293, -0.0804896354675293, -0.0804896354675293, -0.0804896354675293], "metadata": {"source_tokens": ["The", "second", "was", "titled", "`", "##`", "Consider", "Her", "Ways", "'", "##'", "and", "also", "starred", "Barr", "##ie", "as", "the", "lead", "named", "Jane", "Water", "##leigh", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "lead", "[unused2]", "[unused3]", "named", "[unused4]", "[unused5]", "Jane", "Water", "##leigh", "[unused6]", "[SEP]", "[unused1]", "The", "second", "[unused2]", "[unused3]", "starred", "[unused4]", "[unused5]", "Barr", "##ie", "as", "the", "lead", "[unused6]", "[SEP]"]]}

input 319:  {"source": "The series of three constitutional amendments in 1933 severely curtailed the role of the Governor-General of the Irish Free State .\n"}
prediction:  {"predictions": [[1, 1109, 1326, 1104, 1210, 7950, 19696, 1107, 3698, 2, 3, 8669, 16408, 16242, 11908, 4, 5, 1103, 1648, 1104, 1103, 2958, 28137, 2349, 24475, 1348, 1104, 1103, 2600, 4299, 1426, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0002859072119463235, -0.013173580169677734, -0.012319087982177734, -0.012319087982177734, -0.012319087982177734, -0.012319087982177734, -0.012319087982177734, -0.012319087982177734, -0.012319087982177734, -0.012319087982177734], "metadata": {"source_tokens": ["The", "series", "of", "three", "constitutional", "amendments", "in", "1933", "severely", "cu", "##rta", "##iled", "the", "role", "of", "the", "Governor", "##-", "##G", "##ener", "##al", "of", "the", "Irish", "Free", "State", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "series", "of", "three", "constitutional", "amendments", "in", "1933", "[unused2]", "[unused3]", "severely", "cu", "##rta", "##iled", "[unused4]", "[unused5]", "the", "role", "of", "the", "Governor", "##-", "##G", "##ener", "##al", "of", "the", "Irish", "Free", "State", "[unused6]", "[SEP]"]]}

input 320:  {"source": "The site consists of three subterranean Grotto follies , constructed in the 18th century , split between two areas , one on the western side of the lake , at and one on the eastern side at .\n"}
prediction:  {"predictions": [[1, 1109, 1751, 2, 3, 2923, 4, 5, 1104, 1210, 4841, 2083, 18194, 1389, 144, 10595, 2430, 175, 12666, 1905, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1210, 4841, 2083, 18194, 1389, 144, 10595, 2430, 175, 12666, 1905, 2, 3, 3033, 4, 5, 1107, 1103, 4186, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1210, 4841, 2083, 18194, 1389, 144, 10595, 2430, 175, 12666, 1905, 2, 3, 1129, 3325, 4, 5, 1206, 1160, 1877, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017352711409330368, -0.03352946788072586, -0.10020340979099274, -0.046636104583740234, -0.04741621017456055, -0.04741621017456055, -0.04741621017456055, -0.04741621017456055, -0.04741621017456055, -0.04741621017456055], "metadata": {"source_tokens": ["The", "site", "consists", "of", "three", "sub", "##ter", "##rane", "##an", "G", "##rot", "##to", "f", "##oll", "##ies", ",", "constructed", "in", "the", "18th", "century", ",", "split", "between", "two", "areas", ",", "one", "on", "the", "western", "side", "of", "the", "lake", ",", "at", "and", "one", "on", "the", "eastern", "side", "at", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "site", "[unused2]", "[unused3]", "consists", "[unused4]", "[unused5]", "of", "three", "sub", "##ter", "##rane", "##an", "G", "##rot", "##to", "f", "##oll", "##ies", "[unused6]", "[SEP]", "[unused1]", "three", "sub", "##ter", "##rane", "##an", "G", "##rot", "##to", "f", "##oll", "##ies", "[unused2]", "[unused3]", "constructed", "[unused4]", "[unused5]", "in", "the", "18th", "century", "[unused6]", "[SEP]", "[unused1]", "three", "sub", "##ter", "##rane", "##an", "G", "##rot", "##to", "f", "##oll", "##ies", "[unused2]", "[unused3]", "be", "split", "[unused4]", "[unused5]", "between", "two", "areas", "[unused6]", "[SEP]"]]}

input 321:  {"source": "The staff provides a family-style , home-cooked dinner every night , which is attended not only by Dartmouth students , but by community members , Appalachian Trail thru-hikers , tourists , and even Dartmouth professors .\n"}
prediction:  {"predictions": [[1, 1109, 2546, 2, 3, 2790, 4, 5, 170, 1266, 28137, 19994, 117, 1313, 28137, 2528, 27499, 4014, 1451, 1480, 117, 1134, 1110, 2323, 1136, 1178, 1118, 18069, 1651, 117, 1133, 1118, 1661, 1484, 117, 21464, 6938, 24438, 5082, 28137, 3031, 8811, 117, 9061, 117, 1105, 1256, 18069, 14427, 6, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008414196781814098, -0.07417917251586914, -0.07211542129516602, -0.07211494445800781, -0.07211494445800781, -0.07211494445800781, -0.07211494445800781, -0.07211494445800781, -0.07211494445800781, -0.07211494445800781], "metadata": {"source_tokens": ["The", "staff", "provides", "a", "family", "##-", "##style", ",", "home", "##-", "##co", "##oked", "dinner", "every", "night", ",", "which", "is", "attended", "not", "only", "by", "Dartmouth", "students", ",", "but", "by", "community", "members", ",", "Appalachian", "Trail", "th", "##ru", "##-", "##hi", "##kers", ",", "tourists", ",", "and", "even", "Dartmouth", "professors", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "staff", "[unused2]", "[unused3]", "provides", "[unused4]", "[unused5]", "a", "family", "##-", "##style", ",", "home", "##-", "##co", "##oked", "dinner", "every", "night", ",", "which", "is", "attended", "not", "only", "by", "Dartmouth", "students", ",", "but", "by", "community", "members", ",", "Appalachian", "Trail", "th", "##ru", "##-", "##hi", "##kers", ",", "tourists", ",", "and", "even", "Dartmouth", "professors", "[unused6]", "[SEP]"]]}

input 322:  {"source": "The station has a concourse and ticket office area which was internally redesigned and reopened in mid-2012 .\n"}
prediction:  {"predictions": [[1, 1109, 1466, 2, 3, 1144, 4, 5, 170, 14255, 16461, 1105, 7260, 1701, 1298, 1134, 1108, 19266, 18382, 1105, 11996, 1107, 2286, 28137, 10973, 11964, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0006172870052978396, -0.10194969177246094, -0.0970158576965332, -0.0970158576965332, -0.0970158576965332, -0.0970158576965332, -0.0970158576965332, -0.0970158576965332, -0.0970158576965332, -0.0970158576965332], "metadata": {"source_tokens": ["The", "station", "has", "a", "con", "##course", "and", "ticket", "office", "area", "which", "was", "internally", "redesigned", "and", "reopened", "in", "mid", "##-", "##20", "##12", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "station", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "a", "con", "##course", "and", "ticket", "office", "area", "which", "was", "internally", "redesigned", "and", "reopened", "in", "mid", "##-", "##20", "##12", "[unused6]", "[SEP]"]]}

input 323:  {"source": "The stations were both called `` Midsomer Norton and Welton '' ; under British Railways , the S&D station was renamed as Midsomer Norton South after a short period as Midsomer Norton Upper ; and is currently being restored with occasional open weekends with engines in steam .\n"}
prediction:  {"predictions": [[1, 1103, 156, 28130, 2137, 1466, 2, 3, 1108, 3286, 4, 5, 1112, 9825, 11743, 1197, 10685, 1375, 1170, 170, 1603, 1669, 1112, 9825, 11743, 1197, 10685, 5454, 1223, 1418, 9058, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2930, 2, 3, 1127, 1270, 4, 5, 9825, 11743, 1197, 10685, 1105, 1284, 13464, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02521573379635811, -0.05843646079301834, -0.27256155014038086, -0.2820758819580078, -0.2820758819580078, -0.2820758819580078, -0.2820758819580078, -0.2820758819580078, -0.2820758819580078, -0.2820758819580078], "metadata": {"source_tokens": ["The", "stations", "were", "both", "called", "`", "##`", "Mid", "##some", "##r", "Norton", "and", "We", "##lton", "'", "##'", ";", "under", "British", "Railways", ",", "the", "S", "##&", "##D", "station", "was", "renamed", "as", "Mid", "##some", "##r", "Norton", "South", "after", "a", "short", "period", "as", "Mid", "##some", "##r", "Norton", "Upper", ";", "and", "is", "currently", "being", "restored", "with", "occasional", "open", "weekends", "with", "engines", "in", "steam", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "S", "##&", "##D", "station", "[unused2]", "[unused3]", "was", "renamed", "[unused4]", "[unused5]", "as", "Mid", "##some", "##r", "Norton", "South", "after", "a", "short", "period", "as", "Mid", "##some", "##r", "Norton", "Upper", "under", "British", "Railways", "[unused6]", "[SEP]", "[unused1]", "The", "stations", "[unused2]", "[unused3]", "were", "called", "[unused4]", "[unused5]", "Mid", "##some", "##r", "Norton", "and", "We", "##lton", "[unused6]", "[SEP]"]]}

input 324:  {"source": "The stock pot should be chilled and the solid lump of dripping which settles when chilled should be scraped clean and re-chilled for future use .\n"}
prediction:  {"predictions": [[1, 1109, 4482, 9814, 2, 3, 1431, 1129, 27278, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4600, 16401, 1104, 15224, 2, 3, 7098, 1116, 4, 5, 1165, 27278, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4600, 16401, 1104, 15224, 2, 3, 1431, 1129, 22384, 4, 5, 4044, 1105, 1231, 28137, 4313, 11572, 1111, 2174, 1329, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01565910317003727, -0.028639376163482666, -0.055431563407182693, -0.08601140975952148, -0.08487272262573242, -0.08487272262573242, -0.08487272262573242, -0.08487272262573242, -0.08487272262573242, -0.08487272262573242], "metadata": {"source_tokens": ["The", "stock", "pot", "should", "be", "chilled", "and", "the", "solid", "lump", "of", "dripping", "which", "settle", "##s", "when", "chilled", "should", "be", "scraped", "clean", "and", "re", "##-", "##chi", "##lled", "for", "future", "use", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "stock", "pot", "[unused2]", "[unused3]", "should", "be", "chilled", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "the", "solid", "lump", "of", "dripping", "[unused2]", "[unused3]", "settle", "##s", "[unused4]", "[unused5]", "when", "chilled", "[unused6]", "[SEP]", "[unused1]", "the", "solid", "lump", "of", "dripping", "[unused2]", "[unused3]", "should", "be", "scraped", "[unused4]", "[unused5]", "clean", "and", "re", "##-", "##chi", "##lled", "for", "future", "use", "[unused6]", "[SEP]"]]}

input 325:  {"source": "The suit alleged that they conspired to fix prices for e-books , and weaken Amazon.com 's position in the market , in violation of antitrust law .\n"}
prediction:  {"predictions": [[1, 1109, 4228, 2, 3, 6351, 4, 5, 1115, 1152, 14255, 20080, 24599, 1106, 8239, 7352, 1111, 174, 28137, 16429, 117, 1105, 25772, 9786, 28138, 8178, 112, 1116, 1700, 1107, 1103, 2319, 117, 1107, 11574, 1104, 2848, 18062, 8954, 1644, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 14255, 20080, 24599, 4, 5, 1106, 8239, 7352, 1111, 174, 28137, 16429, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0022872579284012318, -0.02208651788532734, -0.08967256546020508, -0.08827400207519531, -0.08827400207519531, -0.08827400207519531, -0.08827400207519531, -0.08827400207519531, -0.08827400207519531, -0.08827400207519531], "metadata": {"source_tokens": ["The", "suit", "alleged", "that", "they", "con", "##sp", "##ired", "to", "fix", "prices", "for", "e", "##-", "##books", ",", "and", "weaken", "Amazon", "##.", "##com", "'", "##s", "position", "in", "the", "market", ",", "in", "violation", "of", "anti", "##tr", "##ust", "law", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "suit", "[unused2]", "[unused3]", "alleged", "[unused4]", "[unused5]", "that", "they", "con", "##sp", "##ired", "to", "fix", "prices", "for", "e", "##-", "##books", ",", "and", "weaken", "Amazon", "##.", "##com", "'", "##s", "position", "in", "the", "market", ",", "in", "violation", "of", "anti", "##tr", "##ust", "law", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "con", "##sp", "##ired", "[unused4]", "[unused5]", "to", "fix", "prices", "for", "e", "##-", "##books", "[unused6]", "[SEP]"]]}

input 326:  {"source": "The third known version is part number 2189014-00-212 , with at least one model being produced in February 1993 .\n"}
prediction:  {"predictions": [[1, 1120, 1655, 1141, 2235, 2, 3, 1217, 1666, 4, 5, 1107, 1428, 1949, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1503, 1227, 1683, 2, 3, 1110, 4, 5, 1226, 1295, 22723, 21500, 17175, 28137, 7629, 28137, 18202, 1477, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04289364814758301, -0.05451824516057968, -0.07317590713500977, -0.07148218154907227, -0.07148218154907227, -0.07148218154907227, -0.07148218154907227, -0.07148218154907227, -0.07148218154907227, -0.07148218154907227], "metadata": {"source_tokens": ["The", "third", "known", "version", "is", "part", "number", "218", "##90", "##14", "##-", "##00", "##-", "##21", "##2", ",", "with", "at", "least", "one", "model", "being", "produced", "in", "February", "1993", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "at", "least", "one", "model", "[unused2]", "[unused3]", "being", "produced", "[unused4]", "[unused5]", "in", "February", "1993", "[unused6]", "[SEP]", "[unused1]", "The", "third", "known", "version", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "part", "number", "218", "##90", "##14", "##-", "##00", "##-", "##21", "##2", "[unused6]", "[SEP]"]]}

input 327:  {"source": "The town was previously served by a station on the Somerset and Dorset Railway but this closed in 1966 , and by a second station on the Bristol and North Somerset Railway at Welton in the valley .\n"}
prediction:  {"predictions": [[1, 1142, 2, 3, 1804, 4, 5, 1107, 2678, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1411, 2, 3, 1108, 1462, 4, 5, 1118, 170, 1466, 1113, 1103, 8860, 1105, 16180, 2847, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07353122532367706, -0.03877686336636543, -0.09502029418945312, -0.091827392578125, -0.091827392578125, -0.091827392578125, -0.091827392578125, -0.091827392578125, -0.091827392578125, -0.091827392578125], "metadata": {"source_tokens": ["The", "town", "was", "previously", "served", "by", "a", "station", "on", "the", "Somerset", "and", "Dorset", "Railway", "but", "this", "closed", "in", "1966", ",", "and", "by", "a", "second", "station", "on", "the", "Bristol", "and", "North", "Somerset", "Railway", "at", "We", "##lton", "in", "the", "valley", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "this", "[unused2]", "[unused3]", "closed", "[unused4]", "[unused5]", "in", "1966", "[unused6]", "[SEP]", "[unused1]", "The", "town", "[unused2]", "[unused3]", "was", "served", "[unused4]", "[unused5]", "by", "a", "station", "on", "the", "Somerset", "and", "Dorset", "Railway", "[unused6]", "[SEP]"]]}

input 328:  {"source": "The very large piers at the crossing signify that there was once a tower .\n"}
prediction:  {"predictions": [[1, 1109, 1304, 1415, 23747, 1120, 1103, 4905, 2, 3, 2951, 6120, 4, 5, 1115, 1175, 1108, 1517, 170, 3590, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00023217634588945657, -0.0920414924621582, -0.08151531219482422, -0.08151531219482422, -0.08151531219482422, -0.08151483535766602, -0.08151531219482422, -0.08151531219482422, -0.08151531219482422, -0.08151531219482422], "metadata": {"source_tokens": ["The", "very", "large", "piers", "at", "the", "crossing", "sign", "##ify", "that", "there", "was", "once", "a", "tower", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "very", "large", "piers", "at", "the", "crossing", "[unused2]", "[unused3]", "sign", "##ify", "[unused4]", "[unused5]", "that", "there", "was", "once", "a", "tower", "[unused6]", "[SEP]"]]}

input 329:  {"source": "The video was the first ever to feature the use of dialogue .\n"}
prediction:  {"predictions": [[1, 1109, 1888, 2, 3, 1108, 4, 5, 1103, 1148, 1518, 1106, 2672, 1103, 1329, 1104, 8556, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1148, 2, 3, 1106, 2672, 4, 5, 1103, 1329, 1104, 8556, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2, 3, 1148, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2, 3, 8556, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2, 3, 8556, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1148, 2, 3, 1103, 2672, 4, 5, 1103, 1329, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1148, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 2672, 1103, 102, 1, 2, 3, 1108, 4, 5, 1103, 1148, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2, 3, 1103, 1148, 4, 5, 1103, 1148, 6, 102, 102, 1, 2, 3, 1103, 1148, 4, 5, 1103, 1148, 6, 102, 102]], "predicted_log_probs": [-0.00011785406968556345, -0.19030903279781342, -0.4650540351867676, -0.4277495741844177, -0.4249034523963928, -0.7946622967720032, -0.36120104789733887, -0.4249474108219147, -0.44699808955192566, -0.46695998311042786], "metadata": {"source_tokens": ["The", "video", "was", "the", "first", "ever", "to", "feature", "the", "use", "of", "dialogue", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "video", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "first", "ever", "to", "feature", "the", "use", "of", "dialogue", "[unused6]", "[SEP]", "[unused1]", "the", "first", "[unused2]", "[unused3]", "to", "feature", "[unused4]", "[unused5]", "the", "use", "of", "dialogue", "[unused6]", "[SEP]", "[unused1]", "the", "[unused2]", "[unused3]", "first", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "the", "[unused2]", "[unused3]", "dialogue", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "the", "[unused2]", "[unused3]", "dialogue", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "the", "first", "[unused2]", "[unused3]", "the", "feature", "[unused4]", "[unused5]", "the", "use", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "[unused6]", "[SEP]", "[unused1]", "the", "first", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "feature", "the", "[SEP]", "[unused1]", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "first", "[unused6]", "[SEP]", "[unused1]", "[unused2]", "[unused3]", "the", "first", "[unused4]", "[unused5]", "the", "first", "[unused6]", "[SEP]", "[unused1]", "[unused2]", "[unused3]", "the", "first", "[unused4]", "[unused5]", "the", "first", "[unused6]", "[SEP]"]]}

input 330:  {"source": "Their mission was always for a specific mandate and lasted for a limited period .\n"}
prediction:  {"predictions": [[1, 2397, 2862, 2, 3, 1108, 4, 5, 1579, 1111, 170, 2747, 13515, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2397, 2862, 2, 3, 5695, 4, 5, 1111, 170, 2609, 1669, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.035570669919252396, -0.0642928034067154, -0.020900726318359375, -0.020775318145751953, -0.020775318145751953, -0.020775318145751953, -0.020775318145751953, -0.020775318145751953, -0.020775318145751953, -0.020775318145751953], "metadata": {"source_tokens": ["Their", "mission", "was", "always", "for", "a", "specific", "mandate", "and", "lasted", "for", "a", "limited", "period", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Their", "mission", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "always", "for", "a", "specific", "mandate", "[unused6]", "[SEP]", "[unused1]", "Their", "mission", "[unused2]", "[unused3]", "lasted", "[unused4]", "[unused5]", "for", "a", "limited", "period", "[unused6]", "[SEP]"]]}

input 331:  {"source": "Their numbers continued to increase each year as rumours about immigration restrictions appeared in much of the Cypriot media .\n"}
prediction:  {"predictions": [[1, 2397, 2849, 2, 3, 1598, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2397, 2849, 2, 3, 1106, 2773, 4, 5, 1296, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 23620, 1164, 9027, 9118, 2, 3, 1691, 4, 5, 1107, 1277, 1104, 1103, 20036, 2394, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.12311973422765732, -0.09447427839040756, -0.010661443695425987, -0.07591724395751953, -0.07811355590820312, -0.07811355590820312, -0.07811355590820312, -0.07811355590820312, -0.07811355590820312, -0.07811355590820312], "metadata": {"source_tokens": ["Their", "numbers", "continued", "to", "increase", "each", "year", "as", "rumours", "about", "immigration", "restrictions", "appeared", "in", "much", "of", "the", "Cypriot", "media", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Their", "numbers", "[unused2]", "[unused3]", "continued", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Their", "numbers", "[unused2]", "[unused3]", "to", "increase", "[unused4]", "[unused5]", "each", "year", "[unused6]", "[SEP]", "[unused1]", "rumours", "about", "immigration", "restrictions", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "in", "much", "of", "the", "Cypriot", "media", "[unused6]", "[SEP]"]]}

input 332:  {"source": "Then the fillets are put in a mix of olive oil , vinegar , sugar , garlic , chill peppers , and lots of parsley or celery .\n"}
prediction:  {"predictions": [[1, 1103, 5475, 6248, 2, 3, 1132, 1508, 4, 5, 1107, 170, 5495, 1104, 13552, 2949, 117, 23230, 5526, 117, 6656, 117, 24861, 117, 11824, 18700, 1116, 117, 1105, 7424, 1104, 14247, 8980, 1137, 172, 11194, 1616, 1599, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0027024666778743267, -0.2338275909423828, -0.2385697364807129, -0.2385692596435547, -0.2385692596435547, -0.23856878280639648, -0.2385692596435547, -0.2385692596435547, -0.2385692596435547, -0.2385692596435547], "metadata": {"source_tokens": ["Then", "the", "fill", "##ets", "are", "put", "in", "a", "mix", "of", "olive", "oil", ",", "vine", "##gar", ",", "sugar", ",", "garlic", ",", "chill", "pepper", "##s", ",", "and", "lots", "of", "par", "##sley", "or", "c", "##ele", "##ry", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "fill", "##ets", "[unused2]", "[unused3]", "are", "put", "[unused4]", "[unused5]", "in", "a", "mix", "of", "olive", "oil", ",", "vine", "##gar", ",", "sugar", ",", "garlic", ",", "chill", "pepper", "##s", ",", "and", "lots", "of", "par", "##sley", "or", "c", "##ele", "##ry", "Then", "[unused6]", "[SEP]"]]}

input 333:  {"source": "There have been two crashes involving fatalities at the airfield since it was established .\n"}
prediction:  {"predictions": [[1, 1160, 21110, 2, 3, 5336, 4, 5, 23515, 1120, 1103, 11897, 1290, 1122, 1108, 1628, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008627255447208881, -0.04546689987182617, -0.04348039627075195, -0.04348039627075195, -0.04348039627075195, -0.04348039627075195, -0.04348039627075195, -0.04348039627075195, -0.04348039627075195, -0.04348039627075195], "metadata": {"source_tokens": ["There", "have", "been", "two", "crashes", "involving", "fatalities", "at", "the", "airfield", "since", "it", "was", "established", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "two", "crashes", "[unused2]", "[unused3]", "involving", "[unused4]", "[unused5]", "fatalities", "at", "the", "airfield", "since", "it", "was", "established", "[unused6]", "[SEP]"]]}

input 334:  {"source": "There used to be a Youth Hostel but it closed in October 2008 and the building has since reopened as Keld Lodge , a hotel with bar and restaurant .\n"}
prediction:  {"predictions": [[1, 1103, 1459, 2, 3, 1144, 11996, 4, 5, 1112, 26835, 5253, 9262, 1290, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1804, 4, 5, 1107, 1357, 1369, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 5253, 9262, 2, 3, 1110, 4, 5, 170, 3415, 1114, 2927, 1105, 4382, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05159718543291092, -0.030363133177161217, -0.03401090204715729, -0.15062808990478516, -0.14925003051757812, -0.14925003051757812, -0.14925003051757812, -0.14925003051757812, -0.14925003051757812, -0.14925003051757812], "metadata": {"source_tokens": ["There", "used", "to", "be", "a", "Youth", "Host", "##el", "but", "it", "closed", "in", "October", "2008", "and", "the", "building", "has", "since", "reopened", "as", "Ke", "##ld", "Lodge", ",", "a", "hotel", "with", "bar", "and", "restaurant", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "building", "[unused2]", "[unused3]", "has", "reopened", "[unused4]", "[unused5]", "as", "Ke", "##ld", "Lodge", "since", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "closed", "[unused4]", "[unused5]", "in", "October", "2008", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ld", "Lodge", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "hotel", "with", "bar", "and", "restaurant", "[unused6]", "[SEP]"]]}

input 335:  {"source": "There were 143 households out of which 30.1 % had children under the age of 18 living with them , 49.7 % were married couples living together , 11.9 % had a female householder with no husband present , and 36.4 % were non-families .\n"}
prediction:  {"predictions": [[1, 3164, 28138, 1527, 110, 2, 3, 1127, 4, 5, 1664, 28137, 8057, 3080, 7875, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3927, 28138, 1559, 110, 2, 3, 1127, 4, 5, 1597, 5509, 1690, 1487, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1429, 28138, 1580, 110, 2, 3, 1125, 4, 5, 170, 2130, 7036, 1114, 1185, 2252, 1675, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3927, 28138, 1559, 110, 2, 3, 1127, 4, 5, 1482, 1223, 1103, 1425, 1104, 1407, 1690, 1114, 1172, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.053009819239377975, -0.11025635153055191, -0.053820401430130005, -0.10988157242536545, -0.2662343978881836, -0.2736530303955078, -0.2736530303955078, -0.2736530303955078, -0.2736530303955078, -0.2736530303955078], "metadata": {"source_tokens": ["There", "were", "143", "households", "out", "of", "which", "30", "##.", "##1", "%", "had", "children", "under", "the", "age", "of", "18", "living", "with", "them", ",", "49", "##.", "##7", "%", "were", "married", "couples", "living", "together", ",", "11", "##.", "##9", "%", "had", "a", "female", "householder", "with", "no", "husband", "present", ",", "and", "36", "##.", "##4", "%", "were", "non", "##-", "##fa", "##mi", "##lies", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "36", "##.", "##4", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "non", "##-", "##fa", "##mi", "##lies", "[unused6]", "[SEP]", "[unused1]", "49", "##.", "##7", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "married", "couples", "living", "together", "[unused6]", "[SEP]", "[unused1]", "11", "##.", "##9", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "female", "householder", "with", "no", "husband", "present", "[unused6]", "[SEP]", "[unused1]", "49", "##.", "##7", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "children", "under", "the", "age", "of", "18", "living", "with", "them", "[unused6]", "[SEP]"]]}

input 336:  {"source": "There were 47,604 households out of which 35.00 % had children under the age of 18 living with them , 56.30 % were married couples living together , 7.50 % had a female householder with no husband present , and 32.50 % were non-families .\n"}
prediction:  {"predictions": [[1, 2724, 28138, 11049, 110, 2, 3, 1127, 4, 5, 1664, 28137, 8057, 3080, 7875, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4376, 28138, 13144, 110, 2, 3, 1127, 4, 5, 1597, 5509, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4376, 28138, 13144, 110, 2, 3, 1125, 4, 5, 1482, 1223, 1103, 1425, 1104, 1407, 1690, 1114, 1172, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4376, 28138, 13144, 110, 2, 3, 1127, 4, 5, 1597, 5509, 1690, 1487, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4376, 28138, 13144, 110, 2, 3, 1127, 4, 5, 1597, 5509, 1690, 1487, 128, 28138, 11049, 110, 1125, 170, 2130, 7036, 1114, 1185, 2252, 1675, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05505824089050293, -0.14907792210578918, -0.08882015198469162, -0.16845309734344482, -0.14288878440856934, -0.21837282180786133, -0.23040485382080078, -0.23040485382080078, -0.23040485382080078, -0.23040485382080078], "metadata": {"source_tokens": ["There", "were", "47", "##,", "##60", "##4", "households", "out", "of", "which", "35", "##.", "##00", "%", "had", "children", "under", "the", "age", "of", "18", "living", "with", "them", ",", "56", "##.", "##30", "%", "were", "married", "couples", "living", "together", ",", "7", "##.", "##50", "%", "had", "a", "female", "householder", "with", "no", "husband", "present", ",", "and", "32", "##.", "##50", "%", "were", "non", "##-", "##fa", "##mi", "##lies", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "32", "##.", "##50", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "non", "##-", "##fa", "##mi", "##lies", "[unused6]", "[SEP]", "[unused1]", "56", "##.", "##30", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "married", "couples", "[unused6]", "[SEP]", "[unused1]", "56", "##.", "##30", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "children", "under", "the", "age", "of", "18", "living", "with", "them", "[unused6]", "[SEP]", "[unused1]", "56", "##.", "##30", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "married", "couples", "living", "together", "[unused6]", "[SEP]", "[unused1]", "56", "##.", "##30", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "married", "couples", "living", "together", "7", "##.", "##50", "%", "had", "a", "female", "householder", "with", "no", "husband", "present", "[unused6]", "[SEP]"]]}

input 337:  {"source": "There were 6,524 households out of which 35.3 % had children under the age of 18 living with them , 31.7 % were married couples living together , 31.5 % had a female householder with no husband present , and 30.6 % were non-families .\n"}
prediction:  {"predictions": [[1, 1955, 28138, 1559, 110, 2, 3, 1127, 4, 5, 1597, 5509, 1690, 1487, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2588, 28138, 1495, 110, 2, 3, 1125, 4, 5, 1482, 1223, 1103, 1425, 1104, 1407, 1690, 1114, 1172, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1955, 28138, 1559, 110, 2, 3, 1127, 4, 5, 1597, 5509, 1690, 1487, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1955, 28138, 1559, 110, 2, 3, 1127, 4, 5, 1597, 5509, 1690, 1487, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1955, 28138, 1559, 110, 2, 3, 1127, 4, 5, 1597, 5509, 1690, 1487, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1955, 28138, 1559, 110, 2, 3, 1127, 4, 5, 1597, 5509, 1690, 1487, 117, 1955, 28138, 1571, 110, 1125, 170, 2130, 7036, 1114, 1185, 2252, 1675, 117, 1105, 1476, 28138, 1545, 110, 1127, 1664, 28137, 8057, 3080, 7875, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.1279563456773758, -0.06809965521097183, -0.16624602675437927, -0.18806223571300507, -0.20514939725399017, -0.11256304383277893, -0.05662345886230469, -0.056670188903808594, -0.056670188903808594, -0.056670188903808594], "metadata": {"source_tokens": ["There", "were", "6", "##,", "##5", "##24", "households", "out", "of", "which", "35", "##.", "##3", "%", "had", "children", "under", "the", "age", "of", "18", "living", "with", "them", ",", "31", "##.", "##7", "%", "were", "married", "couples", "living", "together", ",", "31", "##.", "##5", "%", "had", "a", "female", "householder", "with", "no", "husband", "present", ",", "and", "30", "##.", "##6", "%", "were", "non", "##-", "##fa", "##mi", "##lies", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "31", "##.", "##7", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "married", "couples", "living", "together", "[unused6]", "[SEP]", "[unused1]", "35", "##.", "##3", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "children", "under", "the", "age", "of", "18", "living", "with", "them", "[unused6]", "[SEP]", "[unused1]", "31", "##.", "##7", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "married", "couples", "living", "together", "[unused6]", "[SEP]", "[unused1]", "31", "##.", "##7", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "married", "couples", "living", "together", "[unused6]", "[SEP]", "[unused1]", "31", "##.", "##7", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "married", "couples", "living", "together", "[unused6]", "[SEP]", "[unused1]", "31", "##.", "##7", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "married", "couples", "living", "together", ",", "31", "##.", "##5", "%", "had", "a", "female", "householder", "with", "no", "husband", "present", ",", "and", "30", "##.", "##6", "%", "were", "non", "##-", "##fa", "##mi", "##lies", "[unused6]", "[SEP]"]]}

input 338:  {"source": "These and other attempts supplied a bridge between the literature of the two languages .\n"}
prediction:  {"predictions": [[1, 1636, 1105, 1168, 4021, 2, 3, 7694, 4, 5, 170, 2738, 1206, 1103, 3783, 1104, 1103, 1160, 3483, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-1.4259701856644824e-05, -0.031711578369140625, -0.032668113708496094, -0.032668113708496094, -0.032668113708496094, -0.032668113708496094, -0.032668113708496094, -0.032668113708496094, -0.032668113708496094, -0.032668113708496094], "metadata": {"source_tokens": ["These", "and", "other", "attempts", "supplied", "a", "bridge", "between", "the", "literature", "of", "the", "two", "languages", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "These", "and", "other", "attempts", "[unused2]", "[unused3]", "supplied", "[unused4]", "[unused5]", "a", "bridge", "between", "the", "literature", "of", "the", "two", "languages", "[unused6]", "[SEP]"]]}

input 339:  {"source": "These are visually very similar to part number 2189014-00-211 , with the same AT style plug and chassis , silver label on the reverse bearing the AnyKey moniker , screws holding the keyboard together , macro programming requiring the control key , and lacking the AnyKey inscription on their face .\n"}
prediction:  {"predictions": [[1, 1636, 2, 3, 1132, 4, 5, 19924, 1304, 1861, 1106, 1226, 1295, 22723, 21500, 17175, 28137, 7629, 28137, 18202, 1475, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2878, 3107, 1113, 1103, 7936, 7343, 1103, 6291, 2428, 2254, 24395, 2, 3, 1129, 13084, 1116, 2355, 1103, 9303, 1487, 4, 5, 23639, 2180, 4159, 8753, 1103, 1654, 2501, 117, 1105, 1105, 11744, 1103, 6291, 2428, 2254, 9237, 1113, 1147, 1339, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 7936, 7343, 1103, 6291, 2428, 2254, 24395, 2, 3, 1110, 4, 5, 2878, 3107, 1113, 1103, 7936, 7343, 1103, 6291, 2428, 2254, 24395, 6, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04194624349474907, -0.11263877898454666, -0.1349000632762909, -0.258392333984375, -0.2655038833618164, -0.2655038833618164, -0.2655038833618164, -0.2655038833618164, -0.2655038833618164, -0.2655038833618164], "metadata": {"source_tokens": ["These", "are", "visually", "very", "similar", "to", "part", "number", "218", "##90", "##14", "##-", "##00", "##-", "##21", "##1", ",", "with", "the", "same", "AT", "style", "plug", "and", "chassis", ",", "silver", "label", "on", "the", "reverse", "bearing", "the", "Any", "##K", "##ey", "moniker", ",", "screw", "##s", "holding", "the", "keyboard", "together", ",", "mac", "##ro", "programming", "requiring", "the", "control", "key", ",", "and", "lacking", "the", "Any", "##K", "##ey", "inscription", "on", "their", "face", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "These", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "visually", "very", "similar", "to", "part", "number", "218", "##90", "##14", "##-", "##00", "##-", "##21", "##1", "[unused6]", "[SEP]", "[unused1]", "silver", "label", "on", "the", "reverse", "bearing", "the", "Any", "##K", "##ey", "moniker", "[unused2]", "[unused3]", "be", "screw", "##s", "holding", "the", "keyboard", "together", "[unused4]", "[unused5]", "mac", "##ro", "programming", "requiring", "the", "control", "key", ",", "and", "and", "lacking", "the", "Any", "##K", "##ey", "inscription", "on", "their", "face", "[unused6]", "[SEP]", "[unused1]", "the", "reverse", "bearing", "the", "Any", "##K", "##ey", "moniker", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "silver", "label", "on", "the", "reverse", "bearing", "the", "Any", "##K", "##ey", "moniker", "[unused6]", "[SEP]"]]}

input 340:  {"source": "These beams stem from a cosmic energy source called the `` Omega Effect '' .\n"}
prediction:  {"predictions": [[1, 170, 21545, 2308, 2674, 2, 3, 1270, 4, 5, 1103, 169, 28152, 17648, 27007, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1636, 13903, 2, 3, 1144, 4, 5, 1636, 13903, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1636, 13903, 2, 3, 8175, 4, 5, 1121, 170, 21545, 2308, 2674, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04103413224220276, -0.14335131645202637, -0.08154482394456863, -0.013031482696533203, -0.012202262878417969, -0.012202262878417969, -0.012202262878417969, -0.012202262878417969, -0.012202262878417969, -0.012202262878417969], "metadata": {"source_tokens": ["These", "beams", "stem", "from", "a", "cosmic", "energy", "source", "called", "the", "`", "##`", "Omega", "Effect", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "cosmic", "energy", "source", "[unused2]", "[unused3]", "called", "[unused4]", "[unused5]", "the", "`", "##`", "Omega", "Effect", "[unused6]", "[SEP]", "[unused1]", "These", "beams", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "These", "beams", "[unused6]", "[SEP]", "[unused1]", "These", "beams", "[unused2]", "[unused3]", "stem", "[unused4]", "[unused5]", "from", "a", "cosmic", "energy", "source", "[unused6]", "[SEP]"]]}

input 341:  {"source": "These objects are thrown away if their screen projection is too small .\n"}
prediction:  {"predictions": [[1, 1636, 4546, 2, 3, 1132, 6358, 4, 5, 1283, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1147, 3251, 15178, 2, 3, 1110, 4, 5, 1315, 1353, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0655883178114891, -0.041590068489313126, -0.012753009796142578, -0.012588977813720703, -0.012588977813720703, -0.012588977813720703, -0.012588977813720703, -0.012588977813720703, -0.012588977813720703, -0.012588977813720703], "metadata": {"source_tokens": ["These", "objects", "are", "thrown", "away", "if", "their", "screen", "projection", "is", "too", "small", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "These", "objects", "[unused2]", "[unused3]", "are", "thrown", "[unused4]", "[unused5]", "away", "[unused6]", "[SEP]", "[unused1]", "their", "screen", "projection", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "too", "small", "[unused6]", "[SEP]"]]}

input 342:  {"source": "These orientations allow easy movement , i.e. degrees of freedom , and thus lowers entropy minimally .\n"}
prediction:  {"predictions": [[1, 1636, 10592, 1116, 2, 3, 2621, 4, 5, 3123, 2230, 117, 178, 28138, 1162, 28138, 4842, 1104, 4438, 117, 1105, 2456, 2211, 1116, 4035, 25444, 10298, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0304143987596035, -0.023902416229248047, -0.024648189544677734, -0.024648189544677734, -0.024648189544677734, -0.024648189544677734, -0.024648189544677734, -0.024648189544677734, -0.024648189544677734, -0.024648189544677734], "metadata": {"source_tokens": ["These", "orientation", "##s", "allow", "easy", "movement", ",", "i", "##.", "##e", "##.", "degrees", "of", "freedom", ",", "and", "thus", "lower", "##s", "en", "##tropy", "minimal", "##ly", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "These", "orientation", "##s", "[unused2]", "[unused3]", "allow", "[unused4]", "[unused5]", "easy", "movement", ",", "i", "##.", "##e", "##.", "degrees", "of", "freedom", ",", "and", "thus", "lower", "##s", "en", "##tropy", "minimal", "##ly", "[unused6]", "[SEP]"]]}

input 343:  {"source": "These were often related to European conflict , as the Stuart Pretenders were aided and encouraged by Britain 's continental enemies for their own ends .\n"}
prediction:  {"predictions": [[1, 1103, 6395, 11689, 22910, 1468, 2, 3, 1127, 12340, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6395, 11689, 22910, 1468, 2, 3, 1129, 1129, 6182, 4, 5, 1118, 2855, 112, 1116, 10998, 6380, 1111, 1147, 1319, 3769, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1636, 2, 3, 1127, 2272, 4, 5, 1106, 1735, 4139, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06255415827035904, -0.129675954580307, -0.025238294154405594, -0.09103012084960938, -0.09377861022949219, -0.09377861022949219, -0.09377861022949219, -0.09377861022949219, -0.09377813339233398, -0.09377813339233398], "metadata": {"source_tokens": ["These", "were", "often", "related", "to", "European", "conflict", ",", "as", "the", "Stuart", "Pre", "##tend", "##ers", "were", "aided", "and", "encouraged", "by", "Britain", "'", "##s", "continental", "enemies", "for", "their", "own", "ends", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Stuart", "Pre", "##tend", "##ers", "[unused2]", "[unused3]", "were", "aided", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "the", "Stuart", "Pre", "##tend", "##ers", "[unused2]", "[unused3]", "be", "be", "encouraged", "[unused4]", "[unused5]", "by", "Britain", "'", "##s", "continental", "enemies", "for", "their", "own", "ends", "[unused6]", "[SEP]", "[unused1]", "These", "[unused2]", "[unused3]", "were", "related", "[unused4]", "[unused5]", "to", "European", "conflict", "[unused6]", "[SEP]"]]}

input 344:  {"source": "They beat Milligan 1-0 , Grand View 3-0 , Webber International 1-0 and Azusa Pacific 0-0 to win the NAIA National Championships .\n"}
prediction:  {"predictions": [[1, 1220, 2, 3, 3222, 4, 5, 7664, 10888, 122, 28137, 1568, 1106, 1782, 1103, 151, 1592, 9984, 1305, 2708, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7664, 10888, 122, 28137, 1568, 2, 3, 1110, 4, 5, 2224, 10344, 124, 28137, 1568, 21630, 1570, 122, 28137, 1568, 1105, 138, 10337, 3202, 2662, 121, 28137, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.026197433471679688, -0.043871376663446426, -0.06244087219238281, -0.06483268737792969, -0.06483221054077148, -0.06483268737792969, -0.06483268737792969, -0.06483268737792969, -0.06483268737792969, -0.06483268737792969], "metadata": {"source_tokens": ["They", "beat", "Mill", "##igan", "1", "##-", "##0", ",", "Grand", "View", "3", "##-", "##0", ",", "Webber", "International", "1", "##-", "##0", "and", "A", "##zu", "##sa", "Pacific", "0", "##-", "##0", "to", "win", "the", "N", "##A", "##IA", "National", "Championships", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "They", "[unused2]", "[unused3]", "beat", "[unused4]", "[unused5]", "Mill", "##igan", "1", "##-", "##0", "to", "win", "the", "N", "##A", "##IA", "National", "Championships", "[unused6]", "[SEP]", "[unused1]", "Mill", "##igan", "1", "##-", "##0", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Grand", "View", "3", "##-", "##0", "Webber", "International", "1", "##-", "##0", "and", "A", "##zu", "##sa", "Pacific", "0", "##-", "##0", "[unused6]", "[SEP]"]]}

input 345:  {"source": "They have included some of the most dangerous assassins in the world including Lady Shiva , David Cain , and Merlyn .\n"}
prediction:  {"predictions": [[1, 1220, 2, 3, 1138, 1529, 4, 5, 1199, 1104, 1103, 1211, 4249, 27459, 1107, 1103, 1362, 1259, 2876, 12945, 117, 1681, 11753, 117, 1105, 2508, 25339, 1179, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00023211637744680047, -0.056780338287353516, -0.043401241302490234, -0.043401241302490234, -0.043401241302490234, -0.043401241302490234, -0.043401241302490234, -0.043401241302490234, -0.043401241302490234, -0.043401241302490234], "metadata": {"source_tokens": ["They", "have", "included", "some", "of", "the", "most", "dangerous", "assassins", "in", "the", "world", "including", "Lady", "Shiva", ",", "David", "Cain", ",", "and", "Me", "##rly", "##n", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "They", "[unused2]", "[unused3]", "have", "included", "[unused4]", "[unused5]", "some", "of", "the", "most", "dangerous", "assassins", "in", "the", "world", "including", "Lady", "Shiva", ",", "David", "Cain", ",", "and", "Me", "##rly", "##n", "[unused6]", "[SEP]"]]}

input 346:  {"source": "They usually go through a period of dormancy after flowering .\n"}
prediction:  {"predictions": [[1, 1220, 2, 3, 1301, 4, 5, 1194, 170, 1669, 1104, 22181, 10413, 1170, 11853, 1932, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00019158257055096328, -0.03947305679321289, -0.045813560485839844, -0.04581308364868164, -0.04581308364868164, -0.04581308364868164, -0.04581308364868164, -0.04581308364868164, -0.04581308364868164, -0.04581308364868164], "metadata": {"source_tokens": ["They", "usually", "go", "through", "a", "period", "of", "dorm", "##ancy", "after", "flowering", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "They", "[unused2]", "[unused3]", "go", "[unused4]", "[unused5]", "through", "a", "period", "of", "dorm", "##ancy", "after", "flowering", "usually", "[unused6]", "[SEP]"]]}

input 347:  {"source": "Third TV drama series was broadcast in 2008 - , featuring Mao Inoue as Anmitsu .\n"}
prediction:  {"predictions": [[1, 4180, 1794, 3362, 1326, 2, 3, 1108, 3012, 4, 5, 1107, 1369, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4180, 1794, 3362, 1326, 2, 3, 3022, 4, 5, 16922, 1130, 6094, 1162, 1112, 1760, 9084, 6385, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009426879696547985, -0.025422489270567894, -0.016332149505615234, -0.016998291015625, -0.016998291015625, -0.016998291015625, -0.016998291015625, -0.016998291015625, -0.016998291015625, -0.016998291015625], "metadata": {"source_tokens": ["Third", "TV", "drama", "series", "was", "broadcast", "in", "2008", "-", ",", "featuring", "Mao", "In", "##ou", "##e", "as", "An", "##mit", "##su", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Third", "TV", "drama", "series", "[unused2]", "[unused3]", "was", "broadcast", "[unused4]", "[unused5]", "in", "2008", "[unused6]", "[SEP]", "[unused1]", "Third", "TV", "drama", "series", "[unused2]", "[unused3]", "featuring", "[unused4]", "[unused5]", "Mao", "In", "##ou", "##e", "as", "An", "##mit", "##su", "[unused6]", "[SEP]"]]}

input 348:  {"source": "This attire has also become popular with women of other communities .\n"}
prediction:  {"predictions": [[1, 1188, 22604, 2, 3, 1144, 1145, 1561, 4, 5, 1927, 1114, 1535, 1104, 1168, 3611, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00014675987767986953, -0.06681060791015625, -0.06079530715942383, -0.06079530715942383, -0.06079530715942383, -0.06079530715942383, -0.06079530715942383, -0.06079530715942383, -0.06079530715942383, -0.06079530715942383], "metadata": {"source_tokens": ["This", "attire", "has", "also", "become", "popular", "with", "women", "of", "other", "communities", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "attire", "[unused2]", "[unused3]", "has", "also", "become", "[unused4]", "[unused5]", "popular", "with", "women", "of", "other", "communities", "[unused6]", "[SEP]"]]}

input 349:  {"source": "This can be further generalized by defining a Q-valued Euler characteristic for certain finite categories , a notion compatible with the Euler characteristics of graphs , orbifolds and posets mentioned above .\n"}
prediction:  {"predictions": [[1, 1188, 2, 3, 1169, 1129, 22214, 4, 5, 1118, 13682, 170, 154, 28137, 7501, 17226, 142, 8722, 1197, 7987, 1111, 2218, 10996, 6788, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2218, 10996, 6788, 2, 3, 1129, 1129, 4, 5, 170, 9162, 12173, 1114, 1103, 142, 8722, 1197, 5924, 1104, 21562, 117, 1137, 5567, 10787, 1116, 1105, 14131, 2145, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.053683266043663025, -0.1293896734714508, -0.29926538467407227, -0.3060884475708008, -0.3060884475708008, -0.3060884475708008, -0.3060884475708008, -0.306088924407959, -0.3060884475708008, -0.3060884475708008], "metadata": {"source_tokens": ["This", "can", "be", "further", "generalized", "by", "defining", "a", "Q", "##-", "##val", "##ued", "E", "##ule", "##r", "characteristic", "for", "certain", "finite", "categories", ",", "a", "notion", "compatible", "with", "the", "E", "##ule", "##r", "characteristics", "of", "graphs", ",", "or", "##bi", "##fold", "##s", "and", "pose", "##ts", "mentioned", "above", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "[unused2]", "[unused3]", "can", "be", "generalized", "[unused4]", "[unused5]", "by", "defining", "a", "Q", "##-", "##val", "##ued", "E", "##ule", "##r", "characteristic", "for", "certain", "finite", "categories", "[unused6]", "[SEP]", "[unused1]", "certain", "finite", "categories", "[unused2]", "[unused3]", "be", "be", "[unused4]", "[unused5]", "a", "notion", "compatible", "with", "the", "E", "##ule", "##r", "characteristics", "of", "graphs", ",", "or", "##bi", "##fold", "##s", "and", "pose", "##ts", "[unused6]", "[SEP]"]]}

input 350:  {"source": "This change was soon picked up by Huguenot writers , who began to expand on Calvin and promote the idea of the sovereignty of the people , ideas to which Catholic writers and preachers responded fiercely .\n"}
prediction:  {"predictions": [[1, 1188, 1849, 2, 3, 1108, 3015, 1146, 4, 5, 1118, 20164, 7222, 12512, 5094, 1770, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20164, 7222, 12512, 5094, 2, 3, 1310, 4, 5, 1106, 7380, 1113, 11110, 1105, 4609, 1103, 1911, 1104, 1103, 13578, 1104, 1103, 1234, 117, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2336, 5094, 1105, 18154, 1116, 2, 3, 5133, 4, 5, 17494, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.021979650482535362, -0.04858376085758209, -0.1187601089477539, -0.25957345962524414, -0.24264097213745117, -0.24264097213745117, -0.24264097213745117, -0.24264097213745117, -0.24264097213745117, -0.24264097213745117], "metadata": {"source_tokens": ["This", "change", "was", "soon", "picked", "up", "by", "Hu", "##gue", "##not", "writers", ",", "who", "began", "to", "expand", "on", "Calvin", "and", "promote", "the", "idea", "of", "the", "sovereignty", "of", "the", "people", ",", "ideas", "to", "which", "Catholic", "writers", "and", "preacher", "##s", "responded", "fiercely", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "change", "[unused2]", "[unused3]", "was", "picked", "up", "[unused4]", "[unused5]", "by", "Hu", "##gue", "##not", "writers", "soon", "[unused6]", "[SEP]", "[unused1]", "Hu", "##gue", "##not", "writers", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "to", "expand", "on", "Calvin", "and", "promote", "the", "idea", "of", "the", "sovereignty", "of", "the", "people", ",", "[unused6]", "[SEP]", "[unused1]", "Catholic", "writers", "and", "preacher", "##s", "[unused2]", "[unused3]", "responded", "[unused4]", "[unused5]", "fiercely", "[unused6]", "[SEP]"]]}

input 351:  {"source": "This engine was equipped with an electronically controlled carburetor .\n"}
prediction:  {"predictions": [[1, 1188, 2395, 2, 3, 1108, 5440, 4, 5, 1114, 1126, 4828, 2716, 4013, 1610, 19364, 20713, 1197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-2.822876012942288e-05, -0.014300346374511719, -0.014513492584228516, -0.014513492584228516, -0.014513492584228516, -0.014513492584228516, -0.014513492584228516, -0.014513492584228516, -0.014513492584228516, -0.014513492584228516], "metadata": {"source_tokens": ["This", "engine", "was", "equipped", "with", "an", "electronic", "##ally", "controlled", "car", "##bur", "##eto", "##r", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "engine", "[unused2]", "[unused3]", "was", "equipped", "[unused4]", "[unused5]", "with", "an", "electronic", "##ally", "controlled", "car", "##bur", "##eto", "##r", "[unused6]", "[SEP]"]]}

input 352:  {"source": "This had considerable implications for the Welsh language as it was the main language of the nonconformist churches in Wales .\n"}
prediction:  {"predictions": [[1, 1188, 2, 3, 1125, 4, 5, 5602, 14755, 1111, 1103, 5447, 1846, 1112, 1122, 1108, 1103, 1514, 1846, 1104, 1103, 1664, 7235, 13199, 1776, 5189, 1107, 2717, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 1103, 1514, 1846, 1104, 1103, 1664, 7235, 13199, 1776, 5189, 1107, 2717, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02732476033270359, -0.028979327529668808, -0.028381824493408203, -0.027584552764892578, -0.027584552764892578, -0.027584552764892578, -0.027584552764892578, -0.027584552764892578, -0.027584552764892578, -0.027584552764892578], "metadata": {"source_tokens": ["This", "had", "considerable", "implications", "for", "the", "Welsh", "language", "as", "it", "was", "the", "main", "language", "of", "the", "non", "##con", "##form", "##ist", "churches", "in", "Wales", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "considerable", "implications", "for", "the", "Welsh", "language", "as", "it", "was", "the", "main", "language", "of", "the", "non", "##con", "##form", "##ist", "churches", "in", "Wales", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "main", "language", "of", "the", "non", "##con", "##form", "##ist", "churches", "in", "Wales", "[unused6]", "[SEP]"]]}

input 353:  {"source": "This is most common in Western countries in those with Barrett 's esophagus , and occurs in the cuboidal cells .\n"}
prediction:  {"predictions": [[1, 1188, 2, 3, 4365, 4, 5, 1107, 1103, 16408, 4043, 13293, 3652, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1188, 2, 3, 1110, 4, 5, 1211, 1887, 1107, 2102, 2182, 1107, 1343, 1114, 12908, 112, 1116, 13936, 4184, 2328, 12909, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03987441211938858, -0.01081685721874237, -0.013058662414550781, -0.01279592514038086, -0.01279592514038086, -0.01279592514038086, -0.01279592514038086, -0.01279592514038086, -0.01279592514038086, -0.01279592514038086], "metadata": {"source_tokens": ["This", "is", "most", "common", "in", "Western", "countries", "in", "those", "with", "Barrett", "'", "##s", "es", "##op", "##ha", "##gus", ",", "and", "occurs", "in", "the", "cu", "##bo", "##idal", "cells", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "[unused2]", "[unused3]", "occurs", "[unused4]", "[unused5]", "in", "the", "cu", "##bo", "##idal", "cells", "[unused6]", "[SEP]", "[unused1]", "This", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "most", "common", "in", "Western", "countries", "in", "those", "with", "Barrett", "'", "##s", "es", "##op", "##ha", "##gus", "[unused6]", "[SEP]"]]}

input 354:  {"source": "This line was extended east by the Prahran & Malvern Tramways Trust from Hawthorn Road to Darling Road , Malvern East on 13 November 1913 .\n"}
prediction:  {"predictions": [[1, 1188, 1413, 2, 3, 1108, 2925, 4, 5, 1746, 1118, 1103, 153, 10659, 4047, 111, 18880, 24472, 157, 4515, 8520, 4623, 1121, 26493, 1914, 1106, 12777, 1914, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12777, 1914, 2, 3, 1110, 4, 5, 18880, 24472, 1689, 1113, 1492, 1379, 4325, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06128430739045143, -0.06265159696340561, -0.1323995590209961, -0.13250398635864258, -0.13250446319580078, -0.13250398635864258, -0.13250398635864258, -0.13250398635864258, -0.13250398635864258, -0.13250398635864258], "metadata": {"source_tokens": ["This", "line", "was", "extended", "east", "by", "the", "P", "##rah", "##ran", "&", "Mal", "##vern", "T", "##ram", "##ways", "Trust", "from", "Hawthorn", "Road", "to", "Darling", "Road", ",", "Mal", "##vern", "East", "on", "13", "November", "1913", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "line", "[unused2]", "[unused3]", "was", "extended", "[unused4]", "[unused5]", "east", "by", "the", "P", "##rah", "##ran", "&", "Mal", "##vern", "T", "##ram", "##ways", "Trust", "from", "Hawthorn", "Road", "to", "Darling", "Road", "[unused6]", "[SEP]", "[unused1]", "Darling", "Road", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Mal", "##vern", "East", "on", "13", "November", "1913", "[unused6]", "[SEP]"]]}

input 355:  {"source": "This mutation gives him superhuman strength , speed , reflexes , agility , flexibility , dexterity , coordination , balance , and endurance .\n"}
prediction:  {"predictions": [[1, 1188, 17895, 2, 3, 3114, 4, 5, 1140, 7688, 15319, 3220, 117, 2420, 117, 27820, 1279, 117, 170, 5389, 11796, 117, 18605, 117, 1260, 1775, 2083, 1785, 117, 14501, 117, 5233, 117, 1105, 20655, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004434030503034592, -0.03910684585571289, -0.04003095626831055, -0.04003095626831055, -0.04003095626831055, -0.04003095626831055, -0.04003095626831055, -0.04003095626831055, -0.04003095626831055, -0.04003095626831055], "metadata": {"source_tokens": ["This", "mutation", "gives", "him", "super", "##human", "strength", ",", "speed", ",", "reflex", "##es", ",", "a", "##gi", "##lity", ",", "flexibility", ",", "de", "##x", "##ter", "##ity", ",", "coordination", ",", "balance", ",", "and", "endurance", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "mutation", "[unused2]", "[unused3]", "gives", "[unused4]", "[unused5]", "him", "super", "##human", "strength", ",", "speed", ",", "reflex", "##es", ",", "a", "##gi", "##lity", ",", "flexibility", ",", "de", "##x", "##ter", "##ity", ",", "coordination", ",", "balance", ",", "and", "endurance", "[unused6]", "[SEP]"]]}

input 356:  {"source": "This policy was , however , opposed by the miners who demanded that the inspections be carried out by experienced colliers .\n"}
prediction:  {"predictions": [[1, 1188, 2818, 2, 3, 1108, 4, 5, 1649, 4151, 1118, 1103, 13418, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 13418, 2, 3, 5648, 4, 5, 1115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 11820, 1116, 2, 3, 1129, 2446, 1149, 4, 5, 1118, 4531, 1884, 14367, 1733, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.039877407252788544, -0.08596272766590118, -0.0066632842645049095, -0.01575756072998047, -0.015880584716796875, -0.015880584716796875, -0.015880584716796875, -0.015880584716796875, -0.015880584716796875, -0.015880584716796875], "metadata": {"source_tokens": ["This", "policy", "was", ",", "however", ",", "opposed", "by", "the", "miners", "who", "demanded", "that", "the", "inspection", "##s", "be", "carried", "out", "by", "experienced", "co", "##llie", "##rs", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "policy", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "however", "opposed", "by", "the", "miners", "[unused6]", "[SEP]", "[unused1]", "the", "miners", "[unused2]", "[unused3]", "demanded", "[unused4]", "[unused5]", "that", "[unused6]", "[SEP]", "[unused1]", "the", "inspection", "##s", "[unused2]", "[unused3]", "be", "carried", "out", "[unused4]", "[unused5]", "by", "experienced", "co", "##llie", "##rs", "[unused6]", "[SEP]"]]}

input 357:  {"source": "To assist the pope in the many calls for his help and charity , Pascalina organized and led the `` Magazzino '' , a private papal charity office which employed up to 40 helpers and continued until 1959 .\n"}
prediction:  {"predictions": [[1, 19636, 2983, 2, 3, 3366, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 19636, 2983, 2, 3, 1521, 4, 5, 1103, 169, 28152, 7085, 2571, 15284, 2728, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 2029, 16701, 6630, 1701, 2, 3, 1129, 1598, 4, 5, 1235, 3003, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 2029, 16701, 6630, 1701, 2, 3, 4071, 4, 5, 1146, 1106, 1969, 1494, 1468, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.12915058434009552, -0.062148530036211014, -0.0850023627281189, -0.07713200151920319, -0.023505687713623047, -0.023906230926513672, -0.023906230926513672, -0.023906230926513672, -0.023906230926513672, -0.023906230926513672], "metadata": {"source_tokens": ["To", "assist", "the", "pope", "in", "the", "many", "calls", "for", "his", "help", "and", "charity", ",", "Pascal", "##ina", "organized", "and", "led", "the", "`", "##`", "Ma", "##ga", "##zzi", "##no", "'", "##'", ",", "a", "private", "papal", "charity", "office", "which", "employed", "up", "to", "40", "help", "##ers", "and", "continued", "until", "1959", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pascal", "##ina", "[unused2]", "[unused3]", "organized", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Pascal", "##ina", "[unused2]", "[unused3]", "led", "[unused4]", "[unused5]", "the", "`", "##`", "Ma", "##ga", "##zzi", "##no", "[unused6]", "[SEP]", "[unused1]", "a", "private", "papal", "charity", "office", "[unused2]", "[unused3]", "be", "continued", "[unused4]", "[unused5]", "until", "1959", "[unused6]", "[SEP]", "[unused1]", "a", "private", "papal", "charity", "office", "[unused2]", "[unused3]", "employed", "[unused4]", "[unused5]", "up", "to", "40", "help", "##ers", "[unused6]", "[SEP]"]]}

input 358:  {"source": "To keep the family together , Michael asks his self-centered twin sister Lindsay , her husband Tobias and their daughter Maeby to live together in the Bluth model home with him and George Michael .\n"}
prediction:  {"predictions": [[1, 1847, 2, 3, 4390, 4, 5, 1117, 2191, 28137, 8298, 5686, 5930, 2104, 12218, 117, 1123, 2252, 18167, 1105, 1147, 1797, 1106, 1686, 1487, 1107, 1103, 15223, 1582, 2235, 1313, 1114, 1140, 1105, 1667, 1847, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04018078371882439, -0.09346771240234375, -0.10975503921508789, -0.10975503921508789, -0.10975503921508789, -0.10975503921508789, -0.10975503921508789, -0.10975503921508789, -0.10975503921508789, -0.10975503921508789], "metadata": {"source_tokens": ["To", "keep", "the", "family", "together", ",", "Michael", "asks", "his", "self", "##-", "##cent", "##ered", "twin", "sister", "Lindsay", ",", "her", "husband", "Tobias", "and", "their", "daughter", "Mae", "##by", "to", "live", "together", "in", "the", "Blu", "##th", "model", "home", "with", "him", "and", "George", "Michael", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Michael", "[unused2]", "[unused3]", "asks", "[unused4]", "[unused5]", "his", "self", "##-", "##cent", "##ered", "twin", "sister", "Lindsay", ",", "her", "husband", "Tobias", "and", "their", "daughter", "to", "live", "together", "in", "the", "Blu", "##th", "model", "home", "with", "him", "and", "George", "Michael", "[unused6]", "[SEP]"]]}

input 359:  {"source": "To the Medieval school of Jewish Philosophy , that framed Judaism in light of Greek thought and human intellect , God the Infinite has no needs .\n"}
prediction:  {"predictions": [[1, 1103, 27526, 2, 3, 1144, 4, 5, 1185, 2993, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2778, 8714, 2, 3, 10577, 4, 5, 14142, 1107, 1609, 1104, 2414, 1354, 1105, 1769, 1107, 7854, 18465, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.12497404217720032, -0.057486001402139664, -0.16717195510864258, -0.15317678451538086, -0.15317678451538086, -0.15317678451538086, -0.15317678451538086, -0.15317678451538086, -0.15317678451538086, -0.15317678451538086], "metadata": {"source_tokens": ["To", "the", "Medieval", "school", "of", "Jewish", "Philosophy", ",", "that", "framed", "Judaism", "in", "light", "of", "Greek", "thought", "and", "human", "in", "##tel", "##lect", ",", "God", "the", "Infinite", "has", "no", "needs", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Infinite", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "no", "needs", "[unused6]", "[SEP]", "[unused1]", "Jewish", "Philosophy", "[unused2]", "[unused3]", "framed", "[unused4]", "[unused5]", "Judaism", "in", "light", "of", "Greek", "thought", "and", "human", "in", "##tel", "##lect", "[unused6]", "[SEP]"]]}

input 360:  {"source": "To the north , along and across the same border , live speakers of Lakha .\n"}
prediction:  {"predictions": [[1, 1706, 1103, 1564, 1373, 1105, 1506, 1103, 1269, 3070, 2, 3, 1686, 4, 5, 7417, 1104, 2001, 14457, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05023193359375, -0.13607454299926758, -0.13293838500976562, -0.13293838500976562, -0.13293838500976562, -0.13293838500976562, -0.13293838500976562, -0.13293838500976562, -0.13293838500976562, -0.13293838500976562], "metadata": {"source_tokens": ["To", "the", "north", ",", "along", "and", "across", "the", "same", "border", ",", "live", "speakers", "of", "La", "##kha", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "To", "the", "north", "along", "and", "across", "the", "same", "border", "[unused2]", "[unused3]", "live", "[unused4]", "[unused5]", "speakers", "of", "La", "##kha", "[unused6]", "[SEP]"]]}

input 361:  {"source": "Total ` Fresh Food Story ' constructed at the end of the North Mall .\n"}
prediction:  {"predictions": [[1, 8653, 169, 15756, 6702, 5145, 2, 3, 3033, 4, 5, 1120, 1103, 1322, 1104, 1103, 1456, 11123, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0002579689025878906, -0.009347915649414062, -0.009257793426513672, -0.009257793426513672, -0.009257793426513672, -0.009257793426513672, -0.009257793426513672, -0.009257793426513672, -0.009257793426513672, -0.009257793426513672], "metadata": {"source_tokens": ["Total", "`", "Fresh", "Food", "Story", "'", "constructed", "at", "the", "end", "of", "the", "North", "Mall", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Total", "`", "Fresh", "Food", "Story", "[unused2]", "[unused3]", "constructed", "[unused4]", "[unused5]", "at", "the", "end", "of", "the", "North", "Mall", "[unused6]", "[SEP]"]]}

input 362:  {"source": "Transferred to Key West , Florida , on 1 June 1941 , `` R-11 '' continued her training ship duties throughout the remainder of her career .\n"}
prediction:  {"predictions": [[1, 155, 28137, 14541, 2, 3, 1598, 4, 5, 1123, 2013, 2062, 5078, 2032, 1103, 6311, 1104, 1123, 1578, 1113, 122, 1340, 3018, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008400955237448215, -0.05279254913330078, -0.05318164825439453, -0.05318117141723633, -0.05318117141723633, -0.05318117141723633, -0.05318117141723633, -0.05318117141723633, -0.05318117141723633, -0.05318117141723633], "metadata": {"source_tokens": ["Transfer", "##red", "to", "Key", "West", ",", "Florida", ",", "on", "1", "June", "1941", ",", "`", "##`", "R", "##-", "##11", "'", "##'", "continued", "her", "training", "ship", "duties", "throughout", "the", "remainder", "of", "her", "career", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "R", "##-", "##11", "[unused2]", "[unused3]", "continued", "[unused4]", "[unused5]", "her", "training", "ship", "duties", "throughout", "the", "remainder", "of", "her", "career", "on", "1", "June", "1941", "[unused6]", "[SEP]"]]}

input 363:  {"source": "Trumbull was often incorrectly credited in print as being the sole special-effects creator for 2001 .\n"}
prediction:  {"predictions": [[1, 157, 5697, 17719, 2, 3, 1108, 21605, 5175, 4, 5, 1107, 5911, 1112, 1217, 1103, 6753, 1957, 28137, 11470, 11916, 1116, 9264, 1111, 1630, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00093357905279845, -0.10258340835571289, -0.11101722717285156, -0.11101770401000977, -0.11101722717285156, -0.11101722717285156, -0.11101770401000977, -0.11101722717285156, -0.11101722717285156, -0.11101722717285156], "metadata": {"source_tokens": ["T", "##rum", "##bull", "was", "often", "incorrectly", "credited", "in", "print", "as", "being", "the", "sole", "special", "##-", "##ef", "##fect", "##s", "creator", "for", "2001", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "T", "##rum", "##bull", "[unused2]", "[unused3]", "was", "incorrectly", "credited", "[unused4]", "[unused5]", "in", "print", "as", "being", "the", "sole", "special", "##-", "##ef", "##fect", "##s", "creator", "for", "2001", "often", "[unused6]", "[SEP]"]]}

input 364:  {"source": "Twice divorced and currently married , Ladd is the mother of actress Laura Dern , by her ex-husband , actor Bruce Dern .\n"}
prediction:  {"predictions": [[1, 2001, 13976, 2, 3, 1110, 4, 5, 1103, 1534, 1104, 3647, 6273, 9682, 1179, 117, 1118, 1123, 4252, 28137, 8827, 10198, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027781253680586815, -0.08254337310791016, -0.09336662292480469, -0.09336662292480469, -0.09336662292480469, -0.09336662292480469, -0.09336662292480469, -0.09336662292480469, -0.09336662292480469, -0.09336662292480469], "metadata": {"source_tokens": ["Twice", "divorced", "and", "currently", "married", ",", "La", "##dd", "is", "the", "mother", "of", "actress", "Laura", "Der", "##n", ",", "by", "her", "ex", "##-", "##hus", "##band", ",", "actor", "Bruce", "Der", "##n", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "La", "##dd", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "mother", "of", "actress", "Laura", "Der", "##n", ",", "by", "her", "ex", "##-", "##hus", "##band", "[unused6]", "[SEP]"]]}

input 365:  {"source": "Two seats were won by the Labor-Progressive Party on its own with the re-election of A.A. MacLeod and J.B. Salsberg .\n"}
prediction:  {"predictions": [[1, 1960, 3474, 2, 3, 1127, 1281, 4, 5, 1118, 1103, 6314, 28137, 2101, 24081, 7370, 2109, 1786, 1113, 1157, 1319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1960, 3474, 2, 3, 1127, 1281, 4, 5, 1118, 1103, 6314, 28137, 2101, 24081, 7370, 2109, 1786, 1113, 1157, 1319, 1114, 1103, 1231, 28137, 11194, 5796, 1104, 138, 28138, 1592, 28138, 6603, 18763, 1105, 147, 28138, 2064, 28138, 18613, 19945, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03991982340812683, -0.015587382949888706, -0.029212474822998047, -0.027129173278808594, -0.027129173278808594, -0.027129173278808594, -0.027129173278808594, -0.027129173278808594, -0.027129173278808594, -0.027129173278808594], "metadata": {"source_tokens": ["Two", "seats", "were", "won", "by", "the", "Labor", "##-", "##P", "##rog", "##ress", "##ive", "Party", "on", "its", "own", "with", "the", "re", "##-", "##ele", "##ction", "of", "A", "##.", "##A", "##.", "Mac", "##Leod", "and", "J", "##.", "##B", "##.", "Sal", "##sberg", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Two", "seats", "[unused2]", "[unused3]", "were", "won", "[unused4]", "[unused5]", "by", "the", "Labor", "##-", "##P", "##rog", "##ress", "##ive", "Party", "on", "its", "own", "[unused6]", "[SEP]", "[unused1]", "Two", "seats", "[unused2]", "[unused3]", "were", "won", "[unused4]", "[unused5]", "by", "the", "Labor", "##-", "##P", "##rog", "##ress", "##ive", "Party", "on", "its", "own", "with", "the", "re", "##-", "##ele", "##ction", "of", "A", "##.", "##A", "##.", "Mac", "##Leod", "and", "J", "##.", "##B", "##.", "Sal", "##sberg", "[unused6]", "[SEP]"]]}

input 366:  {"source": "Tyabb also has Tyabb Airport , a private airfield which has been operating for more than thirty years .\n"}
prediction:  {"predictions": [[1, 5331, 6639, 1830, 2, 3, 1144, 4, 5, 5331, 6639, 1830, 3369, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 2029, 11897, 2, 3, 1129, 1144, 1151, 3389, 4, 5, 1111, 1167, 1190, 3961, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012524066492915154, -0.09568820148706436, -0.12909650802612305, -0.13737249374389648, -0.13737249374389648, -0.13737249374389648, -0.13737249374389648, -0.13737249374389648, -0.13737249374389648, -0.13737249374389648], "metadata": {"source_tokens": ["Ty", "##ab", "##b", "also", "has", "Ty", "##ab", "##b", "Airport", ",", "a", "private", "airfield", "which", "has", "been", "operating", "for", "more", "than", "thirty", "years", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ty", "##ab", "##b", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "Ty", "##ab", "##b", "Airport", "[unused6]", "[SEP]", "[unused1]", "a", "private", "airfield", "[unused2]", "[unused3]", "be", "has", "been", "operating", "[unused4]", "[unused5]", "for", "more", "than", "thirty", "years", "[unused6]", "[SEP]"]]}

input 367:  {"source": "US 258 intersects NC 222 in Fountain before entering Edgecombe County .\n"}
prediction:  {"predictions": [[1, 1646, 27434, 2, 3, 18585, 4, 5, 14056, 20640, 1107, 19873, 1196, 5273, 10403, 14231, 1391, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0018133741104975343, -0.015183448791503906, -0.015190601348876953, -0.015190601348876953, -0.015190601348876953, -0.015190601348876953, -0.015190601348876953, -0.015190601348876953, -0.015190601348876953, -0.015190601348876953], "metadata": {"source_tokens": ["US", "258", "intersects", "NC", "222", "in", "Fountain", "before", "entering", "Edge", "##combe", "County", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "US", "258", "[unused2]", "[unused3]", "intersects", "[unused4]", "[unused5]", "NC", "222", "in", "Fountain", "before", "entering", "Edge", "##combe", "County", "[unused6]", "[SEP]"]]}

input 368:  {"source": "Under the Comanche program , each company built different parts of the aircraft .\n"}
prediction:  {"predictions": [[1, 1296, 1419, 2, 3, 1434, 4, 5, 1472, 2192, 1104, 1103, 2163, 2831, 1103, 3291, 1399, 4386, 1788, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-4.7502064262516797e-05, -0.02296304702758789, -0.022213459014892578, -0.022213459014892578, -0.022213459014892578, -0.022213459014892578, -0.022213459014892578, -0.022213459014892578, -0.022213459014892578, -0.022213459014892578], "metadata": {"source_tokens": ["Under", "the", "Co", "##man", "##che", "program", ",", "each", "company", "built", "different", "parts", "of", "the", "aircraft", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "each", "company", "[unused2]", "[unused3]", "built", "[unused4]", "[unused5]", "different", "parts", "of", "the", "aircraft", "Under", "the", "Co", "##man", "##che", "program", "[unused6]", "[SEP]"]]}

input 369:  {"source": "Unlike Uncle Sam later , he is not a figure of authority but rather a yeoman who prefers his small beer and domestic peace , possessed of neither patriarchal power nor heroic defiance .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1110, 1136, 4, 5, 170, 2482, 1104, 3748, 1133, 1897, 170, 6798, 27085, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 6798, 27085, 2, 3, 21042, 4, 5, 1117, 1353, 5298, 1105, 4500, 3519, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 1353, 5298, 1105, 4500, 3519, 2, 3, 8471, 4, 5, 1104, 4534, 27797, 1348, 1540, 4040, 17047, 27071, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05942650884389877, -0.06352481245994568, -0.06434061378240585, -0.18793344497680664, -0.17426061630249023, -0.17426061630249023, -0.17426061630249023, -0.17426061630249023, -0.17426061630249023, -0.17426061630249023], "metadata": {"source_tokens": ["Unlike", "Uncle", "Sam", "later", ",", "he", "is", "not", "a", "figure", "of", "authority", "but", "rather", "a", "ye", "##oman", "who", "prefers", "his", "small", "beer", "and", "domestic", "peace", ",", "possessed", "of", "neither", "patriarch", "##al", "power", "nor", "heroic", "defiance", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "is", "not", "[unused4]", "[unused5]", "a", "figure", "of", "authority", "but", "rather", "a", "ye", "##oman", "later", "[unused6]", "[SEP]", "[unused1]", "a", "ye", "##oman", "[unused2]", "[unused3]", "prefers", "[unused4]", "[unused5]", "his", "small", "beer", "and", "domestic", "peace", "[unused6]", "[SEP]", "[unused1]", "his", "small", "beer", "and", "domestic", "peace", "[unused2]", "[unused3]", "possessed", "[unused4]", "[unused5]", "of", "neither", "patriarch", "##al", "power", "nor", "heroic", "defiance", "[unused6]", "[SEP]"]]}

input 370:  {"source": "Unruly passengers are often put off here to be taken into custody .\n"}
prediction:  {"predictions": [[1, 12118, 23377, 4861, 2, 3, 1132, 1508, 1228, 4, 5, 1303, 1106, 1129, 1678, 1154, 9948, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0008971214410848916, -0.11697149276733398, -0.0883631706237793, -0.0883626937866211, -0.0883626937866211, -0.0883626937866211, -0.0883626937866211, -0.0883626937866211, -0.0883626937866211, -0.0883626937866211], "metadata": {"source_tokens": ["Un", "##ruly", "passengers", "are", "often", "put", "off", "here", "to", "be", "taken", "into", "custody", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Un", "##ruly", "passengers", "[unused2]", "[unused3]", "are", "put", "off", "[unused4]", "[unused5]", "here", "to", "be", "taken", "into", "custody", "often", "[unused6]", "[SEP]"]]}

input 371:  {"source": "Wakeboarding is practiced by both men and women at the competitive level , but they compete in separate categories .\n"}
prediction:  {"predictions": [[1, 1152, 2, 3, 4845, 4, 5, 1107, 2767, 6788, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 13062, 24631, 2, 3, 1110, 8720, 4, 5, 1118, 1241, 1441, 1105, 1535, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.036190468817949295, -0.05244465917348862, -0.10341501235961914, -0.10498237609863281, -0.10498237609863281, -0.10498237609863281, -0.10498237609863281, -0.10498237609863281, -0.10498237609863281, -0.10498237609863281], "metadata": {"source_tokens": ["Wake", "##boarding", "is", "practiced", "by", "both", "men", "and", "women", "at", "the", "competitive", "level", ",", "but", "they", "compete", "in", "separate", "categories", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "they", "[unused2]", "[unused3]", "compete", "[unused4]", "[unused5]", "in", "separate", "categories", "[unused6]", "[SEP]", "[unused1]", "Wake", "##boarding", "[unused2]", "[unused3]", "is", "practiced", "[unused4]", "[unused5]", "by", "both", "men", "and", "women", "[unused6]", "[SEP]"]]}

input 372:  {"source": "Watson has served as Minority Leader since elected by his caucus in November 1998 .\n"}
prediction:  {"predictions": [[1, 7422, 2, 3, 1144, 1462, 4, 5, 1112, 26495, 7308, 1290, 1809, 1118, 1117, 27690, 1107, 1379, 1772, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00013778323773294687, -0.025503158569335938, -0.020586013793945312, -0.02058553695678711, -0.02058553695678711, -0.02058553695678711, -0.02058553695678711, -0.02058553695678711, -0.02058553695678711, -0.02058553695678711], "metadata": {"source_tokens": ["Watson", "has", "served", "as", "Minority", "Leader", "since", "elected", "by", "his", "caucus", "in", "November", "1998", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Watson", "[unused2]", "[unused3]", "has", "served", "[unused4]", "[unused5]", "as", "Minority", "Leader", "since", "elected", "by", "his", "caucus", "in", "November", "1998", "[unused6]", "[SEP]"]]}

input 373:  {"source": "Watson was the founder and editor of `` newcritics.com , '' an online journal of media and arts criticism launched in January , 2007 and shuttered in June , 2009 .\n"}
prediction:  {"predictions": [[1, 1126, 3294, 4897, 1104, 2394, 1105, 3959, 5879, 2, 3, 2536, 4, 5, 1107, 1356, 117, 1384, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7422, 2, 3, 1108, 4, 5, 1103, 3249, 1105, 3045, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1126, 3294, 4897, 1104, 2394, 1105, 3959, 5879, 2, 3, 3210, 7655, 4, 5, 1107, 1340, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07715636491775513, -0.1360306292772293, -0.095061756670475, -0.1104421615600586, -0.11002111434936523, -0.11002111434936523, -0.11002111434936523, -0.11002111434936523, -0.11002111434936523, -0.11002111434936523], "metadata": {"source_tokens": ["Watson", "was", "the", "founder", "and", "editor", "of", "`", "##`", "new", "##c", "##ritic", "##s", "##.", "##com", ",", "'", "##'", "an", "online", "journal", "of", "media", "and", "arts", "criticism", "launched", "in", "January", ",", "2007", "and", "shut", "##tered", "in", "June", ",", "2009", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "an", "online", "journal", "of", "media", "and", "arts", "criticism", "[unused2]", "[unused3]", "launched", "[unused4]", "[unused5]", "in", "January", ",", "2007", "[unused6]", "[SEP]", "[unused1]", "Watson", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "founder", "and", "editor", "[unused6]", "[SEP]", "[unused1]", "an", "online", "journal", "of", "media", "and", "arts", "criticism", "[unused2]", "[unused3]", "shut", "##tered", "[unused4]", "[unused5]", "in", "June", "[unused6]", "[SEP]"]]}

input 374:  {"source": "When Naguib began showing signs of independence from Nasser by distancing himself from the RCC 's land reform decrees and drawing closer to Egypt 's established political forces , namely the Wafd and the Brotherhood , Nasser resolved to depose him .\n"}
prediction:  {"predictions": [[1, 11896, 14607, 2, 3, 10456, 4, 5, 1106, 1260, 14811, 1140, 1332, 11896, 13830, 13292, 1310, 4000, 5300, 1104, 4574, 1121, 11896, 14607, 1118, 4267, 13946, 4869, 1471, 1121, 1103, 25157, 1658, 112, 1116, 1657, 5851, 11903, 1116, 1105, 4619, 2739, 1106, 4498, 112, 1116, 1628, 1741, 2088, 8199, 102, 1, 11896, 14607, 2, 3, 10456, 4, 5, 1106, 1260, 14811, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11896, 13830, 13292, 2, 3, 1310, 4, 5, 4000, 5300, 1104, 4574, 1121, 11896, 14607, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11896, 14607, 2, 3, 10456, 4, 5, 1106, 1260, 14811, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11896, 14607, 2, 3, 10456, 4, 5, 1106, 1260, 14811, 1140, 1332, 11896, 13830, 13292, 1310, 4000, 5300, 1104, 4574, 1121, 11896, 14607, 1118, 4267, 13946, 4869, 1471, 1121, 1103, 25157, 1658, 112, 1116, 1657, 5851, 11903, 1116, 1105, 4619, 2739, 1106, 4498, 112, 1116, 1628, 1741, 2088, 8199, 102, 1, 11896, 14607, 2, 3, 10456, 4, 5, 1106, 1260, 14811, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11896, 14607, 2, 3, 10456, 4, 5, 1106, 1260, 14811, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11896, 14607, 2, 3, 10456, 4, 5, 1106, 1260, 14811, 1140, 1332, 11896, 13830, 13292, 1310, 4000, 5300, 1104, 4574, 1121, 11896, 14607, 1118, 4267, 13946, 4869, 1471, 1121, 1103, 25157, 1658, 112, 1116, 1657, 5851, 11903, 1116, 1105, 4619, 2739, 1106, 4498, 112, 1116, 1628, 1741, 2088, 8199, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.010596967302262783, -0.030064186081290245, -0.0929964929819107, -0.06540818512439728, -0.05516986921429634, -0.11140310764312744, -0.14089825749397278, -0.06393769383430481, -0.19936275482177734, -0.19527769088745117], "metadata": {"source_tokens": ["When", "Na", "##gu", "##ib", "began", "showing", "signs", "of", "independence", "from", "Na", "##sser", "by", "di", "##stan", "##cing", "himself", "from", "the", "RC", "##C", "'", "##s", "land", "reform", "decree", "##s", "and", "drawing", "closer", "to", "Egypt", "'", "##s", "established", "political", "forces", ",", "namely", "the", "W", "##af", "##d", "and", "the", "Brotherhood", ",", "Na", "##sser", "resolved", "to", "de", "##pose", "him", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "resolved", "[unused4]", "[unused5]", "to", "de", "##pose", "him", "When", "Na", "##gu", "##ib", "began", "showing", "signs", "of", "independence", "from", "Na", "##sser", "by", "di", "##stan", "##cing", "himself", "from", "the", "RC", "##C", "'", "##s", "land", "reform", "decree", "##s", "and", "drawing", "closer", "to", "Egypt", "'", "##s", "established", "political", "forces", "namely", "[SEP]", "[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "resolved", "[unused4]", "[unused5]", "to", "de", "##pose", "him", "[unused6]", "[SEP]", "[unused1]", "Na", "##gu", "##ib", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "showing", "signs", "of", "independence", "from", "Na", "##sser", "[unused6]", "[SEP]", "[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "resolved", "[unused4]", "[unused5]", "to", "de", "##pose", "him", "[unused6]", "[SEP]", "[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "resolved", "[unused4]", "[unused5]", "to", "de", "##pose", "him", "When", "Na", "##gu", "##ib", "began", "showing", "signs", "of", "independence", "from", "Na", "##sser", "by", "di", "##stan", "##cing", "himself", "from", "the", "RC", "##C", "'", "##s", "land", "reform", "decree", "##s", "and", "drawing", "closer", "to", "Egypt", "'", "##s", "established", "political", "forces", "namely", "[SEP]", "[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "resolved", "[unused4]", "[unused5]", "to", "de", "##pose", "him", "[unused6]", "[SEP]", "[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "resolved", "[unused4]", "[unused5]", "to", "de", "##pose", "him", "[unused6]", "[SEP]", "[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "resolved", "[unused4]", "[unused5]", "to", "de", "##pose", "him", "When", "Na", "##gu", "##ib", "began", "showing", "signs", "of", "independence", "from", "Na", "##sser", "by", "di", "##stan", "##cing", "himself", "from", "the", "RC", "##C", "'", "##s", "land", "reform", "decree", "##s", "and", "drawing", "closer", "to", "Egypt", "'", "##s", "established", "political", "forces", "namely", "[SEP]"]]}

input 375:  {"source": "When civilian government was introduced in Romblon by the Americans in 16 March 1901 , Banton was one of 11 new municipalities reinstated or created .\n"}
prediction:  {"predictions": [[1, 18393, 1633, 2, 3, 1108, 4, 5, 1141, 1104, 1429, 1207, 7473, 20298, 1137, 1687, 1332, 6688, 1433, 1108, 2234, 1107, 155, 20972, 4934, 1118, 1103, 4038, 1107, 1479, 1345, 5064, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6688, 1433, 2, 3, 1108, 2234, 4, 5, 1107, 155, 20972, 4934, 1118, 1103, 4038, 1107, 1479, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1429, 1207, 7473, 2, 3, 1129, 1687, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04463060572743416, -0.05824049562215805, -0.11997902393341064, -0.09783506393432617, -0.09991264343261719, -0.09991264343261719, -0.09991264343261719, -0.09991264343261719, -0.09991264343261719, -0.09991264343261719], "metadata": {"source_tokens": ["When", "civilian", "government", "was", "introduced", "in", "R", "##omb", "##lon", "by", "the", "Americans", "in", "16", "March", "1901", ",", "Ban", "##ton", "was", "one", "of", "11", "new", "municipalities", "reinstated", "or", "created", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ban", "##ton", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "one", "of", "11", "new", "municipalities", "reinstated", "or", "created", "When", "civilian", "government", "was", "introduced", "in", "R", "##omb", "##lon", "by", "the", "Americans", "in", "16", "March", "1901", "[unused6]", "[SEP]", "[unused1]", "civilian", "government", "[unused2]", "[unused3]", "was", "introduced", "[unused4]", "[unused5]", "in", "R", "##omb", "##lon", "by", "the", "Americans", "in", "16", "[unused6]", "[SEP]", "[unused1]", "11", "new", "municipalities", "[unused2]", "[unused3]", "be", "created", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 376:  {"source": "When the explosion tore through the hut , Stauffenberg was convinced that no one in the room could have survived .\n"}
prediction:  {"predictions": [[1, 1457, 3984, 15475, 8904, 2, 3, 1108, 5857, 4, 5, 1115, 1185, 1141, 1107, 1103, 1395, 1180, 1138, 4399, 1332, 1103, 7552, 9626, 1194, 1103, 16148, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1185, 1141, 1107, 1103, 1395, 2, 3, 1180, 1138, 4399, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0016877404414117336, -0.029771503061056137, -0.09125137329101562, -0.09166669845581055, -0.09166669845581055, -0.09166669845581055, -0.09166669845581055, -0.09166669845581055, -0.09166669845581055, -0.09166669845581055], "metadata": {"source_tokens": ["When", "the", "explosion", "tore", "through", "the", "hut", ",", "St", "##au", "##ffe", "##nberg", "was", "convinced", "that", "no", "one", "in", "the", "room", "could", "have", "survived", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "St", "##au", "##ffe", "##nberg", "[unused2]", "[unused3]", "was", "convinced", "[unused4]", "[unused5]", "that", "no", "one", "in", "the", "room", "could", "have", "survived", "When", "the", "explosion", "tore", "through", "the", "hut", "[unused6]", "[SEP]", "[unused1]", "no", "one", "in", "the", "room", "[unused2]", "[unused3]", "could", "have", "survived", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 377:  {"source": "While pursuing his MFA at Columbia in New York , Scieszka painted apartments .\n"}
prediction:  {"predictions": [[1, 20452, 1905, 1584, 1968, 2, 3, 4331, 4, 5, 10417, 1799, 12137, 1117, 150, 8842, 1120, 3132, 1107, 1203, 1365, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-9.329422755399719e-05, -0.019487380981445312, -0.019118309020996094, -0.019118309020996094, -0.019118309020996094, -0.019118309020996094, -0.019118309020996094, -0.019118309020996094, -0.019118309020996094, -0.019118309020996094], "metadata": {"source_tokens": ["While", "pursuing", "his", "M", "##FA", "at", "Columbia", "in", "New", "York", ",", "Sc", "##ies", "##z", "##ka", "painted", "apartments", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sc", "##ies", "##z", "##ka", "[unused2]", "[unused3]", "painted", "[unused4]", "[unused5]", "apartments", "While", "pursuing", "his", "M", "##FA", "at", "Columbia", "in", "New", "York", "[unused6]", "[SEP]"]]}

input 378:  {"source": "Why the `` Epilogue '' is missing is unknown .\n"}
prediction:  {"predictions": [[1, 1103, 169, 28152, 142, 8508, 12733, 112, 28131, 1110, 3764, 2, 3, 1110, 4, 5, 3655, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03905496746301651, -0.01558685302734375, -0.015410423278808594, -0.015410423278808594, -0.015410423278808594, -0.015410423278808594, -0.015410423278808594, -0.015410423278808594, -0.015410423278808594, -0.015410423278808594], "metadata": {"source_tokens": ["Why", "the", "`", "##`", "E", "##pi", "##logue", "'", "##'", "is", "missing", "is", "unknown", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "`", "##`", "E", "##pi", "##logue", "'", "##'", "is", "missing", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "unknown", "[unused6]", "[SEP]"]]}

input 379:  {"source": "Wide acceptance of zero-energy building technology may require more government incentives or building code regulations , the development of recognized standards , or significant increases in the cost of conventional energy .\n"}
prediction:  {"predictions": [[1, 15268, 10030, 1104, 6756, 28137, 24475, 4873, 1459, 2815, 2, 3, 1336, 4752, 4, 5, 1167, 1433, 24273, 1137, 1459, 3463, 7225, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1459, 3463, 7225, 2, 3, 1110, 4, 5, 1103, 1718, 1104, 3037, 4473, 1137, 2418, 6986, 1107, 1103, 2616, 1104, 7228, 2308, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0036625051870942116, -0.07741578668355942, -0.07140684127807617, -0.07063531875610352, -0.07063531875610352, -0.07063531875610352, -0.07063531875610352, -0.07063531875610352, -0.07063531875610352, -0.07063531875610352], "metadata": {"source_tokens": ["Wide", "acceptance", "of", "zero", "##-", "##ener", "##gy", "building", "technology", "may", "require", "more", "government", "incentives", "or", "building", "code", "regulations", ",", "the", "development", "of", "recognized", "standards", ",", "or", "significant", "increases", "in", "the", "cost", "of", "conventional", "energy", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Wide", "acceptance", "of", "zero", "##-", "##ener", "##gy", "building", "technology", "[unused2]", "[unused3]", "may", "require", "[unused4]", "[unused5]", "more", "government", "incentives", "or", "building", "code", "regulations", "[unused6]", "[SEP]", "[unused1]", "building", "code", "regulations", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "development", "of", "recognized", "standards", "or", "significant", "increases", "in", "the", "cost", "of", "conventional", "energy", "[unused6]", "[SEP]"]]}

input 380:  {"source": "With no assigned task , the Cosmos expressed concern for what Battra might do .\n"}
prediction:  {"predictions": [[1, 1103, 3291, 18818, 2, 3, 4448, 4, 5, 4517, 1111, 1184, 21928, 4487, 1547, 1202, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21928, 4487, 2, 3, 1547, 1202, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00014856125926598907, -0.08021382242441177, -0.020517349243164062, -0.020247936248779297, -0.020247936248779297, -0.020247936248779297, -0.020247936248779297, -0.020247936248779297, -0.020247936248779297, -0.020247936248779297], "metadata": {"source_tokens": ["With", "no", "assigned", "task", ",", "the", "Co", "##smos", "expressed", "concern", "for", "what", "Bat", "##tra", "might", "do", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Co", "##smos", "[unused2]", "[unused3]", "expressed", "[unused4]", "[unused5]", "concern", "for", "what", "Bat", "##tra", "might", "do", "[unused6]", "[SEP]", "[unused1]", "Bat", "##tra", "[unused2]", "[unused3]", "might", "do", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 381:  {"source": "With the help of Morena , the goddess of the underworld , she has captivated Yaromir .\n"}
prediction:  {"predictions": [[1, 1131, 2, 3, 1144, 6707, 3121, 18588, 4, 5, 14680, 16071, 3161, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3046, 1605, 2, 3, 1110, 1103, 9659, 1104, 4, 5, 1103, 23796, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027904033660888672, -0.04191872850060463, -0.07471323013305664, -0.07561063766479492, -0.07561111450195312, -0.07561063766479492, -0.07561063766479492, -0.07561063766479492, -0.07561063766479492, -0.07561063766479492], "metadata": {"source_tokens": ["With", "the", "help", "of", "More", "##na", ",", "the", "goddess", "of", "the", "underworld", ",", "she", "has", "cap", "##ti", "##vated", "Ya", "##rom", "##ir", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "she", "[unused2]", "[unused3]", "has", "cap", "##ti", "##vated", "[unused4]", "[unused5]", "Ya", "##rom", "##ir", "[unused6]", "[SEP]", "[unused1]", "More", "##na", "[unused2]", "[unused3]", "is", "the", "goddess", "of", "[unused4]", "[unused5]", "the", "underworld", "[unused6]", "[SEP]"]]}

input 382:  {"source": "With this act , Russia was officially transformed from an absolute monarchy into a constitutional one , though the exact extent of just `` how '' constitutional quickly became the subject of debate , based upon the emperor 's subsequent actions .\n"}
prediction:  {"predictions": [[1, 2733, 2, 3, 1108, 3184, 8272, 4, 5, 1121, 1126, 7846, 14358, 1154, 170, 7950, 1141, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6129, 6102, 1104, 1198, 169, 28152, 1293, 112, 28131, 7950, 2, 3, 1976, 1245, 4, 5, 1103, 2548, 1104, 5655, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.015600405633449554, -0.0755886435508728, -0.21767473220825195, -0.22743940353393555, -0.22743940353393555, -0.22743940353393555, -0.22743940353393555, -0.22743940353393555, -0.22743940353393555, -0.22743940353393555], "metadata": {"source_tokens": ["With", "this", "act", ",", "Russia", "was", "officially", "transformed", "from", "an", "absolute", "monarchy", "into", "a", "constitutional", "one", ",", "though", "the", "exact", "extent", "of", "just", "`", "##`", "how", "'", "##'", "constitutional", "quickly", "became", "the", "subject", "of", "debate", ",", "based", "upon", "the", "emperor", "'", "##s", "subsequent", "actions", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Russia", "[unused2]", "[unused3]", "was", "officially", "transformed", "[unused4]", "[unused5]", "from", "an", "absolute", "monarchy", "into", "a", "constitutional", "one", "[unused6]", "[SEP]", "[unused1]", "the", "exact", "extent", "of", "just", "`", "##`", "how", "'", "##'", "constitutional", "[unused2]", "[unused3]", "quickly", "became", "[unused4]", "[unused5]", "the", "subject", "of", "debate", "[unused6]", "[SEP]"]]}

input 383:  {"source": "With versions in 1/48 , 1/72 , 1/96 , and 1/144 scale , Big Gun Model Warship combat clubs have rules that make provisions for cannon caliber and armor thickness to be scaled according to that which existed on the prototype vessel .\n"}
prediction:  {"predictions": [[1, 1115, 2, 3, 5131, 4, 5, 1113, 1103, 8933, 5832, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2562, 11274, 6747, 6238, 3157, 4127, 3514, 2, 3, 1129, 21297, 4, 5, 2452, 1106, 1115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2562, 11274, 6747, 6238, 3157, 4127, 3514, 2, 3, 1138, 4, 5, 2995, 1115, 1294, 8939, 1111, 12136, 17836, 1105, 8526, 15830, 1106, 1129, 21297, 2452, 1106, 1115, 6, 102, 102, 1, 2995, 2, 3, 1294, 4, 5, 8939, 1111, 12136, 17836, 1105, 8526, 15830, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.026728015393018723, -0.0861201360821724, -0.06310847401618958, -0.13859400153160095, -0.04671287536621094, -0.04664754867553711, -0.04664754867553711, -0.04664754867553711, -0.04664754867553711, -0.04664754867553711], "metadata": {"source_tokens": ["With", "versions", "in", "1", "##/", "##48", ",", "1", "##/", "##7", "##2", ",", "1", "##/", "##9", "##6", ",", "and", "1", "##/", "##14", "##4", "scale", ",", "Big", "Gun", "Model", "Wars", "##hip", "combat", "clubs", "have", "rules", "that", "make", "provisions", "for", "cannon", "caliber", "and", "armor", "thickness", "to", "be", "scaled", "according", "to", "that", "which", "existed", "on", "the", "prototype", "vessel", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "that", "[unused2]", "[unused3]", "existed", "[unused4]", "[unused5]", "on", "the", "prototype", "vessel", "[unused6]", "[SEP]", "[unused1]", "Big", "Gun", "Model", "Wars", "##hip", "combat", "clubs", "[unused2]", "[unused3]", "be", "scaled", "[unused4]", "[unused5]", "according", "to", "that", "[unused6]", "[SEP]", "[unused1]", "Big", "Gun", "Model", "Wars", "##hip", "combat", "clubs", "[unused2]", "[unused3]", "have", "[unused4]", "[unused5]", "rules", "that", "make", "provisions", "for", "cannon", "caliber", "and", "armor", "thickness", "to", "be", "scaled", "according", "to", "that", "[unused6]", "[SEP]", "[unused1]", "rules", "[unused2]", "[unused3]", "make", "[unused4]", "[unused5]", "provisions", "for", "cannon", "caliber", "and", "armor", "thickness", "[unused6]", "[SEP]"]]}

Batch 3 Test Time =  49.1697211265564  s
Decodertime : 0.0001747608184814453
g_f_logprobs : 0.0385591983795166
Decodertime : 0.00014328956604003906
g_f_logprobs : 0.03774905204772949
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.03764700889587402
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.03757643699645996
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.03754019737243652
Decodertime : 0.0001373291015625
g_f_logprobs : 0.037523746490478516
Decodertime : 0.0001392364501953125
g_f_logprobs : 0.03747105598449707
Decodertime : 0.0001392364501953125
g_f_logprobs : 0.03755545616149902
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.03740549087524414
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.037573814392089844
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.03756117820739746
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.03756427764892578
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.03753185272216797
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.037671566009521484
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.03752613067626953
Decodertime : 0.0001404285430908203
g_f_logprobs : 0.03747367858886719
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.037537336349487305
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.03749418258666992
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.03751826286315918
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.03759002685546875
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.03769063949584961
Decodertime : 0.00013971328735351562
g_f_logprobs : 0.037529945373535156
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.03755331039428711
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.03760838508605957
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.03777265548706055
Decodertime : 0.0001423358917236328
g_f_logprobs : 0.03787422180175781
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.037612199783325195
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.03763294219970703
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.037595510482788086
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.037551164627075195
Decodertime : 0.00014066696166992188
g_f_logprobs : 0.03756117820739746
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.03754305839538574
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.03751039505004883
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.03760385513305664
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.03756594657897949
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.03763175010681152
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.03758502006530762
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.03762364387512207
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.03761458396911621
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.0375823974609375
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.037539005279541016
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.0376591682434082
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.03754472732543945
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.03757119178771973
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.037518978118896484
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.037606239318847656
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.03768754005432129
Decodertime : 0.00014257431030273438
g_f_logprobs : 0.03755021095275879
Decodertime : 0.0001399517059326172
g_f_logprobs : 0.03761601448059082
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.037793636322021484
beam_search_time: 1.9536559581756592 s
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.0590364933013916
Decodertime : 0.0001373291015625
g_f_logprobs : 0.05902385711669922
Decodertime : 0.00014138221740722656
g_f_logprobs : 0.0591890811920166
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.05935168266296387
Decodertime : 0.0001399517059326172
g_f_logprobs : 0.05902290344238281
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.05909156799316406
Decodertime : 0.0001423358917236328
g_f_logprobs : 0.05917191505432129
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.059122562408447266
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.059046030044555664
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.05913090705871582
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.0594022274017334
Decodertime : 0.00013971328735351562
g_f_logprobs : 0.05910897254943848
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.05907917022705078
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.0592653751373291
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.05894589424133301
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.0591588020324707
Decodertime : 0.0001399517059326172
g_f_logprobs : 0.059261322021484375
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.05912375450134277
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.0592348575592041
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.05917477607727051
Decodertime : 0.0001373291015625
g_f_logprobs : 0.05918002128601074
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.05901455879211426
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.05918574333190918
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.05909562110900879
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.05910038948059082
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.05914902687072754
Decodertime : 0.00014328956604003906
g_f_logprobs : 0.05916953086853027
Decodertime : 0.0001697540283203125
g_f_logprobs : 0.059322357177734375
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.059241533279418945
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.059343576431274414
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.059195518493652344
Decodertime : 0.0001399517059326172
g_f_logprobs : 0.059185028076171875
Decodertime : 0.0001373291015625
g_f_logprobs : 0.05915498733520508
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.05924701690673828
Decodertime : 0.0001373291015625
g_f_logprobs : 0.05908679962158203
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.05929112434387207
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.05942201614379883
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.05928301811218262
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.05928492546081543
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.059591054916381836
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.05920720100402832
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.05918550491333008
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.05919051170349121
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.059500694274902344
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.05936169624328613
beam_search_time: 2.7303781509399414 s
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.06941795349121094
Decodertime : 0.0001373291015625
g_f_logprobs : 0.06919455528259277
Decodertime : 0.0001373291015625
g_f_logprobs : 0.06928801536560059
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.06924915313720703
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.06907057762145996
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.06919193267822266
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.069305419921875
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.06937718391418457
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.06921505928039551
Decodertime : 0.0001373291015625
g_f_logprobs : 0.06931328773498535
Decodertime : 0.0001373291015625
g_f_logprobs : 0.06927728652954102
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.0690317153930664
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.0691983699798584
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.06923294067382812
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.06922507286071777
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.06931114196777344
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.0693819522857666
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.0692446231842041
Decodertime : 0.0001373291015625
g_f_logprobs : 0.06944966316223145
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.06940388679504395
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.06929683685302734
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.06952238082885742
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.06939029693603516
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.06919360160827637
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.06935811042785645
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.06926798820495605
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.06930732727050781
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.06923699378967285
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.06927251815795898
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.06940913200378418
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.06960463523864746
Decodertime : 0.00014448165893554688
g_f_logprobs : 0.06955933570861816
Decodertime : 0.00014066696166992188
g_f_logprobs : 0.0694582462310791
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.0694425106048584
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.06926846504211426
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.07166385650634766
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.06938481330871582
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.06939530372619629
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.06934332847595215
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.06929373741149902
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.06923246383666992
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.06932950019836426
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.06923174858093262
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.06937217712402344
Decodertime : 0.0001373291015625
g_f_logprobs : 0.06936907768249512
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.06934738159179688
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.06928753852844238
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.06947445869445801
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.06939697265625
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.06955504417419434
beam_search_time: 3.5423941612243652 s
Decodertime : 0.00014352798461914062
g_f_logprobs : 0.08055281639099121
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.08007049560546875
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.08018374443054199
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.08021211624145508
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.08015608787536621
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.08027052879333496
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.08043694496154785
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.08013796806335449
Decodertime : 0.0001373291015625
g_f_logprobs : 0.08011865615844727
Decodertime : 0.00014019012451171875
g_f_logprobs : 0.08023881912231445
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.08013725280761719
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.08028006553649902
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.08018326759338379
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.08022904396057129
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.08015727996826172
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.08018255233764648
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.08026838302612305
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.08013296127319336
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.08040714263916016
Decodertime : 0.0001373291015625
g_f_logprobs : 0.08028197288513184
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.08026766777038574
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.0802164077758789
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.08042120933532715
Decodertime : 0.00014400482177734375
g_f_logprobs : 0.0802621841430664
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.08028769493103027
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.0803689956665039
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.080230712890625
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.08027219772338867
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.08027887344360352
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.08027386665344238
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.08024978637695312
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.0804586410522461
beam_search_time: 2.6154208183288574 s
Decodertime : 0.0001430511474609375
g_f_logprobs : 0.09852385520935059
Decodertime : 0.00019884109497070312
g_f_logprobs : 0.09675455093383789
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.0965108871459961
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.09662055969238281
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.09723281860351562
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.09663224220275879
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.09661579132080078
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.0966329574584961
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.09662604331970215
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.09680891036987305
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.09658026695251465
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.09672212600708008
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.09685087203979492
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.09676504135131836
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.09671401977539062
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.09661412239074707
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.09676933288574219
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.09674692153930664
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.09671902656555176
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.09673786163330078
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.09653949737548828
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.09684586524963379
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.09664249420166016
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.09667348861694336
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.09698343276977539
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.09678244590759277
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.09658145904541016
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.0967264175415039
Decodertime : 0.00013589859008789062
g_f_logprobs : 0.09676146507263184
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.09684944152832031
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.09672045707702637
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.09669613838195801
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.09662961959838867
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.09690260887145996
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.09683346748352051
beam_search_time: 3.4397809505462646 s
Decodertime : 0.00017070770263671875
g_f_logprobs : 0.11399054527282715
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.11344647407531738
Decodertime : 0.0001373291015625
g_f_logprobs : 0.11378812789916992
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.11377763748168945
Decodertime : 0.0001373291015625
g_f_logprobs : 0.1131753921508789
Decodertime : 0.0001392364501953125
g_f_logprobs : 0.11331462860107422
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.11340212821960449
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.11350393295288086
Decodertime : 0.0001373291015625
g_f_logprobs : 0.11334347724914551
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.11351895332336426
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.11346983909606934
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.11344504356384277
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.11334943771362305
Decodertime : 0.0001373291015625
g_f_logprobs : 0.1135258674621582
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.11362624168395996
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.11328458786010742
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.11345863342285156
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.11338114738464355
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.11338472366333008
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.11353945732116699
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.11350154876708984
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.11351680755615234
Decodertime : 0.0001373291015625
g_f_logprobs : 0.11345577239990234
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.11356639862060547
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.11331367492675781
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.11319756507873535
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.11347270011901855
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.11365127563476562
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.11343908309936523
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.11325263977050781
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.11357665061950684
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.11348485946655273
beam_search_time: 3.6799139976501465 s
Decodertime : 0.00014209747314453125
g_f_logprobs : 0.1315295696258545
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.1304154396057129
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.1305251121520996
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.13035154342651367
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.1305677890777588
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.1303865909576416
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.13042068481445312
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.13049983978271484
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.1303873062133789
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.1305093765258789
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.13025236129760742
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.13192534446716309
Decodertime : 0.00017690658569335938
g_f_logprobs : 0.1303572654724121
Decodertime : 0.0001418590545654297
g_f_logprobs : 0.13026976585388184
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.13039302825927734
Decodertime : 0.00014066696166992188
g_f_logprobs : 0.13015341758728027
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.13037633895874023
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.13019895553588867
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.13024687767028809
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.13025355339050293
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.13043999671936035
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.13027334213256836
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.13052892684936523
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.13069915771484375
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.13045668601989746
Decodertime : 0.0001373291015625
g_f_logprobs : 0.13054156303405762
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.1303267478942871
beam_search_time: 3.564826250076294 s
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.14202618598937988
Decodertime : 0.0001392364501953125
g_f_logprobs : 0.14072322845458984
Decodertime : 0.0001392364501953125
g_f_logprobs : 0.14055085182189941
Decodertime : 0.00013971328735351562
g_f_logprobs : 0.14069342613220215
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.14071083068847656
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.14091849327087402
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.14082002639770508
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.14085960388183594
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.14086270332336426
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.14063549041748047
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.14098739624023438
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.14095091819763184
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.14086031913757324
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.14093852043151855
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.14079666137695312
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.14133691787719727
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.1410655975341797
Decodertime : 0.00014495849609375
g_f_logprobs : 0.1410379409790039
Decodertime : 0.00014400482177734375
g_f_logprobs : 0.14085817337036133
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.14079499244689941
beam_search_time: 2.849743604660034 s
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.15261173248291016
Decodertime : 0.00014090538024902344
g_f_logprobs : 0.151580810546875
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.15149521827697754
Decodertime : 0.00014400482177734375
g_f_logprobs : 0.15117573738098145
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.1512165069580078
Decodertime : 0.00018477439880371094
g_f_logprobs : 0.15134143829345703
Decodertime : 0.0001392364501953125
g_f_logprobs : 0.1511542797088623
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.1513364315032959
Decodertime : 0.0001392364501953125
g_f_logprobs : 0.15153288841247559
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.1513679027557373
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.15123271942138672
Decodertime : 0.0001399517059326172
g_f_logprobs : 0.15116119384765625
Decodertime : 0.00014352798461914062
g_f_logprobs : 0.1513991355895996
Decodertime : 0.000141143798828125
g_f_logprobs : 0.1515049934387207
Decodertime : 0.0001399517059326172
g_f_logprobs : 0.15113425254821777
Decodertime : 0.00014138221740722656
g_f_logprobs : 0.15121769905090332
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.15134263038635254
Decodertime : 0.00014066696166992188
g_f_logprobs : 0.15146994590759277
Decodertime : 0.00014257431030273438
g_f_logprobs : 0.15162038803100586
Decodertime : 0.000148773193359375
g_f_logprobs : 0.15136146545410156
beam_search_time: 3.059784412384033 s
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.16338801383972168
Decodertime : 0.0001399517059326172
g_f_logprobs : 0.16214442253112793
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.16184496879577637
Decodertime : 0.00013971328735351562
g_f_logprobs : 0.1618824005126953
Decodertime : 0.0001404285430908203
g_f_logprobs : 0.1617450714111328
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.16179442405700684
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.16185760498046875
Decodertime : 0.0001404285430908203
g_f_logprobs : 0.1617722511291504
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.1622176170349121
Decodertime : 0.0001392364501953125
g_f_logprobs : 0.16175103187561035
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.16160821914672852
Decodertime : 0.00014066696166992188
g_f_logprobs : 0.16225647926330566
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.1618201732635498
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.1618654727935791
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.1617438793182373
Decodertime : 0.0001399517059326172
g_f_logprobs : 0.16164660453796387
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.16181731224060059
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.1618490219116211
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.16186928749084473
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.16212010383605957
beam_search_time: 3.2707650661468506 s
input 384:  {"source": "Wright was the subject of `` This Is Your Life '' on two occasions : in May 1961 when he was surprised by Eamonn Andrews , and in January 1990 , when Michael Aspel surprised him at Thames Television 's Teddington Studios .\n"}
prediction:  {"predictions": [[1, 1847, 1249, 10522, 2, 3, 3753, 4, 5, 1140, 1120, 11055, 4552, 112, 1116, 6564, 18169, 5406, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 4, 5, 1118, 142, 25902, 1179, 8946, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1188, 2, 3, 2181, 4, 5, 2353, 2583, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04198702052235603, -0.14739085733890533, -0.12637615203857422, -0.08116912841796875, -0.08237743377685547, -0.08237743377685547, -0.08237743377685547, -0.08237743377685547, -0.08237743377685547, -0.08237743377685547], "metadata": {"source_tokens": ["Wright", "was", "the", "subject", "of", "`", "##`", "This", "Is", "Your", "Life", "'", "##'", "on", "two", "occasions", ":", "in", "May", "1961", "when", "he", "was", "surprised", "by", "E", "##amon", "##n", "Andrews", ",", "and", "in", "January", "1990", ",", "when", "Michael", "As", "##pel", "surprised", "him", "at", "Thames", "Television", "'", "##s", "Ted", "##dington", "Studios", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Michael", "As", "##pel", "[unused2]", "[unused3]", "surprised", "[unused4]", "[unused5]", "him", "at", "Thames", "Television", "'", "##s", "Ted", "##dington", "Studios", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "by", "E", "##amon", "##n", "Andrews", "[unused6]", "[SEP]", "[unused1]", "This", "[unused2]", "[unused3]", "Is", "[unused4]", "[unused5]", "Your", "Life", "[unused6]", "[SEP]"]]}

input 385:  {"source": "`` Black Water '' became one of the few records by any act released as a B-side to another Hot 100 hit `` before '' topping the Hot 100 itself .\n"}
prediction:  {"predictions": [[1, 2117, 4434, 2, 3, 1245, 4, 5, 1141, 1104, 1103, 1374, 3002, 1118, 1251, 2496, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1251, 2496, 2, 3, 1308, 4, 5, 1112, 170, 139, 28137, 5570, 1106, 1330, 4126, 1620, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03132088854908943, -0.013133926317095757, -0.252108097076416, -0.2626957893371582, -0.2626957893371582, -0.2626957893371582, -0.2626957893371582, -0.2626957893371582, -0.2626957893371582, -0.2626957893371582], "metadata": {"source_tokens": ["`", "##`", "Black", "Water", "'", "##'", "became", "one", "of", "the", "few", "records", "by", "any", "act", "released", "as", "a", "B", "##-", "##side", "to", "another", "Hot", "100", "hit", "`", "##`", "before", "'", "##'", "topping", "the", "Hot", "100", "itself", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Black", "Water", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "one", "of", "the", "few", "records", "by", "any", "act", "[unused6]", "[SEP]", "[unused1]", "any", "act", "[unused2]", "[unused3]", "released", "[unused4]", "[unused5]", "as", "a", "B", "##-", "##side", "to", "another", "Hot", "100", "[unused6]", "[SEP]"]]}

input 386:  {"source": "`` For a list of all medalists , please see the List of Great American Beer Festival medalists ''\n"}
prediction:  {"predictions": [[1, 1370, 170, 2190, 1104, 1155, 15257, 1116, 2, 3, 4268, 1267, 4, 5, 1103, 5619, 1104, 2038, 1237, 16380, 2263, 15257, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03798758611083031, -0.04317474365234375, -0.04031229019165039, -0.04031229019165039, -0.04031229019165039, -0.04031229019165039, -0.04031229019165039, -0.04031229019165039, -0.04031229019165039, -0.04031229019165039], "metadata": {"source_tokens": ["`", "##`", "For", "a", "list", "of", "all", "medalist", "##s", ",", "please", "see", "the", "List", "of", "Great", "American", "Beer", "Festival", "medalist", "##s", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "For", "a", "list", "of", "all", "medalist", "##s", "[unused2]", "[unused3]", "please", "see", "[unused4]", "[unused5]", "the", "List", "of", "Great", "American", "Beer", "Festival", "medalist", "##s", "[unused6]", "[SEP]"]]}

input 387:  {"source": "`` Greenfish '' was launched by the Electric Boat Co. , Groton , Conn. , 21 December 1945 ; sponsored by Mrs. Thomas J. Doyle ; and commissioned 7 June 1946 , Comdr. R. M. Metcalf commanding .\n"}
prediction:  {"predictions": [[1, 2565, 6529, 2, 3, 1108, 2536, 4, 5, 1118, 1103, 6763, 12936, 3291, 28138, 117, 144, 10595, 1320, 117, 16752, 1179, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2565, 6529, 2, 3, 1108, 2536, 4, 5, 1118, 1103, 6763, 12936, 3291, 28138, 117, 144, 10595, 1320, 117, 16752, 1179, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2565, 6529, 2, 3, 1108, 2536, 4, 5, 1118, 1103, 6763, 12936, 3291, 28138, 117, 144, 10595, 1320, 117, 16752, 1179, 28138, 117, 1626, 1382, 2481, 132, 5988, 1118, 2823, 28138, 1819, 147, 28138, 11296, 132, 1105, 4156, 128, 1340, 3064, 6, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03940002620220184, -0.17794056236743927, -0.16322706639766693, -0.09311962127685547, -0.09547042846679688, -0.09547042846679688, -0.09547042846679688, -0.09547042846679688, -0.09547042846679688, -0.09547042846679688], "metadata": {"source_tokens": ["`", "##`", "Green", "##fish", "'", "##'", "was", "launched", "by", "the", "Electric", "Boat", "Co", "##.", ",", "G", "##rot", "##on", ",", "Con", "##n", "##.", ",", "21", "December", "1945", ";", "sponsored", "by", "Mrs", "##.", "Thomas", "J", "##.", "Doyle", ";", "and", "commissioned", "7", "June", "1946", ",", "Co", "##m", "##dr", "##.", "R", "##.", "M", "##.", "Met", "##cal", "##f", "commanding", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Green", "##fish", "[unused2]", "[unused3]", "was", "launched", "[unused4]", "[unused5]", "by", "the", "Electric", "Boat", "Co", "##.", ",", "G", "##rot", "##on", ",", "Con", "##n", "##.", "[unused6]", "[SEP]", "[unused1]", "Green", "##fish", "[unused2]", "[unused3]", "was", "launched", "[unused4]", "[unused5]", "by", "the", "Electric", "Boat", "Co", "##.", ",", "G", "##rot", "##on", ",", "Con", "##n", "##.", "[unused6]", "[SEP]", "[unused1]", "Green", "##fish", "[unused2]", "[unused3]", "was", "launched", "[unused4]", "[unused5]", "by", "the", "Electric", "Boat", "Co", "##.", ",", "G", "##rot", "##on", ",", "Con", "##n", "##.", ",", "21", "December", "1945", ";", "sponsored", "by", "Mrs", "##.", "Thomas", "J", "##.", "Doyle", ";", "and", "commissioned", "7", "June", "1946", "[unused6]", "[SEP]"]]}

input 388:  {"source": "`` It started from modest beginnings and became a gigantic charity '' .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1245, 4, 5, 170, 23275, 6630, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1408, 4, 5, 1121, 11263, 19304, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04806232452392578, -0.008698035962879658, -0.026336193084716797, -0.025345325469970703, -0.025345325469970703, -0.025345325469970703, -0.025345325469970703, -0.025345325469970703, -0.025345325469970703, -0.025345325469970703], "metadata": {"source_tokens": ["`", "##`", "It", "started", "from", "modest", "beginnings", "and", "became", "a", "gigantic", "charity", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "a", "gigantic", "charity", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "started", "[unused4]", "[unused5]", "from", "modest", "beginnings", "[unused6]", "[SEP]"]]}

input 389:  {"source": "`` Le Griffon '' is reported to be the `` Holy Grail '' of Great Lakes shipwreck hunters .\n"}
prediction:  {"predictions": [[1, 3180, 144, 17387, 1320, 2, 3, 1110, 2103, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3180, 144, 17387, 1320, 2, 3, 1106, 1129, 4, 5, 1103, 169, 28152, 3930, 144, 12797, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.026377879083156586, -0.03753166273236275, -0.17305421829223633, -0.16488027572631836, -0.16488027572631836, -0.16488027572631836, -0.16488027572631836, -0.16488027572631836, -0.16488027572631836, -0.16488027572631836], "metadata": {"source_tokens": ["`", "##`", "Le", "G", "##riff", "##on", "'", "##'", "is", "reported", "to", "be", "the", "`", "##`", "Holy", "G", "##rail", "'", "##'", "of", "Great", "Lakes", "ship", "##w", "##reck", "hunters", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Le", "G", "##riff", "##on", "[unused2]", "[unused3]", "is", "reported", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Le", "G", "##riff", "##on", "[unused2]", "[unused3]", "to", "be", "[unused4]", "[unused5]", "the", "`", "##`", "Holy", "G", "##rail", "[unused6]", "[SEP]"]]}

input 390:  {"source": "`` See also : Grand Duke of Luxembourg , List of Prime Ministers of Luxembourg ''\n"}
prediction:  {"predictions": [[1, 2224, 3131, 1104, 10665, 2, 3, 1110, 4, 5, 5619, 1104, 3460, 15102, 1104, 10665, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.037557926028966904, -0.0721592903137207, -0.06918621063232422, -0.06918573379516602, -0.06918573379516602, -0.06918621063232422, -0.06918573379516602, -0.06918573379516602, -0.06918573379516602, -0.06918573379516602], "metadata": {"source_tokens": ["`", "##`", "See", "also", ":", "Grand", "Duke", "of", "Luxembourg", ",", "List", "of", "Prime", "Ministers", "of", "Luxembourg", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Grand", "Duke", "of", "Luxembourg", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "List", "of", "Prime", "Ministers", "of", "Luxembourg", "[unused6]", "[SEP]"]]}

input 391:  {"source": "`` The Cure '' topped the online music sales charts .\n"}
prediction:  {"predictions": [[1, 1109, 27121, 2, 3, 9065, 4, 5, 1103, 3294, 1390, 3813, 5896, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-4.069010537932627e-05, -0.22487545013427734, -0.2828211784362793, -0.2828207015991211, -0.2828207015991211, -0.2828207015991211, -0.2828207015991211, -0.2828207015991211, -0.2828207015991211, -0.2828207015991211], "metadata": {"source_tokens": ["`", "##`", "The", "Cure", "'", "##'", "topped", "the", "online", "music", "sales", "charts", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Cure", "[unused2]", "[unused3]", "topped", "[unused4]", "[unused5]", "the", "online", "music", "sales", "charts", "[unused6]", "[SEP]"]]}

input 392:  {"source": "he was one of only a few concert organists worldwide who supported themselves exclusively by giving recitals , concerts and master classes , without any supplement from teaching or church position .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1108, 4, 5, 1141, 1104, 1178, 170, 1374, 3838, 19209, 1116, 4529, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1178, 170, 1374, 3838, 19209, 1116, 2, 3, 2726, 4, 5, 2310, 7097, 1118, 2368, 1231, 6617, 22159, 117, 6460, 1105, 3283, 3553, 117, 1443, 1251, 15491, 1121, 3679, 1137, 1749, 1700, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014799541793763638, -0.042627330869436264, -0.12644672393798828, -0.12530946731567383, -0.12530946731567383, -0.12530946731567383, -0.12530946731567383, -0.12530946731567383, -0.12530946731567383, -0.12530946731567383], "metadata": {"source_tokens": ["he", "was", "one", "of", "only", "a", "few", "concert", "organist", "##s", "worldwide", "who", "supported", "themselves", "exclusively", "by", "giving", "re", "##ci", "##tals", ",", "concerts", "and", "master", "classes", ",", "without", "any", "supplement", "from", "teaching", "or", "church", "position", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "one", "of", "only", "a", "few", "concert", "organist", "##s", "worldwide", "[unused6]", "[SEP]", "[unused1]", "only", "a", "few", "concert", "organist", "##s", "[unused2]", "[unused3]", "supported", "[unused4]", "[unused5]", "themselves", "exclusively", "by", "giving", "re", "##ci", "##tals", ",", "concerts", "and", "master", "classes", ",", "without", "any", "supplement", "from", "teaching", "or", "church", "position", "[unused6]", "[SEP]"]]}

input 393:  {"source": "$ 300 million of bonds due Nov. 16 , 1993 , with equity - purchase warrants , indicating a 3 3\\/4 % coupon at par via Nomura International Ltd .\n"}
prediction:  {"predictions": [[1, 109, 3127, 1550, 1104, 10150, 1496, 14152, 28138, 1479, 1114, 12288, 118, 4779, 13178, 1116, 2, 3, 7713, 4, 5, 170, 124, 124, 28148, 28139, 1527, 110, 8707, 1320, 1120, 14247, 2258, 1302, 14535, 1570, 4492, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03443053737282753, -0.07663536071777344, -0.07338571548461914, -0.07338571548461914, -0.07338571548461914, -0.07338571548461914, -0.07338571548461914, -0.07338571548461914, -0.07338571548461914, -0.07338571548461914], "metadata": {"source_tokens": ["$", "300", "million", "of", "bonds", "due", "Nov", "##.", "16", ",", "1993", ",", "with", "equity", "-", "purchase", "warrant", "##s", ",", "indicating", "a", "3", "3", "##\\", "##/", "##4", "%", "coup", "##on", "at", "par", "via", "No", "##mura", "International", "Ltd", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "$", "300", "million", "of", "bonds", "due", "Nov", "##.", "16", "with", "equity", "-", "purchase", "warrant", "##s", "[unused2]", "[unused3]", "indicating", "[unused4]", "[unused5]", "a", "3", "3", "##\\", "##/", "##4", "%", "coup", "##on", "at", "par", "via", "No", "##mura", "International", "Ltd", "[unused6]", "[SEP]"]]}

input 394:  {"source": "( Separately , the Senate last week passed a bill permitting execution of terrorists who kill Americans abroad . )\n"}
prediction:  {"predictions": [[1, 17219, 2, 3, 2311, 4, 5, 4038, 6629, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3279, 2, 3, 2085, 4, 5, 170, 4550, 28049, 7581, 1104, 17219, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004849867429584265, -0.11691416054964066, -0.07406425476074219, -0.07772159576416016, -0.07772159576416016, -0.07772159576416016, -0.07772159576416016, -0.07772159576416016, -0.07772159576416016, -0.07772159576416016], "metadata": {"source_tokens": ["(", "Sep", "##arate", "##ly", ",", "the", "Senate", "last", "week", "passed", "a", "bill", "permitting", "execution", "of", "terrorists", "who", "kill", "Americans", "abroad", ".", ")"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "terrorists", "[unused2]", "[unused3]", "kill", "[unused4]", "[unused5]", "Americans", "abroad", "[unused6]", "[SEP]", "[unused1]", "the", "Senate", "[unused2]", "[unused3]", "passed", "[unused4]", "[unused5]", "a", "bill", "permitting", "execution", "of", "terrorists", "[unused6]", "[SEP]"]]}

input 395:  {"source": "A San Francisco lawyer , Mr. Panelli rowed religiously when he first got the machine , but , he complains , it left grease marks on his carpet , `` and it was boring .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 19073, 1116, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1286, 4, 5, 176, 15691, 6216, 1113, 1117, 10797, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 20339, 2646, 2, 3, 5105, 1174, 2689, 1193, 4, 5, 1165, 1119, 1148, 1400, 1103, 3395, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 12533, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1400, 4, 5, 1103, 3395, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.13613109290599823, -0.10302332043647766, -0.058099061250686646, -0.05710432678461075, -0.0661444365978241, -0.06259441375732422, -0.06325054168701172, -0.06325054168701172, -0.06325054168701172, -0.06325054168701172], "metadata": {"source_tokens": ["A", "San", "Francisco", "lawyer", ",", "Mr", "##.", "Panel", "##li", "row", "##ed", "religious", "##ly", "when", "he", "first", "got", "the", "machine", ",", "but", ",", "he", "complain", "##s", ",", "it", "left", "g", "##rease", "marks", "on", "his", "carpet", ",", "`", "##`", "and", "it", "was", "boring", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "complain", "##s", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "g", "##rease", "marks", "on", "his", "carpet", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "Panel", "##li", "[unused2]", "[unused3]", "row", "##ed", "religious", "##ly", "[unused4]", "[unused5]", "when", "he", "first", "got", "the", "machine", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "boring", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "got", "[unused4]", "[unused5]", "the", "machine", "[unused6]", "[SEP]"]]}

input 396:  {"source": "A half - dozen Soviet space officials , in Tokyo in July for an exhibit , stopped by to see their counterparts at the National Space Development Agency of Japan .\n"}
prediction:  {"predictions": [[1, 138, 1544, 118, 5955, 2461, 2000, 3878, 117, 1107, 4839, 1107, 1351, 1111, 1126, 8245, 2, 3, 2141, 4, 5, 1118, 1106, 1267, 1147, 15289, 1120, 1103, 1305, 4525, 3273, 5571, 1104, 1999, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.042656734585762024, -0.03481864929199219, -0.035761356353759766, -0.035761356353759766, -0.035761356353759766, -0.035761356353759766, -0.035761356353759766, -0.035761356353759766, -0.035761356353759766, -0.035761356353759766], "metadata": {"source_tokens": ["A", "half", "-", "dozen", "Soviet", "space", "officials", ",", "in", "Tokyo", "in", "July", "for", "an", "exhibit", ",", "stopped", "by", "to", "see", "their", "counterparts", "at", "the", "National", "Space", "Development", "Agency", "of", "Japan", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "half", "-", "dozen", "Soviet", "space", "officials", ",", "in", "Tokyo", "in", "July", "for", "an", "exhibit", "[unused2]", "[unused3]", "stopped", "[unused4]", "[unused5]", "by", "to", "see", "their", "counterparts", "at", "the", "National", "Space", "Development", "Agency", "of", "Japan", "[unused6]", "[SEP]"]]}

input 397:  {"source": "A month ago , when Beatrice first filed to sell debt , the company had planned to offer $ 200 million of its senior subordinated reset notes at a yield of 12 3\\/4 % .\n"}
prediction:  {"predictions": [[1, 1103, 1419, 2, 3, 1125, 2919, 4, 5, 1106, 2906, 109, 2363, 1550, 1104, 1157, 2682, 16469, 1181, 1231, 9388, 3697, 1120, 170, 10972, 1104, 1367, 124, 28148, 28139, 1527, 110, 138, 2370, 2403, 1165, 16131, 1148, 5770, 1106, 4582, 6695, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16131, 2, 3, 5770, 4, 5, 1106, 4582, 6695, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05333096906542778, -0.09925607591867447, -0.0885782241821289, -0.0874333381652832, -0.0874333381652832, -0.0874333381652832, -0.0874333381652832, -0.0874333381652832, -0.0874333381652832, -0.0874333381652832], "metadata": {"source_tokens": ["A", "month", "ago", ",", "when", "Beatrice", "first", "filed", "to", "sell", "debt", ",", "the", "company", "had", "planned", "to", "offer", "$", "200", "million", "of", "its", "senior", "subordinate", "##d", "re", "##set", "notes", "at", "a", "yield", "of", "12", "3", "##\\", "##/", "##4", "%", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "company", "[unused2]", "[unused3]", "had", "planned", "[unused4]", "[unused5]", "to", "offer", "$", "200", "million", "of", "its", "senior", "subordinate", "##d", "re", "##set", "notes", "at", "a", "yield", "of", "12", "3", "##\\", "##/", "##4", "%", "A", "month", "ago", "when", "Beatrice", "first", "filed", "to", "sell", "debt", "[unused6]", "[SEP]", "[unused1]", "Beatrice", "[unused2]", "[unused3]", "filed", "[unused4]", "[unused5]", "to", "sell", "debt", "[unused6]", "[SEP]"]]}

input 398:  {"source": "A similar technique is almost impossible to apply to other crops , such as cotton , soybeans and rice .\n"}
prediction:  {"predictions": [[1, 138, 1861, 5531, 2, 3, 1110, 4, 5, 1593, 4763, 1106, 6058, 1106, 1168, 8592, 117, 1216, 1112, 7825, 117, 1177, 1183, 3962, 5443, 1105, 7738, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0040561906062066555, -0.2200016975402832, -0.25989866256713867, -0.2599000930786133, -0.2599005699157715, -0.2599000930786133, -0.2599000930786133, -0.2599005699157715, -0.2599000930786133, -0.2599000930786133], "metadata": {"source_tokens": ["A", "similar", "technique", "is", "almost", "impossible", "to", "apply", "to", "other", "crops", ",", "such", "as", "cotton", ",", "so", "##y", "##be", "##ans", "and", "rice", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "similar", "technique", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "almost", "impossible", "to", "apply", "to", "other", "crops", ",", "such", "as", "cotton", ",", "so", "##y", "##be", "##ans", "and", "rice", "[unused6]", "[SEP]"]]}

input 399:  {"source": "A specialist is an exchange member designated to maintain a fair and orderly market in a specified stock .\n"}
prediction:  {"predictions": [[1, 138, 9131, 2, 3, 1110, 4, 5, 1126, 3670, 1420, 3574, 1106, 4731, 170, 4652, 1105, 28058, 2319, 1107, 170, 9467, 4482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0014092683559283614, -0.0409398078918457, -0.04601335525512695, -0.04601335525512695, -0.04601335525512695, -0.04601335525512695, -0.04601335525512695, -0.04601335525512695, -0.04601335525512695, -0.04601335525512695], "metadata": {"source_tokens": ["A", "specialist", "is", "an", "exchange", "member", "designated", "to", "maintain", "a", "fair", "and", "orderly", "market", "in", "a", "specified", "stock", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "specialist", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "exchange", "member", "designated", "to", "maintain", "a", "fair", "and", "orderly", "market", "in", "a", "specified", "stock", "[unused6]", "[SEP]"]]}

input 400:  {"source": "A spokesman said HealthVest has paid two of the three banks it owed interest to in October and is in negotiations with the third bank .\n"}
prediction:  {"predictions": [[1, 138, 15465, 2, 3, 1163, 4, 5, 3225, 2559, 2556, 1144, 3004, 1160, 1104, 1103, 1210, 5482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3225, 2559, 2556, 2, 3, 1144, 3004, 4, 5, 1160, 1104, 1103, 1210, 5482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 12390, 4, 5, 2199, 1106, 1107, 1357, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01706075668334961, -0.0846799984574318, -0.11394358426332474, -0.32157421112060547, -0.317018985748291, -0.3170185089111328, -0.3170185089111328, -0.317018985748291, -0.3170194625854492, -0.317018985748291], "metadata": {"source_tokens": ["A", "spokesman", "said", "Health", "##V", "##est", "has", "paid", "two", "of", "the", "three", "banks", "it", "owed", "interest", "to", "in", "October", "and", "is", "in", "negotiations", "with", "the", "third", "bank", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "spokesman", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "Health", "##V", "##est", "has", "paid", "two", "of", "the", "three", "banks", "[unused6]", "[SEP]", "[unused1]", "Health", "##V", "##est", "[unused2]", "[unused3]", "has", "paid", "[unused4]", "[unused5]", "two", "of", "the", "three", "banks", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "owed", "[unused4]", "[unused5]", "interest", "to", "in", "October", "[unused6]", "[SEP]"]]}

input 401:  {"source": "A state judge postponed a decision on a move by holders of Telerate Inc. to block the tender offer of Dow Jones & Co. for the 33 % of Telerate it does n't already own .\n"}
prediction:  {"predictions": [[1, 138, 1352, 3942, 2, 3, 16296, 4, 5, 170, 2383, 1113, 170, 1815, 1118, 14322, 1104, 11341, 5970, 1566, 3561, 1106, 3510, 1103, 8886, 2906, 1104, 26535, 2690, 111, 3291, 28138, 1111, 1103, 3081, 110, 1104, 11341, 5970, 1566, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1674, 183, 28131, 1204, 1640, 1319, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03152342140674591, -0.052790164947509766, -0.20271539688110352, -0.20261430740356445, -0.20261430740356445, -0.20261430740356445, -0.20261430740356445, -0.20261430740356445, -0.20261430740356445, -0.20261430740356445], "metadata": {"source_tokens": ["A", "state", "judge", "postponed", "a", "decision", "on", "a", "move", "by", "holders", "of", "Tel", "##era", "##te", "Inc", "##.", "to", "block", "the", "tender", "offer", "of", "Dow", "Jones", "&", "Co", "##.", "for", "the", "33", "%", "of", "Tel", "##era", "##te", "it", "does", "n", "##'", "##t", "already", "own", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "state", "judge", "[unused2]", "[unused3]", "postponed", "[unused4]", "[unused5]", "a", "decision", "on", "a", "move", "by", "holders", "of", "Tel", "##era", "##te", "Inc", "to", "block", "the", "tender", "offer", "of", "Dow", "Jones", "&", "Co", "##.", "for", "the", "33", "%", "of", "Tel", "##era", "##te", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "does", "n", "##'", "##t", "already", "own", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 402:  {"source": "A surprising 78 % of people said they exercise regularly , up from 73 % in 1981 .\n"}
prediction:  {"predictions": [[1, 138, 11567, 5603, 110, 1104, 1234, 2, 3, 1163, 4, 5, 1152, 6730, 4857, 117, 1146, 1121, 5766, 110, 1107, 2358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008348782546818256, -0.04735612869262695, -0.048226356506347656, -0.048226356506347656, -0.048226356506347656, -0.048226356506347656, -0.048226356506347656, -0.048226356506347656, -0.048226356506347656, -0.04822587966918945], "metadata": {"source_tokens": ["A", "surprising", "78", "%", "of", "people", "said", "they", "exercise", "regularly", ",", "up", "from", "73", "%", "in", "1981", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "surprising", "78", "%", "of", "people", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "they", "exercise", "regularly", ",", "up", "from", "73", "%", "in", "1981", "[unused6]", "[SEP]"]]}

input 403:  {"source": "A year earlier UniFirst earned $ 2.4 million , or 24 cents a share adjusted for the split .\n"}
prediction:  {"predictions": [[1, 12118, 1182, 2271, 11836, 1204, 2, 3, 2829, 4, 5, 109, 123, 28138, 1527, 1550, 138, 1214, 2206, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 2934, 2, 3, 10491, 4, 5, 1111, 1103, 3325, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0035918098874390125, -0.02725052833557129, -0.2684049606323242, -0.27657175064086914, -0.27657175064086914, -0.27657175064086914, -0.27657175064086914, -0.27657175064086914, -0.27657175064086914, -0.27657175064086914], "metadata": {"source_tokens": ["A", "year", "earlier", "Un", "##i", "##F", "##irs", "##t", "earned", "$", "2", "##.", "##4", "million", ",", "or", "24", "cents", "a", "share", "adjusted", "for", "the", "split", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Un", "##i", "##F", "##irs", "##t", "[unused2]", "[unused3]", "earned", "[unused4]", "[unused5]", "$", "2", "##.", "##4", "million", "A", "year", "earlier", "[unused6]", "[SEP]", "[unused1]", "a", "share", "[unused2]", "[unused3]", "adjusted", "[unused4]", "[unused5]", "for", "the", "split", "[unused6]", "[SEP]"]]}

input 404:  {"source": "About $ 70 billion is estimated to be tied up in the short - term money market , which acts both as a hedge against inflation for consumers and an accelerator of inflation and deficits for the government .\n"}
prediction:  {"predictions": [[1, 1103, 1603, 118, 1858, 1948, 2319, 2, 3, 4096, 4, 5, 1241, 1112, 170, 21610, 1222, 15503, 1111, 11060, 1105, 1126, 170, 26154, 1104, 15503, 1105, 16312, 1116, 1111, 1103, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3517, 109, 3102, 3775, 2, 3, 1110, 3555, 4, 5, 1106, 1129, 4353, 1146, 1107, 1103, 1603, 118, 1858, 1948, 2319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.018723249435424805, -0.010840152390301228, -0.05089998245239258, -0.05164384841918945, -0.05164384841918945, -0.05164384841918945, -0.05164384841918945, -0.05164384841918945, -0.05164384841918945, -0.05164384841918945], "metadata": {"source_tokens": ["About", "$", "70", "billion", "is", "estimated", "to", "be", "tied", "up", "in", "the", "short", "-", "term", "money", "market", ",", "which", "acts", "both", "as", "a", "hedge", "against", "inflation", "for", "consumers", "and", "an", "a", "##ccelerator", "of", "inflation", "and", "deficit", "##s", "for", "the", "government", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "short", "-", "term", "money", "market", "[unused2]", "[unused3]", "acts", "[unused4]", "[unused5]", "both", "as", "a", "hedge", "against", "inflation", "for", "consumers", "and", "an", "a", "##ccelerator", "of", "inflation", "and", "deficit", "##s", "for", "the", "government", "[unused6]", "[SEP]", "[unused1]", "About", "$", "70", "billion", "[unused2]", "[unused3]", "is", "estimated", "[unused4]", "[unused5]", "to", "be", "tied", "up", "in", "the", "short", "-", "term", "money", "market", "[unused6]", "[SEP]"]]}

input 405:  {"source": "According to one person familiar with the airline , the buy - out group -- led by United 's pilots union and UAL Chairman Stephen Wolf -- has begun billing UAL for fees and expenses it owes to investment bankers , law firms and banks .\n"}
prediction:  {"predictions": [[1, 1103, 4417, 118, 1149, 1372, 2, 3, 1521, 4, 5, 1118, 1244, 112, 1116, 8486, 3779, 1105, 158, 12507, 4284, 3620, 6499, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 27701, 4, 5, 1106, 5151, 15304, 1116, 117, 1644, 9780, 1105, 5482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4417, 118, 1149, 1372, 2, 3, 1144, 4972, 4, 5, 4550, 1158, 158, 12507, 1111, 9942, 1105, 11928, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014882225543260574, -0.04829898104071617, -0.07067035883665085, -0.05425691604614258, -0.05641365051269531, -0.05641365051269531, -0.05641365051269531, -0.05641365051269531, -0.05641365051269531, -0.05641365051269531], "metadata": {"source_tokens": ["According", "to", "one", "person", "familiar", "with", "the", "airline", ",", "the", "buy", "-", "out", "group", "-", "##-", "led", "by", "United", "'", "##s", "pilots", "union", "and", "U", "##AL", "Chairman", "Stephen", "Wolf", "-", "##-", "has", "begun", "bill", "##ing", "U", "##AL", "for", "fees", "and", "expenses", "it", "owes", "to", "investment", "banker", "##s", ",", "law", "firms", "and", "banks", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "buy", "-", "out", "group", "[unused2]", "[unused3]", "led", "[unused4]", "[unused5]", "by", "United", "'", "##s", "pilots", "union", "and", "U", "##AL", "Chairman", "Stephen", "Wolf", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "owes", "[unused4]", "[unused5]", "to", "investment", "banker", "##s", ",", "law", "firms", "and", "banks", "[unused6]", "[SEP]", "[unused1]", "the", "buy", "-", "out", "group", "[unused2]", "[unused3]", "has", "begun", "[unused4]", "[unused5]", "bill", "##ing", "U", "##AL", "for", "fees", "and", "expenses", "[unused6]", "[SEP]"]]}

input 406:  {"source": "After practicing law locally , he was elected to his first 10 - year term as judge in 1971 ; in 1981 , he was effectively re - elected .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1108, 1809, 4, 5, 1106, 1117, 1148, 1275, 118, 1214, 1858, 1112, 3942, 1107, 2507, 1258, 13029, 1644, 6889, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 4, 5, 5877, 1108, 5877, 1231, 118, 1809, 1107, 2358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0007534401374869049, -0.12403648346662521, -0.15475034713745117, -0.15009737014770508, -0.15009689331054688, -0.15009737014770508, -0.15009737014770508, -0.15009737014770508, -0.15009737014770508, -0.15009737014770508], "metadata": {"source_tokens": ["After", "practicing", "law", "locally", ",", "he", "was", "elected", "to", "his", "first", "10", "-", "year", "term", "as", "judge", "in", "1971", ";", "in", "1981", ",", "he", "was", "effectively", "re", "-", "elected", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "was", "elected", "[unused4]", "[unused5]", "to", "his", "first", "10", "-", "year", "term", "as", "judge", "in", "1971", "After", "practicing", "law", "locally", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "effectively", "was", "effectively", "re", "-", "elected", "in", "1981", "[unused6]", "[SEP]"]]}

input 407:  {"source": "After years of talking about selling in Japan , more and more U.S. companies are seriously pouring in .\n"}
prediction:  {"predictions": [[1, 1167, 1105, 1167, 158, 28138, 1708, 28138, 2557, 2, 3, 1132, 5536, 13587, 4, 5, 1107, 1258, 1201, 1104, 2520, 1164, 4147, 1107, 1999, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.024953581392765045, -0.1342625617980957, -0.12136983871459961, -0.12137031555175781, -0.12137031555175781, -0.12137031555175781, -0.12137031555175781, -0.12137031555175781, -0.12137031555175781, -0.12137031555175781], "metadata": {"source_tokens": ["After", "years", "of", "talking", "about", "selling", "in", "Japan", ",", "more", "and", "more", "U", "##.", "##S", "##.", "companies", "are", "seriously", "pouring", "in", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "more", "and", "more", "U", "##.", "##S", "##.", "companies", "[unused2]", "[unused3]", "are", "seriously", "pouring", "[unused4]", "[unused5]", "in", "After", "years", "of", "talking", "about", "selling", "in", "Japan", "[unused6]", "[SEP]"]]}

input 408:  {"source": "Also , the premiums paid by the U.S. government on a purchase of copper for the U.S. Mint were lower than expected , and acted as a price depressant , analysts said .\n"}
prediction:  {"predictions": [[1, 1103, 16865, 1116, 2, 3, 3004, 4, 5, 1118, 1103, 158, 28138, 1708, 28138, 1433, 1113, 170, 4779, 1104, 7335, 1111, 1103, 158, 28138, 1708, 28138, 21192, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 16865, 1116, 2, 3, 1129, 3004, 4, 5, 1118, 1103, 158, 28138, 1708, 28138, 1433, 1113, 170, 4779, 1104, 7335, 1111, 1103, 158, 28138, 1708, 28138, 21192, 1127, 2211, 1190, 2637, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 16865, 1116, 2, 3, 1129, 3004, 4, 5, 1118, 1103, 158, 28138, 1708, 28138, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 16865, 1116, 2, 3, 1129, 3004, 4, 5, 1118, 1103, 158, 28138, 1708, 28138, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 16865, 1116, 2, 3, 1129, 1127, 4, 5, 2211, 1190, 2637, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 16865, 1116, 2, 3, 1129, 3004, 4, 5, 1118, 1103, 158, 28138, 1708, 28138, 1433, 1113, 170, 4779, 1104, 7335, 1111, 1103, 158, 28138, 1708, 28138, 21192, 6, 102, 102, 102, 1, 1103, 16865, 1116, 2, 3, 1129, 3004, 4, 5, 1118, 1103, 158, 28138, 1708, 28138, 1433, 1105, 5376, 1112, 170, 3945, 1260, 11135, 2861, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.018768327310681343, -0.15370099246501923, -0.20270149409770966, -0.18867787718772888, -0.24001336097717285, -0.20922249555587769, -0.20681440830230713, -0.04767274856567383, -0.05211067199707031, -0.05211067199707031], "metadata": {"source_tokens": ["Also", ",", "the", "premium", "##s", "paid", "by", "the", "U", "##.", "##S", "##.", "government", "on", "a", "purchase", "of", "copper", "for", "the", "U", "##.", "##S", "##.", "Mint", "were", "lower", "than", "expected", ",", "and", "acted", "as", "a", "price", "de", "##press", "##ant", ",", "analysts", "said", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "premium", "##s", "[unused2]", "[unused3]", "paid", "[unused4]", "[unused5]", "by", "the", "U", "##.", "##S", "##.", "government", "on", "a", "purchase", "of", "copper", "for", "the", "U", "##.", "##S", "##.", "Mint", "[unused6]", "[SEP]", "[unused1]", "the", "premium", "##s", "[unused2]", "[unused3]", "be", "paid", "[unused4]", "[unused5]", "by", "the", "U", "##.", "##S", "##.", "government", "on", "a", "purchase", "of", "copper", "for", "the", "U", "##.", "##S", "##.", "Mint", "were", "lower", "than", "expected", "[unused6]", "[SEP]", "[unused1]", "the", "premium", "##s", "[unused2]", "[unused3]", "be", "paid", "[unused4]", "[unused5]", "by", "the", "U", "##.", "##S", "##.", "government", "[unused6]", "[SEP]", "[unused1]", "the", "premium", "##s", "[unused2]", "[unused3]", "be", "paid", "[unused4]", "[unused5]", "by", "the", "U", "##.", "##S", "##.", "government", "[unused6]", "[SEP]", "[unused1]", "the", "premium", "##s", "[unused2]", "[unused3]", "be", "were", "[unused4]", "[unused5]", "lower", "than", "expected", "[unused6]", "[SEP]", "[unused1]", "the", "premium", "##s", "[unused2]", "[unused3]", "be", "paid", "[unused4]", "[unused5]", "by", "the", "U", "##.", "##S", "##.", "government", "on", "a", "purchase", "of", "copper", "for", "the", "U", "##.", "##S", "##.", "Mint", "[unused6]", "[SEP]", "[unused1]", "the", "premium", "##s", "[unused2]", "[unused3]", "be", "paid", "[unused4]", "[unused5]", "by", "the", "U", "##.", "##S", "##.", "government", "and", "acted", "as", "a", "price", "de", "##press", "##ant", "[unused6]", "[SEP]"]]}

input 409:  {"source": "Although Heathrow authorities have been watching a group of allegedly crooked baggage handlers for some time , the Gauguin may be `` lost . ''\n"}
prediction:  {"predictions": [[1, 10640, 7596, 3912, 2, 3, 1138, 1151, 2903, 4, 5, 170, 1372, 1104, 9273, 19785, 23539, 4282, 1733, 1111, 1199, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 144, 3984, 25913, 2, 3, 1336, 1129, 1575, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.022928476333618164, -0.008033649995923042, -0.1456594467163086, -0.18641948699951172, -0.18641948699951172, -0.18641948699951172, -0.18641948699951172, -0.18641948699951172, -0.18641948699951172, -0.18641948699951172], "metadata": {"source_tokens": ["Although", "Heath", "##row", "authorities", "have", "been", "watching", "a", "group", "of", "allegedly", "crooked", "baggage", "handle", "##rs", "for", "some", "time", ",", "the", "G", "##au", "##guin", "may", "be", "`", "##`", "lost", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Heath", "##row", "authorities", "[unused2]", "[unused3]", "have", "been", "watching", "[unused4]", "[unused5]", "a", "group", "of", "allegedly", "crooked", "baggage", "handle", "##rs", "for", "some", "time", "[unused6]", "[SEP]", "[unused1]", "the", "G", "##au", "##guin", "[unused2]", "[unused3]", "may", "be", "lost", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 410:  {"source": "Although Mr. Azoff wo n't produce films at first , it is possible that he could do so later , the sources said .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 138, 6112, 3101, 2, 3, 192, 1186, 183, 28131, 1204, 3133, 4, 5, 2441, 1120, 1148, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 4, 5, 1936, 1115, 1119, 1180, 1202, 1177, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3509, 2, 3, 1163, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012485231272876263, -0.08498583734035492, -0.1330300122499466, -0.0812373161315918, -0.08068180084228516, -0.08068132400512695, -0.08068132400512695, -0.08068132400512695, -0.08068132400512695, -0.08068132400512695], "metadata": {"source_tokens": ["Although", "Mr", "##.", "A", "##zo", "##ff", "w", "##o", "n", "##'", "##t", "produce", "films", "at", "first", ",", "it", "is", "possible", "that", "he", "could", "do", "so", "later", ",", "the", "sources", "said", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "A", "##zo", "##ff", "[unused2]", "[unused3]", "w", "##o", "n", "##'", "##t", "produce", "[unused4]", "[unused5]", "films", "at", "first", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "possible", "that", "he", "could", "do", "so", "later", "[unused6]", "[SEP]", "[unused1]", "the", "sources", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 411:  {"source": "Although no specific agreements are expected , Mr. Shevardnadze said `` that does n't mean they will be without an agenda . ''\n"}
prediction:  {"predictions": [[1, 1185, 2747, 11069, 2, 3, 1132, 2637, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 1153, 24698, 1605, 1181, 3171, 2, 3, 1163, 4, 5, 1115, 1674, 183, 28131, 1204, 1928, 1152, 1209, 1129, 1443, 1126, 12932, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04476642608642578, -0.005379712209105492, -0.07513141632080078, -0.08263969421386719, -0.08263969421386719, -0.08263969421386719, -0.08263969421386719, -0.08263969421386719, -0.08263969421386719, -0.08263969421386719], "metadata": {"source_tokens": ["Although", "no", "specific", "agreements", "are", "expected", ",", "Mr", "##.", "She", "##vard", "##na", "##d", "##ze", "said", "`", "##`", "that", "does", "n", "##'", "##t", "mean", "they", "will", "be", "without", "an", "agenda", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "no", "specific", "agreements", "[unused2]", "[unused3]", "are", "expected", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "She", "##vard", "##na", "##d", "##ze", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "that", "does", "n", "##'", "##t", "mean", "they", "will", "be", "without", "an", "agenda", "[unused6]", "[SEP]"]]}

input 412:  {"source": "Although the Treasury will announce details of the November refunding tomorrow , it could be delayed if Congress and President Bush fail to increase the Treasury 's borrowing capacity .\n"}
prediction:  {"predictions": [[1, 1103, 11712, 2, 3, 1209, 15810, 4, 5, 4068, 1104, 1103, 1379, 1231, 14703, 17038, 4911, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2757, 1105, 1697, 6096, 2, 3, 1129, 8088, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2757, 1105, 1697, 6096, 2, 3, 8693, 4, 5, 1106, 2773, 1103, 11712, 112, 1116, 20055, 1158, 3211, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005137826316058636, -0.1284254640340805, -0.0640014111995697, -0.08316707611083984, -0.08747482299804688, -0.08747482299804688, -0.08747482299804688, -0.08747482299804688, -0.08747482299804688, -0.08747482299804688], "metadata": {"source_tokens": ["Although", "the", "Treasury", "will", "announce", "details", "of", "the", "November", "re", "##fu", "##nding", "tomorrow", ",", "it", "could", "be", "delayed", "if", "Congress", "and", "President", "Bush", "fail", "to", "increase", "the", "Treasury", "'", "##s", "borrow", "##ing", "capacity", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Treasury", "[unused2]", "[unused3]", "will", "announce", "[unused4]", "[unused5]", "details", "of", "the", "November", "re", "##fu", "##nding", "tomorrow", "[unused6]", "[SEP]", "[unused1]", "Congress", "and", "President", "Bush", "[unused2]", "[unused3]", "be", "delayed", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Congress", "and", "President", "Bush", "[unused2]", "[unused3]", "fail", "[unused4]", "[unused5]", "to", "increase", "the", "Treasury", "'", "##s", "borrow", "##ing", "capacity", "[unused6]", "[SEP]"]]}

input 413:  {"source": "Among other things , they said , Mr. Azoff would develop musical acts for a new record label .\n"}
prediction:  {"predictions": [[1, 1152, 2, 3, 1163, 4, 5, 1828, 28138, 138, 6112, 3101, 1156, 3689, 2696, 4096, 1111, 170, 1207, 1647, 3107, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.011165867559611797, -0.07530021667480469, -0.07053852081298828, -0.07053852081298828, -0.07053852081298828, -0.07053852081298828, -0.07053852081298828, -0.07053852081298828, -0.07053852081298828, -0.07053852081298828], "metadata": {"source_tokens": ["Among", "other", "things", ",", "they", "said", ",", "Mr", "##.", "A", "##zo", "##ff", "would", "develop", "musical", "acts", "for", "a", "new", "record", "label", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "they", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "Mr", "##.", "A", "##zo", "##ff", "would", "develop", "musical", "acts", "for", "a", "new", "record", "label", "[unused6]", "[SEP]"]]}

input 414:  {"source": "And , since the public has always been fascinated by gossip and voyeurism , reporters and editors will strain for creative angles to justify the inclusion of collateral facts about private lives including sexual activities and domestic relationships , activities of family members , and all matters about mental and physical health .\n"}
prediction:  {"predictions": [[1, 1103, 1470, 2, 3, 1144, 1151, 17136, 4, 5, 1118, 16378, 1105, 191, 7341, 8816, 1863, 1579, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 13509, 1105, 11884, 2, 3, 1209, 10512, 4, 5, 1111, 6228, 12879, 1106, 17422, 1103, 10838, 1104, 1884, 3848, 16719, 9193, 1164, 2029, 2491, 1259, 3785, 2619, 1105, 4500, 6085, 2619, 1104, 1266, 1484, 1105, 1155, 5218, 1164, 4910, 1105, 2952, 2332, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03886985778808594, -0.03734743222594261, -0.11579704284667969, -0.1197657585144043, -0.1197657585144043, -0.1197652816772461, -0.1197657585144043, -0.1197652816772461, -0.1197652816772461, -0.1197652816772461], "metadata": {"source_tokens": ["And", ",", "since", "the", "public", "has", "always", "been", "fascinated", "by", "gossip", "and", "v", "##oy", "##eur", "##ism", ",", "reporters", "and", "editors", "will", "strain", "for", "creative", "angles", "to", "justify", "the", "inclusion", "of", "co", "##lla", "##teral", "facts", "about", "private", "lives", "including", "sexual", "activities", "and", "domestic", "relationships", ",", "activities", "of", "family", "members", ",", "and", "all", "matters", "about", "mental", "and", "physical", "health", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "public", "[unused2]", "[unused3]", "has", "been", "fascinated", "[unused4]", "[unused5]", "by", "gossip", "and", "v", "##oy", "##eur", "##ism", "always", "[unused6]", "[SEP]", "[unused1]", "reporters", "and", "editors", "[unused2]", "[unused3]", "will", "strain", "[unused4]", "[unused5]", "for", "creative", "angles", "to", "justify", "the", "inclusion", "of", "co", "##lla", "##teral", "facts", "about", "private", "lives", "including", "sexual", "activities", "and", "domestic", "relationships", "activities", "of", "family", "members", "and", "all", "matters", "about", "mental", "and", "physical", "health", "[unused6]", "[SEP]"]]}

input 415:  {"source": "And Dewar 's gave discounts on Scottish merchandise to people who sent in bottle labels .\n"}
prediction:  {"predictions": [[1, 1234, 2, 3, 1850, 4, 5, 1107, 5346, 11080, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3177, 7200, 112, 1116, 2, 3, 1522, 4, 5, 23290, 1116, 1113, 3250, 18349, 1106, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005401611328125, -0.01864437200129032, -0.034108638763427734, -0.0593867301940918, -0.0593867301940918, -0.0593867301940918, -0.0593867301940918, -0.0593867301940918, -0.0593867301940918, -0.0593867301940918], "metadata": {"source_tokens": ["And", "De", "##war", "'", "##s", "gave", "discount", "##s", "on", "Scottish", "merchandise", "to", "people", "who", "sent", "in", "bottle", "labels", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "people", "[unused2]", "[unused3]", "sent", "[unused4]", "[unused5]", "in", "bottle", "labels", "[unused6]", "[SEP]", "[unused1]", "De", "##war", "'", "##s", "[unused2]", "[unused3]", "gave", "[unused4]", "[unused5]", "discount", "##s", "on", "Scottish", "merchandise", "to", "[unused6]", "[SEP]"]]}

input 416:  {"source": "And do n't expect many complete games by pitchers -- perhaps three out of 288 , laughs Mr. Fingers , the former Oakland reliever .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 19140, 9915, 2, 3, 1110, 4, 5, 1103, 1393, 8847, 16775, 1197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1262, 2, 3, 1202, 183, 28131, 1204, 5363, 4, 5, 1242, 2335, 1638, 1118, 26970, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.002428026869893074, -0.07644599676132202, -0.09121465682983398, -0.09102487564086914, -0.09102487564086914, -0.09102487564086914, -0.09102535247802734, -0.09102487564086914, -0.09102487564086914, -0.09102535247802734], "metadata": {"source_tokens": ["And", "do", "n", "##'", "##t", "expect", "many", "complete", "games", "by", "pitchers", "-", "##-", "perhaps", "three", "out", "of", "288", ",", "laughs", "Mr", "##.", "Fin", "##gers", ",", "the", "former", "Oakland", "relieve", "##r", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Fin", "##gers", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "former", "Oakland", "relieve", "##r", "[unused6]", "[SEP]", "[unused1]", "And", "[unused2]", "[unused3]", "do", "n", "##'", "##t", "expect", "[unused4]", "[unused5]", "many", "complete", "games", "by", "pitchers", "[unused6]", "[SEP]"]]}

input 417:  {"source": "And he got rid of low - margin businesses that just were n't making money for the company .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1400, 9297, 4, 5, 1104, 1822, 118, 7464, 5028, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1822, 118, 7464, 5028, 2, 3, 1129, 1198, 1127, 1127, 4, 5, 1127, 183, 28131, 1204, 1543, 1948, 1111, 1103, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.026068877428770065, -0.20035748183727264, -0.06081533432006836, -0.06322813034057617, -0.06322765350341797, -0.06322765350341797, -0.06322765350341797, -0.06322765350341797, -0.06322765350341797, -0.06322765350341797], "metadata": {"source_tokens": ["And", "he", "got", "rid", "of", "low", "-", "margin", "businesses", "that", "just", "were", "n", "##'", "##t", "making", "money", "for", "the", "company", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "got", "rid", "[unused4]", "[unused5]", "of", "low", "-", "margin", "businesses", "[unused6]", "[SEP]", "[unused1]", "low", "-", "margin", "businesses", "[unused2]", "[unused3]", "be", "just", "were", "were", "[unused4]", "[unused5]", "were", "n", "##'", "##t", "making", "money", "for", "the", "company", "[unused6]", "[SEP]"]]}

input 418:  {"source": "Annualized interest rates on certain investments as reported by the Federal Reserve Board on a weekly - average basis :\n"}
prediction:  {"predictions": [[1, 8451, 2200, 2199, 5600, 1113, 2218, 12372, 2, 3, 1112, 2103, 4, 5, 1118, 1103, 3467, 5081, 2464, 1113, 170, 5392, 118, 1903, 3142, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03838707506656647, -0.17153453826904297, -0.19713497161865234, -0.19713544845581055, -0.19713544845581055, -0.19713544845581055, -0.19713544845581055, -0.19713544845581055, -0.19713592529296875, -0.19713544845581055], "metadata": {"source_tokens": ["Annual", "##ized", "interest", "rates", "on", "certain", "investments", "as", "reported", "by", "the", "Federal", "Reserve", "Board", "on", "a", "weekly", "-", "average", "basis", ":"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Annual", "##ized", "interest", "rates", "on", "certain", "investments", "[unused2]", "[unused3]", "as", "reported", "[unused4]", "[unused5]", "by", "the", "Federal", "Reserve", "Board", "on", "a", "weekly", "-", "average", "basis", "[unused6]", "[SEP]"]]}

input 419:  {"source": "As a result , he said he will examine the Marcos documents sought by the prosecutors to determine whether turning over the filings is self - incrimination .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1163, 4, 5, 1119, 1209, 11755, 1103, 15541, 4961, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 15541, 4961, 2, 3, 4110, 4, 5, 1118, 1103, 24987, 1106, 4959, 2480, 3219, 1166, 1103, 16504, 1116, 1110, 2191, 118, 1107, 1665, 10205, 9400, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0332622267305851, -0.050353143364191055, -0.10446357727050781, -0.10641145706176758, -0.10641145706176758, -0.10641145706176758, -0.10641145706176758, -0.10641145706176758, -0.10641145706176758, -0.10641145706176758], "metadata": {"source_tokens": ["As", "a", "result", ",", "he", "said", "he", "will", "examine", "the", "Marcos", "documents", "sought", "by", "the", "prosecutors", "to", "determine", "whether", "turning", "over", "the", "filing", "##s", "is", "self", "-", "in", "##c", "##rim", "##ination", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "he", "will", "examine", "the", "Marcos", "documents", "[unused6]", "[SEP]", "[unused1]", "the", "Marcos", "documents", "[unused2]", "[unused3]", "sought", "[unused4]", "[unused5]", "by", "the", "prosecutors", "to", "determine", "whether", "turning", "over", "the", "filing", "##s", "is", "self", "-", "in", "##c", "##rim", "##ination", "[unused6]", "[SEP]"]]}

input 420:  {"source": "As of Sept. 30 , American Brands had 95.2 million shares outstanding .\n"}
prediction:  {"predictions": [[1, 1237, 12381, 1116, 2, 3, 1125, 4, 5, 4573, 28138, 1477, 1550, 6117, 6976, 1249, 1104, 20456, 28138, 1476, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013679244555532932, -0.04614067077636719, -0.0488739013671875, -0.0488739013671875, -0.0488739013671875, -0.0488739013671875, -0.0488739013671875, -0.0488739013671875, -0.0488739013671875, -0.0488739013671875], "metadata": {"source_tokens": ["As", "of", "Sept", "##.", "30", ",", "American", "Brand", "##s", "had", "95", "##.", "##2", "million", "shares", "outstanding", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "American", "Brand", "##s", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "95", "##.", "##2", "million", "shares", "outstanding", "As", "of", "Sept", "##.", "30", "[unused6]", "[SEP]"]]}

input 421:  {"source": "As the London trading session drew to a close , the market was still listening to the parliamentary debate on the economy , with new Chancellor of the Exchequer John Major expected to clarify his approach to the British economy and currency issues .\n"}
prediction:  {"predictions": [[1, 1103, 2319, 2, 3, 1108, 5578, 4, 5, 1106, 1103, 6774, 5655, 1113, 1103, 4190, 1249, 1103, 1498, 6157, 4912, 3583, 1106, 170, 1601, 1253, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1207, 8861, 1104, 1103, 16409, 4386, 19061, 1287, 2868, 2, 3, 2637, 4, 5, 1106, 172, 5815, 6120, 1117, 3136, 1106, 1103, 1418, 4190, 1105, 10202, 2492, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2319, 2, 3, 1108, 5578, 4, 5, 1106, 1103, 6774, 5655, 1113, 1103, 4190, 1114, 1207, 8861, 1104, 1103, 16409, 4386, 19061, 1287, 2868, 2637, 1106, 172, 5815, 6120, 1117, 3136, 1106, 1103, 1418, 4190, 1105, 10202, 2492, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2319, 2, 3, 1108, 5578, 4, 5, 1106, 1103, 6774, 5655, 1113, 1103, 4190, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0168758612126112, -0.06785766035318375, -0.05441272258758545, -0.14347727596759796, -0.2812037467956543, -0.2894887924194336, -0.2894887924194336, -0.2894887924194336, -0.2894887924194336, -0.2894892692565918], "metadata": {"source_tokens": ["As", "the", "London", "trading", "session", "drew", "to", "a", "close", ",", "the", "market", "was", "still", "listening", "to", "the", "parliamentary", "debate", "on", "the", "economy", ",", "with", "new", "Chancellor", "of", "the", "Ex", "##che", "##quer", "John", "Major", "expected", "to", "c", "##lar", "##ify", "his", "approach", "to", "the", "British", "economy", "and", "currency", "issues", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "market", "[unused2]", "[unused3]", "was", "listening", "[unused4]", "[unused5]", "to", "the", "parliamentary", "debate", "on", "the", "economy", "As", "the", "London", "trading", "session", "drew", "to", "a", "close", "still", "[unused6]", "[SEP]", "[unused1]", "new", "Chancellor", "of", "the", "Ex", "##che", "##quer", "John", "Major", "[unused2]", "[unused3]", "expected", "[unused4]", "[unused5]", "to", "c", "##lar", "##ify", "his", "approach", "to", "the", "British", "economy", "and", "currency", "issues", "[unused6]", "[SEP]", "[unused1]", "the", "market", "[unused2]", "[unused3]", "was", "listening", "[unused4]", "[unused5]", "to", "the", "parliamentary", "debate", "on", "the", "economy", "with", "new", "Chancellor", "of", "the", "Ex", "##che", "##quer", "John", "Major", "expected", "to", "c", "##lar", "##ify", "his", "approach", "to", "the", "British", "economy", "and", "currency", "issues", "[unused6]", "[SEP]", "[unused1]", "the", "market", "[unused2]", "[unused3]", "was", "listening", "[unused4]", "[unused5]", "to", "the", "parliamentary", "debate", "on", "the", "economy", "[unused6]", "[SEP]"]]}

input 422:  {"source": "At Giant Bicycle Inc. , Rancho Dominguez , Calif. , sales have tripled since the company entered the U.S. mountain - bike business in 1987 .\n"}
prediction:  {"predictions": [[1, 3813, 2, 3, 1138, 9225, 1181, 4, 5, 1290, 1103, 1419, 2242, 1103, 158, 28138, 1708, 28138, 3231, 118, 8295, 1671, 1107, 2164, 1335, 12510, 139, 1596, 21172, 3561, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1419, 2, 3, 1129, 2242, 4, 5, 1103, 158, 28138, 1708, 28138, 3231, 8295, 1671, 1107, 2164, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.039340659976005554, -0.10140200704336166, -0.05581521987915039, -0.0565953254699707, -0.0565953254699707, -0.0565953254699707, -0.0565953254699707, -0.0565953254699707, -0.0565953254699707, -0.0565953254699707], "metadata": {"source_tokens": ["At", "Giant", "B", "##ic", "##ycle", "Inc", "##.", ",", "Rancho", "Dom", "##ing", "##ue", "##z", ",", "Cal", "##if", "##.", ",", "sales", "have", "triple", "##d", "since", "the", "company", "entered", "the", "U", "##.", "##S", "##.", "mountain", "-", "bike", "business", "in", "1987", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "sales", "[unused2]", "[unused3]", "have", "triple", "##d", "[unused4]", "[unused5]", "since", "the", "company", "entered", "the", "U", "##.", "##S", "##.", "mountain", "-", "bike", "business", "in", "1987", "At", "Giant", "B", "##ic", "##ycle", "Inc", "##.", "[unused6]", "[SEP]", "[unused1]", "the", "company", "[unused2]", "[unused3]", "be", "entered", "[unused4]", "[unused5]", "the", "U", "##.", "##S", "##.", "mountain", "bike", "business", "in", "1987", "[unused6]", "[SEP]"]]}

input 423:  {"source": "At one point , almost all of the shares in the 20 - stock Major Market Index , which mimics the industrial average , were sharply higher .\n"}
prediction:  {"predictions": [[1, 1103, 1406, 118, 4482, 2868, 6923, 10146, 2, 3, 27180, 1116, 4, 5, 1103, 3924, 1903, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1593, 1155, 1104, 1103, 6117, 1107, 1103, 1406, 118, 4482, 2868, 6923, 10146, 2, 3, 1127, 4, 5, 8930, 2299, 1335, 1141, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0216078944504261, -0.023069540038704872, -0.27191781997680664, -0.2708301544189453, -0.2708301544189453, -0.2708301544189453, -0.2708301544189453, -0.2708301544189453, -0.2708301544189453, -0.2708301544189453], "metadata": {"source_tokens": ["At", "one", "point", ",", "almost", "all", "of", "the", "shares", "in", "the", "20", "-", "stock", "Major", "Market", "Index", ",", "which", "mimic", "##s", "the", "industrial", "average", ",", "were", "sharply", "higher", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "20", "-", "stock", "Major", "Market", "Index", "[unused2]", "[unused3]", "mimic", "##s", "[unused4]", "[unused5]", "the", "industrial", "average", "[unused6]", "[SEP]", "[unused1]", "almost", "all", "of", "the", "shares", "in", "the", "20", "-", "stock", "Major", "Market", "Index", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "sharply", "higher", "At", "one", "point", "[unused6]", "[SEP]"]]}

input 424:  {"source": "Avery Inc. said it completed the sale of Uniroyal Chemical Holding Co. to a group led by management of Uniroyal Chemical Co. , the unit 's main business .\n"}
prediction:  {"predictions": [[1, 170, 1372, 2, 3, 1521, 4, 5, 1118, 2635, 1104, 12118, 9992, 18543, 10957, 3291, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12118, 9992, 18543, 10957, 3291, 28138, 2, 3, 1110, 4, 5, 1103, 2587, 112, 1116, 1514, 1671, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 2063, 4, 5, 1103, 4688, 1104, 12118, 9992, 18543, 10957, 14382, 3291, 28138, 1106, 170, 1372, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02532931976020336, -0.07574544847011566, -0.046751558780670166, -0.2472858428955078, -0.23119783401489258, -0.23119831085205078, -0.23119831085205078, -0.23119783401489258, -0.23119783401489258, -0.23119783401489258], "metadata": {"source_tokens": ["Avery", "Inc", "##.", "said", "it", "completed", "the", "sale", "of", "Un", "##iro", "##yal", "Chemical", "Holding", "Co", "##.", "to", "a", "group", "led", "by", "management", "of", "Un", "##iro", "##yal", "Chemical", "Co", "##.", ",", "the", "unit", "'", "##s", "main", "business", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "group", "[unused2]", "[unused3]", "led", "[unused4]", "[unused5]", "by", "management", "of", "Un", "##iro", "##yal", "Chemical", "Co", "##.", "[unused6]", "[SEP]", "[unused1]", "Un", "##iro", "##yal", "Chemical", "Co", "##.", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "unit", "'", "##s", "main", "business", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "completed", "[unused4]", "[unused5]", "the", "sale", "of", "Un", "##iro", "##yal", "Chemical", "Holding", "Co", "##.", "to", "a", "group", "[unused6]", "[SEP]"]]}

input 425:  {"source": "Because patients require less attention from nurses and other staff , room charges are lower -- about $ 100 less per day than a regular room at the Vermont hospital .\n"}
prediction:  {"predictions": [[1, 4420, 2, 3, 4752, 4, 5, 1750, 2209, 1121, 13318, 1105, 1168, 2546, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1395, 4917, 2, 3, 1132, 4, 5, 2211, 1164, 109, 1620, 1750, 1679, 1285, 1190, 170, 2366, 1395, 1120, 1103, 8472, 2704, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.020410895347595215, -0.00901092030107975, -0.11290502548217773, -0.11078786849975586, -0.11078786849975586, -0.11078786849975586, -0.11078786849975586, -0.11078786849975586, -0.11078786849975586, -0.11078786849975586], "metadata": {"source_tokens": ["Because", "patients", "require", "less", "attention", "from", "nurses", "and", "other", "staff", ",", "room", "charges", "are", "lower", "-", "##-", "about", "$", "100", "less", "per", "day", "than", "a", "regular", "room", "at", "the", "Vermont", "hospital", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "patients", "[unused2]", "[unused3]", "require", "[unused4]", "[unused5]", "less", "attention", "from", "nurses", "and", "other", "staff", "[unused6]", "[SEP]", "[unused1]", "room", "charges", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "lower", "about", "$", "100", "less", "per", "day", "than", "a", "regular", "room", "at", "the", "Vermont", "hospital", "[unused6]", "[SEP]"]]}

input 426:  {"source": "Between flashes , certain areas in subjects ' brains are jolted with a magnetic stimulator .\n"}
prediction:  {"predictions": [[1, 2218, 1877, 1107, 5174, 112, 16570, 2, 3, 1132, 26078, 1174, 4, 5, 1114, 170, 8364, 188, 3121, 13601, 13389, 3847, 18324, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0009589671972207725, -0.08457422256469727, -0.08589839935302734, -0.08589839935302734, -0.08589839935302734, -0.08589839935302734, -0.08589839935302734, -0.08589839935302734, -0.08589839935302734, -0.08589839935302734], "metadata": {"source_tokens": ["Between", "flashes", ",", "certain", "areas", "in", "subjects", "'", "brains", "are", "jolt", "##ed", "with", "a", "magnetic", "s", "##ti", "##mu", "##lator", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "certain", "areas", "in", "subjects", "'", "brains", "[unused2]", "[unused3]", "are", "jolt", "##ed", "[unused4]", "[unused5]", "with", "a", "magnetic", "s", "##ti", "##mu", "##lator", "Between", "flashes", "[unused6]", "[SEP]"]]}

input 427:  {"source": "Both reflect the dismissal of lower - level and shorter - tenure executives .\n"}
prediction:  {"predictions": [[1, 2695, 2, 3, 7977, 4, 5, 1103, 16373, 1104, 2211, 118, 1634, 1105, 7681, 118, 6999, 14011, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-3.06129441014491e-05, -0.033371925354003906, -0.030329227447509766, -0.03032970428466797, -0.03032970428466797, -0.030329227447509766, -0.03032970428466797, -0.030329227447509766, -0.03032970428466797, -0.030329227447509766], "metadata": {"source_tokens": ["Both", "reflect", "the", "dismissal", "of", "lower", "-", "level", "and", "shorter", "-", "tenure", "executives", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Both", "[unused2]", "[unused3]", "reflect", "[unused4]", "[unused5]", "the", "dismissal", "of", "lower", "-", "level", "and", "shorter", "-", "tenure", "executives", "[unused6]", "[SEP]"]]}

input 428:  {"source": "British government bonds ended moderately higher , encouraged by a steadier pound and a rise in British stocks .\n"}
prediction:  {"predictions": [[1, 1418, 1433, 10150, 2, 3, 2207, 4, 5, 19455, 2299, 6182, 1118, 170, 188, 12679, 2852, 10074, 1105, 170, 3606, 1107, 1418, 17901, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01787959598004818, -0.017377376556396484, -0.018877506256103516, -0.018877506256103516, -0.018877506256103516, -0.018877506256103516, -0.018877506256103516, -0.018877506256103516, -0.018877506256103516, -0.018877506256103516], "metadata": {"source_tokens": ["British", "government", "bonds", "ended", "moderately", "higher", ",", "encouraged", "by", "a", "s", "##tead", "##ier", "pound", "and", "a", "rise", "in", "British", "stocks", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "British", "government", "bonds", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "moderately", "higher", "encouraged", "by", "a", "s", "##tead", "##ier", "pound", "and", "a", "rise", "in", "British", "stocks", "[unused6]", "[SEP]"]]}

input 429:  {"source": "But , with the state offering only $ 39,000 a year and California 's high standard of living , `` there are n't too many to choose from , '' says Brent Scott , a recruiting officer .\n"}
prediction:  {"predictions": [[1, 1103, 1352, 2, 3, 4733, 4, 5, 1178, 109, 3614, 28136, 7629, 1568, 170, 1214, 1105, 1756, 112, 1116, 1344, 2530, 1104, 1690, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 13150, 2796, 2, 3, 1110, 4, 5, 170, 16226, 2575, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1114, 1103, 1352, 4733, 1178, 109, 3614, 28136, 7629, 1568, 170, 1214, 1105, 1756, 112, 1116, 1344, 2530, 1104, 1690, 117, 169, 28152, 1175, 1132, 183, 28131, 1204, 1315, 1242, 1106, 4835, 1121, 2, 3, 1175, 1132, 183, 28131, 1204, 1315, 1242, 1106, 4835, 1121, 4, 5, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01822504587471485, -0.014649400487542152, -0.1477000117301941, -0.1271500587463379, -0.1272411346435547, -0.1272411346435547, -0.1272411346435547, -0.1272411346435547, -0.1272411346435547, -0.1272411346435547], "metadata": {"source_tokens": ["But", ",", "with", "the", "state", "offering", "only", "$", "39", "##,", "##00", "##0", "a", "year", "and", "California", "'", "##s", "high", "standard", "of", "living", ",", "`", "##`", "there", "are", "n", "##'", "##t", "too", "many", "to", "choose", "from", ",", "'", "##'", "says", "Brent", "Scott", ",", "a", "recruiting", "officer", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "state", "[unused2]", "[unused3]", "offering", "[unused4]", "[unused5]", "only", "$", "39", "##,", "##00", "##0", "a", "year", "and", "California", "'", "##s", "high", "standard", "of", "living", "[unused6]", "[SEP]", "[unused1]", "Brent", "Scott", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "recruiting", "officer", "[unused6]", "[SEP]", "[unused1]", "with", "the", "state", "offering", "only", "$", "39", "##,", "##00", "##0", "a", "year", "and", "California", "'", "##s", "high", "standard", "of", "living", ",", "`", "##`", "there", "are", "n", "##'", "##t", "too", "many", "to", "choose", "from", "[unused2]", "[unused3]", "there", "are", "n", "##'", "##t", "too", "many", "to", "choose", "from", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 430:  {"source": "But although the golden share has been waived , a hostile bidder for Jaguar would still have to alter the British concern 's articles of association which ban shareholdings of more than 15 % .\n"}
prediction:  {"predictions": [[1, 1103, 5404, 2934, 2, 3, 1144, 1151, 17548, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 10518, 6875, 2692, 1111, 21694, 2, 3, 1106, 13000, 4, 5, 1103, 1418, 4517, 112, 1116, 4237, 1104, 3852, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 10518, 6875, 2692, 1111, 21694, 2, 3, 1156, 1138, 4, 5, 1106, 13000, 1103, 1418, 4517, 112, 1116, 4237, 1104, 3852, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 10518, 6875, 2692, 1111, 21694, 2, 3, 1156, 1138, 4, 5, 1106, 13000, 1103, 1418, 4517, 112, 1116, 4237, 1104, 3852, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 10518, 6875, 2692, 1111, 21694, 2, 3, 1156, 1138, 4, 5, 1106, 13000, 1103, 1418, 4517, 112, 1116, 4237, 1104, 3852, 1134, 8214, 2934, 20139, 1116, 1104, 1167, 1190, 1405, 110, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04137137159705162, -0.020836172625422478, -0.08045949786901474, -0.12576311826705933, -0.09326446056365967, -0.05728483200073242, -0.060471534729003906, -0.060471534729003906, -0.060471534729003906, -0.060471534729003906], "metadata": {"source_tokens": ["But", "although", "the", "golden", "share", "has", "been", "waived", ",", "a", "hostile", "bid", "##der", "for", "Jaguar", "would", "still", "have", "to", "alter", "the", "British", "concern", "'", "##s", "articles", "of", "association", "which", "ban", "share", "##holding", "##s", "of", "more", "than", "15", "%", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "golden", "share", "[unused2]", "[unused3]", "has", "been", "waived", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "a", "hostile", "bid", "##der", "for", "Jaguar", "[unused2]", "[unused3]", "to", "alter", "[unused4]", "[unused5]", "the", "British", "concern", "'", "##s", "articles", "of", "association", "[unused6]", "[SEP]", "[unused1]", "a", "hostile", "bid", "##der", "for", "Jaguar", "[unused2]", "[unused3]", "would", "have", "[unused4]", "[unused5]", "to", "alter", "the", "British", "concern", "'", "##s", "articles", "of", "association", "[unused6]", "[SEP]", "[unused1]", "a", "hostile", "bid", "##der", "for", "Jaguar", "[unused2]", "[unused3]", "would", "have", "[unused4]", "[unused5]", "to", "alter", "the", "British", "concern", "'", "##s", "articles", "of", "association", "[unused6]", "[SEP]", "[unused1]", "a", "hostile", "bid", "##der", "for", "Jaguar", "[unused2]", "[unused3]", "would", "have", "[unused4]", "[unused5]", "to", "alter", "the", "British", "concern", "'", "##s", "articles", "of", "association", "which", "ban", "share", "##holding", "##s", "of", "more", "than", "15", "%", "[unused6]", "[SEP]"]]}

input 431:  {"source": "But amid the two dozen bureaucrats and secretaries sits only one real - life PC .\n"}
prediction:  {"predictions": [[1, 15872, 1103, 1160, 5955, 18561, 22292, 1105, 3318, 5927, 2, 3, 7250, 4, 5, 1178, 1141, 1842, 118, 1297, 7054, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1178, 2, 3, 1141, 4, 5, 1842, 1297, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1178, 2, 3, 1141, 4, 5, 1842, 1297, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1178, 2, 3, 1141, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04711466282606125, -0.44062691926956177, -0.5545496940612793, -0.5456002354621887, -0.2436056137084961, -0.25530004501342773, -0.25530004501342773, -0.25530004501342773, -0.25530004501342773, -0.25530004501342773], "metadata": {"source_tokens": ["But", "amid", "the", "two", "dozen", "bureau", "##crats", "and", "secret", "##aries", "sits", "only", "one", "real", "-", "life", "PC", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "amid", "the", "two", "dozen", "bureau", "##crats", "and", "secret", "##aries", "[unused2]", "[unused3]", "sits", "[unused4]", "[unused5]", "only", "one", "real", "-", "life", "PC", "[unused6]", "[SEP]", "[unused1]", "only", "[unused2]", "[unused3]", "one", "[unused4]", "[unused5]", "real", "life", "[unused6]", "[SEP]", "[unused1]", "only", "[unused2]", "[unused3]", "one", "[unused4]", "[unused5]", "real", "life", "[unused6]", "[SEP]", "[unused1]", "only", "[unused2]", "[unused3]", "one", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 432:  {"source": "But fully 90 % of those polled felt they did n't need to belong to a health club .\n"}
prediction:  {"predictions": [[1, 3106, 3078, 110, 1104, 1343, 9590, 1174, 2, 3, 1464, 4, 5, 1152, 1225, 183, 28131, 1204, 1444, 1106, 6772, 1106, 170, 2332, 1526, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.003460354171693325, -0.01768350601196289, -0.019665241241455078, -0.019665241241455078, -0.019665241241455078, -0.019665241241455078, -0.019665241241455078, -0.019665241241455078, -0.019665241241455078, -0.019665241241455078], "metadata": {"source_tokens": ["But", "fully", "90", "%", "of", "those", "poll", "##ed", "felt", "they", "did", "n", "##'", "##t", "need", "to", "belong", "to", "a", "health", "club", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "fully", "90", "%", "of", "those", "poll", "##ed", "[unused2]", "[unused3]", "felt", "[unused4]", "[unused5]", "they", "did", "n", "##'", "##t", "need", "to", "belong", "to", "a", "health", "club", "[unused6]", "[SEP]"]]}

input 433:  {"source": "But he emphasized that new accounts , new sales , inquiries and subsequent sales of stock funds are all up this month from September 's level .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 13463, 4, 5, 1115, 1207, 5756, 117, 1207, 3813, 117, 1107, 24929, 1105, 4194, 3813, 1104, 4482, 4381, 1132, 1155, 1146, 1142, 2370, 1121, 1347, 112, 1116, 1634, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00010057758481707424, -0.22720718383789062, -0.2700324058532715, -0.2700328826904297, -0.2700328826904297, -0.2700328826904297, -0.2700328826904297, -0.2700328826904297, -0.2700328826904297, -0.2700328826904297], "metadata": {"source_tokens": ["But", "he", "emphasized", "that", "new", "accounts", ",", "new", "sales", ",", "in", "##quiries", "and", "subsequent", "sales", "of", "stock", "funds", "are", "all", "up", "this", "month", "from", "September", "'", "##s", "level", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "emphasized", "[unused4]", "[unused5]", "that", "new", "accounts", ",", "new", "sales", ",", "in", "##quiries", "and", "subsequent", "sales", "of", "stock", "funds", "are", "all", "up", "this", "month", "from", "September", "'", "##s", "level", "[unused6]", "[SEP]"]]}

input 434:  {"source": "But it appears to be the sort of hold one makes while heading for the door .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 1106, 1129, 4, 5, 1103, 3271, 1104, 2080, 1141, 2228, 1229, 5312, 1111, 1103, 1442, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0314907468855381, -0.3146672248840332, -0.3173861503601074, -0.3173856735229492, -0.3173856735229492, -0.3173856735229492, -0.3173856735229492, -0.3173861503601074, -0.3173856735229492, -0.3173856735229492], "metadata": {"source_tokens": ["But", "it", "appears", "to", "be", "the", "sort", "of", "hold", "one", "makes", "while", "heading", "for", "the", "door", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "to", "be", "[unused4]", "[unused5]", "the", "sort", "of", "hold", "one", "makes", "while", "heading", "for", "the", "door", "[unused6]", "[SEP]"]]}

input 435:  {"source": "But it does that at the cost of deepening the taxpayer 's exposure if the FHA is forced to pay for more loans going sour .\n"}
prediction:  {"predictions": [[1, 1103, 143, 11612, 2, 3, 1110, 2257, 4, 5, 1106, 2653, 1111, 1167, 11453, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1674, 4, 5, 1115, 1120, 1103, 2616, 1104, 1996, 4777, 1103, 3641, 4163, 7904, 112, 1116, 7401, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1167, 11453, 2, 3, 1129, 1280, 4, 5, 17948, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04364010691642761, -0.03985049948096275, -0.09876193851232529, -0.06287765502929688, -0.05687379837036133, -0.05687379837036133, -0.05687379837036133, -0.05687379837036133, -0.05687379837036133, -0.05687379837036133], "metadata": {"source_tokens": ["But", "it", "does", "that", "at", "the", "cost", "of", "deep", "##ening", "the", "tax", "##pa", "##yer", "'", "##s", "exposure", "if", "the", "F", "##HA", "is", "forced", "to", "pay", "for", "more", "loans", "going", "sour", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "F", "##HA", "[unused2]", "[unused3]", "is", "forced", "[unused4]", "[unused5]", "to", "pay", "for", "more", "loans", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "does", "[unused4]", "[unused5]", "that", "at", "the", "cost", "of", "deep", "##ening", "the", "tax", "##pa", "##yer", "'", "##s", "exposure", "[unused6]", "[SEP]", "[unused1]", "more", "loans", "[unused2]", "[unused3]", "be", "going", "[unused4]", "[unused5]", "sour", "[unused6]", "[SEP]"]]}

input 436:  {"source": "But then Judge O'Kicki often behaved like a man who would be king -- and , some say , an arrogant and abusive one .\n"}
prediction:  {"predictions": [[1, 5274, 152, 28131, 2428, 5345, 1182, 2, 3, 18492, 1181, 4, 5, 1176, 170, 1299, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1299, 2, 3, 1156, 1129, 4, 5, 2226, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.055057380348443985, -0.06693156808614731, -0.06151008605957031, -0.06127023696899414, -0.06127023696899414, -0.06127023696899414, -0.06127023696899414, -0.06127023696899414, -0.06127023696899414, -0.06127023696899414], "metadata": {"source_tokens": ["But", "then", "Judge", "O", "##'", "##K", "##ick", "##i", "often", "behave", "##d", "like", "a", "man", "who", "would", "be", "king", "-", "##-", "and", ",", "some", "say", ",", "an", "arrogant", "and", "abusive", "one", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Judge", "O", "##'", "##K", "##ick", "##i", "[unused2]", "[unused3]", "behave", "##d", "[unused4]", "[unused5]", "like", "a", "man", "often", "[unused6]", "[SEP]", "[unused1]", "a", "man", "[unused2]", "[unused3]", "would", "be", "[unused4]", "[unused5]", "king", "[unused6]", "[SEP]"]]}

input 437:  {"source": "But we can think of many reasons to stay out for the foreseeable future and well beyond .\n"}
prediction:  {"predictions": [[1, 1195, 2, 3, 1169, 1341, 4, 5, 1104, 1242, 3672, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.024306224659085274, -0.11269187927246094, -0.1121530532836914, -0.1121530532836914, -0.1121530532836914, -0.11215353012084961, -0.11215353012084961, -0.1121530532836914, -0.1121530532836914, -0.1121530532836914], "metadata": {"source_tokens": ["But", "we", "can", "think", "of", "many", "reasons", "to", "stay", "out", "for", "the", "fore", "##see", "##able", "future", "and", "well", "beyond", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "we", "[unused2]", "[unused3]", "can", "think", "[unused4]", "[unused5]", "of", "many", "reasons", "[unused6]", "[SEP]"]]}

input 438:  {"source": "But when they arrived at the door , all were afraid to go in , fearing that they would be out of place .\n"}
prediction:  {"predictions": [[1, 1155, 2, 3, 1127, 4, 5, 3737, 1106, 1301, 1107, 1165, 1152, 2474, 1120, 1103, 1442, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1155, 2, 3, 1127, 4, 5, 3737, 1106, 1301, 1107, 19424, 1115, 1152, 1156, 1129, 1149, 1104, 1282, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.036477912217378616, -0.11630498617887497, -0.08185148239135742, -0.08058834075927734, -0.08058834075927734, -0.08058834075927734, -0.08058834075927734, -0.08058834075927734, -0.08058834075927734, -0.08058834075927734], "metadata": {"source_tokens": ["But", "when", "they", "arrived", "at", "the", "door", ",", "all", "were", "afraid", "to", "go", "in", ",", "fearing", "that", "they", "would", "be", "out", "of", "place", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "all", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "afraid", "to", "go", "in", "when", "they", "arrived", "at", "the", "door", "[unused6]", "[SEP]", "[unused1]", "all", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "afraid", "to", "go", "in", "fearing", "that", "they", "would", "be", "out", "of", "place", "[unused6]", "[SEP]"]]}

input 439:  {"source": "But wire transfers from a standing account -- including those bigger than $ 10,000 -- are n't reported .\n"}
prediction:  {"predictions": [[1, 7700, 16845, 1121, 170, 2288, 3300, 118, 28137, 1259, 1343, 6706, 1190, 109, 1275, 28136, 7629, 1568, 2, 3, 1132, 183, 28131, 1204, 2103, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0029565836302936077, -0.044766902923583984, -0.05151653289794922, -0.05151653289794922, -0.05151653289794922, -0.05151653289794922, -0.05151653289794922, -0.05151653289794922, -0.05151653289794922, -0.05151653289794922], "metadata": {"source_tokens": ["But", "wire", "transfers", "from", "a", "standing", "account", "-", "##-", "including", "those", "bigger", "than", "$", "10", "##,", "##00", "##0", "-", "##-", "are", "n", "##'", "##t", "reported", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "wire", "transfers", "from", "a", "standing", "account", "-", "##-", "including", "those", "bigger", "than", "$", "10", "##,", "##00", "##0", "[unused2]", "[unused3]", "are", "n", "##'", "##t", "reported", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 440:  {"source": "But yesterday , Mr. Carpenter said big institutional investors , which he would n't identify , `` told us they would n't do business with firms '' that continued to do index arbitrage for their own accounts .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 13190, 2, 3, 1163, 4, 5, 1992, 15040, 9660, 117, 1134, 1119, 1156, 183, 28131, 1204, 6183, 117, 169, 28152, 1500, 1366, 1152, 1156, 183, 28131, 1204, 1202, 1671, 1114, 9780, 112, 28131, 1115, 1598, 1106, 1202, 7448, 170, 26281, 2875, 20240, 1111, 1147, 1319, 5756, 8128, 102, 1, 1992, 15040, 9660, 2, 3, 1500, 4, 5, 1366, 1152, 1156, 183, 28131, 1204, 1202, 1671, 1114, 9780, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1992, 15040, 9660, 2, 3, 1500, 4, 5, 1366, 1152, 1156, 183, 28131, 1204, 1202, 1671, 1114, 9780, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1992, 15040, 9660, 2, 3, 1500, 4, 5, 1366, 1152, 1156, 183, 28131, 1204, 1202, 1671, 1114, 9780, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1992, 15040, 9660, 2, 3, 1110, 4, 5, 1992, 15040, 9660, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1992, 15040, 9660, 2, 3, 1110, 4, 5, 1992, 15040, 9660, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1992, 15040, 9660, 2, 3, 1110, 4, 5, 1992, 15040, 9660, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1992, 15040, 9660, 2, 3, 1110, 4, 5, 1992, 15040, 9660, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1992, 15040, 9660, 2, 3, 1110, 4, 5, 1992, 15040, 9660, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1992, 15040, 9660, 2, 3, 1110, 4, 5, 1992, 15040, 9660, 6, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03427349030971527, -0.11929360032081604, -0.15553228557109833, -0.17416252195835114, -0.27783530950546265, -0.2774623930454254, -0.2787017226219177, -0.2865552306175232, -0.2802008390426636, -0.27831998467445374], "metadata": {"source_tokens": ["But", "yesterday", ",", "Mr", "##.", "Carpenter", "said", "big", "institutional", "investors", ",", "which", "he", "would", "n", "##'", "##t", "identify", ",", "`", "##`", "told", "us", "they", "would", "n", "##'", "##t", "do", "business", "with", "firms", "'", "##'", "that", "continued", "to", "do", "index", "a", "##rb", "##it", "##rage", "for", "their", "own", "accounts", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Carpenter", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "big", "institutional", "investors", ",", "which", "he", "would", "n", "##'", "##t", "identify", ",", "`", "##`", "told", "us", "they", "would", "n", "##'", "##t", "do", "business", "with", "firms", "'", "##'", "that", "continued", "to", "do", "index", "a", "##rb", "##it", "##rage", "for", "their", "own", "accounts", "yesterday", "[SEP]", "[unused1]", "big", "institutional", "investors", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "us", "they", "would", "n", "##'", "##t", "do", "business", "with", "firms", "[unused6]", "[SEP]", "[unused1]", "big", "institutional", "investors", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "us", "they", "would", "n", "##'", "##t", "do", "business", "with", "firms", "[unused6]", "[SEP]", "[unused1]", "big", "institutional", "investors", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "us", "they", "would", "n", "##'", "##t", "do", "business", "with", "firms", "[unused6]", "[SEP]", "[unused1]", "big", "institutional", "investors", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "big", "institutional", "investors", "[unused6]", "[SEP]", "[unused1]", "big", "institutional", "investors", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "big", "institutional", "investors", "[unused6]", "[SEP]", "[unused1]", "big", "institutional", "investors", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "big", "institutional", "investors", "[unused6]", "[SEP]", "[unused1]", "big", "institutional", "investors", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "big", "institutional", "investors", "[unused6]", "[SEP]", "[unused1]", "big", "institutional", "investors", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "big", "institutional", "investors", "[unused6]", "[SEP]", "[unused1]", "big", "institutional", "investors", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "big", "institutional", "investors", "[unused6]", "[SEP]"]]}

input 441:  {"source": "But you ca n't dismiss Mr. Stoltzman 's music or his motives as merely commercial and lightweight .\n"}
prediction:  {"predictions": [[1, 1128, 2, 3, 11019, 183, 28131, 1204, 21728, 4, 5, 1828, 28138, 1457, 17772, 27277, 112, 1116, 1390, 1137, 1117, 18686, 1112, 5804, 2595, 1105, 14939, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0002651132526807487, -0.055937767028808594, -0.049302101135253906, -0.049302101135253906, -0.049302101135253906, -0.049302101135253906, -0.049302101135253906, -0.049302101135253906, -0.049302101135253906, -0.049302101135253906], "metadata": {"source_tokens": ["But", "you", "ca", "n", "##'", "##t", "dismiss", "Mr", "##.", "St", "##olt", "##zman", "'", "##s", "music", "or", "his", "motives", "as", "merely", "commercial", "and", "lightweight", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "you", "[unused2]", "[unused3]", "ca", "n", "##'", "##t", "dismiss", "[unused4]", "[unused5]", "Mr", "##.", "St", "##olt", "##zman", "'", "##s", "music", "or", "his", "motives", "as", "merely", "commercial", "and", "lightweight", "[unused6]", "[SEP]"]]}

input 442:  {"source": "By increasing the number of PCs it uses from 66 to 1,000 , Omron Tateishi Electronics Co. , of Kyoto , hopes not only to make certain tasks easier but also to transform the way the company is run .\n"}
prediction:  {"predictions": [[1, 152, 1306, 3484, 9727, 20800, 13983, 3291, 28138, 117, 1104, 16083, 2, 3, 7816, 4, 5, 1136, 1178, 1106, 1294, 2218, 8249, 5477, 1133, 1145, 1106, 11303, 1103, 1236, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 2745, 4, 5, 1121, 5046, 1106, 122, 28136, 7629, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1419, 2, 3, 1110, 1576, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04735272750258446, -0.05514399707317352, -0.0866655558347702, -0.024604320526123047, -0.02445220947265625, -0.02445220947265625, -0.02445220947265625, -0.02445220947265625, -0.02445220947265625, -0.02445220947265625], "metadata": {"source_tokens": ["By", "increasing", "the", "number", "of", "PC", "##s", "it", "uses", "from", "66", "to", "1", "##,", "##00", "##0", ",", "O", "##m", "##ron", "Tate", "##ishi", "Electronics", "Co", "##.", ",", "of", "Kyoto", ",", "hopes", "not", "only", "to", "make", "certain", "tasks", "easier", "but", "also", "to", "transform", "the", "way", "the", "company", "is", "run", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "O", "##m", "##ron", "Tate", "##ishi", "Electronics", "Co", "##.", ",", "of", "Kyoto", "[unused2]", "[unused3]", "hopes", "[unused4]", "[unused5]", "not", "only", "to", "make", "certain", "tasks", "easier", "but", "also", "to", "transform", "the", "way", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "uses", "[unused4]", "[unused5]", "from", "66", "to", "1", "##,", "##00", "##0", "[unused6]", "[SEP]", "[unused1]", "the", "company", "[unused2]", "[unused3]", "is", "run", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 443:  {"source": "Coca - Cola Co. , aiming to boost soft - drink volume in Singapore , said it is discussing a joint venture with Fraser & Neave Ltd. , its bottling franchisee in that country .\n"}
prediction:  {"predictions": [[1, 19906, 118, 17492, 3291, 28138, 2, 3, 1163, 4, 5, 1122, 1110, 10751, 170, 4091, 7006, 1114, 9156, 111, 151, 4490, 2707, 4492, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9156, 111, 151, 4490, 2707, 4492, 28138, 2, 3, 1110, 4, 5, 1157, 171, 15719, 1979, 5801, 1162, 1107, 1115, 1583, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 19906, 118, 17492, 3291, 28138, 2, 3, 1110, 14485, 1106, 4, 5, 14112, 2991, 118, 3668, 3884, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04051054269075394, -0.05383685603737831, -0.19058825075626373, -0.07330131530761719, -0.07098245620727539, -0.07098245620727539, -0.07098245620727539, -0.07098245620727539, -0.07098245620727539, -0.07098245620727539], "metadata": {"source_tokens": ["Coca", "-", "Cola", "Co", "##.", ",", "aiming", "to", "boost", "soft", "-", "drink", "volume", "in", "Singapore", ",", "said", "it", "is", "discussing", "a", "joint", "venture", "with", "Fraser", "&", "N", "##ea", "##ve", "Ltd", "##.", ",", "its", "b", "##ott", "##ling", "franchise", "##e", "in", "that", "country", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Coca", "-", "Cola", "Co", "##.", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "is", "discussing", "a", "joint", "venture", "with", "Fraser", "&", "N", "##ea", "##ve", "Ltd", "##.", "[unused6]", "[SEP]", "[unused1]", "Fraser", "&", "N", "##ea", "##ve", "Ltd", "##.", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "its", "b", "##ott", "##ling", "franchise", "##e", "in", "that", "country", "[unused6]", "[SEP]", "[unused1]", "Coca", "-", "Cola", "Co", "##.", "[unused2]", "[unused3]", "is", "aiming", "to", "[unused4]", "[unused5]", "boost", "soft", "-", "drink", "volume", "[unused6]", "[SEP]"]]}

input 444:  {"source": "Combined PC and work - station use in Japan will jump as much as 25 % annually over the next five years , according to some analysts , compared with about 10 % in the U.S. .\n"}
prediction:  {"predictions": [[1, 16544, 7054, 1105, 1250, 118, 1466, 1329, 1107, 1999, 2, 3, 1209, 5152, 4, 5, 1112, 1277, 1112, 1512, 110, 6089, 1166, 1103, 1397, 1421, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16544, 7054, 1105, 1250, 118, 1466, 1329, 1107, 1999, 2, 3, 1209, 5152, 4, 5, 1112, 1277, 1112, 1512, 110, 6089, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.019407140091061592, -0.08478730916976929, -0.2828388214111328, -0.2781815528869629, -0.2781820297241211, -0.2781815528869629, -0.2781820297241211, -0.2781820297241211, -0.2781815528869629, -0.2781815528869629], "metadata": {"source_tokens": ["Combined", "PC", "and", "work", "-", "station", "use", "in", "Japan", "will", "jump", "as", "much", "as", "25", "%", "annually", "over", "the", "next", "five", "years", ",", "according", "to", "some", "analysts", ",", "compared", "with", "about", "10", "%", "in", "the", "U", "##.", "##S", "##.", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Combined", "PC", "and", "work", "-", "station", "use", "in", "Japan", "[unused2]", "[unused3]", "will", "jump", "[unused4]", "[unused5]", "as", "much", "as", "25", "%", "annually", "over", "the", "next", "five", "years", "[unused6]", "[SEP]", "[unused1]", "Combined", "PC", "and", "work", "-", "station", "use", "in", "Japan", "[unused2]", "[unused3]", "will", "jump", "[unused4]", "[unused5]", "as", "much", "as", "25", "%", "annually", "[unused6]", "[SEP]"]]}

input 445:  {"source": "Company officials said the current robust domestic demand that has been fueling sustained economic expansion helped push up sales of products like ships , steel structures , power systems and machinery and resulted in sharply higher profit .\n"}
prediction:  {"predictions": [[1, 1881, 3878, 2, 3, 1163, 4, 5, 1103, 1954, 17351, 4500, 4555, 1115, 1144, 1151, 4251, 1158, 8505, 2670, 4298, 2375, 4684, 1146, 3813, 1104, 2982, 1176, 2968, 117, 3649, 4413, 117, 1540, 2344, 1105, 11360, 1105, 3657, 1107, 8930, 2299, 5022, 6, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1954, 17351, 4500, 4555, 2, 3, 1144, 1151, 4251, 1158, 4, 5, 8505, 2670, 4298, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006433823145925999, -0.05659183859825134, -0.0906972885131836, -0.08986854553222656, -0.08986854553222656, -0.08986854553222656, -0.08986854553222656, -0.08986854553222656, -0.08986854553222656, -0.08986854553222656], "metadata": {"source_tokens": ["Company", "officials", "said", "the", "current", "robust", "domestic", "demand", "that", "has", "been", "fuel", "##ing", "sustained", "economic", "expansion", "helped", "push", "up", "sales", "of", "products", "like", "ships", ",", "steel", "structures", ",", "power", "systems", "and", "machinery", "and", "resulted", "in", "sharply", "higher", "profit", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Company", "officials", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "current", "robust", "domestic", "demand", "that", "has", "been", "fuel", "##ing", "sustained", "economic", "expansion", "helped", "push", "up", "sales", "of", "products", "like", "ships", ",", "steel", "structures", ",", "power", "systems", "and", "machinery", "and", "resulted", "in", "sharply", "higher", "profit", "[unused6]", "[SEP]", "[unused1]", "the", "current", "robust", "domestic", "demand", "[unused2]", "[unused3]", "has", "been", "fuel", "##ing", "[unused4]", "[unused5]", "sustained", "economic", "expansion", "[unused6]", "[SEP]"]]}

input 446:  {"source": "Considered as a whole , Mr. Lane said , the filings required under the proposed rules `` will be at least as effective , if not more so , for investors following transactions . ''\n"}
prediction:  {"predictions": [[1, 1828, 28138, 5319, 2, 3, 1163, 4, 5, 1103, 16504, 1116, 2320, 1223, 1103, 3000, 2995, 169, 28152, 1209, 1129, 1120, 1655, 1112, 3903, 117, 1191, 1136, 1167, 1177, 117, 1111, 9660, 1378, 14409, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008098676800727844, -0.30573320388793945, -0.33743953704833984, -0.33744049072265625, -0.33744001388549805, -0.33744049072265625, -0.33744001388549805, -0.33744049072265625, -0.33744001388549805, -0.33744049072265625], "metadata": {"source_tokens": ["Consider", "##ed", "as", "a", "whole", ",", "Mr", "##.", "Lane", "said", ",", "the", "filing", "##s", "required", "under", "the", "proposed", "rules", "`", "##`", "will", "be", "at", "least", "as", "effective", ",", "if", "not", "more", "so", ",", "for", "investors", "following", "transactions", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Lane", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "filing", "##s", "required", "under", "the", "proposed", "rules", "`", "##`", "will", "be", "at", "least", "as", "effective", ",", "if", "not", "more", "so", ",", "for", "investors", "following", "transactions", "[unused6]", "[SEP]"]]}

input 447:  {"source": "Crouched at shortstop , Bert Campaneris , once Oakland 's master thief , effortlessly scoops up a groundball and flips it to second .\n"}
prediction:  {"predictions": [[1, 15035, 5503, 6354, 4889, 2, 3, 188, 2528, 9706, 1146, 4, 5, 170, 1747, 5892, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 15035, 5503, 6354, 4889, 2, 3, 12785, 1116, 4, 5, 1122, 1106, 1248, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0728607177734375, -0.10381384938955307, -0.06636619567871094, -0.06838798522949219, -0.06838798522949219, -0.06838798522949219, -0.06838798522949219, -0.06838798522949219, -0.06838798522949219, -0.06838798522949219], "metadata": {"source_tokens": ["C", "##rouch", "##ed", "at", "shorts", "##top", ",", "Bert", "Camp", "##ane", "##ris", ",", "once", "Oakland", "'", "##s", "master", "thief", ",", "effort", "##lessly", "s", "##co", "##ops", "up", "a", "ground", "##ball", "and", "flip", "##s", "it", "to", "second", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Bert", "Camp", "##ane", "##ris", "[unused2]", "[unused3]", "s", "##co", "##ops", "up", "[unused4]", "[unused5]", "a", "ground", "##ball", "[unused6]", "[SEP]", "[unused1]", "Bert", "Camp", "##ane", "##ris", "[unused2]", "[unused3]", "flip", "##s", "[unused4]", "[unused5]", "it", "to", "second", "[unused6]", "[SEP]"]]}

input 448:  {"source": "Daimler said it has had talks with Jaguar about possible joint ventures .\n"}
prediction:  {"predictions": [[1, 23084, 20465, 2, 3, 1163, 4, 5, 1122, 1144, 1125, 7430, 1114, 21694, 1164, 1936, 4091, 20135, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1144, 1125, 4, 5, 7430, 1114, 21694, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-7.896423630882055e-05, -0.08357492089271545, -0.017460346221923828, -0.018906593322753906, -0.018906593322753906, -0.018906593322753906, -0.018906593322753906, -0.018906593322753906, -0.018906593322753906, -0.018906593322753906], "metadata": {"source_tokens": ["Dai", "##mler", "said", "it", "has", "had", "talks", "with", "Jaguar", "about", "possible", "joint", "ventures", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Dai", "##mler", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "has", "had", "talks", "with", "Jaguar", "about", "possible", "joint", "ventures", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "has", "had", "[unused4]", "[unused5]", "talks", "with", "Jaguar", "[unused6]", "[SEP]"]]}

input 449:  {"source": "Despite the modest gains , traders said the market remains dull , with investors remaining cautiously on the sidelines .\n"}
prediction:  {"predictions": [[1, 14552, 2, 3, 1163, 4, 5, 1103, 2319, 2606, 10884, 117, 1114, 9660, 2735, 16828, 1113, 1103, 1334, 10443, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.016233492642641068, -0.10518836975097656, -0.10378837585449219, -0.10378837585449219, -0.10378837585449219, -0.10378837585449219, -0.10378837585449219, -0.10378837585449219, -0.10378837585449219, -0.10378837585449219], "metadata": {"source_tokens": ["Despite", "the", "modest", "gains", ",", "traders", "said", "the", "market", "remains", "dull", ",", "with", "investors", "remaining", "cautiously", "on", "the", "side", "##lines", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "traders", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "market", "remains", "dull", ",", "with", "investors", "remaining", "cautiously", "on", "the", "side", "##lines", "[unused6]", "[SEP]"]]}

input 450:  {"source": "During the past 25 years , the number of balloonists ( those who have passed a Federal Aviation Authority lighter - than - air test ) have swelled from a couple hundred to several thousand , with some estimates running as high as 10,000 .\n"}
prediction:  {"predictions": [[1, 1199, 10777, 2, 3, 1919, 4, 5, 1112, 1344, 1112, 1275, 28136, 7629, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1295, 1104, 15758, 3681, 2, 3, 1138, 24201, 4, 5, 1121, 170, 2337, 2937, 1106, 1317, 4032, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1343, 2, 3, 1138, 2085, 4, 5, 170, 3467, 7650, 5987, 9310, 118, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 1190, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.049340810626745224, -0.06326983869075775, -0.4535774886608124, -0.06862163543701172, -0.06515264511108398, -0.06515264511108398, -0.06515264511108398, -0.06515264511108398, -0.06515264511108398, -0.06515264511108398], "metadata": {"source_tokens": ["During", "the", "past", "25", "years", ",", "the", "number", "of", "balloon", "##ists", "(", "those", "who", "have", "passed", "a", "Federal", "Aviation", "Authority", "lighter", "-", "than", "-", "air", "test", ")", "have", "swelled", "from", "a", "couple", "hundred", "to", "several", "thousand", ",", "with", "some", "estimates", "running", "as", "high", "as", "10", "##,", "##00", "##0", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "some", "estimates", "[unused2]", "[unused3]", "running", "[unused4]", "[unused5]", "as", "high", "as", "10", "##,", "##00", "##0", "[unused6]", "[SEP]", "[unused1]", "the", "number", "of", "balloon", "##ists", "[unused2]", "[unused3]", "have", "swelled", "[unused4]", "[unused5]", "from", "a", "couple", "hundred", "to", "several", "thousand", "[unused6]", "[SEP]", "[unused1]", "those", "[unused2]", "[unused3]", "have", "passed", "[unused4]", "[unused5]", "a", "Federal", "Aviation", "Authority", "lighter", "-", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "than", "[SEP]"]]}

input 451:  {"source": "Each company 's share of liability would be based on their share of the national DES market .\n"}
prediction:  {"predictions": [[1, 2994, 1419, 112, 1116, 2934, 1104, 15509, 2, 3, 1156, 1129, 1359, 4, 5, 1113, 1147, 2934, 1104, 1103, 1569, 18581, 1708, 2319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-4.4730993977282196e-05, -0.053661346435546875, -0.08587026596069336, -0.08586978912353516, -0.08587026596069336, -0.08586978912353516, -0.08586978912353516, -0.08587026596069336, -0.08587026596069336, -0.08587026596069336], "metadata": {"source_tokens": ["Each", "company", "'", "##s", "share", "of", "liability", "would", "be", "based", "on", "their", "share", "of", "the", "national", "DE", "##S", "market", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Each", "company", "'", "##s", "share", "of", "liability", "[unused2]", "[unused3]", "would", "be", "based", "[unused4]", "[unused5]", "on", "their", "share", "of", "the", "national", "DE", "##S", "market", "[unused6]", "[SEP]"]]}

input 452:  {"source": "Earlier this year , Blackstone Group , a New York investment bank , had no trouble selling out a special $ 570 million mortgage - securities trust it created for Japanese investors .\n"}
prediction:  {"predictions": [[1, 21861, 4793, 1990, 2, 3, 1125, 4, 5, 1185, 3819, 4147, 1149, 170, 1957, 109, 28081, 1550, 16935, 118, 19313, 3496, 15993, 1142, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21861, 4793, 1990, 2, 3, 1110, 4, 5, 170, 1203, 1365, 5151, 3085, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1957, 109, 28081, 1550, 16935, 118, 19313, 3496, 2, 3, 1687, 4, 5, 1111, 1983, 9660, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0027845127042382956, -0.16952753067016602, -0.060491763055324554, -0.07742118835449219, -0.07564926147460938, -0.07564926147460938, -0.07564926147460938, -0.07564926147460938, -0.07564926147460938, -0.07564926147460938], "metadata": {"source_tokens": ["Earlier", "this", "year", ",", "Blacks", "##tone", "Group", ",", "a", "New", "York", "investment", "bank", ",", "had", "no", "trouble", "selling", "out", "a", "special", "$", "570", "million", "mortgage", "-", "securities", "trust", "it", "created", "for", "Japanese", "investors", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Blacks", "##tone", "Group", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "no", "trouble", "selling", "out", "a", "special", "$", "570", "million", "mortgage", "-", "securities", "trust", "Earlier", "this", "year", "[unused6]", "[SEP]", "[unused1]", "Blacks", "##tone", "Group", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "New", "York", "investment", "bank", "[unused6]", "[SEP]", "[unused1]", "a", "special", "$", "570", "million", "mortgage", "-", "securities", "trust", "[unused2]", "[unused3]", "created", "[unused4]", "[unused5]", "for", "Japanese", "investors", "[unused6]", "[SEP]"]]}

input 453:  {"source": "Early in the morning Mr. Sider , an estate lawyer , pores over last wills and testaments .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 6383, 1197, 2, 3, 185, 12238, 4, 5, 1166, 1314, 1209, 1116, 1105, 2774, 11462, 1116, 4503, 1107, 1103, 2106, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 6383, 1197, 2, 3, 1110, 4, 5, 1126, 3327, 4545, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0058522033505141735, -0.023352839052677155, -0.06009626388549805, -0.06059408187866211, -0.06059408187866211, -0.06059408187866211, -0.06059408187866211, -0.06059408187866211, -0.06059408187866211, -0.06059408187866211], "metadata": {"source_tokens": ["Early", "in", "the", "morning", "Mr", "##.", "Side", "##r", ",", "an", "estate", "lawyer", ",", "p", "##ores", "over", "last", "will", "##s", "and", "test", "##ament", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Side", "##r", "[unused2]", "[unused3]", "p", "##ores", "[unused4]", "[unused5]", "over", "last", "will", "##s", "and", "test", "##ament", "##s", "Early", "in", "the", "morning", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "Side", "##r", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "estate", "lawyer", "[unused6]", "[SEP]"]]}

input 454:  {"source": "Edison Brothers Stores Inc. said it agreed to buy 229 Foxmoor women 's apparel stores from Foxmoor Specialty Stores Corp. , a unit of Dylex Ltd. of Toronto .\n"}
prediction:  {"predictions": [[1, 18221, 5216, 26811, 3561, 2, 3, 1163, 4, 5, 1122, 2675, 1106, 4417, 25325, 3977, 19216, 1535, 112, 1116, 12647, 24971, 4822, 1121, 3977, 19216, 3139, 2340, 26811, 13619, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3977, 19216, 3139, 2340, 26811, 13619, 2, 3, 1110, 4, 5, 170, 2587, 1104, 141, 12415, 1775, 4492, 28138, 1104, 3506, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 2675, 4, 5, 1106, 4417, 25325, 3977, 19216, 1535, 112, 1116, 12647, 24971, 4822, 1121, 3977, 19216, 3139, 2340, 26811, 13619, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013193964958190918, -0.06834825128316879, -0.0758211612701416, -0.059673309326171875, -0.06167316436767578, -0.06167316436767578, -0.06167316436767578, -0.06167316436767578, -0.06167316436767578, -0.06167316436767578], "metadata": {"source_tokens": ["Edison", "Brothers", "Stores", "Inc", "##.", "said", "it", "agreed", "to", "buy", "229", "Fox", "##moor", "women", "'", "##s", "app", "##arel", "stores", "from", "Fox", "##moor", "Special", "##ty", "Stores", "Corp", "##.", ",", "a", "unit", "of", "D", "##yle", "##x", "Ltd", "##.", "of", "Toronto", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Edison", "Brothers", "Stores", "Inc", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "agreed", "to", "buy", "229", "Fox", "##moor", "women", "'", "##s", "app", "##arel", "stores", "from", "Fox", "##moor", "Special", "##ty", "Stores", "Corp", "[unused6]", "[SEP]", "[unused1]", "Fox", "##moor", "Special", "##ty", "Stores", "Corp", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "unit", "of", "D", "##yle", "##x", "Ltd", "##.", "of", "Toronto", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "buy", "229", "Fox", "##moor", "women", "'", "##s", "app", "##arel", "stores", "from", "Fox", "##moor", "Special", "##ty", "Stores", "Corp", "##.", "[unused6]", "[SEP]"]]}

input 455:  {"source": "Employers could also pay a subminimum `` training wage '' for 90 days to new workers who are up to 19 years old , and then for another 90 days if the company institutes a specific training program for the newcomers .\n"}
prediction:  {"predictions": [[1, 1103, 1419, 2, 3, 19077, 4, 5, 170, 2747, 2013, 1788, 1111, 1103, 25551, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1207, 3239, 2, 3, 1132, 4, 5, 1146, 1106, 1627, 1201, 1385, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 18653, 1643, 26179, 1468, 2, 3, 1180, 2653, 4, 5, 170, 4841, 25685, 16268, 169, 28152, 2013, 12634, 112, 28131, 1111, 3078, 1552, 1106, 1207, 3239, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04797286540269852, -0.06461489945650101, -0.06517397612333298, -0.029152870178222656, -0.029186725616455078, -0.029186725616455078, -0.029186725616455078, -0.029186725616455078, -0.029186725616455078, -0.029186725616455078], "metadata": {"source_tokens": ["Em", "##p", "##loy", "##ers", "could", "also", "pay", "a", "sub", "##mini", "##mum", "`", "##`", "training", "wage", "'", "##'", "for", "90", "days", "to", "new", "workers", "who", "are", "up", "to", "19", "years", "old", ",", "and", "then", "for", "another", "90", "days", "if", "the", "company", "institutes", "a", "specific", "training", "program", "for", "the", "newcomer", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "company", "[unused2]", "[unused3]", "institutes", "[unused4]", "[unused5]", "a", "specific", "training", "program", "for", "the", "newcomer", "##s", "[unused6]", "[SEP]", "[unused1]", "new", "workers", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "up", "to", "19", "years", "old", "[unused6]", "[SEP]", "[unused1]", "Em", "##p", "##loy", "##ers", "[unused2]", "[unused3]", "could", "pay", "[unused4]", "[unused5]", "a", "sub", "##mini", "##mum", "`", "##`", "training", "wage", "'", "##'", "for", "90", "days", "to", "new", "workers", "[unused6]", "[SEP]"]]}

input 456:  {"source": "Ever since , the remaining members have been desperate for the United States to rejoin this dreadful group .\n"}
prediction:  {"predictions": [[1, 1103, 2735, 1484, 2, 3, 1138, 1151, 4, 5, 7127, 1111, 1103, 1244, 1311, 1106, 1231, 25665, 1142, 25671, 1372, 10006, 1290, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0011162019800394773, -0.09081315994262695, -0.09196138381958008, -0.09196138381958008, -0.09196138381958008, -0.09196138381958008, -0.09196138381958008, -0.09196138381958008, -0.09196138381958008, -0.09196138381958008], "metadata": {"source_tokens": ["Ever", "since", ",", "the", "remaining", "members", "have", "been", "desperate", "for", "the", "United", "States", "to", "re", "##join", "this", "dreadful", "group", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "remaining", "members", "[unused2]", "[unused3]", "have", "been", "[unused4]", "[unused5]", "desperate", "for", "the", "United", "States", "to", "re", "##join", "this", "dreadful", "group", "Ever", "since", "[unused6]", "[SEP]"]]}

input 457:  {"source": "Feeling the naggings of a culture imperative , I promptly signed up .\n"}
prediction:  {"predictions": [[1, 146, 2, 3, 13796, 1878, 1146, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 146, 2, 3, 1878, 1146, 13085, 4, 5, 1103, 9468, 10932, 1116, 1104, 170, 2754, 24034, 21126, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.030728774145245552, -0.035813990980386734, -0.0409245491027832, -0.04060697555541992, -0.04060697555541992, -0.04060697555541992, -0.04060697555541992, -0.04060697555541992, -0.04060697555541992, -0.04060697555541992], "metadata": {"source_tokens": ["Feeling", "the", "na", "##gging", "##s", "of", "a", "culture", "imp", "##erative", ",", "I", "promptly", "signed", "up", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "I", "[unused2]", "[unused3]", "promptly", "signed", "up", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "I", "[unused2]", "[unused3]", "signed", "up", "Feeling", "[unused4]", "[unused5]", "the", "na", "##gging", "##s", "of", "a", "culture", "imp", "##erative", "[unused6]", "[SEP]"]]}

input 458:  {"source": "Few people in the advertising business have raised as many hackles as Alvin A. Achenbaum .\n"}
prediction:  {"predictions": [[1, 17751, 1234, 1107, 1103, 6437, 1671, 2, 3, 1138, 2120, 4, 5, 1112, 1242, 5871, 19053, 1116, 1112, 18577, 138, 28138, 138, 10415, 14318, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-2.3833026716602035e-05, -0.024466991424560547, -0.023209095001220703, -0.023209095001220703, -0.023209095001220703, -0.023209095001220703, -0.023209095001220703, -0.023209095001220703, -0.023209095001220703, -0.023209095001220703], "metadata": {"source_tokens": ["Few", "people", "in", "the", "advertising", "business", "have", "raised", "as", "many", "ha", "##ckle", "##s", "as", "Alvin", "A", "##.", "A", "##chen", "##baum", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Few", "people", "in", "the", "advertising", "business", "[unused2]", "[unused3]", "have", "raised", "[unused4]", "[unused5]", "as", "many", "ha", "##ckle", "##s", "as", "Alvin", "A", "##.", "A", "##chen", "##baum", "[unused6]", "[SEP]"]]}

input 459:  {"source": "Finally , Mitsubishi Estate has no plans to interfere with Rockefeller 's management beyond taking a place on the board .\n"}
prediction:  {"predictions": [[1, 21450, 9765, 2, 3, 1144, 4, 5, 1185, 2714, 1106, 15891, 1114, 17768, 112, 1116, 2635, 2894, 1781, 170, 1282, 1113, 1103, 2313, 4428, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00098884548060596, -0.15926885604858398, -0.15031671524047852, -0.15031719207763672, -0.15031719207763672, -0.15031719207763672, -0.15031719207763672, -0.15031719207763672, -0.15031719207763672, -0.15031719207763672], "metadata": {"source_tokens": ["Finally", ",", "Mitsubishi", "Estate", "has", "no", "plans", "to", "interfere", "with", "Rockefeller", "'", "##s", "management", "beyond", "taking", "a", "place", "on", "the", "board", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mitsubishi", "Estate", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "no", "plans", "to", "interfere", "with", "Rockefeller", "'", "##s", "management", "beyond", "taking", "a", "place", "on", "the", "board", "Finally", "[unused6]", "[SEP]"]]}

input 460:  {"source": "First Boston incurred millions of dollars of losses on Campeau securities it owned as well as on special securities it could n't sell .\n"}
prediction:  {"predictions": [[1, 1752, 2859, 2, 3, 25240, 4, 5, 9215, 1104, 5860, 1104, 6053, 1113, 5503, 8221, 19313, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5503, 8221, 19313, 2, 3, 1129, 2205, 4, 5, 1112, 1218, 1112, 1113, 1957, 19313, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1180, 183, 28131, 1204, 4582, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017942309379577637, -0.1574316918849945, -0.07953055202960968, -0.09471654891967773, -0.09118175506591797, -0.09118175506591797, -0.09118223190307617, -0.09118175506591797, -0.09118175506591797, -0.09118175506591797], "metadata": {"source_tokens": ["First", "Boston", "incurred", "millions", "of", "dollars", "of", "losses", "on", "Camp", "##eau", "securities", "it", "owned", "as", "well", "as", "on", "special", "securities", "it", "could", "n", "##'", "##t", "sell", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "First", "Boston", "[unused2]", "[unused3]", "incurred", "[unused4]", "[unused5]", "millions", "of", "dollars", "of", "losses", "on", "Camp", "##eau", "securities", "[unused6]", "[SEP]", "[unused1]", "Camp", "##eau", "securities", "[unused2]", "[unused3]", "be", "owned", "[unused4]", "[unused5]", "as", "well", "as", "on", "special", "securities", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "could", "n", "##'", "##t", "sell", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 461:  {"source": "For example , a passenger can fly from Chardon , Neb. , to Denver for as little as $ 89 to $ 109 , according to prices quoted by the company .\n"}
prediction:  {"predictions": [[1, 7352, 2, 3, 9129, 4, 5, 1118, 1103, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4059, 2, 3, 1169, 4689, 4, 5, 1121, 24705, 22528, 117, 151, 15581, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4059, 2, 3, 1169, 4689, 4, 5, 1121, 24705, 22528, 117, 151, 15581, 28138, 117, 1106, 7068, 1111, 1112, 1376, 1112, 109, 5840, 1106, 109, 11523, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008097012527287006, -0.04427138343453407, -0.0844552218914032, -0.1290431022644043, -0.12537765502929688, -0.12537765502929688, -0.12537765502929688, -0.12537765502929688, -0.12537765502929688, -0.12537765502929688], "metadata": {"source_tokens": ["For", "example", ",", "a", "passenger", "can", "fly", "from", "Cha", "##rdon", ",", "N", "##eb", "##.", ",", "to", "Denver", "for", "as", "little", "as", "$", "89", "to", "$", "109", ",", "according", "to", "prices", "quoted", "by", "the", "company", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "prices", "[unused2]", "[unused3]", "quoted", "[unused4]", "[unused5]", "by", "the", "company", "[unused6]", "[SEP]", "[unused1]", "a", "passenger", "[unused2]", "[unused3]", "can", "fly", "[unused4]", "[unused5]", "from", "Cha", "##rdon", ",", "N", "##eb", "##.", "[unused6]", "[SEP]", "[unused1]", "a", "passenger", "[unused2]", "[unused3]", "can", "fly", "[unused4]", "[unused5]", "from", "Cha", "##rdon", ",", "N", "##eb", "##.", ",", "to", "Denver", "for", "as", "little", "as", "$", "89", "to", "$", "109", "[unused6]", "[SEP]"]]}

input 462:  {"source": "For the past five years , unions have n't managed to win wage increases as large as those granted to nonunion workers .\n"}
prediction:  {"predictions": [[1, 1343, 2, 3, 3609, 4, 5, 1106, 1664, 19698, 3239, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10230, 2, 3, 1138, 183, 28131, 1204, 2374, 1106, 1782, 4, 5, 12634, 6986, 1112, 1415, 1112, 1343, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.028515595942735672, -0.04590044543147087, -0.04769420623779297, -0.04680299758911133, -0.04680299758911133, -0.04680299758911133, -0.04680299758911133, -0.04680299758911133, -0.04680299758911133, -0.04680299758911133], "metadata": {"source_tokens": ["For", "the", "past", "five", "years", ",", "unions", "have", "n", "##'", "##t", "managed", "to", "win", "wage", "increases", "as", "large", "as", "those", "granted", "to", "non", "##union", "workers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "those", "[unused2]", "[unused3]", "granted", "[unused4]", "[unused5]", "to", "non", "##union", "workers", "[unused6]", "[SEP]", "[unused1]", "unions", "[unused2]", "[unused3]", "have", "n", "##'", "##t", "managed", "to", "win", "[unused4]", "[unused5]", "wage", "increases", "as", "large", "as", "those", "[unused6]", "[SEP]"]]}

input 463:  {"source": "For the record , Jeffrey Kaufman , an attorney for Fireman 's Fund , said he was `` rattled -- both literally and figuratively . ''\n"}
prediction:  {"predictions": [[1, 10708, 26517, 2, 3, 1163, 4, 5, 1119, 1108, 169, 28152, 21117, 118, 28137, 1241, 6290, 1105, 20497, 13830, 15306, 1193, 1370, 1103, 1647, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10708, 26517, 2, 3, 1110, 1126, 6507, 1111, 4, 5, 4266, 1399, 112, 1116, 6606, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007322307210415602, -0.02458946220576763, -0.26138830184936523, -0.2571282386779785, -0.2571282386779785, -0.2571282386779785, -0.2571282386779785, -0.2571282386779785, -0.2571282386779785, -0.2571287155151367], "metadata": {"source_tokens": ["For", "the", "record", ",", "Jeffrey", "Kaufman", ",", "an", "attorney", "for", "Fire", "##man", "'", "##s", "Fund", ",", "said", "he", "was", "`", "##`", "rattled", "-", "##-", "both", "literally", "and", "fi", "##gu", "##rative", "##ly", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Jeffrey", "Kaufman", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "he", "was", "`", "##`", "rattled", "-", "##-", "both", "literally", "and", "fi", "##gu", "##rative", "##ly", "For", "the", "record", "[unused6]", "[SEP]", "[unused1]", "Jeffrey", "Kaufman", "[unused2]", "[unused3]", "is", "an", "attorney", "for", "[unused4]", "[unused5]", "Fire", "##man", "'", "##s", "Fund", "[unused6]", "[SEP]"]]}

input 464:  {"source": "Ford Motor Co. said it is recalling about 3,600 of its 1990 - model Escorts because the windshield adhesive was improperly applied to some cars .\n"}
prediction:  {"predictions": [[1, 4100, 8226, 3291, 28138, 2, 3, 1163, 4, 5, 1122, 1110, 25839, 1164, 124, 28136, 16480, 1568, 1104, 1157, 1997, 118, 2235, 142, 11428, 13245, 1272, 1103, 21522, 8050, 23838, 1108, 24034, 26554, 1193, 3666, 1106, 1199, 3079, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005535404663532972, -0.3365898132324219, -0.2935914993286133, -0.2935934066772461, -0.2935934066772461, -0.2935934066772461, -0.2935934066772461, -0.2935929298400879, -0.2935929298400879, -0.2935929298400879], "metadata": {"source_tokens": ["Ford", "Motor", "Co", "##.", "said", "it", "is", "recalling", "about", "3", "##,", "##60", "##0", "of", "its", "1990", "-", "model", "E", "##sco", "##rts", "because", "the", "windshield", "ad", "##hesive", "was", "imp", "##roper", "##ly", "applied", "to", "some", "cars", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ford", "Motor", "Co", "##.", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "is", "recalling", "about", "3", "##,", "##60", "##0", "of", "its", "1990", "-", "model", "E", "##sco", "##rts", "because", "the", "windshield", "ad", "##hesive", "was", "imp", "##roper", "##ly", "applied", "to", "some", "cars", "[unused6]", "[SEP]"]]}

input 465:  {"source": "Fraser & Neave , which also has interests in packaging , beer and dairy products , holds the Coke licenses for Malaysia and Brunei , where per - capita consumption is n't as high as in Singapore .\n"}
prediction:  {"predictions": [[1, 9156, 111, 151, 4490, 2707, 2, 3, 1144, 4, 5, 4740, 1107, 17019, 117, 5298, 1105, 14874, 2982, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9156, 111, 151, 4490, 2707, 2, 3, 3486, 4, 5, 1103, 19630, 17488, 1111, 5355, 1105, 20249, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1679, 118, 8008, 8160, 2, 3, 1110, 183, 28131, 1204, 4, 5, 1112, 1344, 1112, 1107, 4478, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.015991751104593277, -0.038803018629550934, -0.10812799632549286, -0.10296297073364258, -0.10232019424438477, -0.10232019424438477, -0.10232019424438477, -0.10232019424438477, -0.10232019424438477, -0.10232019424438477], "metadata": {"source_tokens": ["Fraser", "&", "N", "##ea", "##ve", ",", "which", "also", "has", "interests", "in", "packaging", ",", "beer", "and", "dairy", "products", ",", "holds", "the", "Coke", "licenses", "for", "Malaysia", "and", "Brunei", ",", "where", "per", "-", "capita", "consumption", "is", "n", "##'", "##t", "as", "high", "as", "in", "Singapore", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Fraser", "&", "N", "##ea", "##ve", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "interests", "in", "packaging", ",", "beer", "and", "dairy", "products", "[unused6]", "[SEP]", "[unused1]", "Fraser", "&", "N", "##ea", "##ve", "[unused2]", "[unused3]", "holds", "[unused4]", "[unused5]", "the", "Coke", "licenses", "for", "Malaysia", "and", "Brunei", "[unused6]", "[SEP]", "[unused1]", "per", "-", "capita", "consumption", "[unused2]", "[unused3]", "is", "n", "##'", "##t", "[unused4]", "[unused5]", "as", "high", "as", "in", "Singapore", "[unused6]", "[SEP]"]]}

input 466:  {"source": "Hani Zayadi was appointed president and chief executive officer of this financially troubled department store chain , effective Nov. 15 , succeeding Frank Robertson , who is retiring early .\n"}
prediction:  {"predictions": [[1, 7699, 1182, 163, 12057, 3309, 2, 3, 1108, 1923, 4, 5, 2084, 1105, 2705, 3275, 2575, 1104, 1142, 14396, 12322, 2853, 2984, 4129, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2748, 9693, 2, 3, 1129, 1110, 4, 5, 1150, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2748, 9693, 2, 3, 1129, 4, 5, 1150, 1110, 8970, 1346, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03722946345806122, -0.2692577838897705, -0.25322991609573364, -0.2729983329772949, -0.2703266143798828, -0.2703266143798828, -0.2703266143798828, -0.2703266143798828, -0.2703266143798828, -0.2703266143798828], "metadata": {"source_tokens": ["Han", "##i", "Z", "##aya", "##di", "was", "appointed", "president", "and", "chief", "executive", "officer", "of", "this", "financially", "troubled", "department", "store", "chain", ",", "effective", "Nov", "##.", "15", ",", "succeeding", "Frank", "Robertson", ",", "who", "is", "retiring", "early", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Han", "##i", "Z", "##aya", "##di", "[unused2]", "[unused3]", "was", "appointed", "[unused4]", "[unused5]", "president", "and", "chief", "executive", "officer", "of", "this", "financially", "troubled", "department", "store", "chain", "[unused6]", "[SEP]", "[unused1]", "Frank", "Robertson", "[unused2]", "[unused3]", "be", "is", "[unused4]", "[unused5]", "who", "[unused6]", "[SEP]", "[unused1]", "Frank", "Robertson", "[unused2]", "[unused3]", "be", "[unused4]", "[unused5]", "who", "is", "retiring", "early", "[unused6]", "[SEP]"]]}

input 467:  {"source": "He also contended that the plaintiffs failed to cite any legal authority that would justify such an injunction .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 14255, 21857, 4, 5, 1115, 1103, 23940, 1116, 2604, 1106, 172, 3150, 1251, 2732, 3748, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1251, 2732, 3748, 2, 3, 1129, 1156, 17422, 4, 5, 1216, 1126, 25905, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.025772277265787125, -0.10231079161167145, -0.15583086013793945, -0.16235733032226562, -0.16235733032226562, -0.16235733032226562, -0.16235733032226562, -0.16235733032226562, -0.16235733032226562, -0.16235733032226562], "metadata": {"source_tokens": ["He", "also", "con", "##tended", "that", "the", "plaintiff", "##s", "failed", "to", "c", "##ite", "any", "legal", "authority", "that", "would", "justify", "such", "an", "injunction", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "con", "##tended", "[unused4]", "[unused5]", "that", "the", "plaintiff", "##s", "failed", "to", "c", "##ite", "any", "legal", "authority", "[unused6]", "[SEP]", "[unused1]", "any", "legal", "authority", "[unused2]", "[unused3]", "be", "would", "justify", "[unused4]", "[unused5]", "such", "an", "injunction", "[unused6]", "[SEP]"]]}

input 468:  {"source": "He also unfortunately illustrated this intricate , jazzy tapestry with Mr. Pearson 's images , this time of geometric or repeating objects , in a kitschy mirroring of the musical structure that was thoroughly distracting from Mr. Reich 's piece and Mr. Stoltzman 's elegant execution of it .\n"}
prediction:  {"predictions": [[1, 1103, 2696, 2401, 2, 3, 1108, 16989, 1158, 4, 5, 1121, 1828, 28138, 14994, 112, 1116, 2727, 1105, 1828, 28138, 1457, 17772, 27277, 112, 1116, 12002, 7581, 1104, 1122, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2696, 2401, 2, 3, 1108, 16989, 1158, 4, 5, 1121, 1828, 28138, 14994, 112, 1116, 2727, 1105, 1828, 28138, 1457, 17772, 27277, 112, 1116, 12002, 7581, 1104, 1122, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2696, 2401, 2, 3, 1108, 16989, 1158, 4, 5, 1121, 1828, 28138, 14994, 112, 1116, 2727, 1105, 1828, 28138, 1457, 17772, 27277, 112, 1116, 12002, 7581, 1104, 1122, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2696, 2401, 2, 3, 1108, 16989, 1158, 4, 5, 1121, 1828, 28138, 14994, 112, 1116, 2727, 1105, 1828, 28138, 1457, 17772, 27277, 112, 1116, 12002, 7581, 1104, 1122, 6, 102, 102, 1, 1103, 2696, 2401, 2, 3, 1108, 16989, 1158, 4, 5, 1121, 1828, 28138, 14994, 112, 1116, 2727, 1105, 1828, 28138, 1457, 17772, 27277, 112, 1116, 12002, 7581, 1104, 1122, 6, 102, 102, 102, 102, 102, 1, 1103, 2696, 2401, 2, 3, 1108, 16989, 1158, 4, 5, 1121, 1828, 28138, 14994, 112, 1116, 2727, 1105, 1828, 28138, 1457, 17772, 27277, 112, 1116, 12002, 7581, 1104, 1122, 6, 102, 102, 1, 1103, 2696, 2401, 2, 3, 1108, 16989, 1158, 4, 5, 1121, 1828, 28138, 14994, 112, 1116, 2727, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2696, 2401, 2, 3, 1108, 16989, 1158, 4, 5, 1121, 1828, 28138, 14994, 112, 1116, 2727, 6, 102, 102, 1, 1103, 2696, 2401, 2, 3, 1108, 16989, 1158, 4, 5, 1121, 1828, 28138, 14994, 112, 1116, 2727, 6, 102, 102, 1, 1103, 2696, 2401, 2, 3, 1108, 16989, 1158, 4, 5, 1121, 1828, 28138, 14994, 112, 1116, 2727, 6, 102, 102]], "predicted_log_probs": [-0.02367982640862465, -0.06659702956676483, -0.06101888418197632, -0.06638474762439728, -0.06996442377567291, -0.08330400288105011, -0.10597848892211914, -0.09727049618959427, -0.09807531535625458, -0.11838644742965698], "metadata": {"source_tokens": ["He", "also", "unfortunately", "illustrated", "this", "intricate", ",", "jazz", "##y", "tapes", "##try", "with", "Mr", "##.", "Pearson", "'", "##s", "images", ",", "this", "time", "of", "geometric", "or", "repeating", "objects", ",", "in", "a", "kits", "##chy", "mirror", "##ing", "of", "the", "musical", "structure", "that", "was", "thoroughly", "distract", "##ing", "from", "Mr", "##.", "Reich", "'", "##s", "piece", "and", "Mr", "##.", "St", "##olt", "##zman", "'", "##s", "elegant", "execution", "of", "it", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "musical", "structure", "[unused2]", "[unused3]", "was", "distract", "##ing", "[unused4]", "[unused5]", "from", "Mr", "##.", "Reich", "'", "##s", "piece", "and", "Mr", "##.", "St", "##olt", "##zman", "'", "##s", "elegant", "execution", "of", "it", "[unused6]", "[SEP]", "[unused1]", "the", "musical", "structure", "[unused2]", "[unused3]", "was", "distract", "##ing", "[unused4]", "[unused5]", "from", "Mr", "##.", "Reich", "'", "##s", "piece", "and", "Mr", "##.", "St", "##olt", "##zman", "'", "##s", "elegant", "execution", "of", "it", "[unused6]", "[SEP]", "[unused1]", "the", "musical", "structure", "[unused2]", "[unused3]", "was", "distract", "##ing", "[unused4]", "[unused5]", "from", "Mr", "##.", "Reich", "'", "##s", "piece", "and", "Mr", "##.", "St", "##olt", "##zman", "'", "##s", "elegant", "execution", "of", "it", "[unused6]", "[SEP]", "[unused1]", "the", "musical", "structure", "[unused2]", "[unused3]", "was", "distract", "##ing", "[unused4]", "[unused5]", "from", "Mr", "##.", "Reich", "'", "##s", "piece", "and", "Mr", "##.", "St", "##olt", "##zman", "'", "##s", "elegant", "execution", "of", "it", "[unused6]", "[SEP]", "[unused1]", "the", "musical", "structure", "[unused2]", "[unused3]", "was", "distract", "##ing", "[unused4]", "[unused5]", "from", "Mr", "##.", "Reich", "'", "##s", "piece", "and", "Mr", "##.", "St", "##olt", "##zman", "'", "##s", "elegant", "execution", "of", "it", "[unused6]", "[SEP]", "[unused1]", "the", "musical", "structure", "[unused2]", "[unused3]", "was", "distract", "##ing", "[unused4]", "[unused5]", "from", "Mr", "##.", "Reich", "'", "##s", "piece", "and", "Mr", "##.", "St", "##olt", "##zman", "'", "##s", "elegant", "execution", "of", "it", "[unused6]", "[SEP]", "[unused1]", "the", "musical", "structure", "[unused2]", "[unused3]", "was", "distract", "##ing", "[unused4]", "[unused5]", "from", "Mr", "##.", "Reich", "'", "##s", "piece", "[unused6]", "[SEP]", "[unused1]", "the", "musical", "structure", "[unused2]", "[unused3]", "was", "distract", "##ing", "[unused4]", "[unused5]", "from", "Mr", "##.", "Reich", "'", "##s", "piece", "[unused6]", "[SEP]", "[unused1]", "the", "musical", "structure", "[unused2]", "[unused3]", "was", "distract", "##ing", "[unused4]", "[unused5]", "from", "Mr", "##.", "Reich", "'", "##s", "piece", "[unused6]", "[SEP]", "[unused1]", "the", "musical", "structure", "[unused2]", "[unused3]", "was", "distract", "##ing", "[unused4]", "[unused5]", "from", "Mr", "##.", "Reich", "'", "##s", "piece", "[unused6]", "[SEP]"]]}

input 469:  {"source": "He discovered a 75 - cent discrepancy in the charges made to various departments for computer time and traced it to a user named `` Hunter , '' who had no valid billing address .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 2751, 4, 5, 170, 3453, 118, 9848, 6187, 1874, 10224, 3457, 1107, 1103, 4917, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4917, 2, 3, 1129, 1129, 1189, 4, 5, 1106, 1672, 7844, 1111, 2775, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4795, 1417, 169, 28152, 4242, 2, 3, 1125, 4, 5, 1185, 9221, 4550, 1158, 4134, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 9286, 4, 5, 1122, 1106, 170, 4795, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.040292251855134964, -0.17207765579223633, -0.11350606381893158, -0.15373080968856812, -0.1250925064086914, -0.12520980834960938, -0.12520980834960938, -0.12521028518676758, -0.12520980834960938, -0.12520980834960938], "metadata": {"source_tokens": ["He", "discovered", "a", "75", "-", "cent", "disc", "##re", "##pan", "##cy", "in", "the", "charges", "made", "to", "various", "departments", "for", "computer", "time", "and", "traced", "it", "to", "a", "user", "named", "`", "##`", "Hunter", ",", "'", "##'", "who", "had", "no", "valid", "bill", "##ing", "address", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "discovered", "[unused4]", "[unused5]", "a", "75", "-", "cent", "disc", "##re", "##pan", "##cy", "in", "the", "charges", "[unused6]", "[SEP]", "[unused1]", "the", "charges", "[unused2]", "[unused3]", "be", "be", "made", "[unused4]", "[unused5]", "to", "various", "departments", "for", "computer", "time", "[unused6]", "[SEP]", "[unused1]", "a", "user", "named", "`", "##`", "Hunter", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "no", "valid", "bill", "##ing", "address", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "traced", "[unused4]", "[unused5]", "it", "to", "a", "user", "[unused6]", "[SEP]"]]}

input 470:  {"source": "He has n't been able to replace the M'Bow cabal .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1144, 183, 28131, 1204, 1151, 4, 5, 1682, 1106, 4971, 1103, 150, 28131, 2064, 4064, 10347, 1348, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-6.376142118824646e-05, -0.01603984832763672, -0.01654195785522461, -0.01654195785522461, -0.01654195785522461, -0.01654195785522461, -0.01654195785522461, -0.01654195785522461, -0.01654195785522461, -0.01654195785522461], "metadata": {"source_tokens": ["He", "has", "n", "##'", "##t", "been", "able", "to", "replace", "the", "M", "##'", "##B", "##ow", "cab", "##al", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "has", "n", "##'", "##t", "been", "[unused4]", "[unused5]", "able", "to", "replace", "the", "M", "##'", "##B", "##ow", "cab", "##al", "[unused6]", "[SEP]"]]}

input 471:  {"source": "He said he expects the company to have $ 500 million in sales for this year .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1163, 4, 5, 1119, 27402, 1103, 1419, 1106, 1138, 109, 2260, 1550, 1107, 3813, 1111, 1142, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0017320384504273534, -0.17894792556762695, -0.16955900192260742, -0.16955804824829102, -0.16955804824829102, -0.16955804824829102, -0.16955804824829102, -0.16955804824829102, -0.16955804824829102, -0.16955804824829102], "metadata": {"source_tokens": ["He", "said", "he", "expects", "the", "company", "to", "have", "$", "500", "million", "in", "sales", "for", "this", "year", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "he", "expects", "the", "company", "to", "have", "$", "500", "million", "in", "sales", "for", "this", "year", "[unused6]", "[SEP]"]]}

input 472:  {"source": "He sold them well below market value to raise cash `` to pay off mounting credit - card debts , '' incurred to buy presents for his girlfriend , his attorney , Philip Russell , told IFAR .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1962, 4, 5, 1172, 1218, 2071, 2319, 2860, 1106, 4693, 5948, 1106, 2653, 1228, 17361, 4755, 118, 3621, 14689, 25240, 1106, 4417, 8218, 1111, 1117, 6124, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 6507, 2, 3, 1500, 4, 5, 13729, 12426, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 17361, 4755, 118, 3621, 14689, 2, 3, 1129, 25240, 4, 5, 1106, 4417, 8218, 1111, 1117, 6124, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.08222339302301407, -0.11751484125852585, -0.07887856662273407, -0.2646784782409668, -0.26502418518066406, -0.26502418518066406, -0.26502418518066406, -0.26502418518066406, -0.26502418518066406, -0.26502418518066406], "metadata": {"source_tokens": ["He", "sold", "them", "well", "below", "market", "value", "to", "raise", "cash", "`", "##`", "to", "pay", "off", "mounting", "credit", "-", "card", "debts", ",", "'", "##'", "incurred", "to", "buy", "presents", "for", "his", "girlfriend", ",", "his", "attorney", ",", "Philip", "Russell", ",", "told", "IF", "##AR", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "sold", "[unused4]", "[unused5]", "them", "well", "below", "market", "value", "to", "raise", "cash", "to", "pay", "off", "mounting", "credit", "-", "card", "debts", "incurred", "to", "buy", "presents", "for", "his", "girlfriend", "[unused6]", "[SEP]", "[unused1]", "his", "attorney", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "IF", "##AR", "[unused6]", "[SEP]", "[unused1]", "mounting", "credit", "-", "card", "debts", "[unused2]", "[unused3]", "be", "incurred", "[unused4]", "[unused5]", "to", "buy", "presents", "for", "his", "girlfriend", "[unused6]", "[SEP]"]]}

input 473:  {"source": "Her recent report classifies the stock as a `` hold . ''\n"}
prediction:  {"predictions": [[1, 1430, 2793, 2592, 2, 3, 1705, 9387, 4, 5, 1103, 4482, 1112, 170, 169, 28152, 2080, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-3.362956704222597e-05, -0.028494834899902344, -0.02607440948486328, -0.02607440948486328, -0.02607440948486328, -0.02607440948486328, -0.02607440948486328, -0.02607440948486328, -0.02607440948486328, -0.02607440948486328], "metadata": {"source_tokens": ["Her", "recent", "report", "class", "##ifies", "the", "stock", "as", "a", "`", "##`", "hold", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Her", "recent", "report", "[unused2]", "[unused3]", "class", "##ifies", "[unused4]", "[unused5]", "the", "stock", "as", "a", "`", "##`", "hold", "[unused6]", "[SEP]"]]}

input 474:  {"source": "Here are price trends on the world 's major stock markets , as calculated by Morgan Stanley Capital International Perspective , Geneva .\n"}
prediction:  {"predictions": [[1, 3945, 14652, 1113, 1103, 1362, 112, 1116, 1558, 4482, 5809, 2, 3, 3446, 1132, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3945, 14652, 1113, 1103, 1362, 112, 1116, 1558, 4482, 5809, 2, 3, 10056, 4, 5, 1118, 4461, 5481, 6299, 1570, 14286, 16776, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07400058209896088, -0.06121356040239334, -0.1070408821105957, -0.10858726501464844, -0.10858726501464844, -0.10858726501464844, -0.10858726501464844, -0.10858726501464844, -0.10858726501464844, -0.10858726501464844], "metadata": {"source_tokens": ["Here", "are", "price", "trends", "on", "the", "world", "'", "##s", "major", "stock", "markets", ",", "as", "calculated", "by", "Morgan", "Stanley", "Capital", "International", "Per", "##spective", ",", "Geneva", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "price", "trends", "on", "the", "world", "'", "##s", "major", "stock", "markets", "[unused2]", "[unused3]", "Here", "are", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "price", "trends", "on", "the", "world", "'", "##s", "major", "stock", "markets", "[unused2]", "[unused3]", "calculated", "[unused4]", "[unused5]", "by", "Morgan", "Stanley", "Capital", "International", "Per", "##spective", "[unused6]", "[SEP]"]]}

input 475:  {"source": "However , StatesWest is n't abandoning its pursuit of the much - larger Mesa .\n"}
prediction:  {"predictions": [[1, 1311, 2924, 2556, 2, 3, 1110, 183, 28131, 1204, 22634, 4, 5, 1157, 9542, 1104, 1103, 1277, 118, 2610, 18506, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00012897927081212401, -0.015558719635009766, -0.01463460922241211, -0.01463460922241211, -0.01463460922241211, -0.01463460922241211, -0.01463460922241211, -0.01463460922241211, -0.01463460922241211, -0.01463460922241211], "metadata": {"source_tokens": ["However", ",", "States", "##W", "##est", "is", "n", "##'", "##t", "abandoning", "its", "pursuit", "of", "the", "much", "-", "larger", "Mesa", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "States", "##W", "##est", "[unused2]", "[unused3]", "is", "n", "##'", "##t", "abandoning", "[unused4]", "[unused5]", "its", "pursuit", "of", "the", "much", "-", "larger", "Mesa", "[unused6]", "[SEP]"]]}

input 476:  {"source": "However , a Canadian Embassy official in Tel Aviv said that Canada was unlikely to sell the Candu heavy - water reactor to Israel since Israel has n't signed the Nuclear Non - Proliferation Treaty .\n"}
prediction:  {"predictions": [[1, 170, 2122, 13530, 2078, 1107, 11341, 12927, 2, 3, 1163, 4, 5, 1115, 1803, 1106, 4582, 1103, 2825, 7641, 2302, 118, 1447, 15056, 1106, 3103, 1290, 3103, 1144, 183, 28131, 1204, 1878, 1103, 11560, 7922, 118, 5096, 14430, 6108, 6599, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1803, 2, 3, 1108, 4, 5, 9803, 1106, 4582, 1103, 2825, 7641, 2302, 118, 1447, 15056, 1106, 3103, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3103, 2, 3, 1144, 183, 28131, 1204, 1878, 4, 5, 1103, 11560, 7922, 118, 5096, 14430, 6108, 6599, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.018067745491862297, -0.04062029719352722, -0.05820596218109131, -0.08106708526611328, -0.0820302963256836, -0.0820302963256836, -0.0820302963256836, -0.0820302963256836, -0.0820302963256836, -0.0820302963256836], "metadata": {"source_tokens": ["However", ",", "a", "Canadian", "Embassy", "official", "in", "Tel", "Aviv", "said", "that", "Canada", "was", "unlikely", "to", "sell", "the", "Can", "##du", "heavy", "-", "water", "reactor", "to", "Israel", "since", "Israel", "has", "n", "##'", "##t", "signed", "the", "Nuclear", "Non", "-", "Pro", "##life", "##ration", "Treaty", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "Canadian", "Embassy", "official", "in", "Tel", "Aviv", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "that", "Canada", "to", "sell", "the", "Can", "##du", "heavy", "-", "water", "reactor", "to", "Israel", "since", "Israel", "has", "n", "##'", "##t", "signed", "the", "Nuclear", "Non", "-", "Pro", "##life", "##ration", "Treaty", "[unused6]", "[SEP]", "[unused1]", "Canada", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "unlikely", "to", "sell", "the", "Can", "##du", "heavy", "-", "water", "reactor", "to", "Israel", "[unused6]", "[SEP]", "[unused1]", "Israel", "[unused2]", "[unused3]", "has", "n", "##'", "##t", "signed", "[unused4]", "[unused5]", "the", "Nuclear", "Non", "-", "Pro", "##life", "##ration", "Treaty", "[unused6]", "[SEP]"]]}

input 477:  {"source": "However , the problem is that once most poison pills are adopted , they survive forever .\n"}
prediction:  {"predictions": [[1, 1103, 2463, 2, 3, 1110, 4, 5, 1115, 1517, 1211, 11539, 17029, 1132, 3399, 117, 1152, 5195, 5221, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1211, 11539, 17029, 2, 3, 1132, 3399, 1104, 4, 5, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0007401364273391664, -0.1306549608707428, -0.08442926406860352, -0.08356952667236328, -0.08356952667236328, -0.08356952667236328, -0.08356952667236328, -0.08356952667236328, -0.08356952667236328, -0.08356952667236328], "metadata": {"source_tokens": ["However", ",", "the", "problem", "is", "that", "once", "most", "poison", "pills", "are", "adopted", ",", "they", "survive", "forever", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "problem", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "that", "once", "most", "poison", "pills", "are", "adopted", ",", "they", "survive", "forever", "[unused6]", "[SEP]", "[unused1]", "most", "poison", "pills", "[unused2]", "[unused3]", "are", "adopted", "of", "[unused4]", "[unused5]", "him", "[unused6]", "[SEP]"]]}

input 478:  {"source": "Humana contends that $ 8,000 represents an extreme case and that its regular charge for lithotripsy is $ 4,900 .\n"}
prediction:  {"predictions": [[1, 4243, 1161, 2, 3, 14255, 22910, 1116, 4, 5, 1115, 109, 129, 28136, 7629, 1568, 5149, 1126, 6122, 1692, 1105, 1115, 1157, 2366, 2965, 1111, 4941, 12217, 16669, 5821, 1110, 109, 125, 28136, 21500, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1157, 2366, 2965, 1111, 4941, 12217, 16669, 5821, 2, 3, 1129, 1110, 4, 5, 109, 125, 28136, 21500, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.002926221117377281, -0.03368289768695831, -0.12852716445922852, -0.12578344345092773, -0.12578344345092773, -0.12578344345092773, -0.12578344345092773, -0.12578392028808594, -0.12578344345092773, -0.12578344345092773], "metadata": {"source_tokens": ["Human", "##a", "con", "##tend", "##s", "that", "$", "8", "##,", "##00", "##0", "represents", "an", "extreme", "case", "and", "that", "its", "regular", "charge", "for", "lit", "##hot", "##rip", "##sy", "is", "$", "4", "##,", "##90", "##0", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Human", "##a", "[unused2]", "[unused3]", "con", "##tend", "##s", "[unused4]", "[unused5]", "that", "$", "8", "##,", "##00", "##0", "represents", "an", "extreme", "case", "and", "that", "its", "regular", "charge", "for", "lit", "##hot", "##rip", "##sy", "is", "$", "4", "##,", "##90", "##0", "[unused6]", "[SEP]", "[unused1]", "its", "regular", "charge", "for", "lit", "##hot", "##rip", "##sy", "[unused2]", "[unused3]", "be", "is", "[unused4]", "[unused5]", "$", "4", "##,", "##90", "##0", "[unused6]", "[SEP]"]]}

input 479:  {"source": "Hungary 's Parliament voted to hold a national referendum on an election to fill the new post of president .\n"}
prediction:  {"predictions": [[1, 5169, 112, 1116, 2901, 2, 3, 4751, 1106, 2080, 4, 5, 170, 1569, 9905, 1113, 1126, 1728, 1106, 5475, 1103, 1207, 2112, 1104, 2084, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012231292203068733, -0.027474403381347656, -0.023167133331298828, -0.023167133331298828, -0.023167133331298828, -0.023167133331298828, -0.023167133331298828, -0.023167133331298828, -0.023167133331298828, -0.023167133331298828], "metadata": {"source_tokens": ["Hungary", "'", "##s", "Parliament", "voted", "to", "hold", "a", "national", "referendum", "on", "an", "election", "to", "fill", "the", "new", "post", "of", "president", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hungary", "'", "##s", "Parliament", "[unused2]", "[unused3]", "voted", "to", "hold", "[unused4]", "[unused5]", "a", "national", "referendum", "on", "an", "election", "to", "fill", "the", "new", "post", "of", "president", "[unused6]", "[SEP]"]]}

input 480:  {"source": "I do n't think that is the case . ''\n"}
prediction:  {"predictions": [[1, 146, 2, 3, 1202, 183, 28131, 1204, 1341, 4, 5, 1115, 1110, 1103, 1692, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0005012960755266249, -0.008560657501220703, -0.006893157958984375, -0.006893157958984375, -0.006893157958984375, -0.006893157958984375, -0.006893157958984375, -0.006893157958984375, -0.006893157958984375, -0.006893157958984375], "metadata": {"source_tokens": ["I", "do", "n", "##'", "##t", "think", "that", "is", "the", "case", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "I", "[unused2]", "[unused3]", "do", "n", "##'", "##t", "think", "[unused4]", "[unused5]", "that", "is", "the", "case", "[unused6]", "[SEP]"]]}

input 481:  {"source": "I was pleased to note that your Oct. 23 Centennial Journal item recognized the money - fund concept as one of the significant events of the past century .\n"}
prediction:  {"predictions": [[1, 146, 2, 3, 1108, 4, 5, 7229, 1106, 3805, 1115, 1240, 14125, 28138, 1695, 20988, 3603, 8926, 3037, 1103, 1948, 118, 5841, 3400, 1112, 1141, 1104, 1103, 2418, 1958, 1104, 1103, 1763, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1240, 14125, 28138, 1695, 20988, 3603, 8926, 2, 3, 3037, 4, 5, 1103, 1948, 118, 5841, 3400, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.019437525421380997, -0.05076939985156059, -0.10538530349731445, -0.10387468338012695, -0.10387468338012695, -0.10387468338012695, -0.10387468338012695, -0.10387468338012695, -0.10387516021728516, -0.10387468338012695], "metadata": {"source_tokens": ["I", "was", "pleased", "to", "note", "that", "your", "Oct", "##.", "23", "Centennial", "Journal", "item", "recognized", "the", "money", "-", "fund", "concept", "as", "one", "of", "the", "significant", "events", "of", "the", "past", "century", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "I", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "pleased", "to", "note", "that", "your", "Oct", "##.", "23", "Centennial", "Journal", "item", "recognized", "the", "money", "-", "fund", "concept", "as", "one", "of", "the", "significant", "events", "of", "the", "past", "century", "[unused6]", "[SEP]", "[unused1]", "your", "Oct", "##.", "23", "Centennial", "Journal", "item", "[unused2]", "[unused3]", "recognized", "[unused4]", "[unused5]", "the", "money", "-", "fund", "concept", "[unused6]", "[SEP]"]]}

input 482:  {"source": "If there 's something ' weird and it do n't look good .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 1202, 183, 28131, 1204, 1440, 4, 5, 1363, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00423131650313735, -0.029546260833740234, -0.031991004943847656, -0.031991004943847656, -0.031991004943847656, -0.031991004943847656, -0.031991004943847656, -0.031991004943847656, -0.031991004943847656, -0.031991004943847656], "metadata": {"source_tokens": ["If", "there", "'", "##s", "something", "'", "weird", "and", "it", "do", "n", "##'", "##t", "look", "good", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "do", "n", "##'", "##t", "look", "[unused4]", "[unused5]", "good", "[unused6]", "[SEP]"]]}

input 483:  {"source": "In 1988 , a year and a half after Mrs. Marcos and her late husband , Ferdinand Marcos , the ousted president of the Philippines , fled the Philippines for Hawaii , they were charged with racketeering , conspiracy , obstruction of justice and mail fraud in a scheme in which they allegedly embezzled more than $ 100 million from their homeland .\n"}
prediction:  {"predictions": [[1, 1152, 2, 3, 1127, 4601, 4, 5, 1114, 16365, 16618, 5938, 117, 10758, 117, 184, 4832, 17993, 1104, 5299, 1105, 6346, 10258, 1107, 170, 5471, 1130, 2115, 170, 1214, 1105, 170, 1544, 1170, 2823, 28138, 15541, 1105, 1123, 1523, 2252, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9422, 15541, 2, 3, 6192, 4, 5, 1103, 4336, 1111, 6826, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9422, 15541, 2, 3, 1110, 4, 5, 1103, 20796, 8546, 2084, 1104, 1103, 4336, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 9273, 9712, 3962, 21011, 1181, 4, 5, 1167, 1190, 109, 1620, 1550, 1121, 1147, 14764, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04379411041736603, -0.03154756873846054, -0.07348721474409103, -0.08097640424966812, -0.13454627990722656, -0.139312744140625, -0.139312744140625, -0.139312744140625, -0.139312744140625, -0.139312744140625], "metadata": {"source_tokens": ["In", "1988", ",", "a", "year", "and", "a", "half", "after", "Mrs", "##.", "Marcos", "and", "her", "late", "husband", ",", "Ferdinand", "Marcos", ",", "the", "ou", "##sted", "president", "of", "the", "Philippines", ",", "fled", "the", "Philippines", "for", "Hawaii", ",", "they", "were", "charged", "with", "rack", "##ete", "##ering", ",", "conspiracy", ",", "o", "##bs", "##truction", "of", "justice", "and", "mail", "fraud", "in", "a", "scheme", "in", "which", "they", "allegedly", "em", "##be", "##zzle", "##d", "more", "than", "$", "100", "million", "from", "their", "homeland", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "they", "[unused2]", "[unused3]", "were", "charged", "[unused4]", "[unused5]", "with", "rack", "##ete", "##ering", ",", "conspiracy", ",", "o", "##bs", "##truction", "of", "justice", "and", "mail", "fraud", "in", "a", "scheme", "In", "1988", "a", "year", "and", "a", "half", "after", "Mrs", "##.", "Marcos", "and", "her", "late", "husband", "[unused6]", "[SEP]", "[unused1]", "Ferdinand", "Marcos", "[unused2]", "[unused3]", "fled", "[unused4]", "[unused5]", "the", "Philippines", "for", "Hawaii", "[unused6]", "[SEP]", "[unused1]", "Ferdinand", "Marcos", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "ou", "##sted", "president", "of", "the", "Philippines", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "allegedly", "em", "##be", "##zzle", "##d", "[unused4]", "[unused5]", "more", "than", "$", "100", "million", "from", "their", "homeland", "[unused6]", "[SEP]"]]}

input 484:  {"source": "In Japan , those functions account for only about a third of the software market .\n"}
prediction:  {"predictions": [[1, 1343, 4226, 2, 3, 3300, 4, 5, 1111, 1178, 1164, 170, 1503, 1104, 1103, 3594, 2319, 1130, 1999, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00020399547065608203, -0.017957210540771484, -0.017242908477783203, -0.017242908477783203, -0.017242908477783203, -0.017242908477783203, -0.017242908477783203, -0.017242908477783203, -0.017242908477783203, -0.017242908477783203], "metadata": {"source_tokens": ["In", "Japan", ",", "those", "functions", "account", "for", "only", "about", "a", "third", "of", "the", "software", "market", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "those", "functions", "[unused2]", "[unused3]", "account", "[unused4]", "[unused5]", "for", "only", "about", "a", "third", "of", "the", "software", "market", "In", "Japan", "[unused6]", "[SEP]"]]}

input 485:  {"source": "In recent testimony on Capitol Hill , Treasury officials said they were considering the new reporting requirements , and the expected publication of the proposal in the Federal Register today is the first official step toward creating final regulations .\n"}
prediction:  {"predictions": [[1, 11712, 3878, 2, 3, 1163, 4, 5, 1152, 1127, 6103, 1103, 1207, 7516, 5420, 117, 1105, 1103, 2637, 4128, 1104, 1103, 5835, 1107, 1103, 3467, 4273, 2052, 1110, 1103, 1148, 2078, 2585, 1755, 3780, 1509, 7225, 1130, 2793, 11405, 1113, 9838, 2404, 6, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2637, 4128, 1104, 1103, 5835, 1107, 1103, 3467, 4273, 2, 3, 1110, 4, 5, 1103, 1148, 2078, 2585, 1755, 3780, 1509, 7225, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1127, 6103, 4, 5, 1103, 1207, 7516, 5420, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03929585590958595, -0.024488545954227448, -0.08954048901796341, -0.12471151351928711, -0.12653303146362305, -0.12653303146362305, -0.12653303146362305, -0.12653303146362305, -0.12653303146362305, -0.12653303146362305], "metadata": {"source_tokens": ["In", "recent", "testimony", "on", "Capitol", "Hill", ",", "Treasury", "officials", "said", "they", "were", "considering", "the", "new", "reporting", "requirements", ",", "and", "the", "expected", "publication", "of", "the", "proposal", "in", "the", "Federal", "Register", "today", "is", "the", "first", "official", "step", "toward", "creating", "final", "regulations", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Treasury", "officials", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "they", "were", "considering", "the", "new", "reporting", "requirements", ",", "and", "the", "expected", "publication", "of", "the", "proposal", "in", "the", "Federal", "Register", "today", "is", "the", "first", "official", "step", "toward", "creating", "final", "regulations", "In", "recent", "testimony", "on", "Capitol", "Hill", "[unused6]", "[SEP]", "[unused1]", "the", "expected", "publication", "of", "the", "proposal", "in", "the", "Federal", "Register", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "first", "official", "step", "toward", "creating", "final", "regulations", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "were", "considering", "[unused4]", "[unused5]", "the", "new", "reporting", "requirements", "[unused6]", "[SEP]"]]}

input 486:  {"source": "In the U.S. , more than half the PC software sold is either for spreadsheets or for database analysis , according to Lotus .\n"}
prediction:  {"predictions": [[1, 1167, 1190, 1544, 1103, 7054, 3594, 1962, 2, 3, 1110, 4, 5, 1719, 1111, 23237, 19989, 2145, 1137, 1111, 8539, 3622, 1130, 1103, 158, 28138, 1708, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1167, 1190, 1544, 2, 3, 1962, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017974508926272392, -0.1993863433599472, -0.13750886917114258, -0.13365983963012695, -0.13365983963012695, -0.13365983963012695, -0.13365983963012695, -0.13365983963012695, -0.13365983963012695, -0.13365983963012695], "metadata": {"source_tokens": ["In", "the", "U", "##.", "##S", "##.", ",", "more", "than", "half", "the", "PC", "software", "sold", "is", "either", "for", "spreads", "##hee", "##ts", "or", "for", "database", "analysis", ",", "according", "to", "Lotus", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "more", "than", "half", "the", "PC", "software", "sold", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "either", "for", "spreads", "##hee", "##ts", "or", "for", "database", "analysis", "In", "the", "U", "##.", "##S", "##.", "[unused6]", "[SEP]", "[unused1]", "more", "than", "half", "[unused2]", "[unused3]", "sold", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 487:  {"source": "In the corporate market , an expected debt offering today by International Business Machines Corp. generated considerable attention .\n"}
prediction:  {"predictions": [[1, 1126, 2637, 6695, 4733, 2052, 1118, 1570, 3518, 7792, 1116, 13619, 2, 3, 6455, 4, 5, 5602, 2209, 1130, 1103, 6214, 2319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0012790679465979338, -0.05093860626220703, -0.048987388610839844, -0.048987388610839844, -0.048987388610839844, -0.048987388610839844, -0.048987388610839844, -0.048987388610839844, -0.048987388610839844, -0.048987388610839844], "metadata": {"source_tokens": ["In", "the", "corporate", "market", ",", "an", "expected", "debt", "offering", "today", "by", "International", "Business", "Machine", "##s", "Corp", "##.", "generated", "considerable", "attention", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "an", "expected", "debt", "offering", "today", "by", "International", "Business", "Machine", "##s", "Corp", "[unused2]", "[unused3]", "generated", "[unused4]", "[unused5]", "considerable", "attention", "In", "the", "corporate", "market", "[unused6]", "[SEP]"]]}

input 488:  {"source": "In the first nine months , profit rose 10 % to $ 313.2 million , or $ 3.89 a share , from $ 283.9 million , or $ 3.53 a share .\n"}
prediction:  {"predictions": [[1, 5022, 2, 3, 3152, 4, 5, 1275, 110, 1106, 109, 25620, 28138, 1477, 1550, 1137, 109, 124, 28138, 1604, 1580, 170, 2934, 1121, 109, 1743, 1495, 28138, 1580, 1550, 1137, 109, 124, 28138, 24239, 170, 2934, 1130, 1103, 1148, 2551, 1808, 6, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03669021651148796, -0.2600278854370117, -0.241912841796875, -0.2419114112854004, -0.2419114112854004, -0.2419114112854004, -0.2419114112854004, -0.2419114112854004, -0.2419114112854004, -0.2419114112854004], "metadata": {"source_tokens": ["In", "the", "first", "nine", "months", ",", "profit", "rose", "10", "%", "to", "$", "313", "##.", "##2", "million", ",", "or", "$", "3", "##.", "##8", "##9", "a", "share", ",", "from", "$", "28", "##3", "##.", "##9", "million", ",", "or", "$", "3", "##.", "##53", "a", "share", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "profit", "[unused2]", "[unused3]", "rose", "[unused4]", "[unused5]", "10", "%", "to", "$", "313", "##.", "##2", "million", "or", "$", "3", "##.", "##8", "##9", "a", "share", "from", "$", "28", "##3", "##.", "##9", "million", "or", "$", "3", "##.", "##53", "a", "share", "In", "the", "first", "nine", "months", "[unused6]", "[SEP]"]]}

input 489:  {"source": "Indeed , the insurance adjusters had already bolted out of the courtroom .\n"}
prediction:  {"predictions": [[1, 1103, 5986, 14878, 1468, 2, 3, 1125, 19532, 4, 5, 1149, 1104, 1103, 23699, 1640, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0003086858196184039, -0.023352622985839844, -0.023281097412109375, -0.023281097412109375, -0.023281097412109375, -0.023281097412109375, -0.023281097412109375, -0.023281097412109375, -0.023281097412109375, -0.023281097412109375], "metadata": {"source_tokens": ["Indeed", ",", "the", "insurance", "adjust", "##ers", "had", "already", "bolted", "out", "of", "the", "courtroom", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "insurance", "adjust", "##ers", "[unused2]", "[unused3]", "had", "bolted", "[unused4]", "[unused5]", "out", "of", "the", "courtroom", "already", "[unused6]", "[SEP]"]]}

input 490:  {"source": "Industrial Bank of Japan , which claims to be the biggest Japanese buyer of U.S. mortgage securities , says it will more than double its purchases this year , to an amount one official puts at several billion dollars .\n"}
prediction:  {"predictions": [[1, 7080, 2950, 1104, 1999, 2, 3, 1867, 4, 5, 1122, 1209, 1167, 1190, 2702, 1157, 18908, 1142, 1214, 117, 1106, 1126, 2971, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7080, 2950, 1104, 1999, 2, 3, 3711, 4, 5, 1106, 1129, 1103, 4583, 1983, 20315, 1104, 158, 28138, 1708, 28138, 16935, 19313, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1126, 2971, 2078, 2, 3, 8165, 4, 5, 1120, 1317, 3775, 5860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04511573165655136, -0.059223052114248276, -0.13579218089580536, -0.15918874740600586, -0.15372467041015625, -0.15372467041015625, -0.15372419357299805, -0.15372467041015625, -0.15372467041015625, -0.15372467041015625], "metadata": {"source_tokens": ["Industrial", "Bank", "of", "Japan", ",", "which", "claims", "to", "be", "the", "biggest", "Japanese", "buyer", "of", "U", "##.", "##S", "##.", "mortgage", "securities", ",", "says", "it", "will", "more", "than", "double", "its", "purchases", "this", "year", ",", "to", "an", "amount", "one", "official", "puts", "at", "several", "billion", "dollars", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Industrial", "Bank", "of", "Japan", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "it", "will", "more", "than", "double", "its", "purchases", "this", "year", ",", "to", "an", "amount", "[unused6]", "[SEP]", "[unused1]", "Industrial", "Bank", "of", "Japan", "[unused2]", "[unused3]", "claims", "[unused4]", "[unused5]", "to", "be", "the", "biggest", "Japanese", "buyer", "of", "U", "##.", "##S", "##.", "mortgage", "securities", "[unused6]", "[SEP]", "[unused1]", "an", "amount", "official", "[unused2]", "[unused3]", "puts", "[unused4]", "[unused5]", "at", "several", "billion", "dollars", "[unused6]", "[SEP]"]]}

input 491:  {"source": "It came in London 's `` Big Bang '' 1986 deregulation ; and Toronto 's `` Little Bang '' the same year .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1338, 4, 5, 1107, 1498, 112, 1116, 169, 28152, 2562, 12926, 112, 28131, 2177, 4167, 12606, 6856, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03536650538444519, -0.04985809326171875, -0.049555301666259766, -0.049555301666259766, -0.049555301666259766, -0.049555301666259766, -0.049555301666259766, -0.049555301666259766, -0.049555301666259766, -0.049555301666259766], "metadata": {"source_tokens": ["It", "came", "in", "London", "'", "##s", "`", "##`", "Big", "Bang", "'", "##'", "1986", "der", "##eg", "##ulation", ";", "and", "Toronto", "'", "##s", "`", "##`", "Little", "Bang", "'", "##'", "the", "same", "year", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "in", "London", "'", "##s", "`", "##`", "Big", "Bang", "'", "##'", "1986", "der", "##eg", "##ulation", "[unused6]", "[SEP]"]]}

input 492:  {"source": "It rose 4.8 % for the 12 months ended in June and 4.7 % in the 12 months ended in September 1988 .\n"}
prediction:  {"predictions": [[1, 1103, 1367, 1808, 2, 3, 2207, 4, 5, 1107, 1347, 2115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 3152, 4, 5, 125, 28138, 1604, 110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1367, 1808, 2, 3, 1129, 2207, 4, 5, 1107, 1340, 1105, 125, 28138, 1559, 110, 1107, 1103, 1367, 1808, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017252104356884956, -0.0607588030397892, -0.05902278423309326, -0.01354837417602539, -0.013346195220947266, -0.013346195220947266, -0.013346195220947266, -0.013346195220947266, -0.013346195220947266, -0.013346195220947266], "metadata": {"source_tokens": ["It", "rose", "4", "##.", "##8", "%", "for", "the", "12", "months", "ended", "in", "June", "and", "4", "##.", "##7", "%", "in", "the", "12", "months", "ended", "in", "September", "1988", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "12", "months", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "in", "September", "1988", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "rose", "[unused4]", "[unused5]", "4", "##.", "##8", "%", "[unused6]", "[SEP]", "[unused1]", "the", "12", "months", "[unused2]", "[unused3]", "be", "ended", "[unused4]", "[unused5]", "in", "June", "and", "4", "##.", "##7", "%", "in", "the", "12", "months", "[unused6]", "[SEP]"]]}

input 493:  {"source": "It said CS First Boston `` has consistently been one of the most aggressive firms in merchant banking '' and that `` a very significant portion '' of the firm 's profit in recent years has come from merchant banking - related business .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1163, 4, 5, 24821, 1752, 2859, 169, 28152, 1144, 10887, 1151, 1141, 1104, 1103, 1211, 9233, 9780, 1107, 6800, 9339, 112, 28131, 1105, 1115, 169, 28152, 170, 1304, 2418, 3849, 112, 28131, 1104, 1103, 3016, 112, 1116, 5022, 1107, 2793, 1201, 1144, 1435, 1121, 6800, 9339, 102, 1, 24821, 1752, 2859, 2, 3, 1144, 10887, 1151, 4, 5, 1141, 1104, 1103, 1211, 9233, 9780, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012514173053205013, -0.08954610675573349, -0.2550239562988281, -0.27218151092529297, -0.27218151092529297, -0.27218151092529297, -0.27218151092529297, -0.27218151092529297, -0.27218151092529297, -0.27218151092529297], "metadata": {"source_tokens": ["It", "said", "CS", "First", "Boston", "`", "##`", "has", "consistently", "been", "one", "of", "the", "most", "aggressive", "firms", "in", "merchant", "banking", "'", "##'", "and", "that", "`", "##`", "a", "very", "significant", "portion", "'", "##'", "of", "the", "firm", "'", "##s", "profit", "in", "recent", "years", "has", "come", "from", "merchant", "banking", "-", "related", "business", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "CS", "First", "Boston", "`", "##`", "has", "consistently", "been", "one", "of", "the", "most", "aggressive", "firms", "in", "merchant", "banking", "'", "##'", "and", "that", "`", "##`", "a", "very", "significant", "portion", "'", "##'", "of", "the", "firm", "'", "##s", "profit", "in", "recent", "years", "has", "come", "from", "merchant", "banking", "[SEP]", "[unused1]", "CS", "First", "Boston", "[unused2]", "[unused3]", "has", "consistently", "been", "[unused4]", "[unused5]", "one", "of", "the", "most", "aggressive", "firms", "[unused6]", "[SEP]"]]}

input 494:  {"source": "It surged 2 3\\/4 to 6 on volume of more than 1.7 million shares after the company agreed to be acquired by Japan 's Chugai Pharmaceutical for about $ 110 million -- almost double the market price of Gen - Probe 's stock .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 20420, 4, 5, 123, 124, 28148, 28139, 1527, 1106, 127, 1113, 3884, 1104, 1167, 1190, 122, 28138, 1559, 1550, 6117, 1170, 1103, 1419, 2675, 1106, 1129, 2888, 1118, 1999, 112, 1116, 17144, 21347, 7642, 24275, 2093, 19748, 1111, 1164, 109, 6745, 1550, 1593, 2702, 1103, 2319, 102, 1, 1103, 1419, 2, 3, 2675, 4, 5, 1106, 1129, 2888, 1118, 1999, 112, 1116, 17144, 21347, 7642, 24275, 2093, 19748, 1111, 1164, 109, 6745, 1550, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.024894198402762413, -0.05041918531060219, -0.13376379013061523, -0.12841320037841797, -0.12841320037841797, -0.12841320037841797, -0.12841320037841797, -0.12841320037841797, -0.12841320037841797, -0.12841320037841797], "metadata": {"source_tokens": ["It", "surged", "2", "3", "##\\", "##/", "##4", "to", "6", "on", "volume", "of", "more", "than", "1", "##.", "##7", "million", "shares", "after", "the", "company", "agreed", "to", "be", "acquired", "by", "Japan", "'", "##s", "Chu", "##gai", "Ph", "##arma", "##ce", "##utical", "for", "about", "$", "110", "million", "-", "##-", "almost", "double", "the", "market", "price", "of", "Gen", "-", "Pro", "##be", "'", "##s", "stock", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "surged", "[unused4]", "[unused5]", "2", "3", "##\\", "##/", "##4", "to", "6", "on", "volume", "of", "more", "than", "1", "##.", "##7", "million", "shares", "after", "the", "company", "agreed", "to", "be", "acquired", "by", "Japan", "'", "##s", "Chu", "##gai", "Ph", "##arma", "##ce", "##utical", "for", "about", "$", "110", "million", "almost", "double", "the", "market", "[SEP]", "[unused1]", "the", "company", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "be", "acquired", "by", "Japan", "'", "##s", "Chu", "##gai", "Ph", "##arma", "##ce", "##utical", "for", "about", "$", "110", "million", "[unused6]", "[SEP]"]]}

input 495:  {"source": "It was the most active of the 100 - share index at 8.3 million shares , 6.5 million of which were traded by midday .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1108, 4, 5, 1103, 1211, 2327, 1104, 1103, 1620, 118, 2934, 7448, 1120, 129, 28138, 1495, 1550, 6117, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 127, 28138, 1571, 1550, 1104, 1134, 2, 3, 1127, 6537, 4, 5, 1118, 2286, 6194, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00818671379238367, -0.026471443474292755, -0.016761302947998047, -0.01641559600830078, -0.01641559600830078, -0.01641559600830078, -0.01641559600830078, -0.01641559600830078, -0.01641559600830078, -0.01641559600830078], "metadata": {"source_tokens": ["It", "was", "the", "most", "active", "of", "the", "100", "-", "share", "index", "at", "8", "##.", "##3", "million", "shares", ",", "6", "##.", "##5", "million", "of", "which", "were", "traded", "by", "mid", "##day", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "most", "active", "of", "the", "100", "-", "share", "index", "at", "8", "##.", "##3", "million", "shares", "[unused6]", "[SEP]", "[unused1]", "6", "##.", "##5", "million", "of", "which", "[unused2]", "[unused3]", "were", "traded", "[unused4]", "[unused5]", "by", "mid", "##day", "[unused6]", "[SEP]"]]}

input 496:  {"source": "Jaguar 's own defenses against a hostile bid are weakened , analysts add , because fewer than 3 % of its shares are owned by employees and management .\n"}
prediction:  {"predictions": [[1, 21694, 112, 1116, 1319, 14192, 1222, 170, 10518, 6875, 2, 3, 1132, 12041, 4, 5, 1272, 8307, 1190, 124, 110, 1104, 1157, 6117, 1132, 2205, 1118, 4570, 1105, 2635, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 22018, 2, 3, 5194, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02393478900194168, -0.025842878967523575, -0.0880436897277832, -0.08857345581054688, -0.08857345581054688, -0.08857345581054688, -0.08857345581054688, -0.08857345581054688, -0.08857345581054688, -0.08857345581054688], "metadata": {"source_tokens": ["Jaguar", "'", "##s", "own", "defenses", "against", "a", "hostile", "bid", "are", "weakened", ",", "analysts", "add", ",", "because", "fewer", "than", "3", "%", "of", "its", "shares", "are", "owned", "by", "employees", "and", "management", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Jaguar", "'", "##s", "own", "defenses", "against", "a", "hostile", "bid", "[unused2]", "[unused3]", "are", "weakened", "[unused4]", "[unused5]", "because", "fewer", "than", "3", "%", "of", "its", "shares", "are", "owned", "by", "employees", "and", "management", "[unused6]", "[SEP]", "[unused1]", "analysts", "[unused2]", "[unused3]", "add", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 497:  {"source": "Japanese office workers use PCs at half the rate of their European counterparts and one - third that of the Americans .\n"}
prediction:  {"predictions": [[1, 1983, 1701, 3239, 2, 3, 1329, 4, 5, 7054, 1116, 1120, 1544, 1103, 2603, 1104, 1147, 1735, 15289, 1105, 1141, 118, 1503, 1115, 1104, 1103, 4038, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0006415926036424935, -0.03524446487426758, -0.0354461669921875, -0.0354461669921875, -0.0354461669921875, -0.0354461669921875, -0.0354461669921875, -0.0354466438293457, -0.0354461669921875, -0.0354461669921875], "metadata": {"source_tokens": ["Japanese", "office", "workers", "use", "PC", "##s", "at", "half", "the", "rate", "of", "their", "European", "counterparts", "and", "one", "-", "third", "that", "of", "the", "Americans", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Japanese", "office", "workers", "[unused2]", "[unused3]", "use", "[unused4]", "[unused5]", "PC", "##s", "at", "half", "the", "rate", "of", "their", "European", "counterparts", "and", "one", "-", "third", "that", "of", "the", "Americans", "[unused6]", "[SEP]"]]}

input 498:  {"source": "Keeping the Japanese happy will be one of the most important tasks facing conservative leader Ernesto Ruffo when he takes office Nov. 1 , as the first opposition governor in Mexico 's modern history .\n"}
prediction:  {"predictions": [[1, 22049, 1103, 1983, 2816, 2, 3, 1209, 1129, 4, 5, 1141, 1104, 1103, 1211, 1696, 8249, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1211, 1696, 8249, 2, 3, 4749, 4, 5, 6588, 2301, 24918, 155, 9435, 1186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 2274, 4, 5, 1701, 14152, 28138, 122, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04691893234848976, -0.040624212473630905, -0.0775594711303711, -0.23619365692138672, -0.2394266128540039, -0.2394266128540039, -0.2394266128540039, -0.2394266128540039, -0.2394266128540039, -0.2394266128540039], "metadata": {"source_tokens": ["Keeping", "the", "Japanese", "happy", "will", "be", "one", "of", "the", "most", "important", "tasks", "facing", "conservative", "leader", "Ernesto", "R", "##uff", "##o", "when", "he", "takes", "office", "Nov", "##.", "1", ",", "as", "the", "first", "opposition", "governor", "in", "Mexico", "'", "##s", "modern", "history", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Keeping", "the", "Japanese", "happy", "[unused2]", "[unused3]", "will", "be", "[unused4]", "[unused5]", "one", "of", "the", "most", "important", "tasks", "[unused6]", "[SEP]", "[unused1]", "the", "most", "important", "tasks", "[unused2]", "[unused3]", "facing", "[unused4]", "[unused5]", "conservative", "leader", "Ernesto", "R", "##uff", "##o", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "takes", "[unused4]", "[unused5]", "office", "Nov", "##.", "1", "[unused6]", "[SEP]"]]}

input 499:  {"source": "Labor costs are climbing at a far more rapid pace in the health care industry than in other industries .\n"}
prediction:  {"predictions": [[1, 6314, 4692, 2, 3, 1132, 8259, 4, 5, 1120, 170, 1677, 1167, 6099, 6418, 1107, 1103, 2332, 1920, 2380, 1190, 1107, 1168, 7519, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0005426223506219685, -0.022379398345947266, -0.024274826049804688, -0.024274826049804688, -0.024274826049804688, -0.024274826049804688, -0.024274826049804688, -0.024274826049804688, -0.024274826049804688, -0.024274826049804688], "metadata": {"source_tokens": ["Labor", "costs", "are", "climbing", "at", "a", "far", "more", "rapid", "pace", "in", "the", "health", "care", "industry", "than", "in", "other", "industries", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Labor", "costs", "[unused2]", "[unused3]", "are", "climbing", "[unused4]", "[unused5]", "at", "a", "far", "more", "rapid", "pace", "in", "the", "health", "care", "industry", "than", "in", "other", "industries", "[unused6]", "[SEP]"]]}

input 500:  {"source": "Meanwhile , at home , Mitsubishi has control of some major projects .\n"}
prediction:  {"predictions": [[1, 21450, 2, 3, 1144, 4, 5, 1654, 1104, 1199, 1558, 3203, 5459, 1120, 1313, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027157433331012726, -0.024945735931396484, -0.023612022399902344, -0.023612022399902344, -0.023612022399902344, -0.023612022399902344, -0.023612022399902344, -0.023612022399902344, -0.023612022399902344, -0.023612022399902344], "metadata": {"source_tokens": ["Meanwhile", ",", "at", "home", ",", "Mitsubishi", "has", "control", "of", "some", "major", "projects", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mitsubishi", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "control", "of", "some", "major", "projects", "Meanwhile", "at", "home", "[unused6]", "[SEP]"]]}

input 501:  {"source": "Medical cooperatives , among the most successful in the U.S.S.R. , are banned from providing general - practitioner services ( their main source of income ) , carrying out surgery , and treating cancer patients , drug addicts and pregnant women .\n"}
prediction:  {"predictions": [[1, 3875, 14561, 1116, 2, 3, 1132, 7548, 4, 5, 1121, 3558, 1704, 118, 22351, 1826, 1621, 1103, 1211, 2265, 1107, 1103, 158, 28138, 1708, 28138, 1708, 28138, 2069, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3875, 14561, 1116, 2, 3, 1121, 3558, 4, 5, 1704, 118, 22351, 1826, 113, 1147, 1514, 2674, 1104, 2467, 114, 117, 4004, 1149, 6059, 117, 1105, 12770, 4182, 4420, 117, 3850, 5194, 17882, 1116, 1105, 6391, 1535, 6, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.061041127890348434, -0.07684828341007233, -0.05432701110839844, -0.054050445556640625, -0.054050445556640625, -0.054050445556640625, -0.054050445556640625, -0.054050445556640625, -0.054050445556640625, -0.054050445556640625], "metadata": {"source_tokens": ["Medical", "cooperative", "##s", ",", "among", "the", "most", "successful", "in", "the", "U", "##.", "##S", "##.", "##S", "##.", "##R", "##.", ",", "are", "banned", "from", "providing", "general", "-", "practitioner", "services", "(", "their", "main", "source", "of", "income", ")", ",", "carrying", "out", "surgery", ",", "and", "treating", "cancer", "patients", ",", "drug", "add", "##ict", "##s", "and", "pregnant", "women", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Medical", "cooperative", "##s", "[unused2]", "[unused3]", "are", "banned", "[unused4]", "[unused5]", "from", "providing", "general", "-", "practitioner", "services", "among", "the", "most", "successful", "in", "the", "U", "##.", "##S", "##.", "##S", "##.", "##R", "##.", "[unused6]", "[SEP]", "[unused1]", "Medical", "cooperative", "##s", "[unused2]", "[unused3]", "from", "providing", "[unused4]", "[unused5]", "general", "-", "practitioner", "services", "(", "their", "main", "source", "of", "income", ")", ",", "carrying", "out", "surgery", ",", "and", "treating", "cancer", "patients", ",", "drug", "add", "##ict", "##s", "and", "pregnant", "women", "[unused6]", "[SEP]"]]}

input 502:  {"source": "Merrill said it continues to believe that `` the causes of excess market volatility are far more complex than any particular computer trading strategy .\n"}
prediction:  {"predictions": [[1, 17247, 2, 3, 1163, 4, 5, 1122, 3430, 1106, 2059, 1115, 169, 28152, 1103, 4680, 1104, 10116, 2319, 10857, 11745, 11796, 1132, 1677, 1167, 2703, 1190, 1251, 2440, 2775, 6157, 5564, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4680, 1104, 10116, 2319, 10857, 11745, 11796, 2, 3, 1132, 4, 5, 1677, 1167, 2703, 1190, 1251, 2440, 2775, 6157, 5564, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005280214361846447, -0.040002334862947464, -0.06981086730957031, -0.06879615783691406, -0.06879615783691406, -0.06879615783691406, -0.06879615783691406, -0.06879615783691406, -0.06879615783691406, -0.06879615783691406], "metadata": {"source_tokens": ["Merrill", "said", "it", "continues", "to", "believe", "that", "`", "##`", "the", "causes", "of", "excess", "market", "vol", "##ati", "##lity", "are", "far", "more", "complex", "than", "any", "particular", "computer", "trading", "strategy", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Merrill", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "continues", "to", "believe", "that", "`", "##`", "the", "causes", "of", "excess", "market", "vol", "##ati", "##lity", "are", "far", "more", "complex", "than", "any", "particular", "computer", "trading", "strategy", "[unused6]", "[SEP]", "[unused1]", "the", "causes", "of", "excess", "market", "vol", "##ati", "##lity", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "far", "more", "complex", "than", "any", "particular", "computer", "trading", "strategy", "[unused6]", "[SEP]"]]}

input 503:  {"source": "Metromedia , headed by John W. Kluge , has interests in telecommunications , robotic painting , computer software , restaurants and entertainment .\n"}
prediction:  {"predictions": [[1, 6431, 16418, 2, 3, 2917, 4, 5, 1118, 1287, 160, 28138, 148, 16693, 1162, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6431, 16418, 2, 3, 1144, 4, 5, 4740, 1107, 17955, 117, 24628, 3504, 117, 2775, 3594, 117, 7724, 1105, 5936, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0006158492178656161, -0.0486375093460083, -0.00904226303100586, -0.009009361267089844, -0.009009361267089844, -0.009009361267089844, -0.009009361267089844, -0.009009361267089844, -0.009009361267089844, -0.009009361267089844], "metadata": {"source_tokens": ["Metro", "##media", ",", "headed", "by", "John", "W", "##.", "K", "##lug", "##e", ",", "has", "interests", "in", "telecommunications", ",", "robotic", "painting", ",", "computer", "software", ",", "restaurants", "and", "entertainment", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Metro", "##media", "[unused2]", "[unused3]", "headed", "[unused4]", "[unused5]", "by", "John", "W", "##.", "K", "##lug", "##e", "[unused6]", "[SEP]", "[unused1]", "Metro", "##media", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "interests", "in", "telecommunications", ",", "robotic", "painting", ",", "computer", "software", ",", "restaurants", "and", "entertainment", "[unused6]", "[SEP]"]]}

input 504:  {"source": "Milk sold to the nation 's dairy plants and dealers averaged $ 14.50 for each hundred pounds , up 50 cents from September and up $ 1.50 from October 1988 , the department said .\n"}
prediction:  {"predictions": [[1, 18165, 1962, 1106, 1103, 3790, 112, 1116, 14874, 3546, 1105, 19499, 2, 3, 11445, 4, 5, 109, 1489, 28138, 11049, 1111, 1296, 2937, 6549, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2853, 2, 3, 1163, 4, 5, 1103, 2853, 1163, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 18165, 2, 3, 1962, 4, 5, 1106, 1103, 3790, 112, 1116, 14874, 3546, 1105, 19499, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05963936820626259, -0.1529029756784439, -0.06761934608221054, -0.057611942291259766, -0.05661487579345703, -0.05661487579345703, -0.05661487579345703, -0.05661487579345703, -0.05661487579345703, -0.05661487579345703], "metadata": {"source_tokens": ["Milk", "sold", "to", "the", "nation", "'", "##s", "dairy", "plants", "and", "dealers", "averaged", "$", "14", "##.", "##50", "for", "each", "hundred", "pounds", ",", "up", "50", "cents", "from", "September", "and", "up", "$", "1", "##.", "##50", "from", "October", "1988", ",", "the", "department", "said", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Milk", "sold", "to", "the", "nation", "'", "##s", "dairy", "plants", "and", "dealers", "[unused2]", "[unused3]", "averaged", "[unused4]", "[unused5]", "$", "14", "##.", "##50", "for", "each", "hundred", "pounds", "[unused6]", "[SEP]", "[unused1]", "the", "department", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "department", "said", "[unused6]", "[SEP]", "[unused1]", "Milk", "[unused2]", "[unused3]", "sold", "[unused4]", "[unused5]", "to", "the", "nation", "'", "##s", "dairy", "plants", "and", "dealers", "[unused6]", "[SEP]"]]}

input 505:  {"source": "Most yields on short - term jumbo CDs , those with denominations over $ 90,000 , also moved in the opposite direction of Treasury bill yields .\n"}
prediction:  {"predictions": [[1, 2082, 17376, 1113, 1603, 118, 1858, 179, 1818, 4043, 16881, 2, 3, 1427, 4, 5, 1107, 1103, 3714, 2447, 1104, 11712, 4550, 17376, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03315345197916031, -0.28725385665893555, -0.2708005905151367, -0.2708005905151367, -0.2708005905151367, -0.2708005905151367, -0.2708005905151367, -0.2708005905151367, -0.2708005905151367, -0.2708005905151367], "metadata": {"source_tokens": ["Most", "yields", "on", "short", "-", "term", "j", "##um", "##bo", "CDs", ",", "those", "with", "denominations", "over", "$", "90", "##,", "##00", "##0", ",", "also", "moved", "in", "the", "opposite", "direction", "of", "Treasury", "bill", "yields", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Most", "yields", "on", "short", "-", "term", "j", "##um", "##bo", "CDs", "[unused2]", "[unused3]", "moved", "[unused4]", "[unused5]", "in", "the", "opposite", "direction", "of", "Treasury", "bill", "yields", "[unused6]", "[SEP]"]]}

input 506:  {"source": "Mr. Guber and Mr. Peters also almost certainly would n't be able to participate in future sequels to `` Batman , '' the blockbuster hit they produced for Warner .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 144, 15209, 1197, 1105, 1828, 28138, 12648, 2, 3, 1156, 183, 28131, 1204, 1129, 4, 5, 1682, 1106, 4868, 1107, 2174, 8047, 1116, 1106, 169, 28152, 8622, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3510, 27338, 2, 3, 1855, 4, 5, 1152, 1666, 1111, 6049, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03483542054891586, -0.0910039022564888, -0.05330228805541992, -0.05259513854980469, -0.05259513854980469, -0.05259513854980469, -0.05259513854980469, -0.05259513854980469, -0.05259513854980469, -0.05259513854980469], "metadata": {"source_tokens": ["Mr", "##.", "G", "##ube", "##r", "and", "Mr", "##.", "Peters", "also", "almost", "certainly", "would", "n", "##'", "##t", "be", "able", "to", "participate", "in", "future", "sequel", "##s", "to", "`", "##`", "Batman", ",", "'", "##'", "the", "block", "##buster", "hit", "they", "produced", "for", "Warner", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "G", "##ube", "##r", "and", "Mr", "##.", "Peters", "[unused2]", "[unused3]", "would", "n", "##'", "##t", "be", "[unused4]", "[unused5]", "able", "to", "participate", "in", "future", "sequel", "##s", "to", "`", "##`", "Batman", "[unused6]", "[SEP]", "[unused1]", "the", "block", "##buster", "[unused2]", "[unused3]", "hit", "[unused4]", "[unused5]", "they", "produced", "for", "Warner", "[unused6]", "[SEP]"]]}

input 507:  {"source": "Mr. Mulford said reports of tension between the Treasury and Fed have been exaggerated , insisting that they involved `` nuances . ''\n"}
prediction:  {"predictions": [[1, 1828, 28138, 19569, 9654, 6944, 2, 3, 1163, 4, 5, 3756, 1104, 6646, 1206, 1103, 11712, 1105, 26356, 1138, 1151, 18088, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3756, 1104, 6646, 1206, 1103, 11712, 1105, 26356, 2, 3, 1138, 1151, 18088, 25504, 4, 5, 1115, 1152, 2017, 169, 28152, 183, 8734, 7723, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.036301691085100174, -0.10263527929782867, -0.04665327072143555, -0.04715871810913086, -0.04715871810913086, -0.04715871810913086, -0.04715871810913086, -0.04715871810913086, -0.04715871810913086, -0.04715871810913086], "metadata": {"source_tokens": ["Mr", "##.", "Mu", "##lf", "##ord", "said", "reports", "of", "tension", "between", "the", "Treasury", "and", "Fed", "have", "been", "exaggerated", ",", "insisting", "that", "they", "involved", "`", "##`", "n", "##uan", "##ces", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Mu", "##lf", "##ord", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "reports", "of", "tension", "between", "the", "Treasury", "and", "Fed", "have", "been", "exaggerated", "[unused6]", "[SEP]", "[unused1]", "reports", "of", "tension", "between", "the", "Treasury", "and", "Fed", "[unused2]", "[unused3]", "have", "been", "exaggerated", "insisting", "[unused4]", "[unused5]", "that", "they", "involved", "`", "##`", "n", "##uan", "##ces", "[unused6]", "[SEP]"]]}

input 508:  {"source": "Mr. Phelan is an adroit diplomat who normally appears to be solidly in control of the Big Board 's factions .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 7642, 9945, 1179, 2, 3, 1110, 4, 5, 1126, 8050, 21418, 1204, 11608, 1150, 5156, 2691, 1106, 1129, 4600, 1193, 1107, 1654, 1104, 1103, 2562, 2464, 112, 1116, 14468, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1126, 8050, 21418, 1204, 11608, 2, 3, 1129, 4, 5, 4600, 1193, 1107, 1654, 1104, 1103, 2562, 2464, 112, 1116, 14468, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0003726973372977227, -0.052245598286390305, -0.1185312271118164, -0.11597251892089844, -0.11597204208374023, -0.11597251892089844, -0.11597251892089844, -0.11597251892089844, -0.11597251892089844, -0.11597204208374023], "metadata": {"source_tokens": ["Mr", "##.", "Ph", "##ela", "##n", "is", "an", "ad", "##roi", "##t", "diplomat", "who", "normally", "appears", "to", "be", "solid", "##ly", "in", "control", "of", "the", "Big", "Board", "'", "##s", "factions", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Ph", "##ela", "##n", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "ad", "##roi", "##t", "diplomat", "who", "normally", "appears", "to", "be", "solid", "##ly", "in", "control", "of", "the", "Big", "Board", "'", "##s", "factions", "[unused6]", "[SEP]", "[unused1]", "an", "ad", "##roi", "##t", "diplomat", "[unused2]", "[unused3]", "be", "[unused4]", "[unused5]", "solid", "##ly", "in", "control", "of", "the", "Big", "Board", "'", "##s", "factions", "[unused6]", "[SEP]"]]}

input 509:  {"source": "Mr. Ridley 's decision fires the starting pistol for perhaps a costly contest between the world 's auto giants for Britain 's leading luxury - car maker .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 23013, 112, 1116, 2383, 2, 3, 8966, 4, 5, 1103, 2547, 8951, 1111, 3229, 170, 18372, 5235, 1206, 1103, 1362, 112, 1116, 12365, 21170, 1111, 2855, 112, 1116, 2020, 9886, 118, 1610, 11166, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0003962987393606454, -0.03741312026977539, -0.038422584533691406, -0.038422584533691406, -0.038422584533691406, -0.038422584533691406, -0.038422584533691406, -0.038422584533691406, -0.038422584533691406, -0.038422584533691406], "metadata": {"source_tokens": ["Mr", "##.", "Ridley", "'", "##s", "decision", "fires", "the", "starting", "pistol", "for", "perhaps", "a", "costly", "contest", "between", "the", "world", "'", "##s", "auto", "giants", "for", "Britain", "'", "##s", "leading", "luxury", "-", "car", "maker", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Ridley", "'", "##s", "decision", "[unused2]", "[unused3]", "fires", "[unused4]", "[unused5]", "the", "starting", "pistol", "for", "perhaps", "a", "costly", "contest", "between", "the", "world", "'", "##s", "auto", "giants", "for", "Britain", "'", "##s", "leading", "luxury", "-", "car", "maker", "[unused6]", "[SEP]"]]}

input 510:  {"source": "Mr. Rifenburgh said the board still has n't acted on most of the internal report 's recommendations , pending restatement of the balance sheet .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 155, 24603, 16050, 1324, 2, 3, 1163, 4, 5, 1103, 2313, 1253, 1144, 183, 28131, 1204, 5376, 1113, 1211, 1104, 1103, 4422, 2592, 112, 1116, 11859, 117, 15498, 1832, 2193, 1880, 1104, 1103, 5233, 6837, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2313, 2, 3, 1144, 183, 28131, 1204, 5376, 4, 5, 1113, 1211, 1104, 1103, 4422, 2592, 112, 1116, 11859, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009349465370178223, -0.048920031636953354, -0.1544966697692871, -0.15322160720825195, -0.15322160720825195, -0.15322160720825195, -0.15322160720825195, -0.15322160720825195, -0.15322160720825195, -0.15322160720825195], "metadata": {"source_tokens": ["Mr", "##.", "R", "##ife", "##nburg", "##h", "said", "the", "board", "still", "has", "n", "##'", "##t", "acted", "on", "most", "of", "the", "internal", "report", "'", "##s", "recommendations", ",", "pending", "rest", "##ate", "##ment", "of", "the", "balance", "sheet", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "R", "##ife", "##nburg", "##h", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "board", "still", "has", "n", "##'", "##t", "acted", "on", "most", "of", "the", "internal", "report", "'", "##s", "recommendations", ",", "pending", "rest", "##ate", "##ment", "of", "the", "balance", "sheet", "[unused6]", "[SEP]", "[unused1]", "the", "board", "[unused2]", "[unused3]", "has", "n", "##'", "##t", "acted", "[unused4]", "[unused5]", "on", "most", "of", "the", "internal", "report", "'", "##s", "recommendations", "[unused6]", "[SEP]"]]}

input 511:  {"source": "Mr. Stoll suspected the intruder was one of those precocious students who has fun breaking into computers .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 1457, 12666, 2, 3, 6321, 4, 5, 1103, 1107, 24993, 1108, 1141, 1104, 1343, 3073, 2528, 9589, 1651, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1343, 3073, 2528, 9589, 1651, 2, 3, 1129, 1144, 4, 5, 4106, 4440, 4440, 1154, 7565, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027074337005615234, -0.1368357539176941, -0.17842388153076172, -0.1741347312927246, -0.1741347312927246, -0.1741347312927246, -0.1741347312927246, -0.1741347312927246, -0.1741347312927246, -0.1741347312927246], "metadata": {"source_tokens": ["Mr", "##.", "St", "##oll", "suspected", "the", "in", "##truder", "was", "one", "of", "those", "pre", "##co", "##cious", "students", "who", "has", "fun", "breaking", "into", "computers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "St", "##oll", "[unused2]", "[unused3]", "suspected", "[unused4]", "[unused5]", "the", "in", "##truder", "was", "one", "of", "those", "pre", "##co", "##cious", "students", "[unused6]", "[SEP]", "[unused1]", "those", "pre", "##co", "##cious", "students", "[unused2]", "[unused3]", "be", "has", "[unused4]", "[unused5]", "fun", "breaking", "breaking", "into", "computers", "[unused6]", "[SEP]"]]}

Batch 4 Test Time =  36.71576476097107  s
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.03647446632385254
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.03646731376647949
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.0364377498626709
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.036502838134765625
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.03654885292053223
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.03649330139160156
Decodertime : 0.0001373291015625
g_f_logprobs : 0.03663897514343262
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.03680920600891113
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.03657841682434082
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.03652071952819824
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.03654050827026367
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.036530256271362305
Decodertime : 0.0001373291015625
g_f_logprobs : 0.03654360771179199
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.036538124084472656
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.03655719757080078
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.03653597831726074
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.03650641441345215
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.0365145206451416
Decodertime : 0.0001373291015625
g_f_logprobs : 0.036607980728149414
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.036524295806884766
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.03658628463745117
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.036545753479003906
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.0365293025970459
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.03657221794128418
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.03679943084716797
Decodertime : 0.00014400482177734375
g_f_logprobs : 0.036627769470214844
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.03658127784729004
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.036666154861450195
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.03664541244506836
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.03659987449645996
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.036595821380615234
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.036722660064697266
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.036649227142333984
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.03665494918823242
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.0365900993347168
Decodertime : 0.00013971328735351562
g_f_logprobs : 0.03664827346801758
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.0365748405456543
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.03664064407348633
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.03665328025817871
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.03664588928222656
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.036551713943481445
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.03660774230957031
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.03657817840576172
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.036582231521606445
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.03658699989318848
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.03660702705383301
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.03661370277404785
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.03663444519042969
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.036615610122680664
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.03658699989318848
beam_search_time: 1.9023900032043457 s
Decodertime : 0.00014138221740722656
g_f_logprobs : 0.06234598159790039
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.062250375747680664
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.06231212615966797
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.062219858169555664
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.0623631477355957
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.06222891807556152
Decodertime : 0.0001404285430908203
g_f_logprobs : 0.06215214729309082
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.06222367286682129
Decodertime : 0.0001392364501953125
g_f_logprobs : 0.06232953071594238
Decodertime : 0.00014162063598632812
g_f_logprobs : 0.062129974365234375
Decodertime : 0.00014066696166992188
g_f_logprobs : 0.06229233741760254
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.06236100196838379
Decodertime : 0.000141143798828125
g_f_logprobs : 0.062270164489746094
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.06229758262634277
Decodertime : 0.00014090538024902344
g_f_logprobs : 0.06235861778259277
Decodertime : 0.0001430511474609375
g_f_logprobs : 0.06249499320983887
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.062319278717041016
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.062305450439453125
Decodertime : 0.0001373291015625
g_f_logprobs : 0.06243610382080078
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.06214714050292969
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.0622560977935791
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.062282562255859375
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.06223440170288086
Decodertime : 0.0001373291015625
g_f_logprobs : 0.062303781509399414
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.0623621940612793
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.062374114990234375
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.06232738494873047
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.06239151954650879
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.06219339370727539
Decodertime : 0.0001373291015625
g_f_logprobs : 0.06225895881652832
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.06236433982849121
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.06258606910705566
Decodertime : 0.0001373291015625
g_f_logprobs : 0.06260347366333008
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.06222701072692871
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.06218314170837402
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.06215167045593262
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.06230735778808594
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.06243705749511719
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.06236982345581055
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.06226825714111328
Decodertime : 0.0001373291015625
g_f_logprobs : 0.062337398529052734
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.06228208541870117
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.0624234676361084
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.062369346618652344
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.06222796440124512
Decodertime : 0.0001373291015625
g_f_logprobs : 0.06241774559020996
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.06250452995300293
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.06224775314331055
Decodertime : 0.0001373291015625
g_f_logprobs : 0.06240510940551758
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.06230926513671875
beam_search_time: 3.1895148754119873 s
Decodertime : 0.00013971328735351562
g_f_logprobs : 0.08973813056945801
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.08875393867492676
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.08878326416015625
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.08901309967041016
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.08880805969238281
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.08881974220275879
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.08895111083984375
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.08905434608459473
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.08903074264526367
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.08875799179077148
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.08886456489562988
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.08913707733154297
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.08884072303771973
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.08886361122131348
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.08911442756652832
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.08882927894592285
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.08870625495910645
Decodertime : 0.0001373291015625
g_f_logprobs : 0.08891129493713379
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.08894586563110352
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.08909797668457031
Decodertime : 0.0001373291015625
g_f_logprobs : 0.08899402618408203
Decodertime : 0.0001373291015625
g_f_logprobs : 0.08885478973388672
Decodertime : 0.0001373291015625
g_f_logprobs : 0.08893942832946777
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.08899331092834473
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.08888626098632812
Decodertime : 0.0001373291015625
g_f_logprobs : 0.08935999870300293
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.08939695358276367
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.08881998062133789
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.0888974666595459
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.08905863761901855
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.08894920349121094
beam_search_time: 2.8046698570251465 s
Decodertime : 0.0001423358917236328
g_f_logprobs : 0.10055828094482422
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.09991741180419922
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.09999227523803711
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.09992551803588867
Decodertime : 0.0001392364501953125
g_f_logprobs : 0.09982562065124512
Decodertime : 0.0001373291015625
g_f_logprobs : 0.0998985767364502
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.09985518455505371
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.10007739067077637
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.09986639022827148
Decodertime : 0.000141143798828125
g_f_logprobs : 0.10021758079528809
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.09987068176269531
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.10002350807189941
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.09988069534301758
Decodertime : 0.0001399517059326172
g_f_logprobs : 0.09984874725341797
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.10010266304016113
Decodertime : 0.00014066696166992188
g_f_logprobs : 0.10007524490356445
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.1001427173614502
Decodertime : 0.000148773193359375
g_f_logprobs : 0.10007715225219727
Decodertime : 0.00014066696166992188
g_f_logprobs : 0.09995198249816895
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.10022783279418945
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.1000208854675293
Decodertime : 0.00014138221740722656
g_f_logprobs : 0.10016584396362305
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.09979581832885742
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.09995198249816895
Decodertime : 0.0001373291015625
g_f_logprobs : 0.09981942176818848
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.09982109069824219
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.1000359058380127
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.10005784034729004
Decodertime : 0.0001437664031982422
g_f_logprobs : 0.10007476806640625
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.10040807723999023
Decodertime : 0.0001373291015625
g_f_logprobs : 0.09991765022277832
Decodertime : 0.0001373291015625
g_f_logprobs : 0.1000204086303711
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.09983038902282715
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.09995794296264648
Decodertime : 0.00013589859008789062
g_f_logprobs : 0.10000061988830566
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.10015416145324707
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.09995841979980469
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.1001734733581543
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.1001119613647461
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.10002279281616211
beam_search_time: 4.061437129974365 s
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.11315321922302246
Decodertime : 0.00013589859008789062
g_f_logprobs : 0.11224198341369629
Decodertime : 0.0001373291015625
g_f_logprobs : 0.11272025108337402
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.11227536201477051
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.11236047744750977
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.11249160766601562
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.11256694793701172
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.11260724067687988
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.11236262321472168
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.11257243156433105
Decodertime : 0.00013589859008789062
g_f_logprobs : 0.11238598823547363
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.11254239082336426
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.11238956451416016
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.11237072944641113
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.11226201057434082
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.11229252815246582
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.11246228218078613
Decodertime : 0.00013589859008789062
g_f_logprobs : 0.11269927024841309
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.11230039596557617
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.11261320114135742
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.11255884170532227
Decodertime : 0.0001373291015625
g_f_logprobs : 0.11236691474914551
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.11214184761047363
Decodertime : 0.00013589859008789062
g_f_logprobs : 0.11247825622558594
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.11243510246276855
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.11248111724853516
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.11234164237976074
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.11237978935241699
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.11244320869445801
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.11219620704650879
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.11240553855895996
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.11251139640808105
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.11245584487915039
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.11255240440368652
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.1121206283569336
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.11243891716003418
Decodertime : 0.0001373291015625
g_f_logprobs : 0.1124267578125
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.11264944076538086
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.11238741874694824
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.1124124526977539
beam_search_time: 4.5584046840667725 s
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.12589788436889648
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.12476444244384766
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.12494444847106934
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.12460541725158691
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.124908447265625
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.1247549057006836
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.12468719482421875
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.12476444244384766
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.12540650367736816
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.12480998039245605
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.12494254112243652
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.12492156028747559
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.12469148635864258
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.1251511573791504
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.12510132789611816
Decodertime : 0.00014352798461914062
g_f_logprobs : 0.12495684623718262
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.12495088577270508
Decodertime : 0.000141143798828125
g_f_logprobs : 0.12469983100891113
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.12467384338378906
Decodertime : 0.00014019012451171875
g_f_logprobs : 0.1246039867401123
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.12490415573120117
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.12488245964050293
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.12479352951049805
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.1250293254852295
beam_search_time: 3.0345845222473145 s
Decodertime : 0.0001418590545654297
g_f_logprobs : 0.13834095001220703
Decodertime : 0.000141143798828125
g_f_logprobs : 0.13738322257995605
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.13715720176696777
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.1375572681427002
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.13712406158447266
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.13723111152648926
Decodertime : 0.0001399517059326172
g_f_logprobs : 0.13719916343688965
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.13718795776367188
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.13744211196899414
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.13774538040161133
Decodertime : 0.00014281272888183594
g_f_logprobs : 0.13706517219543457
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.1372675895690918
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.13714218139648438
Decodertime : 0.0001437664031982422
g_f_logprobs : 0.13722705841064453
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.13750147819519043
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.137070894241333
beam_search_time: 2.222203254699707 s
Decodertime : 0.0001418590545654297
g_f_logprobs : 0.13921022415161133
Decodertime : 0.00020885467529296875
g_f_logprobs : 0.1375868320465088
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.13736867904663086
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.13730549812316895
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.13722825050354004
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.13684654235839844
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.13753652572631836
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.13744401931762695
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.13727068901062012
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.1375129222869873
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.13735699653625488
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.13712239265441895
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.13700008392333984
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.13743901252746582
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.1370851993560791
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.1373729705810547
beam_search_time: 2.223623275756836 s
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.13866138458251953
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.13722753524780273
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.13730573654174805
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.13722515106201172
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.13729596138000488
Decodertime : 0.00013875961303710938
g_f_logprobs : 0.13727498054504395
Decodertime : 0.0001373291015625
g_f_logprobs : 0.13737010955810547
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.13707733154296875
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.13723397254943848
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.1373903751373291
Decodertime : 0.0001366138458251953
g_f_logprobs : 0.13722443580627441
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.1370856761932373
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.13716650009155273
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.13727593421936035
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.13885498046875
Decodertime : 0.00018072128295898438
g_f_logprobs : 0.13724374771118164
Decodertime : 0.00014162063598632812
g_f_logprobs : 0.13756155967712402
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.13720154762268066
Decodertime : 0.000141143798828125
g_f_logprobs : 0.1374359130859375
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.137251615524292
Decodertime : 0.0001373291015625
g_f_logprobs : 0.13703680038452148
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.13736534118652344
Decodertime : 0.0001373291015625
g_f_logprobs : 0.13722896575927734
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.13750934600830078
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.13738059997558594
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.13721656799316406
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.13718509674072266
beam_search_time: 3.7509641647338867 s
Decodertime : 0.0001480579376220703
g_f_logprobs : 0.13848233222961426
Decodertime : 0.00013947486877441406
g_f_logprobs : 0.13689899444580078
Decodertime : 0.00014448165893554688
g_f_logprobs : 0.13700294494628906
Decodertime : 0.00013637542724609375
g_f_logprobs : 0.13715839385986328
Decodertime : 0.0001373291015625
g_f_logprobs : 0.13707518577575684
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.13733577728271484
Decodertime : 0.00013756752014160156
g_f_logprobs : 0.13712811470031738
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.13705706596374512
Decodertime : 0.0001373291015625
g_f_logprobs : 0.13708901405334473
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.13706398010253906
Decodertime : 0.00013589859008789062
g_f_logprobs : 0.1373615264892578
Decodertime : 0.00013709068298339844
g_f_logprobs : 0.13701701164245605
Decodertime : 0.00013566017150878906
g_f_logprobs : 0.13753485679626465
Decodertime : 0.00013685226440429688
g_f_logprobs : 0.13715171813964844
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.13718271255493164
Decodertime : 0.0001361370086669922
g_f_logprobs : 0.13710808753967285
beam_search_time: 2.220158100128174 s
input 512:  {"source": "Mr. Wathen , who says Pinkerton 's had a loss of nearly $ 8 million in 1987 under American Brands , boasts that he 's made Pinkerton 's profitable again .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 160, 9779, 1424, 2, 3, 1867, 4, 5, 10763, 20024, 112, 1116, 1125, 170, 2445, 1104, 2212, 109, 129, 1550, 1107, 2164, 1223, 1237, 12381, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 160, 9779, 1424, 2, 3, 24372, 4, 5, 1115, 1119, 112, 1116, 1189, 10763, 20024, 112, 1116, 16244, 1254, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.021717555820941925, -0.03634868934750557, -0.28833770751953125, -0.2663998603820801, -0.2663998603820801, -0.2663998603820801, -0.2663998603820801, -0.2663998603820801, -0.2663998603820801, -0.2663998603820801], "metadata": {"source_tokens": ["Mr", "##.", "W", "##ath", "##en", ",", "who", "says", "Pink", "##erton", "'", "##s", "had", "a", "loss", "of", "nearly", "$", "8", "million", "in", "1987", "under", "American", "Brand", "##s", ",", "boasts", "that", "he", "'", "##s", "made", "Pink", "##erton", "'", "##s", "profitable", "again", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "W", "##ath", "##en", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Pink", "##erton", "'", "##s", "had", "a", "loss", "of", "nearly", "$", "8", "million", "in", "1987", "under", "American", "Brand", "##s", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "W", "##ath", "##en", "[unused2]", "[unused3]", "boasts", "[unused4]", "[unused5]", "that", "he", "'", "##s", "made", "Pink", "##erton", "'", "##s", "profitable", "again", "[unused6]", "[SEP]"]]}

input 513:  {"source": "Mr. Zayadi was previously president and chief operating officer of Zellers Inc. , a retail chain that is owned by Toronto - based Hudson 's Bay Co. , Canada 's largest department store operator .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 163, 12057, 3309, 2, 3, 1108, 4, 5, 2331, 2084, 1105, 2705, 3389, 2575, 1104, 163, 13703, 1116, 3561, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 6989, 4129, 2, 3, 1110, 4, 5, 170, 6989, 4129, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 6989, 4129, 2, 3, 1110, 2205, 4, 5, 1118, 3506, 1359, 6236, 112, 1116, 2410, 3291, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03754574432969093, -0.15198162198066711, -0.08350471407175064, -0.18490362167358398, -0.21775293350219727, -0.21775293350219727, -0.21775293350219727, -0.21775293350219727, -0.21775293350219727, -0.21775293350219727], "metadata": {"source_tokens": ["Mr", "##.", "Z", "##aya", "##di", "was", "previously", "president", "and", "chief", "operating", "officer", "of", "Z", "##eller", "##s", "Inc", "##.", ",", "a", "retail", "chain", "that", "is", "owned", "by", "Toronto", "-", "based", "Hudson", "'", "##s", "Bay", "Co", "##.", ",", "Canada", "'", "##s", "largest", "department", "store", "operator", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Z", "##aya", "##di", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "previously", "president", "and", "chief", "operating", "officer", "of", "Z", "##eller", "##s", "Inc", "[unused6]", "[SEP]", "[unused1]", "a", "retail", "chain", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "retail", "chain", "[unused6]", "[SEP]", "[unused1]", "a", "retail", "chain", "[unused2]", "[unused3]", "is", "owned", "[unused4]", "[unused5]", "by", "Toronto", "based", "Hudson", "'", "##s", "Bay", "Co", "##.", "[unused6]", "[SEP]"]]}

input 514:  {"source": "Mrs. Marcos 's trial is expected to begin in March .\n"}
prediction:  {"predictions": [[1, 2823, 28138, 15541, 112, 1116, 3443, 2, 3, 1110, 2637, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2823, 28138, 15541, 112, 1116, 3443, 2, 3, 1106, 3295, 4, 5, 1107, 1345, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.043329961597919464, -0.020866965875029564, -0.013154029846191406, -0.013592720031738281, -0.013592720031738281, -0.013592720031738281, -0.013592720031738281, -0.013592720031738281, -0.013592720031738281, -0.013592720031738281], "metadata": {"source_tokens": ["Mrs", "##.", "Marcos", "'", "##s", "trial", "is", "expected", "to", "begin", "in", "March", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mrs", "##.", "Marcos", "'", "##s", "trial", "[unused2]", "[unused3]", "is", "expected", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Mrs", "##.", "Marcos", "'", "##s", "trial", "[unused2]", "[unused3]", "to", "begin", "[unused4]", "[unused5]", "in", "March", "[unused6]", "[SEP]"]]}

input 515:  {"source": "Mrs. Marcos has n't admitted that she filed any documents such as those sought by the government .\n"}
prediction:  {"predictions": [[1, 1343, 2, 3, 4110, 4, 5, 1118, 1103, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2823, 28138, 15541, 2, 3, 1144, 183, 28131, 1204, 4120, 4, 5, 1115, 1131, 5770, 1251, 4961, 1216, 1112, 1343, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008106072433292866, -0.026757681742310524, -0.1553192138671875, -0.15267086029052734, -0.15267086029052734, -0.15267086029052734, -0.15267086029052734, -0.15267086029052734, -0.15267086029052734, -0.15267086029052734], "metadata": {"source_tokens": ["Mrs", "##.", "Marcos", "has", "n", "##'", "##t", "admitted", "that", "she", "filed", "any", "documents", "such", "as", "those", "sought", "by", "the", "government", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "those", "[unused2]", "[unused3]", "sought", "[unused4]", "[unused5]", "by", "the", "government", "[unused6]", "[SEP]", "[unused1]", "Mrs", "##.", "Marcos", "[unused2]", "[unused3]", "has", "n", "##'", "##t", "admitted", "[unused4]", "[unused5]", "that", "she", "filed", "any", "documents", "such", "as", "those", "[unused6]", "[SEP]"]]}

input 516:  {"source": "Nixon , on the fourth day of a private visit to China , said that damage to Sino - U.S. relations was `` very great , '' calling the situation `` the most serious '' since 1972 .\n"}
prediction:  {"predictions": [[1, 11302, 2, 3, 1163, 4, 5, 1115, 3290, 1106, 21572, 118, 158, 28138, 1708, 28138, 4125, 1108, 169, 28152, 1304, 1632, 117, 112, 28131, 3516, 1103, 2820, 169, 28152, 1103, 1211, 3021, 112, 28131, 1290, 2388, 1113, 1103, 2223, 1285, 1104, 170, 2029, 3143, 1106, 1975, 6, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.024075569584965706, -0.2969517707824707, -0.2830662727355957, -0.2830662727355957, -0.2830662727355957, -0.2830662727355957, -0.2830662727355957, -0.2830662727355957, -0.2830662727355957, -0.2830662727355957], "metadata": {"source_tokens": ["Nixon", ",", "on", "the", "fourth", "day", "of", "a", "private", "visit", "to", "China", ",", "said", "that", "damage", "to", "Sino", "-", "U", "##.", "##S", "##.", "relations", "was", "`", "##`", "very", "great", ",", "'", "##'", "calling", "the", "situation", "`", "##`", "the", "most", "serious", "'", "##'", "since", "1972", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Nixon", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "that", "damage", "to", "Sino", "-", "U", "##.", "##S", "##.", "relations", "was", "`", "##`", "very", "great", ",", "'", "##'", "calling", "the", "situation", "`", "##`", "the", "most", "serious", "'", "##'", "since", "1972", "on", "the", "fourth", "day", "of", "a", "private", "visit", "to", "China", "[unused6]", "[SEP]"]]}

input 517:  {"source": "Norris McLaughlin is a general - practice firm that has expanded recently into such specialties as banking , labor and environmental work .\n"}
prediction:  {"predictions": [[1, 16309, 26721, 2, 3, 1110, 4, 5, 170, 1704, 118, 2415, 3016, 1115, 1144, 3631, 3055, 1154, 1216, 1957, 4338, 1112, 9339, 117, 5530, 1105, 4801, 1250, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0011040171375498176, -0.06352519989013672, -0.10031938552856445, -0.10031938552856445, -0.10031938552856445, -0.10031938552856445, -0.10031938552856445, -0.10031938552856445, -0.10031938552856445, -0.10031938552856445], "metadata": {"source_tokens": ["Norris", "McLaughlin", "is", "a", "general", "-", "practice", "firm", "that", "has", "expanded", "recently", "into", "such", "special", "##ties", "as", "banking", ",", "labor", "and", "environmental", "work", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Norris", "McLaughlin", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "general", "-", "practice", "firm", "that", "has", "expanded", "recently", "into", "such", "special", "##ties", "as", "banking", ",", "labor", "and", "environmental", "work", "[unused6]", "[SEP]"]]}

input 518:  {"source": "Now Mr. Broberg , a lawyer , claims he 'd play for free .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 139, 25560, 10805, 2, 3, 3711, 4, 5, 1119, 112, 1181, 1505, 1111, 1714, 1986, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 139, 25560, 10805, 2, 3, 1110, 4, 5, 170, 4545, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00027980803861282766, -0.059728216379880905, -0.01734638214111328, -0.016925811767578125, -0.016925811767578125, -0.016925811767578125, -0.016925811767578125, -0.016925811767578125, -0.016925811767578125, -0.016925811767578125], "metadata": {"source_tokens": ["Now", "Mr", "##.", "B", "##robe", "##rg", ",", "a", "lawyer", ",", "claims", "he", "'", "##d", "play", "for", "free", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "B", "##robe", "##rg", "[unused2]", "[unused3]", "claims", "[unused4]", "[unused5]", "he", "'", "##d", "play", "for", "free", "Now", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "B", "##robe", "##rg", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "lawyer", "[unused6]", "[SEP]"]]}

input 519:  {"source": "Now that the New York decision has been left intact , other states may follow suit .\n"}
prediction:  {"predictions": [[1, 1168, 2231, 2, 3, 1336, 2812, 4, 5, 4228, 1986, 1115, 1103, 1203, 1365, 2383, 1144, 1151, 1286, 9964, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0041919187642633915, -0.0969090461730957, -0.09538936614990234, -0.09538936614990234, -0.09538936614990234, -0.09538936614990234, -0.09538936614990234, -0.09538936614990234, -0.09538936614990234, -0.09538936614990234], "metadata": {"source_tokens": ["Now", "that", "the", "New", "York", "decision", "has", "been", "left", "intact", ",", "other", "states", "may", "follow", "suit", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "other", "states", "[unused2]", "[unused3]", "may", "follow", "[unused4]", "[unused5]", "suit", "Now", "that", "the", "New", "York", "decision", "has", "been", "left", "intact", "[unused6]", "[SEP]"]]}

input 520:  {"source": "Of the self - starting vacuum cleaner , he says : `` Could be Cuddles , { Mrs. Stinnett 's dog } . ''\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1867, 4, 5, 7426, 1129, 140, 22940, 2897, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0137094771489501, -0.26981115341186523, -0.27601051330566406, -0.27601051330566406, -0.27601051330566406, -0.27601051330566406, -0.27601051330566406, -0.27601051330566406, -0.27601051330566406, -0.27601051330566406], "metadata": {"source_tokens": ["Of", "the", "self", "-", "starting", "vacuum", "cleaner", ",", "he", "says", ":", "`", "##`", "Could", "be", "C", "##udd", "##les", ",", "{", "Mrs", "##.", "St", "##inn", "##ett", "'", "##s", "dog", "}", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Could", "be", "C", "##udd", "##les", "[unused6]", "[SEP]"]]}

input 521:  {"source": "On a broader scale , the ruling could encourage other states ' courts to adopt the logic of the New York court , not only in DES cases but in other product - related lawsuits , as well .\n"}
prediction:  {"predictions": [[1, 1103, 6550, 2, 3, 1180, 8343, 4, 5, 1168, 2231, 112, 5333, 1106, 11258, 1103, 8738, 1104, 1103, 1203, 1365, 2175, 117, 1136, 1178, 1107, 18581, 1708, 2740, 1133, 1107, 1168, 3317, 118, 2272, 23005, 117, 1112, 1218, 1212, 170, 12594, 3418, 6, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007668918929994106, -0.2695436477661133, -0.2534322738647461, -0.2534322738647461, -0.2534322738647461, -0.2534322738647461, -0.2534322738647461, -0.2534322738647461, -0.2534322738647461, -0.2534322738647461], "metadata": {"source_tokens": ["On", "a", "broader", "scale", ",", "the", "ruling", "could", "encourage", "other", "states", "'", "courts", "to", "adopt", "the", "logic", "of", "the", "New", "York", "court", ",", "not", "only", "in", "DE", "##S", "cases", "but", "in", "other", "product", "-", "related", "lawsuits", ",", "as", "well", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "ruling", "[unused2]", "[unused3]", "could", "encourage", "[unused4]", "[unused5]", "other", "states", "'", "courts", "to", "adopt", "the", "logic", "of", "the", "New", "York", "court", ",", "not", "only", "in", "DE", "##S", "cases", "but", "in", "other", "product", "-", "related", "lawsuits", ",", "as", "well", "On", "a", "broader", "scale", "[unused6]", "[SEP]"]]}

input 522:  {"source": "On a recent afternoon , Mr. Baker and a reporter go ghost - busting , visiting Kathleen Stinnett , a Lexington woman who has phoned the University of Kentucky to report mysterious happenings in her house .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 5779, 1105, 170, 6672, 2, 3, 1301, 4, 5, 7483, 118, 16118, 1158, 1212, 170, 2793, 4427, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 5779, 1105, 170, 6672, 2, 3, 1301, 4, 5, 7483, 118, 16118, 1158, 5807, 15182, 1457, 25409, 5912, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 15134, 1590, 2, 3, 1144, 2179, 1181, 4, 5, 1103, 1239, 1104, 4875, 1106, 2592, 8198, 5664, 1116, 1107, 1123, 1402, 6, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.058430347591638565, -0.12344766408205032, -0.02615164965391159, -0.08240890502929688, -0.08305644989013672, -0.08305644989013672, -0.08305644989013672, -0.08305644989013672, -0.08305644989013672, -0.08305644989013672], "metadata": {"source_tokens": ["On", "a", "recent", "afternoon", ",", "Mr", "##.", "Baker", "and", "a", "reporter", "go", "ghost", "-", "bust", "##ing", ",", "visiting", "Kathleen", "St", "##inn", "##ett", ",", "a", "Lexington", "woman", "who", "has", "phone", "##d", "the", "University", "of", "Kentucky", "to", "report", "mysterious", "happening", "##s", "in", "her", "house", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Baker", "and", "a", "reporter", "[unused2]", "[unused3]", "go", "[unused4]", "[unused5]", "ghost", "-", "bust", "##ing", "On", "a", "recent", "afternoon", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "Baker", "and", "a", "reporter", "[unused2]", "[unused3]", "go", "[unused4]", "[unused5]", "ghost", "-", "bust", "##ing", "visiting", "Kathleen", "St", "##inn", "##ett", "[unused6]", "[SEP]", "[unused1]", "a", "Lexington", "woman", "[unused2]", "[unused3]", "has", "phone", "##d", "[unused4]", "[unused5]", "the", "University", "of", "Kentucky", "to", "report", "mysterious", "happening", "##s", "in", "her", "house", "[unused6]", "[SEP]"]]}

input 523:  {"source": "One had best not dance on top of a coffin until the lid is sealed tightly shut . ''\n"}
prediction:  {"predictions": [[1, 1448, 2, 3, 1125, 1436, 1136, 2842, 4, 5, 1113, 1499, 1104, 170, 16638, 1235, 1103, 14753, 1110, 10410, 6852, 3210, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 14753, 2, 3, 1110, 10410, 4, 5, 6852, 3210, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03258903697133064, -0.13743573427200317, -0.01936197280883789, -0.02155590057373047, -0.021556377410888672, -0.02155590057373047, -0.02155590057373047, -0.02155590057373047, -0.02155590057373047, -0.02155590057373047], "metadata": {"source_tokens": ["One", "had", "best", "not", "dance", "on", "top", "of", "a", "coffin", "until", "the", "lid", "is", "sealed", "tightly", "shut", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "One", "[unused2]", "[unused3]", "had", "best", "not", "dance", "[unused4]", "[unused5]", "on", "top", "of", "a", "coffin", "until", "the", "lid", "is", "sealed", "tightly", "shut", "[unused6]", "[SEP]", "[unused1]", "the", "lid", "[unused2]", "[unused3]", "is", "sealed", "[unused4]", "[unused5]", "tightly", "shut", "[unused6]", "[SEP]"]]}

input 524:  {"source": "Only his factories in Japan and Korea , employing his followers at subsistence wages and producing everything from rifles to ginseng to expensive marble vases , kept the money flowing westward .\n"}
prediction:  {"predictions": [[1, 2809, 1117, 11615, 1107, 1999, 1105, 3577, 2, 3, 2023, 4, 5, 1103, 1948, 8342, 17222, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2809, 1117, 11615, 1107, 1999, 1105, 3577, 2, 3, 16846, 4, 5, 1117, 8618, 1120, 4841, 19031, 13588, 1105, 4411, 1917, 1121, 12385, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05883912742137909, -0.052271388471126556, -0.08847713470458984, -0.0906972885131836, -0.0906972885131836, -0.0906972885131836, -0.0906972885131836, -0.0906972885131836, -0.0906972885131836, -0.0906972885131836], "metadata": {"source_tokens": ["Only", "his", "factories", "in", "Japan", "and", "Korea", ",", "employing", "his", "followers", "at", "sub", "##sistence", "wages", "and", "producing", "everything", "from", "rifles", "to", "g", "##ins", "##eng", "to", "expensive", "marble", "vase", "##s", ",", "kept", "the", "money", "flowing", "westward", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Only", "his", "factories", "in", "Japan", "and", "Korea", "[unused2]", "[unused3]", "kept", "[unused4]", "[unused5]", "the", "money", "flowing", "westward", "[unused6]", "[SEP]", "[unused1]", "Only", "his", "factories", "in", "Japan", "and", "Korea", "[unused2]", "[unused3]", "employing", "[unused4]", "[unused5]", "his", "followers", "at", "sub", "##sistence", "wages", "and", "producing", "everything", "from", "rifles", "[unused6]", "[SEP]"]]}

input 525:  {"source": "Only when one is ascending -- or in our case descending a tad trop rapidement -- does one feel , well , airborne in a picnic basket .\n"}
prediction:  {"predictions": [[1, 1141, 2, 3, 1110, 26457, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1141, 2, 3, 1631, 4, 5, 1218, 1107, 170, 14823, 12916, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05025108903646469, -0.14378155767917633, -0.06490802764892578, -0.06950139999389648, -0.06950139999389648, -0.06950139999389648, -0.06950139999389648, -0.06950139999389648, -0.06950139999389648, -0.06950139999389648], "metadata": {"source_tokens": ["Only", "when", "one", "is", "ascending", "-", "##-", "or", "in", "our", "case", "descending", "a", "ta", "##d", "t", "##rop", "rapid", "##ement", "-", "##-", "does", "one", "feel", ",", "well", ",", "airborne", "in", "a", "picnic", "basket", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "one", "[unused2]", "[unused3]", "is", "ascending", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "one", "[unused2]", "[unused3]", "feel", "[unused4]", "[unused5]", "well", "in", "a", "picnic", "basket", "[unused6]", "[SEP]"]]}

input 526:  {"source": "Osamu Nagayama , deputy president of Chugai , which spends about 15 % of its sales on research and development , was unable to pinpoint how much money Chugai would pump into Gen - Probe .\n"}
prediction:  {"predictions": [[1, 17144, 21347, 2, 3, 16994, 4, 5, 1164, 1405, 110, 1104, 1157, 3813, 1113, 1844, 1105, 1718, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 152, 3202, 13601, 11896, 2571, 11418, 2, 3, 1110, 5874, 2084, 1104, 4, 5, 17144, 21347, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 152, 3202, 13601, 11896, 2571, 11418, 2, 3, 1108, 4, 5, 3372, 1106, 10473, 7587, 1293, 1277, 1948, 17144, 21347, 1156, 11188, 1154, 9198, 5096, 3962, 6, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03382261097431183, -0.05225472152233124, -0.052865006029605865, -0.20403337478637695, -0.2242727279663086, -0.2242722511291504, -0.2242727279663086, -0.2242727279663086, -0.2242727279663086, -0.2242727279663086], "metadata": {"source_tokens": ["O", "##sa", "##mu", "Na", "##ga", "##yama", ",", "deputy", "president", "of", "Chu", "##gai", ",", "which", "spends", "about", "15", "%", "of", "its", "sales", "on", "research", "and", "development", ",", "was", "unable", "to", "pin", "##point", "how", "much", "money", "Chu", "##gai", "would", "pump", "into", "Gen", "-", "Pro", "##be", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Chu", "##gai", "[unused2]", "[unused3]", "spends", "[unused4]", "[unused5]", "about", "15", "%", "of", "its", "sales", "on", "research", "and", "development", "[unused6]", "[SEP]", "[unused1]", "O", "##sa", "##mu", "Na", "##ga", "##yama", "[unused2]", "[unused3]", "is", "deputy", "president", "of", "[unused4]", "[unused5]", "Chu", "##gai", "[unused6]", "[SEP]", "[unused1]", "O", "##sa", "##mu", "Na", "##ga", "##yama", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "unable", "to", "pin", "##point", "how", "much", "money", "Chu", "##gai", "would", "pump", "into", "Gen", "Pro", "##be", "[unused6]", "[SEP]"]]}

input 527:  {"source": "Overall , net sales of all mutual funds , excluding money market funds , fell to $ 1.9 billion in September from $ 4.2 billion in August , the trade group said .\n"}
prediction:  {"predictions": [[1, 5795, 3813, 1104, 1155, 9175, 4381, 117, 14243, 1948, 2319, 4381, 2, 3, 2204, 4, 5, 1106, 109, 122, 28138, 1580, 3775, 1107, 1347, 1121, 109, 125, 28138, 1477, 3775, 1107, 1360, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2597, 1372, 2, 3, 1163, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.015816224738955498, -0.15446360409259796, -0.05749797821044922, -0.05503225326538086, -0.05503225326538086, -0.05503225326538086, -0.05503225326538086, -0.05503225326538086, -0.05503225326538086, -0.05503225326538086], "metadata": {"source_tokens": ["Overall", ",", "net", "sales", "of", "all", "mutual", "funds", ",", "excluding", "money", "market", "funds", ",", "fell", "to", "$", "1", "##.", "##9", "billion", "in", "September", "from", "$", "4", "##.", "##2", "billion", "in", "August", ",", "the", "trade", "group", "said", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "net", "sales", "of", "all", "mutual", "funds", ",", "excluding", "money", "market", "funds", "[unused2]", "[unused3]", "fell", "[unused4]", "[unused5]", "to", "$", "1", "##.", "##9", "billion", "in", "September", "from", "$", "4", "##.", "##2", "billion", "in", "August", "[unused6]", "[SEP]", "[unused1]", "the", "trade", "group", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 528:  {"source": "Panhandle Eastern Corp. said it applied , on behalf of two of its subsidiaries , to the Federal Energy Regulatory Commission for permission to build a 352 - mile , $ 273 million pipeline system from Pittsburg County , Okla. , to Independence , Miss .\n"}
prediction:  {"predictions": [[1, 6991, 9332, 1513, 2882, 13619, 2, 3, 1163, 4, 5, 1122, 3666, 1113, 6261, 1104, 1160, 1104, 1157, 22423, 1106, 1103, 3467, 5514, 23287, 26658, 2827, 1111, 6156, 1106, 3076, 170, 2588, 1477, 118, 2837, 117, 109, 1765, 1495, 1550, 15826, 1449, 1121, 15877, 9364, 1391, 117, 23330, 1742, 102, 1, 1122, 2, 3, 3666, 4, 5, 1113, 6261, 1104, 1160, 1104, 1157, 22423, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 3666, 4, 5, 1113, 6261, 1104, 1160, 1104, 1157, 22423, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 3666, 4, 5, 1113, 6261, 1104, 1160, 1104, 1157, 22423, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 3666, 4, 5, 1113, 6261, 1104, 1160, 1104, 1157, 22423, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 3666, 4, 5, 1113, 6261, 1104, 1160, 1104, 1157, 22423, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 3666, 4, 5, 1113, 6261, 1104, 1160, 1104, 1157, 22423, 6, 102, 102, 1, 1122, 2, 3, 3666, 4, 5, 1113, 6261, 1104, 1160, 1104, 1157, 22423, 6, 102, 102, 1, 1122, 2, 3, 3666, 4, 5, 1113, 6261, 1104, 1160, 1104, 1157, 22423, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 3666, 4, 5, 1113, 6261, 1104, 1160, 1104, 1157, 22423, 6, 102, 102]], "predicted_log_probs": [-0.026204794645309448, -0.06317510455846786, -0.13721269369125366, -0.15551266074180603, -0.16835124790668488, -0.18192850053310394, -0.192611962556839, -0.20356491208076477, -0.20807091891765594, -0.2173689752817154], "metadata": {"source_tokens": ["Pan", "##hand", "##le", "Eastern", "Corp", "##.", "said", "it", "applied", ",", "on", "behalf", "of", "two", "of", "its", "subsidiaries", ",", "to", "the", "Federal", "Energy", "Reg", "##ulatory", "Commission", "for", "permission", "to", "build", "a", "35", "##2", "-", "mile", ",", "$", "27", "##3", "million", "pipeline", "system", "from", "Pitt", "##sburg", "County", ",", "Ok", "##la", "##.", ",", "to", "Independence", ",", "Miss", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pan", "##hand", "##le", "Eastern", "Corp", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "applied", "on", "behalf", "of", "two", "of", "its", "subsidiaries", "to", "the", "Federal", "Energy", "Reg", "##ulatory", "Commission", "for", "permission", "to", "build", "a", "35", "##2", "-", "mile", ",", "$", "27", "##3", "million", "pipeline", "system", "from", "Pitt", "##sburg", "County", ",", "Ok", "##la", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "on", "behalf", "of", "two", "of", "its", "subsidiaries", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "on", "behalf", "of", "two", "of", "its", "subsidiaries", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "on", "behalf", "of", "two", "of", "its", "subsidiaries", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "on", "behalf", "of", "two", "of", "its", "subsidiaries", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "on", "behalf", "of", "two", "of", "its", "subsidiaries", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "on", "behalf", "of", "two", "of", "its", "subsidiaries", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "on", "behalf", "of", "two", "of", "its", "subsidiaries", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "on", "behalf", "of", "two", "of", "its", "subsidiaries", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "on", "behalf", "of", "two", "of", "its", "subsidiaries", "[unused6]", "[SEP]"]]}

input 529:  {"source": "Pennzoil 's poison pill covers five years in order to give current management enough time to put these proceeds to work in a prudent manner .\n"}
prediction:  {"predictions": [[1, 9223, 6112, 2723, 112, 1116, 11539, 21822, 2, 3, 3662, 4, 5, 1421, 1201, 1107, 1546, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9223, 6112, 2723, 112, 1116, 11539, 21822, 2, 3, 3662, 4, 5, 1421, 1201, 1107, 1546, 1106, 1660, 1954, 2635, 1536, 1159, 1106, 1508, 1292, 11283, 1106, 1250, 1107, 170, 185, 25980, 3452, 4758, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02643326111137867, -0.03584979847073555, -0.11208581924438477, -0.10249948501586914, -0.10249948501586914, -0.10249948501586914, -0.10249948501586914, -0.10249948501586914, -0.10249948501586914, -0.10249948501586914], "metadata": {"source_tokens": ["Penn", "##zo", "##il", "'", "##s", "poison", "pill", "covers", "five", "years", "in", "order", "to", "give", "current", "management", "enough", "time", "to", "put", "these", "proceeds", "to", "work", "in", "a", "p", "##rud", "##ent", "manner", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Penn", "##zo", "##il", "'", "##s", "poison", "pill", "[unused2]", "[unused3]", "covers", "[unused4]", "[unused5]", "five", "years", "in", "order", "[unused6]", "[SEP]", "[unused1]", "Penn", "##zo", "##il", "'", "##s", "poison", "pill", "[unused2]", "[unused3]", "covers", "[unused4]", "[unused5]", "five", "years", "in", "order", "to", "give", "current", "management", "enough", "time", "to", "put", "these", "proceeds", "to", "work", "in", "a", "p", "##rud", "##ent", "manner", "[unused6]", "[SEP]"]]}

input 530:  {"source": "Prime Minister Lee Kuan Yew , Singapore 's leader and one of Asia 's leading statesmen for 30 years , recently announced his intention to retire next year -- though not necessarily to end his influence .\n"}
prediction:  {"predictions": [[1, 3460, 2110, 2499, 23209, 1389, 15821, 2246, 2, 3, 1717, 4, 5, 1117, 6247, 1106, 11067, 1397, 1214, 3055, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3460, 2110, 2499, 23209, 1389, 15821, 2246, 2, 3, 1110, 4, 5, 4478, 112, 1116, 2301, 1105, 1141, 1104, 3165, 112, 1116, 2020, 2231, 2354, 1111, 1476, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03321394696831703, -0.03147309273481369, -0.059282779693603516, -0.05682992935180664, -0.056830406188964844, -0.056830406188964844, -0.05682992935180664, -0.05682992935180664, -0.05682992935180664, -0.05682992935180664], "metadata": {"source_tokens": ["Prime", "Minister", "Lee", "Ku", "##an", "Ye", "##w", ",", "Singapore", "'", "##s", "leader", "and", "one", "of", "Asia", "'", "##s", "leading", "states", "##men", "for", "30", "years", ",", "recently", "announced", "his", "intention", "to", "retire", "next", "year", "-", "##-", "though", "not", "necessarily", "to", "end", "his", "influence", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Prime", "Minister", "Lee", "Ku", "##an", "Ye", "##w", "[unused2]", "[unused3]", "announced", "[unused4]", "[unused5]", "his", "intention", "to", "retire", "next", "year", "recently", "[unused6]", "[SEP]", "[unused1]", "Prime", "Minister", "Lee", "Ku", "##an", "Ye", "##w", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Singapore", "'", "##s", "leader", "and", "one", "of", "Asia", "'", "##s", "leading", "states", "##men", "for", "30", "years", "[unused6]", "[SEP]"]]}

input 531:  {"source": "Procter & Gamble Co. recently introduced refillable versions of four products , including Tide and Mr. Clean , in Canada , but does n't plan to bring them to the U.S. .\n"}
prediction:  {"predictions": [[1, 5096, 25857, 111, 144, 16033, 3291, 28138, 2, 3, 2234, 4, 5, 1231, 18591, 1895, 3827, 1104, 1300, 2982, 117, 1259, 27604, 1105, 1828, 28138, 17508, 117, 1107, 1803, 3055, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5096, 25857, 111, 144, 16033, 3291, 28138, 2, 3, 1674, 183, 28131, 1204, 2197, 4, 5, 1106, 2498, 1172, 1106, 1103, 158, 28138, 1708, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01859152317047119, -0.03171335905790329, -0.18244314193725586, -0.1758584976196289, -0.1758584976196289, -0.1758584976196289, -0.1758584976196289, -0.1758584976196289, -0.1758584976196289, -0.1758584976196289], "metadata": {"source_tokens": ["Pro", "##cter", "&", "G", "##amble", "Co", "##.", "recently", "introduced", "re", "##fill", "##able", "versions", "of", "four", "products", ",", "including", "Tide", "and", "Mr", "##.", "Clean", ",", "in", "Canada", ",", "but", "does", "n", "##'", "##t", "plan", "to", "bring", "them", "to", "the", "U", "##.", "##S", "##.", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pro", "##cter", "&", "G", "##amble", "Co", "##.", "[unused2]", "[unused3]", "introduced", "[unused4]", "[unused5]", "re", "##fill", "##able", "versions", "of", "four", "products", ",", "including", "Tide", "and", "Mr", "##.", "Clean", ",", "in", "Canada", "recently", "[unused6]", "[SEP]", "[unused1]", "Pro", "##cter", "&", "G", "##amble", "Co", "##.", "[unused2]", "[unused3]", "does", "n", "##'", "##t", "plan", "[unused4]", "[unused5]", "to", "bring", "them", "to", "the", "U", "##.", "##S", "##.", "[unused6]", "[SEP]"]]}

input 532:  {"source": "RISC technology speeds up a computer by simplifying the internal software .\n"}
prediction:  {"predictions": [[1, 155, 6258, 1658, 2815, 2, 3, 10979, 1146, 170, 2775, 1118, 27466, 8223, 22881, 1158, 4, 5, 1103, 4422, 3594, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009074299596250057, -0.09680843353271484, -0.09968137741088867, -0.09968137741088867, -0.09968137741088867, -0.09968137741088867, -0.09968137741088867, -0.09968137741088867, -0.09968137741088867, -0.09968137741088867], "metadata": {"source_tokens": ["R", "##IS", "##C", "technology", "speeds", "up", "a", "computer", "by", "si", "##mp", "##lify", "##ing", "the", "internal", "software", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "R", "##IS", "##C", "technology", "[unused2]", "[unused3]", "speeds", "up", "a", "computer", "by", "si", "##mp", "##lify", "##ing", "[unused4]", "[unused5]", "the", "internal", "software", "[unused6]", "[SEP]"]]}

input 533:  {"source": "Rather ominously , rabbit studies reveal that RU-486 can cause birth defects , Lancet , the British medical journal , reported in 1987 .\n"}
prediction:  {"predictions": [[1, 16225, 2527, 2, 3, 7063, 4, 5, 1115, 155, 2591, 28137, 19203, 1545, 1169, 2612, 3485, 20705, 117, 11856, 1204, 117, 1103, 1418, 2657, 4897, 117, 2103, 1107, 2164, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 155, 2591, 28137, 19203, 1545, 2, 3, 1169, 2612, 4, 5, 3485, 20705, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.030636034905910492, -0.05535105615854263, -0.08542633056640625, -0.08662223815917969, -0.08662223815917969, -0.08662223815917969, -0.08662223815917969, -0.08662223815917969, -0.08662223815917969, -0.08662223815917969], "metadata": {"source_tokens": ["Rather", "ominous", "##ly", ",", "rabbit", "studies", "reveal", "that", "R", "##U", "##-", "##48", "##6", "can", "cause", "birth", "defects", ",", "Lance", "##t", ",", "the", "British", "medical", "journal", ",", "reported", "in", "1987", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "rabbit", "studies", "[unused2]", "[unused3]", "reveal", "[unused4]", "[unused5]", "that", "R", "##U", "##-", "##48", "##6", "can", "cause", "birth", "defects", ",", "Lance", "##t", ",", "the", "British", "medical", "journal", ",", "reported", "in", "1987", "[unused6]", "[SEP]", "[unused1]", "R", "##U", "##-", "##48", "##6", "[unused2]", "[unused3]", "can", "cause", "[unused4]", "[unused5]", "birth", "defects", "[unused6]", "[SEP]"]]}

input 534:  {"source": "Repeat customers also can purchase luxury items at reduced prices .\n"}
prediction:  {"predictions": [[1, 20777, 13448, 5793, 2, 3, 1169, 4779, 4, 5, 9886, 4454, 1120, 3549, 7352, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00011208478099433705, -0.02898550033569336, -0.027952194213867188, -0.027952194213867188, -0.027952194213867188, -0.027952194213867188, -0.027952194213867188, -0.027952194213867188, -0.027952194213867188, -0.027952194213867188], "metadata": {"source_tokens": ["Rep", "##eat", "customers", "also", "can", "purchase", "luxury", "items", "at", "reduced", "prices", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rep", "##eat", "customers", "[unused2]", "[unused3]", "can", "purchase", "[unused4]", "[unused5]", "luxury", "items", "at", "reduced", "prices", "[unused6]", "[SEP]"]]}

input 535:  {"source": "Richard Newsom , a California state official who last year examined Lincoln 's parent , American Continental Corp. , said he also saw evidence that crimes had been committed .\n"}
prediction:  {"predictions": [[1, 2055, 3128, 4165, 2, 3, 1163, 4, 5, 1119, 1145, 1486, 2554, 1115, 6969, 1125, 1151, 4762, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1756, 1352, 2078, 2, 3, 1129, 8600, 4, 5, 4617, 112, 1116, 6486, 1314, 9211, 13619, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03157053142786026, -0.14344772696495056, -0.22364091873168945, -0.21773433685302734, -0.21773433685302734, -0.21773433685302734, -0.21773433685302734, -0.21773433685302734, -0.21773433685302734, -0.21773433685302734], "metadata": {"source_tokens": ["Richard", "News", "##om", ",", "a", "California", "state", "official", "who", "last", "year", "examined", "Lincoln", "'", "##s", "parent", ",", "American", "Continental", "Corp", "##.", ",", "said", "he", "also", "saw", "evidence", "that", "crimes", "had", "been", "committed", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Richard", "News", "##om", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "he", "also", "saw", "evidence", "that", "crimes", "had", "been", "committed", "[unused6]", "[SEP]", "[unused1]", "a", "California", "state", "official", "[unused2]", "[unused3]", "be", "examined", "[unused4]", "[unused5]", "Lincoln", "'", "##s", "parent", "last", "Continental", "Corp", "[unused6]", "[SEP]"]]}

input 536:  {"source": "Roger M. Marino , president , was named to the new post of vice chairman .\n"}
prediction:  {"predictions": [[1, 4271, 150, 28138, 18940, 2, 3, 1108, 1417, 4, 5, 1106, 1103, 1207, 2112, 1104, 4711, 3931, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4271, 150, 28138, 18940, 2, 3, 1110, 4, 5, 4159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4271, 150, 28138, 18940, 2, 3, 1110, 4, 5, 4159, 2084, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00010194778587901965, -0.12660473585128784, -0.10288965702056885, -0.011020183563232422, -0.010643482208251953, -0.010643482208251953, -0.010643482208251953, -0.010643482208251953, -0.010643482208251953, -0.010643482208251953], "metadata": {"source_tokens": ["Roger", "M", "##.", "Marino", ",", "president", ",", "was", "named", "to", "the", "new", "post", "of", "vice", "chairman", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Roger", "M", "##.", "Marino", "[unused2]", "[unused3]", "was", "named", "[unused4]", "[unused5]", "to", "the", "new", "post", "of", "vice", "chairman", "[unused6]", "[SEP]", "[unused1]", "Roger", "M", "##.", "Marino", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "programming", "[unused6]", "[SEP]", "[unused1]", "Roger", "M", "##.", "Marino", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "programming", "president", "[unused6]", "[SEP]"]]}

input 537:  {"source": "Rolls - Royce Motor Cars Inc. said it expects its U.S. sales to remain steady at about 1,200 cars in 1990 .\n"}
prediction:  {"predictions": [[1, 18856, 118, 15466, 8226, 16644, 3561, 2, 3, 1163, 4, 5, 1122, 27402, 1157, 158, 28138, 1708, 28138, 3813, 1106, 3118, 6386, 1120, 1164, 122, 28136, 10973, 1568, 3079, 1107, 1997, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 27402, 4, 5, 1157, 158, 28138, 1708, 28138, 3813, 1106, 3118, 6386, 1120, 1164, 122, 28136, 10973, 1568, 3079, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0031570547726005316, -0.0281711146235466, -0.05243349075317383, -0.05923128128051758, -0.05923128128051758, -0.05923128128051758, -0.05923128128051758, -0.05923128128051758, -0.05923128128051758, -0.05923128128051758], "metadata": {"source_tokens": ["Rolls", "-", "Royce", "Motor", "Cars", "Inc", "##.", "said", "it", "expects", "its", "U", "##.", "##S", "##.", "sales", "to", "remain", "steady", "at", "about", "1", "##,", "##20", "##0", "cars", "in", "1990", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rolls", "-", "Royce", "Motor", "Cars", "Inc", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "expects", "its", "U", "##.", "##S", "##.", "sales", "to", "remain", "steady", "at", "about", "1", "##,", "##20", "##0", "cars", "in", "1990", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "expects", "[unused4]", "[unused5]", "its", "U", "##.", "##S", "##.", "sales", "to", "remain", "steady", "at", "about", "1", "##,", "##20", "##0", "cars", "[unused6]", "[SEP]"]]}

input 538:  {"source": "Ryukichi Imai , Japan 's ambassador to Mexico , agrees that Mexico may be too eager .\n"}
prediction:  {"predictions": [[1, 155, 19404, 4313, 146, 1918, 1182, 2, 3, 10052, 4, 5, 1115, 2470, 1336, 1129, 1315, 9582, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 155, 19404, 4313, 146, 1918, 1182, 2, 3, 1110, 4, 5, 1999, 112, 1116, 9088, 1106, 2470, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0012849807972088456, -0.061936356127262115, -0.004758358001708984, -0.0046787261962890625, -0.0046787261962890625, -0.0046787261962890625, -0.0046787261962890625, -0.0046787261962890625, -0.0046787261962890625, -0.0046787261962890625], "metadata": {"source_tokens": ["R", "##yuki", "##chi", "I", "##ma", "##i", ",", "Japan", "'", "##s", "ambassador", "to", "Mexico", ",", "agrees", "that", "Mexico", "may", "be", "too", "eager", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "R", "##yuki", "##chi", "I", "##ma", "##i", "[unused2]", "[unused3]", "agrees", "[unused4]", "[unused5]", "that", "Mexico", "may", "be", "too", "eager", "[unused6]", "[SEP]", "[unused1]", "R", "##yuki", "##chi", "I", "##ma", "##i", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Japan", "'", "##s", "ambassador", "to", "Mexico", "[unused6]", "[SEP]"]]}

input 539:  {"source": "Second , the dollar is showing persistent strength despite a slowdown in the U.S. economy shown by economic indicators .\n"}
prediction:  {"predictions": [[1, 1103, 158, 28138, 1708, 28138, 4190, 2, 3, 2602, 4, 5, 1118, 2670, 24091, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 8876, 2, 3, 1110, 4000, 4, 5, 15970, 3220, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 8876, 2, 3, 1110, 4, 5, 4000, 15970, 3220, 2693, 170, 3345, 5455, 1107, 1103, 158, 28138, 1708, 28138, 4190, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04474659636616707, -0.03277624025940895, -0.09697005897760391, -0.018837928771972656, -0.018905162811279297, -0.018905162811279297, -0.018905162811279297, -0.018905162811279297, -0.018905162811279297, -0.018905162811279297], "metadata": {"source_tokens": ["Second", ",", "the", "dollar", "is", "showing", "persistent", "strength", "despite", "a", "slow", "##down", "in", "the", "U", "##.", "##S", "##.", "economy", "shown", "by", "economic", "indicators", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "U", "##.", "##S", "##.", "economy", "[unused2]", "[unused3]", "shown", "[unused4]", "[unused5]", "by", "economic", "indicators", "[unused6]", "[SEP]", "[unused1]", "the", "dollar", "[unused2]", "[unused3]", "is", "showing", "[unused4]", "[unused5]", "persistent", "strength", "[unused6]", "[SEP]", "[unused1]", "the", "dollar", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "showing", "persistent", "strength", "despite", "a", "slow", "##down", "in", "the", "U", "##.", "##S", "##.", "economy", "[unused6]", "[SEP]"]]}

input 540:  {"source": "Sen. Mitchell is confident he has sufficient votes to block such a measure with procedural actions .\n"}
prediction:  {"predictions": [[1, 14895, 28138, 5741, 2, 3, 1110, 4, 5, 9588, 1119, 1144, 6664, 3667, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1144, 4, 5, 6664, 3667, 1106, 3510, 1216, 170, 4929, 1114, 5250, 27433, 3721, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02973935753107071, -0.0075513264164328575, -0.01209878921508789, -0.011400222778320312, -0.011400222778320312, -0.011400222778320312, -0.011400222778320312, -0.011400222778320312, -0.011400222778320312, -0.011400222778320312], "metadata": {"source_tokens": ["Sen", "##.", "Mitchell", "is", "confident", "he", "has", "sufficient", "votes", "to", "block", "such", "a", "measure", "with", "pro", "##cedural", "actions", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sen", "##.", "Mitchell", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "confident", "he", "has", "sufficient", "votes", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "sufficient", "votes", "to", "block", "such", "a", "measure", "with", "pro", "##cedural", "actions", "[unused6]", "[SEP]"]]}

input 541:  {"source": "Senate Appropriations Committee Chairman Robert Byrd ( D. , W.Va . ) strongly resisted deeper cuts sought by the House .\n"}
prediction:  {"predictions": [[1, 3279, 138, 8661, 24594, 2341, 4284, 1823, 19195, 2, 3, 5473, 13672, 4, 5, 6353, 7484, 4110, 1118, 1103, 1585, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1823, 19195, 2, 3, 1110, 4284, 1104, 4, 5, 3279, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004134551156312227, -0.19825983047485352, -0.010972976684570312, -0.011098384857177734, -0.011098384857177734, -0.011098384857177734, -0.011098384857177734, -0.011098384857177734, -0.011098384857177734, -0.011098384857177734], "metadata": {"source_tokens": ["Senate", "A", "##pp", "##ropriations", "Committee", "Chairman", "Robert", "Byrd", "(", "D", "##.", ",", "W", "##.", "##V", "##a", ".", ")", "strongly", "resisted", "deeper", "cuts", "sought", "by", "the", "House", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Senate", "A", "##pp", "##ropriations", "Committee", "Chairman", "Robert", "Byrd", "[unused2]", "[unused3]", "strongly", "resisted", "[unused4]", "[unused5]", "deeper", "cuts", "sought", "by", "the", "House", "[unused6]", "[SEP]", "[unused1]", "Robert", "Byrd", "[unused2]", "[unused3]", "is", "Chairman", "of", "[unused4]", "[unused5]", "Senate", "[unused6]", "[SEP]"]]}

input 542:  {"source": "Separately , Ford and Mazda Motor Corp. 's U.S. sales arm said they are recalling about 88,500 1988 - model Mercury Tracers and 220,000 1986 , 1987 and 1988 model Mazda 323s equipped with 1.6 - liter fuel - injected engines to replace the oil filler cap .\n"}
prediction:  {"predictions": [[1, 4100, 1105, 7085, 26604, 8226, 13619, 28138, 112, 1116, 158, 28138, 1708, 28138, 3813, 1981, 2, 3, 1163, 4, 5, 1152, 1132, 25839, 1164, 5385, 28136, 22682, 2115, 118, 2235, 10080, 22681, 1733, 1105, 10423, 28136, 7629, 1568, 2177, 117, 2164, 1105, 2115, 2235, 7085, 26604, 2724, 1495, 1116, 102, 1, 2164, 1105, 2115, 2235, 7085, 26604, 2724, 1495, 1116, 2, 3, 1129, 5440, 4, 5, 1114, 122, 28138, 1545, 118, 27146, 4251, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1132, 25839, 4, 5, 1164, 5385, 28136, 22682, 2115, 118, 2235, 10080, 22681, 1733, 1105, 10423, 28136, 7629, 1568, 2177, 6, 102, 102, 102, 102, 102, 102, 102, 1, 7085, 26604, 2724, 1495, 1116, 2, 3, 1129, 5440, 4, 5, 1114, 122, 28138, 1545, 118, 27146, 4251, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.015423106029629707, -0.14935104548931122, -0.09747660905122757, -0.25690802931785583, -0.27161455154418945, -0.2763996124267578, -0.2763996124267578, -0.2763996124267578, -0.2763996124267578, -0.2763996124267578], "metadata": {"source_tokens": ["Sep", "##arate", "##ly", ",", "Ford", "and", "Ma", "##zda", "Motor", "Corp", "##.", "'", "##s", "U", "##.", "##S", "##.", "sales", "arm", "said", "they", "are", "recalling", "about", "88", "##,", "##500", "1988", "-", "model", "Mercury", "Trace", "##rs", "and", "220", "##,", "##00", "##0", "1986", ",", "1987", "and", "1988", "model", "Ma", "##zda", "32", "##3", "##s", "equipped", "with", "1", "##.", "##6", "-", "liter", "fuel", "-", "injected", "engines", "to", "replace", "the", "oil", "fill", "##er", "cap", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ford", "and", "Ma", "##zda", "Motor", "Corp", "##.", "'", "##s", "U", "##.", "##S", "##.", "sales", "arm", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "they", "are", "recalling", "about", "88", "##,", "##500", "1988", "-", "model", "Mercury", "Trace", "##rs", "and", "220", "##,", "##00", "##0", "1986", ",", "1987", "and", "1988", "model", "Ma", "##zda", "32", "##3", "##s", "[SEP]", "[unused1]", "1987", "and", "1988", "model", "Ma", "##zda", "32", "##3", "##s", "[unused2]", "[unused3]", "be", "equipped", "[unused4]", "[unused5]", "with", "1", "##.", "##6", "-", "liter", "fuel", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "are", "recalling", "[unused4]", "[unused5]", "about", "88", "##,", "##500", "1988", "-", "model", "Mercury", "Trace", "##rs", "and", "220", "##,", "##00", "##0", "1986", "[unused6]", "[SEP]", "[unused1]", "Ma", "##zda", "32", "##3", "##s", "[unused2]", "[unused3]", "be", "equipped", "[unused4]", "[unused5]", "with", "1", "##.", "##6", "-", "liter", "fuel", "[unused6]", "[SEP]"]]}

input 543:  {"source": "Shaw Industries , which agreed to acquire Armstrong World Industries ' carpet operations for an undisclosed price , rose 2 1\\/4 to 26 1\\/8 .\n"}
prediction:  {"predictions": [[1, 7802, 10699, 2, 3, 3152, 4, 5, 123, 122, 28148, 28139, 1527, 1106, 1744, 122, 28148, 28139, 1604, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7802, 10699, 2, 3, 1129, 2675, 1106, 9703, 4, 5, 8800, 1291, 10699, 112, 10797, 2500, 1111, 1126, 20031, 3945, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013306301087141037, -0.07375913858413696, -0.03312110900878906, -0.03345012664794922, -0.03345060348510742, -0.03345012664794922, -0.03345012664794922, -0.03345012664794922, -0.03345012664794922, -0.03345012664794922], "metadata": {"source_tokens": ["Shaw", "Industries", ",", "which", "agreed", "to", "acquire", "Armstrong", "World", "Industries", "'", "carpet", "operations", "for", "an", "undisclosed", "price", ",", "rose", "2", "1", "##\\", "##/", "##4", "to", "26", "1", "##\\", "##/", "##8", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Shaw", "Industries", "[unused2]", "[unused3]", "rose", "[unused4]", "[unused5]", "2", "1", "##\\", "##/", "##4", "to", "26", "1", "##\\", "##/", "##8", "[unused6]", "[SEP]", "[unused1]", "Shaw", "Industries", "[unused2]", "[unused3]", "be", "agreed", "to", "acquire", "[unused4]", "[unused5]", "Armstrong", "World", "Industries", "'", "carpet", "operations", "for", "an", "undisclosed", "price", "[unused6]", "[SEP]"]]}

input 544:  {"source": "Sidley will maintain its association with the Hashidate Law Office in Tokyo .\n"}
prediction:  {"predictions": [[1, 17916, 1926, 2, 3, 1209, 4731, 4, 5, 1157, 3852, 1114, 1103, 10736, 3031, 9216, 2601, 3060, 1107, 4839, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-3.2164833100978285e-05, -0.013538360595703125, -0.014141082763671875, -0.014141082763671875, -0.014141082763671875, -0.014141082763671875, -0.014141082763671875, -0.014141082763671875, -0.014141082763671875, -0.014141082763671875], "metadata": {"source_tokens": ["Sid", "##ley", "will", "maintain", "its", "association", "with", "the", "Has", "##hi", "##date", "Law", "Office", "in", "Tokyo", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sid", "##ley", "[unused2]", "[unused3]", "will", "maintain", "[unused4]", "[unused5]", "its", "association", "with", "the", "Has", "##hi", "##date", "Law", "Office", "in", "Tokyo", "[unused6]", "[SEP]"]]}

input 545:  {"source": "Similar studies are expected to reveal how stroke patients ' brains regroup -- a first step toward finding ways to bolster that process and speed rehabilitation .\n"}
prediction:  {"predictions": [[1, 12250, 2527, 2, 3, 1132, 2637, 4, 5, 1293, 6625, 4420, 112, 16570, 1231, 16016, 170, 1148, 2585, 1755, 4006, 3242, 1106, 171, 23681, 2083, 1115, 1965, 1105, 2420, 14178, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12250, 2527, 2, 3, 1106, 7063, 4, 5, 1293, 6625, 4420, 112, 16570, 1231, 16016, 118, 28137, 170, 1148, 2585, 1755, 4006, 3242, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06251270323991776, -0.052731018513441086, -0.09654855728149414, -0.09837102890014648, -0.09837102890014648, -0.09837102890014648, -0.09837102890014648, -0.09837102890014648, -0.09837102890014648, -0.09837102890014648], "metadata": {"source_tokens": ["Similar", "studies", "are", "expected", "to", "reveal", "how", "stroke", "patients", "'", "brains", "re", "##group", "-", "##-", "a", "first", "step", "toward", "finding", "ways", "to", "b", "##ols", "##ter", "that", "process", "and", "speed", "rehabilitation", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Similar", "studies", "[unused2]", "[unused3]", "are", "expected", "[unused4]", "[unused5]", "how", "stroke", "patients", "'", "brains", "re", "##group", "a", "first", "step", "toward", "finding", "ways", "to", "b", "##ols", "##ter", "that", "process", "and", "speed", "rehabilitation", "[unused6]", "[SEP]", "[unused1]", "Similar", "studies", "[unused2]", "[unused3]", "to", "reveal", "[unused4]", "[unused5]", "how", "stroke", "patients", "'", "brains", "re", "##group", "-", "##-", "a", "first", "step", "toward", "finding", "ways", "[unused6]", "[SEP]"]]}

input 546:  {"source": "Since the real estate unit also includes debt , the imputed value of the real estate itself is close to $ 3 billion .\n"}
prediction:  {"predictions": [[1, 1103, 24034, 18527, 2860, 1104, 1103, 1842, 3327, 2, 3, 1110, 4, 5, 1601, 1106, 109, 124, 3775, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1842, 3327, 2587, 2, 3, 1129, 1145, 2075, 4, 5, 6695, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02735445834696293, -0.09669174998998642, -0.17987871170043945, -0.1651911735534668, -0.1651911735534668, -0.1651911735534668, -0.1651911735534668, -0.1651911735534668, -0.1651911735534668, -0.1651911735534668], "metadata": {"source_tokens": ["Since", "the", "real", "estate", "unit", "also", "includes", "debt", ",", "the", "imp", "##uted", "value", "of", "the", "real", "estate", "itself", "is", "close", "to", "$", "3", "billion", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "imp", "##uted", "value", "of", "the", "real", "estate", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "close", "to", "$", "3", "billion", "[unused6]", "[SEP]", "[unused1]", "the", "real", "estate", "unit", "[unused2]", "[unused3]", "be", "also", "includes", "[unused4]", "[unused5]", "debt", "[unused6]", "[SEP]"]]}

input 547:  {"source": "Six years ago , Judge O'Kicki was voted president of the Pennsylvania Conference of State Trial Judges by the state 's 400 judges .\n"}
prediction:  {"predictions": [[1, 5274, 152, 28131, 2428, 5345, 1182, 2, 3, 1108, 4751, 4, 5, 2084, 1104, 1103, 2680, 3047, 1104, 1426, 12819, 21312, 1118, 1103, 1352, 112, 1116, 3434, 7030, 4995, 1201, 2403, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.001185546861961484, -0.24886512756347656, -0.259249210357666, -0.259249210357666, -0.259249210357666, -0.259249210357666, -0.259249210357666, -0.259249210357666, -0.259249210357666, -0.259249210357666], "metadata": {"source_tokens": ["Six", "years", "ago", ",", "Judge", "O", "##'", "##K", "##ick", "##i", "was", "voted", "president", "of", "the", "Pennsylvania", "Conference", "of", "State", "Trial", "Judges", "by", "the", "state", "'", "##s", "400", "judges", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Judge", "O", "##'", "##K", "##ick", "##i", "[unused2]", "[unused3]", "was", "voted", "[unused4]", "[unused5]", "president", "of", "the", "Pennsylvania", "Conference", "of", "State", "Trial", "Judges", "by", "the", "state", "'", "##s", "400", "judges", "Six", "years", "ago", "[unused6]", "[SEP]"]]}

input 548:  {"source": "Sometimes , if you have a headache , you can go out and walk it right off . ''\n"}
prediction:  {"predictions": [[1, 1128, 2, 3, 1169, 1301, 4, 5, 1149, 5875, 1191, 1128, 1138, 170, 16320, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1128, 2, 3, 1169, 2647, 1268, 1228, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.11785880476236343, -0.16129474341869354, -0.12824678421020508, -0.1307220458984375, -0.1307220458984375, -0.1307220458984375, -0.1307220458984375, -0.1307220458984375, -0.1307220458984375, -0.1307220458984375], "metadata": {"source_tokens": ["Sometimes", ",", "if", "you", "have", "a", "headache", ",", "you", "can", "go", "out", "and", "walk", "it", "right", "off", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "you", "[unused2]", "[unused3]", "can", "go", "[unused4]", "[unused5]", "out", "Sometimes", "if", "you", "have", "a", "headache", "[unused6]", "[SEP]", "[unused1]", "you", "[unused2]", "[unused3]", "can", "walk", "right", "off", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 549:  {"source": "Soviets remain in charge of education programs , a former head of an African military tribunal for executions is in charge of culture , and a hard - line Polish communist in exile directs the human - rights and peace division .\n"}
prediction:  {"predictions": [[1, 170, 1393, 1246, 1104, 1126, 2170, 1764, 23893, 1111, 26107, 2, 3, 1110, 4, 5, 1107, 2965, 1104, 2754, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1662, 118, 1413, 3129, 8356, 1107, 8879, 2, 3, 26818, 4, 5, 1103, 1769, 118, 2266, 1105, 3519, 2417, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16359, 2, 3, 3118, 4, 5, 1107, 2965, 1104, 1972, 2648, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.047105398029088974, -0.026376228779554367, -0.021340522915124893, -0.016485214233398438, -0.01686239242553711, -0.01686239242553711, -0.01686239242553711, -0.01686239242553711, -0.01686239242553711, -0.01686239242553711], "metadata": {"source_tokens": ["Soviets", "remain", "in", "charge", "of", "education", "programs", ",", "a", "former", "head", "of", "an", "African", "military", "tribunal", "for", "executions", "is", "in", "charge", "of", "culture", ",", "and", "a", "hard", "-", "line", "Polish", "communist", "in", "exile", "directs", "the", "human", "-", "rights", "and", "peace", "division", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "former", "head", "of", "an", "African", "military", "tribunal", "for", "executions", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "in", "charge", "of", "culture", "[unused6]", "[SEP]", "[unused1]", "a", "hard", "-", "line", "Polish", "communist", "in", "exile", "[unused2]", "[unused3]", "directs", "[unused4]", "[unused5]", "the", "human", "-", "rights", "and", "peace", "division", "[unused6]", "[SEP]", "[unused1]", "Soviets", "[unused2]", "[unused3]", "remain", "[unused4]", "[unused5]", "in", "charge", "of", "education", "programs", "[unused6]", "[SEP]"]]}

input 550:  {"source": "Standard & Poor 's 500 - Stock Index climbed 5.29 to 340.36 , the Dow Jones Equity Market Index added 4.70 to 318.79 and the New York Stock Exchange Composite Index climbed 2.65 to\n"}
prediction:  {"predictions": [[1, 1103, 26535, 2690, 25083, 6923, 10146, 2, 3, 1896, 4, 5, 125, 28138, 20829, 1106, 1955, 1604, 28138, 1559, 1580, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1203, 1365, 9924, 7855, 3291, 24729, 13068, 10146, 2, 3, 5998, 4, 5, 123, 28138, 27677, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02362215332686901, -0.04671727865934372, -0.03321266174316406, -0.034287452697753906, -0.034287452697753906, -0.034287452697753906, -0.034287452697753906, -0.034287452697753906, -0.034287452697753906, -0.034287452697753906], "metadata": {"source_tokens": ["Standard", "&", "Poor", "'", "##s", "500", "-", "Stock", "Index", "climbed", "5", "##.", "##29", "to", "340", "##.", "##36", ",", "the", "Dow", "Jones", "Equity", "Market", "Index", "added", "4", "##.", "##70", "to", "31", "##8", "##.", "##7", "##9", "and", "the", "New", "York", "Stock", "Exchange", "Co", "##mpo", "##site", "Index", "climbed", "2", "##.", "##65", "to"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Dow", "Jones", "Equity", "Market", "Index", "[unused2]", "[unused3]", "added", "[unused4]", "[unused5]", "4", "##.", "##70", "to", "31", "##8", "##.", "##7", "##9", "[unused6]", "[SEP]", "[unused1]", "the", "New", "York", "Stock", "Exchange", "Co", "##mpo", "##site", "Index", "[unused2]", "[unused3]", "climbed", "[unused4]", "[unused5]", "2", "##.", "##65", "[unused6]", "[SEP]"]]}

input 551:  {"source": "Strong sales so far this year are certain to turn the tide , but even the 25 % market share that Nissan expects in 1989 will leave it far below its position at the beginning of the decade .\n"}
prediction:  {"predictions": [[1, 1256, 1103, 1512, 110, 2319, 2934, 1115, 17574, 27402, 1107, 2056, 2, 3, 1209, 1817, 4, 5, 1122, 1677, 2071, 1157, 1700, 1120, 1103, 2150, 1104, 1103, 4967, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11661, 3813, 1177, 1677, 1142, 1214, 2, 3, 1132, 4, 5, 2218, 1106, 1885, 1103, 12600, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0224236398935318, -0.055052950978279114, -0.2263169288635254, -0.22562456130981445, -0.22562456130981445, -0.22562456130981445, -0.22562456130981445, -0.22562456130981445, -0.22562456130981445, -0.22562456130981445], "metadata": {"source_tokens": ["Strong", "sales", "so", "far", "this", "year", "are", "certain", "to", "turn", "the", "tide", ",", "but", "even", "the", "25", "%", "market", "share", "that", "Nissan", "expects", "in", "1989", "will", "leave", "it", "far", "below", "its", "position", "at", "the", "beginning", "of", "the", "decade", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "even", "the", "25", "%", "market", "share", "that", "Nissan", "expects", "in", "1989", "[unused2]", "[unused3]", "will", "leave", "[unused4]", "[unused5]", "it", "far", "below", "its", "position", "at", "the", "beginning", "of", "the", "decade", "[unused6]", "[SEP]", "[unused1]", "Strong", "sales", "so", "far", "this", "year", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "certain", "to", "turn", "the", "tide", "[unused6]", "[SEP]"]]}

input 552:  {"source": "Student job postings at Boston University slip 10 % this year following a 10 % drop in 1988 .\n"}
prediction:  {"predictions": [[1, 7646, 2261, 15537, 1116, 1120, 2859, 1239, 2, 3, 7324, 4, 5, 1275, 110, 1142, 1214, 1378, 170, 1275, 110, 3968, 1107, 2115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.001918572699651122, -0.01440572738647461, -0.013136863708496094, -0.013136863708496094, -0.013136863708496094, -0.013136863708496094, -0.013136863708496094, -0.013136863708496094, -0.013136863708496094, -0.013136863708496094], "metadata": {"source_tokens": ["Student", "job", "posting", "##s", "at", "Boston", "University", "slip", "10", "%", "this", "year", "following", "a", "10", "%", "drop", "in", "1988", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Student", "job", "posting", "##s", "at", "Boston", "University", "[unused2]", "[unused3]", "slip", "[unused4]", "[unused5]", "10", "%", "this", "year", "following", "a", "10", "%", "drop", "in", "1988", "[unused6]", "[SEP]"]]}

input 553:  {"source": "THE CHIEF NURSING officer can be responsible for more than 1,000 employees and at least one - third of a hospital 's budget ; a head nurse typically oversees up to 80 employees and $ 8 million .\n"}
prediction:  {"predictions": [[1, 7462, 24890, 17444, 2271, 151, 19556, 13882, 11780, 2575, 2, 3, 1169, 1129, 4, 5, 2784, 1111, 1167, 1190, 122, 28136, 7629, 1568, 4570, 1105, 1120, 1655, 1141, 118, 1503, 1104, 170, 2704, 112, 1116, 4788, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1246, 7439, 2, 3, 3417, 25312, 1146, 4, 5, 1146, 1106, 2908, 4570, 1105, 109, 129, 1550, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006131328176707029, -0.08979982137680054, -0.033901214599609375, -0.03394269943237305, -0.033942222595214844, -0.033942222595214844, -0.033942222595214844, -0.033942222595214844, -0.033942222595214844, -0.033942222595214844], "metadata": {"source_tokens": ["THE", "CH", "##IE", "##F", "N", "##UR", "##SI", "##NG", "officer", "can", "be", "responsible", "for", "more", "than", "1", "##,", "##00", "##0", "employees", "and", "at", "least", "one", "-", "third", "of", "a", "hospital", "'", "##s", "budget", ";", "a", "head", "nurse", "typically", "oversees", "up", "to", "80", "employees", "and", "$", "8", "million", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "THE", "CH", "##IE", "##F", "N", "##UR", "##SI", "##NG", "officer", "[unused2]", "[unused3]", "can", "be", "[unused4]", "[unused5]", "responsible", "for", "more", "than", "1", "##,", "##00", "##0", "employees", "and", "at", "least", "one", "-", "third", "of", "a", "hospital", "'", "##s", "budget", "[unused6]", "[SEP]", "[unused1]", "a", "head", "nurse", "[unused2]", "[unused3]", "typically", "oversees", "up", "[unused4]", "[unused5]", "up", "to", "80", "employees", "and", "$", "8", "million", "[unused6]", "[SEP]"]]}

input 554:  {"source": "Takeover stock traders noted that with the junk - bond market in disarray , Georgia - Pacific 's bid is an indication of where the takeover game is headed : namely , industrial companies can continue bidding for one another , but financial buyers such as leveraged buy - out firms will be at a disadvantage in obtaining financing .\n"}
prediction:  {"predictions": [[1, 5055, 5909, 4482, 14552, 2, 3, 2382, 4, 5, 1115, 1114, 1103, 22323, 118, 7069, 2319, 1107, 4267, 9724, 6447, 117, 3260, 118, 2662, 112, 1116, 6875, 1110, 1126, 12754, 1104, 1187, 1103, 17748, 1342, 1110, 2917, 131, 8199, 117, 3924, 2557, 1169, 2760, 19520, 1111, 1141, 1330, 117, 102, 1, 2798, 19682, 1216, 1112, 24228, 1181, 4417, 118, 1149, 9780, 2, 3, 1209, 1129, 4, 5, 1120, 170, 22611, 1107, 11621, 13080, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 17748, 1342, 2, 3, 1110, 2917, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3924, 2557, 2, 3, 1169, 2760, 19520, 4, 5, 1111, 1141, 1330, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3260, 118, 2662, 112, 1116, 6875, 2, 3, 1110, 4, 5, 1126, 12754, 1104, 1187, 1103, 17748, 1342, 1110, 2917, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03501375392079353, -0.08152782171964645, -0.18067407608032227, -0.09151792526245117, -0.10134176909923553, -0.08446788787841797, -0.08157873153686523, -0.08157873153686523, -0.08157873153686523, -0.08157873153686523], "metadata": {"source_tokens": ["Take", "##over", "stock", "traders", "noted", "that", "with", "the", "junk", "-", "bond", "market", "in", "di", "##sar", "##ray", ",", "Georgia", "-", "Pacific", "'", "##s", "bid", "is", "an", "indication", "of", "where", "the", "takeover", "game", "is", "headed", ":", "namely", ",", "industrial", "companies", "can", "continue", "bidding", "for", "one", "another", ",", "but", "financial", "buyers", "such", "as", "leverage", "##d", "buy", "-", "out", "firms", "will", "be", "at", "a", "disadvantage", "in", "obtaining", "financing", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Take", "##over", "stock", "traders", "[unused2]", "[unused3]", "noted", "[unused4]", "[unused5]", "that", "with", "the", "junk", "-", "bond", "market", "in", "di", "##sar", "##ray", ",", "Georgia", "-", "Pacific", "'", "##s", "bid", "is", "an", "indication", "of", "where", "the", "takeover", "game", "is", "headed", ":", "namely", ",", "industrial", "companies", "can", "continue", "bidding", "for", "one", "another", ",", "[SEP]", "[unused1]", "financial", "buyers", "such", "as", "leverage", "##d", "buy", "-", "out", "firms", "[unused2]", "[unused3]", "will", "be", "[unused4]", "[unused5]", "at", "a", "disadvantage", "in", "obtaining", "financing", "[unused6]", "[SEP]", "[unused1]", "the", "takeover", "game", "[unused2]", "[unused3]", "is", "headed", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "industrial", "companies", "[unused2]", "[unused3]", "can", "continue", "bidding", "[unused4]", "[unused5]", "for", "one", "another", "[unused6]", "[SEP]", "[unused1]", "Georgia", "-", "Pacific", "'", "##s", "bid", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "indication", "of", "where", "the", "takeover", "game", "is", "headed", "[unused6]", "[SEP]"]]}

input 555:  {"source": "Technology stocks bore the brunt of the OTC market 's recent sell - off , and traders say it 's natural that they rebound sharply now that the market has turned around .\n"}
prediction:  {"predictions": [[1, 3529, 17901, 2, 3, 8475, 4, 5, 1103, 9304, 8355, 1104, 1103, 152, 9481, 2319, 112, 1116, 2793, 4582, 118, 1228, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 14552, 2, 3, 1474, 4, 5, 1122, 112, 1116, 2379, 1115, 1152, 1231, 8346, 8930, 1208, 1115, 1103, 2319, 1144, 1454, 1213, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0228907261043787, -0.08255936950445175, -0.05040931701660156, -0.0685572624206543, -0.0685572624206543, -0.0685572624206543, -0.0685572624206543, -0.0685572624206543, -0.0685572624206543, -0.0685572624206543], "metadata": {"source_tokens": ["Technology", "stocks", "bore", "the", "br", "##unt", "of", "the", "O", "##TC", "market", "'", "##s", "recent", "sell", "-", "off", ",", "and", "traders", "say", "it", "'", "##s", "natural", "that", "they", "re", "##bound", "sharply", "now", "that", "the", "market", "has", "turned", "around", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Technology", "stocks", "[unused2]", "[unused3]", "bore", "[unused4]", "[unused5]", "the", "br", "##unt", "of", "the", "O", "##TC", "market", "'", "##s", "recent", "sell", "-", "off", "[unused6]", "[SEP]", "[unused1]", "traders", "[unused2]", "[unused3]", "say", "[unused4]", "[unused5]", "it", "'", "##s", "natural", "that", "they", "re", "##bound", "sharply", "now", "that", "the", "market", "has", "turned", "around", "[unused6]", "[SEP]"]]}

input 556:  {"source": "That compares with 3.5 % butterfat for whole milk .\n"}
prediction:  {"predictions": [[1, 1337, 2, 3, 26153, 4, 5, 1114, 124, 28138, 1571, 110, 13742, 8057, 1204, 1111, 2006, 6831, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-3.328323509776965e-05, -0.020599842071533203, -0.020919322967529297, -0.020919322967529297, -0.020919322967529297, -0.020919322967529297, -0.020919322967529297, -0.020919322967529297, -0.020919322967529297, -0.020919322967529297], "metadata": {"source_tokens": ["That", "compares", "with", "3", "##.", "##5", "%", "butter", "##fa", "##t", "for", "whole", "milk", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "That", "[unused2]", "[unused3]", "compares", "[unused4]", "[unused5]", "with", "3", "##.", "##5", "%", "butter", "##fa", "##t", "for", "whole", "milk", "[unused6]", "[SEP]"]]}

input 557:  {"source": "The $ 150 million in senior subordinated floating - rate notes were targeted to be offered at a price to float four percentage points above the three - month LIBOR .\n"}
prediction:  {"predictions": [[1, 1109, 109, 4214, 1550, 1107, 2682, 16469, 1181, 8379, 118, 2603, 3697, 2, 3, 1127, 9271, 4, 5, 1106, 1129, 2356, 1120, 170, 3945, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 109, 4214, 1550, 1107, 2682, 16469, 1181, 8379, 118, 2603, 3697, 2, 3, 1106, 1129, 2356, 4, 5, 1120, 170, 3945, 1106, 15666, 1300, 6556, 1827, 1807, 1103, 1210, 118, 2370, 149, 27954, 9565, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01629665121436119, -0.03910807520151138, -0.019923686981201172, -0.02096843719482422, -0.02096843719482422, -0.02096843719482422, -0.02096843719482422, -0.02096843719482422, -0.02096843719482422, -0.02096843719482422], "metadata": {"source_tokens": ["The", "$", "150", "million", "in", "senior", "subordinate", "##d", "floating", "-", "rate", "notes", "were", "targeted", "to", "be", "offered", "at", "a", "price", "to", "float", "four", "percentage", "points", "above", "the", "three", "-", "month", "L", "##IB", "##OR", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "$", "150", "million", "in", "senior", "subordinate", "##d", "floating", "-", "rate", "notes", "[unused2]", "[unused3]", "were", "targeted", "[unused4]", "[unused5]", "to", "be", "offered", "at", "a", "price", "[unused6]", "[SEP]", "[unused1]", "The", "$", "150", "million", "in", "senior", "subordinate", "##d", "floating", "-", "rate", "notes", "[unused2]", "[unused3]", "to", "be", "offered", "[unused4]", "[unused5]", "at", "a", "price", "to", "float", "four", "percentage", "points", "above", "the", "three", "-", "month", "L", "##IB", "##OR", "[unused6]", "[SEP]"]]}

input 558:  {"source": "The 41 - year - old Mr. Azoff , a former rock 'n' roll manager , is credited with turning around MCA 's once - moribund music division in his six years at the company .\n"}
prediction:  {"predictions": [[1, 1109, 3746, 118, 1214, 118, 1385, 1828, 28138, 138, 6112, 3101, 2, 3, 1110, 5175, 4, 5, 1114, 3219, 1213, 24955, 112, 1116, 1517, 118, 182, 9012, 7925, 3276, 1390, 2417, 1107, 1117, 1565, 1201, 1120, 1103, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 3746, 1214, 1385, 1828, 28138, 138, 6112, 3101, 2, 3, 1110, 4, 5, 170, 1393, 2067, 112, 1179, 28131, 5155, 2618, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0009764607530087233, -0.06709904968738556, -0.015546321868896484, -0.016972064971923828, -0.016972064971923828, -0.016972064971923828, -0.016972064971923828, -0.016972064971923828, -0.016972064971923828, -0.016972064971923828], "metadata": {"source_tokens": ["The", "41", "-", "year", "-", "old", "Mr", "##.", "A", "##zo", "##ff", ",", "a", "former", "rock", "'", "##n", "##'", "roll", "manager", ",", "is", "credited", "with", "turning", "around", "MCA", "'", "##s", "once", "-", "m", "##ori", "##bu", "##nd", "music", "division", "in", "his", "six", "years", "at", "the", "company", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "41", "-", "year", "-", "old", "Mr", "##.", "A", "##zo", "##ff", "[unused2]", "[unused3]", "is", "credited", "[unused4]", "[unused5]", "with", "turning", "around", "MCA", "'", "##s", "once", "-", "m", "##ori", "##bu", "##nd", "music", "division", "in", "his", "six", "years", "at", "the", "company", "[unused6]", "[SEP]", "[unused1]", "The", "41", "year", "old", "Mr", "##.", "A", "##zo", "##ff", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "former", "rock", "'", "##n", "##'", "roll", "manager", "[unused6]", "[SEP]"]]}

input 559:  {"source": "The Chemical spokeswoman said the bank has examined its methodologies and internal controls .\n"}
prediction:  {"predictions": [[1, 1109, 10957, 2910, 1116, 9462, 2, 3, 1163, 4, 5, 1103, 3085, 1144, 8600, 1157, 3442, 20941, 1105, 4422, 7451, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0001075475083780475, -0.011173725128173828, -0.01023101806640625, -0.01023101806640625, -0.01023101806640625, -0.01023101806640625, -0.01023101806640625, -0.01023101806640625, -0.01023101806640625, -0.01023101806640625], "metadata": {"source_tokens": ["The", "Chemical", "spoke", "##s", "##woman", "said", "the", "bank", "has", "examined", "its", "method", "##ologies", "and", "internal", "controls", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Chemical", "spoke", "##s", "##woman", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "bank", "has", "examined", "its", "method", "##ologies", "and", "internal", "controls", "[unused6]", "[SEP]"]]}

input 560:  {"source": "The Lone Star Steel lawsuit also asks the court to rule that Lone Star Technologies is jointly responsible for a $ 4.5 million Lone Star Steel pension payment that was due , but was n't paid , in September and that the parent company ca n't recover the amount from its subsidiary if the parent company makes the payment .\n"}
prediction:  {"predictions": [[1, 1103, 6486, 1419, 2, 3, 11019, 183, 28131, 1204, 8680, 4, 5, 1103, 2971, 1121, 1157, 7049, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6486, 1419, 2, 3, 1129, 1144, 4, 5, 1109, 19511, 2537, 8180, 9680, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6486, 1419, 2, 3, 1129, 4, 5, 1103, 6486, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6486, 1419, 2, 3, 1129, 4, 5, 1103, 6486, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6486, 1419, 2, 3, 1129, 4, 5, 1103, 6486, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6486, 1419, 2, 3, 1129, 4, 5, 1103, 6486, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6486, 1419, 2, 3, 1129, 1129, 4, 5, 1103, 6486, 1419, 6, 102, 102, 102, 1, 1103, 6486, 1419, 2, 3, 1129, 1129, 4, 5, 1103, 6486, 1419, 6, 102, 102, 102, 1, 1103, 6486, 1419, 2, 3, 11019, 183, 28131, 1204, 8680, 4, 5, 1103, 2971, 1121, 1157, 7049, 1191, 1103, 6486, 1419, 2228, 1103, 7727, 6, 102, 102, 1, 1103, 6486, 2, 3, 1144, 4, 5, 1103, 6486, 1419, 6, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05780477449297905, -0.22375959157943726, -0.3383123278617859, -0.3429655432701111, -0.36586013436317444, -0.3799314796924591, -0.4051527678966522, -0.4168921113014221, -0.1428249180316925, -0.3788301646709442], "metadata": {"source_tokens": ["The", "Lone", "Star", "Steel", "lawsuit", "also", "asks", "the", "court", "to", "rule", "that", "Lone", "Star", "Technologies", "is", "jointly", "responsible", "for", "a", "$", "4", "##.", "##5", "million", "Lone", "Star", "Steel", "pension", "payment", "that", "was", "due", ",", "but", "was", "n", "##'", "##t", "paid", ",", "in", "September", "and", "that", "the", "parent", "company", "ca", "n", "##'", "##t", "recover", "the", "amount", "from", "its", "subsidiary", "if", "the", "parent", "company", "makes", "the", "payment", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "ca", "n", "##'", "##t", "recover", "[unused4]", "[unused5]", "the", "amount", "from", "its", "subsidiary", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "be", "has", "[unused4]", "[unused5]", "The", "Lone", "Star", "Steel", "lawsuit", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "be", "[unused4]", "[unused5]", "the", "parent", "company", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "be", "[unused4]", "[unused5]", "the", "parent", "company", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "be", "[unused4]", "[unused5]", "the", "parent", "company", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "be", "[unused4]", "[unused5]", "the", "parent", "company", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "be", "be", "[unused4]", "[unused5]", "the", "parent", "company", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "be", "be", "[unused4]", "[unused5]", "the", "parent", "company", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "ca", "n", "##'", "##t", "recover", "[unused4]", "[unused5]", "the", "amount", "from", "its", "subsidiary", "if", "the", "parent", "company", "makes", "the", "payment", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "the", "parent", "company", "[unused6]", "[SEP]"]]}

input 561:  {"source": "The National Transportation Safety Board ruled that pilots failed to set the plane 's wing flaps and slats properly for takeoff and failed to make mandatory preflight checks that would have detected the error .\n"}
prediction:  {"predictions": [[1, 1109, 1305, 8373, 9218, 2464, 2, 3, 4741, 4, 5, 1115, 8486, 2604, 1106, 1383, 1103, 4261, 112, 1116, 3092, 23841, 1116, 1105, 188, 16236, 1116, 7513, 1111, 22149, 1105, 2604, 1106, 1294, 11839, 3073, 2087, 4568, 15008, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8486, 2, 3, 2604, 4, 5, 1106, 1383, 1103, 4261, 112, 1116, 3092, 23841, 23841, 1116, 1105, 188, 16236, 1116, 7513, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11839, 3073, 2087, 4568, 15008, 2, 3, 1156, 1138, 11168, 4, 5, 1103, 7353, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013009920716285706, -0.137797012925148, -0.10255065560340881, -0.10183525085449219, -0.10269498825073242, -0.10269498825073242, -0.10269498825073242, -0.10269498825073242, -0.10269498825073242, -0.10269498825073242], "metadata": {"source_tokens": ["The", "National", "Transportation", "Safety", "Board", "ruled", "that", "pilots", "failed", "to", "set", "the", "plane", "'", "##s", "wing", "flap", "##s", "and", "s", "##lat", "##s", "properly", "for", "takeoff", "and", "failed", "to", "make", "mandatory", "pre", "##f", "##light", "checks", "that", "would", "have", "detected", "the", "error", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "National", "Transportation", "Safety", "Board", "[unused2]", "[unused3]", "ruled", "[unused4]", "[unused5]", "that", "pilots", "failed", "to", "set", "the", "plane", "'", "##s", "wing", "flap", "##s", "and", "s", "##lat", "##s", "properly", "for", "takeoff", "and", "failed", "to", "make", "mandatory", "pre", "##f", "##light", "checks", "[unused6]", "[SEP]", "[unused1]", "pilots", "[unused2]", "[unused3]", "failed", "[unused4]", "[unused5]", "to", "set", "the", "plane", "'", "##s", "wing", "flap", "flap", "##s", "and", "s", "##lat", "##s", "properly", "[unused6]", "[SEP]", "[unused1]", "mandatory", "pre", "##f", "##light", "checks", "[unused2]", "[unused3]", "would", "have", "detected", "[unused4]", "[unused5]", "the", "error", "[unused6]", "[SEP]"]]}

input 562:  {"source": "The New Orleans oil and gas exploration and diving operations company added that it does n't expect any further adverse financial impact from the restructuring .\n"}
prediction:  {"predictions": [[1, 1109, 1203, 5705, 2949, 1105, 3245, 10016, 1105, 10398, 2500, 1419, 2, 3, 1896, 4, 5, 1115, 1122, 1674, 183, 28131, 1204, 5363, 1251, 1748, 16798, 2798, 3772, 1121, 1103, 20841, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1674, 183, 28131, 1204, 5363, 4, 5, 1251, 1748, 16798, 2798, 3772, 1121, 1103, 20841, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0009112077532336116, -0.006698256358504295, -0.03991127014160156, -0.043764591217041016, -0.043764591217041016, -0.043764591217041016, -0.043764591217041016, -0.043764591217041016, -0.043764591217041016, -0.043764591217041016], "metadata": {"source_tokens": ["The", "New", "Orleans", "oil", "and", "gas", "exploration", "and", "diving", "operations", "company", "added", "that", "it", "does", "n", "##'", "##t", "expect", "any", "further", "adverse", "financial", "impact", "from", "the", "restructuring", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "New", "Orleans", "oil", "and", "gas", "exploration", "and", "diving", "operations", "company", "[unused2]", "[unused3]", "added", "[unused4]", "[unused5]", "that", "it", "does", "n", "##'", "##t", "expect", "any", "further", "adverse", "financial", "impact", "from", "the", "restructuring", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "does", "n", "##'", "##t", "expect", "[unused4]", "[unused5]", "any", "further", "adverse", "financial", "impact", "from", "the", "restructuring", "[unused6]", "[SEP]"]]}

input 563:  {"source": "The Second Section index , which fell 36.87 points Friday , was down 21.44 points , or 0.59 % , to close at 3636.06 .\n"}
prediction:  {"predictions": [[1, 1109, 2307, 6177, 7448, 2, 3, 2204, 4, 5, 3164, 28138, 1604, 1559, 1827, 5286, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2307, 6177, 7448, 2, 3, 1108, 4, 5, 1205, 1626, 28138, 25041, 1827, 117, 1137, 121, 28138, 1571, 1580, 110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2307, 6177, 7448, 2, 3, 1108, 4, 5, 1205, 1626, 28138, 25041, 1827, 1137, 121, 28138, 1571, 1580, 110, 1106, 1601, 1120, 3164, 22997, 28138, 1568, 1545, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007431646343320608, -0.045960769057273865, -0.08202208578586578, -0.08322811126708984, -0.08251667022705078, -0.08251667022705078, -0.08251667022705078, -0.08251667022705078, -0.08251667022705078, -0.08251667022705078], "metadata": {"source_tokens": ["The", "Second", "Section", "index", ",", "which", "fell", "36", "##.", "##8", "##7", "points", "Friday", ",", "was", "down", "21", "##.", "##44", "points", ",", "or", "0", "##.", "##5", "##9", "%", ",", "to", "close", "at", "36", "##36", "##.", "##0", "##6", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Second", "Section", "index", "[unused2]", "[unused3]", "fell", "[unused4]", "[unused5]", "36", "##.", "##8", "##7", "points", "Friday", "[unused6]", "[SEP]", "[unused1]", "The", "Second", "Section", "index", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "down", "21", "##.", "##44", "points", ",", "or", "0", "##.", "##5", "##9", "%", "[unused6]", "[SEP]", "[unused1]", "The", "Second", "Section", "index", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "down", "21", "##.", "##44", "points", "or", "0", "##.", "##5", "##9", "%", "to", "close", "at", "36", "##36", "##.", "##0", "##6", "[unused6]", "[SEP]"]]}

input 564:  {"source": "The Soviets complicated the issue by offering to include light tanks , which are as light as 10 tons .\n"}
prediction:  {"predictions": [[1, 1109, 16359, 2, 3, 8277, 1103, 2486, 1118, 4733, 1106, 1511, 4, 5, 1609, 6977, 117, 1134, 1132, 1112, 1609, 1112, 1275, 5606, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0353657528758049, -0.12685489654541016, -0.1357731819152832, -0.1357731819152832, -0.1357731819152832, -0.1357731819152832, -0.1357731819152832, -0.1357731819152832, -0.1357731819152832, -0.1357731819152832], "metadata": {"source_tokens": ["The", "Soviets", "complicated", "the", "issue", "by", "offering", "to", "include", "light", "tanks", ",", "which", "are", "as", "light", "as", "10", "tons", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Soviets", "[unused2]", "[unused3]", "complicated", "the", "issue", "by", "offering", "to", "include", "[unused4]", "[unused5]", "light", "tanks", ",", "which", "are", "as", "light", "as", "10", "tons", "[unused6]", "[SEP]"]]}

input 565:  {"source": "The U.S. market , too , is dominated by a giant , International Business Machines Corp .\n"}
prediction:  {"predictions": [[1, 1109, 158, 28138, 1708, 28138, 2319, 2, 3, 1110, 6226, 4, 5, 1118, 170, 4994, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4994, 2, 3, 1129, 1129, 1129, 1129, 1129, 1129, 4, 5, 1570, 3518, 7792, 1116, 13619, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.030775539577007294, -0.23712924122810364, -0.02442455291748047, -0.023772716522216797, -0.023772716522216797, -0.023772716522216797, -0.023772716522216797, -0.023772716522216797, -0.023772716522216797, -0.023772716522216797], "metadata": {"source_tokens": ["The", "U", "##.", "##S", "##.", "market", ",", "too", ",", "is", "dominated", "by", "a", "giant", ",", "International", "Business", "Machine", "##s", "Corp", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "U", "##.", "##S", "##.", "market", "[unused2]", "[unused3]", "is", "dominated", "[unused4]", "[unused5]", "by", "a", "giant", "[unused6]", "[SEP]", "[unused1]", "a", "giant", "[unused2]", "[unused3]", "be", "be", "be", "be", "be", "be", "[unused4]", "[unused5]", "International", "Business", "Machine", "##s", "Corp", "[unused6]", "[SEP]"]]}

input 566:  {"source": "The basket product , while it has got off to a slow start , is being supported by some big brokerage firms -- another member of Mr. Phelan 's splintered constituency .\n"}
prediction:  {"predictions": [[1, 1109, 12916, 3317, 2, 3, 1110, 1217, 2726, 4, 5, 1118, 1199, 1992, 24535, 2553, 9780, 1229, 1122, 1144, 1400, 1228, 1106, 170, 3345, 1838, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1199, 1992, 24535, 2553, 9780, 2, 3, 1129, 1330, 1420, 1104, 1828, 28138, 7642, 9945, 1179, 112, 1116, 188, 1643, 22761, 5686, 5269, 1104, 4, 5, 1828, 28138, 7642, 9945, 1179, 112, 1116, 188, 1643, 22761, 5686, 5269, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05176667124032974, -0.06724945455789566, -0.0818476676940918, -0.08307743072509766, -0.08307743072509766, -0.08307743072509766, -0.08307743072509766, -0.08307743072509766, -0.08307743072509766, -0.08307743072509766], "metadata": {"source_tokens": ["The", "basket", "product", ",", "while", "it", "has", "got", "off", "to", "a", "slow", "start", ",", "is", "being", "supported", "by", "some", "big", "broker", "##age", "firms", "-", "##-", "another", "member", "of", "Mr", "##.", "Ph", "##ela", "##n", "'", "##s", "s", "##p", "##lint", "##ered", "constituency", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "basket", "product", "[unused2]", "[unused3]", "is", "being", "supported", "[unused4]", "[unused5]", "by", "some", "big", "broker", "##age", "firms", "while", "it", "has", "got", "off", "to", "a", "slow", "start", "[unused6]", "[SEP]", "[unused1]", "some", "big", "broker", "##age", "firms", "[unused2]", "[unused3]", "be", "another", "member", "of", "Mr", "##.", "Ph", "##ela", "##n", "'", "##s", "s", "##p", "##lint", "##ered", "constituency", "of", "[unused4]", "[unused5]", "Mr", "##.", "Ph", "##ela", "##n", "'", "##s", "s", "##p", "##lint", "##ered", "constituency", "[unused6]", "[SEP]"]]}

input 567:  {"source": "The campaign , a patriotic celebration of the 200th anniversary of the Bill of Rights , does n't mention cigarettes or smoking ; cigarette ads have been prohibited on television since 1971 .\n"}
prediction:  {"predictions": [[1, 9983, 17641, 2, 3, 1138, 1151, 11018, 4, 5, 1113, 1778, 1290, 2507, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2322, 2, 3, 1674, 183, 28131, 1204, 4734, 4, 5, 16595, 1137, 9987, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2322, 2, 3, 1110, 4, 5, 170, 22435, 7978, 1104, 1103, 2363, 1582, 5453, 1104, 1103, 2617, 1104, 5399, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04304385185241699, -0.012620246037840843, -0.005552619695663452, -0.011077404022216797, -0.011183738708496094, -0.011183738708496094, -0.011183738708496094, -0.011183738708496094, -0.011183738708496094, -0.011183738708496094], "metadata": {"source_tokens": ["The", "campaign", ",", "a", "patriotic", "celebration", "of", "the", "200", "##th", "anniversary", "of", "the", "Bill", "of", "Rights", ",", "does", "n", "##'", "##t", "mention", "cigarettes", "or", "smoking", ";", "cigarette", "ads", "have", "been", "prohibited", "on", "television", "since", "1971", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "cigarette", "ads", "[unused2]", "[unused3]", "have", "been", "prohibited", "[unused4]", "[unused5]", "on", "television", "since", "1971", "[unused6]", "[SEP]", "[unused1]", "The", "campaign", "[unused2]", "[unused3]", "does", "n", "##'", "##t", "mention", "[unused4]", "[unused5]", "cigarettes", "or", "smoking", "[unused6]", "[SEP]", "[unused1]", "The", "campaign", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "patriotic", "celebration", "of", "the", "200", "##th", "anniversary", "of", "the", "Bill", "of", "Rights", "[unused6]", "[SEP]"]]}

input 568:  {"source": "The centerpiece of that complex , the Landmark Tower , will be Japan 's tallest building when it is completed in 1993 .\n"}
prediction:  {"predictions": [[1, 1109, 2057, 9641, 1104, 1115, 2703, 2, 3, 1209, 1129, 4, 5, 1999, 112, 1116, 14369, 1459, 1165, 1122, 1110, 2063, 1107, 1949, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1115, 2703, 2, 3, 1110, 4, 5, 1103, 18405, 5646, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.003107584547251463, -0.01446411944925785, -0.06817770004272461, -0.07069015502929688, -0.07069015502929688, -0.07069015502929688, -0.07069015502929688, -0.07069015502929688, -0.07069015502929688, -0.07069015502929688], "metadata": {"source_tokens": ["The", "center", "##piece", "of", "that", "complex", ",", "the", "Landmark", "Tower", ",", "will", "be", "Japan", "'", "##s", "tallest", "building", "when", "it", "is", "completed", "in", "1993", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "center", "##piece", "of", "that", "complex", "[unused2]", "[unused3]", "will", "be", "[unused4]", "[unused5]", "Japan", "'", "##s", "tallest", "building", "when", "it", "is", "completed", "in", "1993", "[unused6]", "[SEP]", "[unused1]", "that", "complex", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "Landmark", "Tower", "[unused6]", "[SEP]"]]}

input 569:  {"source": "The company said the fastener business `` has been under severe cost pressures for some time . ''\n"}
prediction:  {"predictions": [[1, 1109, 1419, 2, 3, 1163, 4, 5, 1103, 2698, 24475, 1671, 169, 28152, 1144, 1151, 1223, 5199, 2616, 16390, 1111, 1199, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.001153545337729156, -0.028014659881591797, -0.027675151824951172, -0.027675151824951172, -0.027675151824951172, -0.027675151824951172, -0.027675151824951172, -0.027675151824951172, -0.027675151824951172, -0.027675151824951172], "metadata": {"source_tokens": ["The", "company", "said", "the", "fast", "##ener", "business", "`", "##`", "has", "been", "under", "severe", "cost", "pressures", "for", "some", "time", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "company", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "fast", "##ener", "business", "`", "##`", "has", "been", "under", "severe", "cost", "pressures", "for", "some", "time", "[unused6]", "[SEP]"]]}

input 570:  {"source": "The conviction stemmed from federal charges of consumer fraud for sale of phony infant apple juice between 1978 and 1983 .\n"}
prediction:  {"predictions": [[1, 1109, 10774, 2, 3, 8175, 4611, 4, 5, 1121, 2877, 4917, 1104, 8440, 10258, 1111, 4688, 1104, 185, 8613, 1183, 11551, 12075, 12362, 1206, 2406, 1105, 2278, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0053197224624454975, -0.02758026123046875, -0.024292469024658203, -0.024292469024658203, -0.024292469024658203, -0.024292469024658203, -0.024292469024658203, -0.024292469024658203, -0.024292469024658203, -0.024292469024658203], "metadata": {"source_tokens": ["The", "conviction", "stem", "##med", "from", "federal", "charges", "of", "consumer", "fraud", "for", "sale", "of", "p", "##hon", "##y", "infant", "apple", "juice", "between", "1978", "and", "1983", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "conviction", "[unused2]", "[unused3]", "stem", "##med", "[unused4]", "[unused5]", "from", "federal", "charges", "of", "consumer", "fraud", "for", "sale", "of", "p", "##hon", "##y", "infant", "apple", "juice", "between", "1978", "and", "1983", "[unused6]", "[SEP]"]]}

input 571:  {"source": "The discount rate on three - month Treasury bills rose slightly from the average rate at Monday 's auction to 7.79 % for a bond - equivalent yield of 8.04 % .\n"}
prediction:  {"predictions": [[1, 1109, 23290, 2603, 1113, 1210, 118, 2370, 11712, 10020, 2, 3, 3152, 4, 5, 2776, 1121, 1103, 1903, 2603, 1120, 6356, 112, 1116, 11046, 1106, 128, 28138, 1559, 1580, 110, 1111, 170, 7069, 118, 4976, 10972, 1104, 129, 28138, 1568, 1527, 110, 6, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014905574731528759, -0.1560978889465332, -0.14165735244750977, -0.14165735244750977, -0.14165735244750977, -0.14165735244750977, -0.14165735244750977, -0.14165735244750977, -0.14165735244750977, -0.14165735244750977], "metadata": {"source_tokens": ["The", "discount", "rate", "on", "three", "-", "month", "Treasury", "bills", "rose", "slightly", "from", "the", "average", "rate", "at", "Monday", "'", "##s", "auction", "to", "7", "##.", "##7", "##9", "%", "for", "a", "bond", "-", "equivalent", "yield", "of", "8", "##.", "##0", "##4", "%", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "discount", "rate", "on", "three", "-", "month", "Treasury", "bills", "[unused2]", "[unused3]", "rose", "[unused4]", "[unused5]", "slightly", "from", "the", "average", "rate", "at", "Monday", "'", "##s", "auction", "to", "7", "##.", "##7", "##9", "%", "for", "a", "bond", "-", "equivalent", "yield", "of", "8", "##.", "##0", "##4", "%", "[unused6]", "[SEP]"]]}

input 572:  {"source": "The dollar drew strength from the stock market 's climb .\n"}
prediction:  {"predictions": [[1, 1109, 8876, 2, 3, 3583, 4, 5, 3220, 1121, 1103, 4482, 2319, 112, 1116, 6767, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-3.634558743215166e-05, -0.011813640594482422, -0.011814594268798828, -0.011814594268798828, -0.011814594268798828, -0.011814594268798828, -0.011814594268798828, -0.011814594268798828, -0.011814594268798828, -0.011814594268798828], "metadata": {"source_tokens": ["The", "dollar", "drew", "strength", "from", "the", "stock", "market", "'", "##s", "climb", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "dollar", "[unused2]", "[unused3]", "drew", "[unused4]", "[unused5]", "strength", "from", "the", "stock", "market", "'", "##s", "climb", "[unused6]", "[SEP]"]]}

input 573:  {"source": "The effect is that lawsuits that might have been barred because they were filed too late could proceed because of the one - year extension .\n"}
prediction:  {"predictions": [[1, 1109, 2629, 2, 3, 1110, 4, 5, 1115, 23005, 1115, 1547, 1138, 1151, 17081, 1272, 1152, 1127, 5770, 1315, 1523, 1180, 10980, 1272, 1104, 1103, 1141, 118, 1214, 4973, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 23005, 1115, 1547, 1138, 1151, 17081, 1272, 1152, 1127, 5770, 1315, 1523, 2, 3, 1180, 10980, 4, 5, 1272, 1104, 1103, 1141, 118, 1214, 4973, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 23005, 2, 3, 1547, 1138, 1151, 17081, 4, 5, 1272, 1152, 1127, 5770, 1315, 1523, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.002428576350212097, -0.04441468045115471, -0.03769452124834061, -0.10267305374145508, -0.08936214447021484, -0.08936214447021484, -0.08936214447021484, -0.08936214447021484, -0.08936214447021484, -0.08936214447021484], "metadata": {"source_tokens": ["The", "effect", "is", "that", "lawsuits", "that", "might", "have", "been", "barred", "because", "they", "were", "filed", "too", "late", "could", "proceed", "because", "of", "the", "one", "-", "year", "extension", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "effect", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "that", "lawsuits", "that", "might", "have", "been", "barred", "because", "they", "were", "filed", "too", "late", "could", "proceed", "because", "of", "the", "one", "-", "year", "extension", "[unused6]", "[SEP]", "[unused1]", "lawsuits", "that", "might", "have", "been", "barred", "because", "they", "were", "filed", "too", "late", "[unused2]", "[unused3]", "could", "proceed", "[unused4]", "[unused5]", "because", "of", "the", "one", "-", "year", "extension", "[unused6]", "[SEP]", "[unused1]", "lawsuits", "[unused2]", "[unused3]", "might", "have", "been", "barred", "[unused4]", "[unused5]", "because", "they", "were", "filed", "too", "late", "[unused6]", "[SEP]"]]}

input 574:  {"source": "The executives had profited handsomely by building American National Can Co. , Triangle 's chief asset .\n"}
prediction:  {"predictions": [[1, 1109, 14011, 2, 3, 1125, 5022, 1174, 8542, 1193, 4, 5, 1118, 1459, 1237, 1305, 2825, 3291, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1459, 1237, 1305, 2825, 3291, 28138, 2, 3, 1110, 4, 5, 20742, 112, 1116, 2705, 13274, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03623794764280319, -0.08449327200651169, -0.0293121337890625, -0.02646780014038086, -0.02646780014038086, -0.02646780014038086, -0.02646780014038086, -0.02646780014038086, -0.02646780014038086, -0.02646780014038086], "metadata": {"source_tokens": ["The", "executives", "had", "profit", "##ed", "handsome", "##ly", "by", "building", "American", "National", "Can", "Co", "##.", ",", "Triangle", "'", "##s", "chief", "asset", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "executives", "[unused2]", "[unused3]", "had", "profit", "##ed", "handsome", "##ly", "[unused4]", "[unused5]", "by", "building", "American", "National", "Can", "Co", "##.", "[unused6]", "[SEP]", "[unused1]", "building", "American", "National", "Can", "Co", "##.", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Triangle", "'", "##s", "chief", "asset", "[unused6]", "[SEP]"]]}

input 575:  {"source": "The field took off in 1985 after scientists at Britain 's Sheffield University developed a handy , compact magnet for brain stimulation .\n"}
prediction:  {"predictions": [[1, 1109, 1768, 2, 3, 1261, 1228, 4, 5, 1107, 2210, 1170, 6479, 1120, 2855, 112, 1116, 8139, 1239, 1872, 170, 25997, 117, 10114, 24197, 1111, 3575, 23842, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0011601607548072934, -0.06206655502319336, -0.062120914459228516, -0.062120914459228516, -0.062120914459228516, -0.062120914459228516, -0.062120914459228516, -0.062120914459228516, -0.062120914459228516, -0.062120914459228516], "metadata": {"source_tokens": ["The", "field", "took", "off", "in", "1985", "after", "scientists", "at", "Britain", "'", "##s", "Sheffield", "University", "developed", "a", "handy", ",", "compact", "magnet", "for", "brain", "stimulation", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "field", "[unused2]", "[unused3]", "took", "off", "[unused4]", "[unused5]", "in", "1985", "after", "scientists", "at", "Britain", "'", "##s", "Sheffield", "University", "developed", "a", "handy", ",", "compact", "magnet", "for", "brain", "stimulation", "[unused6]", "[SEP]"]]}

input 576:  {"source": "The fitness craze itself has gone soft , the survey found .\n"}
prediction:  {"predictions": [[1, 1103, 5980, 2, 3, 1276, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 12691, 172, 26342, 2111, 2, 3, 1144, 2065, 4, 5, 2991, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06160106509923935, -0.03528207913041115, -0.029089927673339844, -0.026009559631347656, -0.026009559631347656, -0.026009559631347656, -0.026009559631347656, -0.026009559631347656, -0.026009559631347656, -0.026009559631347656], "metadata": {"source_tokens": ["The", "fitness", "c", "##raze", "itself", "has", "gone", "soft", ",", "the", "survey", "found", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "survey", "[unused2]", "[unused3]", "found", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "The", "fitness", "c", "##raze", "itself", "[unused2]", "[unused3]", "has", "gone", "[unused4]", "[unused5]", "soft", "[unused6]", "[SEP]"]]}

input 577:  {"source": "The forest - products concern currently has about 38 million shares outstanding .\n"}
prediction:  {"predictions": [[1, 1109, 3304, 118, 2982, 4517, 2, 3, 1144, 4, 5, 1164, 3383, 1550, 6117, 6976, 1971, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2, 3, 1144, 4, 5, 1164, 3383, 1550, 6117, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0013973838649690151, -0.21775832772254944, -0.1140289306640625, -0.10276508331298828, -0.10276508331298828, -0.10276508331298828, -0.10276508331298828, -0.10276508331298828, -0.10276508331298828, -0.10276508331298828], "metadata": {"source_tokens": ["The", "forest", "-", "products", "concern", "currently", "has", "about", "38", "million", "shares", "outstanding", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "forest", "-", "products", "concern", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "about", "38", "million", "shares", "outstanding", "currently", "[unused6]", "[SEP]", "[unused1]", "The", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "about", "38", "million", "shares", "[unused6]", "[SEP]"]]}

input 578:  {"source": "The government , already buffeted by high interest rates and a slowing economy , has been badly hurt by last week 's shake - up in Mrs. Thatcher 's cabinet .\n"}
prediction:  {"predictions": [[1, 1109, 1433, 2, 3, 171, 9435, 27860, 4, 5, 1118, 1344, 2199, 5600, 1105, 170, 20098, 4190, 1640, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1433, 117, 1640, 171, 9435, 27860, 1118, 1344, 2199, 5600, 1105, 170, 20098, 4190, 2, 3, 1144, 1151, 6118, 2644, 4, 5, 1118, 1314, 1989, 112, 1116, 5854, 118, 1146, 1107, 2823, 28138, 23300, 112, 1116, 6109, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.040571730583906174, -0.03702741861343384, -0.03825569152832031, -0.036429405212402344, -0.036429405212402344, -0.036429405212402344, -0.036429405212402344, -0.036429405212402344, -0.036429405212402344, -0.036429405212402344], "metadata": {"source_tokens": ["The", "government", ",", "already", "b", "##uff", "##eted", "by", "high", "interest", "rates", "and", "a", "slowing", "economy", ",", "has", "been", "badly", "hurt", "by", "last", "week", "'", "##s", "shake", "-", "up", "in", "Mrs", "##.", "Thatcher", "'", "##s", "cabinet", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "government", "[unused2]", "[unused3]", "b", "##uff", "##eted", "[unused4]", "[unused5]", "by", "high", "interest", "rates", "and", "a", "slowing", "economy", "already", "[unused6]", "[SEP]", "[unused1]", "The", "government", ",", "already", "b", "##uff", "##eted", "by", "high", "interest", "rates", "and", "a", "slowing", "economy", "[unused2]", "[unused3]", "has", "been", "badly", "hurt", "[unused4]", "[unused5]", "by", "last", "week", "'", "##s", "shake", "-", "up", "in", "Mrs", "##.", "Thatcher", "'", "##s", "cabinet", "[unused6]", "[SEP]"]]}

input 579:  {"source": "The issue is backed by a 12 % letter of credit from Credit Suisse .\n"}
prediction:  {"predictions": [[1, 1109, 2486, 2, 3, 1110, 5534, 4, 5, 1118, 170, 1367, 110, 2998, 1104, 4755, 1121, 14032, 15463, 19202, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-2.1235509848338552e-05, -0.01870250701904297, -0.017467498779296875, -0.017467498779296875, -0.017467498779296875, -0.017467498779296875, -0.017467498779296875, -0.017467498779296875, -0.017467498779296875, -0.017467498779296875], "metadata": {"source_tokens": ["The", "issue", "is", "backed", "by", "a", "12", "%", "letter", "of", "credit", "from", "Credit", "Su", "##isse", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "issue", "[unused2]", "[unused3]", "is", "backed", "[unused4]", "[unused5]", "by", "a", "12", "%", "letter", "of", "credit", "from", "Credit", "Su", "##isse", "[unused6]", "[SEP]"]]}

input 580:  {"source": "The last time IBM tapped the corporate debt market was in April 1988 , when it offered $ 500 million of debt securities .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 2356, 4, 5, 109, 2260, 1550, 1104, 6695, 19313, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9768, 10316, 1103, 6214, 6695, 2319, 2, 3, 1108, 4, 5, 1107, 1364, 2115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.052684273570775986, -0.03819889947772026, -0.07270050048828125, -0.07564544677734375, -0.07564544677734375, -0.07564544677734375, -0.07564544677734375, -0.07564544677734375, -0.07564544677734375, -0.07564544677734375], "metadata": {"source_tokens": ["The", "last", "time", "IBM", "tapped", "the", "corporate", "debt", "market", "was", "in", "April", "1988", ",", "when", "it", "offered", "$", "500", "million", "of", "debt", "securities", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "offered", "[unused4]", "[unused5]", "$", "500", "million", "of", "debt", "securities", "[unused6]", "[SEP]", "[unused1]", "IBM", "tapped", "the", "corporate", "debt", "market", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "in", "April", "1988", "[unused6]", "[SEP]"]]}

input 581:  {"source": "The latest 10 - year notes ended at about 100 16\\/32 to yield 7.90 % , compared with 100 11\\/32 to yield 7.93 % on Friday .\n"}
prediction:  {"predictions": [[1, 1109, 6270, 1275, 118, 1214, 3697, 2, 3, 2207, 4, 5, 1120, 1164, 1620, 1479, 28148, 28139, 17101, 1106, 10972, 128, 28138, 21500, 110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 6270, 1275, 118, 1214, 3697, 2, 3, 2207, 4, 5, 1120, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 1164, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.036643363535404205, -0.49456557631492615, -0.2582979202270508, -0.24594402313232422, -0.24594402313232422, -0.24594402313232422, -0.24594402313232422, -0.24594402313232422, -0.24594402313232422, -0.24594402313232422], "metadata": {"source_tokens": ["The", "latest", "10", "-", "year", "notes", "ended", "at", "about", "100", "16", "##\\", "##/", "##32", "to", "yield", "7", "##.", "##90", "%", ",", "compared", "with", "100", "11", "##\\", "##/", "##32", "to", "yield", "7", "##.", "##9", "##3", "%", "on", "Friday", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "latest", "10", "-", "year", "notes", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "at", "about", "100", "16", "##\\", "##/", "##32", "to", "yield", "7", "##.", "##90", "%", "[unused6]", "[SEP]", "[unused1]", "The", "latest", "10", "-", "year", "notes", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "at", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "about", "[SEP]"]]}

input 582:  {"source": "The market 's tempo was helped by the dollar 's resiliency , he said .\n"}
prediction:  {"predictions": [[1, 1109, 2319, 112, 1116, 16655, 2, 3, 1108, 2375, 4, 5, 1118, 1103, 8876, 112, 1116, 1231, 5053, 7174, 7232, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1163, 4, 5, 1109, 2319, 112, 1116, 16655, 1108, 2375, 1118, 1103, 8876, 112, 1116, 1231, 5053, 7174, 7232, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0013733584200963378, -0.09077410399913788, -0.2232351303100586, -0.23308753967285156, -0.23308706283569336, -0.23308801651000977, -0.23308801651000977, -0.23308801651000977, -0.23308801651000977, -0.23308801651000977], "metadata": {"source_tokens": ["The", "market", "'", "##s", "tempo", "was", "helped", "by", "the", "dollar", "'", "##s", "re", "##si", "##lie", "##ncy", ",", "he", "said", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "market", "'", "##s", "tempo", "[unused2]", "[unused3]", "was", "helped", "[unused4]", "[unused5]", "by", "the", "dollar", "'", "##s", "re", "##si", "##lie", "##ncy", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "The", "market", "'", "##s", "tempo", "was", "helped", "by", "the", "dollar", "'", "##s", "re", "##si", "##lie", "##ncy", "[unused6]", "[SEP]"]]}

input 583:  {"source": "The offering was priced with an 8.95 % coupon rate at 99.1875 % to yield 9.19 % .\n"}
prediction:  {"predictions": [[1, 1109, 4733, 2, 3, 1108, 23812, 4, 5, 1114, 1126, 129, 28138, 1580, 1571, 110, 8707, 1320, 2603, 1120, 4850, 28138, 15292, 26253, 110, 1106, 10972, 130, 28138, 16382, 110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007663300726562738, -0.08439302444458008, -0.08730125427246094, -0.08730125427246094, -0.08730125427246094, -0.08730125427246094, -0.08730125427246094, -0.08730125427246094, -0.08730125427246094, -0.08730125427246094], "metadata": {"source_tokens": ["The", "offering", "was", "priced", "with", "an", "8", "##.", "##9", "##5", "%", "coup", "##on", "rate", "at", "99", "##.", "##18", "##75", "%", "to", "yield", "9", "##.", "##19", "%", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "offering", "[unused2]", "[unused3]", "was", "priced", "[unused4]", "[unused5]", "with", "an", "8", "##.", "##9", "##5", "%", "coup", "##on", "rate", "at", "99", "##.", "##18", "##75", "%", "to", "yield", "9", "##.", "##19", "%", "[unused6]", "[SEP]"]]}

input 584:  {"source": "The office may also be able to advise foreign and multinational clients on international law and general matters .\n"}
prediction:  {"predictions": [[1, 1109, 1701, 2, 3, 1336, 1145, 1129, 4, 5, 1682, 1106, 19961, 2880, 1105, 24924, 7550, 1113, 1835, 1644, 1105, 1704, 5218, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00012580871407408267, -0.02321910858154297, -0.02845478057861328, -0.02845478057861328, -0.02845478057861328, -0.02845478057861328, -0.02845478057861328, -0.02845478057861328, -0.02845478057861328, -0.02845478057861328], "metadata": {"source_tokens": ["The", "office", "may", "also", "be", "able", "to", "advise", "foreign", "and", "multinational", "clients", "on", "international", "law", "and", "general", "matters", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "office", "[unused2]", "[unused3]", "may", "also", "be", "[unused4]", "[unused5]", "able", "to", "advise", "foreign", "and", "multinational", "clients", "on", "international", "law", "and", "general", "matters", "[unused6]", "[SEP]"]]}

input 585:  {"source": "The operative definition of newsworthiness will favor virtually unrestrained use of personal , sensitive and intimate facts .\n"}
prediction:  {"predictions": [[1, 1109, 13035, 5754, 1104, 2371, 4189, 8405, 2, 3, 1209, 5010, 4, 5, 9024, 18366, 11098, 1174, 1329, 1104, 2357, 117, 7246, 1105, 10666, 9193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00010326930350856856, -0.037966251373291016, -0.0364532470703125, -0.0364532470703125, -0.0364532470703125, -0.0364532470703125, -0.0364532470703125, -0.0364532470703125, -0.0364532470703125, -0.0364532470703125], "metadata": {"source_tokens": ["The", "operative", "definition", "of", "news", "##worth", "##iness", "will", "favor", "virtually", "unrest", "##rain", "##ed", "use", "of", "personal", ",", "sensitive", "and", "intimate", "facts", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "operative", "definition", "of", "news", "##worth", "##iness", "[unused2]", "[unused3]", "will", "favor", "[unused4]", "[unused5]", "virtually", "unrest", "##rain", "##ed", "use", "of", "personal", ",", "sensitive", "and", "intimate", "facts", "[unused6]", "[SEP]"]]}

input 586:  {"source": "The price was n't disclosed but one analyst estimated that it was $ 150 million .\n"}
prediction:  {"predictions": [[1, 1141, 14582, 2, 3, 3555, 4, 5, 1115, 1122, 1108, 109, 4214, 1550, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 3945, 2, 3, 1108, 183, 28131, 1204, 23617, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02648913860321045, -0.01576421968638897, -0.04193258285522461, -0.041290283203125, -0.041290283203125, -0.041290283203125, -0.041290283203125, -0.041290283203125, -0.041290283203125, -0.041290283203125], "metadata": {"source_tokens": ["The", "price", "was", "n", "##'", "##t", "disclosed", "but", "one", "analyst", "estimated", "that", "it", "was", "$", "150", "million", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "one", "analyst", "[unused2]", "[unused3]", "estimated", "[unused4]", "[unused5]", "that", "it", "was", "$", "150", "million", "[unused6]", "[SEP]", "[unused1]", "The", "price", "[unused2]", "[unused3]", "was", "n", "##'", "##t", "disclosed", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 587:  {"source": "The prices of most corn , soybean and wheat futures contracts dropped slightly as farmers in the Midwest continued to rebuild stockpiles that were depleted by the 1988 drought .\n"}
prediction:  {"predictions": [[1, 1109, 7352, 1104, 1211, 11184, 117, 1177, 1183, 3962, 1389, 1105, 11773, 2174, 1116, 8216, 2, 3, 2434, 4, 5, 2776, 1112, 6915, 1107, 1103, 14661, 1598, 1106, 15596, 4482, 24898, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6915, 1107, 1103, 14661, 2, 3, 1598, 4, 5, 1106, 15596, 4482, 24898, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6915, 1107, 1103, 14661, 2, 3, 1598, 4, 5, 1106, 15596, 4482, 24898, 1116, 1115, 1127, 25403, 1118, 1103, 2115, 16076, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.037397004663944244, -0.10196992009878159, -0.10269547253847122, -0.09484243392944336, -0.0864858627319336, -0.0864858627319336, -0.0864858627319336, -0.0864858627319336, -0.0864858627319336, -0.0864858627319336], "metadata": {"source_tokens": ["The", "prices", "of", "most", "corn", ",", "so", "##y", "##be", "##an", "and", "wheat", "future", "##s", "contracts", "dropped", "slightly", "as", "farmers", "in", "the", "Midwest", "continued", "to", "rebuild", "stock", "##pile", "##s", "that", "were", "depleted", "by", "the", "1988", "drought", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "prices", "of", "most", "corn", ",", "so", "##y", "##be", "##an", "and", "wheat", "future", "##s", "contracts", "[unused2]", "[unused3]", "dropped", "[unused4]", "[unused5]", "slightly", "as", "farmers", "in", "the", "Midwest", "continued", "to", "rebuild", "stock", "##pile", "##s", "[unused6]", "[SEP]", "[unused1]", "farmers", "in", "the", "Midwest", "[unused2]", "[unused3]", "continued", "[unused4]", "[unused5]", "to", "rebuild", "stock", "##pile", "##s", "[unused6]", "[SEP]", "[unused1]", "farmers", "in", "the", "Midwest", "[unused2]", "[unused3]", "continued", "[unused4]", "[unused5]", "to", "rebuild", "stock", "##pile", "##s", "that", "were", "depleted", "by", "the", "1988", "drought", "[unused6]", "[SEP]"]]}

input 588:  {"source": "The senior subordinated debentures maturing in 2004 are targeted to be offered at a yield of between 12 5\\/8 % to 12 3\\/4 % .\n"}
prediction:  {"predictions": [[1, 1109, 2682, 16469, 1181, 1260, 19145, 10374, 22591, 6660, 1107, 1516, 2, 3, 1132, 9271, 4, 5, 1106, 1129, 2356, 1120, 170, 10972, 1104, 1206, 1367, 126, 28148, 28139, 1604, 110, 1106, 1367, 124, 28148, 28139, 1527, 110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0026849163696169853, -0.04775524139404297, -0.04767751693725586, -0.04767751693725586, -0.04767751693725586, -0.04767751693725586, -0.04767751693725586, -0.04767751693725586, -0.04767751693725586, -0.04767751693725586], "metadata": {"source_tokens": ["The", "senior", "subordinate", "##d", "de", "##bent", "##ures", "mat", "##uring", "in", "2004", "are", "targeted", "to", "be", "offered", "at", "a", "yield", "of", "between", "12", "5", "##\\", "##/", "##8", "%", "to", "12", "3", "##\\", "##/", "##4", "%", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "senior", "subordinate", "##d", "de", "##bent", "##ures", "mat", "##uring", "in", "2004", "[unused2]", "[unused3]", "are", "targeted", "[unused4]", "[unused5]", "to", "be", "offered", "at", "a", "yield", "of", "between", "12", "5", "##\\", "##/", "##8", "%", "to", "12", "3", "##\\", "##/", "##4", "%", "[unused6]", "[SEP]"]]}

input 589:  {"source": "The share price was languishing at about 400 pence before Ford 's Sept. 19 announcement of its interest in a minority stake .\n"}
prediction:  {"predictions": [[1, 1109, 2934, 3945, 2, 3, 1108, 2495, 2118, 6592, 12802, 4, 5, 1120, 1164, 3434, 8228, 2093, 1196, 4100, 112, 1116, 20456, 28138, 1627, 8679, 1104, 1157, 2199, 1107, 170, 7309, 8219, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0027835301589220762, -0.03025054931640625, -0.02919483184814453, -0.02919483184814453, -0.02919483184814453, -0.02919483184814453, -0.02919483184814453, -0.02919483184814453, -0.02919483184814453, -0.02919483184814453], "metadata": {"source_tokens": ["The", "share", "price", "was", "la", "##ng", "##ui", "##shing", "at", "about", "400", "pen", "##ce", "before", "Ford", "'", "##s", "Sept", "##.", "19", "announcement", "of", "its", "interest", "in", "a", "minority", "stake", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "share", "price", "[unused2]", "[unused3]", "was", "la", "##ng", "##ui", "##shing", "[unused4]", "[unused5]", "at", "about", "400", "pen", "##ce", "before", "Ford", "'", "##s", "Sept", "##.", "19", "announcement", "of", "its", "interest", "in", "a", "minority", "stake", "[unused6]", "[SEP]"]]}

input 590:  {"source": "The surprise announcement came after the IRS broke off negotiations with Mr. Hunt on a settlement of the one - time tycoon 's personal bankruptcy case .\n"}
prediction:  {"predictions": [[1, 1109, 3774, 8679, 2, 3, 1338, 4, 5, 1170, 1103, 146, 8900, 2795, 1228, 7624, 1114, 1828, 28138, 7928, 1113, 170, 3433, 1104, 1103, 1141, 118, 1159, 189, 1183, 18201, 112, 1116, 2357, 11102, 1692, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 146, 8900, 2, 3, 2795, 1228, 4, 5, 7624, 1114, 1828, 28138, 7928, 1113, 170, 3433, 1104, 1103, 1141, 1159, 189, 1183, 18201, 112, 1116, 2357, 11102, 1692, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006938934326171875, -0.041591353714466095, -0.07392406463623047, -0.07914018630981445, -0.07914018630981445, -0.07914018630981445, -0.07914018630981445, -0.07914018630981445, -0.07914018630981445, -0.07914018630981445], "metadata": {"source_tokens": ["The", "surprise", "announcement", "came", "after", "the", "I", "##RS", "broke", "off", "negotiations", "with", "Mr", "##.", "Hunt", "on", "a", "settlement", "of", "the", "one", "-", "time", "t", "##y", "##coon", "'", "##s", "personal", "bankruptcy", "case", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "surprise", "announcement", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "after", "the", "I", "##RS", "broke", "off", "negotiations", "with", "Mr", "##.", "Hunt", "on", "a", "settlement", "of", "the", "one", "-", "time", "t", "##y", "##coon", "'", "##s", "personal", "bankruptcy", "case", "[unused6]", "[SEP]", "[unused1]", "the", "I", "##RS", "[unused2]", "[unused3]", "broke", "off", "[unused4]", "[unused5]", "negotiations", "with", "Mr", "##.", "Hunt", "on", "a", "settlement", "of", "the", "one", "time", "t", "##y", "##coon", "'", "##s", "personal", "bankruptcy", "case", "[unused6]", "[SEP]"]]}

input 591:  {"source": "The tax has raised less than one billion marks ( $ 545.3 million ) annually in recent years , but the government has been reluctant to abolish the levy for budgetary concerns .\n"}
prediction:  {"predictions": [[1, 1109, 3641, 2, 3, 1144, 2120, 4, 5, 1750, 1190, 1141, 3775, 6216, 6089, 1107, 2793, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1433, 2, 3, 1144, 1151, 4, 5, 12061, 1106, 170, 15792, 2944, 1103, 5837, 7170, 1111, 4788, 3113, 5365, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1750, 1190, 1141, 3775, 6216, 2, 3, 1110, 4, 5, 109, 4335, 1571, 28138, 1495, 1550, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03241823986172676, -0.013687812723219395, -0.05412200838327408, -0.04135322570800781, -0.04029130935668945, -0.04029130935668945, -0.04029130935668945, -0.04029130935668945, -0.04029130935668945, -0.04029130935668945], "metadata": {"source_tokens": ["The", "tax", "has", "raised", "less", "than", "one", "billion", "marks", "(", "$", "54", "##5", "##.", "##3", "million", ")", "annually", "in", "recent", "years", ",", "but", "the", "government", "has", "been", "reluctant", "to", "a", "##bol", "##ish", "the", "le", "##vy", "for", "budget", "##ary", "concerns", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "tax", "[unused2]", "[unused3]", "has", "raised", "[unused4]", "[unused5]", "less", "than", "one", "billion", "marks", "annually", "in", "recent", "years", "[unused6]", "[SEP]", "[unused1]", "the", "government", "[unused2]", "[unused3]", "has", "been", "[unused4]", "[unused5]", "reluctant", "to", "a", "##bol", "##ish", "the", "le", "##vy", "for", "budget", "##ary", "concerns", "[unused6]", "[SEP]", "[unused1]", "less", "than", "one", "billion", "marks", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "$", "54", "##5", "##.", "##3", "million", "[unused6]", "[SEP]"]]}

input 592:  {"source": "The three existing plants and their land will be sold .\n"}
prediction:  {"predictions": [[1, 1109, 1210, 3685, 3546, 1105, 1147, 1657, 2, 3, 1209, 1129, 1962, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0007446513627655804, -0.01847362518310547, -0.01953601837158203, -0.01953601837158203, -0.01953601837158203, -0.01953601837158203, -0.01953601837158203, -0.01953601837158203, -0.01953601837158203, -0.01953601837158203], "metadata": {"source_tokens": ["The", "three", "existing", "plants", "and", "their", "land", "will", "be", "sold", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "three", "existing", "plants", "and", "their", "land", "[unused2]", "[unused3]", "will", "be", "sold", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 593:  {"source": "The two leaders are expected to discuss changes sweeping the East bloc as well as human - rights issues , regional disputes and economic cooperation .\n"}
prediction:  {"predictions": [[1, 1109, 1160, 3478, 2, 3, 1132, 2637, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1160, 3478, 2, 3, 1106, 6265, 4, 5, 2607, 13194, 1103, 1689, 171, 27089, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.048969268798828125, -0.07102979719638824, -0.057383060455322266, -0.05237579345703125, -0.05237579345703125, -0.05237579345703125, -0.05237579345703125, -0.05237579345703125, -0.05237579345703125, -0.05237579345703125], "metadata": {"source_tokens": ["The", "two", "leaders", "are", "expected", "to", "discuss", "changes", "sweeping", "the", "East", "b", "##loc", "as", "well", "as", "human", "-", "rights", "issues", ",", "regional", "disputes", "and", "economic", "cooperation", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "two", "leaders", "[unused2]", "[unused3]", "are", "expected", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "The", "two", "leaders", "[unused2]", "[unused3]", "to", "discuss", "[unused4]", "[unused5]", "changes", "sweeping", "the", "East", "b", "##loc", "[unused6]", "[SEP]"]]}

input 594:  {"source": "The two sides are also discussing certain business ventures involving cable rights to Columbia 's movies .\n"}
prediction:  {"predictions": [[1, 1109, 1160, 3091, 2, 3, 1132, 10751, 4, 5, 2218, 1671, 20135, 5336, 6095, 2266, 1106, 3132, 112, 1116, 5558, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.011402544565498829, -0.01867389678955078, -0.025352954864501953, -0.025352954864501953, -0.025352954864501953, -0.025352954864501953, -0.025352954864501953, -0.025352954864501953, -0.025352954864501953, -0.025352954864501953], "metadata": {"source_tokens": ["The", "two", "sides", "are", "also", "discussing", "certain", "business", "ventures", "involving", "cable", "rights", "to", "Columbia", "'", "##s", "movies", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "two", "sides", "[unused2]", "[unused3]", "are", "discussing", "[unused4]", "[unused5]", "certain", "business", "ventures", "involving", "cable", "rights", "to", "Columbia", "'", "##s", "movies", "[unused6]", "[SEP]"]]}

input 595:  {"source": "There 's light at the end of the tunnel for municipals , '' he said , adding that he expects prices to `` inch up '' in the near term .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1163, 4, 5, 1119, 5321, 1115, 1119, 27402, 7352, 1106, 169, 28152, 4305, 1146, 112, 28131, 1107, 1103, 1485, 1858, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.08702729642391205, -0.18742990493774414, -0.17004632949829102, -0.17004632949829102, -0.17004632949829102, -0.17004632949829102, -0.17004632949829102, -0.17004632949829102, -0.17004632949829102, -0.17004632949829102], "metadata": {"source_tokens": ["There", "'", "##s", "light", "at", "the", "end", "of", "the", "tunnel", "for", "municipal", "##s", ",", "'", "##'", "he", "said", ",", "adding", "that", "he", "expects", "prices", "to", "`", "##`", "inch", "up", "'", "##'", "in", "the", "near", "term", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "he", "adding", "that", "he", "expects", "prices", "to", "`", "##`", "inch", "up", "'", "##'", "in", "the", "near", "term", "[unused6]", "[SEP]"]]}

input 596:  {"source": "They claim to have busted spirits , poltergeists and other spooks in hundreds of houses around the country .\n"}
prediction:  {"predictions": [[1, 1220, 2, 3, 3548, 1106, 1138, 16118, 1174, 9494, 117, 185, 17772, 1200, 2176, 3681, 1105, 1168, 188, 5674, 5926, 1116, 1107, 5229, 1104, 2725, 1213, 1103, 1583, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05292879790067673, -0.04822111129760742, -0.05271005630493164, -0.05271005630493164, -0.05271005630493164, -0.05271005630493164, -0.05271005630493164, -0.05271005630493164, -0.05271005630493164, -0.05271005630493164], "metadata": {"source_tokens": ["They", "claim", "to", "have", "bust", "##ed", "spirits", ",", "p", "##olt", "##er", "##ge", "##ists", "and", "other", "s", "##po", "##ok", "##s", "in", "hundreds", "of", "houses", "around", "the", "country", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "They", "[unused2]", "[unused3]", "claim", "to", "have", "bust", "##ed", "spirits", ",", "p", "##olt", "##er", "##ge", "##ists", "and", "other", "s", "##po", "##ok", "##s", "in", "hundreds", "of", "houses", "around", "the", "country", "[unused6]", "[SEP]"]]}

input 597:  {"source": "This involves trade - offs and { it } cuts against the grain of existing consumer and even provider conceptions of what is ` necessary . ' ''\n"}
prediction:  {"predictions": [[1, 1188, 2, 3, 6808, 4, 5, 2597, 118, 12822, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 7484, 4, 5, 1222, 1103, 9478, 1104, 3685, 8440, 1105, 1256, 11482, 17890, 1116, 1104, 1184, 1110, 3238, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01607910729944706, -0.09661831706762314, -0.26012372970581055, -0.2766904830932617, -0.2766904830932617, -0.2766900062561035, -0.2766900062561035, -0.2766900062561035, -0.2766900062561035, -0.2766900062561035], "metadata": {"source_tokens": ["This", "involves", "trade", "-", "offs", "and", "{", "it", "}", "cuts", "against", "the", "grain", "of", "existing", "consumer", "and", "even", "provider", "conception", "##s", "of", "what", "is", "`", "necessary", ".", "'", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "[unused2]", "[unused3]", "involves", "[unused4]", "[unused5]", "trade", "-", "offs", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "cuts", "[unused4]", "[unused5]", "against", "the", "grain", "of", "existing", "consumer", "and", "even", "provider", "conception", "##s", "of", "what", "is", "necessary", "[unused6]", "[SEP]"]]}

input 598:  {"source": "This is the U.N. group that managed to traduce its own charter of promoting education , science and culture .\n"}
prediction:  {"predictions": [[1, 1188, 2, 3, 1110, 4, 5, 1103, 158, 28138, 2249, 28138, 1372, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 158, 28138, 2249, 28138, 1372, 2, 3, 2374, 1106, 189, 9871, 15776, 4, 5, 1157, 1319, 7394, 1104, 7495, 1972, 117, 2598, 1105, 2754, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0038297574501484632, -0.047486696392297745, -0.018932342529296875, -0.018317699432373047, -0.018317699432373047, -0.018317699432373047, -0.018317699432373047, -0.018317699432373047, -0.018317699432373047, -0.018317699432373047], "metadata": {"source_tokens": ["This", "is", "the", "U", "##.", "##N", "##.", "group", "that", "managed", "to", "t", "##rad", "##uce", "its", "own", "charter", "of", "promoting", "education", ",", "science", "and", "culture", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "U", "##.", "##N", "##.", "group", "[unused6]", "[SEP]", "[unused1]", "the", "U", "##.", "##N", "##.", "group", "[unused2]", "[unused3]", "managed", "to", "t", "##rad", "##uce", "[unused4]", "[unused5]", "its", "own", "charter", "of", "promoting", "education", ",", "science", "and", "culture", "[unused6]", "[SEP]"]]}

input 599:  {"source": "This provision met early and strong resistance from investment bankers worried about disruptions in their clients ' portfolios .\n"}
prediction:  {"predictions": [[1, 1188, 9348, 2, 3, 1899, 4, 5, 1346, 1105, 2012, 4789, 1121, 5151, 15304, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5151, 15304, 1116, 2, 3, 4472, 4, 5, 1164, 23730, 1116, 1107, 1147, 7550, 112, 12256, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02957948110997677, -0.025289496406912804, -0.010906696319580078, -0.01027822494506836, -0.01027822494506836, -0.01027822494506836, -0.01027822494506836, -0.01027822494506836, -0.01027822494506836, -0.01027822494506836], "metadata": {"source_tokens": ["This", "provision", "met", "early", "and", "strong", "resistance", "from", "investment", "banker", "##s", "worried", "about", "disruption", "##s", "in", "their", "clients", "'", "portfolio", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "provision", "[unused2]", "[unused3]", "met", "[unused4]", "[unused5]", "early", "and", "strong", "resistance", "from", "investment", "banker", "##s", "[unused6]", "[SEP]", "[unused1]", "investment", "banker", "##s", "[unused2]", "[unused3]", "worried", "[unused4]", "[unused5]", "about", "disruption", "##s", "in", "their", "clients", "'", "portfolio", "##s", "[unused6]", "[SEP]"]]}

input 600:  {"source": "This week , New York City announced a 10 - point policy patterned on the federal bill of rights for taxpayers .\n"}
prediction:  {"predictions": [[1, 1203, 1365, 1392, 2, 3, 1717, 4, 5, 170, 1275, 118, 1553, 2818, 4844, 1174, 1113, 1103, 2877, 4550, 1104, 2266, 1111, 3641, 27452, 1188, 1989, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.001364477793686092, -0.050019264221191406, -0.04786396026611328, -0.04786396026611328, -0.04786396026611328, -0.04786396026611328, -0.04786396026611328, -0.04786396026611328, -0.04786396026611328, -0.04786396026611328], "metadata": {"source_tokens": ["This", "week", ",", "New", "York", "City", "announced", "a", "10", "-", "point", "policy", "pattern", "##ed", "on", "the", "federal", "bill", "of", "rights", "for", "tax", "##payers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "New", "York", "City", "[unused2]", "[unused3]", "announced", "[unused4]", "[unused5]", "a", "10", "-", "point", "policy", "pattern", "##ed", "on", "the", "federal", "bill", "of", "rights", "for", "tax", "##payers", "This", "week", "[unused6]", "[SEP]"]]}

input 601:  {"source": "Though Mr. Packer has since sold his stake , Courtaulds is moving to keep its institutional shareholders happy .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 14667, 1200, 2, 3, 1144, 1962, 4, 5, 1117, 8219, 1290, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2031, 18318, 3680, 2, 3, 1110, 4, 5, 2232, 1106, 1712, 1157, 15040, 16741, 2816, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.018494345247745514, -0.02248462289571762, -0.05664253234863281, -0.05663013458251953, -0.05663013458251953, -0.05663013458251953, -0.05663013458251953, -0.05663013458251953, -0.05663013458251953, -0.05663013458251953], "metadata": {"source_tokens": ["Though", "Mr", "##.", "Pack", "##er", "has", "since", "sold", "his", "stake", ",", "Court", "##aul", "##ds", "is", "moving", "to", "keep", "its", "institutional", "shareholders", "happy", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Pack", "##er", "[unused2]", "[unused3]", "has", "sold", "[unused4]", "[unused5]", "his", "stake", "since", "[unused6]", "[SEP]", "[unused1]", "Court", "##aul", "##ds", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "moving", "to", "keep", "its", "institutional", "shareholders", "happy", "[unused6]", "[SEP]"]]}

input 602:  {"source": "To avoid a runoff , one candidate would have to win 50 % of the vote -- a feat that most analysts consider impossible with so many candidates running .\n"}
prediction:  {"predictions": [[1, 1141, 3234, 2, 3, 1106, 1782, 4, 5, 1851, 110, 1104, 1103, 2992, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1177, 1242, 4765, 2, 3, 1129, 1919, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1211, 22018, 2, 3, 4615, 4, 5, 4763, 1114, 1177, 1242, 4765, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0391230583190918, -0.09067916870117188, -0.05108488351106644, -0.1932964324951172, -0.19337129592895508, -0.19337129592895508, -0.19337129592895508, -0.19337129592895508, -0.19337129592895508, -0.19337129592895508], "metadata": {"source_tokens": ["To", "avoid", "a", "runoff", ",", "one", "candidate", "would", "have", "to", "win", "50", "%", "of", "the", "vote", "-", "##-", "a", "feat", "that", "most", "analysts", "consider", "impossible", "with", "so", "many", "candidates", "running", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "one", "candidate", "[unused2]", "[unused3]", "to", "win", "[unused4]", "[unused5]", "50", "%", "of", "the", "vote", "[unused6]", "[SEP]", "[unused1]", "so", "many", "candidates", "[unused2]", "[unused3]", "be", "running", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "most", "analysts", "[unused2]", "[unused3]", "consider", "[unused4]", "[unused5]", "impossible", "with", "so", "many", "candidates", "[unused6]", "[SEP]"]]}

input 603:  {"source": "To increase their share of that business , jewelry makers such as Crystal Brands Inc. 's Trifari and Monet units and Swank Inc. , maker of Anne Klein jewelry , are launching new lines with as much fanfare as the fragrance companies .\n"}
prediction:  {"predictions": [[1, 12731, 12525, 1216, 1112, 9048, 12381, 1116, 3561, 28138, 112, 1116, 18491, 21975, 1105, 22401, 2105, 2338, 1105, 11956, 1377, 3561, 28138, 2, 3, 1132, 12611, 4, 5, 1207, 2442, 1114, 1112, 1277, 5442, 14154, 1112, 1103, 175, 20484, 10555, 2557, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11956, 1377, 3561, 2, 3, 1110, 11166, 1104, 4, 5, 3967, 12782, 12731, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01429079845547676, -0.1564091444015503, -0.14623308181762695, -0.15127325057983398, -0.15127325057983398, -0.15127325057983398, -0.15127325057983398, -0.15127325057983398, -0.15127325057983398, -0.15127325057983398], "metadata": {"source_tokens": ["To", "increase", "their", "share", "of", "that", "business", ",", "jewelry", "makers", "such", "as", "Crystal", "Brand", "##s", "Inc", "##.", "'", "##s", "Tri", "##fari", "and", "Mon", "##et", "units", "and", "Swan", "##k", "Inc", "##.", ",", "maker", "of", "Anne", "Klein", "jewelry", ",", "are", "launching", "new", "lines", "with", "as", "much", "fan", "##fare", "as", "the", "f", "##rag", "##rance", "companies", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "jewelry", "makers", "such", "as", "Crystal", "Brand", "##s", "Inc", "##.", "'", "##s", "Tri", "##fari", "and", "Mon", "##et", "units", "and", "Swan", "##k", "Inc", "##.", "[unused2]", "[unused3]", "are", "launching", "[unused4]", "[unused5]", "new", "lines", "with", "as", "much", "fan", "##fare", "as", "the", "f", "##rag", "##rance", "companies", "[unused6]", "[SEP]", "[unused1]", "Swan", "##k", "Inc", "[unused2]", "[unused3]", "is", "maker", "of", "[unused4]", "[unused5]", "Anne", "Klein", "jewelry", "[unused6]", "[SEP]"]]}

input 604:  {"source": "To make them directly comparable , each index is based on the close of 1969 equaling 100 .\n"}
prediction:  {"predictions": [[1, 1296, 7448, 2, 3, 1110, 1359, 4, 5, 1113, 1103, 1601, 1104, 2540, 4463, 1158, 1620, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00039351615123450756, -0.01666879653930664, -0.01786947250366211, -0.01786947250366211, -0.01786947250366211, -0.01786947250366211, -0.01786947250366211, -0.01786947250366211, -0.01786947250366211, -0.01786947250366211], "metadata": {"source_tokens": ["To", "make", "them", "directly", "comparable", ",", "each", "index", "is", "based", "on", "the", "close", "of", "1969", "equal", "##ing", "100", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "each", "index", "[unused2]", "[unused3]", "is", "based", "[unused4]", "[unused5]", "on", "the", "close", "of", "1969", "equal", "##ing", "100", "[unused6]", "[SEP]"]]}

input 605:  {"source": "To my knowledge , no government entities , including the EPA , are pursuing UV - B measurements .\n"}
prediction:  {"predictions": [[1, 1185, 1433, 11659, 117, 1259, 1103, 20875, 2, 3, 1132, 12137, 4, 5, 26331, 118, 139, 12307, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.000796025968156755, -0.024529457092285156, -0.02321338653564453, -0.02321338653564453, -0.02321338653564453, -0.02321338653564453, -0.02321338653564453, -0.02321338653564453, -0.02321338653564453, -0.02321338653564453], "metadata": {"source_tokens": ["To", "my", "knowledge", ",", "no", "government", "entities", ",", "including", "the", "EPA", ",", "are", "pursuing", "UV", "-", "B", "measurements", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "no", "government", "entities", ",", "including", "the", "EPA", "[unused2]", "[unused3]", "are", "pursuing", "[unused4]", "[unused5]", "UV", "-", "B", "measurements", "[unused6]", "[SEP]"]]}

input 606:  {"source": "Tom Panelli had a perfectly good reason for not using the $ 300 rowing machine he bought three years ago .\n"}
prediction:  {"predictions": [[1, 2545, 20339, 2646, 2, 3, 1125, 4, 5, 170, 6150, 1363, 2255, 1111, 1136, 1606, 1103, 109, 3127, 18656, 3395, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 109, 3127, 18656, 3395, 2, 3, 3306, 4, 5, 1210, 1201, 2403, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0006944355554878712, -0.08406507968902588, -0.006725788116455078, -0.0070056915283203125, -0.0070056915283203125, -0.0070056915283203125, -0.0070056915283203125, -0.0070056915283203125, -0.0070056915283203125, -0.0070056915283203125], "metadata": {"source_tokens": ["Tom", "Panel", "##li", "had", "a", "perfectly", "good", "reason", "for", "not", "using", "the", "$", "300", "rowing", "machine", "he", "bought", "three", "years", "ago", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Tom", "Panel", "##li", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "perfectly", "good", "reason", "for", "not", "using", "the", "$", "300", "rowing", "machine", "[unused6]", "[SEP]", "[unused1]", "the", "$", "300", "rowing", "machine", "[unused2]", "[unused3]", "bought", "[unused4]", "[unused5]", "three", "years", "ago", "[unused6]", "[SEP]"]]}

input 607:  {"source": "U.S. makers have under 10 % share , compared with half the market in Europe and 80 % at home .\n"}
prediction:  {"predictions": [[1, 158, 28138, 1708, 28138, 12525, 2, 3, 1138, 4, 5, 1223, 1275, 110, 2934, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 158, 28138, 1708, 28138, 12525, 2, 3, 1138, 4, 5, 1223, 1275, 110, 2934, 3402, 1114, 1544, 1103, 2319, 1107, 1980, 1105, 2908, 110, 1120, 1313, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0035207411274313927, -0.03923867642879486, -0.024001121520996094, -0.024017333984375, -0.024017333984375, -0.024017333984375, -0.024017333984375, -0.024017333984375, -0.024017333984375, -0.024017333984375], "metadata": {"source_tokens": ["U", "##.", "##S", "##.", "makers", "have", "under", "10", "%", "share", ",", "compared", "with", "half", "the", "market", "in", "Europe", "and", "80", "%", "at", "home", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "U", "##.", "##S", "##.", "makers", "[unused2]", "[unused3]", "have", "[unused4]", "[unused5]", "under", "10", "%", "share", "[unused6]", "[SEP]", "[unused1]", "U", "##.", "##S", "##.", "makers", "[unused2]", "[unused3]", "have", "[unused4]", "[unused5]", "under", "10", "%", "share", "compared", "with", "half", "the", "market", "in", "Europe", "and", "80", "%", "at", "home", "[unused6]", "[SEP]"]]}

input 608:  {"source": "USG Corp. agreed to sell its headquarters building here to Manufacturers Life Insurance Co. of Toronto , and will lease the 19 - story facility until it moves to a new quarters in 1992 .\n"}
prediction:  {"predictions": [[1, 1646, 2349, 13619, 2, 3, 1209, 10549, 4, 5, 1103, 1627, 118, 1642, 3695, 1235, 1122, 5279, 1106, 170, 1207, 7541, 1107, 1924, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1646, 2349, 13619, 2, 3, 2675, 1106, 4582, 4, 5, 1157, 3834, 1459, 1303, 1106, 2268, 16205, 11179, 24990, 2583, 11037, 3291, 28138, 1104, 3506, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03230913728475571, -0.056921131908893585, -0.04382038116455078, -0.04425954818725586, -0.04425954818725586, -0.04425954818725586, -0.04425954818725586, -0.04425954818725586, -0.04425954818725586, -0.04425954818725586], "metadata": {"source_tokens": ["US", "##G", "Corp", "##.", "agreed", "to", "sell", "its", "headquarters", "building", "here", "to", "Man", "##uf", "##act", "##urers", "Life", "Insurance", "Co", "##.", "of", "Toronto", ",", "and", "will", "lease", "the", "19", "-", "story", "facility", "until", "it", "moves", "to", "a", "new", "quarters", "in", "1992", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "US", "##G", "Corp", "[unused2]", "[unused3]", "will", "lease", "[unused4]", "[unused5]", "the", "19", "-", "story", "facility", "until", "it", "moves", "to", "a", "new", "quarters", "in", "1992", "[unused6]", "[SEP]", "[unused1]", "US", "##G", "Corp", "[unused2]", "[unused3]", "agreed", "to", "sell", "[unused4]", "[unused5]", "its", "headquarters", "building", "here", "to", "Man", "##uf", "##act", "##urers", "Life", "Insurance", "Co", "##.", "of", "Toronto", "[unused6]", "[SEP]"]]}

input 609:  {"source": "Under a merger agreement reached Sept. 14 , the UAL board agreed to reimburse certain of the buy - out group 's expenses out of company funds even if the transaction was n't completed , provided the group did n't breach the agreement .\n"}
prediction:  {"predictions": [[1, 1103, 158, 12507, 2313, 2, 3, 2675, 4, 5, 1106, 1231, 4060, 19364, 2217, 2218, 1104, 1103, 4417, 118, 1149, 1372, 112, 1116, 11928, 1149, 1104, 1419, 4381, 2831, 170, 7256, 3311, 1680, 20456, 28138, 1489, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1372, 2, 3, 1225, 183, 28131, 1204, 13275, 4, 5, 1103, 3311, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 13618, 2, 3, 1108, 4, 5, 183, 28131, 1204, 2063, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 158, 12507, 2313, 2, 3, 2675, 4, 5, 1106, 1231, 4060, 19364, 2217, 2218, 1104, 1103, 4417, 118, 1149, 1372, 112, 1116, 11928, 1149, 1104, 1419, 4381, 1256, 1191, 1103, 13618, 1108, 183, 28131, 1204, 2063, 6, 102, 102, 1, 1103, 158, 12507, 2313, 2, 3, 2675, 4, 5, 1106, 1231, 4060, 19364, 2217, 2218, 1104, 1103, 4417, 118, 1149, 1372, 112, 1116, 11928, 1149, 1104, 1419, 4381, 1256, 1191, 1103, 13618, 1108, 183, 28131, 1204, 2063, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03319360315799713, -0.06082746013998985, -0.06268122047185898, -0.06603271514177322, -0.0745253711938858, -0.19818687438964844, -0.19849586486816406, -0.19849586486816406, -0.19849586486816406, -0.19849586486816406], "metadata": {"source_tokens": ["Under", "a", "merger", "agreement", "reached", "Sept", "##.", "14", ",", "the", "U", "##AL", "board", "agreed", "to", "re", "##im", "##bur", "##se", "certain", "of", "the", "buy", "-", "out", "group", "'", "##s", "expenses", "out", "of", "company", "funds", "even", "if", "the", "transaction", "was", "n", "##'", "##t", "completed", ",", "provided", "the", "group", "did", "n", "##'", "##t", "breach", "the", "agreement", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "U", "##AL", "board", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "re", "##im", "##bur", "##se", "certain", "of", "the", "buy", "-", "out", "group", "'", "##s", "expenses", "out", "of", "company", "funds", "Under", "a", "merger", "agreement", "reached", "Sept", "##.", "14", "[unused6]", "[SEP]", "[unused1]", "the", "group", "[unused2]", "[unused3]", "did", "n", "##'", "##t", "breach", "[unused4]", "[unused5]", "the", "agreement", "[unused6]", "[SEP]", "[unused1]", "the", "transaction", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "n", "##'", "##t", "completed", "[unused6]", "[SEP]", "[unused1]", "the", "U", "##AL", "board", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "re", "##im", "##bur", "##se", "certain", "of", "the", "buy", "-", "out", "group", "'", "##s", "expenses", "out", "of", "company", "funds", "even", "if", "the", "transaction", "was", "n", "##'", "##t", "completed", "[unused6]", "[SEP]", "[unused1]", "the", "U", "##AL", "board", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "re", "##im", "##bur", "##se", "certain", "of", "the", "buy", "-", "out", "group", "'", "##s", "expenses", "out", "of", "company", "funds", "even", "if", "the", "transaction", "was", "n", "##'", "##t", "completed", "[unused6]", "[SEP]"]]}

input 610:  {"source": "Under the debt - equity program , potential investors will submit sealed bids on the percentage of discount they are willing to purchase the debt at , and the bids will be allocated based on these discount offers .\n"}
prediction:  {"predictions": [[1, 3209, 9660, 2, 3, 1209, 12295, 4, 5, 10410, 23733, 1113, 1103, 6556, 1104, 23290, 2831, 1103, 6695, 118, 12288, 1788, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 23733, 2, 3, 1209, 1129, 11117, 4, 5, 1359, 1113, 1292, 23290, 3272, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1132, 4, 5, 4988, 1106, 4779, 1103, 6695, 1120, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04213438928127289, -0.11531861871480942, -0.019304903224110603, -0.06363821029663086, -0.06719017028808594, -0.06719017028808594, -0.06719017028808594, -0.06719017028808594, -0.06719017028808594, -0.06719017028808594], "metadata": {"source_tokens": ["Under", "the", "debt", "-", "equity", "program", ",", "potential", "investors", "will", "submit", "sealed", "bids", "on", "the", "percentage", "of", "discount", "they", "are", "willing", "to", "purchase", "the", "debt", "at", ",", "and", "the", "bids", "will", "be", "allocated", "based", "on", "these", "discount", "offers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "potential", "investors", "[unused2]", "[unused3]", "will", "submit", "[unused4]", "[unused5]", "sealed", "bids", "on", "the", "percentage", "of", "discount", "Under", "the", "debt", "-", "equity", "program", "[unused6]", "[SEP]", "[unused1]", "the", "bids", "[unused2]", "[unused3]", "will", "be", "allocated", "[unused4]", "[unused5]", "based", "on", "these", "discount", "offers", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "willing", "to", "purchase", "the", "debt", "at", "[unused6]", "[SEP]"]]}

input 611:  {"source": "Unemployment has reached 27.6 % in Azerbaijan , 25.7 % in Tadzhikistan , 22.8 % in Uzbekistan , 18.8 % in Turkmenia , 18 % in Armenia and 16.3 % in Kirgizia , the Communist Party newspaper said .\n"}
prediction:  {"predictions": [[1, 12118, 5521, 1643, 26179, 1880, 2, 3, 1144, 1680, 4, 5, 1765, 28138, 1545, 110, 1107, 7955, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12118, 5521, 1643, 26179, 1880, 2, 3, 1144, 1680, 4, 5, 1765, 28138, 1545, 110, 1107, 7955, 117, 1512, 28138, 1559, 110, 1107, 26741, 23239, 15860, 5108, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 5248, 1786, 3054, 2, 3, 1163, 4, 5, 1103, 5248, 1786, 3054, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.025882938876748085, -0.11374084651470184, -0.16720332205295563, -0.0862274169921875, -0.0866689682006836, -0.0866689682006836, -0.0866689682006836, -0.0866689682006836, -0.0866689682006836, -0.0866689682006836], "metadata": {"source_tokens": ["Un", "##em", "##p", "##loy", "##ment", "has", "reached", "27", "##.", "##6", "%", "in", "Azerbaijan", ",", "25", "##.", "##7", "%", "in", "Tad", "##zhi", "##kis", "##tan", ",", "22", "##.", "##8", "%", "in", "Uzbekistan", ",", "18", "##.", "##8", "%", "in", "Tu", "##rk", "##men", "##ia", ",", "18", "%", "in", "Armenia", "and", "16", "##.", "##3", "%", "in", "Ki", "##rg", "##iz", "##ia", ",", "the", "Communist", "Party", "newspaper", "said", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Un", "##em", "##p", "##loy", "##ment", "[unused2]", "[unused3]", "has", "reached", "[unused4]", "[unused5]", "27", "##.", "##6", "%", "in", "Azerbaijan", "[unused6]", "[SEP]", "[unused1]", "Un", "##em", "##p", "##loy", "##ment", "[unused2]", "[unused3]", "has", "reached", "[unused4]", "[unused5]", "27", "##.", "##6", "%", "in", "Azerbaijan", ",", "25", "##.", "##7", "%", "in", "Tad", "##zhi", "##kis", "##tan", "[unused6]", "[SEP]", "[unused1]", "the", "Communist", "Party", "newspaper", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "Communist", "Party", "newspaper", "[unused6]", "[SEP]"]]}

input 612:  {"source": "Vernon E. Jordan was elected to the board of this transportation services concern .\n"}
prediction:  {"predictions": [[1, 11459, 142, 28138, 4421, 2, 3, 1108, 1809, 4, 5, 1106, 1103, 2313, 1104, 1142, 6312, 1826, 4517, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-3.4150623832829297e-05, -0.012423515319824219, -0.012036323547363281, -0.012036323547363281, -0.012036323547363281, -0.012036323547363281, -0.012036323547363281, -0.012036323547363281, -0.012036323547363281, -0.012036323547363281], "metadata": {"source_tokens": ["Vernon", "E", "##.", "Jordan", "was", "elected", "to", "the", "board", "of", "this", "transportation", "services", "concern", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Vernon", "E", "##.", "Jordan", "[unused2]", "[unused3]", "was", "elected", "[unused4]", "[unused5]", "to", "the", "board", "of", "this", "transportation", "services", "concern", "[unused6]", "[SEP]"]]}

input 613:  {"source": "Warner Communications Inc. , which is being acquired by Time Warner , has filed a $ 1 billion breach - of - contract suit against Sony and the two producers .\n"}
prediction:  {"predictions": [[1, 6049, 6345, 3561, 2, 3, 1110, 1217, 2888, 4, 5, 1118, 2614, 6049, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6049, 6345, 3561, 2, 3, 1144, 5770, 4, 5, 170, 109, 122, 3775, 13275, 118, 118, 2329, 4228, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6049, 6345, 3561, 28138, 2, 3, 1144, 5770, 4, 5, 170, 109, 122, 3775, 13275, 1104, 118, 2329, 4228, 1222, 8028, 1105, 1103, 1160, 6419, 6, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.037298887968063354, -0.10439829528331757, -0.04596085101366043, -0.019987106323242188, -0.019456863403320312, -0.019456863403320312, -0.019456863403320312, -0.019456863403320312, -0.019456863403320312, -0.019456863403320312], "metadata": {"source_tokens": ["Warner", "Communications", "Inc", "##.", ",", "which", "is", "being", "acquired", "by", "Time", "Warner", ",", "has", "filed", "a", "$", "1", "billion", "breach", "-", "of", "-", "contract", "suit", "against", "Sony", "and", "the", "two", "producers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Warner", "Communications", "Inc", "[unused2]", "[unused3]", "is", "being", "acquired", "[unused4]", "[unused5]", "by", "Time", "Warner", "[unused6]", "[SEP]", "[unused1]", "Warner", "Communications", "Inc", "[unused2]", "[unused3]", "has", "filed", "[unused4]", "[unused5]", "a", "$", "1", "billion", "breach", "-", "-", "contract", "suit", "[unused6]", "[SEP]", "[unused1]", "Warner", "Communications", "Inc", "##.", "[unused2]", "[unused3]", "has", "filed", "[unused4]", "[unused5]", "a", "$", "1", "billion", "breach", "of", "-", "contract", "suit", "against", "Sony", "and", "the", "two", "producers", "[unused6]", "[SEP]"]]}

input 614:  {"source": "Warner has a five - year exclusive contract with Mr. Guber and Mr. Peters that requires them to make movies exclusively at the Warner Bros. studio .\n"}
prediction:  {"predictions": [[1, 6049, 2, 3, 1144, 4, 5, 170, 1421, 118, 1214, 7114, 2329, 1114, 1828, 28138, 144, 15209, 1197, 1105, 1828, 28138, 12648, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 144, 15209, 1197, 1105, 1828, 28138, 12648, 2, 3, 5315, 4, 5, 1172, 1106, 1294, 5558, 7097, 1120, 1103, 6049, 10145, 28138, 2362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007266535889357328, -0.03719480708241463, -0.07367086410522461, -0.07204627990722656, -0.07204627990722656, -0.07204627990722656, -0.07204627990722656, -0.07204627990722656, -0.07204627990722656, -0.07204627990722656], "metadata": {"source_tokens": ["Warner", "has", "a", "five", "-", "year", "exclusive", "contract", "with", "Mr", "##.", "G", "##ube", "##r", "and", "Mr", "##.", "Peters", "that", "requires", "them", "to", "make", "movies", "exclusively", "at", "the", "Warner", "Bros", "##.", "studio", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Warner", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "a", "five", "-", "year", "exclusive", "contract", "with", "Mr", "##.", "G", "##ube", "##r", "and", "Mr", "##.", "Peters", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "G", "##ube", "##r", "and", "Mr", "##.", "Peters", "[unused2]", "[unused3]", "requires", "[unused4]", "[unused5]", "them", "to", "make", "movies", "exclusively", "at", "the", "Warner", "Bros", "##.", "studio", "[unused6]", "[SEP]"]]}

input 615:  {"source": "While the campaign was Mr. Gibbons 's idea , however , he wo n't be paying for it : The donations will come out of the chain 's national advertising fund , which is financed by the franchisees .\n"}
prediction:  {"predictions": [[1, 1103, 2322, 2, 3, 1108, 4, 5, 1828, 28138, 25759, 112, 1116, 1911, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 192, 1186, 183, 28131, 1204, 1129, 6573, 1111, 1122, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 11725, 2, 3, 1209, 1435, 4, 5, 1149, 1104, 1103, 4129, 112, 1116, 1569, 6437, 5841, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4129, 112, 1116, 1569, 6437, 5841, 2, 3, 1129, 6573, 4, 5, 1111, 1122, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4129, 112, 1116, 1569, 6437, 5841, 2, 3, 1110, 14395, 4, 5, 1118, 1103, 5801, 1279, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04888831451535225, -0.19617879390716553, -0.09705402702093124, -0.0783480703830719, -0.0684584528207779, -0.0341191291809082, -0.0342869758605957, -0.0342869758605957, -0.0342869758605957, -0.0342869758605957], "metadata": {"source_tokens": ["While", "the", "campaign", "was", "Mr", "##.", "Gibbons", "'", "##s", "idea", ",", "however", ",", "he", "w", "##o", "n", "##'", "##t", "be", "paying", "for", "it", ":", "The", "donations", "will", "come", "out", "of", "the", "chain", "'", "##s", "national", "advertising", "fund", ",", "which", "is", "financed", "by", "the", "franchise", "##es", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "campaign", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "Mr", "##.", "Gibbons", "'", "##s", "idea", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "w", "##o", "n", "##'", "##t", "be", "paying", "for", "it", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "The", "donations", "[unused2]", "[unused3]", "will", "come", "[unused4]", "[unused5]", "out", "of", "the", "chain", "'", "##s", "national", "advertising", "fund", "[unused6]", "[SEP]", "[unused1]", "the", "chain", "'", "##s", "national", "advertising", "fund", "[unused2]", "[unused3]", "be", "paying", "[unused4]", "[unused5]", "for", "it", "[unused6]", "[SEP]", "[unused1]", "the", "chain", "'", "##s", "national", "advertising", "fund", "[unused2]", "[unused3]", "is", "financed", "[unused4]", "[unused5]", "by", "the", "franchise", "##es", "[unused6]", "[SEP]"]]}

input 616:  {"source": "With companies such as Honda Motor Co. , Toyota Motor Corp. and Nissan Motor Co. running so - called transplant auto operations , Japanese auto production in the U.S. will reach one million vehicles this year .\n"}
prediction:  {"predictions": [[1, 1983, 12365, 1707, 1107, 1103, 158, 28138, 1708, 28138, 2, 3, 1209, 2519, 4, 5, 1141, 1550, 4011, 1142, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12110, 8226, 3291, 28138, 117, 11801, 8226, 13619, 28138, 1105, 17574, 8226, 3291, 28138, 2, 3, 1919, 4, 5, 1177, 118, 1270, 26965, 12365, 2500, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006075190380215645, -0.08866185694932938, -0.02867412567138672, -0.026936054229736328, -0.026936054229736328, -0.026936054229736328, -0.026936054229736328, -0.026936054229736328, -0.026936054229736328, -0.026936054229736328], "metadata": {"source_tokens": ["With", "companies", "such", "as", "Honda", "Motor", "Co", "##.", ",", "Toyota", "Motor", "Corp", "##.", "and", "Nissan", "Motor", "Co", "##.", "running", "so", "-", "called", "transplant", "auto", "operations", ",", "Japanese", "auto", "production", "in", "the", "U", "##.", "##S", "##.", "will", "reach", "one", "million", "vehicles", "this", "year", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Japanese", "auto", "production", "in", "the", "U", "##.", "##S", "##.", "[unused2]", "[unused3]", "will", "reach", "[unused4]", "[unused5]", "one", "million", "vehicles", "this", "year", "[unused6]", "[SEP]", "[unused1]", "Honda", "Motor", "Co", "##.", ",", "Toyota", "Motor", "Corp", "##.", "and", "Nissan", "Motor", "Co", "##.", "[unused2]", "[unused3]", "running", "[unused4]", "[unused5]", "so", "-", "called", "transplant", "auto", "operations", "[unused6]", "[SEP]"]]}

input 617:  {"source": "With more than 15 million exercise bikes sold in the past five years , he adds , `` a lot of garages , basements and attics must be populated with them . ''\n"}
prediction:  {"predictions": [[1, 1167, 1190, 1405, 1550, 6730, 20852, 2, 3, 1962, 4, 5, 1107, 1103, 1763, 1421, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 9807, 4, 5, 170, 1974, 1104, 7419, 1116, 117, 8078, 1116, 1105, 19554, 1116, 1538, 1129, 10240, 1114, 1172, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009722759947180748, -0.014655756764113903, -0.09153270721435547, -0.07460689544677734, -0.07460689544677734, -0.07460689544677734, -0.07460689544677734, -0.07460689544677734, -0.07460689544677734, -0.07460689544677734], "metadata": {"source_tokens": ["With", "more", "than", "15", "million", "exercise", "bikes", "sold", "in", "the", "past", "five", "years", ",", "he", "adds", ",", "`", "##`", "a", "lot", "of", "garage", "##s", ",", "basement", "##s", "and", "attic", "##s", "must", "be", "populated", "with", "them", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "more", "than", "15", "million", "exercise", "bikes", "[unused2]", "[unused3]", "sold", "[unused4]", "[unused5]", "in", "the", "past", "five", "years", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "adds", "[unused4]", "[unused5]", "a", "lot", "of", "garage", "##s", ",", "basement", "##s", "and", "attic", "##s", "must", "be", "populated", "with", "them", "[unused6]", "[SEP]"]]}

input 618:  {"source": "With real estate experts Olympia & York and Samuel Zell 's Itel owning close to 40 % of Santa Fe 's stock , management was under pressure -- in a favored phrase of Wall Street -- to quickly `` maximize values . ''\n"}
prediction:  {"predictions": [[1, 2635, 2, 3, 1108, 4, 5, 1223, 2997, 1107, 170, 12578, 7224, 1104, 6250, 1715, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1842, 3327, 8724, 18279, 111, 1365, 1105, 4424, 163, 3991, 112, 1116, 1135, 1883, 2, 3, 21554, 4, 5, 1601, 1106, 1969, 110, 1104, 3364, 11907, 112, 1116, 4482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.09918028116226196, -0.05694130063056946, -0.17319250106811523, -0.16666078567504883, -0.16666078567504883, -0.16666078567504883, -0.16666078567504883, -0.16666078567504883, -0.16666078567504883, -0.16666078567504883], "metadata": {"source_tokens": ["With", "real", "estate", "experts", "Olympia", "&", "York", "and", "Samuel", "Z", "##ell", "'", "##s", "It", "##el", "owning", "close", "to", "40", "%", "of", "Santa", "Fe", "'", "##s", "stock", ",", "management", "was", "under", "pressure", "-", "##-", "in", "a", "favored", "phrase", "of", "Wall", "Street", "-", "##-", "to", "quickly", "`", "##`", "ma", "##xi", "##mize", "values", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "management", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "under", "pressure", "in", "a", "favored", "phrase", "of", "Wall", "Street", "[unused6]", "[SEP]", "[unused1]", "real", "estate", "experts", "Olympia", "&", "York", "and", "Samuel", "Z", "##ell", "'", "##s", "It", "##el", "[unused2]", "[unused3]", "owning", "[unused4]", "[unused5]", "close", "to", "40", "%", "of", "Santa", "Fe", "'", "##s", "stock", "[unused6]", "[SEP]"]]}

input 619:  {"source": "Within two hours , viewers pledged over $ 400,000 , according to a Red Cross executive .\n"}
prediction:  {"predictions": [[1, 6827, 2, 3, 18215, 4, 5, 1166, 109, 3434, 28136, 7629, 1568, 5360, 1160, 2005, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6827, 2, 3, 18215, 4, 5, 1166, 109, 3434, 28136, 7629, 1568, 2452, 1106, 170, 2156, 3156, 3275, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013542705215513706, -0.009794799610972404, -0.02299785614013672, -0.02128887176513672, -0.02128887176513672, -0.02128887176513672, -0.02128887176513672, -0.02128887176513672, -0.02128887176513672, -0.02128887176513672], "metadata": {"source_tokens": ["Within", "two", "hours", ",", "viewers", "pledged", "over", "$", "400", "##,", "##00", "##0", ",", "according", "to", "a", "Red", "Cross", "executive", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "viewers", "[unused2]", "[unused3]", "pledged", "[unused4]", "[unused5]", "over", "$", "400", "##,", "##00", "##0", "Within", "two", "hours", "[unused6]", "[SEP]", "[unused1]", "viewers", "[unused2]", "[unused3]", "pledged", "[unused4]", "[unused5]", "over", "$", "400", "##,", "##00", "##0", "according", "to", "a", "Red", "Cross", "executive", "[unused6]", "[SEP]"]]}

input 620:  {"source": "Workers at two Chilean mines , Los Bronces and El Soldado , which belong to the Exxon - owned Minera Disputado group , will vote Thursday on whether to strike after a two - year labor pact ends today .\n"}
prediction:  {"predictions": [[1, 170, 1160, 118, 1214, 5530, 24920, 2, 3, 3769, 4, 5, 2052, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2238, 139, 3484, 7723, 1105, 2896, 17135, 14810, 1186, 2, 3, 1129, 6772, 4, 5, 1106, 1103, 16409, 21501, 118, 2205, 9139, 1611, 12120, 20080, 15012, 2572, 1372, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8736, 1120, 1160, 12208, 7785, 2, 3, 1209, 2992, 4, 5, 9170, 1113, 2480, 1106, 4585, 1170, 170, 1160, 118, 1214, 5530, 24920, 3769, 2052, 6, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06765060126781464, -0.09175138920545578, -0.09517228603363037, -0.0432429313659668, -0.041875362396240234, -0.041875362396240234, -0.041875362396240234, -0.041875362396240234, -0.041875362396240234, -0.041875362396240234], "metadata": {"source_tokens": ["Workers", "at", "two", "Chilean", "mines", ",", "Los", "B", "##ron", "##ces", "and", "El", "Sol", "##dad", "##o", ",", "which", "belong", "to", "the", "Ex", "##xon", "-", "owned", "Mine", "##ra", "Di", "##sp", "##uta", "##do", "group", ",", "will", "vote", "Thursday", "on", "whether", "to", "strike", "after", "a", "two", "-", "year", "labor", "pact", "ends", "today", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "two", "-", "year", "labor", "pact", "[unused2]", "[unused3]", "ends", "[unused4]", "[unused5]", "today", "[unused6]", "[SEP]", "[unused1]", "Los", "B", "##ron", "##ces", "and", "El", "Sol", "##dad", "##o", "[unused2]", "[unused3]", "be", "belong", "[unused4]", "[unused5]", "to", "the", "Ex", "##xon", "-", "owned", "Mine", "##ra", "Di", "##sp", "##uta", "##do", "group", "[unused6]", "[SEP]", "[unused1]", "Workers", "at", "two", "Chilean", "mines", "[unused2]", "[unused3]", "will", "vote", "[unused4]", "[unused5]", "Thursday", "on", "whether", "to", "strike", "after", "a", "two", "-", "year", "labor", "pact", "ends", "today", "[unused6]", "[SEP]"]]}

input 621:  {"source": "Years ago , he collaborated with the new music gurus Peter Serkin and Fred Sherry in the very countercultural chamber group Tashi , which won audiences over to dreaded contemporary scores like Messiaen 's `` Quartet for the End of Time . ''\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 8303, 4, 5, 1114, 1103, 1207, 1390, 176, 14022, 1943, 19536, 4314, 1105, 5291, 1153, 6234, 1107, 1103, 1304, 4073, 19418, 5383, 1372, 5848, 2403, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1304, 4073, 19418, 5383, 1372, 2, 3, 1129, 22515, 5933, 4, 5, 22515, 5933, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 22515, 5933, 2, 3, 1281, 4, 5, 9569, 1166, 1106, 18410, 1174, 3793, 7432, 1176, 2508, 19828, 27237, 112, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014179756864905357, -0.19561129808425903, -0.11432936787605286, -0.0670781135559082, -0.06713438034057617, -0.06713438034057617, -0.06713438034057617, -0.06713438034057617, -0.06713438034057617, -0.06713438034057617], "metadata": {"source_tokens": ["Years", "ago", ",", "he", "collaborated", "with", "the", "new", "music", "g", "##urus", "Peter", "Ser", "##kin", "and", "Fred", "She", "##rry", "in", "the", "very", "counter", "##cultural", "chamber", "group", "Ta", "##shi", ",", "which", "won", "audiences", "over", "to", "dread", "##ed", "contemporary", "scores", "like", "Me", "##ssi", "##aen", "'", "##s", "`", "##`", "Quartet", "for", "the", "End", "of", "Time", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "collaborated", "[unused4]", "[unused5]", "with", "the", "new", "music", "g", "##urus", "Peter", "Ser", "##kin", "and", "Fred", "She", "##rry", "in", "the", "very", "counter", "##cultural", "chamber", "group", "Years", "ago", "[unused6]", "[SEP]", "[unused1]", "the", "very", "counter", "##cultural", "chamber", "group", "[unused2]", "[unused3]", "be", "Ta", "##shi", "[unused4]", "[unused5]", "Ta", "##shi", "[unused6]", "[SEP]", "[unused1]", "Ta", "##shi", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "audiences", "over", "to", "dread", "##ed", "contemporary", "scores", "like", "Me", "##ssi", "##aen", "'", "##s", "[unused6]", "[SEP]"]]}

input 622:  {"source": "Yesterday , Mr. Matthews , now a consultant with the Stamford , Conn. , firm Matthews & Johnston , quipped , `` I think he 'll be very good at that { new job } .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 12495, 2, 3, 186, 6592, 10438, 4, 5, 146, 1341, 1119, 112, 2339, 1129, 1304, 1363, 1120, 1115, 196, 1207, 2261, 21997, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.018720414489507675, -0.13208675384521484, -0.1343250274658203, -0.1343250274658203, -0.1343250274658203, -0.1343250274658203, -0.1343250274658203, -0.1343250274658203, -0.1343250274658203, -0.1343250274658203], "metadata": {"source_tokens": ["Yesterday", ",", "Mr", "##.", "Matthews", ",", "now", "a", "consultant", "with", "the", "Stamford", ",", "Con", "##n", "##.", ",", "firm", "Matthews", "&", "Johnston", ",", "q", "##ui", "##pped", ",", "`", "##`", "I", "think", "he", "'", "##ll", "be", "very", "good", "at", "that", "{", "new", "job", "}", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Matthews", "[unused2]", "[unused3]", "q", "##ui", "##pped", "[unused4]", "[unused5]", "I", "think", "he", "'", "##ll", "be", "very", "good", "at", "that", "{", "new", "job", "Yesterday", "[unused6]", "[SEP]"]]}

input 623:  {"source": "Yet the Soviet leader 's readiness to embark on foreign visits and steady accumulation of personal power , particularly since the last Politburo reshuffle on Sept. 30 , do not suggest that Mr. Gorbachev is on the verge of being toppled ; nor does he look likely to reverse the powers of perestroika .\n"}
prediction:  {"predictions": [[1, 1103, 2461, 2301, 112, 1116, 25922, 1106, 9712, 24063, 1113, 2880, 7508, 1105, 6386, 23168, 1104, 2357, 1540, 2521, 1290, 1103, 1314, 17129, 2875, 19364, 1186, 1231, 16138, 13327, 1113, 20456, 28138, 1476, 2, 3, 1202, 1136, 5996, 4, 5, 1115, 1828, 28138, 3414, 26281, 12804, 1964, 1110, 1113, 102, 1, 1103, 2461, 2301, 112, 1116, 25922, 1106, 9712, 24063, 1113, 2880, 7508, 1105, 6386, 23168, 1104, 2357, 1540, 2521, 1290, 1103, 1314, 17129, 2875, 19364, 1186, 1231, 16138, 13327, 1113, 20456, 28138, 1476, 2, 3, 1202, 1136, 5996, 4, 5, 1115, 1828, 28138, 3414, 26281, 12804, 1964, 1110, 1113, 102, 1, 1828, 28138, 3414, 26281, 12804, 1964, 2, 3, 1129, 1110, 4, 5, 1113, 1103, 18691, 1104, 1217, 1499, 13229, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2461, 2301, 112, 1116, 2, 3, 1106, 9712, 24063, 4, 5, 1113, 2880, 7508, 1105, 6386, 23168, 1104, 2357, 1540, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2461, 2301, 112, 1116, 2, 3, 1106, 9712, 24063, 4, 5, 1113, 2880, 7508, 1105, 6386, 23168, 1104, 2357, 1540, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2461, 2301, 112, 1116, 2, 3, 1106, 9712, 24063, 4, 5, 1113, 2880, 7508, 1105, 6386, 23168, 1104, 2357, 1540, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.019092880189418793, -0.08440916240215302, -0.05729727819561958, -0.14458565413951874, -0.14589554071426392, -0.16253052651882172, -0.30531740188598633, -0.30220699310302734, -0.30220699310302734, -0.30220699310302734], "metadata": {"source_tokens": ["Yet", "the", "Soviet", "leader", "'", "##s", "readiness", "to", "em", "##bark", "on", "foreign", "visits", "and", "steady", "accumulation", "of", "personal", "power", ",", "particularly", "since", "the", "last", "Pol", "##it", "##bur", "##o", "re", "##shu", "##ffle", "on", "Sept", "##.", "30", ",", "do", "not", "suggest", "that", "Mr", "##.", "Go", "##rb", "##ache", "##v", "is", "on", "the", "verge", "of", "being", "top", "##pled", ";", "nor", "does", "he", "look", "likely", "to", "reverse", "the", "powers", "of", "per", "##est", "##roi", "##ka", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Soviet", "leader", "'", "##s", "readiness", "to", "em", "##bark", "on", "foreign", "visits", "and", "steady", "accumulation", "of", "personal", "power", "particularly", "since", "the", "last", "Pol", "##it", "##bur", "##o", "re", "##shu", "##ffle", "on", "Sept", "##.", "30", "[unused2]", "[unused3]", "do", "not", "suggest", "[unused4]", "[unused5]", "that", "Mr", "##.", "Go", "##rb", "##ache", "##v", "is", "on", "[SEP]", "[unused1]", "the", "Soviet", "leader", "'", "##s", "readiness", "to", "em", "##bark", "on", "foreign", "visits", "and", "steady", "accumulation", "of", "personal", "power", "particularly", "since", "the", "last", "Pol", "##it", "##bur", "##o", "re", "##shu", "##ffle", "on", "Sept", "##.", "30", "[unused2]", "[unused3]", "do", "not", "suggest", "[unused4]", "[unused5]", "that", "Mr", "##.", "Go", "##rb", "##ache", "##v", "is", "on", "[SEP]", "[unused1]", "Mr", "##.", "Go", "##rb", "##ache", "##v", "[unused2]", "[unused3]", "be", "is", "[unused4]", "[unused5]", "on", "the", "verge", "of", "being", "top", "##pled", "[unused6]", "[SEP]", "[unused1]", "the", "Soviet", "leader", "'", "##s", "[unused2]", "[unused3]", "to", "em", "##bark", "[unused4]", "[unused5]", "on", "foreign", "visits", "and", "steady", "accumulation", "of", "personal", "power", "[unused6]", "[SEP]", "[unused1]", "the", "Soviet", "leader", "'", "##s", "[unused2]", "[unused3]", "to", "em", "##bark", "[unused4]", "[unused5]", "on", "foreign", "visits", "and", "steady", "accumulation", "of", "personal", "power", "[unused6]", "[SEP]", "[unused1]", "the", "Soviet", "leader", "'", "##s", "[unused2]", "[unused3]", "to", "em", "##bark", "[unused4]", "[unused5]", "on", "foreign", "visits", "and", "steady", "accumulation", "of", "personal", "power", "[unused6]", "[SEP]"]]}

input 624:  {"source": "`` Business across the country is spending more time addressing this issue , '' says Sen. Edward Kennedy ( D. , Mass . ) .\n"}
prediction:  {"predictions": [[1, 3518, 1506, 1103, 1583, 1110, 5369, 1167, 1159, 13735, 1142, 2486, 2, 3, 1867, 4, 5, 14895, 28138, 2594, 5107, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3518, 1506, 1103, 1583, 2, 3, 1110, 5369, 4, 5, 1167, 1159, 13735, 1142, 2486, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004354062490165234, -0.040177926421165466, -0.23898696899414062, -0.22942686080932617, -0.22942686080932617, -0.22942686080932617, -0.22942686080932617, -0.22942686080932617, -0.22942686080932617, -0.22942686080932617], "metadata": {"source_tokens": ["`", "##`", "Business", "across", "the", "country", "is", "spending", "more", "time", "addressing", "this", "issue", ",", "'", "##'", "says", "Sen", "##.", "Edward", "Kennedy", "(", "D", "##.", ",", "Mass", ".", ")", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Business", "across", "the", "country", "is", "spending", "more", "time", "addressing", "this", "issue", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Sen", "##.", "Edward", "Kennedy", "[unused6]", "[SEP]", "[unused1]", "Business", "across", "the", "country", "[unused2]", "[unused3]", "is", "spending", "[unused4]", "[unused5]", "more", "time", "addressing", "this", "issue", "[unused6]", "[SEP]"]]}

input 625:  {"source": "`` I ca n't believe they ( GM ) will let Ford have a free run , '' said Stephen Reitman , a European auto industry analyst at UBS - Phillips & Drew .\n"}
prediction:  {"predictions": [[1, 146, 2, 3, 11019, 183, 28131, 1204, 2059, 4, 5, 1152, 113, 14748, 114, 1209, 1519, 4100, 1138, 170, 1714, 1576, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3620, 11336, 2875, 1399, 2, 3, 1110, 4, 5, 170, 1735, 12365, 2380, 14582, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3620, 11336, 2875, 1399, 2, 3, 1110, 4, 5, 170, 1735, 12365, 2380, 1399, 1120, 158, 9782, 7651, 111, 8633, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04494118690490723, -0.07942429184913635, -0.19941802322864532, -0.1514143943786621, -0.1439533233642578, -0.1439533233642578, -0.1439533233642578, -0.1439533233642578, -0.1439533233642578, -0.1439533233642578], "metadata": {"source_tokens": ["`", "##`", "I", "ca", "n", "##'", "##t", "believe", "they", "(", "GM", ")", "will", "let", "Ford", "have", "a", "free", "run", ",", "'", "##'", "said", "Stephen", "Re", "##it", "##man", ",", "a", "European", "auto", "industry", "analyst", "at", "U", "##BS", "-", "Phillips", "&", "Drew", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "I", "[unused2]", "[unused3]", "ca", "n", "##'", "##t", "believe", "[unused4]", "[unused5]", "they", "(", "GM", ")", "will", "let", "Ford", "have", "a", "free", "run", "[unused6]", "[SEP]", "[unused1]", "Stephen", "Re", "##it", "##man", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "European", "auto", "industry", "analyst", "[unused6]", "[SEP]", "[unused1]", "Stephen", "Re", "##it", "##man", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "European", "auto", "industry", "##man", "at", "U", "##BS", "Phillips", "&", "Drew", "[unused6]", "[SEP]"]]}

input 626:  {"source": "`` I do n't foresee any shortages over the next few months , '' says Ken Allen , an official of Operating Engineers Local 3 in San Francisco .\n"}
prediction:  {"predictions": [[1, 146, 1202, 183, 28131, 1204, 24387, 18628, 1251, 25630, 1166, 1103, 1397, 1374, 1808, 2, 3, 1867, 4, 5, 5928, 4522, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5928, 4522, 2, 3, 1110, 4, 5, 1126, 2078, 1104, 20961, 8665, 5328, 124, 1107, 1727, 2948, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 146, 2, 3, 1202, 183, 28131, 1204, 24387, 18628, 4, 5, 1251, 25630, 1166, 1103, 1397, 1374, 1808, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.016108432784676552, -0.02924163267016411, -0.035717956721782684, -0.06427526473999023, -0.06390571594238281, -0.06390571594238281, -0.06390523910522461, -0.06390523910522461, -0.06390523910522461, -0.06390523910522461], "metadata": {"source_tokens": ["`", "##`", "I", "do", "n", "##'", "##t", "fore", "##see", "any", "shortages", "over", "the", "next", "few", "months", ",", "'", "##'", "says", "Ken", "Allen", ",", "an", "official", "of", "Operating", "Engineers", "Local", "3", "in", "San", "Francisco", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "I", "do", "n", "##'", "##t", "fore", "##see", "any", "shortages", "over", "the", "next", "few", "months", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Ken", "Allen", "[unused6]", "[SEP]", "[unused1]", "Ken", "Allen", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "official", "of", "Operating", "Engineers", "Local", "3", "in", "San", "Francisco", "[unused6]", "[SEP]", "[unused1]", "I", "[unused2]", "[unused3]", "do", "n", "##'", "##t", "fore", "##see", "[unused4]", "[unused5]", "any", "shortages", "over", "the", "next", "few", "months", "[unused6]", "[SEP]"]]}

input 627:  {"source": "`` I wo n't be throwing 90 mph , but I will throw 80 - plus , '' he says .\n"}
prediction:  {"predictions": [[1, 146, 2, 3, 1209, 4932, 4, 5, 2908, 118, 4882, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 146, 2, 3, 192, 1186, 183, 28131, 1204, 1129, 6558, 4, 5, 3078, 4955, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1867, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03214135393500328, -0.10750066488981247, -0.21009401977062225, -0.07609128952026367, -0.07717037200927734, -0.07717037200927734, -0.07717037200927734, -0.07717037200927734, -0.07717037200927734, -0.07717037200927734], "metadata": {"source_tokens": ["`", "##`", "I", "w", "##o", "n", "##'", "##t", "be", "throwing", "90", "mph", ",", "but", "I", "will", "throw", "80", "-", "plus", ",", "'", "##'", "he", "says", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "I", "[unused2]", "[unused3]", "will", "throw", "[unused4]", "[unused5]", "80", "-", "plus", "[unused6]", "[SEP]", "[unused1]", "I", "[unused2]", "[unused3]", "w", "##o", "n", "##'", "##t", "be", "throwing", "[unused4]", "[unused5]", "90", "mph", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 628:  {"source": "`` If working capital financing is not provided , '' he said , `` the RTC may have to slow { S&L sales } or dump acquired assets through fire sales .\n"}
prediction:  {"predictions": [[1, 1684, 2364, 13080, 2, 3, 1110, 1136, 2136, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1163, 4, 5, 1103, 155, 9481, 1336, 1138, 1106, 3345, 196, 156, 28130, 2162, 3813, 198, 1137, 17549, 2888, 6661, 1194, 1783, 3813, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04148278012871742, -0.0376436710357666, -0.02908039093017578, -0.028815269470214844, -0.028815269470214844, -0.028815269470214844, -0.028815269470214844, -0.028815269470214844, -0.028815269470214844, -0.028815269470214844], "metadata": {"source_tokens": ["`", "##`", "If", "working", "capital", "financing", "is", "not", "provided", ",", "'", "##'", "he", "said", ",", "`", "##`", "the", "R", "##TC", "may", "have", "to", "slow", "{", "S", "##&", "##L", "sales", "}", "or", "dump", "acquired", "assets", "through", "fire", "sales", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "working", "capital", "financing", "[unused2]", "[unused3]", "is", "not", "provided", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "R", "##TC", "may", "have", "to", "slow", "{", "S", "##&", "##L", "sales", "}", "or", "dump", "acquired", "assets", "through", "fire", "sales", "[unused6]", "[SEP]"]]}

input 629:  {"source": "`` It 's a super - exciting set of discoveries , '' says Bert Vogelstein , a Johns Hopkins University researcher who has just found a gene pivotal to the triggering of colon cancer .\n"}
prediction:  {"predictions": [[1, 1135, 112, 1116, 170, 7688, 118, 11215, 1383, 1104, 17707, 2, 3, 1867, 4, 5, 15035, 159, 27732, 7879, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 11673, 10055, 1239, 11325, 2, 3, 1129, 1144, 1198, 1276, 4, 5, 170, 5565, 22927, 1106, 1103, 9887, 1158, 1104, 1884, 4934, 4182, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 112, 1116, 4, 5, 170, 7688, 118, 11215, 1383, 1104, 17707, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03609482944011688, -0.05749458819627762, -0.034720949828624725, -0.05918312072753906, -0.05988168716430664, -0.05988168716430664, -0.05988168716430664, -0.05988168716430664, -0.05988168716430664, -0.05988168716430664], "metadata": {"source_tokens": ["`", "##`", "It", "'", "##s", "a", "super", "-", "exciting", "set", "of", "discoveries", ",", "'", "##'", "says", "Bert", "V", "##ogel", "##stein", ",", "a", "Johns", "Hopkins", "University", "researcher", "who", "has", "just", "found", "a", "gene", "pivotal", "to", "the", "trigger", "##ing", "of", "co", "##lon", "cancer", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "'", "##s", "a", "super", "-", "exciting", "set", "of", "discoveries", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Bert", "V", "##ogel", "##stein", "[unused6]", "[SEP]", "[unused1]", "a", "Johns", "Hopkins", "University", "researcher", "[unused2]", "[unused3]", "be", "has", "just", "found", "[unused4]", "[unused5]", "a", "gene", "pivotal", "to", "the", "trigger", "##ing", "of", "co", "##lon", "cancer", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "'", "##s", "[unused4]", "[unused5]", "a", "super", "-", "exciting", "set", "of", "discoveries", "[unused6]", "[SEP]"]]}

input 630:  {"source": "`` It 's a wait - and - see attitude , '' said Dave Vellante , vice president of storage research for International Data Corp .\n"}
prediction:  {"predictions": [[1, 1135, 112, 1116, 170, 3074, 118, 1105, 118, 1267, 7533, 2, 3, 1163, 4, 5, 4111, 159, 7772, 11656, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4111, 159, 7772, 11656, 2, 3, 1110, 4, 5, 4711, 2084, 1104, 5092, 1844, 1111, 1570, 7154, 13619, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 112, 1116, 4, 5, 170, 3074, 1105, 118, 1267, 7533, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04548618942499161, -0.030193910002708435, -0.04371540993452072, -0.019529342651367188, -0.019857406616210938, -0.019857406616210938, -0.019857406616210938, -0.019857406616210938, -0.019857406616210938, -0.019857406616210938], "metadata": {"source_tokens": ["`", "##`", "It", "'", "##s", "a", "wait", "-", "and", "-", "see", "attitude", ",", "'", "##'", "said", "Dave", "V", "##ella", "##nte", ",", "vice", "president", "of", "storage", "research", "for", "International", "Data", "Corp", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "'", "##s", "a", "wait", "-", "and", "-", "see", "attitude", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "Dave", "V", "##ella", "##nte", "[unused6]", "[SEP]", "[unused1]", "Dave", "V", "##ella", "##nte", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "vice", "president", "of", "storage", "research", "for", "International", "Data", "Corp", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "'", "##s", "[unused4]", "[unused5]", "a", "wait", "and", "-", "see", "attitude", "[unused6]", "[SEP]"]]}

input 631:  {"source": "`` It 's really bizarre , '' says Albert Lerman , creative director at the Wells Rich Greene ad agency .\n"}
prediction:  {"predictions": [[1, 1135, 112, 1116, 1541, 15507, 2, 3, 1867, 4, 5, 3986, 3180, 7990, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3986, 3180, 7990, 2, 3, 1110, 4, 5, 6228, 1900, 1120, 1103, 7909, 8864, 10983, 8050, 4792, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 112, 1116, 4, 5, 1541, 15507, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03422984480857849, -0.01468486525118351, -0.05568969249725342, -0.015746593475341797, -0.015886306762695312, -0.015886306762695312, -0.015886306762695312, -0.015886306762695312, -0.015886306762695312, -0.015886306762695312], "metadata": {"source_tokens": ["`", "##`", "It", "'", "##s", "really", "bizarre", ",", "'", "##'", "says", "Albert", "Le", "##rman", ",", "creative", "director", "at", "the", "Wells", "Rich", "Greene", "ad", "agency", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "'", "##s", "really", "bizarre", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Albert", "Le", "##rman", "[unused6]", "[SEP]", "[unused1]", "Albert", "Le", "##rman", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "creative", "director", "at", "the", "Wells", "Rich", "Greene", "ad", "agency", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "'", "##s", "[unused4]", "[unused5]", "really", "bizarre", "[unused6]", "[SEP]"]]}

input 632:  {"source": "`` Most of the LBO guys do n't know how to run a business anyway . ''\n"}
prediction:  {"predictions": [[1, 2082, 1104, 1103, 149, 23904, 3713, 2, 3, 1202, 183, 28131, 1204, 1221, 4, 5, 1293, 1106, 1576, 170, 1671, 4050, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009260575287044048, -0.013979434967041016, -0.01306295394897461, -0.01306295394897461, -0.01306295394897461, -0.01306295394897461, -0.01306295394897461, -0.01306295394897461, -0.01306295394897461, -0.01306295394897461], "metadata": {"source_tokens": ["`", "##`", "Most", "of", "the", "L", "##BO", "guys", "do", "n", "##'", "##t", "know", "how", "to", "run", "a", "business", "anyway", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Most", "of", "the", "L", "##BO", "guys", "[unused2]", "[unused3]", "do", "n", "##'", "##t", "know", "[unused4]", "[unused5]", "how", "to", "run", "a", "business", "anyway", "[unused6]", "[SEP]"]]}

input 633:  {"source": "`` Most people -- whether in Toledo , Tucson or Topeka -- have n't got a clue who we are , '' says Guy L. Smith , Philip Morris 's vice president of corporate affairs .\n"}
prediction:  {"predictions": [[1, 2082, 1234, 118, 28137, 2480, 1107, 13459, 117, 18740, 1137, 3299, 19413, 118, 28137, 1138, 183, 28131, 1204, 1400, 170, 9956, 1150, 1195, 1132, 2, 3, 1867, 4, 5, 6173, 149, 28138, 2159, 117, 4367, 5744, 112, 1116, 4711, 2084, 1104, 6214, 5707, 6, 102, 102, 102, 102, 102, 102, 1, 2082, 1234, 2480, 1107, 13459, 117, 18740, 1137, 3299, 19413, 2, 3, 1138, 183, 28131, 1204, 1400, 4, 5, 170, 9956, 1150, 1195, 1132, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02153746969997883, -0.0627579614520073, -0.06047534942626953, -0.05820894241333008, -0.05820894241333008, -0.05820894241333008, -0.05820894241333008, -0.05820894241333008, -0.05820894241333008, -0.05820894241333008], "metadata": {"source_tokens": ["`", "##`", "Most", "people", "-", "##-", "whether", "in", "Toledo", ",", "Tucson", "or", "Top", "##eka", "-", "##-", "have", "n", "##'", "##t", "got", "a", "clue", "who", "we", "are", ",", "'", "##'", "says", "Guy", "L", "##.", "Smith", ",", "Philip", "Morris", "'", "##s", "vice", "president", "of", "corporate", "affairs", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Most", "people", "-", "##-", "whether", "in", "Toledo", ",", "Tucson", "or", "Top", "##eka", "-", "##-", "have", "n", "##'", "##t", "got", "a", "clue", "who", "we", "are", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Guy", "L", "##.", "Smith", ",", "Philip", "Morris", "'", "##s", "vice", "president", "of", "corporate", "affairs", "[unused6]", "[SEP]", "[unused1]", "Most", "people", "whether", "in", "Toledo", ",", "Tucson", "or", "Top", "##eka", "[unused2]", "[unused3]", "have", "n", "##'", "##t", "got", "[unused4]", "[unused5]", "a", "clue", "who", "we", "are", "[unused6]", "[SEP]"]]}

input 634:  {"source": "`` Nobody told us ; nobody called us , '' says an official close to the case who asked not to be named .\n"}
prediction:  {"predictions": [[1, 9913, 2, 3, 1500, 4, 5, 1366, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1692, 2, 3, 1129, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1692, 2, 3, 1129, 4, 5, 8582, 1270, 1366, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1692, 2, 3, 1129, 4, 5, 8582, 1270, 1366, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8582, 1270, 1366, 2, 3, 1867, 4, 5, 1126, 2078, 1601, 1106, 1103, 1692, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.11069466918706894, -0.26408320665359497, -0.19116368889808655, -0.248380646109581, -0.10419493913650513, -0.2119908332824707, -0.2167963981628418, -0.2167963981628418, -0.2167963981628418, -0.2167963981628418], "metadata": {"source_tokens": ["`", "##`", "Nobody", "told", "us", ";", "nobody", "called", "us", ",", "'", "##'", "says", "an", "official", "close", "to", "the", "case", "who", "asked", "not", "to", "be", "named", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Nobody", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "us", "[unused6]", "[SEP]", "[unused1]", "the", "case", "[unused2]", "[unused3]", "be", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "the", "case", "[unused2]", "[unused3]", "be", "[unused4]", "[unused5]", "nobody", "called", "us", "[unused6]", "[SEP]", "[unused1]", "the", "case", "[unused2]", "[unused3]", "be", "[unused4]", "[unused5]", "nobody", "called", "us", "[unused6]", "[SEP]", "[unused1]", "nobody", "called", "us", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "an", "official", "close", "to", "the", "case", "[unused6]", "[SEP]"]]}

input 635:  {"source": "`` Nothing can be better than this , '' says Don Sider , owner of the West Palm Beach Tropics .\n"}
prediction:  {"predictions": [[1, 4302, 1169, 1129, 1618, 1190, 1142, 2, 3, 1867, 4, 5, 1790, 6383, 1197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1790, 6383, 1197, 2, 3, 1110, 4, 5, 3172, 1104, 1103, 1537, 10739, 3808, 157, 27098, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027434516698122025, -0.03244035691022873, -0.16516447067260742, -0.1593313217163086, -0.1593313217163086, -0.1593313217163086, -0.1593313217163086, -0.1593313217163086, -0.1593313217163086, -0.1593313217163086], "metadata": {"source_tokens": ["`", "##`", "Nothing", "can", "be", "better", "than", "this", ",", "'", "##'", "says", "Don", "Side", "##r", ",", "owner", "of", "the", "West", "Palm", "Beach", "T", "##ropic", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Nothing", "can", "be", "better", "than", "this", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Don", "Side", "##r", "[unused6]", "[SEP]", "[unused1]", "Don", "Side", "##r", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "owner", "of", "the", "West", "Palm", "Beach", "T", "##ropic", "##s", "[unused6]", "[SEP]"]]}

input 636:  {"source": "`` Now everything '' -- such as program trading and wide stock market swings -- `` that everyone had pushed back in their consciousness is just sitting right there . ''\n"}
prediction:  {"predictions": [[1, 2490, 1125, 2873, 1171, 1107, 1147, 8418, 2, 3, 1110, 1198, 2807, 4, 5, 1268, 1175, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.08106078207492828, -0.05622577667236328, -0.057288169860839844, -0.057288169860839844, -0.057288169860839844, -0.057288169860839844, -0.057288169860839844, -0.057288169860839844, -0.057288169860839844, -0.057288169860839844], "metadata": {"source_tokens": ["`", "##`", "Now", "everything", "'", "##'", "-", "##-", "such", "as", "program", "trading", "and", "wide", "stock", "market", "swings", "-", "##-", "`", "##`", "that", "everyone", "had", "pushed", "back", "in", "their", "consciousness", "is", "just", "sitting", "right", "there", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "everyone", "had", "pushed", "back", "in", "their", "consciousness", "[unused2]", "[unused3]", "is", "just", "sitting", "[unused4]", "[unused5]", "right", "there", "[unused6]", "[SEP]"]]}

input 637:  {"source": "`` The bottom line is that if we can get that { Warsaw Pact } superiority brought down to parity , we ought to keep pressing ahead as quickly as possible .\n"}
prediction:  {"predictions": [[1, 1109, 3248, 1413, 2, 3, 1110, 4, 5, 1115, 1191, 1195, 1169, 1243, 1115, 196, 7760, 27175, 198, 21378, 1814, 1205, 1106, 14247, 1785, 117, 1195, 11454, 1106, 1712, 7675, 3075, 1112, 1976, 1112, 1936, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0021472761873155832, -0.12922143936157227, -0.1466379165649414, -0.1466379165649414, -0.1466379165649414, -0.1466379165649414, -0.1466379165649414, -0.1466379165649414, -0.1466379165649414, -0.1466379165649414], "metadata": {"source_tokens": ["`", "##`", "The", "bottom", "line", "is", "that", "if", "we", "can", "get", "that", "{", "Warsaw", "Pact", "}", "superiority", "brought", "down", "to", "par", "##ity", ",", "we", "ought", "to", "keep", "pressing", "ahead", "as", "quickly", "as", "possible", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "bottom", "line", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "that", "if", "we", "can", "get", "that", "{", "Warsaw", "Pact", "}", "superiority", "brought", "down", "to", "par", "##ity", ",", "we", "ought", "to", "keep", "pressing", "ahead", "as", "quickly", "as", "possible", "[unused6]", "[SEP]"]]}

input 638:  {"source": "`` The only people who are flying are those who have to , '' said Frank Moore , chairman of the Australian Tourist Industry Association .\n"}
prediction:  {"predictions": [[1, 1109, 1178, 1234, 1150, 1132, 3754, 2, 3, 1132, 4, 5, 1343, 1150, 1138, 1106, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2748, 4673, 2, 3, 1110, 4, 5, 3931, 1104, 1103, 1925, 3124, 1776, 7358, 1791, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1178, 1234, 1150, 1132, 3754, 1132, 3754, 1132, 1343, 2, 3, 1110, 4, 5, 1343, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1178, 1234, 1150, 1132, 3754, 1132, 3754, 1132, 1343, 2, 3, 1129, 1138, 1106, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05181789770722389, -0.02714565023779869, -0.22377817332744598, -0.2583855986595154, -0.25844240188598633, -0.2708301544189453, -0.2708301544189453, -0.2708301544189453, -0.2708301544189453, -0.2708301544189453], "metadata": {"source_tokens": ["`", "##`", "The", "only", "people", "who", "are", "flying", "are", "those", "who", "have", "to", ",", "'", "##'", "said", "Frank", "Moore", ",", "chairman", "of", "the", "Australian", "Tour", "##ist", "Industry", "Association", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "only", "people", "who", "are", "flying", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "those", "who", "have", "to", "[unused6]", "[SEP]", "[unused1]", "Frank", "Moore", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "chairman", "of", "the", "Australian", "Tour", "##ist", "Industry", "Association", "[unused6]", "[SEP]", "[unused1]", "The", "only", "people", "who", "are", "flying", "are", "flying", "are", "those", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "those", "[unused6]", "[SEP]", "[unused1]", "The", "only", "people", "who", "are", "flying", "are", "flying", "are", "those", "[unused2]", "[unused3]", "be", "have", "to", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 639:  {"source": "`` To allow this massive level of unfettered federal borrowing without prior congressional approval would be irresponsible , '' said Rep. Fortney Stark ( D. , Calif. ) , who has introduced a bill to limit the RTC 's authority to issue debt .\n"}
prediction:  {"predictions": [[1, 20777, 28138, 3144, 4695, 13562, 2, 3, 1144, 2234, 4, 5, 170, 4550, 1106, 5310, 1103, 155, 9481, 112, 1116, 3748, 1106, 2486, 6695, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1706, 2621, 1142, 4672, 1634, 1104, 8362, 8124, 16616, 2877, 20055, 1158, 1443, 2988, 10974, 5684, 2, 3, 1156, 1129, 4, 5, 178, 11604, 26408, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20777, 28138, 3144, 4695, 13562, 2, 3, 1110, 4, 5, 141, 28138, 117, 11917, 8914, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20777, 28138, 3144, 4695, 13562, 2, 3, 1110, 4, 5, 141, 28138, 11917, 8914, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0370134599506855, -0.09306053072214127, -0.14409109950065613, -0.15706086158752441, -0.17763471603393555, -0.20073604583740234, -0.20073604583740234, -0.20073604583740234, -0.20073604583740234, -0.20073604583740234], "metadata": {"source_tokens": ["`", "##`", "To", "allow", "this", "massive", "level", "of", "un", "##fe", "##ttered", "federal", "borrow", "##ing", "without", "prior", "congressional", "approval", "would", "be", "i", "##rre", "##sponsible", ",", "'", "##'", "said", "Rep", "##.", "Fort", "##ney", "Stark", "(", "D", "##.", ",", "Cal", "##if", "##.", ")", ",", "who", "has", "introduced", "a", "bill", "to", "limit", "the", "R", "##TC", "'", "##s", "authority", "to", "issue", "debt", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rep", "##.", "Fort", "##ney", "Stark", "[unused2]", "[unused3]", "has", "introduced", "[unused4]", "[unused5]", "a", "bill", "to", "limit", "the", "R", "##TC", "'", "##s", "authority", "to", "issue", "debt", "[unused6]", "[SEP]", "[unused1]", "To", "allow", "this", "massive", "level", "of", "un", "##fe", "##ttered", "federal", "borrow", "##ing", "without", "prior", "congressional", "approval", "[unused2]", "[unused3]", "would", "be", "[unused4]", "[unused5]", "i", "##rre", "##sponsible", "[unused6]", "[SEP]", "[unused1]", "Rep", "##.", "Fort", "##ney", "Stark", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "D", "##.", ",", "Cal", "##if", "##.", "[unused6]", "[SEP]", "[unused1]", "Rep", "##.", "Fort", "##ney", "Stark", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "D", "##.", "Cal", "##if", "##.", "[unused6]", "[SEP]"]]}

Batch 5 Test Time =  36.08225107192993  s
Decodertime : 0.00020742416381835938
g_f_logprobs : 0.00814366340637207
Decodertime : 0.00017762184143066406
g_f_logprobs : 0.007350921630859375
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.006697177886962891
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.006226778030395508
Decodertime : 0.0001385211944580078
g_f_logprobs : 0.005791664123535156
Decodertime : 0.0001327991485595703
g_f_logprobs : 0.00548863410949707
Decodertime : 0.00013136863708496094
g_f_logprobs : 0.005254268646240234
Decodertime : 0.00012636184692382812
g_f_logprobs : 0.005182981491088867
Decodertime : 0.0001277923583984375
g_f_logprobs : 0.005159139633178711
Decodertime : 0.00012493133544921875
g_f_logprobs : 0.005144834518432617
Decodertime : 0.00012612342834472656
g_f_logprobs : 0.005150794982910156
beam_search_time: 0.08294224739074707 s
Decodertime : 0.000125885009765625
g_f_logprobs : 0.009140968322753906
Decodertime : 0.00014495849609375
g_f_logprobs : 0.009128570556640625
Decodertime : 0.00012946128845214844
g_f_logprobs : 0.009085655212402344
Decodertime : 0.00012803077697753906
g_f_logprobs : 0.009054899215698242
Decodertime : 0.00012373924255371094
g_f_logprobs : 0.00905299186706543
Decodertime : 0.00012493133544921875
g_f_logprobs : 0.009153127670288086
Decodertime : 0.0001277923583984375
g_f_logprobs : 0.009083032608032227
Decodertime : 0.000125885009765625
g_f_logprobs : 0.00905156135559082
Decodertime : 0.0001251697540283203
g_f_logprobs : 0.009114265441894531
beam_search_time: 0.09447193145751953 s
Decodertime : 0.0001220703125
g_f_logprobs : 0.012162208557128906
Decodertime : 0.00012421607971191406
g_f_logprobs : 0.012154102325439453
Decodertime : 0.00012612342834472656
g_f_logprobs : 0.012153387069702148
Decodertime : 0.0001251697540283203
g_f_logprobs : 0.012593507766723633
Decodertime : 0.00013780593872070312
g_f_logprobs : 0.012148141860961914
Decodertime : 0.00013065338134765625
g_f_logprobs : 0.012151956558227539
Decodertime : 0.00012826919555664062
g_f_logprobs : 0.012120723724365234
Decodertime : 0.00012922286987304688
g_f_logprobs : 0.01221013069152832
Decodertime : 0.00012993812561035156
g_f_logprobs : 0.012141227722167969
Decodertime : 0.00012755393981933594
g_f_logprobs : 0.01214289665222168
Decodertime : 0.0001289844512939453
g_f_logprobs : 0.012158393859863281
beam_search_time: 0.14963722229003906 s
Decodertime : 0.00012922286987304688
g_f_logprobs : 0.01611495018005371
Decodertime : 0.00012755393981933594
g_f_logprobs : 0.016139745712280273
beam_search_time: 0.03500652313232422 s
input 640:  {"source": "`` We were oversold and today we bounced back .\n"}
prediction:  {"predictions": [[1, 1195, 2, 3, 13990, 4, 5, 1171, 2052, 6, 102, 102, 1, 1284, 2, 3, 1127, 4, 5, 6, 102, 102, 1, 1284, 2, 3, 1127, 4, 5, 17074, 11015, 6, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.05100804939866066, -0.09801557660102844, -0.06689012050628662, -0.046085357666015625], "metadata": {"source_tokens": ["`", "##`", "We", "were", "overs", "##old", "and", "today", "we", "bounced", "back", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "we", "[unused2]", "[unused3]", "bounced", "[unused4]", "[unused5]", "back", "today", "[unused6]", "[SEP]", "[unused1]", "We", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "We", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "overs", "##old", "[unused6]", "[SEP]"]]}

Batch 6 Test Time =  0.4124608039855957  s
Ending prediction
Total Time =  252.97090935707092  s
============== PROCESSING OUTPUTS ==============
{'<arg1>': '[unused1]', '</arg1>': '[unused2]', '<rel>': '[unused3]', '</rel>': '[unused4]', '<arg2>': '[unused5]', '</arg2>': '[unused6]', 'SENT': '[unused7]', 'PRED': '[unused8]', '@COPY@': '[unused9]', 'EOE': '[unused10]'}
models/imojie_gru_bs8_cd0/test/carb_1/output_5.jsonl
models/imojie_gru_bs8_cd0/test/carb_1/output_6.jsonl
============== EVALUATING OVER CARB ==============
/u/hbeyer/anaconda3/envs/imojie/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.
  warnings.warn(message, FutureWarning)
INFO:root:Writing PR curve of Allennlp to models/imojie_gru_bs8_cd0/test/carb_1/pro_output_5.txt.dat
AUC: 0	 Optimal (precision, recall, F1): (0, 0, 0)	Zero Conf (precision, recall, F1): (0, 0, 0)
/u/hbeyer/anaconda3/envs/imojie/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.
  warnings.warn(message, FutureWarning)
INFO:root:Writing PR curve of Allennlp to models/imojie_gru_bs8_cd0/test/carb_1/pro_output_6.txt.dat
AUC: 0.311	 Optimal (precision, recall, F1): (0.65, 0.424, 0.513)	Zero Conf (precision, recall, F1): (0.635, 0.426, 0.51)
============== COMPILING RESULTS ==============
Best Sum Scores =  (65.00/42.40/51.30, 31.10, 63.50/42.60/51.00)
total time: 2021-12-31 19:54:06.818846 - 2021-12-31 19:49:38.899201 = 0:04:27.919633
(traintime: 0:00:00.000005; testtime: 0:04:27.919628)
[?2004h(imojie) [01;32mhbeyer@mlserv1[00m:[01;34m~/imojie-master[00m$ 