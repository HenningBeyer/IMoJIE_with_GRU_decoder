python allennlp_script.py --param_path imojie/configs/imojie.json --mode test --s models/imojie_bs8[C_cd0
[?2004l{'<arg1>': '[unused1]', '</arg1>': '[unused2]', '<rel>': '[unused3]', '</rel>': '[unused4]', '<arg2>': '[unused5]', '</arg2>': '[unused6]', 'SENT': '[unused7]', 'PRED': '[unused8]', '@COPY@': '[unused9]', 'EOE': '[unused10]'}
/u/hbeyer/anaconda3/envs/imojie/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.
  warnings.warn(message, FutureWarning)
============== GENERATING OUTPUTS ==============
2
4
2021-12-31 18:43:38,306 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-12-31 18:43:38,327 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-12-31 18:43:38,643 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-12-31 18:43:38,645 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-12-31 18:43:38,663 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-12-31 18:43:38,666 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
2021-12-31 18:43:39,172 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
2021-12-31 18:43:39,173 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
2021-12-31 18:43:39,173 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
2021-12-31 18:43:39,174 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
{'<arg1>': '[unused1]', '</arg1>': '[unused2]', '<rel>': '[unused3]', '</rel>': '[unused4]', '<arg2>': '[unused5]', '</arg2>': '[unused6]', 'SENT': '[unused7]', 'PRED': '[unused8]', '@COPY@': '[unused9]', 'EOE': '[unused10]'}
/u/hbeyer/anaconda3/envs/imojie/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.
  warnings.warn(message, FutureWarning)
2021-12-31 18:43:39,330 - INFO - allennlp.models.archival - loading archive file models/imojie_bs8_cd0
2021-12-31 18:43:39,356 - INFO - allennlp.common.registrable - instantiating registered subclass copy_seq2seq_bahdanu of <class 'allennlp.models.model.Model'>
2021-12-31 18:43:39,356 - INFO - allennlp.common.params - vocabulary.type = default
2021-12-31 18:43:39,356 - INFO - allennlp.common.registrable - instantiating registered subclass default of <class 'allennlp.data.vocabulary.Vocabulary'>
2021-12-31 18:43:39,356 - INFO - allennlp.data.vocabulary - Loading token dictionary from models/imojie_bs8_cd0/vocabulary.
2021-12-31 18:43:39,357 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'append': True, 'source_namespace': 'bert', 'source_embedder': {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}}, 'decoder_layers': 1, 'token_based_metric': {'dev_set': 'dev', 'type': 'carb'}, 'type': 'copy_seq2seq_bahdanu', 'target_embedding_dim': 100, 'bert': True, 'max_decoding_steps': 50, 'encoder': {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'}, 'attention': {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'}, 'max_extractions': 10, 'target_namespace': 'bert', 'beam_size': 1} and extras {'vocab'}
2021-12-31 18:43:39,358 - INFO - allennlp.common.params - model.type = copy_seq2seq_bahdanu
2021-12-31 18:43:39,358 - INFO - allennlp.common.from_params - instantiating class <class 'imojie.models.copy_seq2seq_bahdanu.CopyNetSeq2Seq'> from params {'append': True, 'source_namespace': 'bert', 'source_embedder': {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}}, 'decoder_layers': 1, 'token_based_metric': {'dev_set': 'dev', 'type': 'carb'}, 'target_embedding_dim': 100, 'bert': True, 'max_decoding_steps': 50, 'encoder': {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'}, 'attention': {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'}, 'max_extractions': 10, 'target_namespace': 'bert', 'beam_size': 1} and extras {'vocab'}
2021-12-31 18:43:39,358 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}} and extras {'vocab'}
2021-12-31 18:43:39,358 - INFO - allennlp.common.params - model.source_embedder.type = basic
2021-12-31 18:43:39,358 - INFO - allennlp.common.params - model.source_embedder.embedder_to_indexer_map = None
2021-12-31 18:43:39,358 - INFO - allennlp.common.params - model.source_embedder.allow_unmatched_keys = False
2021-12-31 18:43:39,358 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'} and extras {'vocab'}
2021-12-31 18:43:39,358 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.type = pretrained_transformer
2021-12-31 18:43:39,358 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'bert-base-cased', 'requires_grad': True} and extras {'vocab'}
2021-12-31 18:43:39,358 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.model_name = bert-base-cased
2021-12-31 18:43:39,358 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.requires_grad = True
2021-12-31 18:43:39,370 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
2021-12-31 18:43:39,371 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
2021-12-31 18:43:39,371 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
2021-12-31 18:43:39,372 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
{'<arg1>': '[unused1]', '</arg1>': '[unused2]', '<rel>': '[unused3]', '</rel>': '[unused4]', '<arg2>': '[unused5]', '</arg2>': '[unused6]', 'SENT': '[unused7]', 'PRED': '[unused8]', '@COPY@': '[unused9]', 'EOE': '[unused10]'}
/u/hbeyer/anaconda3/envs/imojie/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.
  warnings.warn(message, FutureWarning)
2021-12-31 18:43:39,470 - INFO - allennlp.models.archival - loading archive file models/imojie_bs8_cd0
2021-12-31 18:43:39,495 - INFO - allennlp.common.registrable - instantiating registered subclass copy_seq2seq_bahdanu of <class 'allennlp.models.model.Model'>
2021-12-31 18:43:39,495 - INFO - allennlp.common.params - vocabulary.type = default
2021-12-31 18:43:39,495 - INFO - allennlp.common.registrable - instantiating registered subclass default of <class 'allennlp.data.vocabulary.Vocabulary'>
2021-12-31 18:43:39,495 - INFO - allennlp.data.vocabulary - Loading token dictionary from models/imojie_bs8_cd0/vocabulary.
2021-12-31 18:43:39,496 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'source_embedder': {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}}, 'source_namespace': 'bert', 'target_namespace': 'bert', 'max_decoding_steps': 50, 'append': True, 'bert': True, 'token_based_metric': {'dev_set': 'dev', 'type': 'carb'}, 'type': 'copy_seq2seq_bahdanu', 'attention': {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'}, 'target_embedding_dim': 100, 'encoder': {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'}, 'decoder_layers': 1, 'max_extractions': 10, 'beam_size': 1} and extras {'vocab'}
2021-12-31 18:43:39,496 - INFO - allennlp.common.params - model.type = copy_seq2seq_bahdanu
2021-12-31 18:43:39,496 - INFO - allennlp.common.from_params - instantiating class <class 'imojie.models.copy_seq2seq_bahdanu.CopyNetSeq2Seq'> from params {'source_embedder': {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}}, 'source_namespace': 'bert', 'target_namespace': 'bert', 'max_decoding_steps': 50, 'append': True, 'bert': True, 'token_based_metric': {'dev_set': 'dev', 'type': 'carb'}, 'attention': {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'}, 'target_embedding_dim': 100, 'encoder': {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'}, 'decoder_layers': 1, 'max_extractions': 10, 'beam_size': 1} and extras {'vocab'}
2021-12-31 18:43:39,496 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'tokens': {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'}}} and extras {'vocab'}
2021-12-31 18:43:39,496 - INFO - allennlp.common.params - model.source_embedder.type = basic
2021-12-31 18:43:39,497 - INFO - allennlp.common.params - model.source_embedder.embedder_to_indexer_map = None
2021-12-31 18:43:39,497 - INFO - allennlp.common.params - model.source_embedder.allow_unmatched_keys = False
2021-12-31 18:43:39,497 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_name': 'bert-base-cased', 'requires_grad': True, 'type': 'pretrained_transformer'} and extras {'vocab'}
2021-12-31 18:43:39,497 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.type = pretrained_transformer
2021-12-31 18:43:39,497 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.pretrained_transformer_embedder.PretrainedTransformerEmbedder'> from params {'model_name': 'bert-base-cased', 'requires_grad': True} and extras {'vocab'}
2021-12-31 18:43:39,497 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.model_name = bert-base-cased
2021-12-31 18:43:39,497 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.requires_grad = True
2021-12-31 18:43:39,841 - INFO - pytorch_transformers.modeling_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /u/hbeyer/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-12-31 18:43:39,841 - INFO - pytorch_transformers.modeling_utils - Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

2021-12-31 18:43:39,970 - INFO - pytorch_transformers.modeling_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /u/hbeyer/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
2021-12-31 18:43:39,970 - INFO - pytorch_transformers.modeling_utils - Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

2021-12-31 18:43:40,328 - INFO - pytorch_transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /u/hbeyer/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-12-31 18:43:41,078 - INFO - pytorch_transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /u/hbeyer/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
2021-12-31 18:43:42,259 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'} and extras {'vocab'}
2021-12-31 18:43:42,260 - INFO - allennlp.common.params - model.encoder.type = feedforward
2021-12-31 18:43:42,260 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.feedforward_encoder.FeedForwardEncoder'> from params {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}} and extras {'vocab'}
2021-12-31 18:43:42,260 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}
2021-12-31 18:43:42,260 - INFO - allennlp.common.params - model.encoder.feedforward.input_dim = 768
2021-12-31 18:43:42,260 - INFO - allennlp.common.params - model.encoder.feedforward.num_layers = 1
2021-12-31 18:43:42,260 - INFO - allennlp.common.params - model.encoder.feedforward.hidden_dims = [256]
2021-12-31 18:43:42,260 - INFO - allennlp.common.params - model.encoder.feedforward.hidden_dims = [256]
2021-12-31 18:43:42,261 - INFO - allennlp.common.params - model.encoder.feedforward.activations = ['relu']
2021-12-31 18:43:42,261 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params ['relu'] and extras {'vocab'}
2021-12-31 18:43:42,261 - INFO - allennlp.common.params - model.encoder.feedforward.activations = ['relu']
2021-12-31 18:43:42,261 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params relu and extras {'vocab'}
2021-12-31 18:43:42,261 - INFO - allennlp.common.params - type = relu
2021-12-31 18:43:42,261 - INFO - allennlp.common.params - model.encoder.feedforward.dropout = 0.1
2021-12-31 18:43:42,263 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.attention.attention.Attention'> from params {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'} and extras {'vocab'}
2021-12-31 18:43:42,263 - INFO - allennlp.common.params - model.attention.type = linear
2021-12-31 18:43:42,263 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.attention.linear_attention.LinearAttention'> from params {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256'} and extras {'vocab'}
2021-12-31 18:43:42,263 - INFO - allennlp.common.params - model.attention.tensor_1_dim = 256
2021-12-31 18:43:42,263 - INFO - allennlp.common.params - model.attention.tensor_2_dim = 256
2021-12-31 18:43:42,263 - INFO - allennlp.common.params - model.attention.combination = x,y
2021-12-31 18:43:42,263 - INFO - allennlp.common.params - model.attention.activation = tanh
2021-12-31 18:43:42,263 - INFO - allennlp.common.registrable - instantiating registered subclass tanh of <class 'allennlp.nn.activations.Activation'>
2021-12-31 18:43:42,263 - INFO - allennlp.common.params - model.attention.normalize = True
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.beam_size = 1
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.max_decoding_steps = 50
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.target_embedding_dim = 100
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.decoder_layers = 1
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.copy_token = @COPY@
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.source_namespace = bert
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.target_namespace = bert
2021-12-31 18:43:42,264 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.training.metrics.metric.Metric'> from params {'dev_set': 'dev', 'type': 'carb'} and extras {'vocab'}
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.token_based_metric.type = carb
2021-12-31 18:43:42,264 - INFO - allennlp.common.from_params - instantiating class <class 'imojie.carb_metric.Carb'> from params {'dev_set': 'dev'} and extras {'vocab'}
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.token_based_metric.dev_set = dev
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.lambda_diversity = 5
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.beam_search_type = beam_search
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.bert = True
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.append = True
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.coverage = False
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.max_extractions = 10
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.decoder_config = 
2021-12-31 18:43:42,264 - INFO - allennlp.common.params - model.decoder_type = lstm
2021-12-31 18:43:42,265 - INFO - allennlp.common.params - model.teacher_forcing = True
2021-12-31 18:43:42,331 - INFO - allennlp.nn.initializers - Initializing parameters
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers -    _attention._bias
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers -    _attention._weight_vector
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers -    _decoder_cell.bias_hh_l0
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers -    _decoder_cell.bias_ih_l0
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers -    _decoder_cell.weight_hh_l0
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers -    _decoder_cell.weight_ih_l0
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers -    _encoder._feedforward._linear_layers.0.bias
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers -    _encoder._feedforward._linear_layers.0.weight
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers -    _input_projection_layer.bias
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers -    _input_projection_layer.weight
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers -    _output_copying_layer.bias
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers -    _output_copying_layer.weight
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers -    _output_generation_layer.bias
2021-12-31 18:43:42,332 - INFO - allennlp.nn.initializers -    _output_generation_layer.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2021-12-31 18:43:42,333 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2021-12-31 18:43:42,334 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2021-12-31 18:43:42,335 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2021-12-31 18:43:42,336 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2021-12-31 18:43:42,337 - INFO - allennlp.nn.initializers -    _target_embedder.weight
2021-12-31 18:43:42,338 - INFO - root - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.
2021-12-31 18:43:43,106 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}, 'type': 'feedforward'} and extras {'vocab'}
2021-12-31 18:43:43,106 - INFO - allennlp.common.params - model.encoder.type = feedforward
2021-12-31 18:43:43,106 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.feedforward_encoder.FeedForwardEncoder'> from params {'feedforward': {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1}} and extras {'vocab'}
2021-12-31 18:43:43,106 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': ['relu'], 'dropout': 0.1, 'hidden_dims': [256], 'input_dim': 768, 'num_layers': 1} and extras {'vocab'}
2021-12-31 18:43:43,106 - INFO - allennlp.common.params - model.encoder.feedforward.input_dim = 768
2021-12-31 18:43:43,106 - INFO - allennlp.common.params - model.encoder.feedforward.num_layers = 1
2021-12-31 18:43:43,107 - INFO - allennlp.common.params - model.encoder.feedforward.hidden_dims = [256]
2021-12-31 18:43:43,107 - INFO - allennlp.common.params - model.encoder.feedforward.hidden_dims = [256]
2021-12-31 18:43:43,107 - INFO - allennlp.common.params - model.encoder.feedforward.activations = ['relu']
2021-12-31 18:43:43,107 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params ['relu'] and extras {'vocab'}
2021-12-31 18:43:43,107 - INFO - allennlp.common.params - model.encoder.feedforward.activations = ['relu']
2021-12-31 18:43:43,107 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params relu and extras {'vocab'}
2021-12-31 18:43:43,107 - INFO - allennlp.common.params - type = relu
2021-12-31 18:43:43,107 - INFO - allennlp.common.params - model.encoder.feedforward.dropout = 0.1
2021-12-31 18:43:43,109 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.attention.attention.Attention'> from params {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256', 'type': 'linear'} and extras {'vocab'}
2021-12-31 18:43:43,109 - INFO - allennlp.common.params - model.attention.type = linear
2021-12-31 18:43:43,109 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.attention.linear_attention.LinearAttention'> from params {'activation': 'tanh', 'tensor_1_dim': '256', 'tensor_2_dim': '256'} and extras {'vocab'}
2021-12-31 18:43:43,109 - INFO - allennlp.common.params - model.attention.tensor_1_dim = 256
2021-12-31 18:43:43,109 - INFO - allennlp.common.params - model.attention.tensor_2_dim = 256
2021-12-31 18:43:43,109 - INFO - allennlp.common.params - model.attention.combination = x,y
2021-12-31 18:43:43,109 - INFO - allennlp.common.params - model.attention.activation = tanh
2021-12-31 18:43:43,109 - INFO - allennlp.common.registrable - instantiating registered subclass tanh of <class 'allennlp.nn.activations.Activation'>
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.attention.normalize = True
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.beam_size = 1
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.max_decoding_steps = 50
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.target_embedding_dim = 100
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.decoder_layers = 1
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.copy_token = @COPY@
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.source_namespace = bert
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.target_namespace = bert
2021-12-31 18:43:43,110 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.training.metrics.metric.Metric'> from params {'dev_set': 'dev', 'type': 'carb'} and extras {'vocab'}
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.token_based_metric.type = carb
2021-12-31 18:43:43,110 - INFO - allennlp.common.from_params - instantiating class <class 'imojie.carb_metric.Carb'> from params {'dev_set': 'dev'} and extras {'vocab'}
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.token_based_metric.dev_set = dev
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.lambda_diversity = 5
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.beam_search_type = beam_search
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.bert = True
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.append = True
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.coverage = False
2021-12-31 18:43:43,110 - INFO - allennlp.common.params - model.max_extractions = 10
2021-12-31 18:43:43,111 - INFO - allennlp.common.params - model.decoder_config = 
2021-12-31 18:43:43,111 - INFO - allennlp.common.params - model.decoder_type = lstm
2021-12-31 18:43:43,111 - INFO - allennlp.common.params - model.teacher_forcing = True
2021-12-31 18:43:43,178 - INFO - allennlp.nn.initializers - Initializing parameters
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _attention._bias
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _attention._weight_vector
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _decoder_cell.bias_hh_l0
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _decoder_cell.bias_ih_l0
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _decoder_cell.weight_hh_l0
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _decoder_cell.weight_ih_l0
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _encoder._feedforward._linear_layers.0.bias
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _encoder._feedforward._linear_layers.0.weight
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _input_projection_layer.bias
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _input_projection_layer.weight
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _output_copying_layer.bias
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _output_copying_layer.weight
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _output_generation_layer.bias
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _output_generation_layer.weight
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2021-12-31 18:43:43,179 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2021-12-31 18:43:43,180 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2021-12-31 18:43:43,181 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2021-12-31 18:43:43,182 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2021-12-31 18:43:43,183 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2021-12-31 18:43:43,184 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2021-12-31 18:43:43,184 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2021-12-31 18:43:43,184 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2021-12-31 18:43:43,184 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2021-12-31 18:43:43,184 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2021-12-31 18:43:43,184 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2021-12-31 18:43:43,184 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2021-12-31 18:43:43,184 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2021-12-31 18:43:43,184 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2021-12-31 18:43:43,184 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2021-12-31 18:43:43,184 - INFO - allennlp.nn.initializers -    _source_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2021-12-31 18:43:43,184 - INFO - allennlp.nn.initializers -    _target_embedder.weight
2021-12-31 18:43:43,184 - INFO - root - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.
############################################################
############################################################
############################################################
2021-12-31 18:43:46,081 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'bert': True, 'lazy': True, 'max_extractions': 10, 'max_tokens': 500, 'source_token_indexers': {'tokens': {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'}}, 'source_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'target_namespace': 'bert', 'target_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'type': 'copy_seq2multiseq', 'validation': True} and extras set()
2021-12-31 18:43:46,081 - INFO - allennlp.common.params - validation_dataset_reader.type = copy_seq2multiseq
2021-12-31 18:43:46,081 - INFO - allennlp.common.from_params - instantiating class <class 'imojie.dataset_readers.copy_seq2multiseq.CopySeq2MultiSeqNetDatasetReader'> from params {'bert': True, 'lazy': True, 'max_extractions': 10, 'max_tokens': 500, 'source_token_indexers': {'tokens': {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'}}, 'source_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'target_namespace': 'bert', 'target_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'validation': True} and extras set()
2021-12-31 18:43:46,081 - INFO - allennlp.common.params - validation_dataset_reader.target_namespace = bert
2021-12-31 18:43:46,081 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'} and extras set()
2021-12-31 18:43:46,081 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.type = pretrained_transformer
2021-12-31 18:43:46,081 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': []} and extras set()
2021-12-31 18:43:46,082 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.model_name = bert-base-cased
2021-12-31 18:43:46,082 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.do_lowercase = False
2021-12-31 18:43:46,082 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.start_tokens = []
2021-12-31 18:43:46,082 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.end_tokens = []
2021-12-31 18:43:46,575 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /u/hbeyer/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-12-31 18:43:46,729 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'} and extras set()
2021-12-31 18:43:46,729 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.type = pretrained_transformer
2021-12-31 18:43:46,730 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': []} and extras set()
2021-12-31 18:43:46,730 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.model_name = bert-base-cased
2021-12-31 18:43:46,730 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.do_lowercase = False
2021-12-31 18:43:46,730 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.start_tokens = []
2021-12-31 18:43:46,730 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.end_tokens = []
############################################################
############################################################
############################################################
2021-12-31 18:43:46,805 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'bert': True, 'lazy': True, 'max_extractions': 10, 'max_tokens': 500, 'source_token_indexers': {'tokens': {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'}}, 'source_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'target_namespace': 'bert', 'target_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'type': 'copy_seq2multiseq', 'validation': True} and extras set()
2021-12-31 18:43:46,805 - INFO - allennlp.common.params - validation_dataset_reader.type = copy_seq2multiseq
2021-12-31 18:43:46,805 - INFO - allennlp.common.from_params - instantiating class <class 'imojie.dataset_readers.copy_seq2multiseq.CopySeq2MultiSeqNetDatasetReader'> from params {'bert': True, 'lazy': True, 'max_extractions': 10, 'max_tokens': 500, 'source_token_indexers': {'tokens': {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'}}, 'source_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'target_namespace': 'bert', 'target_tokenizer': {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'}, 'validation': True} and extras set()
2021-12-31 18:43:46,806 - INFO - allennlp.common.params - validation_dataset_reader.target_namespace = bert
2021-12-31 18:43:46,806 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'} and extras set()
2021-12-31 18:43:46,806 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.type = pretrained_transformer
2021-12-31 18:43:46,806 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': []} and extras set()
2021-12-31 18:43:46,806 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.model_name = bert-base-cased
2021-12-31 18:43:46,806 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.do_lowercase = False
2021-12-31 18:43:46,806 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.start_tokens = []
2021-12-31 18:43:46,806 - INFO - allennlp.common.params - validation_dataset_reader.source_tokenizer.end_tokens = []
2021-12-31 18:43:47,206 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /u/hbeyer/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-12-31 18:43:47,255 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'} and extras set()
2021-12-31 18:43:47,255 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.type = pretrained_transformer
2021-12-31 18:43:47,255 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert'} and extras set()
2021-12-31 18:43:47,256 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.model_name = bert-base-cased
2021-12-31 18:43:47,256 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.do_lowercase = False
2021-12-31 18:43:47,256 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.namespace = bert
2021-12-31 18:43:47,256 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.token_min_padding_length = 0
2021-12-31 18:43:47,283 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /u/hbeyer/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-12-31 18:43:47,462 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': [], 'type': 'pretrained_transformer'} and extras set()
2021-12-31 18:43:47,463 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.type = pretrained_transformer
2021-12-31 18:43:47,463 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': False, 'end_tokens': [], 'model_name': 'bert-base-cased', 'start_tokens': []} and extras set()
2021-12-31 18:43:47,463 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.model_name = bert-base-cased
2021-12-31 18:43:47,463 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.do_lowercase = False
2021-12-31 18:43:47,463 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.start_tokens = []
2021-12-31 18:43:47,463 - INFO - allennlp.common.params - validation_dataset_reader.target_tokenizer.end_tokens = []
2021-12-31 18:43:47,749 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /u/hbeyer/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-12-31 18:43:47,812 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 0
2021-12-31 18:43:47,812 - INFO - allennlp.common.params - validation_dataset_reader.lazy = True
2021-12-31 18:43:47,812 - INFO - allennlp.common.params - validation_dataset_reader.max_tokens = 500
2021-12-31 18:43:47,812 - INFO - allennlp.common.params - validation_dataset_reader.bert = True
2021-12-31 18:43:47,813 - INFO - allennlp.common.params - validation_dataset_reader.max_extractions = 10
2021-12-31 18:43:47,813 - INFO - allennlp.common.params - validation_dataset_reader.dev_path = None
2021-12-31 18:43:47,813 - INFO - allennlp.common.params - validation_dataset_reader.min_confidence = None
2021-12-31 18:43:47,813 - INFO - allennlp.common.params - validation_dataset_reader.max_confidence = None
2021-12-31 18:43:47,813 - INFO - allennlp.common.params - validation_dataset_reader.extraction_ratio = 1
2021-12-31 18:43:47,813 - INFO - allennlp.common.params - validation_dataset_reader.validation = True
2021-12-31 18:43:47,813 - INFO - allennlp.common.params - validation_dataset_reader.gradients = True
2021-12-31 18:43:47,813 - INFO - allennlp.common.params - validation_dataset_reader.append_test = False
2021-12-31 18:43:47,813 - INFO - allennlp.common.params - validation_dataset_reader.probability = False
2021-12-31 18:43:47,813 - INFO - allennlp.common.params - validation_dataset_reader.order_sentences = 
2021-12-31 18:43:47,815 - INFO - allennlp.common.registrable - instantiating registered subclass noie_seq2seq of <class 'allennlp.predictors.predictor.Predictor'>
Starting prediction
2021-12-31 18:43:47,942 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /u/hbeyer/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
2021-12-31 18:43:47,991 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert', 'type': 'pretrained_transformer'} and extras set()
2021-12-31 18:43:47,991 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.type = pretrained_transformer
2021-12-31 18:43:47,991 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.pretrained_transformer_indexer.PretrainedTransformerIndexer from params {'do_lowercase': False, 'model_name': 'bert-base-cased', 'namespace': 'bert'} and extras set()
2021-12-31 18:43:47,991 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.model_name = bert-base-cased
2021-12-31 18:43:47,991 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.do_lowercase = False
2021-12-31 18:43:47,991 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.namespace = bert
2021-12-31 18:43:47,991 - INFO - allennlp.common.params - validation_dataset_reader.source_token_indexers.tokens.token_min_padding_length = 0
Decodertime : 0.0005693435668945312
g_f_logprobs : 0.055555105209350586
Decodertime : 0.00026154518127441406
g_f_logprobs : 0.05381035804748535
Decodertime : 0.0001900196075439453
g_f_logprobs : 0.03902554512023926
Decodertime : 0.00017547607421875
g_f_logprobs : 0.03780627250671387
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.03848981857299805
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.0368809700012207
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.03690910339355469
Decodertime : 0.0001456737518310547
2021-12-31 18:43:48,483 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /u/hbeyer/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
g_f_logprobs : 0.03694295883178711
Decodertime : 0.0001518726348876953
2021-12-31 18:43:48,549 - INFO - allennlp.data.token_indexers.pretrained_transformer_indexer - Using token indexer padding value of 0
2021-12-31 18:43:48,549 - INFO - allennlp.common.params - validation_dataset_reader.lazy = True
2021-12-31 18:43:48,549 - INFO - allennlp.common.params - validation_dataset_reader.max_tokens = 500
2021-12-31 18:43:48,549 - INFO - allennlp.common.params - validation_dataset_reader.bert = True
2021-12-31 18:43:48,549 - INFO - allennlp.common.params - validation_dataset_reader.max_extractions = 10
2021-12-31 18:43:48,549 - INFO - allennlp.common.params - validation_dataset_reader.dev_path = None
2021-12-31 18:43:48,549 - INFO - allennlp.common.params - validation_dataset_reader.min_confidence = None
2021-12-31 18:43:48,549 - INFO - allennlp.common.params - validation_dataset_reader.max_confidence = None
2021-12-31 18:43:48,549 - INFO - allennlp.common.params - validation_dataset_reader.extraction_ratio = 1
2021-12-31 18:43:48,549 - INFO - allennlp.common.params - validation_dataset_reader.validation = True
2021-12-31 18:43:48,550 - INFO - allennlp.common.params - validation_dataset_reader.gradients = True
2021-12-31 18:43:48,550 - INFO - allennlp.common.params - validation_dataset_reader.append_test = False
2021-12-31 18:43:48,550 - INFO - allennlp.common.params - validation_dataset_reader.probability = False
2021-12-31 18:43:48,550 - INFO - allennlp.common.params - validation_dataset_reader.order_sentences = 
2021-12-31 18:43:48,551 - INFO - allennlp.common.registrable - instantiating registered subclass noie_seq2seq of <class 'allennlp.predictors.predictor.Predictor'>
Starting prediction
g_f_logprobs : 0.03730297088623047
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.037613630294799805
Decodertime : 0.00019359588623046875
g_f_logprobs : 0.037102699279785156
Decodertime : 0.00017833709716796875
g_f_logprobs : 0.09542989730834961
Decodertime : 0.00021576881408691406
Decodertime : 0.0003821849822998047
g_f_logprobs : 0.20802807807922363
Decodertime : 0.00020647048950195312
g_f_logprobs : 0.06640172004699707
Decodertime : 0.0001952648162841797
g_f_logprobs : 0.06423234939575195
Decodertime : 0.00017452239990234375
g_f_logprobs : 0.06761813163757324
Decodertime : 0.0001800060272216797
g_f_logprobs : 0.06277751922607422
Decodertime : 0.00018262863159179688
g_f_logprobs : 0.0656883716583252
g_f_logprobs : 0.06413578987121582
Decodertime : 0.0001850128173828125
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.06329178810119629
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.06966257095336914
Decodertime : 0.00017905235290527344
g_f_logprobs : 0.06481266021728516
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.06597256660461426
Decodertime : 0.00017261505126953125
g_f_logprobs : 0.06403493881225586
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.06588530540466309
Decodertime : 0.0001761913299560547
g_f_logprobs : 0.06479239463806152
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.06618547439575195
Decodertime : 0.00019669532775878906
g_f_logprobs : 0.06477832794189453
Decodertime : 0.00019097328186035156
g_f_logprobs : 0.06586265563964844
Decodertime : 0.0001742839813232422
g_f_logprobs : 0.06388616561889648
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.06712579727172852
Decodertime : 0.00021958351135253906
g_f_logprobs : 0.06501412391662598
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.0659172534942627
Decodertime : 0.00017452239990234375
g_f_logprobs : 0.06474947929382324
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.06603574752807617
Decodertime : 0.00017571449279785156
g_f_logprobs : 0.06345963478088379
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.06749939918518066
Decodertime : 0.00021195411682128906
g_f_logprobs : 0.0646970272064209
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.06585526466369629
Decodertime : 0.00018024444580078125
g_f_logprobs : 0.06507396697998047
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.06570124626159668
Decodertime : 0.0001862049102783203
g_f_logprobs : 0.0654897689819336
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.0659780502319336
Decodertime : 0.00017952919006347656
g_f_logprobs : 0.06500720977783203
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.06573081016540527
Decodertime : 0.0001742839813232422
g_f_logprobs : 0.06539630889892578
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.0659024715423584
Decodertime : 0.00017523765563964844
g_f_logprobs : 0.06498837471008301
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.06569337844848633
Decodertime : 0.00017595291137695312
g_f_logprobs : 0.06485581398010254
Decodertime : 0.0002391338348388672
g_f_logprobs : 0.06550073623657227
Decodertime : 0.0001728534698486328
g_f_logprobs : 0.06555867195129395
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.06595635414123535
Decodertime : 0.00017499923706054688
g_f_logprobs : 0.06540298461914062
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.0659952163696289
Decodertime : 0.00020051002502441406
g_f_logprobs : 0.06483149528503418
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.06598091125488281
Decodertime : 0.00017070770263671875
g_f_logprobs : 0.06502294540405273
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.06579971313476562
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.06494140625
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.06607675552368164
Decodertime : 0.0001685619354248047
g_f_logprobs : 0.06487059593200684
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.06613016128540039
Decodertime : 0.00016927719116210938
g_f_logprobs : 0.06502270698547363
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.06568574905395508
Decodertime : 0.0001678466796875
g_f_logprobs : 0.06492733955383301
Decodertime : 0.0001735687255859375
g_f_logprobs : 0.06610274314880371
Decodertime : 0.00017380714416503906
g_f_logprobs : 0.06482672691345215
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.06613397598266602
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.06489825248718262
Decodertime : 0.0001850128173828125
g_f_logprobs : 0.06616449356079102
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.0649709701538086
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.06571340560913086
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.0649864673614502
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.06610250473022461
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.06486296653747559
Decodertime : 0.000164031982421875
g_f_logprobs : 0.06613707542419434
Decodertime : 0.00016760826110839844
g_f_logprobs : 0.06487464904785156
Decodertime : 0.0001850128173828125
g_f_logprobs : 0.06617259979248047
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.06495189666748047
Decodertime : 0.00017261505126953125
g_f_logprobs : 0.06615424156188965
Decodertime : 0.0001678466796875
g_f_logprobs : 0.06490135192871094
Decodertime : 0.00018024444580078125
g_f_logprobs : 0.0661318302154541
Decodertime : 0.0001723766326904297
g_f_logprobs : 0.06486082077026367
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.06619715690612793
Decodertime : 0.0001685619354248047
g_f_logprobs : 0.06489419937133789
beam_search_time: 3.2459874153137207 s
g_f_logprobs : 0.2823169231414795
Decodertime : 0.0001735687255859375
Decodertime : 0.000171661376953125
g_f_logprobs : 0.16590332984924316
Decodertime : 0.000186920166015625
g_f_logprobs : 0.06426072120666504
Decodertime : 0.00019097328186035156
g_f_logprobs : 0.10611391067504883
Decodertime : 0.0001678466796875
g_f_logprobs : 0.06557989120483398
Decodertime : 0.000179290771484375
g_f_logprobs : 0.10505533218383789
Decodertime : 0.00017547607421875
g_f_logprobs : 0.06611394882202148
Decodertime : 0.0001785755157470703
g_f_logprobs : 0.06393575668334961
Decodertime : 0.0002167224884033203
g_f_logprobs : 0.1061849594116211
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.06633853912353516
Decodertime : 0.000186920166015625
g_f_logprobs : 0.06388616561889648
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.1067507266998291
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.06623625755310059
Decodertime : 0.00032591819763183594
g_f_logprobs : 0.10561609268188477
Decodertime : 0.00017333030700683594
g_f_logprobs : 0.0657496452331543
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.06388235092163086
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.10681629180908203
Decodertime : 0.00017714500427246094
g_f_logprobs : 0.06615757942199707
Decodertime : 0.0001690387725830078
g_f_logprobs : 0.10567879676818848
Decodertime : 0.0002155303955078125
g_f_logprobs : 0.06537270545959473
Decodertime : 0.00017333030700683594
g_f_logprobs : 0.0639336109161377
beam_search_time: 3.7336575984954834 s
g_f_logprobs : 0.18985581398010254
Decodertime : 0.00015163421630859375
Decodertime : 0.00019240379333496094
g_f_logprobs : 0.32825589179992676
Decodertime : 0.00020241737365722656
g_f_logprobs : 0.10603952407836914
Decodertime : 0.0002033710479736328
g_f_logprobs : 0.10548925399780273
Decodertime : 0.0001728534698486328
g_f_logprobs : 0.10662078857421875
Decodertime : 0.000171661376953125
g_f_logprobs : 0.10547876358032227
Decodertime : 0.0001685619354248047
g_f_logprobs : 0.10771465301513672
Decodertime : 0.00023889541625976562
g_f_logprobs : 0.10484981536865234
Decodertime : 0.00019669532775878906
g_f_logprobs : 0.10658407211303711
Decodertime : 0.00017404556274414062
g_f_logprobs : 0.10540294647216797
Decodertime : 0.00023293495178222656
g_f_logprobs : 0.10672211647033691
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.10543203353881836
Decodertime : 0.00017213821411132812
g_f_logprobs : 0.10676860809326172
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.10609745979309082
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.10710763931274414
Decodertime : 0.00020647048950195312
g_f_logprobs : 0.10509729385375977
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.10670781135559082
Decodertime : 0.0001766681671142578
g_f_logprobs : 0.10548853874206543
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.10680413246154785
Decodertime : 0.00017571449279785156
g_f_logprobs : 0.10553264617919922
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.10672974586486816
Decodertime : 0.000194549560546875
g_f_logprobs : 0.10438203811645508
Decodertime : 0.00014495849609375
g_f_logprobs : 0.10677075386047363
g_f_logprobs : 0.10418581962585449
Decodertime : 0.0001842975616455078
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.1055765151977539
g_f_logprobs : 0.10633015632629395
Decodertime : 0.00015401840209960938
Decodertime : 0.0001857280731201172
g_f_logprobs : 0.10635948181152344
g_f_logprobs : 0.10576391220092773
Decodertime : 0.0001552104949951172
Decodertime : 0.00023412704467773438
g_f_logprobs : 0.1063230037689209
g_f_logprobs : 0.10567522048950195
Decodertime : 0.00015687942504882812
Decodertime : 0.00018167495727539062
g_f_logprobs : 0.10632038116455078
g_f_logprobs : 0.10573029518127441
Decodertime : 0.00015735626220703125
Decodertime : 0.00017833709716796875
g_f_logprobs : 0.10632801055908203
g_f_logprobs : 0.10572099685668945
Decodertime : 0.00015401840209960938
Decodertime : 0.000179290771484375
g_f_logprobs : 0.10633373260498047
g_f_logprobs : 0.10573625564575195
Decodertime : 0.00015735626220703125
Decodertime : 0.00017786026000976562
g_f_logprobs : 0.10625696182250977
g_f_logprobs : 0.10566926002502441
Decodertime : 0.00016355514526367188
Decodertime : 0.00017976760864257812
g_f_logprobs : 0.10629844665527344
g_f_logprobs : 0.10571861267089844
Decodertime : 0.0001552104949951172
Decodertime : 0.000179290771484375
g_f_logprobs : 0.10636401176452637
g_f_logprobs : 0.10577774047851562
Decodertime : 0.00015854835510253906
Decodertime : 0.0001773834228515625
g_f_logprobs : 0.10643196105957031
g_f_logprobs : 0.10584664344787598
Decodertime : 0.00015425682067871094
Decodertime : 0.0001780986785888672
g_f_logprobs : 0.10580158233642578
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.10624027252197266
Decodertime : 0.00017333030700683594
g_f_logprobs : 0.10614132881164551
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.10468506813049316
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.10617232322692871
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.10462284088134766
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.10613369941711426
Decodertime : 0.00017523765563964844
g_f_logprobs : 0.10455203056335449
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.10634374618530273
Decodertime : 0.00017023086547851562
g_f_logprobs : 0.10477709770202637
Decodertime : 0.00017070770263671875
g_f_logprobs : 0.1061086654663086
Decodertime : 0.00017142295837402344
g_f_logprobs : 0.10456514358520508
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.10617470741271973
Decodertime : 0.0001747608184814453
g_f_logprobs : 0.1046135425567627
Decodertime : 0.00016760826110839844
g_f_logprobs : 0.10608649253845215
Decodertime : 0.00022339820861816406
g_f_logprobs : 0.10513114929199219
Decodertime : 0.00017261505126953125
g_f_logprobs : 0.10578703880310059
Decodertime : 0.0001697540283203125
g_f_logprobs : 0.10583996772766113
Decodertime : 0.0001728534698486328
g_f_logprobs : 0.1055915355682373
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.10622954368591309
Decodertime : 0.0001704692840576172
g_f_logprobs : 0.10568714141845703
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.10624122619628906
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.1050255298614502
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.10626029968261719
Decodertime : 0.0001761913299560547
g_f_logprobs : 0.10505270957946777
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.10626840591430664
Decodertime : 0.00019311904907226562
g_f_logprobs : 0.10510039329528809
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.10629773139953613
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.10504937171936035
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.10631322860717773
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.10467314720153809
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.10694432258605957
Decodertime : 0.0002446174621582031
g_f_logprobs : 0.10546374320983887
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.10627579689025879
Decodertime : 0.0001678466796875
g_f_logprobs : 0.10506629943847656
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.10631251335144043
Decodertime : 0.0001678466796875
g_f_logprobs : 0.10521817207336426
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.10644698143005371
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.10516190528869629
beam_search_time: 5.688463926315308 s
g_f_logprobs : 0.14578461647033691
Decodertime : 0.0001697540283203125
g_f_logprobs : 0.5281915664672852
Decodertime : 0.0002162456512451172
Decodertime : 0.00020241737365722656
g_f_logprobs : 0.10290122032165527
Decodertime : 0.00018215179443359375
g_f_logprobs : 0.14829540252685547
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.10607099533081055
Decodertime : 0.0001742839813232422
g_f_logprobs : 0.14738130569458008
Decodertime : 0.0001785755157470703
g_f_logprobs : 0.10616827011108398
Decodertime : 0.00017333030700683594
g_f_logprobs : 0.1041262149810791
Decodertime : 0.00016760826110839844
g_f_logprobs : 0.14911222457885742
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.10709667205810547
Decodertime : 0.00018978118896484375
g_f_logprobs : 0.14769268035888672
Decodertime : 0.0001964569091796875
g_f_logprobs : 0.10664963722229004
Decodertime : 0.00017499923706054688
g_f_logprobs : 0.10416793823242188
Decodertime : 0.00017309188842773438
g_f_logprobs : 0.1492595672607422
Decodertime : 0.00023102760314941406
g_f_logprobs : 0.10689020156860352
beam_search_time: 5.8883044719696045 s
g_f_logprobs : 0.32230377197265625
Decodertime : 0.00014829635620117188
Decodertime : 0.00019216537475585938
g_f_logprobs : 0.38955187797546387
Decodertime : 0.00017762184143066406
g_f_logprobs : 0.1419832706451416
Decodertime : 0.00017571449279785156
g_f_logprobs : 0.14771199226379395
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.14193987846374512
Decodertime : 0.00017690658569335938
g_f_logprobs : 0.1478278636932373
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.1419827938079834
Decodertime : 0.00017595291137695312
g_f_logprobs : 0.14783573150634766
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.14188289642333984
Decodertime : 0.0001742839813232422
g_f_logprobs : 0.1477673053741455
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.14186978340148926
Decodertime : 0.00020813941955566406
g_f_logprobs : 0.14774227142333984
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.1418132781982422
Decodertime : 0.00016927719116210938
g_f_logprobs : 0.1482541561126709
Decodertime : 0.000164031982421875
g_f_logprobs : 0.14178967475891113
Decodertime : 0.00016927719116210938
g_f_logprobs : 0.14780282974243164
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.14186406135559082
Decodertime : 0.000171661376953125
g_f_logprobs : 0.14766550064086914
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.1417090892791748
Decodertime : 0.00016999244689941406
g_f_logprobs : 0.14765715599060059
Decodertime : 0.00017070770263671875
g_f_logprobs : 0.14175176620483398
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.14753150939941406
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.14159703254699707
Decodertime : 0.00017380714416503906
g_f_logprobs : 0.14757490158081055
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.1417093276977539
Decodertime : 0.00016999244689941406
g_f_logprobs : 0.14755821228027344
Decodertime : 0.0001704692840576172
g_f_logprobs : 0.1416783332824707
Decodertime : 0.0001690387725830078
g_f_logprobs : 0.14770770072937012
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.1417686939239502
Decodertime : 0.00016927719116210938
g_f_logprobs : 0.14746999740600586
Decodertime : 0.000164031982421875
g_f_logprobs : 0.14157581329345703
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.14749979972839355
Decodertime : 0.000164031982421875
g_f_logprobs : 0.1415557861328125
Decodertime : 0.00016760826110839844
g_f_logprobs : 0.14735984802246094
Decodertime : 0.00017070770263671875
g_f_logprobs : 0.14149808883666992
Decodertime : 0.00017213821411132812
g_f_logprobs : 0.14752984046936035
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.14118051528930664
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.13915133476257324
Decodertime : 0.00016951560974121094
g_f_logprobs : 0.14974093437194824
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.14222311973571777
Decodertime : 0.0001678466796875
g_f_logprobs : 0.1481332778930664
Decodertime : 0.00019812583923339844
g_f_logprobs : 0.14223551750183105
Decodertime : 0.000179290771484375
g_f_logprobs : 0.14801716804504395
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.14213919639587402
Decodertime : 0.00017380714416503906
g_f_logprobs : 0.14810442924499512
Decodertime : 0.00016951560974121094
g_f_logprobs : 0.14212751388549805
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.14797377586364746
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.14208340644836426
Decodertime : 0.00017333030700683594
g_f_logprobs : 0.14796876907348633
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.14215826988220215
Decodertime : 0.00017189979553222656
g_f_logprobs : 0.14798593521118164
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.14206862449645996
Decodertime : 0.00019073486328125
g_f_logprobs : 0.1479792594909668
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.142014741897583
Decodertime : 0.00016760826110839844
g_f_logprobs : 0.14786434173583984
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.14210987091064453
Decodertime : 0.0001742839813232422
g_f_logprobs : 0.14806365966796875
Decodertime : 0.00017762184143066406
g_f_logprobs : 0.1419835090637207
Decodertime : 0.00016760826110839844
g_f_logprobs : 0.14786481857299805
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.1419544219970703
Decodertime : 0.0001723766326904297
g_f_logprobs : 0.14787888526916504
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.14189481735229492
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.14773774147033691
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.14185595512390137
Decodertime : 0.00017404556274414062
g_f_logprobs : 0.14781761169433594
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.14255833625793457
Decodertime : 0.0002346038818359375
g_f_logprobs : 0.14772319793701172
Decodertime : 0.00021219253540039062
g_f_logprobs : 0.14195775985717773
Decodertime : 0.00016927719116210938
g_f_logprobs : 0.14765501022338867
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.14194416999816895
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.1477053165435791
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.1418149471282959
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.14770007133483887
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.14179635047912598
Decodertime : 0.0001678466796875
g_f_logprobs : 0.14761614799499512
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.14170050621032715
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.14766669273376465
Decodertime : 0.0001723766326904297
g_f_logprobs : 0.14176177978515625
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.14752697944641113
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.14163589477539062
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.14764928817749023
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.14168953895568848
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.14751529693603516
Decodertime : 0.00018930435180664062
g_f_logprobs : 0.1416182518005371
Decodertime : 0.00016951560974121094
g_f_logprobs : 0.1476268768310547
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.1417081356048584
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.14740920066833496
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.1415095329284668
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.14807438850402832
beam_search_time: 7.901719808578491 s
g_f_logprobs : 0.14054250717163086
Decodertime : 0.00020003318786621094
g_f_logprobs : 0.7357697486877441
Decodertime : 0.0001857280731201172
Decodertime : 0.00018477439880371094
g_f_logprobs : 0.13512253761291504
Decodertime : 0.0002048015594482422
g_f_logprobs : 0.18571949005126953
Decodertime : 0.00016689300537109375
g_f_logprobs : 0.1413099765777588
Decodertime : 0.00017595291137695312
g_f_logprobs : 0.18451809883117676
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.14189839363098145
Decodertime : 0.00016760826110839844
g_f_logprobs : 0.13921141624450684
beam_search_time: 7.787451505661011 s
g_f_logprobs : 0.2177739143371582
Decodertime : 0.00015091896057128906
Decodertime : 0.00022864341735839844
g_f_logprobs : 0.7030031681060791
Decodertime : 0.0001728534698486328
g_f_logprobs : 0.18108797073364258
Decodertime : 0.0001766681671142578
g_f_logprobs : 0.18529033660888672
Decodertime : 0.0001747608184814453
g_f_logprobs : 0.18123698234558105
Decodertime : 0.00017642974853515625
g_f_logprobs : 0.18610930442810059
Decodertime : 0.00017380714416503906
g_f_logprobs : 0.1808462142944336
Decodertime : 0.00017762184143066406
g_f_logprobs : 0.18561601638793945
Decodertime : 0.000171661376953125
g_f_logprobs : 0.18047785758972168
Decodertime : 0.00017571449279785156
g_f_logprobs : 0.1847364902496338
Decodertime : 0.00017070770263671875
g_f_logprobs : 0.1811661720275879
Decodertime : 0.00017714500427246094
g_f_logprobs : 0.18598365783691406
Decodertime : 0.00016760826110839844
g_f_logprobs : 0.18080639839172363
Decodertime : 0.00017952919006347656
g_f_logprobs : 0.1850874423980713
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.18069100379943848
Decodertime : 0.00016951560974121094
g_f_logprobs : 0.1861116886138916
Decodertime : 0.00017690658569335938
g_f_logprobs : 0.18096399307250977
Decodertime : 0.00017261505126953125
g_f_logprobs : 0.18593668937683105
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.18098664283752441
Decodertime : 0.00017380714416503906
g_f_logprobs : 0.18599510192871094
Decodertime : 0.0001678466796875
g_f_logprobs : 0.18091249465942383
Decodertime : 0.0001728534698486328
g_f_logprobs : 0.18591833114624023
Decodertime : 0.0001685619354248047
g_f_logprobs : 0.1809375286102295
Decodertime : 0.00017213821411132812
g_f_logprobs : 0.18590331077575684
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.18099021911621094
Decodertime : 0.000171661376953125
g_f_logprobs : 0.18595290184020996
Decodertime : 0.00016689300537109375
g_f_logprobs : 0.18093371391296387
Decodertime : 0.0001735687255859375
g_f_logprobs : 0.18591713905334473
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.18097710609436035
Decodertime : 0.00017118453979492188
g_f_logprobs : 0.1852426528930664
Decodertime : 0.00036454200744628906
g_f_logprobs : 0.1801164150238037
Decodertime : 0.00017118453979492188
g_f_logprobs : 0.1848454475402832
Decodertime : 0.00017261505126953125
g_f_logprobs : 0.18093085289001465
Decodertime : 0.00017309188842773438
g_f_logprobs : 0.18582534790039062
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.1808784008026123
Decodertime : 0.00017118453979492188
g_f_logprobs : 0.185821533203125
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.18076515197753906
Decodertime : 0.00020051002502441406
g_f_logprobs : 0.18568873405456543
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.18070435523986816
Decodertime : 0.0001976490020751953
g_f_logprobs : 0.18582940101623535
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.1806926727294922
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.1856522560119629
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.18073081970214844
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.18567347526550293
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.18051385879516602
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.18552255630493164
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.180708646774292
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.18628334999084473
Decodertime : 0.00017404556274414062
g_f_logprobs : 0.1804180145263672
Decodertime : 0.0001735687255859375
g_f_logprobs : 0.18558955192565918
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.18056631088256836
Decodertime : 0.00016927719116210938
g_f_logprobs : 0.18561148643493652
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.18066906929016113
Decodertime : 0.00017547607421875
g_f_logprobs : 0.18486499786376953
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.18069171905517578
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.18551349639892578
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.18033266067504883
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.18535590171813965
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.18056559562683105
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.1855025291442871
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.17972064018249512
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.18534278869628906
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.18046307563781738
Decodertime : 0.0001685619354248047
g_f_logprobs : 0.18538403511047363
Decodertime : 0.00016999244689941406
g_f_logprobs : 0.18040919303894043
Decodertime : 0.000171661376953125
g_f_logprobs : 0.18561816215515137
Decodertime : 0.000179290771484375
g_f_logprobs : 0.18073344230651855
Decodertime : 0.0001709461212158203
g_f_logprobs : 0.18544840812683105
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.17957496643066406
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.18528151512145996
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.18040966987609863
Decodertime : 0.0001678466796875
g_f_logprobs : 0.18534493446350098
Decodertime : 0.0001857280731201172
g_f_logprobs : 0.1803452968597412
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.18526816368103027
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.180283784866333
Decodertime : 0.00017595291137695312
g_f_logprobs : 0.1852867603302002
g_f_logprobs : 0.17819690704345703
Decodertime : 0.00018143653869628906
Decodertime : 0.00017595291137695312
g_f_logprobs : 0.17999744415283203
Decodertime : 0.00019168853759765625
g_f_logprobs : 0.18878889083862305
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.18114829063415527
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.1861274242401123
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.18112468719482422
Decodertime : 0.00017309188842773438
g_f_logprobs : 0.18613314628601074
Decodertime : 0.00017142295837402344
g_f_logprobs : 0.1810288429260254
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.18598031997680664
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.1807258129119873
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.1849820613861084
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.18126463890075684
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.18607163429260254
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.18097782135009766
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.18600916862487793
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.1808321475982666
Decodertime : 0.00016760826110839844
g_f_logprobs : 0.1858515739440918
Decodertime : 0.000164031982421875
g_f_logprobs : 0.18110132217407227
Decodertime : 0.000171661376953125
g_f_logprobs : 0.18609118461608887
beam_search_time: 9.92642617225647 s
g_f_logprobs : 0.2460324764251709
Decodertime : 0.00018715858459472656
Decodertime : 0.00018787384033203125
g_f_logprobs : 0.8295934200286865
Decodertime : 0.0001888275146484375
g_f_logprobs : 0.17774033546447754
beam_search_time: 9.861576080322266 s
g_f_logprobs : 0.26195645332336426
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.8555054664611816
Decodertime : 0.0002231597900390625
Decodertime : 0.000232696533203125
g_f_logprobs : 0.21758317947387695
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.23490166664123535
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.21629953384399414
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.23071813583374023
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.2162623405456543
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.23037147521972656
Decodertime : 0.0001480579376220703
g_f_logprobs : 0.21609807014465332
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.23058390617370605
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.21625542640686035
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.23053956031799316
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.2160937786102295
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.23023748397827148
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.21612048149108887
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.23066973686218262
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.21621322631835938
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.23031306266784668
Decodertime : 0.0001685619354248047
g_f_logprobs : 0.21642208099365234
Decodertime : 0.00017023086547851562
g_f_logprobs : 0.23071670532226562
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.2164630889892578
Decodertime : 0.00018906593322753906
g_f_logprobs : 0.23054194450378418
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.21642279624938965
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.23064565658569336
Decodertime : 0.00014781951904296875
g_f_logprobs : 0.2163398265838623
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.23071050643920898
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.21641135215759277
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.23064780235290527
Decodertime : 0.000152587890625
g_f_logprobs : 0.21653199195861816
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.2309584617614746
Decodertime : 0.0001819133758544922
g_f_logprobs : 0.2166132926940918
Decodertime : 0.00018095970153808594
g_f_logprobs : 0.21392583847045898
Decodertime : 0.00017380714416503906
g_f_logprobs : 0.23255491256713867
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.21682977676391602
Decodertime : 0.00017213821411132812
g_f_logprobs : 0.23045086860656738
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.21653437614440918
Decodertime : 0.00017142295837402344
g_f_logprobs : 0.23075366020202637
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.21645712852478027
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.23088479042053223
Decodertime : 0.00017499923706054688
g_f_logprobs : 0.21601557731628418
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.23018789291381836
Decodertime : 0.00017023086547851562
g_f_logprobs : 0.21602225303649902
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.23057198524475098
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.21646475791931152
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.23048043251037598
Decodertime : 0.000164031982421875
g_f_logprobs : 0.2160029411315918
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.23037195205688477
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.21600866317749023
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.23043394088745117
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.21616315841674805
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.23042964935302734
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.2164626121520996
Decodertime : 0.000164031982421875
g_f_logprobs : 0.23047232627868652
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.21625971794128418
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.22954607009887695
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.21530604362487793
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.23067378997802734
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.21659541130065918
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.23044657707214355
Decodertime : 0.0001780986785888672
g_f_logprobs : 0.2158520221710205
Decodertime : 0.00018215179443359375
g_f_logprobs : 0.23063373565673828
Decodertime : 0.00020360946655273438
g_f_logprobs : 0.21644282341003418
Decodertime : 0.00022172927856445312
g_f_logprobs : 0.213958740234375
Decodertime : 0.00017118453979492188
g_f_logprobs : 0.23274874687194824
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.21619415283203125
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.2304394245147705
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.21535587310791016
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.2297837734222412
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.21623659133911133
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.2307744026184082
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.2163379192352295
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.23066473007202148
Decodertime : 0.00014495849609375
g_f_logprobs : 0.21641755104064941
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.23079204559326172
Decodertime : 0.00014495849609375
g_f_logprobs : 0.2185814380645752
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.23113656044006348
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.21655011177062988
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.23076653480529785
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.21647071838378906
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.23046398162841797
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.21639633178710938
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.23063039779663086
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.21636605262756348
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.23039865493774414
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.2162916660308838
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.22994184494018555
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.21538734436035156
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.23044228553771973
Decodertime : 0.00014352798461914062
g_f_logprobs : 0.21639680862426758
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.23061513900756836
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.2162337303161621
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.23045086860656738
beam_search_time: 11.35854721069336 s
g_f_logprobs : 0.21123480796813965
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.9444019794464111
Decodertime : 0.00017452239990234375
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.213029146194458
Decodertime : 0.00017261505126953125
g_f_logprobs : 0.23154306411743164
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.21611547470092773
beam_search_time: 11.624488353729248 s
g_f_logprobs : 0.34333181381225586
Decodertime : 0.00014829635620117188
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.7786660194396973
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.21753454208374023
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.23034954071044922
Decodertime : 0.00014781951904296875
g_f_logprobs : 0.21616291999816895
Decodertime : 0.00019216537475585938
g_f_logprobs : 0.23073220252990723
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.21659255027770996
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.2304978370666504
Decodertime : 0.00017070770263671875
g_f_logprobs : 0.21631264686584473
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.23047089576721191
Decodertime : 0.00014495849609375
g_f_logprobs : 0.2161111831665039
Decodertime : 0.0001678466796875
g_f_logprobs : 0.230452299118042
Decodertime : 0.000152587890625
g_f_logprobs : 0.21644377708435059
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.23059678077697754
Decodertime : 0.0001437664031982422
g_f_logprobs : 0.21628022193908691
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.23026490211486816
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.21624302864074707
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.2300713062286377
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.21569037437438965
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.23050856590270996
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.21633148193359375
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.23063302040100098
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.2164602279663086
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.23047137260437012
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.21624374389648438
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.2307415008544922
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.21632146835327148
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.21387434005737305
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.2322697639465332
Decodertime : 0.0001437664031982422
g_f_logprobs : 0.21629643440246582
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.23047971725463867
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.21587705612182617
Decodertime : 0.000164031982421875
g_f_logprobs : 0.23030543327331543
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.21645259857177734
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.2309095859527588
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.21628212928771973
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.23069286346435547
Decodertime : 0.00014495849609375
g_f_logprobs : 0.21628928184509277
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.2305893898010254
Decodertime : 0.00014400482177734375
g_f_logprobs : 0.21654939651489258
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.23050761222839355
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.2159867286682129
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.23056507110595703
Decodertime : 0.00014495849609375
g_f_logprobs : 0.21635961532592773
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.23042774200439453
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.2160797119140625
Decodertime : 0.0001850128173828125
g_f_logprobs : 0.23064947128295898
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.2164463996887207
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.23043060302734375
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.21592044830322266
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.2305440902709961
Decodertime : 0.0001747608184814453
g_f_logprobs : 0.21643877029418945
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.2303938865661621
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.21628069877624512
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.22983360290527344
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.2155013084411621
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.2303314208984375
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.21413445472717285
Decodertime : 0.00014829635620117188
g_f_logprobs : 0.2128596305847168
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.23243403434753418
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.21615099906921387
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.23043012619018555
Decodertime : 0.000152587890625
g_f_logprobs : 0.2164163589477539
Decodertime : 0.000164031982421875
g_f_logprobs : 0.2306811809539795
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.21610188484191895
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.230682373046875
Decodertime : 0.00014495849609375
g_f_logprobs : 0.2164454460144043
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.23058056831359863
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.2164008617401123
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.23050594329833984
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.21631598472595215
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.23051071166992188
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.21626496315002441
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.2305893898010254
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.21650290489196777
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.23056483268737793
Decodertime : 0.00014281272888183594
g_f_logprobs : 0.21634888648986816
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.23044538497924805
Decodertime : 0.00014400482177734375
g_f_logprobs : 0.21625494956970215
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.23047852516174316
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.2161564826965332
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.23022770881652832
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.2162179946899414
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.2307279109954834
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.2165207862854004
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.2304060459136963
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.216231107711792
Decodertime : 0.00018334388732910156
g_f_logprobs : 0.21397900581359863
g_f_logprobs : 0.230757474899292
beam_search_time: 9.806262731552124 s
Decodertime : 0.00015020370483398438
g_f_logprobs : 1.035952091217041
Decodertime : 0.0001761913299560547
Decodertime : 0.00017881393432617188
g_f_logprobs : 0.2314472198486328
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.24890851974487305
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.23127269744873047
Decodertime : 0.00017189979553222656
g_f_logprobs : 0.24837064743041992
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.23110580444335938
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.2479844093322754
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.2311384677886963
beam_search_time: 13.098753690719604 s
g_f_logprobs : 0.2751612663269043
Decodertime : 0.00016427040100097656
Decodertime : 0.000171661376953125
g_f_logprobs : 0.9851124286651611
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.2421433925628662
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.2482156753540039
Decodertime : 0.000152587890625
g_f_logprobs : 0.2409529685974121
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.24818015098571777
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.2407701015472412
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.24791669845581055
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.24121308326721191
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.24841666221618652
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.24119782447814941
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.24816060066223145
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.24098443984985352
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.24823403358459473
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.24112534523010254
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.2479534149169922
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.24070000648498535
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.24816322326660156
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.24045419692993164
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.24723553657531738
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.24101710319519043
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.24822616577148438
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.24083757400512695
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.24768352508544922
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.240570068359375
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.24793624877929688
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.24100708961486816
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.24781537055969238
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.24035906791687012
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.2484755516052246
beam_search_time: 5.516939640045166 s
g_f_logprobs : 0.5924208164215088
Decodertime : 0.00021719932556152344
Decodertime : 0.0002086162567138672
g_f_logprobs : 0.6906735897064209
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.2492692470550537
Decodertime : 0.0001761913299560547
g_f_logprobs : 0.24115204811096191
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.24718284606933594
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.24007797241210938
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.24833941459655762
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.24114060401916504
Decodertime : 0.0001697540283203125
g_f_logprobs : 0.24787044525146484
Decodertime : 0.000152587890625
g_f_logprobs : 0.2406635284423828
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.2478618621826172
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.24090147018432617
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.24809503555297852
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.24057245254516602
Decodertime : 0.00014495849609375
g_f_logprobs : 0.24783992767333984
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.24106740951538086
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.24786853790283203
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.24041414260864258
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.2480299472808838
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.24129509925842285
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.24812912940979004
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.24090957641601562
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.24825119972229004
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.2411491870880127
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.24793243408203125
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.2408158779144287
Decodertime : 0.00014495849609375
g_f_logprobs : 0.24734210968017578
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.2402803897857666
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.24789929389953613
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.24069643020629883
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.23843860626220703
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.24885320663452148
Decodertime : 0.000148773193359375
g_f_logprobs : 0.24018502235412598
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.24848413467407227
Decodertime : 0.00018739700317382812
g_f_logprobs : 0.24095726013183594
Decodertime : 0.00017786026000976562
g_f_logprobs : 0.24631118774414062
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.24080753326416016
beam_search_time: 9.058978796005249 s
g_f_logprobs : 0.2696511745452881
Decodertime : 0.00016045570373535156
g_f_logprobs : 1.002539873123169
beam_search_time: 5.542776107788086 s
Decodertime : 0.00018548965454101562
Decodertime : 0.00018715858459472656
g_f_logprobs : 0.989490270614624
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.25226831436157227
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.26630306243896484
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.25106024742126465
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.2660379409790039
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.24999785423278809
Decodertime : 0.00017905235290527344
g_f_logprobs : 0.26572608947753906
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.2506520748138428
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.2659938335418701
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.2506592273712158
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.26590514183044434
Decodertime : 0.0001723766326904297
g_f_logprobs : 0.25084805488586426
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.26608705520629883
Decodertime : 0.00014495849609375
g_f_logprobs : 0.25082898139953613
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.2661004066467285
Decodertime : 0.00014781951904296875
g_f_logprobs : 0.25075459480285645
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.26625537872314453
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.2508983612060547
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.265794038772583
Decodertime : 0.0001723766326904297
g_f_logprobs : 0.2504770755767822
Decodertime : 0.00017309188842773438
g_f_logprobs : 0.2657144069671631
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.2503223419189453
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.26593971252441406
beam_search_time: 3.939359664916992 s
g_f_logprobs : 0.4001333713531494
Decodertime : 0.00016307830810546875
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.955162763595581
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.26660990715026855
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.25037050247192383
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.2659108638763428
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.25057458877563477
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.26485514640808105
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.24948453903198242
Decodertime : 0.0001690387725830078
g_f_logprobs : 0.24788808822631836
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.26882481575012207
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.2507929801940918
Decodertime : 0.000152587890625
g_f_logprobs : 0.26613807678222656
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.25087928771972656
beam_search_time: 5.656628370285034 s
g_f_logprobs : 0.26707887649536133
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.9482283592224121
Decodertime : 0.00014901161193847656
Decodertime : 0.00017333030700683594
g_f_logprobs : 0.3849599361419678
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.26644182205200195
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.26643872261047363
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.2662346363067627
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.26640868186950684
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.266312837600708
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.26613759994506836
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.2661442756652832
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.26636290550231934
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.266357421875
Decodertime : 0.00018525123596191406
g_f_logprobs : 0.26640963554382324
Decodertime : 0.000148773193359375
g_f_logprobs : 0.26622605323791504
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.2664613723754883
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.266495943069458
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.2664330005645752
Decodertime : 0.00017762184143066406
g_f_logprobs : 0.2662513256072998
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.26629114151000977
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.26636314392089844
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.26656103134155273
Decodertime : 0.00014495849609375
g_f_logprobs : 0.26624369621276855
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.26607298851013184
Decodertime : 0.000152587890625
g_f_logprobs : 0.2662677764892578
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.26644086837768555
beam_search_time: 5.903727769851685 s
g_f_logprobs : 0.511211633682251
Decodertime : 0.0001533031463623047
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.9053895473480225
beam_search_time: 4.3765528202056885 s
input 0:  {"source": "32.7 % of all households were made up of individuals and 15.7 % had someone living alone who was 65 years of age or older .\n"}
prediction:  {"predictions": [[1, 2724, 28138, 1559, 110, 1104, 1155, 3065, 2, 3, 1127, 1189, 1146, 4, 5, 1104, 2833, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1405, 28138, 1559, 110, 2, 3, 1125, 4, 5, 1800, 1690, 2041, 1150, 1108, 2625, 1201, 1104, 1425, 1137, 2214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.040251292288303375, -0.01126482430845499, -0.07659673690795898, -0.16192197799682617, -0.16192197799682617, -0.16192197799682617, -0.16192197799682617, -0.16192197799682617, -0.16192197799682617, -0.16192197799682617], "metadata": {"source_tokens": ["32", "##.", "##7", "%", "of", "all", "households", "were", "made", "up", "of", "individuals", "and", "15", "##.", "##7", "%", "had", "someone", "living", "alone", "who", "was", "65", "years", "of", "age", "or", "older", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "32", "##.", "##7", "%", "of", "all", "households", "[unused2]", "[unused3]", "were", "made", "up", "[unused4]", "[unused5]", "of", "individuals", "[unused6]", "[SEP]", "[unused1]", "15", "##.", "##7", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "someone", "living", "alone", "who", "was", "65", "years", "of", "age", "or", "older", "[unused6]", "[SEP]"]]}

input 1:  {"source": "A CEN forms an important but small part of a Local Strategic Partnership .\n"}
prediction:  {"predictions": [[1, 138, 9855, 2249, 2, 3, 2769, 4, 5, 1126, 1696, 1133, 1353, 1226, 1104, 170, 5328, 12367, 17330, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00013301486615091562, -0.00017786026000976562, -0.00017976760864257812, -0.00017976760864257812, -0.00017976760864257812, -0.00017976760864257812, -0.00017976760864257812, -0.00017976760864257812, -0.00017976760864257812, -0.00017976760864257812], "metadata": {"source_tokens": ["A", "CE", "##N", "forms", "an", "important", "but", "small", "part", "of", "a", "Local", "Strategic", "Partnership", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "CE", "##N", "[unused2]", "[unused3]", "forms", "[unused4]", "[unused5]", "an", "important", "but", "small", "part", "of", "a", "Local", "Strategic", "Partnership", "[unused6]", "[SEP]"]]}

input 2:  {"source": "A Democrat , he became the youngest mayor in Pittsburgh 's history in September 2006 at the age of 26 .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1245, 4, 5, 1103, 6074, 4398, 1107, 5610, 112, 1116, 1607, 1107, 1347, 1386, 1120, 1103, 1425, 1104, 1744, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1245, 4, 5, 1103, 6074, 4398, 138, 7319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00254999240860343, -0.10077263414859772, -0.21202468872070312, -0.2116703987121582, -0.2116703987121582, -0.2116703987121582, -0.2116703987121582, -0.2116703987121582, -0.2116703987121582, -0.2116703987121582], "metadata": {"source_tokens": ["A", "Democrat", ",", "he", "became", "the", "youngest", "mayor", "in", "Pittsburgh", "'", "##s", "history", "in", "September", "2006", "at", "the", "age", "of", "26", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "the", "youngest", "mayor", "in", "Pittsburgh", "'", "##s", "history", "in", "September", "2006", "at", "the", "age", "of", "26", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "the", "youngest", "mayor", "A", "Democrat", "[unused6]", "[SEP]"]]}

input 3:  {"source": "A cafeteria is also located on the sixth floor , a chapel on the 14th floor , and a study hall on the 15th floor .\n"}
prediction:  {"predictions": [[1, 138, 18698, 2, 3, 1110, 1145, 1388, 4, 5, 1113, 1103, 3971, 1837, 117, 170, 6221, 1113, 1103, 5740, 1837, 117, 1105, 170, 2025, 2885, 1113, 1103, 5617, 1837, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.020252563059329987, -0.03293943405151367, -0.03220248222351074, -0.03220248222351074, -0.03220248222351074, -0.03220248222351074, -0.03220248222351074, -0.03220248222351074, -0.03220248222351074, -0.03220248222351074], "metadata": {"source_tokens": ["A", "cafeteria", "is", "also", "located", "on", "the", "sixth", "floor", ",", "a", "chapel", "on", "the", "14th", "floor", ",", "and", "a", "study", "hall", "on", "the", "15th", "floor", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "cafeteria", "[unused2]", "[unused3]", "is", "also", "located", "[unused4]", "[unused5]", "on", "the", "sixth", "floor", ",", "a", "chapel", "on", "the", "14th", "floor", ",", "and", "a", "study", "hall", "on", "the", "15th", "floor", "[unused6]", "[SEP]"]]}

input 4:  {"source": "A casting director at the time told Scott that he had wished that he 'd met him a week before ; he was casting for the `` G.I. Joe '' cartoon .\n"}
prediction:  {"predictions": [[1, 138, 9616, 1900, 1120, 1103, 1159, 2, 3, 1500, 4, 5, 2796, 1115, 1119, 1125, 5608, 1115, 1119, 112, 1181, 1899, 1140, 170, 1989, 1196, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 9616, 4, 5, 1111, 1103, 169, 28152, 144, 28138, 2240, 28138, 2658, 112, 28131, 11540, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 112, 1181, 1899, 4, 5, 1140, 170, 1989, 1196, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008082764223217964, -0.006510882172733545, -0.028939804062247276, -0.2531477212905884, -0.2700979709625244, -0.2700979709625244, -0.2700979709625244, -0.2700979709625244, -0.2700979709625244, -0.2700979709625244], "metadata": {"source_tokens": ["A", "casting", "director", "at", "the", "time", "told", "Scott", "that", "he", "had", "wished", "that", "he", "'", "##d", "met", "him", "a", "week", "before", ";", "he", "was", "casting", "for", "the", "`", "##`", "G", "##.", "##I", "##.", "Joe", "'", "##'", "cartoon", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "casting", "director", "at", "the", "time", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "Scott", "that", "he", "had", "wished", "that", "he", "'", "##d", "met", "him", "a", "week", "before", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "casting", "[unused4]", "[unused5]", "for", "the", "`", "##`", "G", "##.", "##I", "##.", "Joe", "'", "##'", "cartoon", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "'", "##d", "met", "[unused4]", "[unused5]", "him", "a", "week", "before", "[unused6]", "[SEP]"]]}

input 5:  {"source": "A common name , logo , and programming schedule followed in 1982 , with the establishment of the `` TV8 '' network between the three stations , changed to the `` Southern Cross Network '' seven years later .\n"}
prediction:  {"predictions": [[1, 138, 1887, 1271, 117, 7998, 117, 1105, 4159, 6030, 2, 3, 1723, 4, 5, 1107, 2294, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 169, 28152, 1794, 1604, 112, 28131, 2443, 1206, 1103, 1210, 2930, 2, 3, 2014, 4, 5, 1106, 1103, 169, 28152, 2685, 3156, 3998, 112, 28131, 1978, 1201, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 1887, 1271, 7998, 1105, 4159, 6030, 2, 3, 1723, 4, 5, 1107, 2294, 1114, 1103, 4544, 1104, 1103, 1794, 1604, 2443, 1206, 1103, 1210, 2930, 2014, 1106, 1103, 2685, 3156, 3998, 1978, 1201, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04716460779309273, -0.03884589672088623, -0.04825519025325775, -0.11926436424255371, -0.11929607391357422, -0.11929607391357422, -0.11929607391357422, -0.11929607391357422, -0.11929607391357422, -0.11929607391357422], "metadata": {"source_tokens": ["A", "common", "name", ",", "logo", ",", "and", "programming", "schedule", "followed", "in", "1982", ",", "with", "the", "establishment", "of", "the", "`", "##`", "TV", "##8", "'", "##'", "network", "between", "the", "three", "stations", ",", "changed", "to", "the", "`", "##`", "Southern", "Cross", "Network", "'", "##'", "seven", "years", "later", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "common", "name", ",", "logo", ",", "and", "programming", "schedule", "[unused2]", "[unused3]", "followed", "[unused4]", "[unused5]", "in", "1982", "[unused6]", "[SEP]", "[unused1]", "the", "`", "##`", "TV", "##8", "'", "##'", "network", "between", "the", "three", "stations", "[unused2]", "[unused3]", "changed", "[unused4]", "[unused5]", "to", "the", "`", "##`", "Southern", "Cross", "Network", "'", "##'", "seven", "years", "later", "[unused6]", "[SEP]", "[unused1]", "A", "common", "name", "logo", "and", "programming", "schedule", "[unused2]", "[unused3]", "followed", "[unused4]", "[unused5]", "in", "1982", "with", "the", "establishment", "of", "the", "TV", "##8", "network", "between", "the", "three", "stations", "changed", "to", "the", "Southern", "Cross", "Network", "seven", "years", "later", "[unused6]", "[SEP]"]]}

input 6:  {"source": "A cooling center is a temporary air-conditioned public space set up by local authorities to deal with the health effects of a heat wave .\n"}
prediction:  {"predictions": [[1, 138, 12147, 2057, 2, 3, 1110, 4, 5, 170, 5335, 1586, 28137, 7235, 14669, 1174, 1470, 2000, 1383, 1146, 1118, 1469, 3912, 1106, 2239, 1114, 1103, 2332, 3154, 1104, 170, 3208, 4003, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 5335, 1586, 28137, 7235, 14669, 1174, 1470, 2000, 2, 3, 1383, 1146, 4, 5, 1118, 1469, 3912, 1106, 2239, 1114, 1103, 2332, 3154, 1104, 170, 3208, 4003, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.018537171185016632, -0.01244081649929285, -0.04349637031555176, -0.04011964797973633, -0.04011964797973633, -0.04011964797973633, -0.04011964797973633, -0.04011964797973633, -0.04011964797973633, -0.04011964797973633], "metadata": {"source_tokens": ["A", "cooling", "center", "is", "a", "temporary", "air", "##-", "##con", "##dition", "##ed", "public", "space", "set", "up", "by", "local", "authorities", "to", "deal", "with", "the", "health", "effects", "of", "a", "heat", "wave", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "cooling", "center", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "temporary", "air", "##-", "##con", "##dition", "##ed", "public", "space", "set", "up", "by", "local", "authorities", "to", "deal", "with", "the", "health", "effects", "of", "a", "heat", "wave", "[unused6]", "[SEP]", "[unused1]", "a", "temporary", "air", "##-", "##con", "##dition", "##ed", "public", "space", "[unused2]", "[unused3]", "set", "up", "[unused4]", "[unused5]", "by", "local", "authorities", "to", "deal", "with", "the", "health", "effects", "of", "a", "heat", "wave", "[unused6]", "[SEP]"]]}

input 7:  {"source": "A manifold is `` prime '' if it can not be presented as a connected sum of more than one manifold , none of which is the sphere of the same dimension .\n"}
prediction:  {"predictions": [[1, 3839, 1104, 1134, 2, 3, 1110, 4, 5, 1103, 11036, 1104, 1103, 1269, 11025, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 22502, 2, 3, 1110, 4, 5, 5748, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1169, 1136, 1129, 2756, 4, 5, 1112, 170, 3387, 7584, 1104, 1167, 1190, 1141, 22502, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.039255134761333466, -0.04676647484302521, -0.0021644432563334703, -0.03220939636230469, -0.032209157943725586, -0.032209157943725586, -0.032209157943725586, -0.032209157943725586, -0.032209157943725586, -0.032209157943725586], "metadata": {"source_tokens": ["A", "manifold", "is", "`", "##`", "prime", "'", "##'", "if", "it", "can", "not", "be", "presented", "as", "a", "connected", "sum", "of", "more", "than", "one", "manifold", ",", "none", "of", "which", "is", "the", "sphere", "of", "the", "same", "dimension", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "none", "of", "which", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "sphere", "of", "the", "same", "dimension", "[unused6]", "[SEP]", "[unused1]", "A", "manifold", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "prime", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "can", "not", "be", "presented", "[unused4]", "[unused5]", "as", "a", "connected", "sum", "of", "more", "than", "one", "manifold", "[unused6]", "[SEP]"]]}

input 8:  {"source": "A mid-March 2002 court order to stop printing for three months , was evaded by printing under other titles , such as `` Not That Respublika '' .\n"}
prediction:  {"predictions": [[1, 138, 2286, 28137, 2107, 1813, 1732, 1617, 2175, 1546, 2, 3, 1108, 174, 27923, 1181, 4, 5, 1118, 8455, 1223, 1168, 3727, 117, 1216, 1112, 169, 28152, 1753, 1337, 11336, 20080, 10354, 19921, 1161, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 2286, 28137, 2107, 1813, 1732, 1617, 2175, 1546, 1106, 1831, 8455, 1111, 1210, 1808, 2, 3, 1108, 174, 27923, 1181, 4, 5, 1118, 8455, 1223, 1168, 3727, 1216, 1112, 1753, 1337, 11336, 20080, 10354, 19921, 1161, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01397145725786686, -0.05804324895143509, -0.07699060440063477, -0.0770714282989502, -0.0770714282989502, -0.0770714282989502, -0.0770714282989502, -0.0770714282989502, -0.0770714282989502, -0.0770714282989502], "metadata": {"source_tokens": ["A", "mid", "##-", "##M", "##ar", "##ch", "2002", "court", "order", "to", "stop", "printing", "for", "three", "months", ",", "was", "e", "##vade", "##d", "by", "printing", "under", "other", "titles", ",", "such", "as", "`", "##`", "Not", "That", "Re", "##sp", "##ub", "##lik", "##a", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "mid", "##-", "##M", "##ar", "##ch", "2002", "court", "order", "[unused2]", "[unused3]", "was", "e", "##vade", "##d", "[unused4]", "[unused5]", "by", "printing", "under", "other", "titles", ",", "such", "as", "`", "##`", "Not", "That", "Re", "##sp", "##ub", "##lik", "##a", "[unused6]", "[SEP]", "[unused1]", "A", "mid", "##-", "##M", "##ar", "##ch", "2002", "court", "order", "to", "stop", "printing", "for", "three", "months", "[unused2]", "[unused3]", "was", "e", "##vade", "##d", "[unused4]", "[unused5]", "by", "printing", "under", "other", "titles", "such", "as", "Not", "That", "Re", "##sp", "##ub", "##lik", "##a", "[unused6]", "[SEP]"]]}

input 9:  {"source": "A motorcycle speedway long-track meeting , one of the few held in the UK , was staged at Ammanford .\n"}
prediction:  {"predictions": [[1, 1103, 1374, 2, 3, 1316, 4, 5, 1107, 1103, 1993, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 9580, 2420, 2787, 1263, 28137, 22117, 2309, 2, 3, 1108, 9645, 4, 5, 1120, 7277, 1399, 2821, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009579567238688469, -0.005473664961755276, -0.038707733154296875, -0.038590431213378906, -0.038590431213378906, -0.038590431213378906, -0.038590431213378906, -0.038590431213378906, -0.038590431213378906, -0.038590431213378906], "metadata": {"source_tokens": ["A", "motorcycle", "speed", "##way", "long", "##-", "##track", "meeting", ",", "one", "of", "the", "few", "held", "in", "the", "UK", ",", "was", "staged", "at", "Am", "##man", "##ford", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "few", "[unused2]", "[unused3]", "held", "[unused4]", "[unused5]", "in", "the", "UK", "[unused6]", "[SEP]", "[unused1]", "A", "motorcycle", "speed", "##way", "long", "##-", "##track", "meeting", "[unused2]", "[unused3]", "was", "staged", "[unused4]", "[unused5]", "at", "Am", "##man", "##ford", "[unused6]", "[SEP]"]]}

input 10:  {"source": "A partial list of turbomachinery that may use one or more centrifugal compressors within the machine are listed here .\n"}
prediction:  {"predictions": [[1, 138, 7597, 2190, 1104, 189, 2149, 4043, 1918, 12285, 5075, 2, 3, 1132, 2345, 4, 5, 1303, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 189, 2149, 4043, 1918, 12285, 5075, 2, 3, 1336, 1329, 4, 5, 1141, 1137, 1167, 9848, 2047, 14703, 6997, 3254, 11135, 3864, 1439, 1103, 3395, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.029831552878022194, -0.015589816495776176, -0.009060859680175781, -0.009078502655029297, -0.009078502655029297, -0.009078502655029297, -0.009078502655029297, -0.009078502655029297, -0.009078502655029297, -0.009078502655029297], "metadata": {"source_tokens": ["A", "partial", "list", "of", "t", "##ur", "##bo", "##ma", "##chin", "##ery", "that", "may", "use", "one", "or", "more", "cent", "##ri", "##fu", "##gal", "com", "##press", "##ors", "within", "the", "machine", "are", "listed", "here", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "partial", "list", "of", "t", "##ur", "##bo", "##ma", "##chin", "##ery", "[unused2]", "[unused3]", "are", "listed", "[unused4]", "[unused5]", "here", "[unused6]", "[SEP]", "[unused1]", "t", "##ur", "##bo", "##ma", "##chin", "##ery", "[unused2]", "[unused3]", "may", "use", "[unused4]", "[unused5]", "one", "or", "more", "cent", "##ri", "##fu", "##gal", "com", "##press", "##ors", "within", "the", "machine", "[unused6]", "[SEP]"]]}

input 11:  {"source": "A short distance to the east , NC 111 diverges on Greenwood Boulevard .\n"}
prediction:  {"predictions": [[1, 14056, 11084, 2, 3, 23448, 7562, 4, 5, 1113, 17999, 8691, 138, 1603, 2462, 1106, 1103, 1746, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0007884502410888672, -0.008979320526123047, -0.008939743041992188, -0.008939743041992188, -0.008939743041992188, -0.008939743041992188, -0.008939743041992188, -0.008939743041992188, -0.008939743041992188, -0.008939743041992188], "metadata": {"source_tokens": ["A", "short", "distance", "to", "the", "east", ",", "NC", "111", "diver", "##ges", "on", "Greenwood", "Boulevard", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "NC", "111", "[unused2]", "[unused3]", "diver", "##ges", "[unused4]", "[unused5]", "on", "Greenwood", "Boulevard", "A", "short", "distance", "to", "the", "east", "[unused6]", "[SEP]"]]}

input 12:  {"source": "A spectrum from a single FID has a low signal-to-noise ratio , but fortunately it improves readily with averaging of repeated acquisitions .\n"}
prediction:  {"predictions": [[1, 138, 10122, 1121, 170, 1423, 143, 9949, 2, 3, 1144, 4, 5, 170, 1822, 4344, 28137, 2430, 28137, 2728, 4862, 6022, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 4607, 1116, 12337, 4, 5, 1114, 15883, 1104, 4892, 23345, 22649, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0030914098024368286, -0.051216915249824524, -0.03378939628601074, -0.03606247901916504, -0.03606247901916504, -0.03606247901916504, -0.03606247901916504, -0.03606247901916504, -0.03606247901916504, -0.03606247901916504], "metadata": {"source_tokens": ["A", "spectrum", "from", "a", "single", "F", "##ID", "has", "a", "low", "signal", "##-", "##to", "##-", "##no", "##ise", "ratio", ",", "but", "fortunate", "##ly", "it", "improve", "##s", "readily", "with", "averaging", "of", "repeated", "acquisitions", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "spectrum", "from", "a", "single", "F", "##ID", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "a", "low", "signal", "##-", "##to", "##-", "##no", "##ise", "ratio", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "improve", "##s", "readily", "[unused4]", "[unused5]", "with", "averaging", "of", "repeated", "acquisitions", "fortunate", "##ly", "[unused6]", "[SEP]"]]}

input 13:  {"source": "According to Hofmann , while still a teenage coin collector , he forged a rare mint mark on a dime and was told by an organization of coin collectors that it was genuine .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 17667, 4, 5, 170, 4054, 22532, 4551, 1113, 170, 12563, 1162, 1229, 1253, 170, 11009, 9584, 12116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1500, 4, 5, 1118, 1126, 2369, 1104, 9584, 16801, 1115, 1122, 1108, 10416, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 17667, 4, 5, 170, 4054, 22532, 4551, 1113, 170, 12563, 1162, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 10416, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 17667, 4, 5, 170, 4054, 22532, 4551, 1792, 1106, 9800, 2087, 4119, 1229, 1253, 170, 11009, 9584, 12116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.032319165766239166, -0.053745515644550323, -0.16080814599990845, -0.13041505217552185, -0.13776765763759613, -0.2960219383239746, -0.294277548789978, -0.294277548789978, -0.294277548789978, -0.294277548789978], "metadata": {"source_tokens": ["According", "to", "Ho", "##f", "##mann", ",", "while", "still", "a", "teenage", "coin", "collector", ",", "he", "forged", "a", "rare", "mint", "mark", "on", "a", "dim", "##e", "and", "was", "told", "by", "an", "organization", "of", "coin", "collectors", "that", "it", "was", "genuine", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "forged", "[unused4]", "[unused5]", "a", "rare", "mint", "mark", "on", "a", "dim", "##e", "while", "still", "a", "teenage", "coin", "collector", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "told", "[unused4]", "[unused5]", "by", "an", "organization", "of", "coin", "collectors", "that", "it", "was", "genuine", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "forged", "[unused4]", "[unused5]", "a", "rare", "mint", "mark", "on", "a", "dim", "##e", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "genuine", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "forged", "[unused4]", "[unused5]", "a", "rare", "mint", "mark", "According", "to", "Ho", "##f", "##mann", "while", "still", "a", "teenage", "coin", "collector", "[unused6]", "[SEP]"]]}

input 14:  {"source": "According to Samaritan tradition , however , the Samaritan ethnonym is not derived from the region of Samaria , but from the fact that they were the `` Guardians '' of the true Israelite religion .\n"}
prediction:  {"predictions": [[1, 1103, 2687, 7710, 5108, 3084, 7272, 10031, 1306, 2, 3, 1110, 1136, 4408, 4, 5, 1121, 1103, 1805, 1104, 2687, 11315, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1127, 4, 5, 1103, 169, 28152, 21444, 112, 28131, 1104, 1103, 2276, 4878, 1566, 4483, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012910649180412292, -0.00733146769925952, -0.1824343204498291, -0.19151735305786133, -0.19151735305786133, -0.19151735305786133, -0.19151735305786133, -0.19151735305786133, -0.19151735305786133, -0.19151735305786133], "metadata": {"source_tokens": ["According", "to", "Sam", "##ari", "##tan", "tradition", ",", "however", ",", "the", "Sam", "##ari", "##tan", "et", "##hn", "##ony", "##m", "is", "not", "derived", "from", "the", "region", "of", "Sam", "##aria", ",", "but", "from", "the", "fact", "that", "they", "were", "the", "`", "##`", "Guardians", "'", "##'", "of", "the", "true", "Israeli", "##te", "religion", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Sam", "##ari", "##tan", "et", "##hn", "##ony", "##m", "[unused2]", "[unused3]", "is", "not", "derived", "[unused4]", "[unused5]", "from", "the", "region", "of", "Sam", "##aria", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "the", "`", "##`", "Guardians", "'", "##'", "of", "the", "true", "Israeli", "##te", "religion", "[unused6]", "[SEP]"]]}

input 15:  {"source": "According to the 2010 census , the population of the town is 2,310 .\n"}
prediction:  {"predictions": [[1, 1103, 1416, 1104, 1103, 1411, 2, 3, 1110, 4, 5, 123, 28136, 22639, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00034656282514333725, -0.0005140304565429688, -0.00047397613525390625, -0.00047397613525390625, -0.00047397613525390625, -0.00047397613525390625, -0.00047397613525390625, -0.00047397613525390625, -0.00047397613525390625, -0.00047397613525390625], "metadata": {"source_tokens": ["According", "to", "the", "2010", "census", ",", "the", "population", "of", "the", "town", "is", "2", "##,", "##31", "##0", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "population", "of", "the", "town", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "2", "##,", "##31", "##0", "[unused6]", "[SEP]"]]}

input 16:  {"source": "According to the South Koreans , many Koreans became victims of Japanese brutalities during the colonial period .\n"}
prediction:  {"predictions": [[1, 1242, 27757, 2, 3, 1245, 4, 5, 5256, 1104, 1983, 12800, 4233, 1219, 1103, 5929, 1669, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0007418582099489868, -0.021996021270751953, -0.021996021270751953, -0.021996021270751953, -0.021996021270751953, -0.021996021270751953, -0.021996021270751953, -0.021996021270751953, -0.021996021270751953, -0.021996021270751953], "metadata": {"source_tokens": ["According", "to", "the", "South", "Koreans", ",", "many", "Koreans", "became", "victims", "of", "Japanese", "brutal", "##ities", "during", "the", "colonial", "period", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "many", "Koreans", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "victims", "of", "Japanese", "brutal", "##ities", "during", "the", "colonial", "period", "[unused6]", "[SEP]"]]}

input 17:  {"source": "According to the United States Census Bureau , the town has a total area of , all of it land .\n"}
prediction:  {"predictions": [[1, 1103, 1411, 2, 3, 1144, 4, 5, 170, 1703, 1298, 1104, 117, 1155, 1104, 1122, 1657, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0014769978588446975, -0.008933544158935547, -0.008981704711914062, -0.008981704711914062, -0.008981704711914062, -0.008981704711914062, -0.008981704711914062, -0.008981704711914062, -0.008981704711914062, -0.008981704711914062], "metadata": {"source_tokens": ["According", "to", "the", "United", "States", "Census", "Bureau", ",", "the", "town", "has", "a", "total", "area", "of", ",", "all", "of", "it", "land", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "town", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "a", "total", "area", "of", ",", "all", "of", "it", "land", "[unused6]", "[SEP]"]]}

input 18:  {"source": "According to the indictment , Gonzalez is accused of defrauding the West Bronx Neighborhood Association Inc. , a not-for-profit corporation , by using funds donated to the organization in order to pay for over $ 37,000 in personal expenses .\n"}
prediction:  {"predictions": [[1, 21125, 2, 3, 1110, 4806, 4, 5, 1104, 19353, 1611, 21705, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 28138, 1118, 1606, 4381, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4381, 2, 3, 6384, 4, 5, 1106, 1103, 2369, 1107, 1546, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21125, 2, 3, 1110, 4806, 4, 5, 1104, 19353, 1611, 21705, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 1118, 1606, 4381, 6384, 1106, 1103, 2369, 1107, 1546, 1106, 2653, 1111, 1166, 109, 3413, 28136, 7629, 1568, 1107, 2357, 11928, 1792, 1106, 1103, 27926, 6, 102, 102, 102, 1, 21125, 2, 3, 1110, 4806, 4, 5, 1104, 19353, 1611, 21705, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 1118, 1606, 4381, 6384, 1106, 1103, 2369, 1107, 1546, 1106, 2653, 1111, 1166, 109, 3413, 28136, 7629, 1568, 1107, 2357, 11928, 6, 102, 102, 102, 102, 102, 102, 102, 1, 21125, 2, 3, 1110, 4806, 4, 5, 1104, 19353, 1611, 21705, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 1118, 1606, 4381, 6384, 1106, 1103, 2369, 1107, 1546, 1106, 2653, 1111, 1166, 109, 3413, 28136, 7629, 1568, 1107, 2357, 11928, 6, 102, 102, 102, 102, 102, 102, 102, 1, 21125, 2, 3, 1110, 4806, 4, 5, 1104, 19353, 1611, 21705, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 1118, 1606, 4381, 6384, 1106, 1103, 2369, 1107, 1546, 1106, 2653, 1111, 1166, 109, 3413, 28136, 7629, 1568, 1107, 2357, 11928, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.08918242156505585, -0.03237256780266762, -0.06460634618997574, -0.0760592371225357, -0.08396878838539124, -0.09265950322151184, -0.2931957244873047, -0.2983872890472412, -0.2984158992767334, -0.2984158992767334], "metadata": {"source_tokens": ["According", "to", "the", "indictment", ",", "Gonzalez", "is", "accused", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "##.", ",", "a", "not", "##-", "##fo", "##r", "##-", "##p", "##ro", "##fit", "corporation", ",", "by", "using", "funds", "donated", "to", "the", "organization", "in", "order", "to", "pay", "for", "over", "$", "37", "##,", "##00", "##0", "in", "personal", "expenses", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Gonzalez", "[unused2]", "[unused3]", "is", "accused", "[unused4]", "[unused5]", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "##.", "by", "using", "funds", "[unused6]", "[SEP]", "[unused1]", "funds", "[unused2]", "[unused3]", "donated", "[unused4]", "[unused5]", "to", "the", "organization", "in", "order", "[unused6]", "[SEP]", "[unused1]", "Gonzalez", "[unused2]", "[unused3]", "is", "accused", "[unused4]", "[unused5]", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "by", "using", "funds", "donated", "to", "the", "organization", "in", "order", "to", "pay", "for", "over", "$", "37", "##,", "##00", "##0", "in", "personal", "expenses", "According", "to", "the", "indictment", "[unused6]", "[SEP]", "[unused1]", "Gonzalez", "[unused2]", "[unused3]", "is", "accused", "[unused4]", "[unused5]", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "by", "using", "funds", "donated", "to", "the", "organization", "in", "order", "to", "pay", "for", "over", "$", "37", "##,", "##00", "##0", "in", "personal", "expenses", "[unused6]", "[SEP]", "[unused1]", "Gonzalez", "[unused2]", "[unused3]", "is", "accused", "[unused4]", "[unused5]", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "by", "using", "funds", "donated", "to", "the", "organization", "in", "order", "to", "pay", "for", "over", "$", "37", "##,", "##00", "##0", "in", "personal", "expenses", "[unused6]", "[SEP]", "[unused1]", "Gonzalez", "[unused2]", "[unused3]", "is", "accused", "[unused4]", "[unused5]", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "by", "using", "funds", "donated", "to", "the", "organization", "in", "order", "to", "pay", "for", "over", "$", "37", "##,", "##00", "##0", "in", "personal", "expenses", "[unused6]", "[SEP]"]]}

input 19:  {"source": "Accordingly , the 1962 Roman Missal , the edition whose continued use as an extraordinary form of the Roman Rite is authorized by the motu proprio `` Summorum Pontificum '' , also has no mention of her .\n"}
prediction:  {"predictions": [[1, 1103, 2832, 2264, 3056, 1348, 2, 3, 1144, 4, 5, 1185, 4734, 1104, 1123, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2596, 2133, 1598, 1329, 1112, 1126, 10264, 1532, 1104, 1103, 2264, 23787, 2, 3, 1110, 9320, 4, 5, 1118, 1103, 182, 3329, 1358, 21146, 8558, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.022223783656954765, -0.03468906134366989, -0.07695293426513672, -0.08094239234924316, -0.08094239234924316, -0.08094239234924316, -0.08094239234924316, -0.08094239234924316, -0.08094239234924316, -0.08094239234924316], "metadata": {"source_tokens": ["Accordingly", ",", "the", "1962", "Roman", "Miss", "##al", ",", "the", "edition", "whose", "continued", "use", "as", "an", "extraordinary", "form", "of", "the", "Roman", "Rite", "is", "authorized", "by", "the", "m", "##ot", "##u", "prop", "##rio", "`", "##`", "Su", "##mm", "##orum", "Pont", "##ific", "##um", "'", "##'", ",", "also", "has", "no", "mention", "of", "her", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "1962", "Roman", "Miss", "##al", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "no", "mention", "of", "her", "[unused6]", "[SEP]", "[unused1]", "the", "edition", "whose", "continued", "use", "as", "an", "extraordinary", "form", "of", "the", "Roman", "Rite", "[unused2]", "[unused3]", "is", "authorized", "[unused4]", "[unused5]", "by", "the", "m", "##ot", "##u", "prop", "##rio", "[unused6]", "[SEP]"]]}

input 20:  {"source": "Additionally , the French Community of Belgium has controversially begun referring to itself exclusively as the ` Wallonia-Brussels Federation ' to emphasize the links between the French Community , Wallonia and Brussels .\n"}
prediction:  {"predictions": [[1, 1103, 1497, 3704, 1104, 4990, 2, 3, 1144, 6241, 1193, 4972, 4, 5, 7455, 1106, 2111, 7097, 1112, 1103, 169, 6250, 11357, 28137, 2064, 25357, 5999, 4245, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1497, 3704, 1104, 4990, 2, 3, 1144, 4972, 4, 5, 7455, 1106, 2111, 7097, 1112, 1103, 6250, 11357, 28137, 2064, 25357, 5999, 4245, 1106, 19291, 1103, 6743, 1206, 1103, 1497, 3704, 6250, 11357, 1105, 9062, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1497, 3704, 1104, 4990, 2, 3, 1144, 4972, 4, 5, 7455, 1106, 2111, 7097, 1112, 1103, 6250, 11357, 28137, 2064, 25357, 5999, 4245, 1106, 19291, 1103, 6743, 1206, 1103, 1497, 3704, 6250, 11357, 1105, 9062, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05896937474608421, -0.06283696740865707, -0.07601100951433182, -0.21220695972442627, -0.2122100591659546, -0.2122100591659546, -0.2122100591659546, -0.2122100591659546, -0.2122100591659546, -0.2122100591659546], "metadata": {"source_tokens": ["Additionally", ",", "the", "French", "Community", "of", "Belgium", "has", "controversial", "##ly", "begun", "referring", "to", "itself", "exclusively", "as", "the", "`", "Wall", "##onia", "##-", "##B", "##russ", "##els", "Federation", "'", "to", "emphasize", "the", "links", "between", "the", "French", "Community", ",", "Wall", "##onia", "and", "Brussels", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "French", "Community", "of", "Belgium", "[unused2]", "[unused3]", "has", "controversial", "##ly", "begun", "[unused4]", "[unused5]", "referring", "to", "itself", "exclusively", "as", "the", "`", "Wall", "##onia", "##-", "##B", "##russ", "##els", "Federation", "[unused6]", "[SEP]", "[unused1]", "the", "French", "Community", "of", "Belgium", "[unused2]", "[unused3]", "has", "begun", "[unused4]", "[unused5]", "referring", "to", "itself", "exclusively", "as", "the", "Wall", "##onia", "##-", "##B", "##russ", "##els", "Federation", "to", "emphasize", "the", "links", "between", "the", "French", "Community", "Wall", "##onia", "and", "Brussels", "[unused6]", "[SEP]", "[unused1]", "the", "French", "Community", "of", "Belgium", "[unused2]", "[unused3]", "has", "begun", "[unused4]", "[unused5]", "referring", "to", "itself", "exclusively", "as", "the", "Wall", "##onia", "##-", "##B", "##russ", "##els", "Federation", "to", "emphasize", "the", "links", "between", "the", "French", "Community", "Wall", "##onia", "and", "Brussels", "[unused6]", "[SEP]"]]}

input 21:  {"source": "After 1895 cable hauling ceased and locomotives pulled trains the whole length of the Victoria and Waterloo tunnels .\n"}
prediction:  {"predictions": [[1, 7499, 2, 3, 1865, 4, 5, 3918, 1103, 2006, 2251, 1104, 1103, 3006, 1105, 14233, 11175, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5639, 6095, 26483, 2, 3, 6445, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03754458203911781, -0.06413079053163528, -0.032201290130615234, -0.032201290130615234, -0.032201290130615234, -0.032201290130615234, -0.032201290130615234, -0.032201290130615234, -0.032201290130615234, -0.032201290130615234], "metadata": {"source_tokens": ["After", "1895", "cable", "hauling", "ceased", "and", "locomotives", "pulled", "trains", "the", "whole", "length", "of", "the", "Victoria", "and", "Waterloo", "tunnels", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "locomotives", "[unused2]", "[unused3]", "pulled", "[unused4]", "[unused5]", "trains", "the", "whole", "length", "of", "the", "Victoria", "and", "Waterloo", "tunnels", "[unused6]", "[SEP]", "[unused1]", "1895", "cable", "hauling", "[unused2]", "[unused3]", "ceased", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 22:  {"source": "After five years of searching , the Colonials found a primitive , lush and vibrant new world and named it Earth .\n"}
prediction:  {"predictions": [[1, 1103, 10319, 1116, 2, 3, 1276, 4, 5, 170, 12130, 117, 19302, 1105, 18652, 1207, 1362, 1105, 1417, 1122, 2746, 1258, 1421, 1201, 1104, 6205, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 10319, 1116, 2, 3, 1417, 4, 5, 1122, 2746, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027314255014061928, -0.022129883989691734, -0.07634544372558594, -0.07634258270263672, -0.07634258270263672, -0.07634258270263672, -0.07634258270263672, -0.07634258270263672, -0.07634258270263672, -0.07634258270263672], "metadata": {"source_tokens": ["After", "five", "years", "of", "searching", ",", "the", "Colonial", "##s", "found", "a", "primitive", ",", "lush", "and", "vibrant", "new", "world", "and", "named", "it", "Earth", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Colonial", "##s", "[unused2]", "[unused3]", "found", "[unused4]", "[unused5]", "a", "primitive", ",", "lush", "and", "vibrant", "new", "world", "and", "named", "it", "Earth", "After", "five", "years", "of", "searching", "[unused6]", "[SEP]", "[unused1]", "the", "Colonial", "##s", "[unused2]", "[unused3]", "named", "[unused4]", "[unused5]", "it", "Earth", "[unused6]", "[SEP]"]]}

input 23:  {"source": "After leaving `` Hex '' , Cole went on to appear as Blanche Ingram in the critically acclaimed `` Jane Eyre '' TV serial for the BBC and guest starred as Lilith in the `` Doctor Who '' episode `` The Shakespeare Code '' .\n"}
prediction:  {"predictions": [[1, 4922, 2, 3, 1355, 1113, 4, 5, 1106, 2845, 1112, 21086, 25885, 1107, 1103, 11774, 10214, 169, 28152, 4074, 142, 10930, 112, 28131, 1794, 7838, 1111, 1103, 3173, 1105, 3648, 4950, 1112, 14138, 7088, 1107, 1103, 169, 28152, 4157, 2627, 112, 28131, 2004, 169, 28152, 1109, 7647, 6741, 1258, 102, 1, 4922, 2, 3, 1355, 1113, 4, 5, 1106, 2845, 1112, 21086, 25885, 1107, 1103, 11774, 10214, 4074, 142, 10930, 1794, 7838, 1111, 1103, 3173, 1105, 3648, 4950, 1112, 14138, 7088, 1107, 1103, 169, 28152, 4157, 2627, 2004, 169, 28152, 1109, 7647, 6741, 1258, 2128, 169, 28152, 1124, 1775, 6, 102, 1, 4922, 2, 3, 1355, 1113, 4, 5, 1106, 2845, 1112, 21086, 25885, 1107, 1103, 11774, 10214, 4074, 142, 10930, 1794, 7838, 1111, 1103, 3173, 1105, 3648, 4950, 1112, 14138, 7088, 1107, 1103, 169, 28152, 4157, 2627, 2004, 169, 28152, 1109, 7647, 6741, 6, 102, 102, 102, 102, 102, 102, 102, 1, 4922, 2, 3, 1355, 1113, 4, 5, 1106, 2845, 1112, 21086, 25885, 1107, 1103, 11774, 10214, 4074, 142, 10930, 1794, 7838, 1111, 1103, 3173, 1105, 3648, 4950, 1112, 14138, 7088, 1107, 1103, 4157, 2627, 2004, 1109, 7647, 6741, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.048490677028894424, -0.08640003204345703, -0.09949864447116852, -0.11622012406587601, -0.324383020401001, -0.32459378242492676, -0.32469677925109863, -0.32469677925109863, -0.32469677925109863, -0.32469677925109863], "metadata": {"source_tokens": ["After", "leaving", "`", "##`", "He", "##x", "'", "##'", ",", "Cole", "went", "on", "to", "appear", "as", "Blanche", "Ingram", "in", "the", "critically", "acclaimed", "`", "##`", "Jane", "E", "##yre", "'", "##'", "TV", "serial", "for", "the", "BBC", "and", "guest", "starred", "as", "Lil", "##ith", "in", "the", "`", "##`", "Doctor", "Who", "'", "##'", "episode", "`", "##`", "The", "Shakespeare", "Code", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Cole", "[unused2]", "[unused3]", "went", "on", "[unused4]", "[unused5]", "to", "appear", "as", "Blanche", "Ingram", "in", "the", "critically", "acclaimed", "`", "##`", "Jane", "E", "##yre", "'", "##'", "TV", "serial", "for", "the", "BBC", "and", "guest", "starred", "as", "Lil", "##ith", "in", "the", "`", "##`", "Doctor", "Who", "'", "##'", "episode", "`", "##`", "The", "Shakespeare", "Code", "After", "[SEP]", "[unused1]", "Cole", "[unused2]", "[unused3]", "went", "on", "[unused4]", "[unused5]", "to", "appear", "as", "Blanche", "Ingram", "in", "the", "critically", "acclaimed", "Jane", "E", "##yre", "TV", "serial", "for", "the", "BBC", "and", "guest", "starred", "as", "Lil", "##ith", "in", "the", "`", "##`", "Doctor", "Who", "episode", "`", "##`", "The", "Shakespeare", "Code", "After", "leaving", "`", "##`", "He", "##x", "[unused6]", "[SEP]", "[unused1]", "Cole", "[unused2]", "[unused3]", "went", "on", "[unused4]", "[unused5]", "to", "appear", "as", "Blanche", "Ingram", "in", "the", "critically", "acclaimed", "Jane", "E", "##yre", "TV", "serial", "for", "the", "BBC", "and", "guest", "starred", "as", "Lil", "##ith", "in", "the", "`", "##`", "Doctor", "Who", "episode", "`", "##`", "The", "Shakespeare", "Code", "[unused6]", "[SEP]", "[unused1]", "Cole", "[unused2]", "[unused3]", "went", "on", "[unused4]", "[unused5]", "to", "appear", "as", "Blanche", "Ingram", "in", "the", "critically", "acclaimed", "Jane", "E", "##yre", "TV", "serial", "for", "the", "BBC", "and", "guest", "starred", "as", "Lil", "##ith", "in", "the", "Doctor", "Who", "episode", "The", "Shakespeare", "Code", "[unused6]", "[SEP]"]]}

input 24:  {"source": "After the battle , Battra rested in the Arctic Ocean , whereas Mothra retired to Infant Island , accompanied by the two Cosmos .\n"}
prediction:  {"predictions": [[1, 21928, 4487, 2, 3, 8237, 4, 5, 1107, 1103, 10925, 4879, 1258, 1103, 2321, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12556, 1582, 1611, 2, 3, 2623, 4, 5, 1106, 1130, 26636, 2054, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1130, 26636, 2054, 2, 3, 4977, 4, 5, 1118, 1103, 1160, 3291, 18818, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21928, 4487, 2, 3, 8237, 4, 5, 1107, 1103, 10925, 4879, 6142, 12556, 1582, 1611, 2623, 1106, 1130, 26636, 2054, 4977, 1118, 1103, 1160, 3291, 18818, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.049348194152116776, -0.06026684492826462, -0.07035627961158752, -0.038729771971702576, -0.11983251571655273, -0.11972427368164062, -0.11972427368164062, -0.11972427368164062, -0.11972427368164062, -0.11972427368164062], "metadata": {"source_tokens": ["After", "the", "battle", ",", "Bat", "##tra", "rested", "in", "the", "Arctic", "Ocean", ",", "whereas", "Mo", "##th", "##ra", "retired", "to", "In", "##fant", "Island", ",", "accompanied", "by", "the", "two", "Co", "##smos", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Bat", "##tra", "[unused2]", "[unused3]", "rested", "[unused4]", "[unused5]", "in", "the", "Arctic", "Ocean", "After", "the", "battle", "[unused6]", "[SEP]", "[unused1]", "Mo", "##th", "##ra", "[unused2]", "[unused3]", "retired", "[unused4]", "[unused5]", "to", "In", "##fant", "Island", "[unused6]", "[SEP]", "[unused1]", "In", "##fant", "Island", "[unused2]", "[unused3]", "accompanied", "[unused4]", "[unused5]", "by", "the", "two", "Co", "##smos", "[unused6]", "[SEP]", "[unused1]", "Bat", "##tra", "[unused2]", "[unused3]", "rested", "[unused4]", "[unused5]", "in", "the", "Arctic", "Ocean", "whereas", "Mo", "##th", "##ra", "retired", "to", "In", "##fant", "Island", "accompanied", "by", "the", "two", "Co", "##smos", "[unused6]", "[SEP]"]]}

input 25:  {"source": "After this point many of the republicans were arrested in Free State `` round ups '' when they had come out of hiding and returned home .\n"}
prediction:  {"predictions": [[1, 1242, 1104, 1103, 22679, 1116, 2, 3, 1127, 3950, 4, 5, 1107, 4299, 1426, 169, 28152, 1668, 12534, 1258, 1142, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1125, 1435, 4, 5, 1149, 1104, 5797, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1608, 4, 5, 1313, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1242, 1104, 1103, 22679, 1116, 2, 3, 1127, 3950, 4, 5, 1107, 4299, 1426, 1668, 12534, 1165, 1152, 1125, 1435, 1149, 1104, 5797, 1105, 1608, 1313, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06152796745300293, -0.06850537657737732, -0.10995091497898102, -0.08667222410440445, -0.11932516098022461, -0.11934661865234375, -0.11934661865234375, -0.11934661865234375, -0.11934661865234375, -0.11934661865234375], "metadata": {"source_tokens": ["After", "this", "point", "many", "of", "the", "republican", "##s", "were", "arrested", "in", "Free", "State", "`", "##`", "round", "ups", "'", "##'", "when", "they", "had", "come", "out", "of", "hiding", "and", "returned", "home", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "many", "of", "the", "republican", "##s", "[unused2]", "[unused3]", "were", "arrested", "[unused4]", "[unused5]", "in", "Free", "State", "`", "##`", "round", "ups", "After", "this", "point", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "had", "come", "[unused4]", "[unused5]", "out", "of", "hiding", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "returned", "[unused4]", "[unused5]", "home", "[unused6]", "[SEP]", "[unused1]", "many", "of", "the", "republican", "##s", "[unused2]", "[unused3]", "were", "arrested", "[unused4]", "[unused5]", "in", "Free", "State", "round", "ups", "when", "they", "had", "come", "out", "of", "hiding", "and", "returned", "home", "[unused6]", "[SEP]"]]}

input 26:  {"source": "Although Knievel broke his arms , he was more distraught over a permanent injury his accident caused to the cameraman .\n"}
prediction:  {"predictions": [[1, 148, 5213, 12559, 2, 3, 2795, 4, 5, 1117, 1739, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 4, 5, 1167, 4267, 16468, 11266, 1166, 170, 4088, 3773, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4088, 3773, 2, 3, 2416, 4, 5, 1106, 1103, 4504, 1399, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.015381886623799801, -0.027865374460816383, -0.034638531506061554, -0.0756533145904541, -0.0757596492767334, -0.0757596492767334, -0.0757596492767334, -0.0757596492767334, -0.0757596492767334, -0.0757596492767334], "metadata": {"source_tokens": ["Although", "K", "##nie", "##vel", "broke", "his", "arms", ",", "he", "was", "more", "di", "##stra", "##ught", "over", "a", "permanent", "injury", "his", "accident", "caused", "to", "the", "camera", "##man", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "K", "##nie", "##vel", "[unused2]", "[unused3]", "broke", "[unused4]", "[unused5]", "his", "arms", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "more", "di", "##stra", "##ught", "over", "a", "permanent", "injury", "[unused6]", "[SEP]", "[unused1]", "a", "permanent", "injury", "[unused2]", "[unused3]", "caused", "[unused4]", "[unused5]", "to", "the", "camera", "##man", "[unused6]", "[SEP]"]]}

input 27:  {"source": "Although under constant attack from kamikazes as well as fighters and dive-bombers , `` Hazelwood '' came through the invasion untouched and on the night of 25 February sank two small enemy freighters with her guns .\n"}
prediction:  {"predictions": [[1, 21021, 2615, 2, 3, 1338, 4, 5, 1194, 1103, 4923, 25135, 1223, 4836, 2035, 1121, 24181, 3080, 1968, 11846, 1112, 1218, 1112, 7705, 1105, 12706, 28137, 4043, 10615, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1428, 2, 3, 7095, 4, 5, 1160, 1353, 3437, 8872, 1468, 1114, 1123, 3832, 1113, 1103, 1480, 1104, 1512, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21021, 2615, 2, 3, 1338, 4, 5, 1194, 1103, 4923, 25135, 1966, 1223, 4836, 2035, 1121, 24181, 3080, 1968, 11846, 1112, 1218, 1112, 7705, 1105, 12706, 28137, 4043, 10615, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21021, 2615, 2, 3, 1338, 4, 5, 1194, 1103, 4923, 25135, 1966, 1223, 4836, 2035, 1121, 24181, 3080, 1968, 11846, 1112, 1218, 1112, 7705, 1105, 12706, 28137, 4043, 10615, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04210273548960686, -0.04579925537109375, -0.08083206415176392, -0.10679157078266144, -0.3414270877838135, -0.345780611038208, -0.345780611038208, -0.345780611038208, -0.345780611038208, -0.345780611038208], "metadata": {"source_tokens": ["Although", "under", "constant", "attack", "from", "ka", "##mi", "##ka", "##zes", "as", "well", "as", "fighters", "and", "dive", "##-", "##bo", "##mber", "##s", ",", "`", "##`", "Hazel", "##wood", "'", "##'", "came", "through", "the", "invasion", "untouched", "and", "on", "the", "night", "of", "25", "February", "sank", "two", "small", "enemy", "freight", "##ers", "with", "her", "guns", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hazel", "##wood", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "through", "the", "invasion", "untouched", "under", "constant", "attack", "from", "ka", "##mi", "##ka", "##zes", "as", "well", "as", "fighters", "and", "dive", "##-", "##bo", "##mber", "##s", "[unused6]", "[SEP]", "[unused1]", "February", "[unused2]", "[unused3]", "sank", "[unused4]", "[unused5]", "two", "small", "enemy", "freight", "##ers", "with", "her", "guns", "on", "the", "night", "of", "25", "[unused6]", "[SEP]", "[unused1]", "Hazel", "##wood", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "through", "the", "invasion", "untouched", "Although", "under", "constant", "attack", "from", "ka", "##mi", "##ka", "##zes", "as", "well", "as", "fighters", "and", "dive", "##-", "##bo", "##mber", "##s", "[unused6]", "[SEP]", "[unused1]", "Hazel", "##wood", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "through", "the", "invasion", "untouched", "Although", "under", "constant", "attack", "from", "ka", "##mi", "##ka", "##zes", "as", "well", "as", "fighters", "and", "dive", "##-", "##bo", "##mber", "##s", "[unused6]", "[SEP]"]]}

input 28:  {"source": "An animal that cares for its young but shows no other sociality traits is said to be `` subsocial '' .\n"}
prediction:  {"predictions": [[1, 1760, 3724, 1115, 16903, 1111, 1157, 1685, 1133, 2196, 1185, 1168, 1934, 1785, 13474, 2, 3, 1106, 1129, 4, 5, 4841, 7301, 12562, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1760, 3724, 1115, 16903, 1111, 1157, 1685, 1133, 2196, 1185, 1168, 1934, 1785, 13474, 2, 3, 1110, 1163, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1760, 3724, 2, 3, 16903, 4, 5, 1111, 1157, 1685, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1760, 3724, 2, 3, 2196, 4, 5, 1185, 1168, 1934, 1785, 13474, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.052320368587970734, -0.043265994638204575, -0.051532745361328125, -0.04337967187166214, -0.03846597671508789, -0.03853416442871094, -0.03853416442871094, -0.03853416442871094, -0.03853416442871094, -0.03853416442871094], "metadata": {"source_tokens": ["An", "animal", "that", "cares", "for", "its", "young", "but", "shows", "no", "other", "social", "##ity", "traits", "is", "said", "to", "be", "`", "##`", "sub", "##so", "##cial", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "An", "animal", "that", "cares", "for", "its", "young", "but", "shows", "no", "other", "social", "##ity", "traits", "[unused2]", "[unused3]", "to", "be", "[unused4]", "[unused5]", "sub", "##so", "##cial", "[unused6]", "[SEP]", "[unused1]", "An", "animal", "that", "cares", "for", "its", "young", "but", "shows", "no", "other", "social", "##ity", "traits", "[unused2]", "[unused3]", "is", "said", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "An", "animal", "[unused2]", "[unused3]", "cares", "[unused4]", "[unused5]", "for", "its", "young", "[unused6]", "[SEP]", "[unused1]", "An", "animal", "[unused2]", "[unused3]", "shows", "[unused4]", "[unused5]", "no", "other", "social", "##ity", "traits", "[unused6]", "[SEP]"]]}

input 29:  {"source": "An original limited artist edition of 250 was published in 1989 and was an oversized fine press slip-cased book with stainless steel faced boards and digital clock inset into the front cover .\n"}
prediction:  {"predictions": [[1, 1760, 1560, 2609, 2360, 2596, 1104, 4805, 2, 3, 1108, 4, 5, 1107, 2056, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1760, 1560, 2609, 2360, 2596, 1104, 4805, 2, 3, 1108, 4, 5, 1126, 24223, 2503, 3181, 7324, 28137, 14083, 1181, 1520, 1114, 21771, 3649, 3544, 8190, 1105, 3539, 4705, 22233, 2105, 1154, 1103, 1524, 2267, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1760, 1560, 2609, 2360, 2596, 1104, 4805, 2, 3, 1108, 1502, 4, 5, 1107, 2056, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3539, 4705, 2, 3, 22233, 2105, 4, 5, 1154, 1103, 1524, 2267, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.08419554680585861, -0.03040037676692009, -0.029182463884353638, -0.09936310350894928, -0.21154606342315674, -0.21171033382415771, -0.21171033382415771, -0.21171033382415771, -0.21171033382415771, -0.21171033382415771], "metadata": {"source_tokens": ["An", "original", "limited", "artist", "edition", "of", "250", "was", "published", "in", "1989", "and", "was", "an", "oversized", "fine", "press", "slip", "##-", "##case", "##d", "book", "with", "stainless", "steel", "faced", "boards", "and", "digital", "clock", "ins", "##et", "into", "the", "front", "cover", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "An", "original", "limited", "artist", "edition", "of", "250", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "in", "1989", "[unused6]", "[SEP]", "[unused1]", "An", "original", "limited", "artist", "edition", "of", "250", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "an", "oversized", "fine", "press", "slip", "##-", "##case", "##d", "book", "with", "stainless", "steel", "faced", "boards", "and", "digital", "clock", "ins", "##et", "into", "the", "front", "cover", "[unused6]", "[SEP]", "[unused1]", "An", "original", "limited", "artist", "edition", "of", "250", "[unused2]", "[unused3]", "was", "published", "[unused4]", "[unused5]", "in", "1989", "[unused6]", "[SEP]", "[unused1]", "digital", "clock", "[unused2]", "[unused3]", "ins", "##et", "[unused4]", "[unused5]", "into", "the", "front", "cover", "[unused6]", "[SEP]"]]}

input 30:  {"source": "And ABS has formed a partnership with Habitat for Humanity to give a free Bible to each of its new homeowners in the United States .\n"}
prediction:  {"predictions": [[1, 20066, 2, 3, 1144, 1824, 4, 5, 170, 5210, 1114, 11679, 9208, 2980, 1111, 4243, 1785, 1106, 1660, 170, 1714, 5905, 1106, 1296, 1104, 1157, 1207, 1313, 13798, 1468, 1107, 1103, 1244, 1311, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20066, 2, 3, 1144, 1824, 4, 5, 170, 5210, 1106, 1660, 170, 1714, 5905, 1107, 1103, 1244, 1311, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20066, 2, 3, 1144, 1824, 4, 5, 170, 5210, 1106, 1660, 170, 1714, 5905, 1107, 1103, 1244, 1311, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013748313300311565, -0.09742069244384766, -0.08013288676738739, -0.12370157241821289, -0.12387585639953613, -0.12387585639953613, -0.12387585639953613, -0.12387585639953613, -0.12387585639953613, -0.12387585639953613], "metadata": {"source_tokens": ["And", "ABS", "has", "formed", "a", "partnership", "with", "Ha", "##bit", "##at", "for", "Human", "##ity", "to", "give", "a", "free", "Bible", "to", "each", "of", "its", "new", "home", "##own", "##ers", "in", "the", "United", "States", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "ABS", "[unused2]", "[unused3]", "has", "formed", "[unused4]", "[unused5]", "a", "partnership", "with", "Ha", "##bit", "##at", "for", "Human", "##ity", "to", "give", "a", "free", "Bible", "to", "each", "of", "its", "new", "home", "##own", "##ers", "in", "the", "United", "States", "[unused6]", "[SEP]", "[unused1]", "ABS", "[unused2]", "[unused3]", "has", "formed", "[unused4]", "[unused5]", "a", "partnership", "to", "give", "a", "free", "Bible", "in", "the", "United", "States", "[unused6]", "[SEP]", "[unused1]", "ABS", "[unused2]", "[unused3]", "has", "formed", "[unused4]", "[unused5]", "a", "partnership", "to", "give", "a", "free", "Bible", "in", "the", "United", "States", "[unused6]", "[SEP]"]]}

input 31:  {"source": "And he was in Ali 's army in the Battle of Jamal and later it was Muhammad ibn Abu Bakr who escorted Aisha back to Madina .\n"}
prediction:  {"predictions": [[1, 6710, 10452, 8158, 18757, 1377, 1197, 2, 3, 13539, 4, 5, 19294, 5480, 1171, 1106, 10779, 2983, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 4, 5, 1107, 4149, 112, 1116, 2306, 1107, 1103, 2651, 1104, 27440, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 6710, 10452, 8158, 18757, 1377, 1197, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06423363834619522, -0.017270900309085846, -0.06547924876213074, -0.07655596733093262, -0.0765378475189209, -0.0765378475189209, -0.0765378475189209, -0.0765378475189209, -0.0765378475189209, -0.0765378475189209], "metadata": {"source_tokens": ["And", "he", "was", "in", "Ali", "'", "##s", "army", "in", "the", "Battle", "of", "Jamal", "and", "later", "it", "was", "Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "who", "escorted", "Ai", "##sha", "back", "to", "Mad", "##ina", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "[unused2]", "[unused3]", "escorted", "[unused4]", "[unused5]", "Ai", "##sha", "back", "to", "Mad", "##ina", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "in", "Ali", "'", "##s", "army", "in", "the", "Battle", "of", "Jamal", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "later", "[unused6]", "[SEP]"]]}

input 32:  {"source": "Andrea Bianco 's atlas of 1436 comprises ten leaves of vellum , measuring , in an 18th-century binding .\n"}
prediction:  {"predictions": [[1, 8326, 139, 1811, 2528, 112, 1116, 1120, 7580, 1104, 17025, 1545, 2, 3, 8302, 4, 5, 1995, 2972, 1104, 1396, 21275, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8326, 139, 1811, 2528, 112, 1116, 1120, 7580, 1104, 17025, 1545, 2, 3, 8302, 4, 5, 1995, 2972, 1104, 1396, 21275, 10099, 1107, 1126, 4186, 28137, 8298, 11366, 7861, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8326, 139, 1811, 2528, 112, 1116, 1120, 7580, 1104, 17025, 1545, 2, 3, 8302, 4, 5, 1995, 2972, 1104, 1396, 21275, 10099, 1107, 1126, 4186, 28137, 8298, 11366, 7861, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006672064308077097, -0.03380199149250984, -0.33371949195861816, -0.042558349668979645, -0.07700061798095703, -0.07700061798095703, -0.07700061798095703, -0.07700061798095703, -0.07700061798095703, -0.07700061798095703], "metadata": {"source_tokens": ["Andrea", "B", "##ian", "##co", "'", "##s", "at", "##las", "of", "143", "##6", "comprises", "ten", "leaves", "of", "ve", "##llum", ",", "measuring", ",", "in", "an", "18th", "##-", "##cent", "##ury", "binding", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Andrea", "B", "##ian", "##co", "'", "##s", "at", "##las", "of", "143", "##6", "[unused2]", "[unused3]", "comprises", "[unused4]", "[unused5]", "ten", "leaves", "of", "ve", "##llum", "[unused6]", "[SEP]", "[unused1]", "Andrea", "B", "##ian", "##co", "'", "##s", "at", "##las", "of", "143", "##6", "[unused2]", "[unused3]", "comprises", "[unused4]", "[unused5]", "ten", "leaves", "of", "ve", "##llum", "measuring", "in", "an", "18th", "##-", "##cent", "##ury", "binding", "[unused6]", "[SEP]"]]}

input 33:  {"source": "Apartment buildings , shops , medical clinics , cinemas etc. were built in close proximity to the MAZ plant , providing plant workers with local necessities .\n"}
prediction:  {"predictions": [[1, 10342, 1880, 2275, 117, 7116, 117, 2657, 20562, 117, 27081, 3576, 28138, 2, 3, 1127, 1434, 4, 5, 1107, 1601, 10013, 1106, 1103, 9960, 5301, 2582, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10342, 1880, 2275, 7116, 2657, 20562, 27081, 3576, 28138, 2, 3, 1127, 1434, 4, 5, 1107, 1601, 10013, 3558, 2582, 3239, 1114, 1469, 24928, 22371, 4233, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013391302898526192, -0.08280116319656372, -0.07637691497802734, -0.07637739181518555, -0.07637739181518555, -0.07637739181518555, -0.07637739181518555, -0.07637739181518555, -0.07637739181518555, -0.07637739181518555], "metadata": {"source_tokens": ["Apart", "##ment", "buildings", ",", "shops", ",", "medical", "clinics", ",", "cinemas", "etc", "##.", "were", "built", "in", "close", "proximity", "to", "the", "MA", "##Z", "plant", ",", "providing", "plant", "workers", "with", "local", "ne", "##cess", "##ities", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Apart", "##ment", "buildings", ",", "shops", ",", "medical", "clinics", ",", "cinemas", "etc", "##.", "[unused2]", "[unused3]", "were", "built", "[unused4]", "[unused5]", "in", "close", "proximity", "to", "the", "MA", "##Z", "plant", "[unused6]", "[SEP]", "[unused1]", "Apart", "##ment", "buildings", "shops", "medical", "clinics", "cinemas", "etc", "##.", "[unused2]", "[unused3]", "were", "built", "[unused4]", "[unused5]", "in", "close", "proximity", "providing", "plant", "workers", "with", "local", "ne", "##cess", "##ities", "[unused6]", "[SEP]"]]}

input 34:  {"source": "Applications can use this service to record activity for a production system while implementations of other OSIDs can use the service to record detailed data during development , debugging , or analyzing performance .\n"}
prediction:  {"predictions": [[1, 7249, 1116, 1104, 1168, 11570, 9949, 1116, 2, 3, 1169, 1329, 4, 5, 1103, 1555, 1106, 1647, 6448, 2233, 1219, 1718, 117, 1260, 7925, 10932, 117, 1137, 23389, 2099, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20603, 2, 3, 1169, 1329, 4, 5, 1142, 1555, 1106, 1647, 3246, 1111, 170, 1707, 1449, 1229, 7249, 1116, 1104, 1168, 11570, 9949, 1116, 1169, 1329, 1103, 1555, 1106, 1647, 6448, 2233, 1219, 1718, 1260, 7925, 10932, 1137, 23389, 2099, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20603, 2, 3, 1169, 1329, 4, 5, 1142, 1555, 1106, 1647, 3246, 1111, 170, 1707, 1449, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20603, 2, 3, 1169, 1329, 4, 5, 1142, 1555, 1106, 1647, 3246, 1229, 7249, 1116, 1104, 1168, 11570, 9949, 1116, 1169, 1329, 1103, 1555, 1106, 1647, 6448, 2233, 1219, 1718, 1260, 7925, 10932, 1137, 23389, 2099, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.018846556544303894, -0.06247727945446968, -0.13651017844676971, -0.09937327355146408, -0.31696510314941406, -0.33248186111450195, -0.33248186111450195, -0.33248186111450195, -0.33248186111450195, -0.33248186111450195], "metadata": {"source_tokens": ["Applications", "can", "use", "this", "service", "to", "record", "activity", "for", "a", "production", "system", "while", "implementation", "##s", "of", "other", "OS", "##ID", "##s", "can", "use", "the", "service", "to", "record", "detailed", "data", "during", "development", ",", "de", "##bu", "##gging", ",", "or", "analyzing", "performance", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "implementation", "##s", "of", "other", "OS", "##ID", "##s", "[unused2]", "[unused3]", "can", "use", "[unused4]", "[unused5]", "the", "service", "to", "record", "detailed", "data", "during", "development", ",", "de", "##bu", "##gging", ",", "or", "analyzing", "performance", "[unused6]", "[SEP]", "[unused1]", "Applications", "[unused2]", "[unused3]", "can", "use", "[unused4]", "[unused5]", "this", "service", "to", "record", "activity", "for", "a", "production", "system", "while", "implementation", "##s", "of", "other", "OS", "##ID", "##s", "can", "use", "the", "service", "to", "record", "detailed", "data", "during", "development", "de", "##bu", "##gging", "or", "analyzing", "performance", "[unused6]", "[SEP]", "[unused1]", "Applications", "[unused2]", "[unused3]", "can", "use", "[unused4]", "[unused5]", "this", "service", "to", "record", "activity", "for", "a", "production", "system", "[unused6]", "[SEP]", "[unused1]", "Applications", "[unused2]", "[unused3]", "can", "use", "[unused4]", "[unused5]", "this", "service", "to", "record", "activity", "while", "implementation", "##s", "of", "other", "OS", "##ID", "##s", "can", "use", "the", "service", "to", "record", "detailed", "data", "during", "development", "de", "##bu", "##gging", "or", "analyzing", "performance", "[unused6]", "[SEP]"]]}

input 35:  {"source": "Applying this technique facilitates the connection of the center of the foot with the lower abdomen .\n"}
prediction:  {"predictions": [[1, 138, 8661, 15318, 1142, 5531, 2, 3, 11000, 1116, 4, 5, 1103, 3797, 1104, 1103, 2057, 1104, 1103, 2555, 1114, 1103, 2211, 14701, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00048556237015873194, -0.0009679794311523438, -0.0010366439819335938, -0.0010366439819335938, -0.0010366439819335938, -0.0010366439819335938, -0.0010366439819335938, -0.0010366439819335938, -0.0010366439819335938, -0.0010366439819335938], "metadata": {"source_tokens": ["A", "##pp", "##lying", "this", "technique", "facilitate", "##s", "the", "connection", "of", "the", "center", "of", "the", "foot", "with", "the", "lower", "abdomen", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "##pp", "##lying", "this", "technique", "[unused2]", "[unused3]", "facilitate", "##s", "[unused4]", "[unused5]", "the", "connection", "of", "the", "center", "of", "the", "foot", "with", "the", "lower", "abdomen", "[unused6]", "[SEP]"]]}

input 36:  {"source": "As Attorney General he clashed with Daniel O'Connell when he insisted , against O'Connell 's wishes , on the appointment of Abraham Brewster as Law Adviser to the Lord Lieutenant of Ireland .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 25144, 4, 5, 1114, 2979, 152, 28131, 1658, 26823, 1165, 1119, 6744, 117, 1222, 152, 28131, 1658, 26823, 112, 1116, 8921, 117, 1113, 1103, 5516, 1104, 7752, 25673, 1112, 2601, 24930, 16641, 1197, 1106, 1103, 2188, 3897, 1104, 2270, 6, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 6744, 4, 5, 1222, 152, 28131, 1658, 26823, 112, 1116, 8921, 1113, 1103, 5516, 1104, 7752, 25673, 1112, 2601, 24930, 16641, 1197, 1106, 1103, 2188, 3897, 1104, 2270, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 25144, 4, 5, 1114, 2979, 152, 28131, 1658, 26823, 1165, 1119, 6744, 1222, 152, 28131, 1658, 26823, 112, 1116, 8921, 1113, 1103, 5516, 1104, 7752, 25673, 1112, 2601, 24930, 16641, 1197, 1106, 1103, 2188, 3897, 1104, 2270, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009570729918777943, -0.039159759879112244, -0.09404082596302032, -0.2636120319366455, -0.26380395889282227, -0.26380395889282227, -0.26380395889282227, -0.26380395889282227, -0.26380395889282227, -0.26380395889282227], "metadata": {"source_tokens": ["As", "Attorney", "General", "he", "clashed", "with", "Daniel", "O", "##'", "##C", "##onnell", "when", "he", "insisted", ",", "against", "O", "##'", "##C", "##onnell", "'", "##s", "wishes", ",", "on", "the", "appointment", "of", "Abraham", "Brewster", "as", "Law", "Ad", "##vise", "##r", "to", "the", "Lord", "Lieutenant", "of", "Ireland", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "clashed", "[unused4]", "[unused5]", "with", "Daniel", "O", "##'", "##C", "##onnell", "when", "he", "insisted", ",", "against", "O", "##'", "##C", "##onnell", "'", "##s", "wishes", ",", "on", "the", "appointment", "of", "Abraham", "Brewster", "as", "Law", "Ad", "##vise", "##r", "to", "the", "Lord", "Lieutenant", "of", "Ireland", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "insisted", "[unused4]", "[unused5]", "against", "O", "##'", "##C", "##onnell", "'", "##s", "wishes", "on", "the", "appointment", "of", "Abraham", "Brewster", "as", "Law", "Ad", "##vise", "##r", "to", "the", "Lord", "Lieutenant", "of", "Ireland", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "clashed", "[unused4]", "[unused5]", "with", "Daniel", "O", "##'", "##C", "##onnell", "when", "he", "insisted", "against", "O", "##'", "##C", "##onnell", "'", "##s", "wishes", "on", "the", "appointment", "of", "Abraham", "Brewster", "as", "Law", "Ad", "##vise", "##r", "to", "the", "Lord", "Lieutenant", "of", "Ireland", "[unused6]", "[SEP]"]]}

input 37:  {"source": "As a group , the team was enshrined into the Basketball Hall of Fame in 1959 .\n"}
prediction:  {"predictions": [[1, 1103, 1264, 2, 3, 1108, 4035, 2737, 8643, 1181, 4, 5, 1154, 1103, 6035, 1944, 1104, 4710, 1107, 3003, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00029992515919730067, -0.03854179382324219, -0.038547515869140625, -0.038547515869140625, -0.038547515869140625, -0.038547515869140625, -0.038547515869140625, -0.038547515869140625, -0.038547515869140625, -0.038547515869140625], "metadata": {"source_tokens": ["As", "a", "group", ",", "the", "team", "was", "en", "##sh", "##rine", "##d", "into", "the", "Basketball", "Hall", "of", "Fame", "in", "1959", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "team", "[unused2]", "[unused3]", "was", "en", "##sh", "##rine", "##d", "[unused4]", "[unused5]", "into", "the", "Basketball", "Hall", "of", "Fame", "in", "1959", "[unused6]", "[SEP]"]]}

input 38:  {"source": "As a result , it becomes clear that the microbe can not survive outside a narrow pH range .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 3316, 4, 5, 2330, 1115, 1103, 17599, 3962, 1169, 1136, 5195, 1796, 170, 4142, 20149, 2079, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 17599, 3962, 2, 3, 1169, 1136, 5195, 4, 5, 1796, 170, 4142, 20149, 2079, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0020708171650767326, -0.015990184620022774, -0.008941650390625, -0.008933067321777344, -0.008933067321777344, -0.008933067321777344, -0.008933067321777344, -0.008933067321777344, -0.008933067321777344, -0.008933067321777344], "metadata": {"source_tokens": ["As", "a", "result", ",", "it", "becomes", "clear", "that", "the", "micro", "##be", "can", "not", "survive", "outside", "a", "narrow", "pH", "range", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "becomes", "[unused4]", "[unused5]", "clear", "that", "the", "micro", "##be", "can", "not", "survive", "outside", "a", "narrow", "pH", "range", "[unused6]", "[SEP]", "[unused1]", "the", "micro", "##be", "[unused2]", "[unused3]", "can", "not", "survive", "[unused4]", "[unused5]", "outside", "a", "narrow", "pH", "range", "[unused6]", "[SEP]"]]}

input 39:  {"source": "As a result , the lower river had to be dredged three times in two years .\n"}
prediction:  {"predictions": [[1, 1103, 2211, 2186, 2, 3, 1106, 1129, 173, 4359, 3660, 4, 5, 1210, 1551, 1107, 1160, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009565019980072975, -0.016765117645263672, -0.01726245880126953, -0.01726245880126953, -0.01726245880126953, -0.01726245880126953, -0.01726245880126953, -0.01726245880126953, -0.01726245880126953, -0.01726245880126953], "metadata": {"source_tokens": ["As", "a", "result", ",", "the", "lower", "river", "had", "to", "be", "d", "##red", "##ged", "three", "times", "in", "two", "years", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "lower", "river", "[unused2]", "[unused3]", "to", "be", "d", "##red", "##ged", "[unused4]", "[unused5]", "three", "times", "in", "two", "years", "[unused6]", "[SEP]"]]}

input 40:  {"source": "As early as the 15th century , the French kings sent commissioners to the provinces to inspect on royal and administrative affairs and to take necessary action .\n"}
prediction:  {"predictions": [[1, 1103, 1497, 9419, 2, 3, 1850, 4, 5, 22207, 1106, 1103, 7112, 1106, 25151, 1113, 4276, 1105, 3207, 5707, 1105, 1106, 1321, 3238, 2168, 1249, 1346, 1112, 1103, 5617, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1497, 9419, 2, 3, 1850, 4, 5, 22207, 1106, 1103, 7112, 1106, 1106, 1321, 3238, 2168, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1497, 9419, 2, 3, 1850, 4, 5, 22207, 1106, 25151, 1113, 4276, 1105, 3207, 5707, 1105, 1106, 1321, 3238, 2168, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1497, 9419, 2, 3, 1850, 4, 5, 22207, 1106, 25151, 1113, 4276, 1105, 3207, 5707, 1105, 1106, 1321, 3238, 2168, 1249, 1346, 1112, 1103, 5617, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004871522542089224, -0.09834799915552139, -0.10375282913446426, -0.09695909917354584, -0.21406984329223633, -0.2140645980834961, -0.2140645980834961, -0.2140645980834961, -0.2140645980834961, -0.2140645980834961], "metadata": {"source_tokens": ["As", "early", "as", "the", "15th", "century", ",", "the", "French", "kings", "sent", "commissioners", "to", "the", "provinces", "to", "inspect", "on", "royal", "and", "administrative", "affairs", "and", "to", "take", "necessary", "action", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "French", "kings", "[unused2]", "[unused3]", "sent", "[unused4]", "[unused5]", "commissioners", "to", "the", "provinces", "to", "inspect", "on", "royal", "and", "administrative", "affairs", "and", "to", "take", "necessary", "action", "As", "early", "as", "the", "15th", "century", "[unused6]", "[SEP]", "[unused1]", "the", "French", "kings", "[unused2]", "[unused3]", "sent", "[unused4]", "[unused5]", "commissioners", "to", "the", "provinces", "to", "to", "take", "necessary", "action", "[unused6]", "[SEP]", "[unused1]", "the", "French", "kings", "[unused2]", "[unused3]", "sent", "[unused4]", "[unused5]", "commissioners", "to", "inspect", "on", "royal", "and", "administrative", "affairs", "and", "to", "take", "necessary", "action", "[unused6]", "[SEP]", "[unused1]", "the", "French", "kings", "[unused2]", "[unused3]", "sent", "[unused4]", "[unused5]", "commissioners", "to", "inspect", "on", "royal", "and", "administrative", "affairs", "and", "to", "take", "necessary", "action", "As", "early", "as", "the", "15th", "century", "[unused6]", "[SEP]"]]}

input 41:  {"source": "As in his first novel , Armah contrasts the two worlds of materialism and moral values , corruption and dreams , two worlds of integrity and social pressure .\n"}
prediction:  {"predictions": [[1, 24446, 3354, 2, 3, 26856, 4, 5, 1103, 1160, 11308, 1104, 2578, 1863, 1105, 7279, 4718, 117, 8065, 1105, 6149, 117, 1160, 11308, 1104, 12363, 1105, 1934, 2997, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01109156385064125, -0.032204627990722656, -0.032204627990722656, -0.032204627990722656, -0.032204627990722656, -0.032204627990722656, -0.032204627990722656, -0.032204627990722656, -0.032204627990722656, -0.032204627990722656], "metadata": {"source_tokens": ["As", "in", "his", "first", "novel", ",", "Arm", "##ah", "contrasts", "the", "two", "worlds", "of", "material", "##ism", "and", "moral", "values", ",", "corruption", "and", "dreams", ",", "two", "worlds", "of", "integrity", "and", "social", "pressure", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Arm", "##ah", "[unused2]", "[unused3]", "contrasts", "[unused4]", "[unused5]", "the", "two", "worlds", "of", "material", "##ism", "and", "moral", "values", ",", "corruption", "and", "dreams", ",", "two", "worlds", "of", "integrity", "and", "social", "pressure", "[unused6]", "[SEP]"]]}

input 42:  {"source": "As is true for all sensors , absolute accuracy of a measurement requires a functionality for calibration .\n"}
prediction:  {"predictions": [[1, 7846, 10893, 1104, 170, 11842, 2, 3, 5315, 4, 5, 170, 16354, 1111, 11019, 2646, 6766, 2116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0003546359948813915, -0.02200460433959961, -0.022005081176757812, -0.022005081176757812, -0.022005081176757812, -0.022005081176757812, -0.022005081176757812, -0.022005081176757812, -0.022005081176757812, -0.022005081176757812], "metadata": {"source_tokens": ["As", "is", "true", "for", "all", "sensors", ",", "absolute", "accuracy", "of", "a", "measurement", "requires", "a", "functionality", "for", "ca", "##li", "##bra", "##tion", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "absolute", "accuracy", "of", "a", "measurement", "[unused2]", "[unused3]", "requires", "[unused4]", "[unused5]", "a", "functionality", "for", "ca", "##li", "##bra", "##tion", "[unused6]", "[SEP]"]]}

input 43:  {"source": "As of `` A Wind in the Door '' , Sandy aspires to become a banker , on the grounds that it is practical and lucrative .\n"}
prediction:  {"predictions": [[1, 9908, 2, 3, 1112, 20082, 1116, 4, 5, 1106, 1561, 170, 15304, 117, 1113, 1103, 4745, 1115, 1122, 1110, 6691, 1105, 23284, 1249, 1104, 169, 28152, 138, 7943, 1107, 1103, 15087, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 4, 5, 6691, 1105, 23284, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9908, 2, 3, 1106, 1561, 4, 5, 170, 15304, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05180950462818146, -0.03361105918884277, -0.10366692394018173, -0.07645702362060547, -0.0766291618347168, -0.0766291618347168, -0.0766291618347168, -0.0766291618347168, -0.0766291618347168, -0.0766291618347168], "metadata": {"source_tokens": ["As", "of", "`", "##`", "A", "Wind", "in", "the", "Door", "'", "##'", ",", "Sandy", "as", "##pire", "##s", "to", "become", "a", "banker", ",", "on", "the", "grounds", "that", "it", "is", "practical", "and", "lucrative", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sandy", "[unused2]", "[unused3]", "as", "##pire", "##s", "[unused4]", "[unused5]", "to", "become", "a", "banker", ",", "on", "the", "grounds", "that", "it", "is", "practical", "and", "lucrative", "As", "of", "`", "##`", "A", "Wind", "in", "the", "Door", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "practical", "and", "lucrative", "[unused6]", "[SEP]", "[unused1]", "Sandy", "[unused2]", "[unused3]", "to", "become", "[unused4]", "[unused5]", "a", "banker", "[unused6]", "[SEP]"]]}

input 44:  {"source": "As part of several efforts to have the Gypsy Horse recognized as a breed outside the Romanichal community , a more descriptive name was sought for it , starting in the 1990s .\n"}
prediction:  {"predictions": [[1, 170, 1167, 27938, 1271, 2, 3, 1108, 4110, 4, 5, 1111, 1122, 2547, 1107, 1103, 3281, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 22153, 7429, 2, 3, 3037, 4, 5, 1112, 170, 9489, 1796, 1103, 27876, 17436, 1661, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1167, 27938, 1271, 2, 3, 1108, 4110, 4, 5, 1111, 1122, 1249, 1226, 1104, 1317, 3268, 1106, 1138, 1103, 22153, 7429, 3037, 1112, 170, 9489, 1796, 1103, 27876, 17436, 1661, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03653186187148094, -0.024286339059472084, -0.05383840203285217, -0.1491224765777588, -0.1500101089477539, -0.1500101089477539, -0.1500101089477539, -0.1500101089477539, -0.1500101089477539, -0.1500101089477539], "metadata": {"source_tokens": ["As", "part", "of", "several", "efforts", "to", "have", "the", "Gypsy", "Horse", "recognized", "as", "a", "breed", "outside", "the", "Romani", "##chal", "community", ",", "a", "more", "descriptive", "name", "was", "sought", "for", "it", ",", "starting", "in", "the", "1990s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "more", "descriptive", "name", "[unused2]", "[unused3]", "was", "sought", "[unused4]", "[unused5]", "for", "it", "starting", "in", "the", "1990s", "[unused6]", "[SEP]", "[unused1]", "the", "Gypsy", "Horse", "[unused2]", "[unused3]", "recognized", "[unused4]", "[unused5]", "as", "a", "breed", "outside", "the", "Romani", "##chal", "community", "[unused6]", "[SEP]", "[unused1]", "a", "more", "descriptive", "name", "[unused2]", "[unused3]", "was", "sought", "[unused4]", "[unused5]", "for", "it", "As", "part", "of", "several", "efforts", "to", "have", "the", "Gypsy", "Horse", "recognized", "as", "a", "breed", "outside", "the", "Romani", "##chal", "community", "[unused6]", "[SEP]"]]}

input 45:  {"source": "Assisting in the recording process were Fernando Cabello and two friends of the group , Eva Dalda and Lydia Iovanne .\n"}
prediction:  {"predictions": [[1, 1249, 22398, 1158, 1107, 1103, 2730, 1965, 2, 3, 1127, 4, 5, 8834, 140, 22377, 6643, 1105, 1160, 2053, 1104, 1103, 1372, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1372, 2, 3, 1110, 4, 5, 9734, 25938, 1810, 1105, 14639, 146, 8625, 10934, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01709807850420475, -0.050123170018196106, -0.009048938751220703, -0.009046554565429688, -0.009046554565429688, -0.009046554565429688, -0.009046554565429688, -0.009046554565429688, -0.009046554565429688, -0.009046554565429688], "metadata": {"source_tokens": ["As", "##sist", "##ing", "in", "the", "recording", "process", "were", "Fernando", "C", "##abe", "##llo", "and", "two", "friends", "of", "the", "group", ",", "Eva", "Dal", "##da", "and", "Lydia", "I", "##ova", "##nne", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "As", "##sist", "##ing", "in", "the", "recording", "process", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "Fernando", "C", "##abe", "##llo", "and", "two", "friends", "of", "the", "group", "[unused6]", "[SEP]", "[unused1]", "the", "group", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Eva", "Dal", "##da", "and", "Lydia", "I", "##ova", "##nne", "[unused6]", "[SEP]"]]}

input 46:  {"source": "At a presentation in the Toronto Pearson International Airport hangar , Celine Dion helped the newly solvent airline debut its new image .\n"}
prediction:  {"predictions": [[1, 24664, 2568, 21322, 2, 3, 2375, 4, 5, 1103, 3599, 27624, 8694, 1963, 1157, 1207, 3077, 1335, 170, 8685, 1107, 1103, 3506, 13079, 1570, 3369, 22043, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3599, 27624, 8694, 2, 3, 1963, 4, 5, 1157, 1207, 3077, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0003947882796637714, -0.02085193432867527, -0.05634641647338867, -0.059731483459472656, -0.059731483459472656, -0.059731483459472656, -0.059731483459472656, -0.059731483459472656, -0.059731483459472656, -0.059731483459472656], "metadata": {"source_tokens": ["At", "a", "presentation", "in", "the", "Toronto", "Pearson", "International", "Airport", "hangar", ",", "Ce", "##line", "Dion", "helped", "the", "newly", "solvent", "airline", "debut", "its", "new", "image", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ce", "##line", "Dion", "[unused2]", "[unused3]", "helped", "[unused4]", "[unused5]", "the", "newly", "solvent", "airline", "debut", "its", "new", "image", "At", "a", "presentation", "in", "the", "Toronto", "Pearson", "International", "Airport", "hangar", "[unused6]", "[SEP]", "[unused1]", "the", "newly", "solvent", "airline", "[unused2]", "[unused3]", "debut", "[unused4]", "[unused5]", "its", "new", "image", "[unused6]", "[SEP]"]]}

input 47:  {"source": "At least 11 villagers disappeared and 8 people were killed in the ensuing tsunami , two of which are prisoners at one of the Permisan prisons .\n"}
prediction:  {"predictions": [[1, 1335, 1655, 1429, 12453, 2, 3, 4712, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 129, 1234, 2, 3, 1127, 1841, 4, 5, 1107, 1103, 14332, 24212, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1160, 1104, 1134, 2, 3, 1132, 4, 5, 5419, 1120, 1141, 1104, 1103, 14286, 15394, 1389, 20070, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01422262191772461, -0.038764819502830505, -0.015104388818144798, -0.03221607208251953, -0.03221726417541504, -0.03221726417541504, -0.03221726417541504, -0.03221726417541504, -0.03221726417541504, -0.03221726417541504], "metadata": {"source_tokens": ["At", "least", "11", "villagers", "disappeared", "and", "8", "people", "were", "killed", "in", "the", "ensuing", "tsunami", ",", "two", "of", "which", "are", "prisoners", "at", "one", "of", "the", "Per", "##mis", "##an", "prisons", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "At", "least", "11", "villagers", "[unused2]", "[unused3]", "disappeared", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "8", "people", "[unused2]", "[unused3]", "were", "killed", "[unused4]", "[unused5]", "in", "the", "ensuing", "tsunami", "[unused6]", "[SEP]", "[unused1]", "two", "of", "which", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "prisoners", "at", "one", "of", "the", "Per", "##mis", "##an", "prisons", "[unused6]", "[SEP]"]]}

input 48:  {"source": "At no cost to the parents , these services are provided in compliance with state and federal law ; and are reasonably calculated to yield meaningful educational benefit and student progress .\n"}
prediction:  {"predictions": [[1, 1292, 1826, 2, 3, 1132, 2136, 4, 5, 1107, 14037, 1114, 1352, 1105, 2877, 1644, 1335, 1185, 2616, 1106, 1103, 2153, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1292, 1826, 2, 3, 1132, 17517, 10056, 4, 5, 1106, 10972, 17119, 4339, 5257, 1105, 2377, 5070, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008957992307841778, -0.04110954329371452, -0.07629919052124023, -0.07629871368408203, -0.07629871368408203, -0.07629871368408203, -0.07629871368408203, -0.07629871368408203, -0.07629871368408203, -0.07629871368408203], "metadata": {"source_tokens": ["At", "no", "cost", "to", "the", "parents", ",", "these", "services", "are", "provided", "in", "compliance", "with", "state", "and", "federal", "law", ";", "and", "are", "reasonably", "calculated", "to", "yield", "meaningful", "educational", "benefit", "and", "student", "progress", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "these", "services", "[unused2]", "[unused3]", "are", "provided", "[unused4]", "[unused5]", "in", "compliance", "with", "state", "and", "federal", "law", "At", "no", "cost", "to", "the", "parents", "[unused6]", "[SEP]", "[unused1]", "these", "services", "[unused2]", "[unused3]", "are", "reasonably", "calculated", "[unused4]", "[unused5]", "to", "yield", "meaningful", "educational", "benefit", "and", "student", "progress", "[unused6]", "[SEP]"]]}

input 49:  {"source": "At one point , Ballard is nearly possessed , but resists when she is given a drug and discovers that the spirits are attacking them as they believe that the humans are invaders and plan to exterminate the humans on Mars .\n"}
prediction:  {"predictions": [[1, 24241, 2, 3, 1110, 2212, 8471, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 24241, 2, 3, 9345, 1116, 4, 5, 1165, 1131, 1110, 1549, 170, 3850, 1105, 9149, 1115, 1103, 9494, 1132, 7492, 1172, 1112, 1152, 2059, 1115, 1103, 3612, 1132, 22864, 1105, 2197, 1106, 4252, 2083, 17379, 1103, 3612, 1113, 7403, 1335, 1141, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3612, 2, 3, 1132, 4, 5, 22864, 1105, 2197, 1106, 4252, 2083, 17379, 1103, 3612, 1113, 7403, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1110, 1549, 4, 5, 170, 3850, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 9149, 4, 5, 1115, 1103, 9494, 1132, 7492, 1172, 1112, 1152, 2059, 1115, 1103, 3612, 1132, 22864, 1105, 2197, 1106, 4252, 2083, 17379, 1103, 3612, 1113, 7403, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 9494, 2, 3, 1132, 7492, 4, 5, 1172, 1112, 1152, 2059, 1115, 1103, 3612, 1132, 22864, 1105, 2197, 1106, 4252, 2083, 17379, 1103, 3612, 1113, 7403, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.24439391493797302, -0.03146698698401451, -0.09978307783603668, -0.17220155894756317, -0.06238318979740143, -0.09062332659959793, -0.3471195697784424, -0.3446993827819824, -0.3446993827819824, -0.3446993827819824], "metadata": {"source_tokens": ["At", "one", "point", ",", "Ballard", "is", "nearly", "possessed", ",", "but", "resist", "##s", "when", "she", "is", "given", "a", "drug", "and", "discovers", "that", "the", "spirits", "are", "attacking", "them", "as", "they", "believe", "that", "the", "humans", "are", "invaders", "and", "plan", "to", "ex", "##ter", "##minate", "the", "humans", "on", "Mars", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ballard", "[unused2]", "[unused3]", "is", "nearly", "possessed", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Ballard", "[unused2]", "[unused3]", "resist", "##s", "[unused4]", "[unused5]", "when", "she", "is", "given", "a", "drug", "and", "discovers", "that", "the", "spirits", "are", "attacking", "them", "as", "they", "believe", "that", "the", "humans", "are", "invaders", "and", "plan", "to", "ex", "##ter", "##minate", "the", "humans", "on", "Mars", "At", "one", "point", "[unused6]", "[SEP]", "[unused1]", "the", "humans", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "invaders", "and", "plan", "to", "ex", "##ter", "##minate", "the", "humans", "on", "Mars", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "is", "given", "[unused4]", "[unused5]", "a", "drug", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "discovers", "[unused4]", "[unused5]", "that", "the", "spirits", "are", "attacking", "them", "as", "they", "believe", "that", "the", "humans", "are", "invaders", "and", "plan", "to", "ex", "##ter", "##minate", "the", "humans", "on", "Mars", "[unused6]", "[SEP]", "[unused1]", "the", "spirits", "[unused2]", "[unused3]", "are", "attacking", "[unused4]", "[unused5]", "them", "as", "they", "believe", "that", "the", "humans", "are", "invaders", "and", "plan", "to", "ex", "##ter", "##minate", "the", "humans", "on", "Mars", "[unused6]", "[SEP]"]]}

input 50:  {"source": "Barbara , however , unable to leave behind her vigilante life , fought a mugger and ultimately miscarried her child .\n"}
prediction:  {"predictions": [[1, 5934, 2, 3, 3214, 4, 5, 170, 15761, 2895, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5934, 3372, 1106, 1817, 1481, 1123, 191, 24874, 26093, 1297, 2, 3, 1940, 26996, 18888, 4, 5, 1123, 2027, 4444, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.12673233449459076, -0.06306510418653488, -0.15060925483703613, -0.15061521530151367, -0.15061521530151367, -0.15061521530151367, -0.15061521530151367, -0.15061521530151367, -0.15061521530151367, -0.15061521530151367], "metadata": {"source_tokens": ["Barbara", ",", "however", ",", "unable", "to", "leave", "behind", "her", "v", "##igi", "##lante", "life", ",", "fought", "a", "mug", "##ger", "and", "ultimately", "mi", "##sca", "##rried", "her", "child", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Barbara", "[unused2]", "[unused3]", "fought", "[unused4]", "[unused5]", "a", "mug", "##ger", "[unused6]", "[SEP]", "[unused1]", "Barbara", "unable", "to", "leave", "behind", "her", "v", "##igi", "##lante", "life", "[unused2]", "[unused3]", "mi", "##sca", "##rried", "[unused4]", "[unused5]", "her", "child", "ultimately", "[unused6]", "[SEP]"]]}

input 51:  {"source": "Because Yesler Way marks the boundary between two different plats , the street grid north of Yesler does not line up with the neighborhood 's other streets , so the northern `` border '' of the district zigzags along numerous streets .\n"}
prediction:  {"predictions": [[1, 2160, 2879, 4714, 2, 3, 6216, 4, 5, 1103, 5904, 1206, 1160, 1472, 185, 16236, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2472, 8866, 1564, 1104, 2160, 2879, 2, 3, 1674, 1136, 1413, 1146, 4, 5, 1114, 1103, 4532, 112, 1116, 1168, 4324, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2350, 3070, 1104, 1103, 1629, 2, 3, 195, 6512, 3293, 5700, 4, 5, 1373, 2567, 4324, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.031286004930734634, -0.011787145398557186, -0.060735005885362625, -0.12908291816711426, -0.13959836959838867, -0.13959836959838867, -0.13959836959838867, -0.13959836959838867, -0.13959836959838867, -0.13959836959838867], "metadata": {"source_tokens": ["Because", "Yes", "##ler", "Way", "marks", "the", "boundary", "between", "two", "different", "p", "##lat", "##s", ",", "the", "street", "grid", "north", "of", "Yes", "##ler", "does", "not", "line", "up", "with", "the", "neighborhood", "'", "##s", "other", "streets", ",", "so", "the", "northern", "`", "##`", "border", "'", "##'", "of", "the", "district", "z", "##ig", "##za", "##gs", "along", "numerous", "streets", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Yes", "##ler", "Way", "[unused2]", "[unused3]", "marks", "[unused4]", "[unused5]", "the", "boundary", "between", "two", "different", "p", "##lat", "##s", "[unused6]", "[SEP]", "[unused1]", "the", "street", "grid", "north", "of", "Yes", "##ler", "[unused2]", "[unused3]", "does", "not", "line", "up", "[unused4]", "[unused5]", "with", "the", "neighborhood", "'", "##s", "other", "streets", "[unused6]", "[SEP]", "[unused1]", "the", "northern", "border", "of", "the", "district", "[unused2]", "[unused3]", "z", "##ig", "##za", "##gs", "[unused4]", "[unused5]", "along", "numerous", "streets", "[unused6]", "[SEP]"]]}

input 52:  {"source": "Because of Muhammad 's role in its formation , the alliance plays a significant role in Islamic ethics .\n"}
prediction:  {"predictions": [[1, 1103, 7214, 2, 3, 2399, 4, 5, 170, 2418, 1648, 1107, 4769, 13438, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00040286779403686523, -0.0012269020080566406, -0.0013537406921386719, -0.0013537406921386719, -0.0013537406921386719, -0.0013537406921386719, -0.0013537406921386719, -0.0013537406921386719, -0.0013537406921386719, -0.0013537406921386719], "metadata": {"source_tokens": ["Because", "of", "Muhammad", "'", "##s", "role", "in", "its", "formation", ",", "the", "alliance", "plays", "a", "significant", "role", "in", "Islamic", "ethics", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "alliance", "[unused2]", "[unused3]", "plays", "[unused4]", "[unused5]", "a", "significant", "role", "in", "Islamic", "ethics", "[unused6]", "[SEP]"]]}

input 53:  {"source": "Because of his talents and training , Beast can outperform any Olympic-level athlete , contorting his body and performing aerial feats gracefully .\n"}
prediction:  {"predictions": [[1, 11868, 2, 3, 1169, 1149, 3365, 13199, 4, 5, 1251, 3557, 28137, 23403, 1883, 8765, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11868, 2, 3, 1169, 1149, 3365, 13199, 4, 5, 1251, 3557, 28137, 23403, 1883, 8765, 14255, 2772, 1916, 1117, 1404, 1105, 4072, 10485, 8809, 1116, 21620, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023199770599603653, -0.05744893476366997, -0.2114088535308838, -0.2661888599395752, -0.2661888599395752, -0.2661888599395752, -0.2661888599395752, -0.2661888599395752, -0.2661888599395752, -0.2661888599395752], "metadata": {"source_tokens": ["Because", "of", "his", "talents", "and", "training", ",", "Beast", "can", "out", "##per", "##form", "any", "Olympic", "##-", "##lev", "##el", "athlete", ",", "con", "##tor", "##ting", "his", "body", "and", "performing", "aerial", "feat", "##s", "graceful", "##ly", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Beast", "[unused2]", "[unused3]", "can", "out", "##per", "##form", "[unused4]", "[unused5]", "any", "Olympic", "##-", "##lev", "##el", "athlete", "[unused6]", "[SEP]", "[unused1]", "Beast", "[unused2]", "[unused3]", "can", "out", "##per", "##form", "[unused4]", "[unused5]", "any", "Olympic", "##-", "##lev", "##el", "athlete", "con", "##tor", "##ting", "his", "body", "and", "performing", "aerial", "feat", "##s", "graceful", "##ly", "[unused6]", "[SEP]"]]}

input 54:  {"source": "Bruce 's Justice Lord counterpart was happily married to Wonder Woman as well until her Justice Lord counterpart killed him .\n"}
prediction:  {"predictions": [[1, 4767, 112, 1116, 3302, 2188, 14132, 2, 3, 1108, 11786, 1597, 4, 5, 1106, 10991, 5651, 1235, 1123, 3302, 2188, 14132, 1841, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4767, 112, 1116, 3302, 2188, 14132, 2, 3, 1108, 1597, 4, 5, 1106, 10991, 5651, 1112, 1218, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04524916037917137, -0.0941191166639328, -0.03220319747924805, -0.032204627990722656, -0.032204627990722656, -0.032204627990722656, -0.032204627990722656, -0.032204627990722656, -0.032204627990722656, -0.032204627990722656], "metadata": {"source_tokens": ["Bruce", "'", "##s", "Justice", "Lord", "counterpart", "was", "happily", "married", "to", "Wonder", "Woman", "as", "well", "until", "her", "Justice", "Lord", "counterpart", "killed", "him", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Bruce", "'", "##s", "Justice", "Lord", "counterpart", "[unused2]", "[unused3]", "was", "happily", "married", "[unused4]", "[unused5]", "to", "Wonder", "Woman", "until", "her", "Justice", "Lord", "counterpart", "killed", "him", "[unused6]", "[SEP]", "[unused1]", "Bruce", "'", "##s", "Justice", "Lord", "counterpart", "[unused2]", "[unused3]", "was", "married", "[unused4]", "[unused5]", "to", "Wonder", "Woman", "as", "well", "[unused6]", "[SEP]"]]}

input 55:  {"source": "Burnham died of heart failure at the age of 86 , on September 1 , 1947 at his home in Santa , Barbara , California .\n"}
prediction:  {"predictions": [[1, 16915, 2522, 2, 3, 1452, 4, 5, 1104, 1762, 4290, 1120, 1103, 1425, 1104, 5942, 1113, 1347, 122, 1120, 1117, 1313, 1107, 3364, 117, 5934, 117, 1756, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16915, 2522, 2, 3, 1452, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16915, 2522, 2, 3, 1452, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16915, 2522, 2, 3, 1452, 4, 5, 1113, 1347, 122, 3138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.10327222943305969, -0.07149893045425415, -0.1212177500128746, -0.20510299503803253, -0.3178286552429199, -0.3154451847076416, -0.3154451847076416, -0.3154451847076416, -0.3154451847076416, -0.3154451847076416], "metadata": {"source_tokens": ["Burn", "##ham", "died", "of", "heart", "failure", "at", "the", "age", "of", "86", ",", "on", "September", "1", ",", "1947", "at", "his", "home", "in", "Santa", ",", "Barbara", ",", "California", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Burn", "##ham", "[unused2]", "[unused3]", "died", "[unused4]", "[unused5]", "of", "heart", "failure", "at", "the", "age", "of", "86", "on", "September", "1", "at", "his", "home", "in", "Santa", ",", "Barbara", ",", "California", "[unused6]", "[SEP]", "[unused1]", "Burn", "##ham", "[unused2]", "[unused3]", "died", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Burn", "##ham", "[unused2]", "[unused3]", "died", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Burn", "##ham", "[unused2]", "[unused3]", "died", "[unused4]", "[unused5]", "on", "September", "1", "1947", "[unused6]", "[SEP]"]]}

input 56:  {"source": "But this practice simply reduces government interest costs rather than truly canceling government debt , and can result in hyperinflation if used unsparingly .\n"}
prediction:  {"predictions": [[1, 1142, 2415, 2, 3, 13822, 4, 5, 1433, 2199, 4692, 1897, 1190, 5098, 19722, 1158, 1433, 6695, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1142, 2415, 2, 3, 1169, 1871, 4, 5, 1107, 177, 24312, 1394, 2087, 6840, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1142, 2415, 2, 3, 1169, 1871, 4, 5, 1107, 177, 24312, 1394, 2087, 6840, 1191, 1215, 8362, 20080, 10832, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05875673145055771, -0.03883654996752739, -0.04557894170284271, -0.07634377479553223, -0.07634425163269043, -0.07634425163269043, -0.07634425163269043, -0.07634425163269043, -0.07634425163269043, -0.07634425163269043], "metadata": {"source_tokens": ["But", "this", "practice", "simply", "reduces", "government", "interest", "costs", "rather", "than", "truly", "cancel", "##ing", "government", "debt", ",", "and", "can", "result", "in", "h", "##yper", "##in", "##f", "##lation", "if", "used", "un", "##sp", "##aring", "##ly", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "this", "practice", "[unused2]", "[unused3]", "reduces", "[unused4]", "[unused5]", "government", "interest", "costs", "rather", "than", "truly", "cancel", "##ing", "government", "debt", "[unused6]", "[SEP]", "[unused1]", "this", "practice", "[unused2]", "[unused3]", "can", "result", "[unused4]", "[unused5]", "in", "h", "##yper", "##in", "##f", "##lation", "[unused6]", "[SEP]", "[unused1]", "this", "practice", "[unused2]", "[unused3]", "can", "result", "[unused4]", "[unused5]", "in", "h", "##yper", "##in", "##f", "##lation", "if", "used", "un", "##sp", "##aring", "##ly", "[unused6]", "[SEP]"]]}

input 57:  {"source": "By then , she was raising not only her own children but also her nephews , who had been orphaned by the plague .\n"}
prediction:  {"predictions": [[1, 1131, 2, 3, 1108, 5920, 4, 5, 1136, 1178, 1123, 1319, 1482, 1133, 1145, 1123, 7502, 1116, 1650, 1173, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1123, 7502, 1116, 2, 3, 1125, 1151, 25298, 1174, 4, 5, 1118, 1103, 13824, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.033945515751838684, -0.04125525802373886, -0.03235745429992676, -0.03229379653930664, -0.03229379653930664, -0.03229379653930664, -0.03229379653930664, -0.03229379653930664, -0.03229379653930664, -0.03229379653930664], "metadata": {"source_tokens": ["By", "then", ",", "she", "was", "raising", "not", "only", "her", "own", "children", "but", "also", "her", "nephew", "##s", ",", "who", "had", "been", "orphan", "##ed", "by", "the", "plague", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "she", "[unused2]", "[unused3]", "was", "raising", "[unused4]", "[unused5]", "not", "only", "her", "own", "children", "but", "also", "her", "nephew", "##s", "By", "then", "[unused6]", "[SEP]", "[unused1]", "her", "nephew", "##s", "[unused2]", "[unused3]", "had", "been", "orphan", "##ed", "[unused4]", "[unused5]", "by", "the", "plague", "[unused6]", "[SEP]"]]}

input 58:  {"source": "By this point , Simpson had returned to his mansion in Brentwood and had surrendered to police .\n"}
prediction:  {"predictions": [[1, 8989, 2, 3, 1125, 1608, 4, 5, 1106, 1117, 8280, 1107, 13150, 2615, 1650, 1142, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8989, 2, 3, 1125, 10738, 4, 5, 1106, 2021, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.020467789843678474, -0.03787827491760254, -0.07655763626098633, -0.07657790184020996, -0.07657790184020996, -0.07657790184020996, -0.07657790184020996, -0.07657790184020996, -0.07657790184020996, -0.07657790184020996], "metadata": {"source_tokens": ["By", "this", "point", ",", "Simpson", "had", "returned", "to", "his", "mansion", "in", "Brent", "##wood", "and", "had", "surrendered", "to", "police", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Simpson", "[unused2]", "[unused3]", "had", "returned", "[unused4]", "[unused5]", "to", "his", "mansion", "in", "Brent", "##wood", "By", "this", "point", "[unused6]", "[SEP]", "[unused1]", "Simpson", "[unused2]", "[unused3]", "had", "surrendered", "[unused4]", "[unused5]", "to", "police", "[unused6]", "[SEP]"]]}

input 59:  {"source": "Byers states that global citizenship is a `` powerful term '' because `` people that invoke it do so to provoke and justify action , '' and encourages the attendees of his lecture to re-appropriate it in order for its meaning to have a positive purpose , based on idealistic values .\n"}
prediction:  {"predictions": [[1, 17774, 1733, 2, 3, 2231, 4, 5, 1115, 4265, 9709, 1110, 170, 169, 28152, 3110, 1858, 112, 28131, 1272, 169, 28152, 1234, 1115, 1107, 14638, 1122, 1202, 1177, 1106, 5250, 14638, 1105, 17422, 2168, 117, 112, 28131, 1105, 17233, 1103, 23150, 1104, 1117, 10309, 1106, 1231, 28137, 11478, 1643, 102, 1, 1157, 2764, 2, 3, 1106, 1138, 4, 5, 170, 3112, 3007, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 17774, 1733, 2, 3, 2231, 4, 5, 1115, 4265, 9709, 1110, 170, 3110, 1858, 1272, 169, 28152, 1234, 1115, 1107, 14638, 1122, 1202, 1177, 1106, 5250, 14638, 1105, 17422, 2168, 117, 112, 28131, 1105, 17233, 1103, 23150, 1104, 1117, 10309, 1106, 1231, 28137, 11478, 1643, 12736, 3464, 1566, 1122, 102, 1, 17774, 1733, 2, 3, 2231, 4, 5, 1115, 4265, 9709, 1110, 170, 3110, 1858, 1272, 1234, 1115, 1107, 14638, 1122, 1202, 1177, 1106, 5250, 14638, 1105, 17422, 2168, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 17774, 1733, 2, 3, 2231, 4, 5, 1115, 4265, 9709, 1110, 170, 3110, 1858, 1272, 1234, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 17774, 1733, 2, 3, 2231, 4, 5, 1115, 4265, 9709, 1110, 170, 3110, 1858, 1272, 1234, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 17774, 1733, 2, 3, 2231, 4, 5, 1115, 4265, 9709, 1110, 170, 3110, 1858, 1272, 1234, 6, 102, 102, 1, 17774, 1733, 2, 3, 2231, 4, 5, 1115, 4265, 9709, 1110, 170, 3110, 1858, 1272, 1234, 6, 102, 102, 1, 17774, 1733, 2, 3, 2231, 4, 5, 1115, 4265, 9709, 1110, 170, 3110, 1858, 1272, 1234, 6, 102, 102, 1, 4265, 9709, 2, 3, 1110, 4, 5, 170, 3110, 1858, 6, 102, 102]], "predicted_log_probs": [-0.02103399485349655, -0.11796768754720688, -0.09959806501865387, -0.1741284877061844, -0.27341657876968384, -0.26719218492507935, -0.2632397711277008, -0.2606746256351471, -0.2597386837005615, -0.21327561140060425], "metadata": {"source_tokens": ["Bye", "##rs", "states", "that", "global", "citizenship", "is", "a", "`", "##`", "powerful", "term", "'", "##'", "because", "`", "##`", "people", "that", "in", "##voke", "it", "do", "so", "to", "pro", "##voke", "and", "justify", "action", ",", "'", "##'", "and", "encourages", "the", "attendees", "of", "his", "lecture", "to", "re", "##-", "##ap", "##p", "##rop", "##ria", "##te", "it", "in", "order", "for", "its", "meaning", "to", "have", "a", "positive", "purpose", ",", "based", "on", "ideal", "##istic", "values", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Bye", "##rs", "[unused2]", "[unused3]", "states", "[unused4]", "[unused5]", "that", "global", "citizenship", "is", "a", "`", "##`", "powerful", "term", "'", "##'", "because", "`", "##`", "people", "that", "in", "##voke", "it", "do", "so", "to", "pro", "##voke", "and", "justify", "action", ",", "'", "##'", "and", "encourages", "the", "attendees", "of", "his", "lecture", "to", "re", "##-", "##ap", "##p", "[SEP]", "[unused1]", "its", "meaning", "[unused2]", "[unused3]", "to", "have", "[unused4]", "[unused5]", "a", "positive", "purpose", "[unused6]", "[SEP]", "[unused1]", "Bye", "##rs", "[unused2]", "[unused3]", "states", "[unused4]", "[unused5]", "that", "global", "citizenship", "is", "a", "powerful", "term", "because", "`", "##`", "people", "that", "in", "##voke", "it", "do", "so", "to", "pro", "##voke", "and", "justify", "action", ",", "'", "##'", "and", "encourages", "the", "attendees", "of", "his", "lecture", "to", "re", "##-", "##ap", "##p", "##rop", "##ria", "##te", "it", "[SEP]", "[unused1]", "Bye", "##rs", "[unused2]", "[unused3]", "states", "[unused4]", "[unused5]", "that", "global", "citizenship", "is", "a", "powerful", "term", "because", "people", "that", "in", "##voke", "it", "do", "so", "to", "pro", "##voke", "and", "justify", "action", "[unused6]", "[SEP]", "[unused1]", "Bye", "##rs", "[unused2]", "[unused3]", "states", "[unused4]", "[unused5]", "that", "global", "citizenship", "is", "a", "powerful", "term", "because", "people", "[unused6]", "[SEP]", "[unused1]", "Bye", "##rs", "[unused2]", "[unused3]", "states", "[unused4]", "[unused5]", "that", "global", "citizenship", "is", "a", "powerful", "term", "because", "people", "[unused6]", "[SEP]", "[unused1]", "Bye", "##rs", "[unused2]", "[unused3]", "states", "[unused4]", "[unused5]", "that", "global", "citizenship", "is", "a", "powerful", "term", "because", "people", "[unused6]", "[SEP]", "[unused1]", "Bye", "##rs", "[unused2]", "[unused3]", "states", "[unused4]", "[unused5]", "that", "global", "citizenship", "is", "a", "powerful", "term", "because", "people", "[unused6]", "[SEP]", "[unused1]", "Bye", "##rs", "[unused2]", "[unused3]", "states", "[unused4]", "[unused5]", "that", "global", "citizenship", "is", "a", "powerful", "term", "because", "people", "[unused6]", "[SEP]", "[unused1]", "global", "citizenship", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "powerful", "term", "[unused6]", "[SEP]"]]}

input 60:  {"source": "Carl uses the `` old magic '' to tame the Deep Crow , claiming it is not his `` first time to the rodeo . ''\n"}
prediction:  {"predictions": [[1, 4804, 2, 3, 2745, 4, 5, 1103, 169, 28152, 1385, 3974, 112, 28131, 1106, 27629, 3263, 1103, 7786, 15252, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4804, 2, 3, 2745, 1103, 169, 28152, 1385, 3974, 6330, 4, 5, 1122, 1110, 1136, 1117, 169, 28152, 1148, 1159, 1106, 1103, 8335, 1186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4804, 2, 3, 2745, 4, 5, 1103, 1385, 3974, 1106, 27629, 3263, 1103, 7786, 15252, 6330, 1122, 1110, 1136, 1117, 1148, 1159, 1106, 1103, 8335, 1186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06845308095216751, -0.08273560553789139, -0.09608075022697449, -0.2065349817276001, -0.2096925973892212, -0.2096925973892212, -0.2096925973892212, -0.2096925973892212, -0.2096925973892212, -0.2096925973892212], "metadata": {"source_tokens": ["Carl", "uses", "the", "`", "##`", "old", "magic", "'", "##'", "to", "ta", "##me", "the", "Deep", "Crow", ",", "claiming", "it", "is", "not", "his", "`", "##`", "first", "time", "to", "the", "rode", "##o", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Carl", "[unused2]", "[unused3]", "uses", "[unused4]", "[unused5]", "the", "`", "##`", "old", "magic", "'", "##'", "to", "ta", "##me", "the", "Deep", "Crow", "[unused6]", "[SEP]", "[unused1]", "Carl", "[unused2]", "[unused3]", "uses", "the", "`", "##`", "old", "magic", "claiming", "[unused4]", "[unused5]", "it", "is", "not", "his", "`", "##`", "first", "time", "to", "the", "rode", "##o", "[unused6]", "[SEP]", "[unused1]", "Carl", "[unused2]", "[unused3]", "uses", "[unused4]", "[unused5]", "the", "old", "magic", "to", "ta", "##me", "the", "Deep", "Crow", "claiming", "it", "is", "not", "his", "first", "time", "to", "the", "rode", "##o", "[unused6]", "[SEP]"]]}

input 61:  {"source": "Certain fractional quantum Hall phases appear to have the right properties for building a topological quantum computer .\n"}
prediction:  {"predictions": [[1, 16482, 13394, 1348, 9539, 1944, 12877, 2, 3, 2845, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16482, 13394, 1348, 9539, 1944, 12877, 2, 3, 1106, 1138, 4, 5, 1103, 1268, 4625, 1111, 1459, 170, 1499, 7542, 9539, 2775, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004082577768713236, -0.0015948438085615635, -0.0005950927734375, -0.0006542205810546875, -0.0006542205810546875, -0.0006542205810546875, -0.0006542205810546875, -0.0006542205810546875, -0.0006542205810546875, -0.0006542205810546875], "metadata": {"source_tokens": ["Certain", "fraction", "##al", "quantum", "Hall", "phases", "appear", "to", "have", "the", "right", "properties", "for", "building", "a", "top", "##ological", "quantum", "computer", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Certain", "fraction", "##al", "quantum", "Hall", "phases", "[unused2]", "[unused3]", "appear", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Certain", "fraction", "##al", "quantum", "Hall", "phases", "[unused2]", "[unused3]", "to", "have", "[unused4]", "[unused5]", "the", "right", "properties", "for", "building", "a", "top", "##ological", "quantum", "computer", "[unused6]", "[SEP]"]]}

input 62:  {"source": "Chevalier fulfilled his promise the following year by erecting a shrine dedicated to the honour of Mary under the title of `` Our Lady of the Sacred Heart '' .\n"}
prediction:  {"predictions": [[1, 26353, 2, 3, 18210, 4, 5, 1117, 4437, 1103, 1378, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 12157, 2, 3, 3256, 4, 5, 1106, 1103, 6565, 1104, 2090, 1223, 1103, 1641, 1104, 169, 28152, 3458, 2876, 1104, 1103, 11373, 4641, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26353, 2, 3, 18210, 1117, 4437, 1118, 15685, 1158, 4, 5, 170, 12157, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0982840433716774, -0.06297179311513901, -0.08420216292142868, -0.13657832145690918, -0.13062214851379395, -0.13062214851379395, -0.13062214851379395, -0.13062214851379395, -0.13062214851379395, -0.13062214851379395], "metadata": {"source_tokens": ["Chevalier", "fulfilled", "his", "promise", "the", "following", "year", "by", "erect", "##ing", "a", "shrine", "dedicated", "to", "the", "honour", "of", "Mary", "under", "the", "title", "of", "`", "##`", "Our", "Lady", "of", "the", "Sacred", "Heart", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Chevalier", "[unused2]", "[unused3]", "fulfilled", "[unused4]", "[unused5]", "his", "promise", "the", "following", "year", "[unused6]", "[SEP]", "[unused1]", "a", "shrine", "[unused2]", "[unused3]", "dedicated", "[unused4]", "[unused5]", "to", "the", "honour", "of", "Mary", "under", "the", "title", "of", "`", "##`", "Our", "Lady", "of", "the", "Sacred", "Heart", "[unused6]", "[SEP]", "[unused1]", "Chevalier", "[unused2]", "[unused3]", "fulfilled", "his", "promise", "by", "erect", "##ing", "[unused4]", "[unused5]", "a", "shrine", "[unused6]", "[SEP]"]]}

input 63:  {"source": "Cis-regulatory elements are sequences that control the transcription of a nearby gene .\n"}
prediction:  {"predictions": [[1, 140, 1548, 28137, 1874, 13830, 13389, 1183, 3050, 2, 3, 1132, 4, 5, 10028, 1115, 1654, 1103, 15416, 1104, 170, 2721, 5565, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00020351409330032766, -0.038555145263671875, -0.03855562210083008, -0.03855562210083008, -0.03855562210083008, -0.03855562210083008, -0.03855562210083008, -0.03855562210083008, -0.03855562210083008, -0.03855562210083008], "metadata": {"source_tokens": ["C", "##is", "##-", "##re", "##gu", "##lator", "##y", "elements", "are", "sequences", "that", "control", "the", "transcription", "of", "a", "nearby", "gene", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "C", "##is", "##-", "##re", "##gu", "##lator", "##y", "elements", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "sequences", "that", "control", "the", "transcription", "of", "a", "nearby", "gene", "[unused6]", "[SEP]"]]}

input 64:  {"source": "Citizens for Responsibility and Ethics in Washington filed an Ethics Committee complaint against Bond over his role in the ouster of Graves .\n"}
prediction:  {"predictions": [[1, 14649, 1111, 11336, 20080, 4199, 7706, 1105, 17475, 1107, 1994, 2, 3, 5770, 4, 5, 1126, 17475, 2341, 12522, 1222, 8211, 1166, 1117, 1648, 1107, 1103, 20796, 4648, 1104, 16494, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 14649, 1111, 11336, 20080, 4199, 7706, 1105, 17475, 1107, 1994, 2, 3, 5770, 4, 5, 1126, 17475, 2341, 12522, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.002047018613666296, -0.04976153373718262, -0.15041446685791016, -0.14948248863220215, -0.14948248863220215, -0.14948248863220215, -0.14948248863220215, -0.14948248863220215, -0.14948248863220215, -0.14948248863220215], "metadata": {"source_tokens": ["Citizens", "for", "Re", "##sp", "##ons", "##ibility", "and", "Ethics", "in", "Washington", "filed", "an", "Ethics", "Committee", "complaint", "against", "Bond", "over", "his", "role", "in", "the", "ou", "##ster", "of", "Graves", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Citizens", "for", "Re", "##sp", "##ons", "##ibility", "and", "Ethics", "in", "Washington", "[unused2]", "[unused3]", "filed", "[unused4]", "[unused5]", "an", "Ethics", "Committee", "complaint", "against", "Bond", "over", "his", "role", "in", "the", "ou", "##ster", "of", "Graves", "[unused6]", "[SEP]", "[unused1]", "Citizens", "for", "Re", "##sp", "##ons", "##ibility", "and", "Ethics", "in", "Washington", "[unused2]", "[unused3]", "filed", "[unused4]", "[unused5]", "an", "Ethics", "Committee", "complaint", "[unused6]", "[SEP]"]]}

input 65:  {"source": "Combined with appropriate match pellets these rifles produce a consistent 10 ring performance , so a non-maximal result during the initial phase can be attributed to the participant .\n"}
prediction:  {"predictions": [[1, 1292, 12385, 2, 3, 3133, 4, 5, 170, 8080, 1275, 3170, 2099, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1664, 28137, 22871, 8628, 1233, 1871, 1219, 1103, 3288, 4065, 2, 3, 1169, 1129, 6547, 4, 5, 1106, 1103, 14031, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.030489834025502205, -0.005561701953411102, -0.037790775299072266, -0.03794145584106445, -0.03794145584106445, -0.03794145584106445, -0.03794145584106445, -0.03794145584106445, -0.03794145584106445, -0.03794145584106445], "metadata": {"source_tokens": ["Combined", "with", "appropriate", "match", "p", "##elle", "##ts", "these", "rifles", "produce", "a", "consistent", "10", "ring", "performance", ",", "so", "a", "non", "##-", "##max", "##ima", "##l", "result", "during", "the", "initial", "phase", "can", "be", "attributed", "to", "the", "participant", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "these", "rifles", "[unused2]", "[unused3]", "produce", "[unused4]", "[unused5]", "a", "consistent", "10", "ring", "performance", "[unused6]", "[SEP]", "[unused1]", "a", "non", "##-", "##max", "##ima", "##l", "result", "during", "the", "initial", "phase", "[unused2]", "[unused3]", "can", "be", "attributed", "[unused4]", "[unused5]", "to", "the", "participant", "[unused6]", "[SEP]"]]}

input 66:  {"source": "Curley was the first classical organist to perform a solo organ recital at the White House , and also played before several European heads of state .\n"}
prediction:  {"predictions": [[1, 140, 27009, 2, 3, 1108, 4, 5, 1103, 1148, 4521, 19209, 1106, 3870, 170, 3444, 5677, 1231, 6617, 6163, 1120, 1103, 2061, 1585, 117, 1105, 1145, 1307, 1196, 1317, 1735, 4075, 1104, 1352, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 140, 27009, 2, 3, 1108, 4, 5, 1103, 1148, 4521, 19209, 1106, 3870, 170, 3444, 5677, 1231, 6617, 6163, 1120, 1103, 2061, 1585, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 140, 27009, 2, 3, 1108, 4, 5, 1103, 1148, 4521, 19209, 1106, 3870, 170, 3444, 5677, 1231, 6617, 6163, 1120, 1103, 2061, 1585, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 140, 27009, 2, 3, 1108, 4, 5, 1103, 1148, 4521, 19209, 1106, 3870, 170, 3444, 5677, 1231, 6617, 6163, 1120, 1103, 2061, 1585, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03294766694307327, -0.06279446184635162, -0.11893400549888611, -0.1477837860584259, -0.25044798851013184, -0.25038838386535645, -0.25038838386535645, -0.25038838386535645, -0.25038838386535645, -0.25038838386535645], "metadata": {"source_tokens": ["C", "##urley", "was", "the", "first", "classical", "organist", "to", "perform", "a", "solo", "organ", "re", "##ci", "##tal", "at", "the", "White", "House", ",", "and", "also", "played", "before", "several", "European", "heads", "of", "state", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "C", "##urley", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "first", "classical", "organist", "to", "perform", "a", "solo", "organ", "re", "##ci", "##tal", "at", "the", "White", "House", ",", "and", "also", "played", "before", "several", "European", "heads", "of", "state", "[unused6]", "[SEP]", "[unused1]", "C", "##urley", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "first", "classical", "organist", "to", "perform", "a", "solo", "organ", "re", "##ci", "##tal", "at", "the", "White", "House", "[unused6]", "[SEP]", "[unused1]", "C", "##urley", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "first", "classical", "organist", "to", "perform", "a", "solo", "organ", "re", "##ci", "##tal", "at", "the", "White", "House", "[unused6]", "[SEP]", "[unused1]", "C", "##urley", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "first", "classical", "organist", "to", "perform", "a", "solo", "organ", "re", "##ci", "##tal", "at", "the", "White", "House", "[unused6]", "[SEP]"]]}

input 67:  {"source": "DC Comics held a memorial service in Manhattan 's Lower East Side , a neighborhood Eisner often visited in his work , at the Angel Orensanz Foundation on Norfolk Street .\n"}
prediction:  {"predictions": [[1, 5227, 7452, 2, 3, 1316, 4, 5, 170, 6768, 1555, 1107, 6545, 112, 1116, 5738, 1689, 6383, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4532, 2, 3, 3891, 4, 5, 1107, 1117, 1250, 1120, 1103, 5876, 2926, 5026, 1389, 1584, 2974, 1113, 7240, 1715, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5227, 7452, 2, 3, 1316, 4, 5, 170, 6768, 1555, 1107, 6545, 112, 1116, 5738, 1689, 6383, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5227, 7452, 2, 3, 1316, 4, 5, 170, 6768, 1555, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5227, 7452, 2, 3, 1316, 4, 5, 170, 6768, 1555, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.018476521596312523, -0.03662360459566116, -0.09952707588672638, -0.14226152002811432, -0.14877590537071228, -0.3196045160293579, -0.32920610904693604, -0.32920610904693604, -0.32920610904693604, -0.32920610904693604], "metadata": {"source_tokens": ["DC", "Comics", "held", "a", "memorial", "service", "in", "Manhattan", "'", "##s", "Lower", "East", "Side", ",", "a", "neighborhood", "E", "##is", "##ner", "often", "visited", "in", "his", "work", ",", "at", "the", "Angel", "Or", "##ens", "##an", "##z", "Foundation", "on", "Norfolk", "Street", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "DC", "Comics", "[unused2]", "[unused3]", "held", "[unused4]", "[unused5]", "a", "memorial", "service", "in", "Manhattan", "'", "##s", "Lower", "East", "Side", "[unused6]", "[SEP]", "[unused1]", "a", "neighborhood", "[unused2]", "[unused3]", "visited", "[unused4]", "[unused5]", "in", "his", "work", "at", "the", "Angel", "Or", "##ens", "##an", "##z", "Foundation", "on", "Norfolk", "Street", "often", "[unused6]", "[SEP]", "[unused1]", "DC", "Comics", "[unused2]", "[unused3]", "held", "[unused4]", "[unused5]", "a", "memorial", "service", "in", "Manhattan", "'", "##s", "Lower", "East", "Side", "[unused6]", "[SEP]", "[unused1]", "DC", "Comics", "[unused2]", "[unused3]", "held", "[unused4]", "[unused5]", "a", "memorial", "service", "[unused6]", "[SEP]", "[unused1]", "DC", "Comics", "[unused2]", "[unused3]", "held", "[unused4]", "[unused5]", "a", "memorial", "service", "[unused6]", "[SEP]"]]}

input 68:  {"source": "Despite the below-freezing temperatures , Beuerlein was red-hot , out-dueling Brett Favre and connecting on 29 of 42 attempts , with 3 TDs and no INTs , and passing for a then franchise-record 373 yards .\n"}
prediction:  {"predictions": [[1, 4108, 10232, 18929, 2, 3, 1108, 4, 5, 1894, 28137, 12217, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4108, 10232, 18929, 2, 3, 1108, 4, 5, 1894, 28137, 12217, 1149, 28137, 21405, 1979, 12161, 143, 23140, 1874, 1105, 6755, 1113, 1853, 1104, 3565, 4021, 1114, 124, 15439, 1116, 1105, 1185, 15969, 1942, 1116, 1105, 3744, 1111, 170, 1173, 5801, 28137, 1874, 19248, 1181, 3413, 1495, 3422, 2711, 102, 1, 4108, 10232, 18929, 2, 3, 1108, 4, 5, 1894, 28137, 12217, 2711, 1103, 2071, 28137, 26743, 6185, 7479, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4108, 10232, 18929, 2, 3, 1108, 4, 5, 1894, 28137, 12217, 1149, 28137, 21405, 1979, 12161, 143, 23140, 1874, 1105, 6755, 1113, 1853, 1104, 3565, 4021, 1114, 124, 15439, 1116, 1105, 1185, 15969, 1942, 1116, 1105, 3744, 1111, 170, 1173, 5801, 28137, 1874, 19248, 1181, 3413, 1495, 3422, 2711, 102, 1, 4108, 10232, 18929, 2, 3, 1108, 4, 5, 1894, 28137, 12217, 1149, 28137, 21405, 1979, 12161, 143, 23140, 1874, 1105, 6755, 1113, 1853, 1104, 3565, 4021, 1114, 124, 15439, 1116, 1105, 1185, 15969, 1942, 1116, 1105, 3744, 1111, 170, 1173, 5801, 28137, 1874, 19248, 1181, 3413, 1495, 3422, 2711, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.060089726001024246, -0.06248066946864128, -0.08769022673368454, -0.06469352543354034, -0.07008520513772964, -0.2420649528503418, -0.29393434524536133, -0.29393434524536133, -0.29393434524536133, -0.29393434524536133], "metadata": {"source_tokens": ["Despite", "the", "below", "##-", "##free", "##zing", "temperatures", ",", "Be", "##uer", "##lein", "was", "red", "##-", "##hot", ",", "out", "##-", "##due", "##ling", "Brett", "F", "##av", "##re", "and", "connecting", "on", "29", "of", "42", "attempts", ",", "with", "3", "TD", "##s", "and", "no", "IN", "##T", "##s", ",", "and", "passing", "for", "a", "then", "franchise", "##-", "##re", "##cor", "##d", "37", "##3", "yards", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Be", "##uer", "##lein", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "red", "##-", "##hot", "[unused6]", "[SEP]", "[unused1]", "Be", "##uer", "##lein", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "red", "##-", "##hot", "out", "##-", "##due", "##ling", "Brett", "F", "##av", "##re", "and", "connecting", "on", "29", "of", "42", "attempts", "with", "3", "TD", "##s", "and", "no", "IN", "##T", "##s", "and", "passing", "for", "a", "then", "franchise", "##-", "##re", "##cor", "##d", "37", "##3", "yards", "Despite", "[SEP]", "[unused1]", "Be", "##uer", "##lein", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "red", "##-", "##hot", "Despite", "the", "below", "##-", "##free", "##zing", "temperatures", "[unused6]", "[SEP]", "[unused1]", "Be", "##uer", "##lein", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "red", "##-", "##hot", "out", "##-", "##due", "##ling", "Brett", "F", "##av", "##re", "and", "connecting", "on", "29", "of", "42", "attempts", "with", "3", "TD", "##s", "and", "no", "IN", "##T", "##s", "and", "passing", "for", "a", "then", "franchise", "##-", "##re", "##cor", "##d", "37", "##3", "yards", "Despite", "[SEP]", "[unused1]", "Be", "##uer", "##lein", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "red", "##-", "##hot", "out", "##-", "##due", "##ling", "Brett", "F", "##av", "##re", "and", "connecting", "on", "29", "of", "42", "attempts", "with", "3", "TD", "##s", "and", "no", "IN", "##T", "##s", "and", "passing", "for", "a", "then", "franchise", "##-", "##re", "##cor", "##d", "37", "##3", "yards", "Despite", "[SEP]"]]}

input 69:  {"source": "Dodo was originally intended to have a `` common '' accent , and is portrayed this way at the end of `` The Massacre '' .\n"}
prediction:  {"predictions": [[1, 2091, 2572, 2, 3, 1108, 3005, 4, 5, 1106, 1138, 170, 169, 28152, 1887, 112, 28131, 9603, 2034, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2091, 2572, 2, 3, 1110, 6313, 4, 5, 1142, 1236, 1120, 1103, 1322, 1104, 169, 28152, 1109, 20507, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2091, 2572, 2, 3, 1106, 1138, 4, 5, 170, 169, 28152, 1887, 112, 28131, 9603, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.050783514976501465, -0.04139026626944542, -0.08170750737190247, -0.07624030113220215, -0.07624268531799316, -0.07624268531799316, -0.07624268531799316, -0.07624268531799316, -0.07624268531799316, -0.07624268531799316], "metadata": {"source_tokens": ["Do", "##do", "was", "originally", "intended", "to", "have", "a", "`", "##`", "common", "'", "##'", "accent", ",", "and", "is", "portrayed", "this", "way", "at", "the", "end", "of", "`", "##`", "The", "Massacre", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Do", "##do", "[unused2]", "[unused3]", "was", "intended", "[unused4]", "[unused5]", "to", "have", "a", "`", "##`", "common", "'", "##'", "accent", "originally", "[unused6]", "[SEP]", "[unused1]", "Do", "##do", "[unused2]", "[unused3]", "is", "portrayed", "[unused4]", "[unused5]", "this", "way", "at", "the", "end", "of", "`", "##`", "The", "Massacre", "[unused6]", "[SEP]", "[unused1]", "Do", "##do", "[unused2]", "[unused3]", "to", "have", "[unused4]", "[unused5]", "a", "`", "##`", "common", "'", "##'", "accent", "[unused6]", "[SEP]"]]}

input 70:  {"source": "Dr. Pim played for Ireland against England in 1892 , 1893 , 1894 and 1896 .\n"}
prediction:  {"predictions": [[1, 1987, 28138, 21902, 1306, 2, 3, 1307, 4, 5, 1111, 2270, 1222, 1652, 1107, 5889, 117, 5843, 117, 5901, 1105, 5645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.021030673757195473, -0.03813648223876953, -0.038524627685546875, -0.038524627685546875, -0.038524627685546875, -0.038524627685546875, -0.038524627685546875, -0.038524627685546875, -0.038524627685546875, -0.038524627685546875], "metadata": {"source_tokens": ["Dr", "##.", "Pi", "##m", "played", "for", "Ireland", "against", "England", "in", "1892", ",", "1893", ",", "1894", "and", "1896", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Dr", "##.", "Pi", "##m", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "for", "Ireland", "against", "England", "in", "1892", ",", "1893", ",", "1894", "and", "1896", "[unused6]", "[SEP]"]]}

input 71:  {"source": "Due to the opposing nature of the two songs , they can be viewed as a debate on the opposing attitudes on love found throughout the play .\n"}
prediction:  {"predictions": [[1, 1103, 10137, 15149, 1113, 1567, 2, 3, 1276, 4, 5, 2032, 1103, 1505, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1169, 1129, 6497, 4, 5, 1112, 170, 5655, 1113, 1103, 10137, 15149, 1113, 1567, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01348707266151905, -0.00047304629697464406, -0.022001266479492188, -0.022001266479492188, -0.022001266479492188, -0.022001266479492188, -0.022001266479492188, -0.022001266479492188, -0.022001266479492188, -0.022001266479492188], "metadata": {"source_tokens": ["Due", "to", "the", "opposing", "nature", "of", "the", "two", "songs", ",", "they", "can", "be", "viewed", "as", "a", "debate", "on", "the", "opposing", "attitudes", "on", "love", "found", "throughout", "the", "play", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "opposing", "attitudes", "on", "love", "[unused2]", "[unused3]", "found", "[unused4]", "[unused5]", "throughout", "the", "play", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "can", "be", "viewed", "[unused4]", "[unused5]", "as", "a", "debate", "on", "the", "opposing", "attitudes", "on", "love", "[unused6]", "[SEP]"]]}

input 72:  {"source": "Due to the transmitter location being based in Tyrone and a smaller signal wattage , it was barely hearable in the northern portions of Atlanta beyond the downtown area or even the northern reaches of Fulton or DeKalb Counties , as it was a rimshot to the southwest of the city .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 1108, 4, 5, 170, 13840, 21879, 1106, 1103, 5090, 1104, 1103, 1331, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 11991, 2450, 2, 3, 1217, 1359, 4, 5, 1107, 20314, 1105, 170, 2964, 4344, 20049, 5100, 2176, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 2100, 1895, 1107, 1103, 2350, 8924, 1104, 5161, 2894, 1103, 5215, 1298, 1137, 1256, 1103, 2350, 5965, 1104, 18196, 1137, 3177, 2428, 1348, 1830, 12259, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 2100, 1895, 1107, 1103, 2350, 8924, 1104, 5161, 2894, 1103, 5215, 1298, 1137, 1256, 1103, 2350, 5965, 1104, 18196, 1137, 3177, 2428, 1348, 1830, 12259, 1112, 1122, 1108, 170, 13840, 21879, 1106, 1103, 5090, 1104, 1103, 1331, 4187, 1106, 1103, 11991, 2450, 1217, 102, 1, 1122, 2, 3, 1108, 4, 5, 2100, 1895, 1107, 1103, 2350, 8924, 1104, 5161, 2894, 1103, 5215, 1298, 1137, 1256, 1103, 2350, 5965, 1104, 18196, 1137, 3177, 2428, 1348, 1830, 12259, 1112, 1122, 1108, 170, 13840, 21879, 1106, 1103, 5090, 1104, 1103, 1331, 6, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.025373520329594612, -0.029622793197631836, -0.035877108573913574, -0.09546378999948502, -0.10013487190008163, -0.34665465354919434, -0.3466916084289551, -0.3466916084289551, -0.3466916084289551, -0.3466916084289551], "metadata": {"source_tokens": ["Due", "to", "the", "transmitter", "location", "being", "based", "in", "Tyrone", "and", "a", "smaller", "signal", "wa", "##tta", "##ge", ",", "it", "was", "barely", "hear", "##able", "in", "the", "northern", "portions", "of", "Atlanta", "beyond", "the", "downtown", "area", "or", "even", "the", "northern", "reaches", "of", "Fulton", "or", "De", "##K", "##al", "##b", "Counties", ",", "as", "it", "was", "a", "rim", "##shot", "to", "the", "southwest", "of", "the", "city", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "rim", "##shot", "to", "the", "southwest", "of", "the", "city", "[unused6]", "[SEP]", "[unused1]", "the", "transmitter", "location", "[unused2]", "[unused3]", "being", "based", "[unused4]", "[unused5]", "in", "Tyrone", "and", "a", "smaller", "signal", "wa", "##tta", "##ge", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "hear", "##able", "in", "the", "northern", "portions", "of", "Atlanta", "beyond", "the", "downtown", "area", "or", "even", "the", "northern", "reaches", "of", "Fulton", "or", "De", "##K", "##al", "##b", "Counties", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "hear", "##able", "in", "the", "northern", "portions", "of", "Atlanta", "beyond", "the", "downtown", "area", "or", "even", "the", "northern", "reaches", "of", "Fulton", "or", "De", "##K", "##al", "##b", "Counties", "as", "it", "was", "a", "rim", "##shot", "to", "the", "southwest", "of", "the", "city", "Due", "to", "the", "transmitter", "location", "being", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "hear", "##able", "in", "the", "northern", "portions", "of", "Atlanta", "beyond", "the", "downtown", "area", "or", "even", "the", "northern", "reaches", "of", "Fulton", "or", "De", "##K", "##al", "##b", "Counties", "as", "it", "was", "a", "rim", "##shot", "to", "the", "southwest", "of", "the", "city", "[unused6]", "[SEP]"]]}

input 73:  {"source": "During the Second World War , the number of Turkish run cafes increased from 20 in 1939 to 200 in 1945 which created a demand for more Turkish Cypriot workers .\n"}
prediction:  {"predictions": [[1, 1103, 1295, 1104, 4229, 1576, 17287, 1116, 2, 3, 2569, 4, 5, 1121, 1406, 1107, 3061, 1106, 2363, 1107, 2481, 1507, 1103, 2307, 1291, 1414, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2481, 2, 3, 1687, 4, 5, 170, 4555, 1111, 1167, 4229, 20036, 3239, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1295, 1104, 4229, 1576, 17287, 1116, 2, 3, 2569, 4, 5, 1121, 1406, 1107, 3061, 1106, 2363, 1107, 2481, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02333020232617855, -0.01678849756717682, -0.06885319948196411, -0.15147709846496582, -0.15120244026184082, -0.15120244026184082, -0.15120244026184082, -0.15120244026184082, -0.15120244026184082, -0.15120244026184082], "metadata": {"source_tokens": ["During", "the", "Second", "World", "War", ",", "the", "number", "of", "Turkish", "run", "cafe", "##s", "increased", "from", "20", "in", "1939", "to", "200", "in", "1945", "which", "created", "a", "demand", "for", "more", "Turkish", "Cypriot", "workers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "number", "of", "Turkish", "run", "cafe", "##s", "[unused2]", "[unused3]", "increased", "[unused4]", "[unused5]", "from", "20", "in", "1939", "to", "200", "in", "1945", "During", "the", "Second", "World", "War", "[unused6]", "[SEP]", "[unused1]", "1945", "[unused2]", "[unused3]", "created", "[unused4]", "[unused5]", "a", "demand", "for", "more", "Turkish", "Cypriot", "workers", "[unused6]", "[SEP]", "[unused1]", "the", "number", "of", "Turkish", "run", "cafe", "##s", "[unused2]", "[unused3]", "increased", "[unused4]", "[unused5]", "from", "20", "in", "1939", "to", "200", "in", "1945", "[unused6]", "[SEP]"]]}

input 74:  {"source": "During the morning and evening rush hours some services run direct to/from Paddington and Reading .\n"}
prediction:  {"predictions": [[1, 1199, 1826, 2, 3, 1576, 4, 5, 2904, 1106, 28139, 2087, 16071, 19585, 24103, 1105, 8003, 1507, 1103, 2106, 1105, 3440, 6274, 2005, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004033262841403484, -0.1510322093963623, -0.1510028839111328, -0.1510028839111328, -0.1510028839111328, -0.1510028839111328, -0.1510028839111328, -0.1510028839111328, -0.1510028839111328, -0.1510028839111328], "metadata": {"source_tokens": ["During", "the", "morning", "and", "evening", "rush", "hours", "some", "services", "run", "direct", "to", "##/", "##f", "##rom", "Pa", "##ddington", "and", "Reading", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "some", "services", "[unused2]", "[unused3]", "run", "[unused4]", "[unused5]", "direct", "to", "##/", "##f", "##rom", "Pa", "##ddington", "and", "Reading", "During", "the", "morning", "and", "evening", "rush", "hours", "[unused6]", "[SEP]"]]}

input 75:  {"source": "During the off-season the ACT Rugby Union was renamed the ACT and Southern NSW Rugby Union , and the name of the team was changed to Brumbies Rugby .\n"}
prediction:  {"predictions": [[1, 1103, 21111, 5457, 1913, 2, 3, 1108, 3286, 4, 5, 1103, 21111, 1105, 2685, 11557, 5457, 1913, 1507, 1103, 1228, 28137, 19885, 2142, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1271, 1104, 1103, 1264, 2, 3, 1108, 2014, 4, 5, 1106, 139, 5697, 16751, 5457, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02293998934328556, -0.0016521995421499014, -0.07680344581604004, -0.07679343223571777, -0.07679343223571777, -0.07679343223571777, -0.07679343223571777, -0.07679343223571777, -0.07679343223571777, -0.07679343223571777], "metadata": {"source_tokens": ["During", "the", "off", "##-", "##sea", "##son", "the", "ACT", "Rugby", "Union", "was", "renamed", "the", "ACT", "and", "Southern", "NSW", "Rugby", "Union", ",", "and", "the", "name", "of", "the", "team", "was", "changed", "to", "B", "##rum", "##bies", "Rugby", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "ACT", "Rugby", "Union", "[unused2]", "[unused3]", "was", "renamed", "[unused4]", "[unused5]", "the", "ACT", "and", "Southern", "NSW", "Rugby", "Union", "During", "the", "off", "##-", "##sea", "##son", "[unused6]", "[SEP]", "[unused1]", "the", "name", "of", "the", "team", "[unused2]", "[unused3]", "was", "changed", "[unused4]", "[unused5]", "to", "B", "##rum", "##bies", "Rugby", "[unused6]", "[SEP]"]]}

input 76:  {"source": "Each of the Matoran brought their Toa stone and met each other at the Great Temple .\n"}
prediction:  {"predictions": [[1, 2994, 1104, 1103, 25702, 15186, 2, 3, 1814, 4, 5, 1147, 1706, 1161, 2576, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2994, 1104, 1103, 25702, 15186, 2, 3, 1899, 4, 5, 1296, 1168, 1120, 1103, 2038, 4407, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012470189481973648, -0.0020596792455762625, -0.038544654846191406, -0.038544654846191406, -0.038544654846191406, -0.038544654846191406, -0.038544654846191406, -0.038544654846191406, -0.038544654846191406, -0.038544654846191406], "metadata": {"source_tokens": ["Each", "of", "the", "Mat", "##oran", "brought", "their", "To", "##a", "stone", "and", "met", "each", "other", "at", "the", "Great", "Temple", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Each", "of", "the", "Mat", "##oran", "[unused2]", "[unused3]", "brought", "[unused4]", "[unused5]", "their", "To", "##a", "stone", "[unused6]", "[SEP]", "[unused1]", "Each", "of", "the", "Mat", "##oran", "[unused2]", "[unused3]", "met", "[unused4]", "[unused5]", "each", "other", "at", "the", "Great", "Temple", "[unused6]", "[SEP]"]]}

input 77:  {"source": "Each time Cluemaster escapes or starts some new plan , Stephanie dons her costume again .\n"}
prediction:  {"predictions": [[1, 11952, 2, 3, 1274, 1116, 4, 5, 1123, 10220, 1254, 2994, 1159, 140, 19224, 6532, 13481, 1137, 3816, 1199, 1207, 2197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 140, 19224, 6532, 2, 3, 13481, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006100734230130911, -0.028919219970703125, -0.07487773895263672, -0.07603597640991211, -0.07603597640991211, -0.07603597640991211, -0.07603597640991211, -0.07603597640991211, -0.07603597640991211, -0.07603597640991211], "metadata": {"source_tokens": ["Each", "time", "C", "##lue", "##master", "escapes", "or", "starts", "some", "new", "plan", ",", "Stephanie", "don", "##s", "her", "costume", "again", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Stephanie", "[unused2]", "[unused3]", "don", "##s", "[unused4]", "[unused5]", "her", "costume", "again", "Each", "time", "C", "##lue", "##master", "escapes", "or", "starts", "some", "new", "plan", "[unused6]", "[SEP]", "[unused1]", "C", "##lue", "##master", "[unused2]", "[unused3]", "escapes", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 78:  {"source": "Erotica and pornography involving sex between women have been predominantly produced by men for a male and female audience .\n"}
prediction:  {"predictions": [[1, 142, 10595, 4578, 1105, 22912, 2, 3, 5336, 4, 5, 2673, 1206, 1535, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 142, 10595, 4578, 1105, 22912, 2, 3, 1138, 1151, 8941, 1666, 4, 5, 1118, 1441, 1111, 170, 2581, 1105, 2130, 3703, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.055249571800231934, -0.011849895119667053, -0.0219879150390625, -0.021996021270751953, -0.021996021270751953, -0.021996021270751953, -0.021996021270751953, -0.021996021270751953, -0.021996021270751953, -0.021996021270751953], "metadata": {"source_tokens": ["E", "##rot", "##ica", "and", "pornography", "involving", "sex", "between", "women", "have", "been", "predominantly", "produced", "by", "men", "for", "a", "male", "and", "female", "audience", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "E", "##rot", "##ica", "and", "pornography", "[unused2]", "[unused3]", "involving", "[unused4]", "[unused5]", "sex", "between", "women", "[unused6]", "[SEP]", "[unused1]", "E", "##rot", "##ica", "and", "pornography", "[unused2]", "[unused3]", "have", "been", "predominantly", "produced", "[unused4]", "[unused5]", "by", "men", "for", "a", "male", "and", "female", "audience", "[unused6]", "[SEP]"]]}

input 79:  {"source": "Failure to perform the duty could lead to prosecution at law and re-enslavement .\n"}
prediction:  {"predictions": [[1, 143, 11922, 3313, 1106, 3870, 1103, 4019, 2, 3, 1180, 1730, 4, 5, 1106, 12369, 1120, 1644, 1105, 1231, 28137, 5026, 9516, 14529, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0003660642250906676, -0.03785896301269531, -0.037831783294677734, -0.037831783294677734, -0.037831783294677734, -0.037831783294677734, -0.037831783294677734, -0.037831783294677734, -0.037831783294677734, -0.037831783294677734], "metadata": {"source_tokens": ["F", "##ail", "##ure", "to", "perform", "the", "duty", "could", "lead", "to", "prosecution", "at", "law", "and", "re", "##-", "##ens", "##lav", "##ement", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "F", "##ail", "##ure", "to", "perform", "the", "duty", "[unused2]", "[unused3]", "could", "lead", "[unused4]", "[unused5]", "to", "prosecution", "at", "law", "and", "re", "##-", "##ens", "##lav", "##ement", "[unused6]", "[SEP]"]]}

input 80:  {"source": "Falun Gong 's teachings are compiled from Li 's lectures , and Li holds definitional power in that belief system .\n"}
prediction:  {"predictions": [[1, 5255, 2, 3, 3486, 4, 5, 5754, 1348, 1540, 1107, 1115, 6369, 1449, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 143, 1348, 3488, 23703, 112, 1116, 12815, 2, 3, 1132, 9064, 4, 5, 1121, 5255, 112, 1116, 9548, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04250778630375862, -0.00037834190879948437, -0.0044803619384765625, -0.0045146942138671875, -0.0045146942138671875, -0.0045146942138671875, -0.0045146942138671875, -0.0045146942138671875, -0.0045146942138671875, -0.0045146942138671875], "metadata": {"source_tokens": ["F", "##al", "##un", "Gong", "'", "##s", "teachings", "are", "compiled", "from", "Li", "'", "##s", "lectures", ",", "and", "Li", "holds", "definition", "##al", "power", "in", "that", "belief", "system", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Li", "[unused2]", "[unused3]", "holds", "[unused4]", "[unused5]", "definition", "##al", "power", "in", "that", "belief", "system", "[unused6]", "[SEP]", "[unused1]", "F", "##al", "##un", "Gong", "'", "##s", "teachings", "[unused2]", "[unused3]", "are", "compiled", "[unused4]", "[unused5]", "from", "Li", "'", "##s", "lectures", "[unused6]", "[SEP]"]]}

input 81:  {"source": "Fans reacted to the news of the suspension by canceling their XM Radio subscriptions , with some fans even going as far as smashing their XM units .\n"}
prediction:  {"predictions": [[1, 16061, 1116, 2, 3, 15510, 4, 5, 1106, 1103, 2371, 1104, 1103, 8605, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16061, 1116, 2, 3, 15510, 4, 5, 1106, 1103, 2371, 1104, 1103, 8605, 1118, 19722, 1158, 1147, 161, 2107, 2664, 16759, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1199, 3899, 2, 3, 1256, 1280, 4, 5, 1112, 1677, 1112, 24881, 1158, 1147, 161, 2107, 2338, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16061, 1116, 2, 3, 15510, 4, 5, 1106, 1103, 2371, 1104, 1103, 8605, 1114, 1199, 3899, 1256, 1280, 1112, 1677, 1112, 24881, 1158, 1147, 161, 2107, 2338, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16061, 1116, 2, 3, 15510, 4, 5, 1106, 1103, 2371, 1104, 1103, 8605, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.042449526488780975, -0.10206454992294312, -0.032709408551454544, -0.04083162546157837, -0.0844670832157135, -0.21193170547485352, -0.2120882272720337, -0.2120882272720337, -0.2120882272720337, -0.2120882272720337], "metadata": {"source_tokens": ["Fan", "##s", "reacted", "to", "the", "news", "of", "the", "suspension", "by", "cancel", "##ing", "their", "X", "##M", "Radio", "subscription", "##s", ",", "with", "some", "fans", "even", "going", "as", "far", "as", "smash", "##ing", "their", "X", "##M", "units", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Fan", "##s", "[unused2]", "[unused3]", "reacted", "[unused4]", "[unused5]", "to", "the", "news", "of", "the", "suspension", "[unused6]", "[SEP]", "[unused1]", "Fan", "##s", "[unused2]", "[unused3]", "reacted", "[unused4]", "[unused5]", "to", "the", "news", "of", "the", "suspension", "by", "cancel", "##ing", "their", "X", "##M", "Radio", "subscription", "##s", "[unused6]", "[SEP]", "[unused1]", "some", "fans", "[unused2]", "[unused3]", "even", "going", "[unused4]", "[unused5]", "as", "far", "as", "smash", "##ing", "their", "X", "##M", "units", "[unused6]", "[SEP]", "[unused1]", "Fan", "##s", "[unused2]", "[unused3]", "reacted", "[unused4]", "[unused5]", "to", "the", "news", "of", "the", "suspension", "with", "some", "fans", "even", "going", "as", "far", "as", "smash", "##ing", "their", "X", "##M", "units", "[unused6]", "[SEP]", "[unused1]", "Fan", "##s", "[unused2]", "[unused3]", "reacted", "[unused4]", "[unused5]", "to", "the", "news", "of", "the", "suspension", "[unused6]", "[SEP]"]]}

input 82:  {"source": "From 1909 to 1912 , the Miami Canal was dug , bypassing the rapids at the head of the North Fork .\n"}
prediction:  {"predictions": [[1, 1103, 4916, 6327, 2, 3, 1108, 8423, 4, 5, 1622, 4818, 1106, 4080, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4916, 6327, 2, 3, 13981, 1158, 4, 5, 1103, 6099, 1116, 1120, 1103, 1246, 1104, 1103, 1456, 16384, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02363617718219757, -0.025586022064089775, -0.07619524002075195, -0.07619500160217285, -0.07619500160217285, -0.07619500160217285, -0.07619500160217285, -0.07619500160217285, -0.07619500160217285, -0.07619500160217285], "metadata": {"source_tokens": ["From", "1909", "to", "1912", ",", "the", "Miami", "Canal", "was", "dug", ",", "bypass", "##ing", "the", "rapid", "##s", "at", "the", "head", "of", "the", "North", "Fork", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Miami", "Canal", "[unused2]", "[unused3]", "was", "dug", "[unused4]", "[unused5]", "From", "1909", "to", "1912", "[unused6]", "[SEP]", "[unused1]", "the", "Miami", "Canal", "[unused2]", "[unused3]", "bypass", "##ing", "[unused4]", "[unused5]", "the", "rapid", "##s", "at", "the", "head", "of", "the", "North", "Fork", "[unused6]", "[SEP]"]]}

input 83:  {"source": "From the start of the first semester of 2010 , the University banned smoking on any of its property , including inside and outside buildings in areas that were once designated as smoking areas .\n"}
prediction:  {"predictions": [[1, 1877, 2, 3, 1127, 3574, 4, 5, 1112, 9987, 1877, 1517, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1239, 2, 3, 7548, 4, 5, 9987, 1113, 1251, 1104, 1157, 2400, 117, 1259, 1656, 1105, 1796, 2275, 1107, 1877, 1622, 1103, 1838, 1104, 1103, 1148, 14594, 1104, 1333, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1239, 2, 3, 7548, 4, 5, 9987, 1113, 1251, 1104, 1157, 2400, 1259, 1656, 1105, 1796, 2275, 1107, 1877, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04315042495727539, -0.040187444537878036, -0.0959734097123146, -0.279266357421875, -0.26302027702331543, -0.26302027702331543, -0.26302027702331543, -0.26302027702331543, -0.26302027702331543, -0.26302027702331543], "metadata": {"source_tokens": ["From", "the", "start", "of", "the", "first", "semester", "of", "2010", ",", "the", "University", "banned", "smoking", "on", "any", "of", "its", "property", ",", "including", "inside", "and", "outside", "buildings", "in", "areas", "that", "were", "once", "designated", "as", "smoking", "areas", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "areas", "[unused2]", "[unused3]", "were", "designated", "[unused4]", "[unused5]", "as", "smoking", "areas", "once", "[unused6]", "[SEP]", "[unused1]", "the", "University", "[unused2]", "[unused3]", "banned", "[unused4]", "[unused5]", "smoking", "on", "any", "of", "its", "property", ",", "including", "inside", "and", "outside", "buildings", "in", "areas", "From", "the", "start", "of", "the", "first", "semester", "of", "2010", "[unused6]", "[SEP]", "[unused1]", "the", "University", "[unused2]", "[unused3]", "banned", "[unused4]", "[unused5]", "smoking", "on", "any", "of", "its", "property", "including", "inside", "and", "outside", "buildings", "in", "areas", "[unused6]", "[SEP]"]]}

input 84:  {"source": "Furthermore , knowledge and interest pertaining to the event , as well as the level of importance , contribute to the frequency of rehearsal .\n"}
prediction:  {"predictions": [[1, 3044, 1105, 2199, 22383, 1106, 1103, 1856, 117, 1112, 1218, 1112, 1103, 1634, 1104, 4495, 2, 3, 8681, 4, 5, 1106, 1103, 5625, 1104, 20762, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3044, 1105, 2199, 2, 3, 22383, 4, 5, 1106, 1103, 1856, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006352982483804226, -0.02360491268336773, -0.022002220153808594, -0.022002220153808594, -0.022002220153808594, -0.022002220153808594, -0.022002220153808594, -0.022002220153808594, -0.022002220153808594, -0.022002220153808594], "metadata": {"source_tokens": ["Furthermore", ",", "knowledge", "and", "interest", "pertaining", "to", "the", "event", ",", "as", "well", "as", "the", "level", "of", "importance", ",", "contribute", "to", "the", "frequency", "of", "rehearsal", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "knowledge", "and", "interest", "pertaining", "to", "the", "event", ",", "as", "well", "as", "the", "level", "of", "importance", "[unused2]", "[unused3]", "contribute", "[unused4]", "[unused5]", "to", "the", "frequency", "of", "rehearsal", "[unused6]", "[SEP]", "[unused1]", "knowledge", "and", "interest", "[unused2]", "[unused3]", "pertaining", "[unused4]", "[unused5]", "to", "the", "event", "[unused6]", "[SEP]"]]}

input 85:  {"source": "Gameplay is very basic ; the player must shoot constantly at a continual stream of enemies in order to reach the end of each level .\n"}
prediction:  {"predictions": [[1, 3497, 11044, 2, 3, 1110, 4, 5, 1304, 3501, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1591, 2, 3, 1538, 5211, 4, 5, 7480, 1120, 170, 14255, 6105, 4746, 5118, 1104, 6380, 1107, 1546, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1591, 2, 3, 1538, 5211, 4, 5, 7480, 1120, 170, 14255, 6105, 4746, 5118, 1104, 6380, 1107, 1546, 1106, 2519, 1103, 1322, 1104, 1296, 1634, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008219500072300434, -0.011862033978104591, -0.03896159306168556, -0.0847787857055664, -0.08906269073486328, -0.08906269073486328, -0.08906269073486328, -0.08906269073486328, -0.08906269073486328, -0.08906269073486328], "metadata": {"source_tokens": ["Game", "##play", "is", "very", "basic", ";", "the", "player", "must", "shoot", "constantly", "at", "a", "con", "##tin", "##ual", "stream", "of", "enemies", "in", "order", "to", "reach", "the", "end", "of", "each", "level", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Game", "##play", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "very", "basic", "[unused6]", "[SEP]", "[unused1]", "the", "player", "[unused2]", "[unused3]", "must", "shoot", "[unused4]", "[unused5]", "constantly", "at", "a", "con", "##tin", "##ual", "stream", "of", "enemies", "in", "order", "[unused6]", "[SEP]", "[unused1]", "the", "player", "[unused2]", "[unused3]", "must", "shoot", "[unused4]", "[unused5]", "constantly", "at", "a", "con", "##tin", "##ual", "stream", "of", "enemies", "in", "order", "to", "reach", "the", "end", "of", "each", "level", "[unused6]", "[SEP]"]]}

input 86:  {"source": "Gavin Hood is a South African filmmaker , screenwriter , producer and actor , best known for writing and directing the Academy Award-winning Foreign Language Film `` Tsotsi '' .\n"}
prediction:  {"predictions": [[1, 9152, 10776, 2, 3, 1110, 4, 5, 170, 1375, 2170, 13140, 117, 11625, 117, 2451, 1105, 2811, 117, 1436, 1227, 1111, 2269, 1105, 10404, 1103, 2127, 1698, 28137, 7445, 3381, 4201, 6828, 2352, 169, 28152, 157, 7301, 2145, 1182, 112, 28131, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1375, 2170, 13140, 117, 11625, 117, 2451, 1105, 2811, 2, 3, 1436, 1227, 4, 5, 1111, 2269, 1105, 10404, 1103, 2127, 1698, 28137, 7445, 3381, 4201, 6828, 2352, 169, 28152, 157, 7301, 2145, 1182, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01594146527349949, -0.049829889088869095, -0.07657146453857422, -0.07657098770141602, -0.07657098770141602, -0.07657098770141602, -0.07657098770141602, -0.07657098770141602, -0.07657098770141602, -0.07657098770141602], "metadata": {"source_tokens": ["Gavin", "Hood", "is", "a", "South", "African", "filmmaker", ",", "screenwriter", ",", "producer", "and", "actor", ",", "best", "known", "for", "writing", "and", "directing", "the", "Academy", "Award", "##-", "##win", "##ning", "Foreign", "Language", "Film", "`", "##`", "T", "##so", "##ts", "##i", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Gavin", "Hood", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "South", "African", "filmmaker", ",", "screenwriter", ",", "producer", "and", "actor", ",", "best", "known", "for", "writing", "and", "directing", "the", "Academy", "Award", "##-", "##win", "##ning", "Foreign", "Language", "Film", "`", "##`", "T", "##so", "##ts", "##i", "'", "##'", "[unused6]", "[SEP]", "[unused1]", "a", "South", "African", "filmmaker", ",", "screenwriter", ",", "producer", "and", "actor", "[unused2]", "[unused3]", "best", "known", "[unused4]", "[unused5]", "for", "writing", "and", "directing", "the", "Academy", "Award", "##-", "##win", "##ning", "Foreign", "Language", "Film", "`", "##`", "T", "##so", "##ts", "##i", "[unused6]", "[SEP]"]]}

input 87:  {"source": "George Bluth Sr. , patriarch of the Bluth family , is the founder and former CEO of the Bluth Company which markets and builds mini-mansions among many other activities .\n"}
prediction:  {"predictions": [[1, 1667, 15223, 1582, 8731, 2, 3, 1110, 4, 5, 1103, 3249, 1105, 1393, 5058, 1104, 1103, 15223, 1582, 1881, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 15223, 1582, 1881, 2, 3, 5809, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1667, 15223, 1582, 8731, 28138, 2, 3, 1110, 27797, 1104, 4, 5, 1103, 15223, 1582, 1266, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 15223, 1582, 1881, 2, 3, 17850, 4, 5, 8715, 28137, 14761, 5266, 1621, 1242, 1168, 2619, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02256879396736622, -0.10088244080543518, -0.09393403679132462, -0.04159446805715561, -0.032208919525146484, -0.03220868110656738, -0.03220868110656738, -0.03220868110656738, -0.03220868110656738, -0.03220868110656738], "metadata": {"source_tokens": ["George", "Blu", "##th", "Sr", "##.", ",", "patriarch", "of", "the", "Blu", "##th", "family", ",", "is", "the", "founder", "and", "former", "CEO", "of", "the", "Blu", "##th", "Company", "which", "markets", "and", "builds", "mini", "##-", "##mans", "##ions", "among", "many", "other", "activities", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "George", "Blu", "##th", "Sr", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "founder", "and", "former", "CEO", "of", "the", "Blu", "##th", "Company", "[unused6]", "[SEP]", "[unused1]", "the", "Blu", "##th", "Company", "[unused2]", "[unused3]", "markets", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "George", "Blu", "##th", "Sr", "##.", "[unused2]", "[unused3]", "is", "patriarch", "of", "[unused4]", "[unused5]", "the", "Blu", "##th", "family", "[unused6]", "[SEP]", "[unused1]", "the", "Blu", "##th", "Company", "[unused2]", "[unused3]", "builds", "[unused4]", "[unused5]", "mini", "##-", "##mans", "##ions", "among", "many", "other", "activities", "[unused6]", "[SEP]"]]}

input 88:  {"source": "Godzilla and Battra battled on the ocean floor , until they caused a rift to open between tectonic plates .\n"}
prediction:  {"predictions": [[1, 1875, 20366, 1105, 21928, 4487, 2, 3, 21600, 4, 5, 1113, 1103, 5969, 1837, 1235, 1152, 2416, 170, 25414, 1106, 1501, 1206, 21359, 26176, 1596, 7463, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 2416, 4, 5, 170, 25414, 1106, 1501, 1206, 21359, 26176, 1596, 7463, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00403831759467721, -0.004339860752224922, -0.039102792739868164, -0.04054546356201172, -0.04054546356201172, -0.04054546356201172, -0.04054546356201172, -0.04054546356201172, -0.04054546356201172, -0.04054546356201172], "metadata": {"source_tokens": ["God", "##zilla", "and", "Bat", "##tra", "battled", "on", "the", "ocean", "floor", ",", "until", "they", "caused", "a", "rift", "to", "open", "between", "te", "##cton", "##ic", "plates", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "God", "##zilla", "and", "Bat", "##tra", "[unused2]", "[unused3]", "battled", "[unused4]", "[unused5]", "on", "the", "ocean", "floor", "until", "they", "caused", "a", "rift", "to", "open", "between", "te", "##cton", "##ic", "plates", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "caused", "[unused4]", "[unused5]", "a", "rift", "to", "open", "between", "te", "##cton", "##ic", "plates", "[unused6]", "[SEP]"]]}

input 89:  {"source": "Good 1H NMR spectra can be acquired with 16 repeats , which takes only minutes .\n"}
prediction:  {"predictions": [[1, 1479, 19811, 2, 3, 2274, 4, 5, 1178, 1904, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2750, 122, 3048, 151, 21148, 188, 26426, 1611, 2, 3, 1169, 1129, 2888, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006277481559664011, -0.015061642974615097, -0.020955562591552734, -0.021161556243896484, -0.021161556243896484, -0.021161556243896484, -0.021161556243896484, -0.021161556243896484, -0.021161556243896484, -0.021161556243896484], "metadata": {"source_tokens": ["Good", "1", "##H", "N", "##MR", "s", "##pect", "##ra", "can", "be", "acquired", "with", "16", "repeats", ",", "which", "takes", "only", "minutes", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "16", "repeats", "[unused2]", "[unused3]", "takes", "[unused4]", "[unused5]", "only", "minutes", "[unused6]", "[SEP]", "[unused1]", "Good", "1", "##H", "N", "##MR", "s", "##pect", "##ra", "[unused2]", "[unused3]", "can", "be", "acquired", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 90:  {"source": "HTB 's aim is for an Alpha course to be accessible to anyone who would like to attend the course , and in this way HTB seeks to spread the teachings of Christianity .\n"}
prediction:  {"predictions": [[1, 145, 1942, 2064, 112, 1116, 6457, 2, 3, 1110, 4, 5, 1111, 1126, 8461, 1736, 1106, 1129, 7385, 1106, 2256, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 145, 1942, 2064, 2, 3, 11053, 4, 5, 1106, 2819, 1103, 12815, 1104, 7522, 1107, 1142, 1236, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2256, 2, 3, 1156, 1176, 4, 5, 1106, 4739, 1103, 1736, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.041283342987298965, -0.06983436644077301, -0.05778080224990845, -0.2203119993209839, -0.24423182010650635, -0.24423182010650635, -0.24423182010650635, -0.24423182010650635, -0.24423182010650635, -0.24423182010650635], "metadata": {"source_tokens": ["H", "##T", "##B", "'", "##s", "aim", "is", "for", "an", "Alpha", "course", "to", "be", "accessible", "to", "anyone", "who", "would", "like", "to", "attend", "the", "course", ",", "and", "in", "this", "way", "H", "##T", "##B", "seeks", "to", "spread", "the", "teachings", "of", "Christianity", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "H", "##T", "##B", "'", "##s", "aim", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "for", "an", "Alpha", "course", "to", "be", "accessible", "to", "anyone", "[unused6]", "[SEP]", "[unused1]", "H", "##T", "##B", "[unused2]", "[unused3]", "seeks", "[unused4]", "[unused5]", "to", "spread", "the", "teachings", "of", "Christianity", "in", "this", "way", "[unused6]", "[SEP]", "[unused1]", "anyone", "[unused2]", "[unused3]", "would", "like", "[unused4]", "[unused5]", "to", "attend", "the", "course", "[unused6]", "[SEP]"]]}

input 91:  {"source": "Hapoel Lod played in the top division during the 1960s and 1980s , and won the State Cup in 1984 .\n"}
prediction:  {"predictions": [[1, 27227, 10605, 1181, 2, 3, 1307, 4, 5, 1107, 1103, 1499, 2417, 1219, 1103, 3266, 1105, 3011, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 27227, 10605, 1181, 2, 3, 1281, 4, 5, 1103, 1426, 1635, 1107, 2219, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02011500671505928, -0.002085357904434204, -0.04031729698181152, -0.07626938819885254, -0.07626938819885254, -0.07626938819885254, -0.07626938819885254, -0.07626938819885254, -0.07626938819885254, -0.07626938819885254], "metadata": {"source_tokens": ["Hapoel", "Lo", "##d", "played", "in", "the", "top", "division", "during", "the", "1960s", "and", "1980s", ",", "and", "won", "the", "State", "Cup", "in", "1984", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hapoel", "Lo", "##d", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "in", "the", "top", "division", "during", "the", "1960s", "and", "1980s", "[unused6]", "[SEP]", "[unused1]", "Hapoel", "Lo", "##d", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "the", "State", "Cup", "in", "1984", "[unused6]", "[SEP]"]]}

input 92:  {"source": "Having been directed to found a monastery of his order in the United States in 1873 , Fr .\n"}
prediction:  {"predictions": [[1, 5823, 1151, 2002, 1106, 1276, 170, 7197, 1104, 1117, 1546, 1107, 1103, 1244, 1311, 1107, 7110, 2, 3, 1110, 4, 5, 13359, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05533619225025177, -0.04998207092285156, -0.0745847225189209, -0.0745847225189209, -0.0745847225189209, -0.0745847225189209, -0.0745847225189209, -0.0745847225189209, -0.0745847225189209, -0.0745847225189209], "metadata": {"source_tokens": ["Having", "been", "directed", "to", "found", "a", "monastery", "of", "his", "order", "in", "the", "United", "States", "in", "1873", ",", "Fr", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Having", "been", "directed", "to", "found", "a", "monastery", "of", "his", "order", "in", "the", "United", "States", "in", "1873", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Fr", "[unused6]", "[SEP]"]]}

input 93:  {"source": "Hawker Pacific Aerospace is a MRO-Service company which offers landing gear and hydraulic MRO services for all major aircraft types .\n"}
prediction:  {"predictions": [[1, 28064, 1197, 2662, 19417, 2, 3, 1110, 4, 5, 170, 25827, 2346, 28137, 1708, 1200, 14301, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 25827, 2346, 28137, 1708, 1200, 14301, 1419, 2, 3, 3272, 4, 5, 4636, 6990, 1105, 16872, 25827, 2346, 1826, 1111, 1155, 1558, 2163, 3322, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00266304612159729, -0.0021683189552277327, -0.022017955780029297, -0.022017478942871094, -0.022017478942871094, -0.022017478942871094, -0.022017478942871094, -0.022017478942871094, -0.022017478942871094, -0.022017478942871094], "metadata": {"source_tokens": ["Hawke", "##r", "Pacific", "Aerospace", "is", "a", "MR", "##O", "##-", "##S", "##er", "##vice", "company", "which", "offers", "landing", "gear", "and", "hydraulic", "MR", "##O", "services", "for", "all", "major", "aircraft", "types", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hawke", "##r", "Pacific", "Aerospace", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "MR", "##O", "##-", "##S", "##er", "##vice", "company", "[unused6]", "[SEP]", "[unused1]", "a", "MR", "##O", "##-", "##S", "##er", "##vice", "company", "[unused2]", "[unused3]", "offers", "[unused4]", "[unused5]", "landing", "gear", "and", "hydraulic", "MR", "##O", "services", "for", "all", "major", "aircraft", "types", "[unused6]", "[SEP]"]]}

input 94:  {"source": "He also possesses enhanced senses and can track people for great distances over open terrain and his feet are sensitive enough to detect electronic signals through solid walls and floors .\n"}
prediction:  {"predictions": [[1, 1117, 1623, 2, 3, 1132, 4, 5, 7246, 1536, 1106, 11552, 4828, 7981, 1194, 4600, 2928, 1105, 7849, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 15614, 4, 5, 9927, 9439, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1169, 1854, 4, 5, 1234, 1111, 1632, 12424, 1166, 1501, 9260, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03135985508561134, -0.05868640914559364, -0.03167511522769928, -0.1235203742980957, -0.1234731674194336, -0.1234731674194336, -0.1234731674194336, -0.1234731674194336, -0.1234731674194336, -0.1234731674194336], "metadata": {"source_tokens": ["He", "also", "possesses", "enhanced", "senses", "and", "can", "track", "people", "for", "great", "distances", "over", "open", "terrain", "and", "his", "feet", "are", "sensitive", "enough", "to", "detect", "electronic", "signals", "through", "solid", "walls", "and", "floors", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "his", "feet", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "sensitive", "enough", "to", "detect", "electronic", "signals", "through", "solid", "walls", "and", "floors", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "possesses", "[unused4]", "[unused5]", "enhanced", "senses", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "can", "track", "[unused4]", "[unused5]", "people", "for", "great", "distances", "over", "open", "terrain", "[unused6]", "[SEP]"]]}

input 95:  {"source": "He also took 124 wickets , with 7 for 39 and 6 for 44 against Sargodha in 1962-63 his best bowling figures .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1261, 4, 5, 13743, 10267, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1261, 4, 5, 13743, 10267, 1114, 128, 1111, 3614, 1105, 127, 1111, 3140, 1222, 17784, 17161, 14016, 1107, 2832, 28137, 1545, 1495, 1117, 1436, 11518, 3736, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.024223674088716507, -0.023972447961568832, -0.07632613182067871, -0.07632207870483398, -0.07632207870483398, -0.07632207870483398, -0.07632207870483398, -0.07632207870483398, -0.07632207870483398, -0.07632207870483398], "metadata": {"source_tokens": ["He", "also", "took", "124", "wickets", ",", "with", "7", "for", "39", "and", "6", "for", "44", "against", "Sa", "##rgo", "##dha", "in", "1962", "##-", "##6", "##3", "his", "best", "bowling", "figures", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "124", "wickets", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "124", "wickets", "with", "7", "for", "39", "and", "6", "for", "44", "against", "Sa", "##rgo", "##dha", "in", "1962", "##-", "##6", "##3", "his", "best", "bowling", "figures", "[unused6]", "[SEP]"]]}

input 96:  {"source": "He appeared in that game alongside his Arsenal midfield colleague Brian Marwood , who had joined them from Sheffield Wednesday eight months earlier .\n"}
prediction:  {"predictions": [[1, 1117, 10503, 26599, 11864, 2, 3, 1125, 1688, 4, 5, 1172, 1121, 8139, 9031, 2022, 1808, 2206, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1691, 4, 5, 1107, 1115, 1342, 3338, 1117, 10503, 26599, 11864, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04271988943219185, -0.013985157012939453, -0.17651581764221191, -0.17649197578430176, -0.17649197578430176, -0.17649197578430176, -0.17649197578430176, -0.17649197578430176, -0.17649197578430176, -0.17649197578430176], "metadata": {"source_tokens": ["He", "appeared", "in", "that", "game", "alongside", "his", "Arsenal", "midfield", "colleague", "Brian", "Mar", "##wood", ",", "who", "had", "joined", "them", "from", "Sheffield", "Wednesday", "eight", "months", "earlier", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "his", "Arsenal", "midfield", "colleague", "[unused2]", "[unused3]", "had", "joined", "[unused4]", "[unused5]", "them", "from", "Sheffield", "Wednesday", "eight", "months", "earlier", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "in", "that", "game", "alongside", "his", "Arsenal", "midfield", "colleague", "[unused6]", "[SEP]"]]}

input 97:  {"source": "He defines Wild Cards as ` Low Probability , High Impact events that , were they to occur , would severely impact the human condition ' .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 12028, 4, 5, 5469, 10103, 1116, 1112, 169, 8274, 5096, 2822, 5474, 117, 1693, 13788, 1958, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1693, 13788, 1958, 2, 3, 1156, 8669, 3772, 4, 5, 1103, 1769, 3879, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1106, 4467, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.040679849684238434, -0.12006466835737228, -0.09020320326089859, -0.1243288516998291, -0.12625741958618164, -0.12625741958618164, -0.12625741958618164, -0.12625741958618164, -0.12625741958618164, -0.12625741958618164], "metadata": {"source_tokens": ["He", "defines", "Wild", "Card", "##s", "as", "`", "Low", "Pro", "##ba", "##bility", ",", "High", "Impact", "events", "that", ",", "were", "they", "to", "occur", ",", "would", "severely", "impact", "the", "human", "condition", "'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "defines", "[unused4]", "[unused5]", "Wild", "Card", "##s", "as", "`", "Low", "Pro", "##ba", "##bility", ",", "High", "Impact", "events", "[unused6]", "[SEP]", "[unused1]", "High", "Impact", "events", "[unused2]", "[unused3]", "would", "severely", "impact", "[unused4]", "[unused5]", "the", "human", "condition", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "to", "occur", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 98:  {"source": "He finds himself in a desert as a group of Neo Arcadians surround him , ending the game .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 4090, 4, 5, 1471, 1107, 170, 6941, 1112, 170, 1372, 1104, 14521, 18647, 21403, 2316, 16858, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 4090, 4, 5, 1471, 1107, 170, 6941, 1112, 170, 1372, 1104, 14521, 18647, 21403, 2316, 16858, 1140, 3830, 1103, 1342, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00783509761095047, -0.10483091324567795, -0.12456870079040527, -0.14641404151916504, -0.14641404151916504, -0.14641404151916504, -0.14641404151916504, -0.14641404151916504, -0.14641404151916504, -0.14641404151916504], "metadata": {"source_tokens": ["He", "finds", "himself", "in", "a", "desert", "as", "a", "group", "of", "Neo", "Arc", "##adia", "##ns", "surround", "him", ",", "ending", "the", "game", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "finds", "[unused4]", "[unused5]", "himself", "in", "a", "desert", "as", "a", "group", "of", "Neo", "Arc", "##adia", "##ns", "surround", "him", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "finds", "[unused4]", "[unused5]", "himself", "in", "a", "desert", "as", "a", "group", "of", "Neo", "Arc", "##adia", "##ns", "surround", "him", "ending", "the", "game", "[unused6]", "[SEP]"]]}

input 99:  {"source": "He had spent 11 years in jail despite having been acquitted twice .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1125, 2097, 4, 5, 1429, 1201, 1107, 7237, 2693, 1515, 1151, 20183, 3059, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012380198575556278, -0.004374504089355469, -0.006001949310302734, -0.006001949310302734, -0.006001949310302734, -0.006001949310302734, -0.006001949310302734, -0.006001949310302734, -0.006001949310302734, -0.006001949310302734], "metadata": {"source_tokens": ["He", "had", "spent", "11", "years", "in", "jail", "despite", "having", "been", "acquitted", "twice", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "had", "spent", "[unused4]", "[unused5]", "11", "years", "in", "jail", "despite", "having", "been", "acquitted", "twice", "[unused6]", "[SEP]"]]}

input 100:  {"source": "He is idolized , receiving the name of `` God '' .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1110, 17642, 2200, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 4172, 4, 5, 1103, 1271, 1104, 169, 28152, 1875, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02270335517823696, -0.011644252575933933, -0.0002598762512207031, -0.0002598762512207031, -0.0002598762512207031, -0.0002598762512207031, -0.0002598762512207031, -0.0002598762512207031, -0.0002598762512207031, -0.0002598762512207031], "metadata": {"source_tokens": ["He", "is", "idol", "##ized", ",", "receiving", "the", "name", "of", "`", "##`", "God", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "is", "idol", "##ized", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "receiving", "[unused4]", "[unused5]", "the", "name", "of", "`", "##`", "God", "[unused6]", "[SEP]"]]}

input 101:  {"source": "He left his old company , V2 records , wanting to expand his career into something bigger .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1286, 4, 5, 1117, 1385, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 1385, 1419, 2, 3, 1110, 4, 5, 159, 1477, 3002, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1286, 4, 5, 1117, 1385, 1419, 5277, 1106, 7380, 1117, 1578, 1154, 1380, 6706, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0372774600982666, -0.08555863797664642, -0.06385810673236847, -0.032202720642089844, -0.0324101448059082, -0.0324101448059082, -0.0324101448059082, -0.0324101448059082, -0.0324101448059082, -0.0324101448059082], "metadata": {"source_tokens": ["He", "left", "his", "old", "company", ",", "V", "##2", "records", ",", "wanting", "to", "expand", "his", "career", "into", "something", "bigger", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "his", "old", "company", "[unused6]", "[SEP]", "[unused1]", "his", "old", "company", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "V", "##2", "records", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "his", "old", "company", "wanting", "to", "expand", "his", "career", "into", "something", "bigger", "[unused6]", "[SEP]"]]}

input 102:  {"source": "He left only a small contingent to guard the defile , and took his entire army to destroy the plain that lay ahead of Alexander 's army .\n"}
prediction:  {"predictions": [[1, 1103, 6188, 2, 3, 3191, 4, 5, 3075, 1104, 2792, 112, 1116, 2306, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1286, 4, 5, 1178, 170, 1353, 17286, 1106, 3542, 1103, 19353, 4759, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1261, 4, 5, 1117, 2072, 2306, 1106, 5535, 1103, 6188, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1286, 4, 5, 1178, 170, 1353, 17286, 1106, 3542, 1103, 19353, 4759, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017170235514640808, -0.03564288839697838, -0.023631827905774117, -0.33915507793426514, -0.11260310560464859, -0.11871027946472168, -0.12410354614257812, -0.12410354614257812, -0.12410354614257812, -0.12410354614257812], "metadata": {"source_tokens": ["He", "left", "only", "a", "small", "contingent", "to", "guard", "the", "def", "##ile", ",", "and", "took", "his", "entire", "army", "to", "destroy", "the", "plain", "that", "lay", "ahead", "of", "Alexander", "'", "##s", "army", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "plain", "[unused2]", "[unused3]", "lay", "[unused4]", "[unused5]", "ahead", "of", "Alexander", "'", "##s", "army", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "only", "a", "small", "contingent", "to", "guard", "the", "def", "##ile", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "his", "entire", "army", "to", "destroy", "the", "plain", "[unused6]", "[SEP]"]]}

input 103:  {"source": "He lodged near the hospital at 28 St Thomas 's Street in Southwark , with other medical students , including Henry Stephens who became a famous inventor and ink magnate .\n"}
prediction:  {"predictions": [[1, 1985, 15752, 2, 3, 1245, 4, 5, 170, 2505, 12989, 1105, 12816, 12477, 21772, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 22422, 4, 5, 1485, 1103, 2704, 1120, 1743, 1457, 1819, 112, 1116, 1715, 1107, 1375, 27319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 22422, 4, 5, 1485, 1103, 2704, 1114, 1168, 2657, 1651, 1259, 1985, 15752, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005215476732701063, -0.025494353845715523, -0.034342262893915176, -0.07705283164978027, -0.07705497741699219, -0.07705497741699219, -0.07705497741699219, -0.07705497741699219, -0.07705497741699219, -0.07705497741699219], "metadata": {"source_tokens": ["He", "lodged", "near", "the", "hospital", "at", "28", "St", "Thomas", "'", "##s", "Street", "in", "South", "##wark", ",", "with", "other", "medical", "students", ",", "including", "Henry", "Stephens", "who", "became", "a", "famous", "inventor", "and", "ink", "ma", "##gnate", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Henry", "Stephens", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "a", "famous", "inventor", "and", "ink", "ma", "##gnate", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "lodged", "[unused4]", "[unused5]", "near", "the", "hospital", "at", "28", "St", "Thomas", "'", "##s", "Street", "in", "South", "##wark", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "lodged", "[unused4]", "[unused5]", "near", "the", "hospital", "with", "other", "medical", "students", "including", "Henry", "Stephens", "[unused6]", "[SEP]"]]}

input 104:  {"source": "He played Perker in the 1985 adaptation of `` The Pickwick Papers '' .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1307, 4, 5, 14286, 4188, 1107, 1103, 2210, 6350, 1104, 169, 28152, 1109, 20984, 6196, 19023, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0008344433736056089, -0.000278472900390625, -0.0002827644348144531, -0.0002827644348144531, -0.0002827644348144531, -0.0002827644348144531, -0.0002827644348144531, -0.0002827644348144531, -0.0002827644348144531, -0.0002827644348144531], "metadata": {"source_tokens": ["He", "played", "Per", "##ker", "in", "the", "1985", "adaptation", "of", "`", "##`", "The", "Pick", "##wick", "Papers", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "Per", "##ker", "in", "the", "1985", "adaptation", "of", "`", "##`", "The", "Pick", "##wick", "Papers", "[unused6]", "[SEP]"]]}

input 105:  {"source": "He represented the riding of Nickel Belt in the Sudbury , Ontario area .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 2533, 4, 5, 1103, 5569, 1104, 3350, 1883, 15834, 1107, 1103, 15463, 26837, 117, 3717, 1298, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0031431803945451975, -0.0004968643188476562, -0.00045490264892578125, -0.00045490264892578125, -0.00045490264892578125, -0.00045490264892578125, -0.00045490264892578125, -0.00045490264892578125, -0.00045490264892578125, -0.00045490264892578125], "metadata": {"source_tokens": ["He", "represented", "the", "riding", "of", "Nick", "##el", "Belt", "in", "the", "Su", "##dbury", ",", "Ontario", "area", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "represented", "[unused4]", "[unused5]", "the", "riding", "of", "Nick", "##el", "Belt", "in", "the", "Su", "##dbury", ",", "Ontario", "area", "[unused6]", "[SEP]"]]}

input 106:  {"source": "He talked to McGee about using his name and received permission , which is confirmed by correspondence between McGee and his family .\n"}
prediction:  {"predictions": [[1, 6156, 2, 3, 1110, 3659, 4, 5, 1118, 12052, 1206, 24539, 1105, 1117, 1266, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 5029, 4, 5, 1106, 24539, 1164, 1606, 1117, 1271, 1105, 1460, 6156, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 5029, 4, 5, 1106, 24539, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.034415312111377716, -0.024639692157506943, -0.12181925028562546, -0.17569494247436523, -0.17571377754211426, -0.17571377754211426, -0.17571377754211426, -0.17571377754211426, -0.17571377754211426, -0.17571377754211426], "metadata": {"source_tokens": ["He", "talked", "to", "McGee", "about", "using", "his", "name", "and", "received", "permission", ",", "which", "is", "confirmed", "by", "correspondence", "between", "McGee", "and", "his", "family", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "permission", "[unused2]", "[unused3]", "is", "confirmed", "[unused4]", "[unused5]", "by", "correspondence", "between", "McGee", "and", "his", "family", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "talked", "[unused4]", "[unused5]", "to", "McGee", "about", "using", "his", "name", "and", "received", "permission", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "talked", "[unused4]", "[unused5]", "to", "McGee", "[unused6]", "[SEP]"]]}

input 107:  {"source": "He was a member of the European Convention , which drafted the text of the European Constitution that never entered into force .\n"}
prediction:  {"predictions": [[1, 1103, 1735, 5317, 2, 3, 1309, 2242, 4, 5, 1154, 2049, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1735, 5818, 2, 3, 7071, 4, 5, 1103, 3087, 1104, 1103, 1735, 5317, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1108, 4, 5, 170, 1420, 1104, 1103, 1735, 5818, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008910403586924076, -0.03676620125770569, -0.006670522503554821, -0.0027375221252441406, -0.002678394317626953, -0.002678394317626953, -0.002678394317626953, -0.002678394317626953, -0.002678394317626953, -0.002678394317626953], "metadata": {"source_tokens": ["He", "was", "a", "member", "of", "the", "European", "Convention", ",", "which", "drafted", "the", "text", "of", "the", "European", "Constitution", "that", "never", "entered", "into", "force", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "European", "Constitution", "[unused2]", "[unused3]", "never", "entered", "[unused4]", "[unused5]", "into", "force", "[unused6]", "[SEP]", "[unused1]", "the", "European", "Convention", "[unused2]", "[unused3]", "drafted", "[unused4]", "[unused5]", "the", "text", "of", "the", "European", "Constitution", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "member", "of", "the", "European", "Convention", "[unused6]", "[SEP]"]]}

input 108:  {"source": "He was buried in the Abbey of the Psalms mausoleum at the Hollywood Forever Cemetery .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1108, 3126, 4, 5, 1107, 1103, 6674, 1104, 1103, 153, 11794, 4206, 27685, 1120, 1103, 4613, 11694, 5501, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00011984507000306621, -0.0008039474487304688, -0.0008349418640136719, -0.0008349418640136719, -0.0008349418640136719, -0.0008349418640136719, -0.0008349418640136719, -0.0008349418640136719, -0.0008349418640136719, -0.0008349418640136719], "metadata": {"source_tokens": ["He", "was", "buried", "in", "the", "Abbey", "of", "the", "P", "##sal", "##ms", "mausoleum", "at", "the", "Hollywood", "Forever", "Cemetery", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "was", "buried", "[unused4]", "[unused5]", "in", "the", "Abbey", "of", "the", "P", "##sal", "##ms", "mausoleum", "at", "the", "Hollywood", "Forever", "Cemetery", "[unused6]", "[SEP]"]]}

input 109:  {"source": "He was subsequently reprieved for a month , and then again for a week .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1108, 1231, 1643, 27055, 1181, 4, 5, 1111, 170, 2370, 2886, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07077442854642868, -0.07596850395202637, -0.1514139175415039, -0.1514139175415039, -0.1514139175415039, -0.1514139175415039, -0.1514139175415039, -0.1514139175415039, -0.1514139175415039, -0.1514139175415039], "metadata": {"source_tokens": ["He", "was", "subsequently", "re", "##p", "##rieve", "##d", "for", "a", "month", ",", "and", "then", "again", "for", "a", "week", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "was", "re", "##p", "##rieve", "##d", "[unused4]", "[unused5]", "for", "a", "month", "subsequently", "[unused6]", "[SEP]"]]}

input 110:  {"source": "Her image held aloft signifies the Earth , which `` hangs in the air '' .\n"}
prediction:  {"predictions": [[1, 1430, 3077, 1316, 2393, 18874, 2, 3, 2951, 9387, 4, 5, 1103, 2746, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2746, 2, 3, 19565, 4, 5, 1107, 1103, 1586, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03558981418609619, -0.0012571719707921147, -0.01768207550048828, -0.020841121673583984, -0.020841121673583984, -0.020841121673583984, -0.020841121673583984, -0.020841121673583984, -0.020841121673583984, -0.020841121673583984], "metadata": {"source_tokens": ["Her", "image", "held", "al", "##oft", "sign", "##ifies", "the", "Earth", ",", "which", "`", "##`", "hangs", "in", "the", "air", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Her", "image", "held", "al", "##oft", "[unused2]", "[unused3]", "sign", "##ifies", "[unused4]", "[unused5]", "the", "Earth", "[unused6]", "[SEP]", "[unused1]", "the", "Earth", "[unused2]", "[unused3]", "hangs", "[unused4]", "[unused5]", "in", "the", "air", "[unused6]", "[SEP]"]]}

input 111:  {"source": "Hilf al-Fudul was a 7th-century alliance created by various Meccans , including the Islamic prophet Muhammad , to establish fair commercial dealing .\n"}
prediction:  {"predictions": [[1, 8790, 9654, 2393, 28137, 2271, 4867, 4654, 2, 3, 1108, 4, 5, 170, 4766, 28137, 8298, 11366, 7214, 1687, 1118, 1672, 25160, 2316, 117, 1259, 1103, 4769, 20718, 6710, 117, 1106, 4586, 4652, 2595, 6705, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4766, 28137, 8298, 11366, 7214, 2, 3, 1687, 4, 5, 1118, 1672, 25160, 2316, 117, 1259, 1103, 4769, 20718, 6710, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006881986744701862, -0.027110865339636803, -0.1195840835571289, -0.11979269981384277, -0.11979269981384277, -0.11979269981384277, -0.11979269981384277, -0.11979269981384277, -0.11979269981384277, -0.11979269981384277], "metadata": {"source_tokens": ["Hi", "##lf", "al", "##-", "##F", "##ud", "##ul", "was", "a", "7th", "##-", "##cent", "##ury", "alliance", "created", "by", "various", "Mecca", "##ns", ",", "including", "the", "Islamic", "prophet", "Muhammad", ",", "to", "establish", "fair", "commercial", "dealing", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hi", "##lf", "al", "##-", "##F", "##ud", "##ul", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "7th", "##-", "##cent", "##ury", "alliance", "created", "by", "various", "Mecca", "##ns", ",", "including", "the", "Islamic", "prophet", "Muhammad", ",", "to", "establish", "fair", "commercial", "dealing", "[unused6]", "[SEP]", "[unused1]", "a", "7th", "##-", "##cent", "##ury", "alliance", "[unused2]", "[unused3]", "created", "[unused4]", "[unused5]", "by", "various", "Mecca", "##ns", ",", "including", "the", "Islamic", "prophet", "Muhammad", "[unused6]", "[SEP]"]]}

input 112:  {"source": "Historically , Aiseau was a village dedicated to agriculture , logging , but also to the industry .\n"}
prediction:  {"predictions": [[1, 19294, 24405, 2, 3, 1108, 4, 5, 170, 1491, 3256, 1106, 6487, 117, 17844, 117, 1133, 1145, 1106, 1103, 2380, 14630, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008978406898677349, -0.10210657119750977, -0.14997625350952148, -0.14997625350952148, -0.14997625350952148, -0.14997625350952148, -0.14997625350952148, -0.14997625350952148, -0.14997625350952148, -0.14997625350952148], "metadata": {"source_tokens": ["Historically", ",", "Ai", "##seau", "was", "a", "village", "dedicated", "to", "agriculture", ",", "logging", ",", "but", "also", "to", "the", "industry", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ai", "##seau", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "village", "dedicated", "to", "agriculture", ",", "logging", ",", "but", "also", "to", "the", "industry", "Historically", "[unused6]", "[SEP]"]]}

input 113:  {"source": "Hoechst 33342 and 33258 are quenched by Bromodeoxyuridine , which is commonly used to detect dividing cells .\n"}
prediction:  {"predictions": [[1, 139, 16071, 13040, 10649, 9379, 10132, 2042, 2, 3, 1110, 3337, 1215, 4, 5, 1106, 11552, 18699, 3652, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9800, 11252, 2050, 23335, 23117, 1105, 3081, 17600, 1604, 2, 3, 1132, 15027, 15986, 4, 5, 1118, 139, 16071, 13040, 10649, 9379, 10132, 2042, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.024887505918741226, -0.001381931477226317, -0.010785102844238281, -0.01064157485961914, -0.01064157485961914, -0.01064157485961914, -0.01064157485961914, -0.01064157485961914, -0.01064157485961914, -0.01064157485961914], "metadata": {"source_tokens": ["Ho", "##ech", "##st", "333", "##42", "and", "33", "##25", "##8", "are", "que", "##nched", "by", "B", "##rom", "##ode", "##ox", "##yu", "##rid", "##ine", ",", "which", "is", "commonly", "used", "to", "detect", "dividing", "cells", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "B", "##rom", "##ode", "##ox", "##yu", "##rid", "##ine", "[unused2]", "[unused3]", "is", "commonly", "used", "[unused4]", "[unused5]", "to", "detect", "dividing", "cells", "[unused6]", "[SEP]", "[unused1]", "Ho", "##ech", "##st", "333", "##42", "and", "33", "##25", "##8", "[unused2]", "[unused3]", "are", "que", "##nched", "[unused4]", "[unused5]", "by", "B", "##rom", "##ode", "##ox", "##yu", "##rid", "##ine", "[unused6]", "[SEP]"]]}

input 114:  {"source": "Hofmann was a below-average high school student , but he had many hobbies including magic , electronics , chemistry , and stamp and coin collecting .\n"}
prediction:  {"predictions": [[1, 9800, 2087, 4119, 2, 3, 1108, 4, 5, 170, 2071, 28137, 18195, 2553, 1344, 1278, 2377, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1125, 4, 5, 1242, 16358, 13834, 1905, 1259, 3974, 117, 11216, 117, 8117, 117, 1105, 13182, 1105, 9584, 9370, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.010243415832519531, -0.016432853415608406, -0.07648968696594238, -0.03220820426940918, -0.03220820426940918, -0.03220820426940918, -0.03220820426940918, -0.03220820426940918, -0.03220820426940918, -0.03220820426940918], "metadata": {"source_tokens": ["Ho", "##f", "##mann", "was", "a", "below", "##-", "##aver", "##age", "high", "school", "student", ",", "but", "he", "had", "many", "ho", "##bb", "##ies", "including", "magic", ",", "electronics", ",", "chemistry", ",", "and", "stamp", "and", "coin", "collecting", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ho", "##f", "##mann", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "below", "##-", "##aver", "##age", "high", "school", "student", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "many", "ho", "##bb", "##ies", "including", "magic", ",", "electronics", ",", "chemistry", ",", "and", "stamp", "and", "coin", "collecting", "[unused6]", "[SEP]"]]}

input 115:  {"source": "However , after pressure campaigns from various human rights groups , BAE Systems recently stated it no longer produces land mines or cluster bombs .\n"}
prediction:  {"predictions": [[1, 12465, 2036, 6475, 2, 3, 2202, 4, 5, 1122, 1185, 2039, 6570, 1657, 7785, 1137, 10005, 10095, 1170, 2997, 7827, 1121, 1672, 1769, 2266, 2114, 3055, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 6570, 4, 5, 1657, 7785, 1137, 10005, 10095, 1185, 2039, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00205733859911561, -0.03172823786735535, -0.07657170295715332, -0.07657408714294434, -0.07657408714294434, -0.07657408714294434, -0.07657408714294434, -0.07657408714294434, -0.07657408714294434, -0.07657408714294434], "metadata": {"source_tokens": ["However", ",", "after", "pressure", "campaigns", "from", "various", "human", "rights", "groups", ",", "BA", "##E", "Systems", "recently", "stated", "it", "no", "longer", "produces", "land", "mines", "or", "cluster", "bombs", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "BA", "##E", "Systems", "[unused2]", "[unused3]", "stated", "[unused4]", "[unused5]", "it", "no", "longer", "produces", "land", "mines", "or", "cluster", "bombs", "after", "pressure", "campaigns", "from", "various", "human", "rights", "groups", "recently", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "produces", "[unused4]", "[unused5]", "land", "mines", "or", "cluster", "bombs", "no", "longer", "[unused6]", "[SEP]"]]}

input 116:  {"source": "However , comic relief sidekick `` Mike McGurk '' bears some resemblance to Tracy 's partner from the strip , Pat Patton ; Tracy 's secretary , Gwen Andrews , provides the same kind of feminine interest as Tess Trueheart ; and FBI Director Clive Anderson is the same kind of avuncular superior as Chief Brandon .\n"}
prediction:  {"predictions": [[1, 8099, 2524, 15295, 4347, 2, 3, 1110, 4, 5, 1103, 1269, 1912, 1104, 170, 25247, 26405, 5552, 7298, 1112, 2534, 8464, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4824, 3893, 1334, 27982, 2, 3, 8807, 4, 5, 1199, 14634, 1106, 10435, 112, 1116, 3547, 1121, 1103, 6322, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10435, 112, 1116, 4848, 2, 3, 2790, 4, 5, 1103, 1269, 1912, 1104, 13385, 2199, 1112, 16613, 7817, 19233, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6322, 2, 3, 1110, 4848, 1104, 4, 5, 10435, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6322, 2, 3, 1110, 4848, 1104, 4, 5, 10435, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6322, 2, 3, 1110, 4848, 1104, 4, 5, 10435, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6322, 2, 3, 1110, 4848, 1104, 4, 5, 10435, 6, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.022293388843536377, -0.06117445230484009, -0.05546647310256958, -0.1501559168100357, -0.13835452497005463, -0.12770289182662964, -0.15733307600021362, -0.22745394706726074, -0.24836516380310059, -0.24836516380310059], "metadata": {"source_tokens": ["However", ",", "comic", "relief", "side", "##kick", "`", "##`", "Mike", "M", "##c", "##G", "##ur", "##k", "'", "##'", "bears", "some", "resemblance", "to", "Tracy", "'", "##s", "partner", "from", "the", "strip", ",", "Pat", "Patton", ";", "Tracy", "'", "##s", "secretary", ",", "Gwen", "Andrews", ",", "provides", "the", "same", "kind", "of", "feminine", "interest", "as", "Tess", "True", "##heart", ";", "and", "FBI", "Director", "Clive", "Anderson", "is", "the", "same", "kind", "of", "a", "##vu", "##nc", "##ular", "superior", "as", "Chief", "Brandon", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "FBI", "Director", "Clive", "Anderson", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "same", "kind", "of", "a", "##vu", "##nc", "##ular", "superior", "as", "Chief", "Brandon", "[unused6]", "[SEP]", "[unused1]", "comic", "relief", "side", "##kick", "[unused2]", "[unused3]", "bears", "[unused4]", "[unused5]", "some", "resemblance", "to", "Tracy", "'", "##s", "partner", "from", "the", "strip", "[unused6]", "[SEP]", "[unused1]", "Tracy", "'", "##s", "secretary", "[unused2]", "[unused3]", "provides", "[unused4]", "[unused5]", "the", "same", "kind", "of", "feminine", "interest", "as", "Tess", "True", "##heart", "[unused6]", "[SEP]", "[unused1]", "the", "strip", "[unused2]", "[unused3]", "is", "secretary", "of", "[unused4]", "[unused5]", "Tracy", "[unused6]", "[SEP]", "[unused1]", "the", "strip", "[unused2]", "[unused3]", "is", "secretary", "of", "[unused4]", "[unused5]", "Tracy", "[unused6]", "[SEP]", "[unused1]", "the", "strip", "[unused2]", "[unused3]", "is", "secretary", "of", "[unused4]", "[unused5]", "Tracy", "[unused6]", "[SEP]", "[unused1]", "the", "strip", "[unused2]", "[unused3]", "is", "secretary", "of", "[unused4]", "[unused5]", "Tracy", "[unused6]", "[SEP]"]]}

input 117:  {"source": "However , during his rehearsal , Knievel lost control of the motorcycle and crashed into a cameraman .\n"}
prediction:  {"predictions": [[1, 148, 5213, 12559, 2, 3, 1575, 4, 5, 1654, 1104, 1103, 9580, 1219, 1117, 20762, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 148, 5213, 12559, 2, 3, 7573, 4, 5, 1154, 170, 4504, 1399, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008528444916009903, -0.039491113275289536, -0.12640762329101562, -0.12371516227722168, -0.12371516227722168, -0.12371516227722168, -0.12371516227722168, -0.12371516227722168, -0.12371516227722168, -0.12371516227722168], "metadata": {"source_tokens": ["However", ",", "during", "his", "rehearsal", ",", "K", "##nie", "##vel", "lost", "control", "of", "the", "motorcycle", "and", "crashed", "into", "a", "camera", "##man", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "K", "##nie", "##vel", "[unused2]", "[unused3]", "lost", "[unused4]", "[unused5]", "control", "of", "the", "motorcycle", "during", "his", "rehearsal", "[unused6]", "[SEP]", "[unused1]", "K", "##nie", "##vel", "[unused2]", "[unused3]", "crashed", "[unused4]", "[unused5]", "into", "a", "camera", "##man", "[unused6]", "[SEP]"]]}

input 118:  {"source": "However , it became far less safe for the Nationals from 1983 onward , and strong population growth over the last three decades has seen it progressively lose its rural territory and reduced it to a more coastal-based and urbanised division .\n"}
prediction:  {"predictions": [[1, 2012, 1416, 3213, 1166, 1103, 1314, 1210, 4397, 2, 3, 1144, 1562, 4, 5, 1122, 22770, 3857, 1157, 3738, 3441, 1105, 3549, 1122, 1106, 170, 1167, 5869, 28137, 14017, 1181, 1105, 3953, 3673, 2417, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1245, 4, 5, 1677, 1750, 2914, 1111, 1103, 16101, 1121, 2278, 17765, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 3549, 4, 5, 1122, 1106, 170, 1167, 5869, 28137, 14017, 1181, 1105, 3953, 3673, 2417, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 3549, 4, 5, 1122, 22770, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 3549, 4, 5, 1122, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 3549, 4, 5, 1122, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03570441156625748, -0.016706684604287148, -0.061609961092472076, -0.1700081080198288, -0.19337649643421173, -0.1956612914800644, -0.2854197025299072, -0.285048246383667, -0.285048246383667, -0.285048246383667], "metadata": {"source_tokens": ["However", ",", "it", "became", "far", "less", "safe", "for", "the", "Nationals", "from", "1983", "onward", ",", "and", "strong", "population", "growth", "over", "the", "last", "three", "decades", "has", "seen", "it", "progressively", "lose", "its", "rural", "territory", "and", "reduced", "it", "to", "a", "more", "coastal", "##-", "##base", "##d", "and", "urban", "##ised", "division", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "strong", "population", "growth", "over", "the", "last", "three", "decades", "[unused2]", "[unused3]", "has", "seen", "[unused4]", "[unused5]", "it", "progressively", "lose", "its", "rural", "territory", "and", "reduced", "it", "to", "a", "more", "coastal", "##-", "##base", "##d", "and", "urban", "##ised", "division", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "far", "less", "safe", "for", "the", "Nationals", "from", "1983", "onward", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "reduced", "[unused4]", "[unused5]", "it", "to", "a", "more", "coastal", "##-", "##base", "##d", "and", "urban", "##ised", "division", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "reduced", "[unused4]", "[unused5]", "it", "progressively", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "reduced", "[unused4]", "[unused5]", "it", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "reduced", "[unused4]", "[unused5]", "it", "[unused6]", "[SEP]"]]}

input 119:  {"source": "However , when the antigenicities of the seed strains and wild viruses do not match , vaccines fail to protect the vaccinees .\n"}
prediction:  {"predictions": [[1, 20034, 1116, 2, 3, 8693, 4, 5, 1106, 3244, 1103, 20034, 1279, 1165, 1103, 2848, 19438, 4233, 1104, 1103, 6478, 21116, 1105, 4098, 20942, 1202, 1136, 1801, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2848, 19438, 4233, 1104, 1103, 6478, 21116, 1105, 4098, 20942, 2, 3, 1202, 1136, 1801, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01405668631196022, -0.028810273855924606, -0.07635354995727539, -0.07635378837585449, -0.07635378837585449, -0.07635378837585449, -0.07635378837585449, -0.07635378837585449, -0.07635378837585449, -0.07635378837585449], "metadata": {"source_tokens": ["However", ",", "when", "the", "anti", "##genic", "##ities", "of", "the", "seed", "strains", "and", "wild", "viruses", "do", "not", "match", ",", "vaccine", "##s", "fail", "to", "protect", "the", "vaccine", "##es", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "vaccine", "##s", "[unused2]", "[unused3]", "fail", "[unused4]", "[unused5]", "to", "protect", "the", "vaccine", "##es", "when", "the", "anti", "##genic", "##ities", "of", "the", "seed", "strains", "and", "wild", "viruses", "do", "not", "match", "[unused6]", "[SEP]", "[unused1]", "the", "anti", "##genic", "##ities", "of", "the", "seed", "strains", "and", "wild", "viruses", "[unused2]", "[unused3]", "do", "not", "match", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 120:  {"source": "If given this data , the Germans would be able to adjust their aim and correct any shortfall .\n"}
prediction:  {"predictions": [[1, 1103, 6494, 2, 3, 1156, 1129, 4, 5, 1682, 1106, 14878, 1147, 6457, 1105, 5663, 1251, 1603, 8877, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6494, 2, 3, 1156, 1129, 4, 5, 1682, 1409, 1549, 1142, 2233, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6494, 2, 3, 1156, 1129, 4, 5, 1682, 1106, 5663, 1251, 1603, 8877, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00039536613621748984, -0.10547532886266708, -0.10254406929016113, -0.14516186714172363, -0.14739298820495605, -0.14739298820495605, -0.14739298820495605, -0.14739298820495605, -0.14739298820495605, -0.14739298820495605], "metadata": {"source_tokens": ["If", "given", "this", "data", ",", "the", "Germans", "would", "be", "able", "to", "adjust", "their", "aim", "and", "correct", "any", "short", "##fall", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Germans", "[unused2]", "[unused3]", "would", "be", "[unused4]", "[unused5]", "able", "to", "adjust", "their", "aim", "and", "correct", "any", "short", "##fall", "[unused6]", "[SEP]", "[unused1]", "the", "Germans", "[unused2]", "[unused3]", "would", "be", "[unused4]", "[unused5]", "able", "If", "given", "this", "data", "[unused6]", "[SEP]", "[unused1]", "the", "Germans", "[unused2]", "[unused3]", "would", "be", "[unused4]", "[unused5]", "able", "to", "correct", "any", "short", "##fall", "[unused6]", "[SEP]"]]}

input 121:  {"source": "If the second excitation pulse is sent prematurely before the relaxation is complete , the average magnetization vector still points in a nonparallel direction , giving suboptimal absorption and emission of the pulse .\n"}
prediction:  {"predictions": [[1, 1103, 1903, 24197, 2734, 9479, 2, 3, 1827, 4, 5, 1107, 170, 1664, 17482, 22096, 1233, 2447, 1253, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1248, 4252, 24214, 8561, 2, 3, 1110, 1850, 4, 5, 24505, 1193, 1196, 1103, 27475, 1110, 2335, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1903, 24197, 2734, 9479, 2, 3, 1827, 4, 5, 1107, 170, 1664, 17482, 22096, 1233, 2447, 2368, 4841, 4184, 3121, 7435, 18099, 1105, 17744, 1104, 1103, 8561, 1409, 1103, 1248, 4252, 24214, 8561, 1110, 1850, 24505, 1193, 1196, 1103, 27475, 1110, 2335, 6, 102, 102, 102, 102, 102, 102, 1, 1103, 1903, 24197, 2734, 9479, 2, 3, 1827, 4, 5, 2368, 4841, 4184, 3121, 7435, 18099, 1105, 17744, 1104, 1103, 8561, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1903, 24197, 2734, 9479, 2, 3, 1827, 4, 5, 2368, 4841, 4184, 3121, 7435, 18099, 1105, 17744, 1104, 1103, 8561, 1409, 1103, 1248, 4252, 24214, 8561, 1110, 1850, 24505, 1193, 1196, 1103, 27475, 1110, 2335, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.026363488286733627, -0.06046190857887268, -0.07099100947380066, -0.09428999572992325, -0.06978633254766464, -0.26349425315856934, -0.2630401849746704, -0.2630401849746704, -0.2630401849746704, -0.2630401849746704], "metadata": {"source_tokens": ["If", "the", "second", "ex", "##citation", "pulse", "is", "sent", "premature", "##ly", "before", "the", "relaxation", "is", "complete", ",", "the", "average", "magnet", "##ization", "vector", "still", "points", "in", "a", "non", "##par", "##alle", "##l", "direction", ",", "giving", "sub", "##op", "##ti", "##mal", "absorption", "and", "emission", "of", "the", "pulse", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "average", "magnet", "##ization", "vector", "[unused2]", "[unused3]", "points", "[unused4]", "[unused5]", "in", "a", "non", "##par", "##alle", "##l", "direction", "still", "[unused6]", "[SEP]", "[unused1]", "the", "second", "ex", "##citation", "pulse", "[unused2]", "[unused3]", "is", "sent", "[unused4]", "[unused5]", "premature", "##ly", "before", "the", "relaxation", "is", "complete", "[unused6]", "[SEP]", "[unused1]", "the", "average", "magnet", "##ization", "vector", "[unused2]", "[unused3]", "points", "[unused4]", "[unused5]", "in", "a", "non", "##par", "##alle", "##l", "direction", "giving", "sub", "##op", "##ti", "##mal", "absorption", "and", "emission", "of", "the", "pulse", "If", "the", "second", "ex", "##citation", "pulse", "is", "sent", "premature", "##ly", "before", "the", "relaxation", "is", "complete", "[unused6]", "[SEP]", "[unused1]", "the", "average", "magnet", "##ization", "vector", "[unused2]", "[unused3]", "points", "[unused4]", "[unused5]", "giving", "sub", "##op", "##ti", "##mal", "absorption", "and", "emission", "of", "the", "pulse", "[unused6]", "[SEP]", "[unused1]", "the", "average", "magnet", "##ization", "vector", "[unused2]", "[unused3]", "points", "[unused4]", "[unused5]", "giving", "sub", "##op", "##ti", "##mal", "absorption", "and", "emission", "of", "the", "pulse", "If", "the", "second", "ex", "##citation", "pulse", "is", "sent", "premature", "##ly", "before", "the", "relaxation", "is", "complete", "[unused6]", "[SEP]"]]}

input 122:  {"source": "In 1005 for example , the governor of the important Adriatic port of Dyrrhachium had surrendered the town to Basil II .\n"}
prediction:  {"predictions": [[1, 1103, 4066, 1104, 1103, 1696, 26122, 4104, 1104, 141, 12577, 1197, 2328, 4313, 1818, 2, 3, 1125, 10738, 4, 5, 1103, 1411, 1106, 16209, 1563, 1130, 1620, 1571, 1111, 1859, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4066, 1104, 1103, 1696, 26122, 4104, 1104, 141, 12577, 1197, 2328, 4313, 1818, 2, 3, 1125, 10738, 4, 5, 1103, 1411, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0035826973617076874, -0.04490550607442856, -0.268718957901001, -0.27381086349487305, -0.27381086349487305, -0.27381086349487305, -0.27381086349487305, -0.27381086349487305, -0.27381086349487305, -0.27381086349487305], "metadata": {"source_tokens": ["In", "100", "##5", "for", "example", ",", "the", "governor", "of", "the", "important", "Adriatic", "port", "of", "D", "##yr", "##r", "##ha", "##chi", "##um", "had", "surrendered", "the", "town", "to", "Basil", "II", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "governor", "of", "the", "important", "Adriatic", "port", "of", "D", "##yr", "##r", "##ha", "##chi", "##um", "[unused2]", "[unused3]", "had", "surrendered", "[unused4]", "[unused5]", "the", "town", "to", "Basil", "II", "In", "100", "##5", "for", "example", "[unused6]", "[SEP]", "[unused1]", "the", "governor", "of", "the", "important", "Adriatic", "port", "of", "D", "##yr", "##r", "##ha", "##chi", "##um", "[unused2]", "[unused3]", "had", "surrendered", "[unused4]", "[unused5]", "the", "town", "[unused6]", "[SEP]"]]}

input 123:  {"source": "In 1866 , he began a second term as Lord Chancellor , which ended with his death in the next year .\n"}
prediction:  {"predictions": [[1, 2188, 8861, 2, 3, 2207, 4, 5, 1114, 1117, 1473, 1107, 1103, 1397, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1310, 4, 5, 170, 1248, 1858, 1112, 2188, 8861, 1130, 7146, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02497577667236328, -0.005833233240991831, -0.07606816291809082, -0.07606792449951172, -0.07606792449951172, -0.07606792449951172, -0.07606792449951172, -0.07606792449951172, -0.07606792449951172, -0.07606792449951172], "metadata": {"source_tokens": ["In", "1866", ",", "he", "began", "a", "second", "term", "as", "Lord", "Chancellor", ",", "which", "ended", "with", "his", "death", "in", "the", "next", "year", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Lord", "Chancellor", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "with", "his", "death", "in", "the", "next", "year", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "a", "second", "term", "as", "Lord", "Chancellor", "In", "1866", "[unused6]", "[SEP]"]]}

input 124:  {"source": "In 1911 , with Francis La Flesche , she published `` The Omaha Tribe '' .\n"}
prediction:  {"predictions": [[1, 1131, 2, 3, 1502, 4, 5, 1109, 13072, 15987, 1130, 4383, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03575938194990158, -0.07604336738586426, -0.07604503631591797, -0.07604503631591797, -0.07604503631591797, -0.07604503631591797, -0.07604503631591797, -0.07604503631591797, -0.07604503631591797, -0.07604503631591797], "metadata": {"source_tokens": ["In", "1911", ",", "with", "Francis", "La", "F", "##les", "##che", ",", "she", "published", "`", "##`", "The", "Omaha", "Tribe", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "she", "[unused2]", "[unused3]", "published", "[unused4]", "[unused5]", "The", "Omaha", "Tribe", "In", "1911", "[unused6]", "[SEP]"]]}

input 125:  {"source": "In 1926 , `` The News and Courier '' was bought by the owners of Charleston 's main evening paper , `` The Evening Post . ''\n"}
prediction:  {"predictions": [[1, 1109, 3128, 1105, 3291, 16706, 2, 3, 1108, 3306, 4, 5, 1118, 1103, 5032, 1104, 10874, 112, 1116, 1514, 3440, 2526, 1130, 4082, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10874, 112, 1116, 1514, 3440, 2526, 2, 3, 1110, 4, 5, 1109, 11718, 3799, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0037050980608910322, -0.057500291615724564, -0.032201528549194336, -0.032201290130615234, -0.032201290130615234, -0.032201290130615234, -0.032201290130615234, -0.032201290130615234, -0.032201290130615234, -0.032201290130615234], "metadata": {"source_tokens": ["In", "1926", ",", "`", "##`", "The", "News", "and", "Co", "##urier", "'", "##'", "was", "bought", "by", "the", "owners", "of", "Charleston", "'", "##s", "main", "evening", "paper", ",", "`", "##`", "The", "Evening", "Post", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "News", "and", "Co", "##urier", "[unused2]", "[unused3]", "was", "bought", "[unused4]", "[unused5]", "by", "the", "owners", "of", "Charleston", "'", "##s", "main", "evening", "paper", "In", "1926", "[unused6]", "[SEP]", "[unused1]", "Charleston", "'", "##s", "main", "evening", "paper", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "The", "Evening", "Post", "[unused6]", "[SEP]"]]}

input 126:  {"source": "In 1954 , a KOMO news photographer discovered a way to develop color film in a new process that took just a few hours instead of days .\n"}
prediction:  {"predictions": [[1, 170, 148, 13041, 2346, 2371, 8152, 2, 3, 2751, 4, 5, 170, 1236, 1106, 3689, 2942, 1273, 1107, 170, 1207, 1965, 1130, 3183, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1207, 1965, 2, 3, 1261, 4, 5, 1198, 170, 1374, 2005, 1939, 1104, 1552, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 148, 13041, 2346, 2371, 8152, 2, 3, 2751, 4, 5, 170, 1236, 1106, 3689, 2942, 1273, 1107, 170, 1207, 1965, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.015074365772306919, -0.009357218630611897, -0.048806216567754745, -0.1201314926147461, -0.13357305526733398, -0.13357305526733398, -0.13357305526733398, -0.13357305526733398, -0.13357305526733398, -0.13357305526733398], "metadata": {"source_tokens": ["In", "1954", ",", "a", "K", "##OM", "##O", "news", "photographer", "discovered", "a", "way", "to", "develop", "color", "film", "in", "a", "new", "process", "that", "took", "just", "a", "few", "hours", "instead", "of", "days", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "K", "##OM", "##O", "news", "photographer", "[unused2]", "[unused3]", "discovered", "[unused4]", "[unused5]", "a", "way", "to", "develop", "color", "film", "in", "a", "new", "process", "In", "1954", "[unused6]", "[SEP]", "[unused1]", "a", "new", "process", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "just", "a", "few", "hours", "instead", "of", "days", "[unused6]", "[SEP]", "[unused1]", "a", "K", "##OM", "##O", "news", "photographer", "[unused2]", "[unused3]", "discovered", "[unused4]", "[unused5]", "a", "way", "to", "develop", "color", "film", "in", "a", "new", "process", "[unused6]", "[SEP]"]]}

input 127:  {"source": "In 1964 Barrie appeared in two episodes of `` Alfred Hitchcock Presents '' .\n"}
prediction:  {"predictions": [[1, 21715, 1663, 2, 3, 1691, 4, 5, 1107, 1160, 3426, 1104, 169, 28152, 5492, 21358, 21680, 1130, 2668, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0006038575083948672, -0.032331228256225586, -0.03232121467590332, -0.03232121467590332, -0.03232121467590332, -0.03232121467590332, -0.03232121467590332, -0.03232121467590332, -0.03232121467590332, -0.03232121467590332], "metadata": {"source_tokens": ["In", "1964", "Barr", "##ie", "appeared", "in", "two", "episodes", "of", "`", "##`", "Alfred", "Hitchcock", "Presents", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Barr", "##ie", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "in", "two", "episodes", "of", "`", "##`", "Alfred", "Hitchcock", "Presents", "In", "1964", "[unused6]", "[SEP]"]]}

Batch 1 Test Time =  78.204017162323  s
g_f_logprobs : 0.20361542701721191
Decodertime : 0.0001621246337890625
Decodertime : 0.0001735687255859375
g_f_logprobs : 0.06352424621582031
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.06308746337890625
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.06310129165649414
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.475527286529541
beam_search_time: 0.6832668781280518 s
input 0:  {"source": "32.7 % of all households were made up of individuals and 15.7 % had someone living alone who was 65 years of age or older .\n"}
prediction:  {"predictions": [[1, 2724, 28138, 1559, 110, 1104, 1155, 3065, 2, 3, 1127, 1189, 1146, 4, 5, 1104, 2833, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1405, 28138, 1559, 110, 2, 3, 1125, 4, 5, 1800, 1690, 2041, 1150, 1108, 2625, 1201, 1104, 1425, 1137, 2214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.027174297720193863, -0.028148040175437927, -0.22284579277038574, -0.22266221046447754, -0.22266221046447754, -0.22266221046447754, -0.22266221046447754, -0.22266221046447754, -0.22266221046447754, -0.22266221046447754], "metadata": {"source_tokens": ["32", "##.", "##7", "%", "of", "all", "households", "were", "made", "up", "of", "individuals", "and", "15", "##.", "##7", "%", "had", "someone", "living", "alone", "who", "was", "65", "years", "of", "age", "or", "older", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "32", "##.", "##7", "%", "of", "all", "households", "[unused2]", "[unused3]", "were", "made", "up", "[unused4]", "[unused5]", "of", "individuals", "[unused6]", "[SEP]", "[unused1]", "15", "##.", "##7", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "someone", "living", "alone", "who", "was", "65", "years", "of", "age", "or", "older", "[unused6]", "[SEP]"]]}

input 1:  {"source": "A CEN forms an important but small part of a Local Strategic Partnership .\n"}
prediction:  {"predictions": [[1, 138, 9855, 2249, 2, 3, 2769, 4, 5, 1126, 1696, 1133, 1353, 1226, 1104, 170, 5328, 12367, 17330, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0008193652029149234, -0.0023665428161621094, -0.0023670196533203125, -0.0023670196533203125, -0.0023670196533203125, -0.0023670196533203125, -0.0023670196533203125, -0.0023670196533203125, -0.0023670196533203125, -0.0023670196533203125], "metadata": {"source_tokens": ["A", "CE", "##N", "forms", "an", "important", "but", "small", "part", "of", "a", "Local", "Strategic", "Partnership", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "CE", "##N", "[unused2]", "[unused3]", "forms", "[unused4]", "[unused5]", "an", "important", "but", "small", "part", "of", "a", "Local", "Strategic", "Partnership", "[unused6]", "[SEP]"]]}

input 2:  {"source": "A Democrat , he became the youngest mayor in Pittsburgh 's history in September 2006 at the age of 26 .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1245, 4, 5, 1103, 6074, 4398, 1107, 5610, 112, 1116, 1607, 1107, 1347, 1386, 1120, 1103, 1425, 1104, 1744, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1245, 4, 5, 1103, 6074, 4398, 1107, 1347, 1386, 138, 7319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0028149366844445467, -0.10157161951065063, -0.16761207580566406, -0.12488937377929688, -0.12488937377929688, -0.12488937377929688, -0.12488937377929688, -0.12488937377929688, -0.12488937377929688, -0.12488937377929688], "metadata": {"source_tokens": ["A", "Democrat", ",", "he", "became", "the", "youngest", "mayor", "in", "Pittsburgh", "'", "##s", "history", "in", "September", "2006", "at", "the", "age", "of", "26", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "the", "youngest", "mayor", "in", "Pittsburgh", "'", "##s", "history", "in", "September", "2006", "at", "the", "age", "of", "26", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "the", "youngest", "mayor", "in", "September", "2006", "A", "Democrat", "[unused6]", "[SEP]"]]}

input 3:  {"source": "A cafeteria is also located on the sixth floor , a chapel on the 14th floor , and a study hall on the 15th floor .\n"}
prediction:  {"predictions": [[1, 138, 18698, 2, 3, 1110, 1145, 1388, 4, 5, 1113, 1103, 3971, 1837, 117, 170, 6221, 1113, 1103, 5740, 1837, 117, 1105, 170, 2025, 2885, 1113, 1103, 5617, 1837, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.009444370865821838, -0.00826120376586914, -0.019139528274536133, -0.019139528274536133, -0.019139528274536133, -0.019139528274536133, -0.019139528274536133, -0.019139528274536133, -0.019139528274536133, -0.019139528274536133], "metadata": {"source_tokens": ["A", "cafeteria", "is", "also", "located", "on", "the", "sixth", "floor", ",", "a", "chapel", "on", "the", "14th", "floor", ",", "and", "a", "study", "hall", "on", "the", "15th", "floor", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "cafeteria", "[unused2]", "[unused3]", "is", "also", "located", "[unused4]", "[unused5]", "on", "the", "sixth", "floor", ",", "a", "chapel", "on", "the", "14th", "floor", ",", "and", "a", "study", "hall", "on", "the", "15th", "floor", "[unused6]", "[SEP]"]]}

input 4:  {"source": "A casting director at the time told Scott that he had wished that he 'd met him a week before ; he was casting for the `` G.I. Joe '' cartoon .\n"}
prediction:  {"predictions": [[1, 138, 9616, 1900, 1120, 1103, 1159, 2, 3, 1500, 4, 5, 2796, 1115, 1119, 1125, 5608, 1115, 1119, 112, 1181, 1899, 1140, 170, 1989, 1196, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 9616, 4, 5, 1111, 1103, 169, 28152, 144, 28138, 2240, 28138, 2658, 112, 28131, 11540, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1125, 5608, 4, 5, 1115, 1119, 112, 1181, 1899, 1140, 170, 1989, 1196, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.012745602056384087, -0.003946560434997082, -0.02845129556953907, -0.23949193954467773, -0.2509026527404785, -0.2509026527404785, -0.2509026527404785, -0.2509026527404785, -0.2509026527404785, -0.2509026527404785], "metadata": {"source_tokens": ["A", "casting", "director", "at", "the", "time", "told", "Scott", "that", "he", "had", "wished", "that", "he", "'", "##d", "met", "him", "a", "week", "before", ";", "he", "was", "casting", "for", "the", "`", "##`", "G", "##.", "##I", "##.", "Joe", "'", "##'", "cartoon", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "casting", "director", "at", "the", "time", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "Scott", "that", "he", "had", "wished", "that", "he", "'", "##d", "met", "him", "a", "week", "before", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "casting", "[unused4]", "[unused5]", "for", "the", "`", "##`", "G", "##.", "##I", "##.", "Joe", "'", "##'", "cartoon", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "had", "wished", "[unused4]", "[unused5]", "that", "he", "'", "##d", "met", "him", "a", "week", "before", "[unused6]", "[SEP]"]]}

input 5:  {"source": "A common name , logo , and programming schedule followed in 1982 , with the establishment of the `` TV8 '' network between the three stations , changed to the `` Southern Cross Network '' seven years later .\n"}
prediction:  {"predictions": [[1, 138, 1887, 1271, 117, 7998, 117, 1105, 4159, 6030, 2, 3, 1723, 4, 5, 1107, 2294, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4544, 1104, 1103, 169, 28152, 1794, 1604, 112, 28131, 2443, 1206, 1103, 1210, 2930, 2, 3, 2014, 4, 5, 1106, 1103, 169, 28152, 2685, 3156, 3998, 112, 28131, 1978, 1201, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.020979637280106544, -0.03392406180500984, -0.2160944938659668, -0.21735572814941406, -0.21735572814941406, -0.21735572814941406, -0.21735572814941406, -0.21735572814941406, -0.21735572814941406, -0.21735572814941406], "metadata": {"source_tokens": ["A", "common", "name", ",", "logo", ",", "and", "programming", "schedule", "followed", "in", "1982", ",", "with", "the", "establishment", "of", "the", "`", "##`", "TV", "##8", "'", "##'", "network", "between", "the", "three", "stations", ",", "changed", "to", "the", "`", "##`", "Southern", "Cross", "Network", "'", "##'", "seven", "years", "later", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "common", "name", ",", "logo", ",", "and", "programming", "schedule", "[unused2]", "[unused3]", "followed", "[unused4]", "[unused5]", "in", "1982", "[unused6]", "[SEP]", "[unused1]", "the", "establishment", "of", "the", "`", "##`", "TV", "##8", "'", "##'", "network", "between", "the", "three", "stations", "[unused2]", "[unused3]", "changed", "[unused4]", "[unused5]", "to", "the", "`", "##`", "Southern", "Cross", "Network", "'", "##'", "seven", "years", "later", "[unused6]", "[SEP]"]]}

input 6:  {"source": "A cooling center is a temporary air-conditioned public space set up by local authorities to deal with the health effects of a heat wave .\n"}
prediction:  {"predictions": [[1, 138, 12147, 2057, 2, 3, 1110, 4, 5, 170, 5335, 1586, 28137, 7235, 14669, 1174, 1470, 2000, 1383, 1146, 1118, 1469, 3912, 1106, 2239, 1114, 1103, 2332, 3154, 1104, 170, 3208, 4003, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 5335, 1586, 28137, 7235, 14669, 1174, 1470, 2000, 2, 3, 1383, 1146, 4, 5, 1118, 1469, 3912, 1106, 2239, 1114, 1103, 2332, 3154, 1104, 170, 3208, 4003, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.009414161555469036, -0.02099166437983513, -0.028298139572143555, -0.05161881446838379, -0.05161881446838379, -0.05161881446838379, -0.05161881446838379, -0.05161881446838379, -0.05161881446838379, -0.05161881446838379], "metadata": {"source_tokens": ["A", "cooling", "center", "is", "a", "temporary", "air", "##-", "##con", "##dition", "##ed", "public", "space", "set", "up", "by", "local", "authorities", "to", "deal", "with", "the", "health", "effects", "of", "a", "heat", "wave", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "cooling", "center", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "temporary", "air", "##-", "##con", "##dition", "##ed", "public", "space", "set", "up", "by", "local", "authorities", "to", "deal", "with", "the", "health", "effects", "of", "a", "heat", "wave", "[unused6]", "[SEP]", "[unused1]", "a", "temporary", "air", "##-", "##con", "##dition", "##ed", "public", "space", "[unused2]", "[unused3]", "set", "up", "[unused4]", "[unused5]", "by", "local", "authorities", "to", "deal", "with", "the", "health", "effects", "of", "a", "heat", "wave", "[unused6]", "[SEP]"]]}

input 7:  {"source": "A manifold is `` prime '' if it can not be presented as a connected sum of more than one manifold , none of which is the sphere of the same dimension .\n"}
prediction:  {"predictions": [[1, 138, 22502, 2, 3, 1110, 4, 5, 5748, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3839, 1104, 1134, 2, 3, 1110, 4, 5, 1103, 11036, 1104, 1103, 1269, 11025, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1169, 1136, 1129, 2756, 4, 5, 1112, 170, 3387, 7584, 1104, 1167, 1190, 1141, 22502, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.08434329926967621, -0.03920472413301468, -0.00512632867321372, -0.06350231170654297, -0.06827759742736816, -0.06827759742736816, -0.06827759742736816, -0.06827759742736816, -0.06827759742736816, -0.06827759742736816], "metadata": {"source_tokens": ["A", "manifold", "is", "`", "##`", "prime", "'", "##'", "if", "it", "can", "not", "be", "presented", "as", "a", "connected", "sum", "of", "more", "than", "one", "manifold", ",", "none", "of", "which", "is", "the", "sphere", "of", "the", "same", "dimension", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "manifold", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "prime", "[unused6]", "[SEP]", "[unused1]", "none", "of", "which", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "sphere", "of", "the", "same", "dimension", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "can", "not", "be", "presented", "[unused4]", "[unused5]", "as", "a", "connected", "sum", "of", "more", "than", "one", "manifold", "[unused6]", "[SEP]"]]}

input 8:  {"source": "A mid-March 2002 court order to stop printing for three months , was evaded by printing under other titles , such as `` Not That Respublika '' .\n"}
prediction:  {"predictions": [[1, 138, 2286, 28137, 2107, 1813, 1732, 1617, 2175, 1546, 2, 3, 1108, 174, 27923, 1181, 4, 5, 1118, 8455, 1223, 1168, 3727, 117, 1216, 1112, 169, 28152, 1753, 1337, 11336, 20080, 10354, 19921, 1161, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 2286, 28137, 2107, 1813, 1732, 1617, 2175, 1546, 2, 3, 1106, 1831, 8455, 4, 5, 1111, 1210, 1808, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.021850144490599632, -0.02403673715889454, -0.07277798652648926, -0.07660436630249023, -0.07660436630249023, -0.07660436630249023, -0.07660436630249023, -0.07660436630249023, -0.07660436630249023, -0.07660436630249023], "metadata": {"source_tokens": ["A", "mid", "##-", "##M", "##ar", "##ch", "2002", "court", "order", "to", "stop", "printing", "for", "three", "months", ",", "was", "e", "##vade", "##d", "by", "printing", "under", "other", "titles", ",", "such", "as", "`", "##`", "Not", "That", "Re", "##sp", "##ub", "##lik", "##a", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "mid", "##-", "##M", "##ar", "##ch", "2002", "court", "order", "[unused2]", "[unused3]", "was", "e", "##vade", "##d", "[unused4]", "[unused5]", "by", "printing", "under", "other", "titles", ",", "such", "as", "`", "##`", "Not", "That", "Re", "##sp", "##ub", "##lik", "##a", "[unused6]", "[SEP]", "[unused1]", "A", "mid", "##-", "##M", "##ar", "##ch", "2002", "court", "order", "[unused2]", "[unused3]", "to", "stop", "printing", "[unused4]", "[unused5]", "for", "three", "months", "[unused6]", "[SEP]"]]}

input 9:  {"source": "A motorcycle speedway long-track meeting , one of the few held in the UK , was staged at Ammanford .\n"}
prediction:  {"predictions": [[1, 1103, 1374, 2, 3, 1316, 4, 5, 1107, 1103, 1993, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 9580, 2420, 2787, 1263, 28137, 22117, 2309, 2, 3, 1108, 9645, 4, 5, 1120, 7277, 1399, 2821, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.005117177963256836, -0.00345120532438159, -0.20260071754455566, -0.20879197120666504, -0.20879197120666504, -0.20879197120666504, -0.20879197120666504, -0.20879197120666504, -0.20879197120666504, -0.20879197120666504], "metadata": {"source_tokens": ["A", "motorcycle", "speed", "##way", "long", "##-", "##track", "meeting", ",", "one", "of", "the", "few", "held", "in", "the", "UK", ",", "was", "staged", "at", "Am", "##man", "##ford", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "few", "[unused2]", "[unused3]", "held", "[unused4]", "[unused5]", "in", "the", "UK", "[unused6]", "[SEP]", "[unused1]", "A", "motorcycle", "speed", "##way", "long", "##-", "##track", "meeting", "[unused2]", "[unused3]", "was", "staged", "[unused4]", "[unused5]", "at", "Am", "##man", "##ford", "[unused6]", "[SEP]"]]}

input 10:  {"source": "A partial list of turbomachinery that may use one or more centrifugal compressors within the machine are listed here .\n"}
prediction:  {"predictions": [[1, 189, 2149, 4043, 1918, 12285, 5075, 2, 3, 1336, 1329, 4, 5, 1141, 1137, 1167, 9848, 2047, 14703, 6997, 3254, 11135, 3864, 1439, 1103, 3395, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 7597, 2190, 1104, 189, 2149, 4043, 1918, 12285, 5075, 2, 3, 1132, 2345, 4, 5, 1303, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.025830388069152832, -0.0057066502049565315, -0.0060939788818359375, -0.0060863494873046875, -0.0060863494873046875, -0.0060863494873046875, -0.0060863494873046875, -0.0060863494873046875, -0.0060863494873046875, -0.0060863494873046875], "metadata": {"source_tokens": ["A", "partial", "list", "of", "t", "##ur", "##bo", "##ma", "##chin", "##ery", "that", "may", "use", "one", "or", "more", "cent", "##ri", "##fu", "##gal", "com", "##press", "##ors", "within", "the", "machine", "are", "listed", "here", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "t", "##ur", "##bo", "##ma", "##chin", "##ery", "[unused2]", "[unused3]", "may", "use", "[unused4]", "[unused5]", "one", "or", "more", "cent", "##ri", "##fu", "##gal", "com", "##press", "##ors", "within", "the", "machine", "[unused6]", "[SEP]", "[unused1]", "A", "partial", "list", "of", "t", "##ur", "##bo", "##ma", "##chin", "##ery", "[unused2]", "[unused3]", "are", "listed", "[unused4]", "[unused5]", "here", "[unused6]", "[SEP]"]]}

input 11:  {"source": "A short distance to the east , NC 111 diverges on Greenwood Boulevard .\n"}
prediction:  {"predictions": [[1, 14056, 11084, 2, 3, 23448, 7562, 4, 5, 1113, 17999, 8691, 138, 1603, 2462, 1106, 1103, 1746, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.001347017241641879, -0.0029997825622558594, -0.00299835205078125, -0.00299835205078125, -0.00299835205078125, -0.00299835205078125, -0.00299835205078125, -0.00299835205078125, -0.00299835205078125, -0.00299835205078125], "metadata": {"source_tokens": ["A", "short", "distance", "to", "the", "east", ",", "NC", "111", "diver", "##ges", "on", "Greenwood", "Boulevard", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "NC", "111", "[unused2]", "[unused3]", "diver", "##ges", "[unused4]", "[unused5]", "on", "Greenwood", "Boulevard", "A", "short", "distance", "to", "the", "east", "[unused6]", "[SEP]"]]}

input 12:  {"source": "A spectrum from a single FID has a low signal-to-noise ratio , but fortunately it improves readily with averaging of repeated acquisitions .\n"}
prediction:  {"predictions": [[1, 138, 10122, 1121, 170, 1423, 143, 9949, 2, 3, 1144, 4, 5, 170, 1822, 4344, 28137, 2430, 28137, 2728, 4862, 6022, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 4607, 1116, 12337, 4, 5, 1114, 15883, 1104, 4892, 23345, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.005019540432840586, -0.03448319435119629, -0.2115187644958496, -0.2110002040863037, -0.2110002040863037, -0.2110002040863037, -0.2110002040863037, -0.2110002040863037, -0.2110002040863037, -0.2110002040863037], "metadata": {"source_tokens": ["A", "spectrum", "from", "a", "single", "F", "##ID", "has", "a", "low", "signal", "##-", "##to", "##-", "##no", "##ise", "ratio", ",", "but", "fortunate", "##ly", "it", "improve", "##s", "readily", "with", "averaging", "of", "repeated", "acquisitions", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "spectrum", "from", "a", "single", "F", "##ID", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "a", "low", "signal", "##-", "##to", "##-", "##no", "##ise", "ratio", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "improve", "##s", "readily", "[unused4]", "[unused5]", "with", "averaging", "of", "repeated", "acquisitions", "[unused6]", "[SEP]"]]}

input 13:  {"source": "According to Hofmann , while still a teenage coin collector , he forged a rare mint mark on a dime and was told by an organization of coin collectors that it was genuine .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 17667, 4, 5, 170, 4054, 22532, 4551, 1113, 170, 12563, 1162, 1229, 1253, 170, 11009, 9584, 12116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1500, 4, 5, 1118, 1126, 2369, 1104, 9584, 16801, 1115, 1122, 1108, 10416, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 17667, 4, 5, 170, 4054, 22532, 4551, 1113, 170, 12563, 1162, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.029975559562444687, -0.045965228229761124, -0.122138611972332, -0.2226414680480957, -0.2226412296295166, -0.2226412296295166, -0.2226412296295166, -0.2226412296295166, -0.2226412296295166, -0.2226412296295166], "metadata": {"source_tokens": ["According", "to", "Ho", "##f", "##mann", ",", "while", "still", "a", "teenage", "coin", "collector", ",", "he", "forged", "a", "rare", "mint", "mark", "on", "a", "dim", "##e", "and", "was", "told", "by", "an", "organization", "of", "coin", "collectors", "that", "it", "was", "genuine", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "forged", "[unused4]", "[unused5]", "a", "rare", "mint", "mark", "on", "a", "dim", "##e", "while", "still", "a", "teenage", "coin", "collector", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "told", "[unused4]", "[unused5]", "by", "an", "organization", "of", "coin", "collectors", "that", "it", "was", "genuine", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "forged", "[unused4]", "[unused5]", "a", "rare", "mint", "mark", "on", "a", "dim", "##e", "[unused6]", "[SEP]"]]}

input 14:  {"source": "According to Samaritan tradition , however , the Samaritan ethnonym is not derived from the region of Samaria , but from the fact that they were the `` Guardians '' of the true Israelite religion .\n"}
prediction:  {"predictions": [[1, 1103, 2687, 7710, 5108, 3084, 7272, 10031, 1306, 2, 3, 1110, 1136, 4408, 4, 5, 1121, 1103, 1805, 1104, 2687, 11315, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1127, 4, 5, 1103, 169, 28152, 21444, 112, 28131, 1104, 1103, 2276, 4878, 1566, 4483, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2687, 7710, 5108, 3084, 7272, 10031, 1306, 2, 3, 1110, 1136, 4408, 4, 5, 1121, 1103, 1805, 1104, 2687, 11315, 1133, 1121, 1103, 1864, 1115, 1152, 1127, 1103, 21444, 1104, 1103, 2276, 4878, 1566, 4483, 1792, 1106, 2687, 7710, 5108, 3904, 6, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02384353242814541, -0.01040303148329258, -0.03850141540169716, -0.1447606086730957, -0.14480924606323242, -0.14480924606323242, -0.14480924606323242, -0.14480924606323242, -0.14480924606323242, -0.14480924606323242], "metadata": {"source_tokens": ["According", "to", "Sam", "##ari", "##tan", "tradition", ",", "however", ",", "the", "Sam", "##ari", "##tan", "et", "##hn", "##ony", "##m", "is", "not", "derived", "from", "the", "region", "of", "Sam", "##aria", ",", "but", "from", "the", "fact", "that", "they", "were", "the", "`", "##`", "Guardians", "'", "##'", "of", "the", "true", "Israeli", "##te", "religion", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Sam", "##ari", "##tan", "et", "##hn", "##ony", "##m", "[unused2]", "[unused3]", "is", "not", "derived", "[unused4]", "[unused5]", "from", "the", "region", "of", "Sam", "##aria", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "the", "`", "##`", "Guardians", "'", "##'", "of", "the", "true", "Israeli", "##te", "religion", "[unused6]", "[SEP]", "[unused1]", "the", "Sam", "##ari", "##tan", "et", "##hn", "##ony", "##m", "[unused2]", "[unused3]", "is", "not", "derived", "[unused4]", "[unused5]", "from", "the", "region", "of", "Sam", "##aria", "but", "from", "the", "fact", "that", "they", "were", "the", "Guardians", "of", "the", "true", "Israeli", "##te", "religion", "According", "to", "Sam", "##ari", "##tan", "tradition", "[unused6]", "[SEP]"]]}

input 15:  {"source": "According to the 2010 census , the population of the town is 2,310 .\n"}
prediction:  {"predictions": [[1, 1103, 1416, 1104, 1103, 1411, 2, 3, 1110, 4, 5, 123, 28136, 22639, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0010541747324168682, -0.0029549598693847656, -0.0029783248901367188, -0.0029783248901367188, -0.0029783248901367188, -0.0029783248901367188, -0.0029783248901367188, -0.0029783248901367188, -0.0029783248901367188, -0.0029783248901367188], "metadata": {"source_tokens": ["According", "to", "the", "2010", "census", ",", "the", "population", "of", "the", "town", "is", "2", "##,", "##31", "##0", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "population", "of", "the", "town", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "2", "##,", "##31", "##0", "[unused6]", "[SEP]"]]}

input 16:  {"source": "According to the South Koreans , many Koreans became victims of Japanese brutalities during the colonial period .\n"}
prediction:  {"predictions": [[1, 1242, 27757, 2, 3, 1245, 4, 5, 5256, 1104, 1983, 12800, 4233, 1219, 1103, 5929, 1669, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.000927699264138937, -0.10921263694763184, -0.09937238693237305, -0.09937238693237305, -0.09937238693237305, -0.09937238693237305, -0.09937238693237305, -0.09937238693237305, -0.09937238693237305, -0.09937238693237305], "metadata": {"source_tokens": ["According", "to", "the", "South", "Koreans", ",", "many", "Koreans", "became", "victims", "of", "Japanese", "brutal", "##ities", "during", "the", "colonial", "period", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "many", "Koreans", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "victims", "of", "Japanese", "brutal", "##ities", "during", "the", "colonial", "period", "[unused6]", "[SEP]"]]}

input 17:  {"source": "According to the United States Census Bureau , the town has a total area of , all of it land .\n"}
prediction:  {"predictions": [[1, 1103, 1411, 2, 3, 1144, 4, 5, 170, 1703, 1298, 1104, 117, 1155, 1104, 1122, 1657, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.003907548729330301, -0.02684497833251953, -0.02174067497253418, -0.02174067497253418, -0.02174067497253418, -0.02174067497253418, -0.02174067497253418, -0.02174067497253418, -0.02174067497253418, -0.02174067497253418], "metadata": {"source_tokens": ["According", "to", "the", "United", "States", "Census", "Bureau", ",", "the", "town", "has", "a", "total", "area", "of", ",", "all", "of", "it", "land", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "town", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "a", "total", "area", "of", ",", "all", "of", "it", "land", "[unused6]", "[SEP]"]]}

input 18:  {"source": "According to the indictment , Gonzalez is accused of defrauding the West Bronx Neighborhood Association Inc. , a not-for-profit corporation , by using funds donated to the organization in order to pay for over $ 37,000 in personal expenses .\n"}
prediction:  {"predictions": [[1, 4381, 2, 3, 6384, 4, 5, 1106, 1103, 2369, 1107, 1546, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21125, 2, 3, 1110, 4806, 4, 5, 1104, 19353, 1611, 21705, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 1118, 1606, 4381, 6384, 1106, 1103, 2369, 1107, 1546, 1106, 2653, 1111, 1166, 109, 3413, 28136, 7629, 1568, 1107, 2357, 11928, 6, 102, 102, 102, 102, 102, 102, 102, 1, 21125, 2, 3, 1110, 4806, 4, 5, 1104, 19353, 1611, 21705, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 1792, 1106, 1103, 27926, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21125, 2, 3, 1104, 19353, 1611, 21705, 4, 5, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1537, 15115, 151, 6851, 5084, 12207, 5914, 1791, 3561, 2, 3, 1110, 4, 5, 170, 1136, 28137, 14467, 1197, 28137, 1643, 2180, 14067, 9715, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.05850758031010628, -0.038442060351371765, -0.09738493710756302, -0.07479505985975266, -0.06477341800928116, -0.22274494171142578, -0.22274470329284668, -0.22274470329284668, -0.22274470329284668, -0.22274470329284668], "metadata": {"source_tokens": ["According", "to", "the", "indictment", ",", "Gonzalez", "is", "accused", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "##.", ",", "a", "not", "##-", "##fo", "##r", "##-", "##p", "##ro", "##fit", "corporation", ",", "by", "using", "funds", "donated", "to", "the", "organization", "in", "order", "to", "pay", "for", "over", "$", "37", "##,", "##00", "##0", "in", "personal", "expenses", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "funds", "[unused2]", "[unused3]", "donated", "[unused4]", "[unused5]", "to", "the", "organization", "in", "order", "[unused6]", "[SEP]", "[unused1]", "Gonzalez", "[unused2]", "[unused3]", "is", "accused", "[unused4]", "[unused5]", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "by", "using", "funds", "donated", "to", "the", "organization", "in", "order", "to", "pay", "for", "over", "$", "37", "##,", "##00", "##0", "in", "personal", "expenses", "[unused6]", "[SEP]", "[unused1]", "Gonzalez", "[unused2]", "[unused3]", "is", "accused", "[unused4]", "[unused5]", "of", "def", "##ra", "##uding", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "According", "to", "the", "indictment", "[unused6]", "[SEP]", "[unused1]", "Gonzalez", "[unused2]", "[unused3]", "of", "def", "##ra", "##uding", "[unused4]", "[unused5]", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "[unused6]", "[SEP]", "[unused1]", "the", "West", "Bronx", "N", "##ei", "##gh", "##bor", "##hood", "Association", "Inc", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "not", "##-", "##fo", "##r", "##-", "##p", "##ro", "##fit", "corporation", "[unused6]", "[SEP]"]]}

g_f_logprobs : 0.04495668411254883
input 19:  {"source": "Accordingly , the 1962 Roman Missal , the edition whose continued use as an extraordinary form of the Roman Rite is authorized by the motu proprio `` Summorum Pontificum '' , also has no mention of her .\n"}
prediction:  {"predictions": [[1, 1103, 2832, 2264, 3056, 1348, 2, 3, 1144, 4, 5, 1185, 4734, 1104, 1123, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2596, 2, 3, 1110, 9320, 4, 5, 1118, 1103, 182, 3329, 1358, 21146, 8558, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2596, 2, 3, 1598, 1329, 4, 5, 1112, 1126, 10264, 1532, 1104, 1103, 2264, 23787, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02836155891418457, -0.05203721299767494, -0.051978908479213715, -0.2559034824371338, -0.25461792945861816, -0.25461792945861816, -0.25461792945861816, -0.25461792945861816, -0.25461792945861816, -0.25461792945861816], "metadata": {"source_tokens": ["Accordingly", ",", "the", "1962", "Roman", "Miss", "##al", ",", "the", "edition", "whose", "continued", "use", "as", "an", "extraordinary", "form", "of", "the", "Roman", "Rite", "is", "authorized", "by", "the", "m", "##ot", "##u", "prop", "##rio", "`", "##`", "Su", "##mm", "##orum", "Pont", "##ific", "##um", "'", "##'", ",", "also", "has", "no", "mention", "of", "her", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "1962", "Roman", "Miss", "##al", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "no", "mention", "of", "her", "[unused6]", "[SEP]", "[unused1]", "the", "edition", "[unused2]", "[unused3]", "is", "authorized", "[unused4]", "[unused5]", "by", "the", "m", "##ot", "##u", "prop", "##rio", "[unused6]", "[SEP]", "[unused1]", "the", "edition", "[unused2]", "[unused3]", "continued", "use", "[unused4]", "[unused5]", "as", "an", "extraordinary", "form", "of", "the", "Roman", "Rite", "[unused6]", "[SEP]"]]}

input 20:  {"source": "Additionally , the French Community of Belgium has controversially begun referring to itself exclusively as the ` Wallonia-Brussels Federation ' to emphasize the links between the French Community , Wallonia and Brussels .\n"}
prediction:  {"predictions": [[1, 1103, 1497, 3704, 1104, 4990, 2, 3, 1144, 6241, 1193, 4972, 4, 5, 7455, 1106, 2111, 7097, 1112, 1103, 169, 6250, 11357, 28137, 2064, 25357, 5999, 4245, 1106, 19291, 1103, 6743, 1206, 1103, 1497, 3704, 117, 6250, 11357, 1105, 9062, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1497, 3704, 1104, 4990, 2, 3, 1144, 4972, 4, 5, 7455, 1106, 2111, 7097, 1112, 1103, 6250, 11357, 28137, 2064, 25357, 5999, 4245, 1106, 19291, 1103, 6743, 1206, 1103, 1497, 3704, 6250, 11357, 1105, 9062, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04295755550265312, -0.05277881771326065, -0.22269129753112793, -0.2226862907409668, -0.2226862907409668, -0.2226862907409668, -0.2226862907409668, -0.2226862907409668, -0.2226862907409668, -0.2226862907409668], "metadata": {"source_tokens": ["Additionally", ",", "the", "French", "Community", "of", "Belgium", "has", "controversial", "##ly", "begun", "referring", "to", "itself", "exclusively", "as", "the", "`", "Wall", "##onia", "##-", "##B", "##russ", "##els", "Federation", "'", "to", "emphasize", "the", "links", "between", "the", "French", "Community", ",", "Wall", "##onia", "and", "Brussels", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "French", "Community", "of", "Belgium", "[unused2]", "[unused3]", "has", "controversial", "##ly", "begun", "[unused4]", "[unused5]", "referring", "to", "itself", "exclusively", "as", "the", "`", "Wall", "##onia", "##-", "##B", "##russ", "##els", "Federation", "to", "emphasize", "the", "links", "between", "the", "French", "Community", ",", "Wall", "##onia", "and", "Brussels", "[unused6]", "[SEP]", "[unused1]", "the", "French", "Community", "of", "Belgium", "[unused2]", "[unused3]", "has", "begun", "[unused4]", "[unused5]", "referring", "to", "itself", "exclusively", "as", "the", "Wall", "##onia", "##-", "##B", "##russ", "##els", "Federation", "to", "emphasize", "the", "links", "between", "the", "French", "Community", "Wall", "##onia", "and", "Brussels", "[unused6]", "[SEP]"]]}

input 21:  {"source": "After 1895 cable hauling ceased and locomotives pulled trains the whole length of the Victoria and Waterloo tunnels .\n"}
prediction:  {"predictions": [[1, 7499, 2, 3, 1865, 4, 5, 3918, 1103, 2006, 2251, 1104, 1103, 3006, 1105, 14233, 11175, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5639, 6095, 26483, 2, 3, 6445, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03602050617337227, -0.03714444488286972, -0.006073474884033203, -0.006074428558349609, -0.006074428558349609, -0.006074428558349609, -0.006074428558349609, -0.006074428558349609, -0.006074428558349609, -0.006074428558349609], "metadata": {"source_tokens": ["After", "1895", "cable", "hauling", "ceased", "and", "locomotives", "pulled", "trains", "the", "whole", "length", "of", "the", "Victoria", "and", "Waterloo", "tunnels", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "locomotives", "[unused2]", "[unused3]", "pulled", "[unused4]", "[unused5]", "trains", "the", "whole", "length", "of", "the", "Victoria", "and", "Waterloo", "tunnels", "[unused6]", "[SEP]", "[unused1]", "1895", "cable", "hauling", "[unused2]", "[unused3]", "ceased", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 22:  {"source": "After five years of searching , the Colonials found a primitive , lush and vibrant new world and named it Earth .\n"}
prediction:  {"predictions": [[1, 1103, 10319, 1116, 2, 3, 1276, 4, 5, 170, 12130, 117, 19302, 1105, 18652, 1207, 1362, 1258, 1421, 1201, 1104, 6205, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 10319, 1116, 2, 3, 1417, 4, 5, 1122, 2746, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.023952126502990723, -0.02092943713068962, -0.1448206901550293, -0.14484143257141113, -0.14484143257141113, -0.14484143257141113, -0.14484143257141113, -0.14484143257141113, -0.14484143257141113, -0.14484143257141113], "metadata": {"source_tokens": ["After", "five", "years", "of", "searching", ",", "the", "Colonial", "##s", "found", "a", "primitive", ",", "lush", "and", "vibrant", "new", "world", "and", "named", "it", "Earth", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Colonial", "##s", "[unused2]", "[unused3]", "found", "[unused4]", "[unused5]", "a", "primitive", ",", "lush", "and", "vibrant", "new", "world", "After", "five", "years", "of", "searching", "[unused6]", "[SEP]", "[unused1]", "the", "Colonial", "##s", "[unused2]", "[unused3]", "named", "[unused4]", "[unused5]", "it", "Earth", "[unused6]", "[SEP]"]]}

input 23:  {"source": "After leaving `` Hex '' , Cole went on to appear as Blanche Ingram in the critically acclaimed `` Jane Eyre '' TV serial for the BBC and guest starred as Lilith in the `` Doctor Who '' episode `` The Shakespeare Code '' .\n"}
prediction:  {"predictions": [[1, 4922, 2, 3, 1355, 1113, 4, 5, 1106, 2845, 1112, 21086, 25885, 1107, 1103, 11774, 10214, 169, 28152, 4074, 142, 10930, 112, 28131, 1794, 7838, 1111, 1103, 3173, 1105, 3648, 4950, 1112, 14138, 7088, 1107, 1103, 169, 28152, 4157, 2627, 112, 28131, 2004, 169, 28152, 1109, 7647, 6741, 1258, 102, 1, 4922, 2, 3, 1355, 1113, 4, 5, 1106, 2845, 1112, 21086, 25885, 1107, 1103, 11774, 10214, 4074, 142, 10930, 1794, 7838, 1111, 1103, 3173, 1105, 3648, 4950, 1112, 14138, 7088, 1107, 1103, 169, 28152, 4157, 2627, 112, 28131, 2004, 169, 28152, 1109, 7647, 6741, 6, 102, 102, 102, 102, 102, 1, 4922, 2, 3, 1355, 1113, 4, 5, 1106, 2845, 1112, 21086, 25885, 1107, 1103, 11774, 10214, 4074, 142, 10930, 1794, 7838, 1111, 1103, 3173, 1105, 3648, 4950, 1112, 14138, 7088, 1107, 1103, 4157, 2004, 1109, 7647, 6741, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4922, 2, 3, 1355, 1113, 4, 5, 1106, 2845, 1112, 21086, 25885, 1107, 1103, 11774, 10214, 4074, 142, 10930, 1794, 7838, 1111, 1103, 3173, 1105, 3648, 4950, 1112, 14138, 7088, 1107, 1103, 4157, 2004, 1109, 7647, 6741, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04732229560613632, -0.09087655693292618, -0.09327451884746552, -0.10422007739543915, -0.22270488739013672, -0.22270512580871582, -0.22270512580871582, -0.22270512580871582, -0.22270512580871582, -0.22270512580871582], "metadata": {"source_tokens": ["After", "leaving", "`", "##`", "He", "##x", "'", "##'", ",", "Cole", "went", "on", "to", "appear", "as", "Blanche", "Ingram", "in", "the", "critically", "acclaimed", "`", "##`", "Jane", "E", "##yre", "'", "##'", "TV", "serial", "for", "the", "BBC", "and", "guest", "starred", "as", "Lil", "##ith", "in", "the", "`", "##`", "Doctor", "Who", "'", "##'", "episode", "`", "##`", "The", "Shakespeare", "Code", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Cole", "[unused2]", "[unused3]", "went", "on", "[unused4]", "[unused5]", "to", "appear", "as", "Blanche", "Ingram", "in", "the", "critically", "acclaimed", "`", "##`", "Jane", "E", "##yre", "'", "##'", "TV", "serial", "for", "the", "BBC", "and", "guest", "starred", "as", "Lil", "##ith", "in", "the", "`", "##`", "Doctor", "Who", "'", "##'", "episode", "`", "##`", "The", "Shakespeare", "Code", "After", "[SEP]", "[unused1]", "Cole", "[unused2]", "[unused3]", "went", "on", "[unused4]", "[unused5]", "to", "appear", "as", "Blanche", "Ingram", "in", "the", "critically", "acclaimed", "Jane", "E", "##yre", "TV", "serial", "for", "the", "BBC", "and", "guest", "starred", "as", "Lil", "##ith", "in", "the", "`", "##`", "Doctor", "Who", "'", "##'", "episode", "`", "##`", "The", "Shakespeare", "Code", "[unused6]", "[SEP]", "[unused1]", "Cole", "[unused2]", "[unused3]", "went", "on", "[unused4]", "[unused5]", "to", "appear", "as", "Blanche", "Ingram", "in", "the", "critically", "acclaimed", "Jane", "E", "##yre", "TV", "serial", "for", "the", "BBC", "and", "guest", "starred", "as", "Lil", "##ith", "in", "the", "Doctor", "episode", "The", "Shakespeare", "Code", "[unused6]", "[SEP]", "[unused1]", "Cole", "[unused2]", "[unused3]", "went", "on", "[unused4]", "[unused5]", "to", "appear", "as", "Blanche", "Ingram", "in", "the", "critically", "acclaimed", "Jane", "E", "##yre", "TV", "serial", "for", "the", "BBC", "and", "guest", "starred", "as", "Lil", "##ith", "in", "the", "Doctor", "episode", "The", "Shakespeare", "Code", "[unused6]", "[SEP]"]]}

Decodertime : 0.00022172927856445312
input 24:  {"source": "After the battle , Battra rested in the Arctic Ocean , whereas Mothra retired to Infant Island , accompanied by the two Cosmos .\n"}
prediction:  {"predictions": [[1, 21928, 4487, 2, 3, 8237, 4, 5, 1107, 1103, 10925, 4879, 6142, 12556, 1582, 1611, 2623, 1106, 1130, 26636, 2054, 1258, 1103, 2321, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12556, 1582, 1611, 2, 3, 2623, 4, 5, 1106, 1130, 26636, 2054, 4977, 1118, 1103, 1160, 3291, 18818, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.012055227532982826, -0.041282184422016144, -0.2226557731628418, -0.2226543426513672, -0.2226543426513672, -0.2226543426513672, -0.2226543426513672, -0.2226543426513672, -0.2226543426513672, -0.2226543426513672], "metadata": {"source_tokens": ["After", "the", "battle", ",", "Bat", "##tra", "rested", "in", "the", "Arctic", "Ocean", ",", "whereas", "Mo", "##th", "##ra", "retired", "to", "In", "##fant", "Island", ",", "accompanied", "by", "the", "two", "Co", "##smos", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Bat", "##tra", "[unused2]", "[unused3]", "rested", "[unused4]", "[unused5]", "in", "the", "Arctic", "Ocean", "whereas", "Mo", "##th", "##ra", "retired", "to", "In", "##fant", "Island", "After", "the", "battle", "[unused6]", "[SEP]", "[unused1]", "Mo", "##th", "##ra", "[unused2]", "[unused3]", "retired", "[unused4]", "[unused5]", "to", "In", "##fant", "Island", "accompanied", "by", "the", "two", "Co", "##smos", "[unused6]", "[SEP]"]]}

input 25:  {"source": "After this point many of the republicans were arrested in Free State `` round ups '' when they had come out of hiding and returned home .\n"}
prediction:  {"predictions": [[1, 1242, 1104, 1103, 22679, 1116, 2, 3, 1127, 3950, 4, 5, 1107, 4299, 1426, 169, 28152, 1668, 12534, 1165, 1152, 1125, 1435, 1149, 1104, 5797, 1105, 1608, 1313, 1258, 1142, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1125, 1435, 4, 5, 1149, 1104, 5797, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1125, 1608, 4, 5, 1313, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.020411014556884766, -0.038169100880622864, -0.17315512895584106, -0.14504098892211914, -0.14504075050354004, -0.14504075050354004, -0.14504075050354004, -0.14504075050354004, -0.14504075050354004, -0.14504075050354004], "metadata": {"source_tokens": ["After", "this", "point", "many", "of", "the", "republican", "##s", "were", "arrested", "in", "Free", "State", "`", "##`", "round", "ups", "'", "##'", "when", "they", "had", "come", "out", "of", "hiding", "and", "returned", "home", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "many", "of", "the", "republican", "##s", "[unused2]", "[unused3]", "were", "arrested", "[unused4]", "[unused5]", "in", "Free", "State", "`", "##`", "round", "ups", "when", "they", "had", "come", "out", "of", "hiding", "and", "returned", "home", "After", "this", "point", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "had", "come", "[unused4]", "[unused5]", "out", "of", "hiding", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "had", "returned", "[unused4]", "[unused5]", "home", "[unused6]", "[SEP]"]]}

input 26:  {"source": "Although Knievel broke his arms , he was more distraught over a permanent injury his accident caused to the cameraman .\n"}
prediction:  {"predictions": [[1, 148, 5213, 12559, 2, 3, 2795, 4, 5, 1117, 1739, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 4, 5, 1167, 4267, 16468, 11266, 1166, 170, 4088, 3773, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4088, 3773, 2, 3, 2416, 4, 5, 1106, 1103, 4504, 1399, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.025016289204359055, -0.034518901258707047, -0.05191899091005325, -0.22039151191711426, -0.2369680404663086, -0.2369680404663086, -0.2369680404663086, -0.2369680404663086, -0.2369680404663086, -0.2369680404663086], "metadata": {"source_tokens": ["Although", "K", "##nie", "##vel", "broke", "his", "arms", ",", "he", "was", "more", "di", "##stra", "##ught", "over", "a", "permanent", "injury", "his", "accident", "caused", "to", "the", "camera", "##man", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "K", "##nie", "##vel", "[unused2]", "[unused3]", "broke", "[unused4]", "[unused5]", "his", "arms", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "more", "di", "##stra", "##ught", "over", "a", "permanent", "injury", "[unused6]", "[SEP]", "[unused1]", "a", "permanent", "injury", "[unused2]", "[unused3]", "caused", "[unused4]", "[unused5]", "to", "the", "camera", "##man", "[unused6]", "[SEP]"]]}

input 27:  {"source": "Although under constant attack from kamikazes as well as fighters and dive-bombers , `` Hazelwood '' came through the invasion untouched and on the night of 25 February sank two small enemy freighters with her guns .\n"}
prediction:  {"predictions": [[1, 21021, 2615, 2, 3, 1338, 4, 5, 1194, 1103, 4923, 25135, 1105, 1113, 1103, 1480, 1104, 1512, 1428, 7095, 1160, 1353, 3437, 8872, 1468, 1114, 1123, 3832, 1223, 4836, 2035, 1121, 24181, 3080, 1968, 11846, 1112, 1218, 1112, 7705, 1105, 12706, 28137, 4043, 10615, 1116, 6, 102, 102, 102, 102, 1, 21021, 2615, 2, 3, 7095, 4, 5, 1160, 1353, 3437, 8872, 1468, 1114, 1123, 3832, 1113, 1103, 1480, 1104, 1512, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21021, 2615, 2, 3, 1338, 4, 5, 1194, 1103, 4923, 25135, 1966, 1223, 4836, 2035, 1121, 24181, 3080, 1968, 11846, 1112, 1218, 1112, 7705, 1105, 12706, 28137, 4043, 10615, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.053511008620262146, -0.08925890177488327, -0.07736184448003769, -0.22270870208740234, -0.22270965576171875, -0.22270965576171875, -0.22270965576171875, -0.22270965576171875, -0.22270965576171875, -0.22270965576171875], "metadata": {"source_tokens": ["Although", "under", "constant", "attack", "from", "ka", "##mi", "##ka", "##zes", "as", "well", "as", "fighters", "and", "dive", "##-", "##bo", "##mber", "##s", ",", "`", "##`", "Hazel", "##wood", "'", "##'", "came", "through", "the", "invasion", "untouched", "and", "on", "the", "night", "of", "25", "February", "sank", "two", "small", "enemy", "freight", "##ers", "with", "her", "guns", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hazel", "##wood", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "through", "the", "invasion", "untouched", "and", "on", "the", "night", "of", "25", "February", "sank", "two", "small", "enemy", "freight", "##ers", "with", "her", "guns", "under", "constant", "attack", "from", "ka", "##mi", "##ka", "##zes", "as", "well", "as", "fighters", "and", "dive", "##-", "##bo", "##mber", "##s", "[unused6]", "[SEP]", "[unused1]", "Hazel", "##wood", "[unused2]", "[unused3]", "sank", "[unused4]", "[unused5]", "two", "small", "enemy", "freight", "##ers", "with", "her", "guns", "on", "the", "night", "of", "25", "[unused6]", "[SEP]", "[unused1]", "Hazel", "##wood", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "through", "the", "invasion", "untouched", "Although", "under", "constant", "attack", "from", "ka", "##mi", "##ka", "##zes", "as", "well", "as", "fighters", "and", "dive", "##-", "##bo", "##mber", "##s", "[unused6]", "[SEP]"]]}

input 28:  {"source": "An animal that cares for its young but shows no other sociality traits is said to be `` subsocial '' .\n"}
prediction:  {"predictions": [[1, 1760, 3724, 2, 3, 16903, 4, 5, 1111, 1157, 1685, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1760, 3724, 1115, 16903, 1111, 1157, 1685, 1133, 2196, 1185, 1168, 1934, 1785, 13474, 2, 3, 1106, 1129, 4, 5, 4841, 7301, 12562, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1760, 3724, 1115, 16903, 1111, 1157, 1685, 1133, 2196, 1185, 1168, 1934, 1785, 13474, 2, 3, 1110, 1163, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.012386798858642578, -0.047257598489522934, -0.04445486515760422, -0.31198740005493164, -0.2551400661468506, -0.2551400661468506, -0.2551400661468506, -0.2551400661468506, -0.2551400661468506, -0.2551400661468506], "metadata": {"source_tokens": ["An", "animal", "that", "cares", "for", "its", "young", "but", "shows", "no", "other", "social", "##ity", "traits", "is", "said", "to", "be", "`", "##`", "sub", "##so", "##cial", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "An", "animal", "[unused2]", "[unused3]", "cares", "[unused4]", "[unused5]", "for", "its", "young", "[unused6]", "[SEP]", "[unused1]", "An", "animal", "that", "cares", "for", "its", "young", "but", "shows", "no", "other", "social", "##ity", "traits", "[unused2]", "[unused3]", "to", "be", "[unused4]", "[unused5]", "sub", "##so", "##cial", "[unused6]", "[SEP]", "[unused1]", "An", "animal", "that", "cares", "for", "its", "young", "but", "shows", "no", "other", "social", "##ity", "traits", "[unused2]", "[unused3]", "is", "said", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 29:  {"source": "An original limited artist edition of 250 was published in 1989 and was an oversized fine press slip-cased book with stainless steel faced boards and digital clock inset into the front cover .\n"}
prediction:  {"predictions": [[1, 1760, 1560, 2609, 2360, 2596, 1104, 4805, 2, 3, 1108, 1502, 4, 5, 1107, 2056, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1760, 1560, 2609, 2360, 2596, 1104, 4805, 2, 3, 1108, 4, 5, 1126, 24223, 2503, 3181, 7324, 28137, 14083, 1181, 1520, 1114, 21771, 3649, 3544, 8190, 1105, 3539, 4705, 22233, 2105, 1154, 1103, 1524, 2267, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.033453963696956635, -0.012281082570552826, -0.22265362739562988, -0.22449922561645508, -0.22449922561645508, -0.22449922561645508, -0.22449922561645508, -0.22449922561645508, -0.22449922561645508, -0.22449922561645508], "metadata": {"source_tokens": ["An", "original", "limited", "artist", "edition", "of", "250", "was", "published", "in", "1989", "and", "was", "an", "oversized", "fine", "press", "slip", "##-", "##case", "##d", "book", "with", "stainless", "steel", "faced", "boards", "and", "digital", "clock", "ins", "##et", "into", "the", "front", "cover", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "An", "original", "limited", "artist", "edition", "of", "250", "[unused2]", "[unused3]", "was", "published", "[unused4]", "[unused5]", "in", "1989", "[unused6]", "[SEP]", "[unused1]", "An", "original", "limited", "artist", "edition", "of", "250", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "an", "oversized", "fine", "press", "slip", "##-", "##case", "##d", "book", "with", "stainless", "steel", "faced", "boards", "and", "digital", "clock", "ins", "##et", "into", "the", "front", "cover", "[unused6]", "[SEP]"]]}

input 30:  {"source": "And ABS has formed a partnership with Habitat for Humanity to give a free Bible to each of its new homeowners in the United States .\n"}
prediction:  {"predictions": [[1, 20066, 2, 3, 1144, 1824, 4, 5, 170, 5210, 1114, 11679, 9208, 2980, 1111, 4243, 1785, 1106, 1660, 170, 1714, 5905, 1106, 1296, 1104, 1157, 1207, 1313, 13798, 1468, 1107, 1103, 1244, 1311, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20066, 2, 3, 1144, 1824, 4, 5, 170, 5210, 1114, 11679, 9208, 2980, 1111, 4243, 1785, 1106, 1660, 170, 1714, 5905, 1106, 1296, 1104, 1157, 1207, 1313, 13798, 1468, 1107, 1103, 1244, 1311, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.004014174919575453, -0.046793997287750244, -0.1527407169342041, -0.14599394798278809, -0.14599394798278809, -0.14599394798278809, -0.14599394798278809, -0.14599394798278809, -0.14599394798278809, -0.14599394798278809], "metadata": {"source_tokens": ["And", "ABS", "has", "formed", "a", "partnership", "with", "Ha", "##bit", "##at", "for", "Human", "##ity", "to", "give", "a", "free", "Bible", "to", "each", "of", "its", "new", "home", "##own", "##ers", "in", "the", "United", "States", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "ABS", "[unused2]", "[unused3]", "has", "formed", "[unused4]", "[unused5]", "a", "partnership", "with", "Ha", "##bit", "##at", "for", "Human", "##ity", "to", "give", "a", "free", "Bible", "to", "each", "of", "its", "new", "home", "##own", "##ers", "in", "the", "United", "States", "[unused6]", "[SEP]", "[unused1]", "ABS", "[unused2]", "[unused3]", "has", "formed", "[unused4]", "[unused5]", "a", "partnership", "with", "Ha", "##bit", "##at", "for", "Human", "##ity", "to", "give", "a", "free", "Bible", "to", "each", "of", "its", "new", "home", "##own", "##ers", "in", "the", "United", "States", "[unused6]", "[SEP]"]]}

input 31:  {"source": "And he was in Ali 's army in the Battle of Jamal and later it was Muhammad ibn Abu Bakr who escorted Aisha back to Madina .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1108, 4, 5, 1107, 4149, 112, 1116, 2306, 1107, 1103, 2651, 1104, 27440, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6710, 10452, 8158, 18757, 1377, 1197, 2, 3, 13539, 4, 5, 19294, 5480, 1171, 1106, 10779, 2983, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 6710, 10452, 8158, 18757, 1377, 1197, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.023625940084457397, -0.01750858500599861, -0.022589676082134247, -0.05295133590698242, -0.05327939987182617, -0.05327939987182617, -0.05327939987182617, -0.05327939987182617, -0.05327939987182617, -0.05327939987182617], "metadata": {"source_tokens": ["And", "he", "was", "in", "Ali", "'", "##s", "army", "in", "the", "Battle", "of", "Jamal", "and", "later", "it", "was", "Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "who", "escorted", "Ai", "##sha", "back", "to", "Mad", "##ina", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "in", "Ali", "'", "##s", "army", "in", "the", "Battle", "of", "Jamal", "[unused6]", "[SEP]", "[unused1]", "Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "[unused2]", "[unused3]", "escorted", "[unused4]", "[unused5]", "Ai", "##sha", "back", "to", "Mad", "##ina", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "later", "[unused6]", "[SEP]"]]}

input 32:  {"source": "Andrea Bianco 's atlas of 1436 comprises ten leaves of vellum , measuring , in an 18th-century binding .\n"}
prediction:  {"predictions": [[1, 8326, 139, 1811, 2528, 112, 1116, 1120, 7580, 1104, 17025, 1545, 2, 3, 8302, 4, 5, 1995, 2972, 1104, 1396, 21275, 117, 10099, 117, 1107, 1126, 4186, 28137, 8298, 11366, 7861, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.005636576563119888, -0.21463871002197266, -0.20269250869750977, -0.20269250869750977, -0.20269250869750977, -0.20269250869750977, -0.20269250869750977, -0.20269250869750977, -0.20269250869750977, -0.20269250869750977], "metadata": {"source_tokens": ["Andrea", "B", "##ian", "##co", "'", "##s", "at", "##las", "of", "143", "##6", "comprises", "ten", "leaves", "of", "ve", "##llum", ",", "measuring", ",", "in", "an", "18th", "##-", "##cent", "##ury", "binding", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Andrea", "B", "##ian", "##co", "'", "##s", "at", "##las", "of", "143", "##6", "[unused2]", "[unused3]", "comprises", "[unused4]", "[unused5]", "ten", "leaves", "of", "ve", "##llum", ",", "measuring", ",", "in", "an", "18th", "##-", "##cent", "##ury", "binding", "[unused6]", "[SEP]"]]}

input 33:  {"source": "Apartment buildings , shops , medical clinics , cinemas etc. were built in close proximity to the MAZ plant , providing plant workers with local necessities .\n"}
prediction:  {"predictions": [[1, 10342, 1880, 2275, 117, 7116, 117, 2657, 20562, 117, 27081, 3576, 28138, 2, 3, 1127, 1434, 4, 5, 1107, 1601, 10013, 1106, 1103, 9960, 5301, 2582, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10342, 1880, 2275, 117, 7116, 117, 2657, 20562, 117, 27081, 3576, 28138, 2, 3, 1127, 1434, 4, 5, 1107, 1601, 10013, 1106, 1103, 9960, 5301, 2582, 3558, 2582, 3239, 1114, 1469, 24928, 22371, 4233, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.009219761937856674, -0.07265985012054443, -0.1450493335723877, -0.14502453804016113, -0.14502453804016113, -0.14502453804016113, -0.14502453804016113, -0.14502453804016113, -0.14502453804016113, -0.14502453804016113], "metadata": {"source_tokens": ["Apart", "##ment", "buildings", ",", "shops", ",", "medical", "clinics", ",", "cinemas", "etc", "##.", "were", "built", "in", "close", "proximity", "to", "the", "MA", "##Z", "plant", ",", "providing", "plant", "workers", "with", "local", "ne", "##cess", "##ities", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Apart", "##ment", "buildings", ",", "shops", ",", "medical", "clinics", ",", "cinemas", "etc", "##.", "[unused2]", "[unused3]", "were", "built", "[unused4]", "[unused5]", "in", "close", "proximity", "to", "the", "MA", "##Z", "plant", "[unused6]", "[SEP]", "[unused1]", "Apart", "##ment", "buildings", ",", "shops", ",", "medical", "clinics", ",", "cinemas", "etc", "##.", "[unused2]", "[unused3]", "were", "built", "[unused4]", "[unused5]", "in", "close", "proximity", "to", "the", "MA", "##Z", "plant", "providing", "plant", "workers", "with", "local", "ne", "##cess", "##ities", "[unused6]", "[SEP]"]]}

input 34:  {"source": "Applications can use this service to record activity for a production system while implementations of other OSIDs can use the service to record detailed data during development , debugging , or analyzing performance .\n"}
prediction:  {"predictions": [[1, 20603, 2, 3, 1169, 1329, 4, 5, 1142, 1555, 1106, 1647, 3246, 1111, 170, 1707, 1449, 1229, 7249, 1116, 1104, 1168, 11570, 9949, 1116, 1169, 1329, 1103, 1555, 1106, 1647, 6448, 2233, 1219, 1718, 117, 1260, 7925, 10932, 117, 1137, 23389, 2099, 6, 102, 102, 102, 102, 102, 102, 102, 1, 7249, 1116, 1104, 1168, 11570, 9949, 1116, 2, 3, 1169, 1329, 4, 5, 1103, 1555, 1106, 1647, 6448, 2233, 1219, 1718, 117, 1260, 7925, 10932, 117, 1137, 23389, 2099, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20603, 2, 3, 1169, 1329, 4, 5, 1142, 1555, 1106, 1647, 3246, 1111, 170, 1707, 1449, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02716297097504139, -0.029185259714722633, -0.12545430660247803, -0.2227025032043457, -0.22269606590270996, -0.22269606590270996, -0.22269606590270996, -0.22269606590270996, -0.22269606590270996, -0.22269606590270996], "metadata": {"source_tokens": ["Applications", "can", "use", "this", "service", "to", "record", "activity", "for", "a", "production", "system", "while", "implementation", "##s", "of", "other", "OS", "##ID", "##s", "can", "use", "the", "service", "to", "record", "detailed", "data", "during", "development", ",", "de", "##bu", "##gging", ",", "or", "analyzing", "performance", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Applications", "[unused2]", "[unused3]", "can", "use", "[unused4]", "[unused5]", "this", "service", "to", "record", "activity", "for", "a", "production", "system", "while", "implementation", "##s", "of", "other", "OS", "##ID", "##s", "can", "use", "the", "service", "to", "record", "detailed", "data", "during", "development", ",", "de", "##bu", "##gging", ",", "or", "analyzing", "performance", "[unused6]", "[SEP]", "[unused1]", "implementation", "##s", "of", "other", "OS", "##ID", "##s", "[unused2]", "[unused3]", "can", "use", "[unused4]", "[unused5]", "the", "service", "to", "record", "detailed", "data", "during", "development", ",", "de", "##bu", "##gging", ",", "or", "analyzing", "performance", "[unused6]", "[SEP]", "[unused1]", "Applications", "[unused2]", "[unused3]", "can", "use", "[unused4]", "[unused5]", "this", "service", "to", "record", "activity", "for", "a", "production", "system", "[unused6]", "[SEP]"]]}

input 35:  {"source": "Applying this technique facilitates the connection of the center of the foot with the lower abdomen .\n"}
prediction:  {"predictions": [[1, 138, 8661, 15318, 1142, 5531, 2, 3, 11000, 1116, 4, 5, 1103, 3797, 1104, 1103, 2057, 1104, 1103, 2555, 1114, 1103, 2211, 14701, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0006884978502057493, -0.002955913543701172, -0.0029535293579101562, -0.0029535293579101562, -0.0029535293579101562, -0.0029535293579101562, -0.0029535293579101562, -0.0029535293579101562, -0.0029535293579101562, -0.0029535293579101562], "metadata": {"source_tokens": ["A", "##pp", "##lying", "this", "technique", "facilitate", "##s", "the", "connection", "of", "the", "center", "of", "the", "foot", "with", "the", "lower", "abdomen", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "##pp", "##lying", "this", "technique", "[unused2]", "[unused3]", "facilitate", "##s", "[unused4]", "[unused5]", "the", "connection", "of", "the", "center", "of", "the", "foot", "with", "the", "lower", "abdomen", "[unused6]", "[SEP]"]]}

input 36:  {"source": "As Attorney General he clashed with Daniel O'Connell when he insisted , against O'Connell 's wishes , on the appointment of Abraham Brewster as Law Adviser to the Lord Lieutenant of Ireland .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 25144, 4, 5, 1114, 2979, 152, 28131, 1658, 26823, 1165, 1119, 6744, 117, 1222, 152, 28131, 1658, 26823, 112, 1116, 8921, 117, 1113, 1103, 5516, 1104, 7752, 25673, 1112, 2601, 24930, 16641, 1197, 1106, 1103, 2188, 3897, 1104, 2270, 6, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 6744, 4, 5, 1222, 152, 28131, 1658, 26823, 112, 1116, 8921, 1113, 1103, 5516, 1104, 7752, 25673, 1112, 2601, 24930, 16641, 1197, 1106, 1103, 2188, 3897, 1104, 2270, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 6744, 4, 5, 1222, 152, 28131, 1658, 26823, 112, 1116, 8921, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.01753942482173443, -0.0654873251914978, -0.19573001563549042, -0.22291350364685059, -0.22290897369384766, -0.22290897369384766, -0.22290897369384766, -0.22290897369384766, -0.22290897369384766, -0.22290897369384766], "metadata": {"source_tokens": ["As", "Attorney", "General", "he", "clashed", "with", "Daniel", "O", "##'", "##C", "##onnell", "when", "he", "insisted", ",", "against", "O", "##'", "##C", "##onnell", "'", "##s", "wishes", ",", "on", "the", "appointment", "of", "Abraham", "Brewster", "as", "Law", "Ad", "##vise", "##r", "to", "the", "Lord", "Lieutenant", "of", "Ireland", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "clashed", "[unused4]", "[unused5]", "with", "Daniel", "O", "##'", "##C", "##onnell", "when", "he", "insisted", ",", "against", "O", "##'", "##C", "##onnell", "'", "##s", "wishes", ",", "on", "the", "appointment", "of", "Abraham", "Brewster", "as", "Law", "Ad", "##vise", "##r", "to", "the", "Lord", "Lieutenant", "of", "Ireland", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "insisted", "[unused4]", "[unused5]", "against", "O", "##'", "##C", "##onnell", "'", "##s", "wishes", "on", "the", "appointment", "of", "Abraham", "Brewster", "as", "Law", "Ad", "##vise", "##r", "to", "the", "Lord", "Lieutenant", "of", "Ireland", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "insisted", "[unused4]", "[unused5]", "against", "O", "##'", "##C", "##onnell", "'", "##s", "wishes", "[unused6]", "[SEP]"]]}

input 37:  {"source": "As a group , the team was enshrined into the Basketball Hall of Fame in 1959 .\n"}
prediction:  {"predictions": [[1, 1103, 1264, 2, 3, 1108, 4035, 2737, 8643, 1181, 4, 5, 1154, 1103, 6035, 1944, 1104, 4710, 1107, 3003, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0008475022041238844, -0.152970552444458, -0.1529529094696045, -0.1529529094696045, -0.1529529094696045, -0.1529529094696045, -0.1529529094696045, -0.1529529094696045, -0.1529529094696045, -0.1529529094696045], "metadata": {"source_tokens": ["As", "a", "group", ",", "the", "team", "was", "en", "##sh", "##rine", "##d", "into", "the", "Basketball", "Hall", "of", "Fame", "in", "1959", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "team", "[unused2]", "[unused3]", "was", "en", "##sh", "##rine", "##d", "[unused4]", "[unused5]", "into", "the", "Basketball", "Hall", "of", "Fame", "in", "1959", "[unused6]", "[SEP]"]]}

input 38:  {"source": "As a result , it becomes clear that the microbe can not survive outside a narrow pH range .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 3316, 4, 5, 2330, 1115, 1103, 17599, 3962, 1169, 1136, 5195, 1796, 170, 4142, 20149, 2079, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 17599, 3962, 2, 3, 1169, 1136, 5195, 4, 5, 1796, 170, 4142, 20149, 2079, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0055006202310323715, -0.016586847603321075, -0.008249759674072266, -0.00870060920715332, -0.00870060920715332, -0.00870060920715332, -0.00870060920715332, -0.00870060920715332, -0.00870060920715332, -0.00870060920715332], "metadata": {"source_tokens": ["As", "a", "result", ",", "it", "becomes", "clear", "that", "the", "micro", "##be", "can", "not", "survive", "outside", "a", "narrow", "pH", "range", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "becomes", "[unused4]", "[unused5]", "clear", "that", "the", "micro", "##be", "can", "not", "survive", "outside", "a", "narrow", "pH", "range", "[unused6]", "[SEP]", "[unused1]", "the", "micro", "##be", "[unused2]", "[unused3]", "can", "not", "survive", "[unused4]", "[unused5]", "outside", "a", "narrow", "pH", "range", "[unused6]", "[SEP]"]]}

input 39:  {"source": "As a result , the lower river had to be dredged three times in two years .\n"}
prediction:  {"predictions": [[1, 1103, 2211, 2186, 2, 3, 1106, 1129, 173, 4359, 3660, 4, 5, 1210, 1551, 1107, 1160, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.001235699630342424, -0.1536712646484375, -0.153778076171875, -0.153778076171875, -0.153778076171875, -0.153778076171875, -0.153778076171875, -0.153778076171875, -0.153778076171875, -0.153778076171875], "metadata": {"source_tokens": ["As", "a", "result", ",", "the", "lower", "river", "had", "to", "be", "d", "##red", "##ged", "three", "times", "in", "two", "years", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "lower", "river", "[unused2]", "[unused3]", "to", "be", "d", "##red", "##ged", "[unused4]", "[unused5]", "three", "times", "in", "two", "years", "[unused6]", "[SEP]"]]}

input 40:  {"source": "As early as the 15th century , the French kings sent commissioners to the provinces to inspect on royal and administrative affairs and to take necessary action .\n"}
prediction:  {"predictions": [[1, 1103, 1497, 9419, 2, 3, 1850, 4, 5, 22207, 1106, 1103, 7112, 1106, 25151, 1113, 4276, 1105, 3207, 5707, 1105, 1106, 1321, 3238, 2168, 1249, 1346, 1112, 1103, 5617, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1497, 9419, 2, 3, 1850, 4, 5, 22207, 1106, 25151, 1113, 4276, 1105, 3207, 5707, 1105, 1106, 1321, 3238, 2168, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.009526027366518974, -0.05084535852074623, -0.1446535587310791, -0.1444082260131836, -0.1444082260131836, -0.1444082260131836, -0.1444082260131836, -0.1444082260131836, -0.1444082260131836, -0.1444082260131836], "metadata": {"source_tokens": ["As", "early", "as", "the", "15th", "century", ",", "the", "French", "kings", "sent", "commissioners", "to", "the", "provinces", "to", "inspect", "on", "royal", "and", "administrative", "affairs", "and", "to", "take", "necessary", "action", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "French", "kings", "[unused2]", "[unused3]", "sent", "[unused4]", "[unused5]", "commissioners", "to", "the", "provinces", "to", "inspect", "on", "royal", "and", "administrative", "affairs", "and", "to", "take", "necessary", "action", "As", "early", "as", "the", "15th", "century", "[unused6]", "[SEP]", "[unused1]", "the", "French", "kings", "[unused2]", "[unused3]", "sent", "[unused4]", "[unused5]", "commissioners", "to", "inspect", "on", "royal", "and", "administrative", "affairs", "and", "to", "take", "necessary", "action", "[unused6]", "[SEP]"]]}

input 41:  {"source": "As in his first novel , Armah contrasts the two worlds of materialism and moral values , corruption and dreams , two worlds of integrity and social pressure .\n"}
prediction:  {"predictions": [[1, 24446, 3354, 2, 3, 26856, 4, 5, 1103, 1160, 11308, 1104, 2578, 1863, 1105, 7279, 4718, 117, 8065, 1105, 6149, 117, 1160, 11308, 1104, 12363, 1105, 1934, 2997, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.004019283689558506, -0.15808963775634766, -0.1627178192138672, -0.1627178192138672, -0.1627178192138672, -0.1627178192138672, -0.1627178192138672, -0.1627178192138672, -0.1627178192138672, -0.1627178192138672], "metadata": {"source_tokens": ["As", "in", "his", "first", "novel", ",", "Arm", "##ah", "contrasts", "the", "two", "worlds", "of", "material", "##ism", "and", "moral", "values", ",", "corruption", "and", "dreams", ",", "two", "worlds", "of", "integrity", "and", "social", "pressure", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Arm", "##ah", "[unused2]", "[unused3]", "contrasts", "[unused4]", "[unused5]", "the", "two", "worlds", "of", "material", "##ism", "and", "moral", "values", ",", "corruption", "and", "dreams", ",", "two", "worlds", "of", "integrity", "and", "social", "pressure", "[unused6]", "[SEP]"]]}

input 42:  {"source": "As is true for all sensors , absolute accuracy of a measurement requires a functionality for calibration .\n"}
prediction:  {"predictions": [[1, 7846, 10893, 1104, 170, 11842, 2, 3, 5315, 4, 5, 170, 16354, 1111, 11019, 2646, 6766, 2116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0008911431068554521, -0.05583548545837402, -0.05584883689880371, -0.05584883689880371, -0.05584883689880371, -0.05584883689880371, -0.05584883689880371, -0.05584883689880371, -0.05584883689880371, -0.05584883689880371], "metadata": {"source_tokens": ["As", "is", "true", "for", "all", "sensors", ",", "absolute", "accuracy", "of", "a", "measurement", "requires", "a", "functionality", "for", "ca", "##li", "##bra", "##tion", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "absolute", "accuracy", "of", "a", "measurement", "[unused2]", "[unused3]", "requires", "[unused4]", "[unused5]", "a", "functionality", "for", "ca", "##li", "##bra", "##tion", "[unused6]", "[SEP]"]]}

input 43:  {"source": "As of `` A Wind in the Door '' , Sandy aspires to become a banker , on the grounds that it is practical and lucrative .\n"}
prediction:  {"predictions": [[1, 9908, 2, 3, 1112, 20082, 1116, 4, 5, 1106, 1561, 170, 15304, 117, 1113, 1103, 4745, 1115, 1122, 1110, 6691, 1105, 23284, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 4, 5, 6691, 1105, 23284, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9908, 2, 3, 1112, 20082, 1116, 4, 5, 1106, 1561, 170, 15304, 1249, 1104, 138, 7943, 1107, 1103, 15087, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.05696060135960579, -0.052305448800325394, -0.0665842816233635, -0.2226409912109375, -0.2226409912109375, -0.2226409912109375, -0.2226409912109375, -0.2226409912109375, -0.2226409912109375, -0.2226409912109375], "metadata": {"source_tokens": ["As", "of", "`", "##`", "A", "Wind", "in", "the", "Door", "'", "##'", ",", "Sandy", "as", "##pire", "##s", "to", "become", "a", "banker", ",", "on", "the", "grounds", "that", "it", "is", "practical", "and", "lucrative", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sandy", "[unused2]", "[unused3]", "as", "##pire", "##s", "[unused4]", "[unused5]", "to", "become", "a", "banker", ",", "on", "the", "grounds", "that", "it", "is", "practical", "and", "lucrative", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "practical", "and", "lucrative", "[unused6]", "[SEP]", "[unused1]", "Sandy", "[unused2]", "[unused3]", "as", "##pire", "##s", "[unused4]", "[unused5]", "to", "become", "a", "banker", "As", "of", "A", "Wind", "in", "the", "Door", "[unused6]", "[SEP]"]]}

input 44:  {"source": "As part of several efforts to have the Gypsy Horse recognized as a breed outside the Romanichal community , a more descriptive name was sought for it , starting in the 1990s .\n"}
prediction:  {"predictions": [[1, 170, 1167, 27938, 1271, 2, 3, 1108, 4110, 4, 5, 1111, 1122, 2547, 1107, 1103, 3281, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 22153, 7429, 2, 3, 3037, 4, 5, 1112, 170, 9489, 1796, 1103, 27876, 17436, 1661, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.027497021481394768, -0.009569055400788784, -0.22274160385131836, -0.22271084785461426, -0.22271084785461426, -0.22271084785461426, -0.22271084785461426, -0.22271084785461426, -0.22271084785461426, -0.22271084785461426], "metadata": {"source_tokens": ["As", "part", "of", "several", "efforts", "to", "have", "the", "Gypsy", "Horse", "recognized", "as", "a", "breed", "outside", "the", "Romani", "##chal", "community", ",", "a", "more", "descriptive", "name", "was", "sought", "for", "it", ",", "starting", "in", "the", "1990s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "more", "descriptive", "name", "[unused2]", "[unused3]", "was", "sought", "[unused4]", "[unused5]", "for", "it", "starting", "in", "the", "1990s", "[unused6]", "[SEP]", "[unused1]", "the", "Gypsy", "Horse", "[unused2]", "[unused3]", "recognized", "[unused4]", "[unused5]", "as", "a", "breed", "outside", "the", "Romani", "##chal", "community", "[unused6]", "[SEP]"]]}

input 45:  {"source": "Assisting in the recording process were Fernando Cabello and two friends of the group , Eva Dalda and Lydia Iovanne .\n"}
prediction:  {"predictions": [[1, 1249, 22398, 1158, 1107, 1103, 2730, 1965, 2, 3, 1127, 4, 5, 8834, 140, 22377, 6643, 1105, 1160, 2053, 1104, 1103, 1372, 117, 9734, 25938, 1810, 1105, 14639, 146, 8625, 10934, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.021378222852945328, -0.008704185485839844, -0.033477783203125, -0.033477783203125, -0.033477783203125, -0.033477783203125, -0.033477783203125, -0.033477783203125, -0.033477783203125, -0.033477783203125], "metadata": {"source_tokens": ["As", "##sist", "##ing", "in", "the", "recording", "process", "were", "Fernando", "C", "##abe", "##llo", "and", "two", "friends", "of", "the", "group", ",", "Eva", "Dal", "##da", "and", "Lydia", "I", "##ova", "##nne", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "As", "##sist", "##ing", "in", "the", "recording", "process", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "Fernando", "C", "##abe", "##llo", "and", "two", "friends", "of", "the", "group", ",", "Eva", "Dal", "##da", "and", "Lydia", "I", "##ova", "##nne", "[unused6]", "[SEP]"]]}

input 46:  {"source": "At a presentation in the Toronto Pearson International Airport hangar , Celine Dion helped the newly solvent airline debut its new image .\n"}
prediction:  {"predictions": [[1, 24664, 2568, 21322, 2, 3, 2375, 4, 5, 1103, 3599, 27624, 8694, 1963, 1157, 1207, 3077, 1335, 170, 8685, 1107, 1103, 3506, 13079, 1570, 3369, 22043, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3599, 27624, 8694, 2, 3, 1963, 4, 5, 1157, 1207, 3077, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0009761020774021745, -0.037825360894203186, -0.14505267143249512, -0.14505267143249512, -0.14505267143249512, -0.14505267143249512, -0.14505267143249512, -0.14505267143249512, -0.14505267143249512, -0.14505267143249512], "metadata": {"source_tokens": ["At", "a", "presentation", "in", "the", "Toronto", "Pearson", "International", "Airport", "hangar", ",", "Ce", "##line", "Dion", "helped", "the", "newly", "solvent", "airline", "debut", "its", "new", "image", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ce", "##line", "Dion", "[unused2]", "[unused3]", "helped", "[unused4]", "[unused5]", "the", "newly", "solvent", "airline", "debut", "its", "new", "image", "At", "a", "presentation", "in", "the", "Toronto", "Pearson", "International", "Airport", "hangar", "[unused6]", "[SEP]", "[unused1]", "the", "newly", "solvent", "airline", "[unused2]", "[unused3]", "debut", "[unused4]", "[unused5]", "its", "new", "image", "[unused6]", "[SEP]"]]}

input 47:  {"source": "At least 11 villagers disappeared and 8 people were killed in the ensuing tsunami , two of which are prisoners at one of the Permisan prisons .\n"}
prediction:  {"predictions": [[1, 1335, 1655, 1429, 12453, 2, 3, 4712, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 129, 1234, 2, 3, 1127, 1841, 4, 5, 1107, 1103, 14332, 24212, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1160, 1104, 1134, 2, 3, 1132, 4, 5, 5419, 1120, 1141, 1104, 1103, 14286, 15394, 1389, 20070, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.027972975745797157, -0.046459633857011795, -0.028216833248734474, -0.02898550033569336, -0.03279519081115723, -0.03279519081115723, -0.03279519081115723, -0.03279519081115723, -0.03279519081115723, -0.03279519081115723], "metadata": {"source_tokens": ["At", "least", "11", "villagers", "disappeared", "and", "8", "people", "were", "killed", "in", "the", "ensuing", "tsunami", ",", "two", "of", "which", "are", "prisoners", "at", "one", "of", "the", "Per", "##mis", "##an", "prisons", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "At", "least", "11", "villagers", "[unused2]", "[unused3]", "disappeared", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "8", "people", "[unused2]", "[unused3]", "were", "killed", "[unused4]", "[unused5]", "in", "the", "ensuing", "tsunami", "[unused6]", "[SEP]", "[unused1]", "two", "of", "which", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "prisoners", "at", "one", "of", "the", "Per", "##mis", "##an", "prisons", "[unused6]", "[SEP]"]]}

input 48:  {"source": "At no cost to the parents , these services are provided in compliance with state and federal law ; and are reasonably calculated to yield meaningful educational benefit and student progress .\n"}
prediction:  {"predictions": [[1, 1292, 1826, 2, 3, 1132, 2136, 4, 5, 1107, 14037, 1114, 1352, 1105, 2877, 1644, 1335, 1185, 2616, 1106, 1103, 2153, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1292, 1826, 2, 3, 1132, 10056, 4, 5, 1106, 10972, 17119, 4339, 5257, 1105, 2377, 5070, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1292, 1826, 2, 3, 1132, 10056, 4, 5, 1106, 10972, 17119, 4339, 5257, 1105, 2377, 5070, 17517, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.004514096770435572, -0.04432404786348343, -0.07236476987600327, -0.14500737190246582, -0.1449117660522461, -0.1449117660522461, -0.1449117660522461, -0.1449117660522461, -0.1449117660522461, -0.1449117660522461], "metadata": {"source_tokens": ["At", "no", "cost", "to", "the", "parents", ",", "these", "services", "are", "provided", "in", "compliance", "with", "state", "and", "federal", "law", ";", "and", "are", "reasonably", "calculated", "to", "yield", "meaningful", "educational", "benefit", "and", "student", "progress", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "these", "services", "[unused2]", "[unused3]", "are", "provided", "[unused4]", "[unused5]", "in", "compliance", "with", "state", "and", "federal", "law", "At", "no", "cost", "to", "the", "parents", "[unused6]", "[SEP]", "[unused1]", "these", "services", "[unused2]", "[unused3]", "are", "calculated", "[unused4]", "[unused5]", "to", "yield", "meaningful", "educational", "benefit", "and", "student", "progress", "[unused6]", "[SEP]", "[unused1]", "these", "services", "[unused2]", "[unused3]", "are", "calculated", "[unused4]", "[unused5]", "to", "yield", "meaningful", "educational", "benefit", "and", "student", "progress", "reasonably", "[unused6]", "[SEP]"]]}

input 49:  {"source": "At one point , Ballard is nearly possessed , but resists when she is given a drug and discovers that the spirits are attacking them as they believe that the humans are invaders and plan to exterminate the humans on Mars .\n"}
prediction:  {"predictions": [[1, 24241, 2, 3, 9345, 1116, 4, 5, 1165, 1131, 1110, 1549, 170, 3850, 1105, 9149, 1115, 1103, 9494, 1132, 7492, 1172, 1112, 1152, 2059, 1115, 1103, 3612, 1132, 22864, 1105, 2197, 1106, 4252, 2083, 17379, 1103, 3612, 1113, 7403, 1335, 1141, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 1, 24241, 2, 3, 1110, 8471, 4, 5, 1335, 1141, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 24241, 2, 3, 1110, 8471, 4, 5, 2212, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1110, 1549, 4, 5, 170, 3850, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1110, 1549, 4, 5, 170, 3850, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 9149, 4, 5, 1115, 1103, 9494, 1132, 7492, 1172, 1112, 1152, 2059, 1115, 1103, 3612, 1132, 22864, 1105, 2197, 1106, 4252, 2083, 17379, 1103, 3612, 1113, 7403, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 2059, 4, 5, 1115, 1103, 3612, 1132, 22864, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 9494, 2, 3, 1132, 7492, 4, 5, 1172, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03466999903321266, -0.14986377954483032, -0.23522023856639862, -0.07442415505647659, -0.2081853598356247, -0.07531321793794632, -0.14906875789165497, -0.2635398209095001, -0.22266626358032227, -0.22266602516174316], "metadata": {"source_tokens": ["At", "one", "point", ",", "Ballard", "is", "nearly", "possessed", ",", "but", "resist", "##s", "when", "she", "is", "given", "a", "drug", "and", "discovers", "that", "the", "spirits", "are", "attacking", "them", "as", "they", "believe", "that", "the", "humans", "are", "invaders", "and", "plan", "to", "ex", "##ter", "##minate", "the", "humans", "on", "Mars", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ballard", "[unused2]", "[unused3]", "resist", "##s", "[unused4]", "[unused5]", "when", "she", "is", "given", "a", "drug", "and", "discovers", "that", "the", "spirits", "are", "attacking", "them", "as", "they", "believe", "that", "the", "humans", "are", "invaders", "and", "plan", "to", "ex", "##ter", "##minate", "the", "humans", "on", "Mars", "At", "one", "point", "[unused6]", "[SEP]", "[unused1]", "Ballard", "[unused2]", "[unused3]", "is", "possessed", "[unused4]", "[unused5]", "At", "one", "point", "[unused6]", "[SEP]", "[unused1]", "Ballard", "[unused2]", "[unused3]", "is", "possessed", "[unused4]", "[unused5]", "nearly", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "is", "given", "[unused4]", "[unused5]", "a", "drug", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "is", "given", "[unused4]", "[unused5]", "a", "drug", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "discovers", "[unused4]", "[unused5]", "that", "the", "spirits", "are", "attacking", "them", "as", "they", "believe", "that", "the", "humans", "are", "invaders", "and", "plan", "to", "ex", "##ter", "##minate", "the", "humans", "on", "Mars", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "believe", "[unused4]", "[unused5]", "that", "the", "humans", "are", "invaders", "[unused6]", "[SEP]", "[unused1]", "the", "spirits", "[unused2]", "[unused3]", "are", "attacking", "[unused4]", "[unused5]", "them", "[unused6]", "[SEP]"]]}

input 50:  {"source": "Barbara , however , unable to leave behind her vigilante life , fought a mugger and ultimately miscarried her child .\n"}
prediction:  {"predictions": [[1, 5934, 3372, 1106, 1817, 1481, 1123, 191, 24874, 26093, 1297, 2, 3, 3214, 4, 5, 170, 15761, 2895, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5934, 3372, 1106, 1817, 1481, 1123, 191, 24874, 26093, 1297, 2, 3, 1940, 26996, 18888, 4, 5, 1123, 2027, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.039318472146987915, -0.10909803211688995, -0.15494704246520996, -0.14959931373596191, -0.14959931373596191, -0.14959931373596191, -0.14959931373596191, -0.14959931373596191, -0.14959931373596191, -0.14959931373596191], "metadata": {"source_tokens": ["Barbara", ",", "however", ",", "unable", "to", "leave", "behind", "her", "v", "##igi", "##lante", "life", ",", "fought", "a", "mug", "##ger", "and", "ultimately", "mi", "##sca", "##rried", "her", "child", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Barbara", "unable", "to", "leave", "behind", "her", "v", "##igi", "##lante", "life", "[unused2]", "[unused3]", "fought", "[unused4]", "[unused5]", "a", "mug", "##ger", "[unused6]", "[SEP]", "[unused1]", "Barbara", "unable", "to", "leave", "behind", "her", "v", "##igi", "##lante", "life", "[unused2]", "[unused3]", "mi", "##sca", "##rried", "[unused4]", "[unused5]", "her", "child", "[unused6]", "[SEP]"]]}

input 51:  {"source": "Because Yesler Way marks the boundary between two different plats , the street grid north of Yesler does not line up with the neighborhood 's other streets , so the northern `` border '' of the district zigzags along numerous streets .\n"}
prediction:  {"predictions": [[1, 2160, 2879, 4714, 2, 3, 6216, 4, 5, 1103, 5904, 1206, 1160, 1472, 185, 16236, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2472, 8866, 1564, 1104, 2160, 2879, 2, 3, 1674, 1136, 1413, 1146, 4, 5, 1114, 1103, 4532, 112, 1116, 1168, 4324, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2350, 169, 28152, 3070, 112, 28131, 1104, 1103, 1629, 2, 3, 195, 6512, 3293, 5700, 4, 5, 1373, 2567, 4324, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.05307266488671303, -0.02469281107187271, -0.06705617159605026, -0.23990225791931152, -0.2488255500793457, -0.2488255500793457, -0.2488255500793457, -0.2488255500793457, -0.2488255500793457, -0.2488255500793457], "metadata": {"source_tokens": ["Because", "Yes", "##ler", "Way", "marks", "the", "boundary", "between", "two", "different", "p", "##lat", "##s", ",", "the", "street", "grid", "north", "of", "Yes", "##ler", "does", "not", "line", "up", "with", "the", "neighborhood", "'", "##s", "other", "streets", ",", "so", "the", "northern", "`", "##`", "border", "'", "##'", "of", "the", "district", "z", "##ig", "##za", "##gs", "along", "numerous", "streets", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Yes", "##ler", "Way", "[unused2]", "[unused3]", "marks", "[unused4]", "[unused5]", "the", "boundary", "between", "two", "different", "p", "##lat", "##s", "[unused6]", "[SEP]", "[unused1]", "the", "street", "grid", "north", "of", "Yes", "##ler", "[unused2]", "[unused3]", "does", "not", "line", "up", "[unused4]", "[unused5]", "with", "the", "neighborhood", "'", "##s", "other", "streets", "[unused6]", "[SEP]", "[unused1]", "the", "northern", "`", "##`", "border", "'", "##'", "of", "the", "district", "[unused2]", "[unused3]", "z", "##ig", "##za", "##gs", "[unused4]", "[unused5]", "along", "numerous", "streets", "[unused6]", "[SEP]"]]}

input 52:  {"source": "Because of Muhammad 's role in its formation , the alliance plays a significant role in Islamic ethics .\n"}
prediction:  {"predictions": [[1, 1103, 7214, 2, 3, 2399, 4, 5, 170, 2418, 1648, 1107, 4769, 13438, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0011072754859924316, -0.005129337310791016, -0.0055408477783203125, -0.0055408477783203125, -0.0055408477783203125, -0.0055408477783203125, -0.0055408477783203125, -0.0055408477783203125, -0.0055408477783203125, -0.0055408477783203125], "metadata": {"source_tokens": ["Because", "of", "Muhammad", "'", "##s", "role", "in", "its", "formation", ",", "the", "alliance", "plays", "a", "significant", "role", "in", "Islamic", "ethics", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "alliance", "[unused2]", "[unused3]", "plays", "[unused4]", "[unused5]", "a", "significant", "role", "in", "Islamic", "ethics", "[unused6]", "[SEP]"]]}

input 53:  {"source": "Because of his talents and training , Beast can outperform any Olympic-level athlete , contorting his body and performing aerial feats gracefully .\n"}
prediction:  {"predictions": [[1, 11868, 2, 3, 1169, 1149, 3365, 13199, 4, 5, 1251, 3557, 28137, 23403, 1883, 8765, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11868, 2, 3, 1169, 1149, 3365, 13199, 1251, 3557, 28137, 23403, 1883, 8765, 14255, 2772, 1916, 4, 5, 1117, 1404, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11868, 2, 3, 1169, 1149, 3365, 13199, 4, 5, 1251, 3557, 28137, 23403, 1883, 8765, 14255, 2772, 1916, 1117, 1404, 1105, 4072, 10485, 8809, 1116, 21620, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.027274953201413155, -0.07565343379974365, -0.06742460280656815, -0.1459660530090332, -0.14550995826721191, -0.14550995826721191, -0.14550995826721191, -0.14550995826721191, -0.14550995826721191, -0.14550995826721191], "metadata": {"source_tokens": ["Because", "of", "his", "talents", "and", "training", ",", "Beast", "can", "out", "##per", "##form", "any", "Olympic", "##-", "##lev", "##el", "athlete", ",", "con", "##tor", "##ting", "his", "body", "and", "performing", "aerial", "feat", "##s", "graceful", "##ly", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Beast", "[unused2]", "[unused3]", "can", "out", "##per", "##form", "[unused4]", "[unused5]", "any", "Olympic", "##-", "##lev", "##el", "athlete", "[unused6]", "[SEP]", "[unused1]", "Beast", "[unused2]", "[unused3]", "can", "out", "##per", "##form", "any", "Olympic", "##-", "##lev", "##el", "athlete", "con", "##tor", "##ting", "[unused4]", "[unused5]", "his", "body", "[unused6]", "[SEP]", "[unused1]", "Beast", "[unused2]", "[unused3]", "can", "out", "##per", "##form", "[unused4]", "[unused5]", "any", "Olympic", "##-", "##lev", "##el", "athlete", "con", "##tor", "##ting", "his", "body", "and", "performing", "aerial", "feat", "##s", "graceful", "##ly", "[unused6]", "[SEP]"]]}

input 54:  {"source": "Bruce 's Justice Lord counterpart was happily married to Wonder Woman as well until her Justice Lord counterpart killed him .\n"}
prediction:  {"predictions": [[1, 4767, 112, 1116, 3302, 2188, 14132, 2, 3, 1108, 11786, 4, 5, 1597, 1106, 10991, 5651, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1123, 3302, 2188, 14132, 2, 3, 1841, 4, 5, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.08030765503644943, -0.016385097056627274, -0.14502835273742676, -0.14502525329589844, -0.14502525329589844, -0.14502525329589844, -0.14502525329589844, -0.14502525329589844, -0.14502525329589844, -0.14502525329589844], "metadata": {"source_tokens": ["Bruce", "'", "##s", "Justice", "Lord", "counterpart", "was", "happily", "married", "to", "Wonder", "Woman", "as", "well", "until", "her", "Justice", "Lord", "counterpart", "killed", "him", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Bruce", "'", "##s", "Justice", "Lord", "counterpart", "[unused2]", "[unused3]", "was", "happily", "[unused4]", "[unused5]", "married", "to", "Wonder", "Woman", "[unused6]", "[SEP]", "[unused1]", "her", "Justice", "Lord", "counterpart", "[unused2]", "[unused3]", "killed", "[unused4]", "[unused5]", "him", "[unused6]", "[SEP]"]]}

input 55:  {"source": "Burnham died of heart failure at the age of 86 , on September 1 , 1947 at his home in Santa , Barbara , California .\n"}
prediction:  {"predictions": [[1, 16915, 2522, 2, 3, 1452, 4, 5, 1104, 1762, 4290, 1120, 1103, 1425, 1104, 5942, 1113, 1347, 122, 3138, 1120, 1117, 1313, 1107, 3364, 117, 5934, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16915, 2522, 2, 3, 1452, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.06700773537158966, -0.07061926275491714, -0.22264719009399414, -0.22264719009399414, -0.22264719009399414, -0.22264719009399414, -0.22264719009399414, -0.22264719009399414, -0.22264719009399414, -0.22264719009399414], "metadata": {"source_tokens": ["Burn", "##ham", "died", "of", "heart", "failure", "at", "the", "age", "of", "86", ",", "on", "September", "1", ",", "1947", "at", "his", "home", "in", "Santa", ",", "Barbara", ",", "California", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Burn", "##ham", "[unused2]", "[unused3]", "died", "[unused4]", "[unused5]", "of", "heart", "failure", "at", "the", "age", "of", "86", "on", "September", "1", "1947", "at", "his", "home", "in", "Santa", ",", "Barbara", "[unused6]", "[SEP]", "[unused1]", "Burn", "##ham", "[unused2]", "[unused3]", "died", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 56:  {"source": "But this practice simply reduces government interest costs rather than truly canceling government debt , and can result in hyperinflation if used unsparingly .\n"}
prediction:  {"predictions": [[1, 1142, 2415, 2, 3, 2566, 13822, 4, 5, 1433, 2199, 4692, 1897, 1190, 5098, 19722, 1158, 1433, 6695, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1142, 2415, 2, 3, 1169, 1871, 4, 5, 1107, 177, 24312, 1394, 2087, 6840, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1142, 2415, 2, 3, 1169, 1871, 4, 5, 1107, 177, 24312, 1394, 2087, 6840, 1191, 1215, 8362, 20080, 10832, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03787704184651375, -0.033602770417928696, -0.02162141352891922, -0.2037062644958496, -0.19663476943969727, -0.19663476943969727, -0.19663476943969727, -0.19663476943969727, -0.19663476943969727, -0.19663476943969727], "metadata": {"source_tokens": ["But", "this", "practice", "simply", "reduces", "government", "interest", "costs", "rather", "than", "truly", "cancel", "##ing", "government", "debt", ",", "and", "can", "result", "in", "h", "##yper", "##in", "##f", "##lation", "if", "used", "un", "##sp", "##aring", "##ly", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "this", "practice", "[unused2]", "[unused3]", "simply", "reduces", "[unused4]", "[unused5]", "government", "interest", "costs", "rather", "than", "truly", "cancel", "##ing", "government", "debt", "[unused6]", "[SEP]", "[unused1]", "this", "practice", "[unused2]", "[unused3]", "can", "result", "[unused4]", "[unused5]", "in", "h", "##yper", "##in", "##f", "##lation", "[unused6]", "[SEP]", "[unused1]", "this", "practice", "[unused2]", "[unused3]", "can", "result", "[unused4]", "[unused5]", "in", "h", "##yper", "##in", "##f", "##lation", "if", "used", "un", "##sp", "##aring", "##ly", "[unused6]", "[SEP]"]]}

input 57:  {"source": "By then , she was raising not only her own children but also her nephews , who had been orphaned by the plague .\n"}
prediction:  {"predictions": [[1, 1131, 2, 3, 1108, 5920, 4, 5, 1136, 1178, 1123, 1319, 1482, 1133, 1145, 1123, 7502, 1116, 1650, 1173, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1145, 1123, 7502, 1116, 2, 3, 1125, 1151, 25298, 1174, 4, 5, 1118, 1103, 13824, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02708190120756626, -0.04073077440261841, -0.05176281929016113, -0.051763296127319336, -0.051763296127319336, -0.051763296127319336, -0.051763296127319336, -0.051763296127319336, -0.051763296127319336, -0.051763296127319336], "metadata": {"source_tokens": ["By", "then", ",", "she", "was", "raising", "not", "only", "her", "own", "children", "but", "also", "her", "nephew", "##s", ",", "who", "had", "been", "orphan", "##ed", "by", "the", "plague", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "she", "[unused2]", "[unused3]", "was", "raising", "[unused4]", "[unused5]", "not", "only", "her", "own", "children", "but", "also", "her", "nephew", "##s", "By", "then", "[unused6]", "[SEP]", "[unused1]", "also", "her", "nephew", "##s", "[unused2]", "[unused3]", "had", "been", "orphan", "##ed", "[unused4]", "[unused5]", "by", "the", "plague", "[unused6]", "[SEP]"]]}

input 58:  {"source": "By this point , Simpson had returned to his mansion in Brentwood and had surrendered to police .\n"}
prediction:  {"predictions": [[1, 8989, 2, 3, 1125, 1608, 4, 5, 1106, 1117, 8280, 1107, 13150, 2615, 1650, 1142, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8989, 2, 3, 1125, 10738, 4, 5, 1106, 2021, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02222837135195732, -0.011661031283438206, -0.0074634552001953125, -0.01097869873046875, -0.01097869873046875, -0.01097869873046875, -0.01097869873046875, -0.01097869873046875, -0.01097869873046875, -0.01097869873046875], "metadata": {"source_tokens": ["By", "this", "point", ",", "Simpson", "had", "returned", "to", "his", "mansion", "in", "Brent", "##wood", "and", "had", "surrendered", "to", "police", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Simpson", "[unused2]", "[unused3]", "had", "returned", "[unused4]", "[unused5]", "to", "his", "mansion", "in", "Brent", "##wood", "By", "this", "point", "[unused6]", "[SEP]", "[unused1]", "Simpson", "[unused2]", "[unused3]", "had", "surrendered", "[unused4]", "[unused5]", "to", "police", "[unused6]", "[SEP]"]]}

input 59:  {"source": "Byers states that global citizenship is a `` powerful term '' because `` people that invoke it do so to provoke and justify action , '' and encourages the attendees of his lecture to re-appropriate it in order for its meaning to have a positive purpose , based on idealistic values .\n"}
prediction:  {"predictions": [[1, 17774, 1733, 2, 3, 2231, 4, 5, 1115, 4265, 9709, 1110, 170, 3110, 1858, 1272, 169, 28152, 1234, 1115, 1107, 14638, 1122, 1202, 1177, 1106, 5250, 14638, 1105, 17422, 2168, 117, 112, 28131, 1105, 17233, 1103, 23150, 1104, 1117, 10309, 1106, 1231, 28137, 11478, 1643, 12736, 3464, 1566, 1122, 102, 1, 1234, 1115, 1107, 14638, 1122, 1202, 1177, 1106, 5250, 14638, 1105, 17422, 2168, 2, 3, 17233, 4, 5, 1103, 23150, 1104, 1117, 10309, 1106, 1231, 28137, 11478, 1643, 12736, 3464, 1566, 1107, 1546, 1111, 1157, 2764, 1106, 1138, 170, 3112, 3007, 1359, 1113, 7891, 5562, 4718, 6, 102, 102, 102, 1, 1234, 2, 3, 1107, 14638, 4, 5, 1122, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4265, 9709, 2, 3, 1110, 4, 5, 170, 3110, 1858, 1272, 1234, 1115, 1107, 14638, 1122, 1202, 1177, 1106, 5250, 14638, 1105, 17422, 2168, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1234, 1115, 1107, 14638, 1122, 2, 3, 1202, 4, 5, 1177, 1106, 5250, 14638, 1105, 17422, 2168, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4265, 9709, 2, 3, 1110, 4, 5, 170, 3110, 1858, 1272, 1234, 1115, 1107, 14638, 1122, 1202, 1177, 1106, 5250, 14638, 1105, 17422, 2168, 1105, 17233, 1103, 23150, 1104, 1117, 10309, 1106, 1231, 28137, 11478, 1643, 12736, 3464, 1566, 1122, 1107, 1546, 1111, 1157, 2764, 1106, 1138, 170, 3112, 102, 1, 1234, 2, 3, 1107, 14638, 4, 5, 1122, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1234, 2, 3, 1107, 14638, 4, 5, 1122, 6, 102, 102, 102, 1, 1234, 2, 3, 1107, 14638, 4, 5, 1122, 1202, 1177, 1106, 5250, 14638, 1105, 17422, 2168, 6, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0409962423145771, -0.06758425384759903, -0.22276955842971802, -0.1197696402668953, -0.13232655823230743, -0.07667366415262222, -0.2678304612636566, -0.2748792767524719, -0.2041872888803482, -0.22279977798461914], "metadata": {"source_tokens": ["Bye", "##rs", "states", "that", "global", "citizenship", "is", "a", "`", "##`", "powerful", "term", "'", "##'", "because", "`", "##`", "people", "that", "in", "##voke", "it", "do", "so", "to", "pro", "##voke", "and", "justify", "action", ",", "'", "##'", "and", "encourages", "the", "attendees", "of", "his", "lecture", "to", "re", "##-", "##ap", "##p", "##rop", "##ria", "##te", "it", "in", "order", "for", "its", "meaning", "to", "have", "a", "positive", "purpose", ",", "based", "on", "ideal", "##istic", "values", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Bye", "##rs", "[unused2]", "[unused3]", "states", "[unused4]", "[unused5]", "that", "global", "citizenship", "is", "a", "powerful", "term", "because", "`", "##`", "people", "that", "in", "##voke", "it", "do", "so", "to", "pro", "##voke", "and", "justify", "action", ",", "'", "##'", "and", "encourages", "the", "attendees", "of", "his", "lecture", "to", "re", "##-", "##ap", "##p", "##rop", "##ria", "##te", "it", "[SEP]", "[unused1]", "people", "that", "in", "##voke", "it", "do", "so", "to", "pro", "##voke", "and", "justify", "action", "[unused2]", "[unused3]", "encourages", "[unused4]", "[unused5]", "the", "attendees", "of", "his", "lecture", "to", "re", "##-", "##ap", "##p", "##rop", "##ria", "##te", "in", "order", "for", "its", "meaning", "to", "have", "a", "positive", "purpose", "based", "on", "ideal", "##istic", "values", "[unused6]", "[SEP]", "[unused1]", "people", "[unused2]", "[unused3]", "in", "##voke", "[unused4]", "[unused5]", "it", "[unused6]", "[SEP]", "[unused1]", "global", "citizenship", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "powerful", "term", "because", "people", "that", "in", "##voke", "it", "do", "so", "to", "pro", "##voke", "and", "justify", "action", "[unused6]", "[SEP]", "[unused1]", "people", "that", "in", "##voke", "it", "[unused2]", "[unused3]", "do", "[unused4]", "[unused5]", "so", "to", "pro", "##voke", "and", "justify", "action", "[unused6]", "[SEP]", "[unused1]", "global", "citizenship", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "powerful", "term", "because", "people", "that", "in", "##voke", "it", "do", "so", "to", "pro", "##voke", "and", "justify", "action", "and", "encourages", "the", "attendees", "of", "his", "lecture", "to", "re", "##-", "##ap", "##p", "##rop", "##ria", "##te", "it", "in", "order", "for", "its", "meaning", "to", "have", "a", "positive", "[SEP]", "[unused1]", "people", "[unused2]", "[unused3]", "in", "##voke", "[unused4]", "[unused5]", "it", "[unused6]", "[SEP]", "[unused1]", "people", "[unused2]", "[unused3]", "in", "##voke", "[unused4]", "[unused5]", "it", "[unused6]", "[SEP]", "[unused1]", "people", "[unused2]", "[unused3]", "in", "##voke", "[unused4]", "[unused5]", "it", "do", "so", "to", "pro", "##voke", "and", "justify", "action", "[unused6]", "[SEP]"]]}

input 60:  {"source": "Carl uses the `` old magic '' to tame the Deep Crow , claiming it is not his `` first time to the rodeo . ''\n"}
prediction:  {"predictions": [[1, 4804, 2, 3, 2745, 4, 5, 1103, 1385, 3974, 1106, 27629, 3263, 1103, 7786, 15252, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4804, 2, 3, 2745, 4, 5, 1103, 1385, 3974, 1106, 27629, 3263, 1103, 7786, 15252, 6330, 1122, 1110, 1136, 1117, 1148, 1159, 1106, 1103, 8335, 1186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4804, 2, 3, 2745, 4, 5, 1103, 1385, 3974, 1106, 27629, 3263, 1103, 7786, 15252, 6330, 1122, 1110, 1136, 1117, 1148, 1159, 1106, 1103, 8335, 1186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 1136, 4, 5, 1117, 169, 28152, 1148, 1159, 1106, 1103, 8335, 1186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.07167688012123108, -0.05880763754248619, -0.07263825088739395, -0.07125252485275269, -0.17911267280578613, -0.17954301834106445, -0.17954301834106445, -0.17954301834106445, -0.17954301834106445, -0.17954301834106445], "metadata": {"source_tokens": ["Carl", "uses", "the", "`", "##`", "old", "magic", "'", "##'", "to", "ta", "##me", "the", "Deep", "Crow", ",", "claiming", "it", "is", "not", "his", "`", "##`", "first", "time", "to", "the", "rode", "##o", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Carl", "[unused2]", "[unused3]", "uses", "[unused4]", "[unused5]", "the", "old", "magic", "to", "ta", "##me", "the", "Deep", "Crow", "[unused6]", "[SEP]", "[unused1]", "Carl", "[unused2]", "[unused3]", "uses", "[unused4]", "[unused5]", "the", "old", "magic", "to", "ta", "##me", "the", "Deep", "Crow", "claiming", "it", "is", "not", "his", "first", "time", "to", "the", "rode", "##o", "[unused6]", "[SEP]", "[unused1]", "Carl", "[unused2]", "[unused3]", "uses", "[unused4]", "[unused5]", "the", "old", "magic", "to", "ta", "##me", "the", "Deep", "Crow", "claiming", "it", "is", "not", "his", "first", "time", "to", "the", "rode", "##o", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "not", "[unused4]", "[unused5]", "his", "`", "##`", "first", "time", "to", "the", "rode", "##o", "[unused6]", "[SEP]"]]}

input 61:  {"source": "Certain fractional quantum Hall phases appear to have the right properties for building a topological quantum computer .\n"}
prediction:  {"predictions": [[1, 16482, 13394, 1348, 9539, 1944, 12877, 2, 3, 2845, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16482, 13394, 1348, 9539, 1944, 12877, 2, 3, 1106, 1138, 4, 5, 1103, 1268, 4625, 1111, 1459, 170, 1499, 7542, 9539, 2775, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.004341014660894871, -0.0008147668559104204, -0.0019412040710449219, -0.0019521713256835938, -0.0019521713256835938, -0.0019521713256835938, -0.0019521713256835938, -0.0019521713256835938, -0.0019521713256835938, -0.0019521713256835938], "metadata": {"source_tokens": ["Certain", "fraction", "##al", "quantum", "Hall", "phases", "appear", "to", "have", "the", "right", "properties", "for", "building", "a", "top", "##ological", "quantum", "computer", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Certain", "fraction", "##al", "quantum", "Hall", "phases", "[unused2]", "[unused3]", "appear", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Certain", "fraction", "##al", "quantum", "Hall", "phases", "[unused2]", "[unused3]", "to", "have", "[unused4]", "[unused5]", "the", "right", "properties", "for", "building", "a", "top", "##ological", "quantum", "computer", "[unused6]", "[SEP]"]]}

input 62:  {"source": "Chevalier fulfilled his promise the following year by erecting a shrine dedicated to the honour of Mary under the title of `` Our Lady of the Sacred Heart '' .\n"}
prediction:  {"predictions": [[1, 26353, 2, 3, 18210, 4, 5, 1117, 4437, 1103, 1378, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26353, 2, 3, 18210, 1117, 4437, 1118, 15685, 1158, 4, 5, 170, 12157, 3256, 1106, 1103, 6565, 1104, 2090, 1223, 1103, 1641, 1104, 169, 28152, 3458, 2876, 1104, 1103, 11373, 4641, 112, 28131, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.023821797221899033, -0.048173729330301285, -0.14751195907592773, -0.1439821720123291, -0.1439821720123291, -0.1439821720123291, -0.1439821720123291, -0.1439821720123291, -0.1439821720123291, -0.1439821720123291], "metadata": {"source_tokens": ["Chevalier", "fulfilled", "his", "promise", "the", "following", "year", "by", "erect", "##ing", "a", "shrine", "dedicated", "to", "the", "honour", "of", "Mary", "under", "the", "title", "of", "`", "##`", "Our", "Lady", "of", "the", "Sacred", "Heart", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Chevalier", "[unused2]", "[unused3]", "fulfilled", "[unused4]", "[unused5]", "his", "promise", "the", "following", "year", "[unused6]", "[SEP]", "[unused1]", "Chevalier", "[unused2]", "[unused3]", "fulfilled", "his", "promise", "by", "erect", "##ing", "[unused4]", "[unused5]", "a", "shrine", "dedicated", "to", "the", "honour", "of", "Mary", "under", "the", "title", "of", "`", "##`", "Our", "Lady", "of", "the", "Sacred", "Heart", "'", "##'", "[unused6]", "[SEP]"]]}

input 63:  {"source": "Cis-regulatory elements are sequences that control the transcription of a nearby gene .\n"}
prediction:  {"predictions": [[1, 140, 1548, 28137, 1874, 13830, 13389, 1183, 3050, 2, 3, 1132, 4, 5, 10028, 1115, 1654, 1103, 15416, 1104, 170, 2721, 5565, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0007479858468286693, -0.002285003662109375, -0.002377033233642578, -0.002377033233642578, -0.002377033233642578, -0.002377033233642578, -0.002377033233642578, -0.002377033233642578, -0.002377033233642578, -0.002377033233642578], "metadata": {"source_tokens": ["C", "##is", "##-", "##re", "##gu", "##lator", "##y", "elements", "are", "sequences", "that", "control", "the", "transcription", "of", "a", "nearby", "gene", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "C", "##is", "##-", "##re", "##gu", "##lator", "##y", "elements", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "sequences", "that", "control", "the", "transcription", "of", "a", "nearby", "gene", "[unused6]", "[SEP]"]]}

input 64:  {"source": "Citizens for Responsibility and Ethics in Washington filed an Ethics Committee complaint against Bond over his role in the ouster of Graves .\n"}
prediction:  {"predictions": [[1, 14649, 1111, 11336, 20080, 4199, 7706, 1105, 17475, 1107, 1994, 2, 3, 5770, 4, 5, 1126, 17475, 2341, 12522, 1222, 8211, 1166, 1117, 1648, 1107, 1103, 20796, 4648, 1104, 16494, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0012849172344431281, -0.21201658248901367, -0.13310861587524414, -0.13310861587524414, -0.13310861587524414, -0.13310861587524414, -0.13310861587524414, -0.13310861587524414, -0.13310861587524414, -0.13310861587524414], "metadata": {"source_tokens": ["Citizens", "for", "Re", "##sp", "##ons", "##ibility", "and", "Ethics", "in", "Washington", "filed", "an", "Ethics", "Committee", "complaint", "against", "Bond", "over", "his", "role", "in", "the", "ou", "##ster", "of", "Graves", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Citizens", "for", "Re", "##sp", "##ons", "##ibility", "and", "Ethics", "in", "Washington", "[unused2]", "[unused3]", "filed", "[unused4]", "[unused5]", "an", "Ethics", "Committee", "complaint", "against", "Bond", "over", "his", "role", "in", "the", "ou", "##ster", "of", "Graves", "[unused6]", "[SEP]"]]}

input 65:  {"source": "Combined with appropriate match pellets these rifles produce a consistent 10 ring performance , so a non-maximal result during the initial phase can be attributed to the participant .\n"}
prediction:  {"predictions": [[1, 170, 1664, 28137, 22871, 8628, 1233, 1871, 1219, 1103, 3288, 4065, 2, 3, 1169, 1129, 6547, 4, 5, 1106, 1103, 14031, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1292, 12385, 2, 3, 3133, 4, 5, 170, 8080, 1275, 3170, 2099, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02613113820552826, -0.016171637922525406, -0.042531728744506836, -0.04283475875854492, -0.04283475875854492, -0.04283475875854492, -0.04283475875854492, -0.04283475875854492, -0.04283475875854492, -0.04283475875854492], "metadata": {"source_tokens": ["Combined", "with", "appropriate", "match", "p", "##elle", "##ts", "these", "rifles", "produce", "a", "consistent", "10", "ring", "performance", ",", "so", "a", "non", "##-", "##max", "##ima", "##l", "result", "during", "the", "initial", "phase", "can", "be", "attributed", "to", "the", "participant", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "non", "##-", "##max", "##ima", "##l", "result", "during", "the", "initial", "phase", "[unused2]", "[unused3]", "can", "be", "attributed", "[unused4]", "[unused5]", "to", "the", "participant", "[unused6]", "[SEP]", "[unused1]", "these", "rifles", "[unused2]", "[unused3]", "produce", "[unused4]", "[unused5]", "a", "consistent", "10", "ring", "performance", "[unused6]", "[SEP]"]]}

input 66:  {"source": "Curley was the first classical organist to perform a solo organ recital at the White House , and also played before several European heads of state .\n"}
prediction:  {"predictions": [[1, 140, 27009, 2, 3, 1108, 4, 5, 1103, 1148, 4521, 19209, 1106, 3870, 170, 3444, 5677, 1231, 6617, 6163, 1120, 1103, 2061, 1585, 117, 1105, 1145, 1307, 1196, 1317, 1735, 4075, 1104, 1352, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 140, 27009, 2, 3, 1307, 4, 5, 1196, 1317, 1735, 4075, 1104, 1352, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.024866554886102676, -0.0927986428141594, -0.22264862060546875, -0.22264862060546875, -0.22264862060546875, -0.22264862060546875, -0.22264862060546875, -0.22264862060546875, -0.22264862060546875, -0.22264862060546875], "metadata": {"source_tokens": ["C", "##urley", "was", "the", "first", "classical", "organist", "to", "perform", "a", "solo", "organ", "re", "##ci", "##tal", "at", "the", "White", "House", ",", "and", "also", "played", "before", "several", "European", "heads", "of", "state", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "C", "##urley", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "first", "classical", "organist", "to", "perform", "a", "solo", "organ", "re", "##ci", "##tal", "at", "the", "White", "House", ",", "and", "also", "played", "before", "several", "European", "heads", "of", "state", "[unused6]", "[SEP]", "[unused1]", "C", "##urley", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "before", "several", "European", "heads", "of", "state", "[unused6]", "[SEP]"]]}

input 67:  {"source": "DC Comics held a memorial service in Manhattan 's Lower East Side , a neighborhood Eisner often visited in his work , at the Angel Orensanz Foundation on Norfolk Street .\n"}
prediction:  {"predictions": [[1, 5227, 7452, 2, 3, 1316, 4, 5, 170, 6768, 1555, 1107, 6545, 112, 1116, 5738, 1689, 6383, 1120, 1103, 5876, 2926, 5026, 1389, 1584, 2974, 1113, 7240, 1715, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4532, 2, 3, 3891, 4, 5, 1107, 1117, 1250, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.025047147646546364, -0.08918654173612595, -0.22275233268737793, -0.22275733947753906, -0.22275733947753906, -0.22275733947753906, -0.22275733947753906, -0.22275733947753906, -0.22275733947753906, -0.22275733947753906], "metadata": {"source_tokens": ["DC", "Comics", "held", "a", "memorial", "service", "in", "Manhattan", "'", "##s", "Lower", "East", "Side", ",", "a", "neighborhood", "E", "##is", "##ner", "often", "visited", "in", "his", "work", ",", "at", "the", "Angel", "Or", "##ens", "##an", "##z", "Foundation", "on", "Norfolk", "Street", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "DC", "Comics", "[unused2]", "[unused3]", "held", "[unused4]", "[unused5]", "a", "memorial", "service", "in", "Manhattan", "'", "##s", "Lower", "East", "Side", "at", "the", "Angel", "Or", "##ens", "##an", "##z", "Foundation", "on", "Norfolk", "Street", "[unused6]", "[SEP]", "[unused1]", "a", "neighborhood", "[unused2]", "[unused3]", "visited", "[unused4]", "[unused5]", "in", "his", "work", "often", "[unused6]", "[SEP]"]]}

input 68:  {"source": "Despite the below-freezing temperatures , Beuerlein was red-hot , out-dueling Brett Favre and connecting on 29 of 42 attempts , with 3 TDs and no INTs , and passing for a then franchise-record 373 yards .\n"}
prediction:  {"predictions": [[1, 4108, 10232, 18929, 2, 3, 1108, 4, 5, 1894, 28137, 12217, 1149, 28137, 21405, 1979, 12161, 143, 23140, 1874, 1105, 6755, 1113, 1853, 1104, 3565, 4021, 1114, 124, 15439, 1116, 1105, 1185, 15969, 1942, 1116, 1105, 3744, 1111, 170, 1173, 5801, 28137, 1874, 19248, 1181, 3413, 1495, 3422, 6, 102, 1, 4108, 10232, 18929, 2, 3, 1108, 4, 5, 1894, 28137, 12217, 1149, 28137, 21405, 1979, 12161, 143, 23140, 1874, 1105, 6755, 1113, 1853, 1104, 3565, 4021, 1114, 124, 15439, 1116, 1105, 1185, 15969, 1942, 1116, 1105, 3744, 1111, 170, 1173, 5801, 28137, 1874, 19248, 1181, 3413, 1495, 3422, 2711, 102, 1, 4108, 10232, 18929, 2, 3, 1108, 4, 5, 1894, 28137, 12217, 1149, 28137, 21405, 1979, 12161, 143, 23140, 1874, 1105, 6755, 1113, 1853, 1104, 3565, 4021, 1114, 124, 15439, 1116, 1105, 1185, 15969, 1942, 1116, 1105, 3744, 1111, 170, 1173, 5801, 28137, 1874, 19248, 1181, 3413, 1495, 3422, 6, 102, 1, 4108, 10232, 18929, 2, 3, 1108, 4, 5, 1894, 28137, 12217, 1149, 28137, 21405, 1979, 12161, 143, 23140, 1874, 1105, 6755, 1113, 1853, 1104, 3565, 4021, 1114, 124, 15439, 1116, 1105, 1185, 15969, 1942, 1116, 1105, 3744, 1111, 170, 1173, 5801, 28137, 1874, 19248, 1181, 3413, 1495, 3422, 2711, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.046507932245731354, -0.04697687551379204, -0.058767709881067276, -0.060869067907333374, -0.22292351722717285, -0.22290802001953125, -0.22290802001953125, -0.22290802001953125, -0.22290802001953125, -0.22290802001953125], "metadata": {"source_tokens": ["Despite", "the", "below", "##-", "##free", "##zing", "temperatures", ",", "Be", "##uer", "##lein", "was", "red", "##-", "##hot", ",", "out", "##-", "##due", "##ling", "Brett", "F", "##av", "##re", "and", "connecting", "on", "29", "of", "42", "attempts", ",", "with", "3", "TD", "##s", "and", "no", "IN", "##T", "##s", ",", "and", "passing", "for", "a", "then", "franchise", "##-", "##re", "##cor", "##d", "37", "##3", "yards", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Be", "##uer", "##lein", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "red", "##-", "##hot", "out", "##-", "##due", "##ling", "Brett", "F", "##av", "##re", "and", "connecting", "on", "29", "of", "42", "attempts", "with", "3", "TD", "##s", "and", "no", "IN", "##T", "##s", "and", "passing", "for", "a", "then", "franchise", "##-", "##re", "##cor", "##d", "37", "##3", "yards", "[unused6]", "[SEP]", "[unused1]", "Be", "##uer", "##lein", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "red", "##-", "##hot", "out", "##-", "##due", "##ling", "Brett", "F", "##av", "##re", "and", "connecting", "on", "29", "of", "42", "attempts", "with", "3", "TD", "##s", "and", "no", "IN", "##T", "##s", "and", "passing", "for", "a", "then", "franchise", "##-", "##re", "##cor", "##d", "37", "##3", "yards", "Despite", "[SEP]", "[unused1]", "Be", "##uer", "##lein", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "red", "##-", "##hot", "out", "##-", "##due", "##ling", "Brett", "F", "##av", "##re", "and", "connecting", "on", "29", "of", "42", "attempts", "with", "3", "TD", "##s", "and", "no", "IN", "##T", "##s", "and", "passing", "for", "a", "then", "franchise", "##-", "##re", "##cor", "##d", "37", "##3", "yards", "[unused6]", "[SEP]", "[unused1]", "Be", "##uer", "##lein", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "red", "##-", "##hot", "out", "##-", "##due", "##ling", "Brett", "F", "##av", "##re", "and", "connecting", "on", "29", "of", "42", "attempts", "with", "3", "TD", "##s", "and", "no", "IN", "##T", "##s", "and", "passing", "for", "a", "then", "franchise", "##-", "##re", "##cor", "##d", "37", "##3", "yards", "Despite", "[SEP]"]]}

input 69:  {"source": "Dodo was originally intended to have a `` common '' accent , and is portrayed this way at the end of `` The Massacre '' .\n"}
prediction:  {"predictions": [[1, 2091, 2572, 2, 3, 1110, 6313, 4, 5, 1142, 1236, 1120, 1103, 1322, 1104, 169, 28152, 1109, 20507, 2034, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2091, 2572, 2, 3, 1106, 1138, 4, 5, 170, 169, 28152, 1887, 112, 28131, 9603, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2091, 2572, 2, 3, 1108, 3005, 4, 5, 1106, 1138, 170, 169, 28152, 1887, 112, 28131, 9603, 2034, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.06559682637453079, -0.022669587284326553, -0.09861394017934799, -0.026833772659301758, -0.026833534240722656, -0.026833534240722656, -0.026833534240722656, -0.026833534240722656, -0.026833534240722656, -0.026833534240722656], "metadata": {"source_tokens": ["Do", "##do", "was", "originally", "intended", "to", "have", "a", "`", "##`", "common", "'", "##'", "accent", ",", "and", "is", "portrayed", "this", "way", "at", "the", "end", "of", "`", "##`", "The", "Massacre", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Do", "##do", "[unused2]", "[unused3]", "is", "portrayed", "[unused4]", "[unused5]", "this", "way", "at", "the", "end", "of", "`", "##`", "The", "Massacre", "originally", "[unused6]", "[SEP]", "[unused1]", "Do", "##do", "[unused2]", "[unused3]", "to", "have", "[unused4]", "[unused5]", "a", "`", "##`", "common", "'", "##'", "accent", "[unused6]", "[SEP]", "[unused1]", "Do", "##do", "[unused2]", "[unused3]", "was", "intended", "[unused4]", "[unused5]", "to", "have", "a", "`", "##`", "common", "'", "##'", "accent", "originally", "[unused6]", "[SEP]"]]}

input 70:  {"source": "Dr. Pim played for Ireland against England in 1892 , 1893 , 1894 and 1896 .\n"}
prediction:  {"predictions": [[1, 1987, 28138, 21902, 1306, 2, 3, 1307, 4, 5, 1111, 2270, 1222, 1652, 1107, 5889, 117, 5843, 117, 5901, 1105, 5645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.005722890142351389, -0.0030155181884765625, -0.003025531768798828, -0.003025531768798828, -0.003025531768798828, -0.003025531768798828, -0.003025531768798828, -0.003025531768798828, -0.003025531768798828, -0.003025531768798828], "metadata": {"source_tokens": ["Dr", "##.", "Pi", "##m", "played", "for", "Ireland", "against", "England", "in", "1892", ",", "1893", ",", "1894", "and", "1896", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Dr", "##.", "Pi", "##m", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "for", "Ireland", "against", "England", "in", "1892", ",", "1893", ",", "1894", "and", "1896", "[unused6]", "[SEP]"]]}

input 71:  {"source": "Due to the opposing nature of the two songs , they can be viewed as a debate on the opposing attitudes on love found throughout the play .\n"}
prediction:  {"predictions": [[1, 1103, 10137, 15149, 1113, 1567, 2, 3, 1276, 4, 5, 2032, 1103, 1505, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1169, 1129, 6497, 4, 5, 1112, 170, 5655, 1113, 1103, 10137, 15149, 1113, 1567, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.009040461853146553, -0.0011029660236090422, -0.022370100021362305, -0.022488832473754883, -0.022488832473754883, -0.022488832473754883, -0.022488832473754883, -0.022488832473754883, -0.022488832473754883, -0.022488832473754883], "metadata": {"source_tokens": ["Due", "to", "the", "opposing", "nature", "of", "the", "two", "songs", ",", "they", "can", "be", "viewed", "as", "a", "debate", "on", "the", "opposing", "attitudes", "on", "love", "found", "throughout", "the", "play", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "opposing", "attitudes", "on", "love", "[unused2]", "[unused3]", "found", "[unused4]", "[unused5]", "throughout", "the", "play", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "can", "be", "viewed", "[unused4]", "[unused5]", "as", "a", "debate", "on", "the", "opposing", "attitudes", "on", "love", "[unused6]", "[SEP]"]]}

input 72:  {"source": "Due to the transmitter location being based in Tyrone and a smaller signal wattage , it was barely hearable in the northern portions of Atlanta beyond the downtown area or even the northern reaches of Fulton or DeKalb Counties , as it was a rimshot to the southwest of the city .\n"}
prediction:  {"predictions": [[1, 1103, 11991, 2450, 2, 3, 1217, 1359, 4, 5, 1107, 20314, 1105, 170, 2964, 4344, 20049, 5100, 2176, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 2100, 1895, 1107, 1103, 2350, 8924, 1104, 5161, 2894, 1103, 5215, 1298, 1137, 1256, 1103, 2350, 5965, 1104, 18196, 1137, 3177, 2428, 1348, 1830, 12259, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 170, 13840, 21879, 1106, 1103, 5090, 1104, 1103, 1331, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 2100, 1895, 1107, 1103, 2350, 8924, 1104, 5161, 2894, 1103, 5215, 1298, 1137, 1256, 1103, 2350, 5965, 1104, 18196, 1137, 3177, 2428, 1348, 1830, 12259, 1112, 1122, 1108, 170, 13840, 21879, 1106, 1103, 5090, 1104, 1103, 1331, 6, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 2100, 1895, 1107, 1103, 2350, 8924, 1104, 5161, 2894, 1103, 5215, 1298, 1137, 1256, 1103, 2350, 5965, 1104, 18196, 1137, 3177, 2428, 1348, 1830, 12259, 1112, 1122, 1108, 170, 13840, 21879, 1106, 1103, 5090, 1104, 1103, 1331, 6, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 2100, 1895, 1107, 1103, 2350, 8924, 1104, 5161, 2894, 1103, 5215, 1298, 1137, 1256, 1103, 2350, 5965, 1104, 18196, 1137, 3177, 2428, 1348, 1830, 12259, 1112, 1122, 1108, 170, 13840, 21879, 1106, 1103, 5090, 1104, 1103, 1331, 6, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 2100, 1895, 1107, 1103, 2350, 8924, 1104, 5161, 2894, 1103, 5215, 1298, 1137, 1256, 1103, 2350, 5965, 1104, 18196, 1137, 3177, 2428, 1348, 1830, 12259, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02867819555103779, -0.021747203543782234, -0.009066103026270866, -0.07707632333040237, -0.0818643718957901, -0.08718015998601913, -0.10460672527551651, -0.2227461338043213, -0.22272944450378418, -0.22272944450378418], "metadata": {"source_tokens": ["Due", "to", "the", "transmitter", "location", "being", "based", "in", "Tyrone", "and", "a", "smaller", "signal", "wa", "##tta", "##ge", ",", "it", "was", "barely", "hear", "##able", "in", "the", "northern", "portions", "of", "Atlanta", "beyond", "the", "downtown", "area", "or", "even", "the", "northern", "reaches", "of", "Fulton", "or", "De", "##K", "##al", "##b", "Counties", ",", "as", "it", "was", "a", "rim", "##shot", "to", "the", "southwest", "of", "the", "city", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "transmitter", "location", "[unused2]", "[unused3]", "being", "based", "[unused4]", "[unused5]", "in", "Tyrone", "and", "a", "smaller", "signal", "wa", "##tta", "##ge", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "hear", "##able", "in", "the", "northern", "portions", "of", "Atlanta", "beyond", "the", "downtown", "area", "or", "even", "the", "northern", "reaches", "of", "Fulton", "or", "De", "##K", "##al", "##b", "Counties", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "rim", "##shot", "to", "the", "southwest", "of", "the", "city", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "hear", "##able", "in", "the", "northern", "portions", "of", "Atlanta", "beyond", "the", "downtown", "area", "or", "even", "the", "northern", "reaches", "of", "Fulton", "or", "De", "##K", "##al", "##b", "Counties", "as", "it", "was", "a", "rim", "##shot", "to", "the", "southwest", "of", "the", "city", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "hear", "##able", "in", "the", "northern", "portions", "of", "Atlanta", "beyond", "the", "downtown", "area", "or", "even", "the", "northern", "reaches", "of", "Fulton", "or", "De", "##K", "##al", "##b", "Counties", "as", "it", "was", "a", "rim", "##shot", "to", "the", "southwest", "of", "the", "city", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "hear", "##able", "in", "the", "northern", "portions", "of", "Atlanta", "beyond", "the", "downtown", "area", "or", "even", "the", "northern", "reaches", "of", "Fulton", "or", "De", "##K", "##al", "##b", "Counties", "as", "it", "was", "a", "rim", "##shot", "to", "the", "southwest", "of", "the", "city", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "hear", "##able", "in", "the", "northern", "portions", "of", "Atlanta", "beyond", "the", "downtown", "area", "or", "even", "the", "northern", "reaches", "of", "Fulton", "or", "De", "##K", "##al", "##b", "Counties", "[unused6]", "[SEP]"]]}

input 73:  {"source": "During the Second World War , the number of Turkish run cafes increased from 20 in 1939 to 200 in 1945 which created a demand for more Turkish Cypriot workers .\n"}
prediction:  {"predictions": [[1, 1103, 1295, 1104, 4229, 1576, 17287, 1116, 2, 3, 2569, 4, 5, 1121, 1406, 1107, 3061, 1106, 2363, 1107, 2481, 1507, 1103, 2307, 1291, 1414, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2481, 2, 3, 1687, 4, 5, 170, 4555, 1111, 1167, 4229, 20036, 3239, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1295, 1104, 4229, 1576, 17287, 1116, 2, 3, 2569, 4, 5, 1121, 1406, 1107, 3061, 1106, 2363, 1107, 2481, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.01523925643414259, -0.02144378423690796, -0.030928857624530792, -0.14474844932556152, -0.1410205364227295, -0.1410205364227295, -0.1410205364227295, -0.1410205364227295, -0.1410205364227295, -0.1410205364227295], "metadata": {"source_tokens": ["During", "the", "Second", "World", "War", ",", "the", "number", "of", "Turkish", "run", "cafe", "##s", "increased", "from", "20", "in", "1939", "to", "200", "in", "1945", "which", "created", "a", "demand", "for", "more", "Turkish", "Cypriot", "workers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "number", "of", "Turkish", "run", "cafe", "##s", "[unused2]", "[unused3]", "increased", "[unused4]", "[unused5]", "from", "20", "in", "1939", "to", "200", "in", "1945", "During", "the", "Second", "World", "War", "[unused6]", "[SEP]", "[unused1]", "1945", "[unused2]", "[unused3]", "created", "[unused4]", "[unused5]", "a", "demand", "for", "more", "Turkish", "Cypriot", "workers", "[unused6]", "[SEP]", "[unused1]", "the", "number", "of", "Turkish", "run", "cafe", "##s", "[unused2]", "[unused3]", "increased", "[unused4]", "[unused5]", "from", "20", "in", "1939", "to", "200", "in", "1945", "[unused6]", "[SEP]"]]}

input 74:  {"source": "During the morning and evening rush hours some services run direct to/from Paddington and Reading .\n"}
prediction:  {"predictions": [[1, 1199, 1826, 2, 3, 1576, 4, 5, 2904, 1106, 28139, 2087, 16071, 19585, 24103, 1105, 8003, 1507, 1103, 2106, 1105, 3440, 6274, 2005, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.009865081869065762, -0.2861969470977783, -0.2862508296966553, -0.2862508296966553, -0.2862508296966553, -0.2862508296966553, -0.2862508296966553, -0.2862508296966553, -0.2862508296966553, -0.2862508296966553], "metadata": {"source_tokens": ["During", "the", "morning", "and", "evening", "rush", "hours", "some", "services", "run", "direct", "to", "##/", "##f", "##rom", "Pa", "##ddington", "and", "Reading", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "some", "services", "[unused2]", "[unused3]", "run", "[unused4]", "[unused5]", "direct", "to", "##/", "##f", "##rom", "Pa", "##ddington", "and", "Reading", "During", "the", "morning", "and", "evening", "rush", "hours", "[unused6]", "[SEP]"]]}

input 75:  {"source": "During the off-season the ACT Rugby Union was renamed the ACT and Southern NSW Rugby Union , and the name of the team was changed to Brumbies Rugby .\n"}
prediction:  {"predictions": [[1, 1103, 1271, 1104, 1103, 1264, 2, 3, 1108, 2014, 4, 5, 1106, 139, 5697, 16751, 5457, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 21111, 5457, 1913, 2, 3, 1108, 3286, 4, 5, 1103, 21111, 1105, 2685, 11557, 5457, 1913, 1507, 1103, 1228, 28137, 19885, 2142, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.011072076857089996, -0.008751184679567814, -0.22530078887939453, -0.14130449295043945, -0.14130449295043945, -0.14130449295043945, -0.14130449295043945, -0.14130449295043945, -0.14130449295043945, -0.14130449295043945], "metadata": {"source_tokens": ["During", "the", "off", "##-", "##sea", "##son", "the", "ACT", "Rugby", "Union", "was", "renamed", "the", "ACT", "and", "Southern", "NSW", "Rugby", "Union", ",", "and", "the", "name", "of", "the", "team", "was", "changed", "to", "B", "##rum", "##bies", "Rugby", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "name", "of", "the", "team", "[unused2]", "[unused3]", "was", "changed", "[unused4]", "[unused5]", "to", "B", "##rum", "##bies", "Rugby", "[unused6]", "[SEP]", "[unused1]", "the", "ACT", "Rugby", "Union", "[unused2]", "[unused3]", "was", "renamed", "[unused4]", "[unused5]", "the", "ACT", "and", "Southern", "NSW", "Rugby", "Union", "During", "the", "off", "##-", "##sea", "##son", "[unused6]", "[SEP]"]]}

input 76:  {"source": "Each of the Matoran brought their Toa stone and met each other at the Great Temple .\n"}
prediction:  {"predictions": [[1, 2994, 1104, 1103, 25702, 15186, 2, 3, 1814, 4, 5, 1147, 1706, 1161, 2576, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2994, 1104, 1103, 25702, 15186, 2, 3, 1899, 4, 5, 1296, 1168, 1120, 1103, 2038, 4407, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03738896921277046, -0.002132842317223549, -0.03095698356628418, -0.030757427215576172, -0.030757427215576172, -0.030757427215576172, -0.030757427215576172, -0.030757427215576172, -0.030757427215576172, -0.030757427215576172], "metadata": {"source_tokens": ["Each", "of", "the", "Mat", "##oran", "brought", "their", "To", "##a", "stone", "and", "met", "each", "other", "at", "the", "Great", "Temple", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Each", "of", "the", "Mat", "##oran", "[unused2]", "[unused3]", "brought", "[unused4]", "[unused5]", "their", "To", "##a", "stone", "[unused6]", "[SEP]", "[unused1]", "Each", "of", "the", "Mat", "##oran", "[unused2]", "[unused3]", "met", "[unused4]", "[unused5]", "each", "other", "at", "the", "Great", "Temple", "[unused6]", "[SEP]"]]}

input 77:  {"source": "Each time Cluemaster escapes or starts some new plan , Stephanie dons her costume again .\n"}
prediction:  {"predictions": [[1, 11952, 2, 3, 1274, 1116, 4, 5, 1123, 10220, 1254, 2994, 1159, 140, 19224, 6532, 13481, 1137, 3816, 1199, 1207, 2197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 140, 19224, 6532, 2, 3, 3816, 4, 5, 1199, 1207, 2197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.012161712162196636, -0.22305774688720703, -0.0774935632944107, -0.1490328311920166, -0.14940404891967773, -0.14940404891967773, -0.14940404891967773, -0.14940404891967773, -0.14940404891967773, -0.14940404891967773], "metadata": {"source_tokens": ["Each", "time", "C", "##lue", "##master", "escapes", "or", "starts", "some", "new", "plan", ",", "Stephanie", "don", "##s", "her", "costume", "again", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Stephanie", "[unused2]", "[unused3]", "don", "##s", "[unused4]", "[unused5]", "her", "costume", "again", "Each", "time", "C", "##lue", "##master", "escapes", "or", "starts", "some", "new", "plan", "[unused6]", "[SEP]"]]}

input 78:  {"source": "Erotica and pornography involving sex between women have been predominantly produced by men for a male and female audience .\n"}
prediction:  {"predictions": [[1, 142, 10595, 4578, 1105, 22912, 2, 3, 5336, 4, 5, 2673, 1206, 1535, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 142, 10595, 4578, 1105, 22912, 2, 3, 1138, 1151, 8941, 1666, 4, 5, 1118, 1441, 1111, 170, 2581, 1105, 2130, 3703, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.058421313762664795, -0.01693795621395111, -0.005665302276611328, -0.0055425167083740234, -0.0055425167083740234, -0.0055425167083740234, -0.0055425167083740234, -0.0055425167083740234, -0.0055425167083740234, -0.0055425167083740234], "metadata": {"source_tokens": ["E", "##rot", "##ica", "and", "pornography", "involving", "sex", "between", "women", "have", "been", "predominantly", "produced", "by", "men", "for", "a", "male", "and", "female", "audience", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "E", "##rot", "##ica", "and", "pornography", "[unused2]", "[unused3]", "involving", "[unused4]", "[unused5]", "sex", "between", "women", "[unused6]", "[SEP]", "[unused1]", "E", "##rot", "##ica", "and", "pornography", "[unused2]", "[unused3]", "have", "been", "predominantly", "produced", "[unused4]", "[unused5]", "by", "men", "for", "a", "male", "and", "female", "audience", "[unused6]", "[SEP]"]]}

input 79:  {"source": "Failure to perform the duty could lead to prosecution at law and re-enslavement .\n"}
prediction:  {"predictions": [[1, 143, 11922, 3313, 1106, 3870, 1103, 4019, 2, 3, 1180, 1730, 4, 5, 1106, 12369, 1120, 1644, 1105, 1231, 28137, 5026, 9516, 14529, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0006921841413713992, -0.0036821365356445312, -0.004466533660888672, -0.004466533660888672, -0.004466533660888672, -0.004466533660888672, -0.004466533660888672, -0.004466533660888672, -0.004466533660888672, -0.004466533660888672], "metadata": {"source_tokens": ["F", "##ail", "##ure", "to", "perform", "the", "duty", "could", "lead", "to", "prosecution", "at", "law", "and", "re", "##-", "##ens", "##lav", "##ement", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "F", "##ail", "##ure", "to", "perform", "the", "duty", "[unused2]", "[unused3]", "could", "lead", "[unused4]", "[unused5]", "to", "prosecution", "at", "law", "and", "re", "##-", "##ens", "##lav", "##ement", "[unused6]", "[SEP]"]]}

input 80:  {"source": "Falun Gong 's teachings are compiled from Li 's lectures , and Li holds definitional power in that belief system .\n"}
prediction:  {"predictions": [[1, 5255, 2, 3, 3486, 4, 5, 5754, 1348, 1540, 1107, 1115, 6369, 1449, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 143, 1348, 3488, 23703, 112, 1116, 12815, 2, 3, 1132, 9064, 4, 5, 1121, 5255, 112, 1116, 9548, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.01948785036802292, -0.0009148177923634648, -0.0016140937805175781, -0.0016241073608398438, -0.0016241073608398438, -0.0016241073608398438, -0.0016241073608398438, -0.0016241073608398438, -0.0016241073608398438, -0.0016241073608398438], "metadata": {"source_tokens": ["F", "##al", "##un", "Gong", "'", "##s", "teachings", "are", "compiled", "from", "Li", "'", "##s", "lectures", ",", "and", "Li", "holds", "definition", "##al", "power", "in", "that", "belief", "system", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Li", "[unused2]", "[unused3]", "holds", "[unused4]", "[unused5]", "definition", "##al", "power", "in", "that", "belief", "system", "[unused6]", "[SEP]", "[unused1]", "F", "##al", "##un", "Gong", "'", "##s", "teachings", "[unused2]", "[unused3]", "are", "compiled", "[unused4]", "[unused5]", "from", "Li", "'", "##s", "lectures", "[unused6]", "[SEP]"]]}

input 81:  {"source": "Fans reacted to the news of the suspension by canceling their XM Radio subscriptions , with some fans even going as far as smashing their XM units .\n"}
prediction:  {"predictions": [[1, 16061, 1116, 2, 3, 15510, 4, 5, 1106, 1103, 2371, 1104, 1103, 8605, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16061, 1116, 2, 3, 15510, 4, 5, 1106, 1103, 2371, 1104, 1103, 8605, 1118, 19722, 1158, 1147, 161, 2107, 2664, 16759, 1116, 1114, 1199, 3899, 1256, 1280, 1112, 1677, 1112, 24881, 1158, 1147, 161, 2107, 2338, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16061, 1116, 2, 3, 15510, 4, 5, 1106, 1103, 2371, 1104, 1103, 8605, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16061, 1116, 2, 3, 15510, 4, 5, 1106, 1103, 2371, 1104, 1103, 8605, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16061, 1116, 2, 3, 15510, 4, 5, 1106, 1103, 2371, 1104, 1103, 8605, 1118, 19722, 1158, 1147, 161, 2107, 2664, 16759, 1116, 1114, 1199, 3899, 1256, 1280, 1112, 1677, 1112, 24881, 1158, 1147, 161, 2107, 2338, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02362579107284546, -0.029528673738241196, -0.08969758450984955, -0.11386433243751526, -0.06303539127111435, -0.22269010543823242, -0.22269248962402344, -0.22269248962402344, -0.22269248962402344, -0.22269248962402344], "metadata": {"source_tokens": ["Fan", "##s", "reacted", "to", "the", "news", "of", "the", "suspension", "by", "cancel", "##ing", "their", "X", "##M", "Radio", "subscription", "##s", ",", "with", "some", "fans", "even", "going", "as", "far", "as", "smash", "##ing", "their", "X", "##M", "units", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Fan", "##s", "[unused2]", "[unused3]", "reacted", "[unused4]", "[unused5]", "to", "the", "news", "of", "the", "suspension", "[unused6]", "[SEP]", "[unused1]", "Fan", "##s", "[unused2]", "[unused3]", "reacted", "[unused4]", "[unused5]", "to", "the", "news", "of", "the", "suspension", "by", "cancel", "##ing", "their", "X", "##M", "Radio", "subscription", "##s", "with", "some", "fans", "even", "going", "as", "far", "as", "smash", "##ing", "their", "X", "##M", "units", "[unused6]", "[SEP]", "[unused1]", "Fan", "##s", "[unused2]", "[unused3]", "reacted", "[unused4]", "[unused5]", "to", "the", "news", "of", "the", "suspension", "[unused6]", "[SEP]", "[unused1]", "Fan", "##s", "[unused2]", "[unused3]", "reacted", "[unused4]", "[unused5]", "to", "the", "news", "of", "the", "suspension", "[unused6]", "[SEP]", "[unused1]", "Fan", "##s", "[unused2]", "[unused3]", "reacted", "[unused4]", "[unused5]", "to", "the", "news", "of", "the", "suspension", "by", "cancel", "##ing", "their", "X", "##M", "Radio", "subscription", "##s", "with", "some", "fans", "even", "going", "as", "far", "as", "smash", "##ing", "their", "X", "##M", "units", "[unused6]", "[SEP]"]]}

input 82:  {"source": "From 1909 to 1912 , the Miami Canal was dug , bypassing the rapids at the head of the North Fork .\n"}
prediction:  {"predictions": [[1, 1103, 4916, 6327, 2, 3, 1108, 8423, 4, 5, 1622, 4818, 1106, 4080, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4916, 6327, 2, 3, 13981, 1158, 4, 5, 1103, 6099, 1116, 1120, 1103, 1246, 1104, 1103, 1456, 16384, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.05613872408866882, -0.010940222069621086, -0.21633338928222656, -0.22808027267456055, -0.22808027267456055, -0.22808027267456055, -0.22808027267456055, -0.22808027267456055, -0.22808027267456055, -0.22808027267456055], "metadata": {"source_tokens": ["From", "1909", "to", "1912", ",", "the", "Miami", "Canal", "was", "dug", ",", "bypass", "##ing", "the", "rapid", "##s", "at", "the", "head", "of", "the", "North", "Fork", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Miami", "Canal", "[unused2]", "[unused3]", "was", "dug", "[unused4]", "[unused5]", "From", "1909", "to", "1912", "[unused6]", "[SEP]", "[unused1]", "the", "Miami", "Canal", "[unused2]", "[unused3]", "bypass", "##ing", "[unused4]", "[unused5]", "the", "rapid", "##s", "at", "the", "head", "of", "the", "North", "Fork", "[unused6]", "[SEP]"]]}

input 83:  {"source": "From the start of the first semester of 2010 , the University banned smoking on any of its property , including inside and outside buildings in areas that were once designated as smoking areas .\n"}
prediction:  {"predictions": [[1, 1877, 2, 3, 1127, 3574, 4, 5, 1112, 9987, 1877, 1517, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1239, 2, 3, 7548, 4, 5, 9987, 1113, 1251, 1104, 1157, 2400, 117, 1259, 1656, 1105, 1796, 2275, 1107, 1877, 1622, 1103, 1838, 1104, 1103, 1148, 14594, 1104, 1333, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1239, 2, 3, 7548, 4, 5, 9987, 1259, 1656, 1105, 1796, 2275, 1107, 1877, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1239, 2, 3, 7548, 4, 5, 9987, 1113, 1251, 1104, 1157, 2400, 1259, 1656, 1105, 1796, 2275, 1107, 1877, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.034003548324108124, -0.01886233501136303, -0.07926546037197113, -0.10785453021526337, -0.22265386581420898, -0.22265386581420898, -0.22265386581420898, -0.22265386581420898, -0.22265386581420898, -0.22265386581420898], "metadata": {"source_tokens": ["From", "the", "start", "of", "the", "first", "semester", "of", "2010", ",", "the", "University", "banned", "smoking", "on", "any", "of", "its", "property", ",", "including", "inside", "and", "outside", "buildings", "in", "areas", "that", "were", "once", "designated", "as", "smoking", "areas", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "areas", "[unused2]", "[unused3]", "were", "designated", "[unused4]", "[unused5]", "as", "smoking", "areas", "once", "[unused6]", "[SEP]", "[unused1]", "the", "University", "[unused2]", "[unused3]", "banned", "[unused4]", "[unused5]", "smoking", "on", "any", "of", "its", "property", ",", "including", "inside", "and", "outside", "buildings", "in", "areas", "From", "the", "start", "of", "the", "first", "semester", "of", "2010", "[unused6]", "[SEP]", "[unused1]", "the", "University", "[unused2]", "[unused3]", "banned", "[unused4]", "[unused5]", "smoking", "including", "inside", "and", "outside", "buildings", "in", "areas", "[unused6]", "[SEP]", "[unused1]", "the", "University", "[unused2]", "[unused3]", "banned", "[unused4]", "[unused5]", "smoking", "on", "any", "of", "its", "property", "including", "inside", "and", "outside", "buildings", "in", "areas", "[unused6]", "[SEP]"]]}

input 84:  {"source": "Furthermore , knowledge and interest pertaining to the event , as well as the level of importance , contribute to the frequency of rehearsal .\n"}
prediction:  {"predictions": [[1, 3044, 1105, 2199, 22383, 1106, 1103, 1856, 117, 1112, 1218, 1112, 1103, 1634, 1104, 4495, 2, 3, 8681, 4, 5, 1106, 1103, 5625, 1104, 20762, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3044, 1105, 2199, 2, 3, 22383, 4, 5, 1106, 1103, 1856, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.007439230103045702, -0.02039848081767559, -0.005722999572753906, -0.005899906158447266, -0.005899906158447266, -0.005899906158447266, -0.005899906158447266, -0.005899906158447266, -0.005899906158447266, -0.005899906158447266], "metadata": {"source_tokens": ["Furthermore", ",", "knowledge", "and", "interest", "pertaining", "to", "the", "event", ",", "as", "well", "as", "the", "level", "of", "importance", ",", "contribute", "to", "the", "frequency", "of", "rehearsal", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "knowledge", "and", "interest", "pertaining", "to", "the", "event", ",", "as", "well", "as", "the", "level", "of", "importance", "[unused2]", "[unused3]", "contribute", "[unused4]", "[unused5]", "to", "the", "frequency", "of", "rehearsal", "[unused6]", "[SEP]", "[unused1]", "knowledge", "and", "interest", "[unused2]", "[unused3]", "pertaining", "[unused4]", "[unused5]", "to", "the", "event", "[unused6]", "[SEP]"]]}

input 85:  {"source": "Gameplay is very basic ; the player must shoot constantly at a continual stream of enemies in order to reach the end of each level .\n"}
prediction:  {"predictions": [[1, 3497, 11044, 2, 3, 1110, 4, 5, 1304, 3501, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1591, 2, 3, 1538, 5211, 7480, 4, 5, 1120, 170, 14255, 6105, 4746, 5118, 1104, 6380, 1107, 1546, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1591, 2, 3, 1538, 5211, 4, 5, 7480, 1120, 170, 14255, 6105, 4746, 5118, 1104, 6380, 1107, 1546, 1106, 2519, 1103, 1322, 1104, 1296, 1634, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.015805264934897423, -0.0216971468180418, -0.0423656702041626, -0.14505958557128906, -0.14505887031555176, -0.14505887031555176, -0.14505887031555176, -0.14505887031555176, -0.14505887031555176, -0.14505887031555176], "metadata": {"source_tokens": ["Game", "##play", "is", "very", "basic", ";", "the", "player", "must", "shoot", "constantly", "at", "a", "con", "##tin", "##ual", "stream", "of", "enemies", "in", "order", "to", "reach", "the", "end", "of", "each", "level", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Game", "##play", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "very", "basic", "[unused6]", "[SEP]", "[unused1]", "the", "player", "[unused2]", "[unused3]", "must", "shoot", "constantly", "[unused4]", "[unused5]", "at", "a", "con", "##tin", "##ual", "stream", "of", "enemies", "in", "order", "[unused6]", "[SEP]", "[unused1]", "the", "player", "[unused2]", "[unused3]", "must", "shoot", "[unused4]", "[unused5]", "constantly", "at", "a", "con", "##tin", "##ual", "stream", "of", "enemies", "in", "order", "to", "reach", "the", "end", "of", "each", "level", "[unused6]", "[SEP]"]]}

input 86:  {"source": "Gavin Hood is a South African filmmaker , screenwriter , producer and actor , best known for writing and directing the Academy Award-winning Foreign Language Film `` Tsotsi '' .\n"}
prediction:  {"predictions": [[1, 9152, 10776, 2, 3, 1110, 4, 5, 170, 1375, 2170, 13140, 117, 11625, 117, 2451, 1105, 2811, 117, 1436, 1227, 1111, 2269, 1105, 10404, 1103, 2127, 1698, 28137, 7445, 3381, 4201, 6828, 2352, 169, 28152, 157, 7301, 2145, 1182, 112, 28131, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1375, 2170, 13140, 117, 11625, 117, 2451, 1105, 2811, 2, 3, 1436, 1227, 4, 5, 1111, 2269, 1105, 10404, 1103, 2127, 1698, 28137, 7445, 3381, 4201, 6828, 2352, 169, 28152, 157, 7301, 2145, 1182, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.021004371345043182, -0.04120379686355591, -0.03681373596191406, -0.051493167877197266, -0.051493167877197266, -0.051493167877197266, -0.051493167877197266, -0.051493167877197266, -0.051493167877197266, -0.051493167877197266], "metadata": {"source_tokens": ["Gavin", "Hood", "is", "a", "South", "African", "filmmaker", ",", "screenwriter", ",", "producer", "and", "actor", ",", "best", "known", "for", "writing", "and", "directing", "the", "Academy", "Award", "##-", "##win", "##ning", "Foreign", "Language", "Film", "`", "##`", "T", "##so", "##ts", "##i", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Gavin", "Hood", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "South", "African", "filmmaker", ",", "screenwriter", ",", "producer", "and", "actor", ",", "best", "known", "for", "writing", "and", "directing", "the", "Academy", "Award", "##-", "##win", "##ning", "Foreign", "Language", "Film", "`", "##`", "T", "##so", "##ts", "##i", "'", "##'", "[unused6]", "[SEP]", "[unused1]", "a", "South", "African", "filmmaker", ",", "screenwriter", ",", "producer", "and", "actor", "[unused2]", "[unused3]", "best", "known", "[unused4]", "[unused5]", "for", "writing", "and", "directing", "the", "Academy", "Award", "##-", "##win", "##ning", "Foreign", "Language", "Film", "`", "##`", "T", "##so", "##ts", "##i", "[unused6]", "[SEP]"]]}

input 87:  {"source": "George Bluth Sr. , patriarch of the Bluth family , is the founder and former CEO of the Bluth Company which markets and builds mini-mansions among many other activities .\n"}
prediction:  {"predictions": [[1, 1667, 15223, 1582, 8731, 28138, 2, 3, 1110, 4, 5, 1103, 3249, 1105, 1393, 5058, 1104, 1103, 15223, 1582, 1881, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 15223, 1582, 1881, 2, 3, 17850, 4, 5, 8715, 28137, 14761, 5266, 1621, 1242, 1168, 2619, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1667, 15223, 1582, 8731, 28138, 2, 3, 1110, 4, 5, 1103, 3249, 1105, 1393, 5058, 1104, 1103, 15223, 1582, 1881, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 15223, 1582, 1881, 2, 3, 5809, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1667, 15223, 1582, 8731, 28138, 2, 3, 1110, 27797, 1104, 4, 5, 1103, 15223, 1582, 1266, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.041654665023088455, -0.06630955636501312, -0.06473858654499054, -0.12449508160352707, -0.057615719735622406, -0.05561995506286621, -0.05562853813171387, -0.05562853813171387, -0.05562853813171387, -0.05562853813171387], "metadata": {"source_tokens": ["George", "Blu", "##th", "Sr", "##.", ",", "patriarch", "of", "the", "Blu", "##th", "family", ",", "is", "the", "founder", "and", "former", "CEO", "of", "the", "Blu", "##th", "Company", "which", "markets", "and", "builds", "mini", "##-", "##mans", "##ions", "among", "many", "other", "activities", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "George", "Blu", "##th", "Sr", "##.", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "founder", "and", "former", "CEO", "of", "the", "Blu", "##th", "Company", "[unused6]", "[SEP]", "[unused1]", "the", "Blu", "##th", "Company", "[unused2]", "[unused3]", "builds", "[unused4]", "[unused5]", "mini", "##-", "##mans", "##ions", "among", "many", "other", "activities", "[unused6]", "[SEP]", "[unused1]", "George", "Blu", "##th", "Sr", "##.", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "founder", "and", "former", "CEO", "of", "the", "Blu", "##th", "Company", "[unused6]", "[SEP]", "[unused1]", "the", "Blu", "##th", "Company", "[unused2]", "[unused3]", "markets", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "George", "Blu", "##th", "Sr", "##.", "[unused2]", "[unused3]", "is", "patriarch", "of", "[unused4]", "[unused5]", "the", "Blu", "##th", "family", "[unused6]", "[SEP]"]]}

input 88:  {"source": "Godzilla and Battra battled on the ocean floor , until they caused a rift to open between tectonic plates .\n"}
prediction:  {"predictions": [[1, 1875, 20366, 1105, 21928, 4487, 2, 3, 21600, 4, 5, 1113, 1103, 5969, 1837, 1235, 1152, 2416, 170, 25414, 1106, 1501, 1206, 21359, 26176, 1596, 7463, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 2416, 4, 5, 170, 25414, 1106, 1501, 1206, 21359, 26176, 1596, 7463, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.003434707410633564, -0.0012390746269375086, -0.060221195220947266, -0.05592036247253418, -0.05592036247253418, -0.05592036247253418, -0.05592036247253418, -0.05592036247253418, -0.05592036247253418, -0.05592036247253418], "metadata": {"source_tokens": ["God", "##zilla", "and", "Bat", "##tra", "battled", "on", "the", "ocean", "floor", ",", "until", "they", "caused", "a", "rift", "to", "open", "between", "te", "##cton", "##ic", "plates", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "God", "##zilla", "and", "Bat", "##tra", "[unused2]", "[unused3]", "battled", "[unused4]", "[unused5]", "on", "the", "ocean", "floor", "until", "they", "caused", "a", "rift", "to", "open", "between", "te", "##cton", "##ic", "plates", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "caused", "[unused4]", "[unused5]", "a", "rift", "to", "open", "between", "te", "##cton", "##ic", "plates", "[unused6]", "[SEP]"]]}

input 89:  {"source": "Good 1H NMR spectra can be acquired with 16 repeats , which takes only minutes .\n"}
prediction:  {"predictions": [[1, 1479, 19811, 2, 3, 2274, 4, 5, 1178, 1904, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2750, 122, 3048, 151, 21148, 188, 26426, 1611, 2, 3, 1169, 1129, 2888, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.004739562515169382, -0.008342815563082695, -0.05243945121765137, -0.05291628837585449, -0.05291628837585449, -0.05291628837585449, -0.05291628837585449, -0.05291628837585449, -0.05291628837585449, -0.05291628837585449], "metadata": {"source_tokens": ["Good", "1", "##H", "N", "##MR", "s", "##pect", "##ra", "can", "be", "acquired", "with", "16", "repeats", ",", "which", "takes", "only", "minutes", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "16", "repeats", "[unused2]", "[unused3]", "takes", "[unused4]", "[unused5]", "only", "minutes", "[unused6]", "[SEP]", "[unused1]", "Good", "1", "##H", "N", "##MR", "s", "##pect", "##ra", "[unused2]", "[unused3]", "can", "be", "acquired", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 90:  {"source": "HTB 's aim is for an Alpha course to be accessible to anyone who would like to attend the course , and in this way HTB seeks to spread the teachings of Christianity .\n"}
prediction:  {"predictions": [[1, 145, 1942, 2064, 112, 1116, 6457, 2, 3, 1110, 4, 5, 1111, 1126, 8461, 1736, 1106, 1129, 7385, 1106, 2256, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 145, 1942, 2064, 2, 3, 11053, 1106, 2819, 4, 5, 1103, 12815, 1104, 7522, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2256, 2, 3, 1156, 1176, 1106, 4739, 4, 5, 1103, 1736, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 145, 1942, 2064, 2, 3, 11053, 4, 5, 1106, 2819, 1103, 12815, 1104, 7522, 1107, 1142, 1236, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 145, 1942, 2064, 2, 3, 11053, 4, 5, 1106, 2819, 1103, 12815, 1104, 7522, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.023386763408780098, -0.029966533184051514, -0.12273711711168289, -0.06365971267223358, -0.10294979810714722, -0.22267413139343262, -0.22267413139343262, -0.22267413139343262, -0.22267413139343262, -0.22267413139343262], "metadata": {"source_tokens": ["H", "##T", "##B", "'", "##s", "aim", "is", "for", "an", "Alpha", "course", "to", "be", "accessible", "to", "anyone", "who", "would", "like", "to", "attend", "the", "course", ",", "and", "in", "this", "way", "H", "##T", "##B", "seeks", "to", "spread", "the", "teachings", "of", "Christianity", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "H", "##T", "##B", "'", "##s", "aim", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "for", "an", "Alpha", "course", "to", "be", "accessible", "to", "anyone", "[unused6]", "[SEP]", "[unused1]", "H", "##T", "##B", "[unused2]", "[unused3]", "seeks", "to", "spread", "[unused4]", "[unused5]", "the", "teachings", "of", "Christianity", "[unused6]", "[SEP]", "[unused1]", "anyone", "[unused2]", "[unused3]", "would", "like", "to", "attend", "[unused4]", "[unused5]", "the", "course", "[unused6]", "[SEP]", "[unused1]", "H", "##T", "##B", "[unused2]", "[unused3]", "seeks", "[unused4]", "[unused5]", "to", "spread", "the", "teachings", "of", "Christianity", "in", "this", "way", "[unused6]", "[SEP]", "[unused1]", "H", "##T", "##B", "[unused2]", "[unused3]", "seeks", "[unused4]", "[unused5]", "to", "spread", "the", "teachings", "of", "Christianity", "[unused6]", "[SEP]"]]}

input 91:  {"source": "Hapoel Lod played in the top division during the 1960s and 1980s , and won the State Cup in 1984 .\n"}
prediction:  {"predictions": [[1, 27227, 10605, 1181, 2, 3, 1281, 4, 5, 1103, 1426, 1635, 1107, 2219, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 27227, 10605, 1181, 2, 3, 1307, 4, 5, 1107, 1103, 1499, 2417, 1219, 1103, 3266, 1105, 3011, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02299177646636963, -0.005759847350418568, -0.14503908157348633, -0.14503908157348633, -0.14503908157348633, -0.14503908157348633, -0.14503908157348633, -0.14503908157348633, -0.14503908157348633, -0.14503908157348633], "metadata": {"source_tokens": ["Hapoel", "Lo", "##d", "played", "in", "the", "top", "division", "during", "the", "1960s", "and", "1980s", ",", "and", "won", "the", "State", "Cup", "in", "1984", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hapoel", "Lo", "##d", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "the", "State", "Cup", "in", "1984", "[unused6]", "[SEP]", "[unused1]", "Hapoel", "Lo", "##d", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "in", "the", "top", "division", "during", "the", "1960s", "and", "1980s", "[unused6]", "[SEP]"]]}

input 92:  {"source": "Having been directed to found a monastery of his order in the United States in 1873 , Fr .\n"}
prediction:  {"predictions": [[1, 13359, 2, 3, 1151, 2002, 4, 5, 1106, 1276, 170, 7197, 1104, 1117, 1546, 1107, 1103, 1244, 1311, 1107, 7110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.029525380581617355, -0.007846355438232422, -0.008381843566894531, -0.008381843566894531, -0.008381843566894531, -0.008381843566894531, -0.008381843566894531, -0.008381843566894531, -0.008381843566894531, -0.008381843566894531], "metadata": {"source_tokens": ["Having", "been", "directed", "to", "found", "a", "monastery", "of", "his", "order", "in", "the", "United", "States", "in", "1873", ",", "Fr", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Fr", "[unused2]", "[unused3]", "been", "directed", "[unused4]", "[unused5]", "to", "found", "a", "monastery", "of", "his", "order", "in", "the", "United", "States", "in", "1873", "[unused6]", "[SEP]"]]}

input 93:  {"source": "Hawker Pacific Aerospace is a MRO-Service company which offers landing gear and hydraulic MRO services for all major aircraft types .\n"}
prediction:  {"predictions": [[1, 28064, 1197, 2662, 19417, 2, 3, 1110, 4, 5, 170, 25827, 2346, 28137, 1708, 1200, 14301, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 25827, 2346, 28137, 1708, 1200, 14301, 1419, 2, 3, 3272, 4, 5, 4636, 6990, 1105, 16872, 25827, 2346, 1826, 1111, 1155, 1558, 2163, 3322, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0034343302249908447, -0.0009318419615738094, -0.0036001205444335938, -0.0035610198974609375, -0.0035610198974609375, -0.0035610198974609375, -0.0035610198974609375, -0.0035610198974609375, -0.0035610198974609375, -0.0035610198974609375], "metadata": {"source_tokens": ["Hawke", "##r", "Pacific", "Aerospace", "is", "a", "MR", "##O", "##-", "##S", "##er", "##vice", "company", "which", "offers", "landing", "gear", "and", "hydraulic", "MR", "##O", "services", "for", "all", "major", "aircraft", "types", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hawke", "##r", "Pacific", "Aerospace", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "MR", "##O", "##-", "##S", "##er", "##vice", "company", "[unused6]", "[SEP]", "[unused1]", "a", "MR", "##O", "##-", "##S", "##er", "##vice", "company", "[unused2]", "[unused3]", "offers", "[unused4]", "[unused5]", "landing", "gear", "and", "hydraulic", "MR", "##O", "services", "for", "all", "major", "aircraft", "types", "[unused6]", "[SEP]"]]}

input 94:  {"source": "He also possesses enhanced senses and can track people for great distances over open terrain and his feet are sensitive enough to detect electronic signals through solid walls and floors .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 15614, 4, 5, 9927, 9439, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 1623, 2, 3, 1132, 4, 5, 7246, 1536, 1106, 11552, 4828, 7981, 1194, 4600, 2928, 1105, 7849, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1169, 1854, 4, 5, 1234, 1111, 1632, 12424, 1166, 1501, 9260, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.07807957381010056, -0.03180435672402382, -0.03190590441226959, -0.21886682510375977, -0.237046480178833, -0.237046480178833, -0.237046480178833, -0.237046480178833, -0.237046480178833, -0.237046480178833], "metadata": {"source_tokens": ["He", "also", "possesses", "enhanced", "senses", "and", "can", "track", "people", "for", "great", "distances", "over", "open", "terrain", "and", "his", "feet", "are", "sensitive", "enough", "to", "detect", "electronic", "signals", "through", "solid", "walls", "and", "floors", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "possesses", "[unused4]", "[unused5]", "enhanced", "senses", "[unused6]", "[SEP]", "[unused1]", "his", "feet", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "sensitive", "enough", "to", "detect", "electronic", "signals", "through", "solid", "walls", "and", "floors", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "can", "track", "[unused4]", "[unused5]", "people", "for", "great", "distances", "over", "open", "terrain", "[unused6]", "[SEP]"]]}

input 95:  {"source": "He also took 124 wickets , with 7 for 39 and 6 for 44 against Sargodha in 1962-63 his best bowling figures .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1261, 4, 5, 13743, 10267, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1261, 4, 5, 13743, 10267, 1114, 128, 1111, 3614, 1105, 127, 1111, 3140, 1222, 17784, 17161, 14016, 1107, 2832, 28137, 1545, 1495, 1117, 1436, 11518, 3736, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.01642482914030552, -0.017061803489923477, -0.0765678882598877, -0.07676196098327637, -0.07676196098327637, -0.07676196098327637, -0.07676196098327637, -0.07676196098327637, -0.07676196098327637, -0.07676196098327637], "metadata": {"source_tokens": ["He", "also", "took", "124", "wickets", ",", "with", "7", "for", "39", "and", "6", "for", "44", "against", "Sa", "##rgo", "##dha", "in", "1962", "##-", "##6", "##3", "his", "best", "bowling", "figures", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "124", "wickets", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "124", "wickets", "with", "7", "for", "39", "and", "6", "for", "44", "against", "Sa", "##rgo", "##dha", "in", "1962", "##-", "##6", "##3", "his", "best", "bowling", "figures", "[unused6]", "[SEP]"]]}

input 96:  {"source": "He appeared in that game alongside his Arsenal midfield colleague Brian Marwood , who had joined them from Sheffield Wednesday eight months earlier .\n"}
prediction:  {"predictions": [[1, 1117, 10503, 26599, 11864, 3579, 9751, 2615, 2, 3, 1125, 1688, 4, 5, 1172, 1121, 8139, 9031, 2022, 1808, 2206, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1691, 4, 5, 1107, 1115, 1342, 3338, 1117, 10503, 26599, 11864, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.015930714085698128, -0.04418467730283737, -0.14598417282104492, -0.3023965358734131, -0.3023965358734131, -0.3023965358734131, -0.3023965358734131, -0.3023965358734131, -0.3023965358734131, -0.3023965358734131], "metadata": {"source_tokens": ["He", "appeared", "in", "that", "game", "alongside", "his", "Arsenal", "midfield", "colleague", "Brian", "Mar", "##wood", ",", "who", "had", "joined", "them", "from", "Sheffield", "Wednesday", "eight", "months", "earlier", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "his", "Arsenal", "midfield", "colleague", "Brian", "Mar", "##wood", "[unused2]", "[unused3]", "had", "joined", "[unused4]", "[unused5]", "them", "from", "Sheffield", "Wednesday", "eight", "months", "earlier", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "in", "that", "game", "alongside", "his", "Arsenal", "midfield", "colleague", "[unused6]", "[SEP]"]]}

input 97:  {"source": "He defines Wild Cards as ` Low Probability , High Impact events that , were they to occur , would severely impact the human condition ' .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 12028, 4, 5, 5469, 10103, 1116, 1112, 169, 8274, 5096, 2822, 5474, 117, 1693, 13788, 1958, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8274, 5096, 2822, 5474, 117, 1693, 13788, 1958, 2, 3, 1156, 8669, 3772, 4, 5, 1103, 1769, 3879, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1106, 4467, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.003954226151108742, -0.061816174536943436, -0.07156200706958771, -0.0625300407409668, -0.06253743171691895, -0.06253743171691895, -0.06253743171691895, -0.06253743171691895, -0.06253743171691895, -0.06253743171691895], "metadata": {"source_tokens": ["He", "defines", "Wild", "Card", "##s", "as", "`", "Low", "Pro", "##ba", "##bility", ",", "High", "Impact", "events", "that", ",", "were", "they", "to", "occur", ",", "would", "severely", "impact", "the", "human", "condition", "'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "defines", "[unused4]", "[unused5]", "Wild", "Card", "##s", "as", "`", "Low", "Pro", "##ba", "##bility", ",", "High", "Impact", "events", "[unused6]", "[SEP]", "[unused1]", "Low", "Pro", "##ba", "##bility", ",", "High", "Impact", "events", "[unused2]", "[unused3]", "would", "severely", "impact", "[unused4]", "[unused5]", "the", "human", "condition", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "to", "occur", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 98:  {"source": "He finds himself in a desert as a group of Neo Arcadians surround him , ending the game .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 4090, 4, 5, 1471, 1107, 170, 6941, 1112, 170, 1372, 1104, 14521, 18647, 21403, 2316, 16858, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 4090, 4, 5, 1471, 1107, 170, 6941, 1112, 170, 1372, 1104, 14521, 18647, 21403, 2316, 16858, 1140, 3830, 1103, 1342, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0031255846843123436, -0.053486648947000504, -0.14368534088134766, -0.14376401901245117, -0.14376401901245117, -0.14376401901245117, -0.14376401901245117, -0.14376401901245117, -0.14376401901245117, -0.14376401901245117], "metadata": {"source_tokens": ["He", "finds", "himself", "in", "a", "desert", "as", "a", "group", "of", "Neo", "Arc", "##adia", "##ns", "surround", "him", ",", "ending", "the", "game", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "finds", "[unused4]", "[unused5]", "himself", "in", "a", "desert", "as", "a", "group", "of", "Neo", "Arc", "##adia", "##ns", "surround", "him", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "finds", "[unused4]", "[unused5]", "himself", "in", "a", "desert", "as", "a", "group", "of", "Neo", "Arc", "##adia", "##ns", "surround", "him", "ending", "the", "game", "[unused6]", "[SEP]"]]}

input 99:  {"source": "He had spent 11 years in jail despite having been acquitted twice .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1125, 2097, 4, 5, 1429, 1201, 1107, 7237, 2693, 1515, 1151, 20183, 3059, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.003569904016330838, -0.0029306411743164062, -0.0029306411743164062, -0.0029306411743164062, -0.0029306411743164062, -0.0029306411743164062, -0.0029306411743164062, -0.0029306411743164062, -0.0029306411743164062, -0.0029306411743164062], "metadata": {"source_tokens": ["He", "had", "spent", "11", "years", "in", "jail", "despite", "having", "been", "acquitted", "twice", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "had", "spent", "[unused4]", "[unused5]", "11", "years", "in", "jail", "despite", "having", "been", "acquitted", "twice", "[unused6]", "[SEP]"]]}

input 100:  {"source": "He is idolized , receiving the name of `` God '' .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1110, 17642, 2200, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 4172, 4, 5, 1103, 1271, 1104, 169, 28152, 1875, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02171945571899414, -0.0243703443557024, -0.0026140213012695312, -0.0026307106018066406, -0.0026307106018066406, -0.0026307106018066406, -0.0026307106018066406, -0.0026307106018066406, -0.0026307106018066406, -0.0026307106018066406], "metadata": {"source_tokens": ["He", "is", "idol", "##ized", ",", "receiving", "the", "name", "of", "`", "##`", "God", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "is", "idol", "##ized", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "receiving", "[unused4]", "[unused5]", "the", "name", "of", "`", "##`", "God", "[unused6]", "[SEP]"]]}

input 101:  {"source": "He left his old company , V2 records , wanting to expand his career into something bigger .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1286, 4, 5, 1117, 1385, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 1385, 1419, 2, 3, 1110, 4, 5, 159, 1477, 3002, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1286, 1117, 1385, 1419, 5277, 1106, 7380, 4, 5, 1117, 1578, 1154, 1380, 6706, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02664848230779171, -0.10753722488880157, -0.07866767048835754, -0.08285784721374512, -0.08323359489440918, -0.08323359489440918, -0.08323359489440918, -0.08323359489440918, -0.08323359489440918, -0.08323359489440918], "metadata": {"source_tokens": ["He", "left", "his", "old", "company", ",", "V", "##2", "records", ",", "wanting", "to", "expand", "his", "career", "into", "something", "bigger", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "his", "old", "company", "[unused6]", "[SEP]", "[unused1]", "his", "old", "company", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "V", "##2", "records", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "left", "his", "old", "company", "wanting", "to", "expand", "[unused4]", "[unused5]", "his", "career", "into", "something", "bigger", "[unused6]", "[SEP]"]]}

input 102:  {"source": "He left only a small contingent to guard the defile , and took his entire army to destroy the plain that lay ahead of Alexander 's army .\n"}
prediction:  {"predictions": [[1, 1103, 6188, 2, 3, 3191, 4, 5, 3075, 1104, 2792, 112, 1116, 2306, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1286, 4, 5, 1178, 170, 1353, 17286, 1106, 3542, 1103, 19353, 4759, 117, 1105, 1261, 1117, 2072, 2306, 1106, 5535, 1103, 6188, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1261, 4, 5, 1117, 2072, 2306, 1106, 5535, 1103, 6188, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03960014134645462, -0.04515691474080086, -0.04018121212720871, -0.22265028953552246, -0.22264432907104492, -0.22264432907104492, -0.22264432907104492, -0.22264432907104492, -0.22264432907104492, -0.22264432907104492], "metadata": {"source_tokens": ["He", "left", "only", "a", "small", "contingent", "to", "guard", "the", "def", "##ile", ",", "and", "took", "his", "entire", "army", "to", "destroy", "the", "plain", "that", "lay", "ahead", "of", "Alexander", "'", "##s", "army", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "plain", "[unused2]", "[unused3]", "lay", "[unused4]", "[unused5]", "ahead", "of", "Alexander", "'", "##s", "army", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "only", "a", "small", "contingent", "to", "guard", "the", "def", "##ile", ",", "and", "took", "his", "entire", "army", "to", "destroy", "the", "plain", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "his", "entire", "army", "to", "destroy", "the", "plain", "[unused6]", "[SEP]"]]}

input 103:  {"source": "He lodged near the hospital at 28 St Thomas 's Street in Southwark , with other medical students , including Henry Stephens who became a famous inventor and ink magnate .\n"}
prediction:  {"predictions": [[1, 1985, 15752, 2, 3, 1245, 4, 5, 170, 2505, 12989, 1105, 12816, 12477, 21772, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 22422, 4, 5, 1485, 1103, 2704, 1120, 1743, 1457, 1819, 112, 1116, 1715, 1107, 1375, 27319, 117, 1114, 1168, 2657, 1651, 117, 1259, 1985, 15752, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.018287882208824158, -0.032043226063251495, -0.1354379653930664, -0.14504194259643555, -0.14504194259643555, -0.14504194259643555, -0.14504194259643555, -0.14504194259643555, -0.14504194259643555, -0.14504194259643555], "metadata": {"source_tokens": ["He", "lodged", "near", "the", "hospital", "at", "28", "St", "Thomas", "'", "##s", "Street", "in", "South", "##wark", ",", "with", "other", "medical", "students", ",", "including", "Henry", "Stephens", "who", "became", "a", "famous", "inventor", "and", "ink", "ma", "##gnate", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Henry", "Stephens", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "a", "famous", "inventor", "and", "ink", "ma", "##gnate", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "lodged", "[unused4]", "[unused5]", "near", "the", "hospital", "at", "28", "St", "Thomas", "'", "##s", "Street", "in", "South", "##wark", ",", "with", "other", "medical", "students", ",", "including", "Henry", "Stephens", "[unused6]", "[SEP]"]]}

input 104:  {"source": "He played Perker in the 1985 adaptation of `` The Pickwick Papers '' .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1307, 4, 5, 14286, 4188, 1107, 1103, 2210, 6350, 1104, 169, 28152, 1109, 20984, 6196, 19023, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0033139099832624197, -0.001918792724609375, -0.0019307136535644531, -0.0019307136535644531, -0.0019307136535644531, -0.0019307136535644531, -0.0019307136535644531, -0.0019307136535644531, -0.0019307136535644531, -0.0019307136535644531], "metadata": {"source_tokens": ["He", "played", "Per", "##ker", "in", "the", "1985", "adaptation", "of", "`", "##`", "The", "Pick", "##wick", "Papers", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "Per", "##ker", "in", "the", "1985", "adaptation", "of", "`", "##`", "The", "Pick", "##wick", "Papers", "[unused6]", "[SEP]"]]}

input 105:  {"source": "He represented the riding of Nickel Belt in the Sudbury , Ontario area .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 2533, 4, 5, 1103, 5569, 1104, 3350, 1883, 15834, 1107, 1103, 15463, 26837, 117, 3717, 1298, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0073377653025090694, -0.0024881362915039062, -0.0024728775024414062, -0.0024728775024414062, -0.0024728775024414062, -0.0024728775024414062, -0.0024728775024414062, -0.0024728775024414062, -0.0024728775024414062, -0.0024728775024414062], "metadata": {"source_tokens": ["He", "represented", "the", "riding", "of", "Nick", "##el", "Belt", "in", "the", "Su", "##dbury", ",", "Ontario", "area", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "represented", "[unused4]", "[unused5]", "the", "riding", "of", "Nick", "##el", "Belt", "in", "the", "Su", "##dbury", ",", "Ontario", "area", "[unused6]", "[SEP]"]]}

input 106:  {"source": "He talked to McGee about using his name and received permission , which is confirmed by correspondence between McGee and his family .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 5029, 4, 5, 1106, 24539, 1164, 1606, 1117, 1271, 1105, 1460, 6156, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6156, 2, 3, 1110, 3659, 4, 5, 1118, 12052, 1206, 24539, 1105, 1117, 1266, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.044637322425842285, -0.004598673898726702, -0.14261651039123535, -0.14705204963684082, -0.14705204963684082, -0.14705204963684082, -0.14705204963684082, -0.14705204963684082, -0.14705204963684082, -0.14705204963684082], "metadata": {"source_tokens": ["He", "talked", "to", "McGee", "about", "using", "his", "name", "and", "received", "permission", ",", "which", "is", "confirmed", "by", "correspondence", "between", "McGee", "and", "his", "family", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "talked", "[unused4]", "[unused5]", "to", "McGee", "about", "using", "his", "name", "and", "received", "permission", "[unused6]", "[SEP]", "[unused1]", "permission", "[unused2]", "[unused3]", "is", "confirmed", "[unused4]", "[unused5]", "by", "correspondence", "between", "McGee", "and", "his", "family", "[unused6]", "[SEP]"]]}

input 107:  {"source": "He was a member of the European Convention , which drafted the text of the European Constitution that never entered into force .\n"}
prediction:  {"predictions": [[1, 1103, 1735, 5317, 2, 3, 1309, 2242, 4, 5, 1154, 2049, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1735, 5818, 2, 3, 7071, 4, 5, 1103, 3087, 1104, 1103, 1735, 5317, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1108, 4, 5, 170, 1420, 1104, 1103, 1735, 5818, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.05135585740208626, -0.03324486315250397, -0.01799779012799263, -0.0016794204711914062, -0.0016999244689941406, -0.0016999244689941406, -0.0016999244689941406, -0.0016999244689941406, -0.0016999244689941406, -0.0016999244689941406], "metadata": {"source_tokens": ["He", "was", "a", "member", "of", "the", "European", "Convention", ",", "which", "drafted", "the", "text", "of", "the", "European", "Constitution", "that", "never", "entered", "into", "force", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "European", "Constitution", "[unused2]", "[unused3]", "never", "entered", "[unused4]", "[unused5]", "into", "force", "[unused6]", "[SEP]", "[unused1]", "the", "European", "Convention", "[unused2]", "[unused3]", "drafted", "[unused4]", "[unused5]", "the", "text", "of", "the", "European", "Constitution", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "member", "of", "the", "European", "Convention", "[unused6]", "[SEP]"]]}

input 108:  {"source": "He was buried in the Abbey of the Psalms mausoleum at the Hollywood Forever Cemetery .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1108, 3126, 4, 5, 1107, 1103, 6674, 1104, 1103, 153, 11794, 4206, 27685, 1120, 1103, 4613, 11694, 5501, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0007107853889465332, -0.0018873214721679688, -0.0019068717956542969, -0.0019068717956542969, -0.0019068717956542969, -0.0019068717956542969, -0.0019068717956542969, -0.0019068717956542969, -0.0019068717956542969, -0.0019068717956542969], "metadata": {"source_tokens": ["He", "was", "buried", "in", "the", "Abbey", "of", "the", "P", "##sal", "##ms", "mausoleum", "at", "the", "Hollywood", "Forever", "Cemetery", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "was", "buried", "[unused4]", "[unused5]", "in", "the", "Abbey", "of", "the", "P", "##sal", "##ms", "mausoleum", "at", "the", "Hollywood", "Forever", "Cemetery", "[unused6]", "[SEP]"]]}

input 109:  {"source": "He was subsequently reprieved for a month , and then again for a week .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1108, 1231, 1643, 27055, 1181, 4, 5, 1111, 170, 2370, 1105, 1173, 1254, 1111, 170, 1989, 2886, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.05478084459900856, -0.05270743370056152, -0.05499720573425293, -0.05499720573425293, -0.05499720573425293, -0.05499720573425293, -0.05499720573425293, -0.05499720573425293, -0.05499720573425293, -0.05499720573425293], "metadata": {"source_tokens": ["He", "was", "subsequently", "re", "##p", "##rieve", "##d", "for", "a", "month", ",", "and", "then", "again", "for", "a", "week", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "was", "re", "##p", "##rieve", "##d", "[unused4]", "[unused5]", "for", "a", "month", "and", "then", "again", "for", "a", "week", "subsequently", "[unused6]", "[SEP]"]]}

input 110:  {"source": "Her image held aloft signifies the Earth , which `` hangs in the air '' .\n"}
prediction:  {"predictions": [[1, 1430, 3077, 1316, 2393, 18874, 2, 3, 2951, 9387, 4, 5, 1103, 2746, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2746, 2, 3, 19565, 4, 5, 1107, 1103, 1586, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.016673684120178223, -0.004320062231272459, -0.17606163024902344, -0.17200398445129395, -0.17200398445129395, -0.17200398445129395, -0.17200398445129395, -0.17200398445129395, -0.17200398445129395, -0.17200398445129395], "metadata": {"source_tokens": ["Her", "image", "held", "al", "##oft", "sign", "##ifies", "the", "Earth", ",", "which", "`", "##`", "hangs", "in", "the", "air", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Her", "image", "held", "al", "##oft", "[unused2]", "[unused3]", "sign", "##ifies", "[unused4]", "[unused5]", "the", "Earth", "[unused6]", "[SEP]", "[unused1]", "the", "Earth", "[unused2]", "[unused3]", "hangs", "[unused4]", "[unused5]", "in", "the", "air", "[unused6]", "[SEP]"]]}

input 111:  {"source": "Hilf al-Fudul was a 7th-century alliance created by various Meccans , including the Islamic prophet Muhammad , to establish fair commercial dealing .\n"}
prediction:  {"predictions": [[1, 8790, 9654, 2393, 28137, 2271, 4867, 4654, 2, 3, 1108, 4, 5, 170, 4766, 28137, 8298, 11366, 7214, 1687, 1118, 1672, 25160, 2316, 117, 1259, 1103, 4769, 20718, 6710, 117, 1106, 4586, 4652, 2595, 6705, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4766, 28137, 8298, 11366, 7214, 2, 3, 1687, 4, 5, 1118, 1672, 25160, 2316, 117, 1259, 1103, 4769, 20718, 6710, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.006739842239767313, -0.041522521525621414, -0.1462843418121338, -0.14641928672790527, -0.14641928672790527, -0.14641928672790527, -0.14641928672790527, -0.14641928672790527, -0.14641928672790527, -0.14641928672790527], "metadata": {"source_tokens": ["Hi", "##lf", "al", "##-", "##F", "##ud", "##ul", "was", "a", "7th", "##-", "##cent", "##ury", "alliance", "created", "by", "various", "Mecca", "##ns", ",", "including", "the", "Islamic", "prophet", "Muhammad", ",", "to", "establish", "fair", "commercial", "dealing", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hi", "##lf", "al", "##-", "##F", "##ud", "##ul", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "7th", "##-", "##cent", "##ury", "alliance", "created", "by", "various", "Mecca", "##ns", ",", "including", "the", "Islamic", "prophet", "Muhammad", ",", "to", "establish", "fair", "commercial", "dealing", "[unused6]", "[SEP]", "[unused1]", "a", "7th", "##-", "##cent", "##ury", "alliance", "[unused2]", "[unused3]", "created", "[unused4]", "[unused5]", "by", "various", "Mecca", "##ns", ",", "including", "the", "Islamic", "prophet", "Muhammad", "[unused6]", "[SEP]"]]}

input 112:  {"source": "Historically , Aiseau was a village dedicated to agriculture , logging , but also to the industry .\n"}
prediction:  {"predictions": [[1, 19294, 24405, 2, 3, 1108, 4, 5, 170, 1491, 3256, 1106, 6487, 117, 17844, 117, 1133, 1145, 1106, 1103, 2380, 14630, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0040284148417413235, -0.0030493736267089844, -0.0031938552856445312, -0.0031938552856445312, -0.0031938552856445312, -0.0031938552856445312, -0.0031938552856445312, -0.0031938552856445312, -0.0031938552856445312, -0.0031938552856445312], "metadata": {"source_tokens": ["Historically", ",", "Ai", "##seau", "was", "a", "village", "dedicated", "to", "agriculture", ",", "logging", ",", "but", "also", "to", "the", "industry", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ai", "##seau", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "village", "dedicated", "to", "agriculture", ",", "logging", ",", "but", "also", "to", "the", "industry", "Historically", "[unused6]", "[SEP]"]]}

input 113:  {"source": "Hoechst 33342 and 33258 are quenched by Bromodeoxyuridine , which is commonly used to detect dividing cells .\n"}
prediction:  {"predictions": [[1, 139, 16071, 13040, 10649, 9379, 10132, 2042, 2, 3, 1110, 3337, 1215, 4, 5, 1106, 11552, 18699, 3652, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9800, 11252, 2050, 23335, 23117, 1105, 3081, 17600, 1604, 2, 3, 1132, 15027, 15986, 4, 5, 1118, 139, 16071, 13040, 10649, 9379, 10132, 2042, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.028426749631762505, -0.0009238278144039214, -0.05144023895263672, -0.05142021179199219, -0.05142021179199219, -0.05142021179199219, -0.05142021179199219, -0.05142021179199219, -0.05142021179199219, -0.05142021179199219], "metadata": {"source_tokens": ["Ho", "##ech", "##st", "333", "##42", "and", "33", "##25", "##8", "are", "que", "##nched", "by", "B", "##rom", "##ode", "##ox", "##yu", "##rid", "##ine", ",", "which", "is", "commonly", "used", "to", "detect", "dividing", "cells", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "B", "##rom", "##ode", "##ox", "##yu", "##rid", "##ine", "[unused2]", "[unused3]", "is", "commonly", "used", "[unused4]", "[unused5]", "to", "detect", "dividing", "cells", "[unused6]", "[SEP]", "[unused1]", "Ho", "##ech", "##st", "333", "##42", "and", "33", "##25", "##8", "[unused2]", "[unused3]", "are", "que", "##nched", "[unused4]", "[unused5]", "by", "B", "##rom", "##ode", "##ox", "##yu", "##rid", "##ine", "[unused6]", "[SEP]"]]}

input 114:  {"source": "Hofmann was a below-average high school student , but he had many hobbies including magic , electronics , chemistry , and stamp and coin collecting .\n"}
prediction:  {"predictions": [[1, 9800, 2087, 4119, 2, 3, 1108, 4, 5, 170, 2071, 28137, 18195, 2553, 1344, 1278, 2377, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1125, 4, 5, 1242, 16358, 13834, 1905, 1259, 3974, 117, 11216, 117, 8117, 117, 1105, 13182, 1105, 9584, 9370, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.017707999795675278, -0.0040665571577847, -0.03336596488952637, -0.008457183837890625, -0.008457183837890625, -0.008457183837890625, -0.008457183837890625, -0.008457183837890625, -0.008457183837890625, -0.008457183837890625], "metadata": {"source_tokens": ["Ho", "##f", "##mann", "was", "a", "below", "##-", "##aver", "##age", "high", "school", "student", ",", "but", "he", "had", "many", "ho", "##bb", "##ies", "including", "magic", ",", "electronics", ",", "chemistry", ",", "and", "stamp", "and", "coin", "collecting", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ho", "##f", "##mann", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "below", "##-", "##aver", "##age", "high", "school", "student", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "many", "ho", "##bb", "##ies", "including", "magic", ",", "electronics", ",", "chemistry", ",", "and", "stamp", "and", "coin", "collecting", "[unused6]", "[SEP]"]]}

input 115:  {"source": "However , after pressure campaigns from various human rights groups , BAE Systems recently stated it no longer produces land mines or cluster bombs .\n"}
prediction:  {"predictions": [[1, 12465, 2036, 6475, 2, 3, 2202, 4, 5, 1122, 1185, 2039, 6570, 1657, 7785, 1137, 10005, 10095, 1170, 2997, 7827, 1121, 1672, 1769, 2266, 2114, 3055, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 6570, 4, 5, 1657, 7785, 1137, 10005, 10095, 1185, 2039, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.004873883910477161, -0.01319509744644165, -0.14586281776428223, -0.14473319053649902, -0.14473319053649902, -0.14473319053649902, -0.14473319053649902, -0.14473319053649902, -0.14473319053649902, -0.14473319053649902], "metadata": {"source_tokens": ["However", ",", "after", "pressure", "campaigns", "from", "various", "human", "rights", "groups", ",", "BA", "##E", "Systems", "recently", "stated", "it", "no", "longer", "produces", "land", "mines", "or", "cluster", "bombs", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "BA", "##E", "Systems", "[unused2]", "[unused3]", "stated", "[unused4]", "[unused5]", "it", "no", "longer", "produces", "land", "mines", "or", "cluster", "bombs", "after", "pressure", "campaigns", "from", "various", "human", "rights", "groups", "recently", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "produces", "[unused4]", "[unused5]", "land", "mines", "or", "cluster", "bombs", "no", "longer", "[unused6]", "[SEP]"]]}

input 116:  {"source": "However , comic relief sidekick `` Mike McGurk '' bears some resemblance to Tracy 's partner from the strip , Pat Patton ; Tracy 's secretary , Gwen Andrews , provides the same kind of feminine interest as Tess Trueheart ; and FBI Director Clive Anderson is the same kind of avuncular superior as Chief Brandon .\n"}
prediction:  {"predictions": [[1, 4824, 3893, 1334, 27982, 169, 28152, 2639, 150, 1665, 2349, 2149, 1377, 2, 3, 8807, 4, 5, 1199, 14634, 1106, 10435, 112, 1116, 3547, 1121, 1103, 6322, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8099, 2524, 15295, 4347, 2, 3, 1110, 4, 5, 1103, 1269, 1912, 1104, 170, 25247, 26405, 5552, 7298, 1112, 2534, 8464, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10435, 112, 1116, 4848, 2, 3, 2790, 4, 5, 1103, 1269, 1912, 1104, 13385, 2199, 1112, 16613, 7817, 19233, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6322, 2, 3, 1110, 4, 5, 7195, 19451, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10435, 112, 1116, 4848, 2, 3, 1110, 4, 5, 11746, 8946, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03630927577614784, -0.03001389466226101, -0.03498454391956329, -0.10900051146745682, -0.09609425067901611, -0.15314722061157227, -0.15302824974060059, -0.15302824974060059, -0.15302824974060059, -0.15302824974060059], "metadata": {"source_tokens": ["However", ",", "comic", "relief", "side", "##kick", "`", "##`", "Mike", "M", "##c", "##G", "##ur", "##k", "'", "##'", "bears", "some", "resemblance", "to", "Tracy", "'", "##s", "partner", "from", "the", "strip", ",", "Pat", "Patton", ";", "Tracy", "'", "##s", "secretary", ",", "Gwen", "Andrews", ",", "provides", "the", "same", "kind", "of", "feminine", "interest", "as", "Tess", "True", "##heart", ";", "and", "FBI", "Director", "Clive", "Anderson", "is", "the", "same", "kind", "of", "a", "##vu", "##nc", "##ular", "superior", "as", "Chief", "Brandon", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "comic", "relief", "side", "##kick", "`", "##`", "Mike", "M", "##c", "##G", "##ur", "##k", "[unused2]", "[unused3]", "bears", "[unused4]", "[unused5]", "some", "resemblance", "to", "Tracy", "'", "##s", "partner", "from", "the", "strip", "[unused6]", "[SEP]", "[unused1]", "FBI", "Director", "Clive", "Anderson", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "same", "kind", "of", "a", "##vu", "##nc", "##ular", "superior", "as", "Chief", "Brandon", "[unused6]", "[SEP]", "[unused1]", "Tracy", "'", "##s", "secretary", "[unused2]", "[unused3]", "provides", "[unused4]", "[unused5]", "the", "same", "kind", "of", "feminine", "interest", "as", "Tess", "True", "##heart", "[unused6]", "[SEP]", "[unused1]", "the", "strip", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Pat", "Patton", "[unused6]", "[SEP]", "[unused1]", "Tracy", "'", "##s", "secretary", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Gwen", "Andrews", "[unused6]", "[SEP]"]]}

input 117:  {"source": "However , during his rehearsal , Knievel lost control of the motorcycle and crashed into a cameraman .\n"}
prediction:  {"predictions": [[1, 148, 5213, 12559, 2, 3, 1575, 4, 5, 1654, 1104, 1103, 9580, 1219, 1117, 20762, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 148, 5213, 12559, 2, 3, 7573, 4, 5, 1154, 170, 4504, 1399, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03499232232570648, -0.02809612825512886, -0.22264862060546875, -0.22264909744262695, -0.22264909744262695, -0.22264909744262695, -0.22264909744262695, -0.22264909744262695, -0.22264909744262695, -0.22264909744262695], "metadata": {"source_tokens": ["However", ",", "during", "his", "rehearsal", ",", "K", "##nie", "##vel", "lost", "control", "of", "the", "motorcycle", "and", "crashed", "into", "a", "camera", "##man", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "K", "##nie", "##vel", "[unused2]", "[unused3]", "lost", "[unused4]", "[unused5]", "control", "of", "the", "motorcycle", "during", "his", "rehearsal", "[unused6]", "[SEP]", "[unused1]", "K", "##nie", "##vel", "[unused2]", "[unused3]", "crashed", "[unused4]", "[unused5]", "into", "a", "camera", "##man", "[unused6]", "[SEP]"]]}

input 118:  {"source": "However , it became far less safe for the Nationals from 1983 onward , and strong population growth over the last three decades has seen it progressively lose its rural territory and reduced it to a more coastal-based and urbanised division .\n"}
prediction:  {"predictions": [[1, 2012, 1416, 3213, 1166, 1103, 1314, 1210, 4397, 2, 3, 1144, 1562, 4, 5, 1122, 22770, 3857, 1157, 3738, 3441, 1105, 3549, 1122, 1106, 170, 1167, 5869, 28137, 14017, 1181, 1105, 3953, 3673, 2417, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1245, 4, 5, 1677, 1750, 2914, 1111, 1103, 16101, 1121, 2278, 17765, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 3549, 4, 5, 1122, 1106, 170, 1167, 5869, 28137, 14017, 1181, 1105, 3953, 3673, 2417, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 3857, 4, 5, 1157, 3738, 3441, 22770, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.06515451520681381, -0.016140632331371307, -0.08239047229290009, -0.07759751379489899, -0.22541499137878418, -0.22477245330810547, -0.22477245330810547, -0.22477221488952637, -0.22477221488952637, -0.22477221488952637], "metadata": {"source_tokens": ["However", ",", "it", "became", "far", "less", "safe", "for", "the", "Nationals", "from", "1983", "onward", ",", "and", "strong", "population", "growth", "over", "the", "last", "three", "decades", "has", "seen", "it", "progressively", "lose", "its", "rural", "territory", "and", "reduced", "it", "to", "a", "more", "coastal", "##-", "##base", "##d", "and", "urban", "##ised", "division", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "strong", "population", "growth", "over", "the", "last", "three", "decades", "[unused2]", "[unused3]", "has", "seen", "[unused4]", "[unused5]", "it", "progressively", "lose", "its", "rural", "territory", "and", "reduced", "it", "to", "a", "more", "coastal", "##-", "##base", "##d", "and", "urban", "##ised", "division", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "far", "less", "safe", "for", "the", "Nationals", "from", "1983", "onward", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "reduced", "[unused4]", "[unused5]", "it", "to", "a", "more", "coastal", "##-", "##base", "##d", "and", "urban", "##ised", "division", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "lose", "[unused4]", "[unused5]", "its", "rural", "territory", "progressively", "[unused6]", "[SEP]"]]}

input 119:  {"source": "However , when the antigenicities of the seed strains and wild viruses do not match , vaccines fail to protect the vaccinees .\n"}
prediction:  {"predictions": [[1, 20034, 1116, 2, 3, 8693, 4, 5, 1106, 3244, 1103, 20034, 1279, 1165, 1103, 2848, 19438, 4233, 1104, 1103, 6478, 21116, 1105, 4098, 20942, 1202, 1136, 1801, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2848, 19438, 4233, 1104, 1103, 6478, 21116, 1105, 4098, 20942, 2, 3, 1202, 1136, 1801, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0072803376242518425, -0.0036095997784286737, -0.14380168914794922, -0.14468955993652344, -0.14468955993652344, -0.14468955993652344, -0.14468955993652344, -0.14468955993652344, -0.14468955993652344, -0.14468955993652344], "metadata": {"source_tokens": ["However", ",", "when", "the", "anti", "##genic", "##ities", "of", "the", "seed", "strains", "and", "wild", "viruses", "do", "not", "match", ",", "vaccine", "##s", "fail", "to", "protect", "the", "vaccine", "##es", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "vaccine", "##s", "[unused2]", "[unused3]", "fail", "[unused4]", "[unused5]", "to", "protect", "the", "vaccine", "##es", "when", "the", "anti", "##genic", "##ities", "of", "the", "seed", "strains", "and", "wild", "viruses", "do", "not", "match", "[unused6]", "[SEP]", "[unused1]", "the", "anti", "##genic", "##ities", "of", "the", "seed", "strains", "and", "wild", "viruses", "[unused2]", "[unused3]", "do", "not", "match", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 120:  {"source": "If given this data , the Germans would be able to adjust their aim and correct any shortfall .\n"}
prediction:  {"predictions": [[1, 1103, 6494, 2, 3, 1156, 1129, 4, 5, 1682, 1106, 14878, 1147, 6457, 1105, 5663, 1251, 1603, 8877, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0010437511373311281, -0.16055083274841309, -0.15301132202148438, -0.15301132202148438, -0.15301132202148438, -0.15301132202148438, -0.15301132202148438, -0.15301132202148438, -0.15301132202148438, -0.15301132202148438], "metadata": {"source_tokens": ["If", "given", "this", "data", ",", "the", "Germans", "would", "be", "able", "to", "adjust", "their", "aim", "and", "correct", "any", "short", "##fall", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Germans", "[unused2]", "[unused3]", "would", "be", "[unused4]", "[unused5]", "able", "to", "adjust", "their", "aim", "and", "correct", "any", "short", "##fall", "[unused6]", "[SEP]"]]}

input 121:  {"source": "If the second excitation pulse is sent prematurely before the relaxation is complete , the average magnetization vector still points in a nonparallel direction , giving suboptimal absorption and emission of the pulse .\n"}
prediction:  {"predictions": [[1, 1103, 1903, 24197, 2734, 9479, 2, 3, 1827, 4, 5, 1107, 170, 1664, 17482, 22096, 1233, 2447, 1253, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1248, 4252, 24214, 8561, 2, 3, 1110, 1850, 24505, 1193, 4, 5, 1196, 1103, 27475, 1110, 2335, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1903, 24197, 2734, 9479, 2, 3, 1827, 4, 5, 1107, 170, 1664, 17482, 22096, 1233, 2447, 2368, 4841, 4184, 3121, 7435, 18099, 1105, 17744, 1104, 1103, 8561, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1903, 24197, 2734, 9479, 2, 3, 1827, 4, 5, 1107, 170, 1664, 17482, 22096, 1233, 2447, 2368, 4841, 4184, 3121, 7435, 18099, 1105, 17744, 1104, 1103, 8561, 1409, 1103, 1248, 4252, 24214, 8561, 1110, 1850, 24505, 1193, 1196, 1103, 27475, 1110, 2335, 6, 102, 102, 102, 102, 102, 102, 1, 1103, 1903, 24197, 2734, 9479, 2, 3, 1827, 4, 5, 1107, 170, 1664, 17482, 22096, 1233, 2447, 2368, 4841, 4184, 3121, 7435, 18099, 1105, 17744, 1104, 1103, 8561, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03121289424598217, -0.04032161831855774, -0.03571541607379913, -0.046359833329916, -0.055550847202539444, -0.22274303436279297, -0.22274398803710938, -0.22274398803710938, -0.22274398803710938, -0.22274398803710938], "metadata": {"source_tokens": ["If", "the", "second", "ex", "##citation", "pulse", "is", "sent", "premature", "##ly", "before", "the", "relaxation", "is", "complete", ",", "the", "average", "magnet", "##ization", "vector", "still", "points", "in", "a", "non", "##par", "##alle", "##l", "direction", ",", "giving", "sub", "##op", "##ti", "##mal", "absorption", "and", "emission", "of", "the", "pulse", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "average", "magnet", "##ization", "vector", "[unused2]", "[unused3]", "points", "[unused4]", "[unused5]", "in", "a", "non", "##par", "##alle", "##l", "direction", "still", "[unused6]", "[SEP]", "[unused1]", "the", "second", "ex", "##citation", "pulse", "[unused2]", "[unused3]", "is", "sent", "premature", "##ly", "[unused4]", "[unused5]", "before", "the", "relaxation", "is", "complete", "[unused6]", "[SEP]", "[unused1]", "the", "average", "magnet", "##ization", "vector", "[unused2]", "[unused3]", "points", "[unused4]", "[unused5]", "in", "a", "non", "##par", "##alle", "##l", "direction", "giving", "sub", "##op", "##ti", "##mal", "absorption", "and", "emission", "of", "the", "pulse", "[unused6]", "[SEP]", "[unused1]", "the", "average", "magnet", "##ization", "vector", "[unused2]", "[unused3]", "points", "[unused4]", "[unused5]", "in", "a", "non", "##par", "##alle", "##l", "direction", "giving", "sub", "##op", "##ti", "##mal", "absorption", "and", "emission", "of", "the", "pulse", "If", "the", "second", "ex", "##citation", "pulse", "is", "sent", "premature", "##ly", "before", "the", "relaxation", "is", "complete", "[unused6]", "[SEP]", "[unused1]", "the", "average", "magnet", "##ization", "vector", "[unused2]", "[unused3]", "points", "[unused4]", "[unused5]", "in", "a", "non", "##par", "##alle", "##l", "direction", "giving", "sub", "##op", "##ti", "##mal", "absorption", "and", "emission", "of", "the", "pulse", "[unused6]", "[SEP]"]]}

input 122:  {"source": "In 1005 for example , the governor of the important Adriatic port of Dyrrhachium had surrendered the town to Basil II .\n"}
prediction:  {"predictions": [[1, 1103, 4066, 1104, 1103, 1696, 26122, 4104, 1104, 141, 12577, 1197, 2328, 4313, 1818, 2, 3, 1125, 10738, 4, 5, 1103, 1411, 1106, 16209, 1563, 1130, 1620, 1571, 1111, 1859, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.019495248794555664, -0.12704205513000488, -0.12619566917419434, -0.12619566917419434, -0.12619566917419434, -0.12619566917419434, -0.12619566917419434, -0.12619566917419434, -0.12619566917419434, -0.12619566917419434], "metadata": {"source_tokens": ["In", "100", "##5", "for", "example", ",", "the", "governor", "of", "the", "important", "Adriatic", "port", "of", "D", "##yr", "##r", "##ha", "##chi", "##um", "had", "surrendered", "the", "town", "to", "Basil", "II", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "governor", "of", "the", "important", "Adriatic", "port", "of", "D", "##yr", "##r", "##ha", "##chi", "##um", "[unused2]", "[unused3]", "had", "surrendered", "[unused4]", "[unused5]", "the", "town", "to", "Basil", "II", "In", "100", "##5", "for", "example", "[unused6]", "[SEP]"]]}

input 123:  {"source": "In 1866 , he began a second term as Lord Chancellor , which ended with his death in the next year .\n"}
prediction:  {"predictions": [[1, 2188, 8861, 2, 3, 2207, 4, 5, 1114, 1117, 1473, 1107, 1103, 1397, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1310, 4, 5, 170, 1248, 1858, 1112, 2188, 8861, 1130, 7146, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.018694793805480003, -0.0037826369516551495, -0.05176234245300293, -0.05176234245300293, -0.05176234245300293, -0.05176234245300293, -0.05176234245300293, -0.05176234245300293, -0.05176234245300293, -0.05176234245300293], "metadata": {"source_tokens": ["In", "1866", ",", "he", "began", "a", "second", "term", "as", "Lord", "Chancellor", ",", "which", "ended", "with", "his", "death", "in", "the", "next", "year", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Lord", "Chancellor", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "with", "his", "death", "in", "the", "next", "year", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "a", "second", "term", "as", "Lord", "Chancellor", "In", "1866", "[unused6]", "[SEP]"]]}

input 124:  {"source": "In 1911 , with Francis La Flesche , she published `` The Omaha Tribe '' .\n"}
prediction:  {"predictions": [[1, 1131, 2, 3, 1502, 4, 5, 1109, 13072, 15987, 1130, 4383, 1114, 3720, 2001, 143, 2897, 4386, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.00704877357929945, -0.2567179203033447, -0.25123119354248047, -0.25123143196105957, -0.25123119354248047, -0.25123119354248047, -0.25123119354248047, -0.25123119354248047, -0.25123119354248047, -0.25123119354248047], "metadata": {"source_tokens": ["In", "1911", ",", "with", "Francis", "La", "F", "##les", "##che", ",", "she", "published", "`", "##`", "The", "Omaha", "Tribe", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "she", "[unused2]", "[unused3]", "published", "[unused4]", "[unused5]", "The", "Omaha", "Tribe", "In", "1911", "with", "Francis", "La", "F", "##les", "##che", "[unused6]", "[SEP]"]]}

input 125:  {"source": "In 1926 , `` The News and Courier '' was bought by the owners of Charleston 's main evening paper , `` The Evening Post . ''\n"}
prediction:  {"predictions": [[1, 1109, 3128, 1105, 3291, 16706, 2, 3, 1108, 3306, 4, 5, 1118, 1103, 5032, 1104, 10874, 112, 1116, 1514, 3440, 2526, 1130, 4082, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10874, 112, 1116, 1514, 3440, 2526, 2, 3, 1110, 4, 5, 1109, 11718, 3799, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0015258104540407658, -0.02443367801606655, -0.058846235275268555, -0.04546189308166504, -0.04546189308166504, -0.04546189308166504, -0.04546189308166504, -0.04546189308166504, -0.04546189308166504, -0.04546189308166504], "metadata": {"source_tokens": ["In", "1926", ",", "`", "##`", "The", "News", "and", "Co", "##urier", "'", "##'", "was", "bought", "by", "the", "owners", "of", "Charleston", "'", "##s", "main", "evening", "paper", ",", "`", "##`", "The", "Evening", "Post", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "News", "and", "Co", "##urier", "[unused2]", "[unused3]", "was", "bought", "[unused4]", "[unused5]", "by", "the", "owners", "of", "Charleston", "'", "##s", "main", "evening", "paper", "In", "1926", "[unused6]", "[SEP]", "[unused1]", "Charleston", "'", "##s", "main", "evening", "paper", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "The", "Evening", "Post", "[unused6]", "[SEP]"]]}

input 126:  {"source": "In 1954 , a KOMO news photographer discovered a way to develop color film in a new process that took just a few hours instead of days .\n"}
prediction:  {"predictions": [[1, 170, 148, 13041, 2346, 2371, 8152, 2, 3, 2751, 4, 5, 170, 1236, 1106, 3689, 2942, 1273, 1107, 170, 1207, 1965, 1130, 3183, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1207, 1965, 2, 3, 1261, 4, 5, 1198, 170, 1374, 2005, 1939, 1104, 1552, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.021253487095236778, -0.002016883809119463, -0.22280097007751465, -0.22279739379882812, -0.22279739379882812, -0.22279739379882812, -0.22279739379882812, -0.22279739379882812, -0.22279739379882812, -0.22279739379882812], "metadata": {"source_tokens": ["In", "1954", ",", "a", "K", "##OM", "##O", "news", "photographer", "discovered", "a", "way", "to", "develop", "color", "film", "in", "a", "new", "process", "that", "took", "just", "a", "few", "hours", "instead", "of", "days", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "K", "##OM", "##O", "news", "photographer", "[unused2]", "[unused3]", "discovered", "[unused4]", "[unused5]", "a", "way", "to", "develop", "color", "film", "in", "a", "new", "process", "In", "1954", "[unused6]", "[SEP]", "[unused1]", "a", "new", "process", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "just", "a", "few", "hours", "instead", "of", "days", "[unused6]", "[SEP]"]]}

input 127:  {"source": "In 1964 Barrie appeared in two episodes of `` Alfred Hitchcock Presents '' .\n"}
prediction:  {"predictions": [[1, 21715, 1663, 2, 3, 1691, 4, 5, 1107, 1160, 3426, 1104, 169, 28152, 5492, 21358, 21680, 1130, 2668, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0024894531816244125, -0.0049419403076171875, -0.004957675933837891, -0.004957675933837891, -0.004957675933837891, -0.004957675933837891, -0.004957675933837891, -0.004957675933837891, -0.004957675933837891, -0.004957675933837891], "metadata": {"source_tokens": ["In", "1964", "Barr", "##ie", "appeared", "in", "two", "episodes", "of", "`", "##`", "Alfred", "Hitchcock", "Presents", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Barr", "##ie", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "in", "two", "episodes", "of", "`", "##`", "Alfred", "Hitchcock", "Presents", "In", "1964", "[unused6]", "[SEP]"]]}

Batch 1 Test Time =  79.54552149772644  s
g_f_logprobs : 0.051276206970214844
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.03773927688598633
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.20596694946289062
Decodertime : 0.00015401840209960938
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.11060190200805664
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.06378698348999023
Decodertime : 0.00014829635620117188
g_f_logprobs : 0.0646967887878418
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.0645139217376709
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.0645146369934082
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.06452155113220215
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.0645301342010498
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.06458783149719238
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.06449556350708008
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.06453800201416016
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.06450343132019043
Decodertime : 0.00018978118896484375
g_f_logprobs : 0.06459259986877441
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.06453251838684082
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.06458806991577148
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.06453680992126465
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.06462669372558594
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.06449651718139648
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.06461548805236816
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.06451725959777832
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.06457734107971191
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.06458425521850586
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.06466007232666016
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.06455779075622559
Decodertime : 0.00016951560974121094
g_f_logprobs : 0.06461167335510254
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.06453156471252441
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.06459856033325195
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.06458282470703125
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.06460928916931152
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.06453752517700195
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.06459188461303711
Decodertime : 0.00018286705017089844
g_f_logprobs : 0.06450295448303223
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.06447625160217285
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.06453704833984375
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.06461286544799805
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.06452059745788574
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.06455469131469727
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.06441903114318848
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.06449174880981445
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.06453585624694824
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.06459712982177734
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.06457042694091797
Decodertime : 0.000164031982421875
g_f_logprobs : 0.06464147567749023
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.064544677734375
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.0646066665649414
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.06453204154968262
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.0645453929901123
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.0646209716796875
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.06460952758789062
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.0644989013671875
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.06456565856933594
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.06451749801635742
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.06453442573547363
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.06452631950378418
Decodertime : 0.0001857280731201172
g_f_logprobs : 0.06459927558898926
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.06451416015625
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.0646054744720459
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.06447696685791016
Decodertime : 0.000164031982421875
g_f_logprobs : 0.06449437141418457
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.0645296573638916
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.06378960609436035
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.06463956832885742
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.06385946273803711
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.06468534469604492
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.06454777717590332
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.06456804275512695
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.06458139419555664
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.06457829475402832
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.06459188461303711
Decodertime : 0.000156402587890625
g_f_logprobs : 0.06450819969177246
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.06455445289611816
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.0644528865814209
Decodertime : 0.00016999244689941406
g_f_logprobs : 0.06449198722839355
Decodertime : 0.00018024444580078125
g_f_logprobs : 0.06448125839233398
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.06453967094421387
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.06455349922180176
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.06456255912780762
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.06440377235412598
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.06446003913879395
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.06448507308959961
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.06454920768737793
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.06459212303161621
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.06463360786437988
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.06449556350708008
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.0637972354888916
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.06465816497802734
beam_search_time: 3.446903944015503 s
g_f_logprobs : 0.06919074058532715
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.3477659225463867
Decodertime : 0.00014519691467285156
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.09496927261352539
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.06308126449584961
Decodertime : 0.000152587890625
g_f_logprobs : 0.10860610008239746
Decodertime : 0.000148773193359375
g_f_logprobs : 0.06489920616149902
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.10869383811950684
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.0648350715637207
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.06310772895812988
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.1099703311920166
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.06409049034118652
beam_search_time: 3.6381027698516846 s
g_f_logprobs : 0.3677699565887451
Decodertime : 0.00015306472778320312
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.17432451248168945
Decodertime : 0.0001888275146484375
g_f_logprobs : 0.10879898071289062
Decodertime : 0.0001437664031982422
g_f_logprobs : 0.10883760452270508
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.10885262489318848
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.10893750190734863
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.10890650749206543
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.10885238647460938
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.10888099670410156
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.10882568359375
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.10891938209533691
Decodertime : 0.000156402587890625
g_f_logprobs : 0.1088857650756836
Decodertime : 0.00014829635620117188
g_f_logprobs : 0.10894441604614258
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.10881352424621582
Decodertime : 0.00016021728515625
g_f_logprobs : 0.10891532897949219
Decodertime : 0.0001780986785888672
g_f_logprobs : 0.10890722274780273
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.10896992683410645
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.10889959335327148
Decodertime : 0.00016021728515625
g_f_logprobs : 0.10894942283630371
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.10890603065490723
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.10894942283630371
Decodertime : 0.000156402587890625
g_f_logprobs : 0.10850763320922852
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.10857081413269043
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.10880279541015625
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.10884904861450195
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.10887551307678223
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.10894322395324707
Decodertime : 0.000156402587890625
g_f_logprobs : 0.10892677307128906
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.10898709297180176
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.10880661010742188
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.10888862609863281
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.10890460014343262
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.10894989967346191
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.10883641242980957
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.10894918441772461
Decodertime : 0.00018072128295898438
g_f_logprobs : 0.10899209976196289
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.10898351669311523
Decodertime : 0.000156402587890625
g_f_logprobs : 0.10886693000793457
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.10895514488220215
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.10890889167785645
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.10896921157836914
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.10890960693359375
Decodertime : 0.00016021728515625
g_f_logprobs : 0.10894632339477539
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.10890865325927734
Decodertime : 0.00018358230590820312
g_f_logprobs : 0.10895133018493652
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.10881900787353516
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.10885238647460938
Decodertime : 0.000156402587890625
g_f_logprobs : 0.10881280899047852
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.10894608497619629
Decodertime : 0.000156402587890625
g_f_logprobs : 0.10886240005493164
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.10882019996643066
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.10881328582763672
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.10889530181884766
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.10885190963745117
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.10887932777404785
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.1088559627532959
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.10893917083740234
Decodertime : 0.00018072128295898438
g_f_logprobs : 0.10888934135437012
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.10888290405273438
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.10892701148986816
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.1089787483215332
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.10883760452270508
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.10888528823852539
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.10881543159484863
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.10894989967346191
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.10890650749206543
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.1089487075805664
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.10887789726257324
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.10897421836853027
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.1088869571685791
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.10888504981994629
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.10888361930847168
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.10901284217834473
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.1088864803314209
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.10887384414672852
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.10886025428771973
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.10895824432373047
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.10891008377075195
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.10890316963195801
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.10880899429321289
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.1089026927947998
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.1089022159576416
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.10897588729858398
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.1089015007019043
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.1089475154876709
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.10886096954345703
Decodertime : 0.0001857280731201172
g_f_logprobs : 0.10890865325927734
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.10885286331176758
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.10896468162536621
Decodertime : 0.00016021728515625
g_f_logprobs : 0.10882329940795898
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.1088860034942627
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.10883235931396484
beam_search_time: 5.864372730255127 s
g_f_logprobs : 0.16758346557617188
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.5191051959991455
Decodertime : 0.00015664100646972656
Decodertime : 0.000179290771484375
g_f_logprobs : 0.10960578918457031
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.15380334854125977
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.1090383529663086
Decodertime : 0.00018095970153808594
g_f_logprobs : 0.15278959274291992
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.10919070243835449
beam_search_time: 6.007803916931152 s
g_f_logprobs : 0.6291356086730957
Decodertime : 0.00017333030700683594
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.15381193161010742
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.15359091758728027
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.153214693069458
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.15287256240844727
Decodertime : 0.00014352798461914062
g_f_logprobs : 0.1539473533630371
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.15149378776550293
Decodertime : 0.00014448165893554688
g_f_logprobs : 0.1526961326599121
g_f_logprobs : 0.1509101390838623
Decodertime : 0.00017642974853515625
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.15285468101501465
g_f_logprobs : 0.15181279182434082
Decodertime : 0.0001621246337890625
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.152388334274292
g_f_logprobs : 0.15206074714660645
Decodertime : 0.00016260147094726562
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.1524806022644043
g_f_logprobs : 0.15218114852905273
Decodertime : 0.00016450881958007812
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.15228581428527832
g_f_logprobs : 0.1519770622253418
Decodertime : 0.00016450881958007812
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.15220069885253906
g_f_logprobs : 0.15189766883850098
Decodertime : 0.00016236305236816406
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.15246963500976562
g_f_logprobs : 0.1521739959716797
Decodertime : 0.00016236305236816406
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.1524064540863037
g_f_logprobs : 0.152055025100708
Decodertime : 0.0001628398895263672
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.15256619453430176
g_f_logprobs : 0.15227961540222168
Decodertime : 0.0001628398895263672
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.15247702598571777
g_f_logprobs : 0.1521773338317871
Decodertime : 0.0001621246337890625
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.15205788612365723
g_f_logprobs : 0.15174269676208496
Decodertime : 0.00016188621520996094
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.15252375602722168
g_f_logprobs : 0.15221619606018066
Decodertime : 0.0001842975616455078
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.15240740776062012
g_f_logprobs : 0.15212178230285645
Decodertime : 0.0001621246337890625
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.15223145484924316
g_f_logprobs : 0.15193843841552734
Decodertime : 0.000164031982421875
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.15241146087646484
g_f_logprobs : 0.15211248397827148
Decodertime : 0.00016927719116210938
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.1523280143737793
g_f_logprobs : 0.15202641487121582
Decodertime : 0.0001633167266845703
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.15242552757263184
g_f_logprobs : 0.15236186981201172
Decodertime : 0.00016045570373535156
Decodertime : 0.00017142295837402344
g_f_logprobs : 0.15263056755065918
g_f_logprobs : 0.15204811096191406
Decodertime : 0.00016760826110839844
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.15230441093444824
g_f_logprobs : 0.15201854705810547
Decodertime : 0.00016236305236816406
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.15250682830810547
g_f_logprobs : 0.15219378471374512
Decodertime : 0.00016736984252929688
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.15245747566223145
g_f_logprobs : 0.1521589756011963
Decodertime : 0.00016355514526367188
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.15237808227539062
g_f_logprobs : 0.1520833969116211
Decodertime : 0.0001633167266845703
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.1523723602294922
g_f_logprobs : 0.1520233154296875
Decodertime : 0.0001628398895263672
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.15223455429077148
g_f_logprobs : 0.15197491645812988
Decodertime : 0.0001647472381591797
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.15247058868408203
g_f_logprobs : 0.15218710899353027
Decodertime : 0.00016570091247558594
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.15250730514526367
g_f_logprobs : 0.15219974517822266
Decodertime : 0.00016641616821289062
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.15233445167541504
g_f_logprobs : 0.1522982120513916
Decodertime : 0.00016117095947265625
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.15277385711669922
g_f_logprobs : 0.15220999717712402
Decodertime : 0.00016427040100097656
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.15230941772460938
g_f_logprobs : 0.15200495719909668
Decodertime : 0.000164031982421875
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.1521437168121338
g_f_logprobs : 0.15187406539916992
Decodertime : 0.000164031982421875
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.15330004692077637
g_f_logprobs : 0.15325021743774414
Decodertime : 0.0001633167266845703
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.15259790420532227
g_f_logprobs : 0.15201950073242188
Decodertime : 0.00016570091247558594
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.15239977836608887
g_f_logprobs : 0.15212583541870117
Decodertime : 0.00018358230590820312
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.15253257751464844
g_f_logprobs : 0.15228581428527832
Decodertime : 0.00018358230590820312
Decodertime : 0.000152587890625
g_f_logprobs : 0.15207791328430176
g_f_logprobs : 0.15180325508117676
Decodertime : 0.0001633167266845703
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.15243959426879883
g_f_logprobs : 0.15218567848205566
Decodertime : 0.00016546249389648438
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.1524946689605713
g_f_logprobs : 0.15222477912902832
Decodertime : 0.00016427040100097656
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.1522507667541504
g_f_logprobs : 0.15198206901550293
Decodertime : 0.00016498565673828125
Decodertime : 0.0001728534698486328
g_f_logprobs : 0.15236997604370117
g_f_logprobs : 0.1520848274230957
Decodertime : 0.00016355514526367188
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.1523573398590088
g_f_logprobs : 0.1520860195159912
Decodertime : 0.00016355514526367188
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.1522378921508789
g_f_logprobs : 0.15195488929748535
Decodertime : 0.0001628398895263672
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.15247297286987305
g_f_logprobs : 0.15218901634216309
Decodertime : 0.00016379356384277344
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.15222787857055664
g_f_logprobs : 0.15194392204284668
Decodertime : 0.00016498565673828125
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.15247225761413574
g_f_logprobs : 0.15219759941101074
Decodertime : 0.00014257431030273438
beam_search_time: 8.19431185722351 s
g_f_logprobs : 0.7704048156738281
Decodertime : 0.00014638900756835938
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.15562963485717773
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.1983497142791748
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.15357255935668945
beam_search_time: 8.33836817741394 s
g_f_logprobs : 0.6508221626281738
Decodertime : 0.00015282630920410156
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.3156106472015381
Decodertime : 0.00017070770263671875
g_f_logprobs : 0.18430113792419434
Decodertime : 0.000148773193359375
g_f_logprobs : 0.1975390911102295
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.18315887451171875
Decodertime : 0.00017023086547851562
g_f_logprobs : 0.19699835777282715
Decodertime : 0.0001685619354248047
g_f_logprobs : 0.18271160125732422
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.18140816688537598
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.19989967346191406
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.18329548835754395
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.1975414752960205
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.18326234817504883
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.19764375686645508
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.18335366249084473
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.19750642776489258
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.18339157104492188
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.19766974449157715
Decodertime : 0.00018405914306640625
g_f_logprobs : 0.18335628509521484
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.19756436347961426
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.18340659141540527
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.19756555557250977
Decodertime : 0.000164031982421875
g_f_logprobs : 0.18322110176086426
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.19759011268615723
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.18334078788757324
Decodertime : 0.0001811981201171875
g_f_logprobs : 0.19779276847839355
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.18344449996948242
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.19760465621948242
Decodertime : 0.00018644332885742188
g_f_logprobs : 0.18332672119140625
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.19760560989379883
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.18334197998046875
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.19766688346862793
Decodertime : 0.00016689300537109375
g_f_logprobs : 0.18331408500671387
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.19749689102172852
Decodertime : 0.000156402587890625
g_f_logprobs : 0.1813342571258545
Decodertime : 0.00014495849609375
g_f_logprobs : 0.18040752410888672
Decodertime : 0.000156402587890625
g_f_logprobs : 0.19953060150146484
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.18342852592468262
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.19756126403808594
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.1834731101989746
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.19771838188171387
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.18326210975646973
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.19756579399108887
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.18339061737060547
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.19761943817138672
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.18259668350219727
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.19772863388061523
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.1826310157775879
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.19790339469909668
Decodertime : 0.00016951560974121094
g_f_logprobs : 0.18335509300231934
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.19754719734191895
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.1832742691040039
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.1975553035736084
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.18322539329528809
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.19759893417358398
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.18334674835205078
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.19744110107421875
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.18314766883850098
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.19863605499267578
Decodertime : 0.00021910667419433594
g_f_logprobs : 0.18288540840148926
Decodertime : 0.00022530555725097656
g_f_logprobs : 0.18111920356750488
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.19992399215698242
Decodertime : 0.00018286705017089844
g_f_logprobs : 0.18335366249084473
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.19755816459655762
Decodertime : 0.000164031982421875
g_f_logprobs : 0.18323802947998047
Decodertime : 0.00018024444580078125
g_f_logprobs : 0.1975688934326172
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.18340706825256348
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.19771456718444824
Decodertime : 0.00016760826110839844
g_f_logprobs : 0.1832590103149414
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.197509765625
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.18331551551818848
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.19755983352661133
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.18328380584716797
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.19760847091674805
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.1833972930908203
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.1975858211517334
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.1831960678100586
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.1975395679473877
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.1833021640777588
Decodertime : 0.00016021728515625
g_f_logprobs : 0.19759917259216309
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.18327951431274414
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.19756817817687988
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.1832904815673828
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.19749855995178223
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.18319129943847656
Decodertime : 0.00016021728515625
g_f_logprobs : 0.19758915901184082
g_f_logprobs : 0.18122196197509766
Decodertime : 0.00015592575073242188
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.18346667289733887
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.20000672340393066
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.18335199356079102
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.19760727882385254
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.18326258659362793
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.19754600524902344
Decodertime : 0.00016760826110839844
g_f_logprobs : 0.183319091796875
beam_search_time: 8.872595310211182 s
g_f_logprobs : 0.3846428394317627
Decodertime : 0.0001556873321533203
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.6300256252288818
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.19793295860290527
Decodertime : 0.000156402587890625
g_f_logprobs : 0.19755077362060547
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.19670772552490234
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.19758820533752441
beam_search_time: 11.178922414779663 s
g_f_logprobs : 0.6572411060333252
Decodertime : 0.0001780986785888672
Decodertime : 0.00020360946655273438
g_f_logprobs : 0.5034856796264648
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.24288702011108398
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.197066068649292
Decodertime : 0.0001678466796875
g_f_logprobs : 0.19490718841552734
Decodertime : 0.00018739700317382812
g_f_logprobs : 0.24384713172912598
Decodertime : 0.0001811981201171875
g_f_logprobs : 0.19736123085021973
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.24149775505065918
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.1971755027770996
Decodertime : 0.00016021728515625
g_f_logprobs : 0.2416703701019287
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.19715237617492676
Decodertime : 0.00016021728515625
g_f_logprobs : 0.24154114723205566
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.1970958709716797
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.19486546516418457
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.2439253330230713
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.19730067253112793
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.24170780181884766
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.19708895683288574
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.2416243553161621
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.19714760780334473
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.24181818962097168
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.19732379913330078
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.1946725845336914
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.24369001388549805
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.1974029541015625
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.24188494682312012
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.19725680351257324
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.24179625511169434
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.197265625
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.24152851104736328
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.1970527172088623
Decodertime : 0.00016021728515625
g_f_logprobs : 0.2416667938232422
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.19716238975524902
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.19458460807800293
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.24368667602539062
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.1972975730895996
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.24165678024291992
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.19728684425354004
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.2418050765991211
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.19726133346557617
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.24092507362365723
Decodertime : 0.00017118453979492188
g_f_logprobs : 0.19646263122558594
Decodertime : 0.0001819133758544922
g_f_logprobs : 0.1947321891784668
Decodertime : 0.0002167224884033203
g_f_logprobs : 0.24384331703186035
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.19721412658691406
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.24157357215881348
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.19714999198913574
Decodertime : 0.00017118453979492188
g_f_logprobs : 0.24165058135986328
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.19719624519348145
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.24182748794555664
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.19725418090820312
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.19463396072387695
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.24357962608337402
Decodertime : 0.00020003318786621094
g_f_logprobs : 0.19735240936279297
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.24188709259033203
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.19719505310058594
Decodertime : 0.00016689300537109375
g_f_logprobs : 0.24161934852600098
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.19719743728637695
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.24166584014892578
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.19708800315856934
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.24139142036437988
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.19688677787780762
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.19459891319274902
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.24367952346801758
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.19751620292663574
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.24183034896850586
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.1964731216430664
Decodertime : 0.00016021728515625
g_f_logprobs : 0.24168968200683594
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.1970977783203125
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.24173545837402344
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.19720005989074707
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.19472885131835938
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.2436833381652832
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.19721722602844238
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.2416524887084961
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.19709181785583496
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.24147820472717285
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.1970217227935791
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.2416079044342041
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.197188138961792
Decodertime : 0.00016021728515625
g_f_logprobs : 0.19472980499267578
beam_search_time: 10.29584789276123 s
g_f_logprobs : 0.24163508415222168
Decodertime : 0.00015473365783691406
Decodertime : 0.0001850128173828125
g_f_logprobs : 0.9468719959259033
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.22360634803771973
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.2412409782409668
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.22344279289245605
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.24200892448425293
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.22343897819519043
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.24241352081298828
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.2235407829284668
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.2418651580810547
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.22336363792419434
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.24228620529174805
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.22360682487487793
Decodertime : 0.00014495849609375
g_f_logprobs : 0.24220991134643555
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.22338199615478516
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.24206161499023438
Decodertime : 0.0001850128173828125
g_f_logprobs : 0.2235276699066162
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.24208641052246094
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.22304177284240723
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.24180006980895996
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.22342133522033691
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.24227547645568848
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.22345876693725586
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.24225187301635742
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.22303247451782227
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.22088003158569336
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.24496769905090332
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.22374272346496582
Decodertime : 0.00014495849609375
g_f_logprobs : 0.2427229881286621
beam_search_time: 12.9153311252594 s
g_f_logprobs : 0.978238582611084
Decodertime : 0.00014591217041015625
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.24836063385009766
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.24347233772277832
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.2232975959777832
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.24131250381469727
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.22293591499328613
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.24209284782409668
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.22343969345092773
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.2422783374786377
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.22353792190551758
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.24180865287780762
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.22332096099853516
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.24229717254638672
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.22353315353393555
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.24215984344482422
Decodertime : 0.0001761913299560547
g_f_logprobs : 0.22337603569030762
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.2421741485595703
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.22349119186401367
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.24234700202941895
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.22354483604431152
Decodertime : 0.00014495849609375
g_f_logprobs : 0.22119951248168945
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.2444930076599121
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.22341704368591309
Decodertime : 0.0001437664031982422
g_f_logprobs : 0.24223995208740234
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.22357511520385742
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.24203729629516602
Decodertime : 0.000148773193359375
g_f_logprobs : 0.2234513759613037
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.2420029640197754
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.2234055995941162
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.2418382167816162
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.22345733642578125
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.24200654029846191
Decodertime : 0.0001728534698486328
g_f_logprobs : 0.22355127334594727
Decodertime : 0.00014495849609375
g_f_logprobs : 0.2423710823059082
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.22350573539733887
Decodertime : 0.00014328956604003906
g_f_logprobs : 0.24198055267333984
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.22335529327392578
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.2423105239868164
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.22348427772521973
Decodertime : 0.0001430511474609375
g_f_logprobs : 0.24218320846557617
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.22355985641479492
Decodertime : 0.00014352798461914062
g_f_logprobs : 0.24215412139892578
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.2233591079711914
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.2423403263092041
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.22353148460388184
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.2211008071899414
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.24415874481201172
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.2236340045928955
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.24210786819458008
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.22336649894714355
Decodertime : 0.00014257431030273438
g_f_logprobs : 0.2422504425048828
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.22344279289245605
Decodertime : 0.00018143653869628906
g_f_logprobs : 0.24184608459472656
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.22335457801818848
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.2422330379486084
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.22368407249450684
Decodertime : 0.00014448165893554688
g_f_logprobs : 0.24239253997802734
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.22355103492736816
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.24196147918701172
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.2234821319580078
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.24206972122192383
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.22335457801818848
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.24210715293884277
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.22359180450439453
beam_search_time: 11.591899394989014 s
g_f_logprobs : 1.0070490837097168
Decodertime : 0.00015282630920410156
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.29605674743652344
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.25316333770751953
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.24281835556030273
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.25258612632751465
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.2429957389831543
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.2528691291809082
Decodertime : 0.000148773193359375
g_f_logprobs : 0.24304986000061035
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.2529792785644531
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.24300026893615723
Decodertime : 0.00017213821411132812
g_f_logprobs : 0.2528717517852783
Decodertime : 0.000148773193359375
g_f_logprobs : 0.24293041229248047
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.2530391216278076
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.24319171905517578
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.2531118392944336
Decodertime : 0.000148773193359375
g_f_logprobs : 0.24326062202453613
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.25251197814941406
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.2425687313079834
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.252946138381958
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.24294495582580566
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.2530794143676758
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.24309253692626953
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.2528870105743408
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.242997407913208
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.25283241271972656
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.24295520782470703
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.2529628276824951
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.2430248260498047
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.25237226486206055
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.24253273010253906
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.25304484367370605
Decodertime : 0.0001704692840576172
g_f_logprobs : 0.24311041831970215
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.2530241012573242
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.24310088157653809
beam_search_time: 12.561116933822632 s
g_f_logprobs : 1.121232032775879
Decodertime : 0.00017023086547851562
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.24487638473510742
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.2690730094909668
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.2535707950592041
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.26670145988464355
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.2533388137817383
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.2667713165283203
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.25324249267578125
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.2668321132659912
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.2537422180175781
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.26718640327453613
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.2534904479980469
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.2668192386627197
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.25367236137390137
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.2670481204986572
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.2533698081970215
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.266282320022583
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.25300025939941406
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.2666659355163574
Decodertime : 0.0001735687255859375
g_f_logprobs : 0.2535860538482666
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.26665449142456055
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.25337743759155273
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.26685476303100586
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.25368666648864746
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.2672610282897949
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.25376176834106445
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.26703715324401855
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.2536187171936035
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.26710057258605957
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.2536890506744385
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.26561808586120605
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.2521810531616211
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.2671537399291992
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.2537674903869629
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.25020623207092285
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.2695009708404541
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.2538163661956787
Decodertime : 0.0001690387725830078
g_f_logprobs : 0.26720428466796875
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.2531447410583496
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.26639580726623535
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.2535088062286377
Decodertime : 0.00014829635620117188
g_f_logprobs : 0.267042875289917
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.25356268882751465
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.2670259475708008
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.2536337375640869
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.2670173645019531
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.25348782539367676
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.2669994831085205
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.2535409927368164
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.2668137550354004
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.25350284576416016
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.2670474052429199
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.2533111572265625
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.26636481285095215
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.2533683776855469
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.26700639724731445
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.253462553024292
Decodertime : 0.000148773193359375
g_f_logprobs : 0.26654624938964844
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.2530057430267334
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.26648640632629395
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.2534353733062744
beam_search_time: 13.106694221496582 s
g_f_logprobs : 0.22313427925109863
Decodertime : 0.00018215179443359375
g_f_logprobs : 1.2154998779296875
Decodertime : 0.00018262863159179688
Decodertime : 0.00018143653869628906
g_f_logprobs : 0.23514127731323242
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.29467272758483887
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.26741671562194824
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.2952284812927246
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.26703715324401855
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.2949385643005371
Decodertime : 0.00014829635620117188
g_f_logprobs : 0.2673509120941162
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.29553651809692383
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.26715564727783203
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.2945241928100586
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.266859769821167
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.295180082321167
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.2675163745880127
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.2643716335296631
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.2984631061553955
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.2678394317626953
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.2958378791809082
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.26760411262512207
beam_search_time: 11.901894330978394 s
g_f_logprobs : 0.5527992248535156
Decodertime : 0.00024390220642089844
Decodertime : 0.00020313262939453125
g_f_logprobs : 0.8927655220031738
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.2679586410522461
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.2953329086303711
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.26749658584594727
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.2944056987762451
Decodertime : 0.0001480579376220703
g_f_logprobs : 0.2666769027709961
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.2955751419067383
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.2672865390777588
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.29505014419555664
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.26726698875427246
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.29543018341064453
g_f_logprobs : 0.26433277130126953
Decodertime : 0.00015425682067871094
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.26749253273010254
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.2987985610961914
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.2679939270019531
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.29572415351867676
Decodertime : 0.00014781951904296875
g_f_logprobs : 0.2674379348754883
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.2955818176269531
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.2674293518066406
Decodertime : 0.00017309188842773438
g_f_logprobs : 0.29512476921081543
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.2674753665924072
Decodertime : 0.00017642974853515625
g_f_logprobs : 0.2955613136291504
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.26763272285461426
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.2954750061035156
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.2672147750854492
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.29520177841186523
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.2678835391998291
Decodertime : 0.0001876354217529297
g_f_logprobs : 0.29505205154418945
Decodertime : 0.0001842975616455078
g_f_logprobs : 0.26660776138305664
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.29539012908935547
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.2673020362854004
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.26390671730041504
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.2976388931274414
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.2674262523651123
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.29540562629699707
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.2663688659667969
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.29436612129211426
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.26774144172668457
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.29506468772888184
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.26692748069763184
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.29537367820739746
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.2674903869628906
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.2953355312347412
Decodertime : 0.00017499923706054688
g_f_logprobs : 0.26729512214660645
beam_search_time: 6.18981409072876 s
g_f_logprobs : 1.039275884628296
Decodertime : 0.00015211105346679688
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.3943905830383301
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.268634557723999
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.29499268531799316
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.2673916816711426
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.2947120666503906
beam_search_time: 11.819448709487915 s
g_f_logprobs : 0.2606058120727539
Decodertime : 0.00016808509826660156
g_f_logprobs : 1.242185115814209
Decodertime : 0.0001876354217529297
Decodertime : 0.00018787384033203125
g_f_logprobs : 0.23645520210266113
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.29443955421447754
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.2677123546600342
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.29557037353515625
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.26735663414001465
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.29543519020080566
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.2674560546875
Decodertime : 0.00020003318786621094
g_f_logprobs : 0.29519081115722656
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.26712512969970703
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.29508066177368164
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.26715803146362305
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.29389381408691406
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.2662348747253418
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.264049768447876
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.29804468154907227
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.26730895042419434
Decodertime : 0.000152587890625
g_f_logprobs : 0.29535818099975586
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.26712751388549805
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.29530882835388184
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.2675149440765381
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.2952897548675537
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.2671365737915039
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.29494619369506836
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.2674257755279541
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.29550719261169434
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.26761317253112793
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.295194149017334
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.2669713497161865
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.29482102394104004
Decodertime : 0.00014495849609375
g_f_logprobs : 0.2671945095062256
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.2951319217681885
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.2670152187347412
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.2639651298522949
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.2978489398956299
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.26711416244506836
beam_search_time: 7.125104904174805 s
g_f_logprobs : 0.3562922477722168
Decodertime : 0.00018215179443359375
Decodertime : 0.00016021728515625
g_f_logprobs : 1.087024450302124
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.26898694038391113
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.2949867248535156
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.2673518657684326
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.29526567459106445
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.2673311233520508
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.2952263355255127
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.2671513557434082
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.2950472831726074
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.26738786697387695
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.29541540145874023
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.2674896717071533
Decodertime : 0.00017333030700683594
g_f_logprobs : 0.295581579208374
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.2673909664154053
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.26423048973083496
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.2980620861053467
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.2690725326538086
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.2962191104888916
Decodertime : 0.0001480579376220703
g_f_logprobs : 0.26717472076416016
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.2947535514831543
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.2669544219970703
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.2948637008666992
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.2669253349304199
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.29506468772888184
Decodertime : 0.00014781951904296875
g_f_logprobs : 0.26746416091918945
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.2954237461090088
Decodertime : 0.00014829635620117188
g_f_logprobs : 0.2671489715576172
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.2950141429901123
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.26747584342956543
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.29529428482055664
Decodertime : 0.000152587890625
g_f_logprobs : 0.2670316696166992
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.2948472499847412
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.2669999599456787
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.29535484313964844
Decodertime : 0.00014781951904296875
g_f_logprobs : 0.2677128314971924
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.2642176151275635
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.2981383800506592
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.2668285369873047
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.2949986457824707
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.2674117088317871
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.2953042984008789
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.26735758781433105
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.2951009273529053
Decodertime : 0.00017070770263671875
g_f_logprobs : 0.26723194122314453
beam_search_time: 6.190894603729248 s
input 128:  {"source": "In 1972 , he won from Yakutpura and later in 1978 , again from Charminar .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1281, 4, 5, 1121, 14680, 4786, 1204, 24790, 1105, 1224, 1107, 2406, 1254, 1121, 24705, 9019, 2983, 1197, 1130, 2388, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1281, 4, 5, 1121, 14680, 4786, 1204, 24790, 1105, 1224, 1107, 2406, 1254, 1121, 24705, 9019, 2983, 1197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04573553428053856, -0.0797945037484169, -0.15298831462860107, -0.16927504539489746, -0.1692749261856079, -0.1692749261856079, -0.16927504539489746, -0.16927504539489746, -0.16927504539489746, -0.16927504539489746], "metadata": {"source_tokens": ["In", "1972", ",", "he", "won", "from", "Ya", "##ku", "##t", "##pura", "and", "later", "in", "1978", ",", "again", "from", "Cha", "##rm", "##ina", "##r", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "from", "Ya", "##ku", "##t", "##pura", "and", "later", "in", "1978", "again", "from", "Cha", "##rm", "##ina", "##r", "In", "1972", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "from", "Ya", "##ku", "##t", "##pura", "and", "later", "in", "1978", "again", "from", "Cha", "##rm", "##ina", "##r", "[unused6]", "[SEP]"]]}

input 129:  {"source": "In 1972 , researchers found metallic conductivity in the charge-transfer complex TTF-TCNQ .\n"}
prediction:  {"predictions": [[1, 6962, 2, 3, 1276, 4, 5, 13256, 5880, 6366, 1107, 1103, 2965, 28137, 4487, 2316, 6732, 2703, 157, 22169, 28137, 9481, 2249, 4880, 1130, 2388, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0007839970639906824, -0.07655096054077148, -0.07750558853149414, -0.07750558853149414, -0.07750558853149414, -0.07750558853149414, -0.07750558853149414, -0.07750558853149414, -0.07750558853149414, -0.07750558853149414], "metadata": {"source_tokens": ["In", "1972", ",", "researchers", "found", "metallic", "conduct", "##ivity", "in", "the", "charge", "##-", "##tra", "##ns", "##fer", "complex", "T", "##TF", "##-", "##TC", "##N", "##Q", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "researchers", "[unused2]", "[unused3]", "found", "[unused4]", "[unused5]", "metallic", "conduct", "##ivity", "in", "the", "charge", "##-", "##tra", "##ns", "##fer", "complex", "T", "##TF", "##-", "##TC", "##N", "##Q", "In", "1972", "[unused6]", "[SEP]"]]}

input 130:  {"source": "In 1975 Barrie was directed by Lee Grant in the television movie `` For The Use Of The Hall '' as `` Charlotte '' .\n"}
prediction:  {"predictions": [[1, 21715, 1663, 2, 3, 1108, 2002, 4, 5, 1118, 2499, 4468, 1107, 1103, 1778, 2523, 1130, 2429, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21715, 1663, 2, 3, 1108, 2002, 4, 5, 1118, 2499, 4468, 1107, 1103, 1778, 2523, 1370, 1109, 11696, 2096, 1109, 1944, 1112, 5204, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04108858108520508, -0.05119291692972183, -0.15829074382781982, -0.1537480354309082, -0.1537480354309082, -0.1537480354309082, -0.1537480354309082, -0.1537480354309082, -0.1537480354309082, -0.1537480354309082], "metadata": {"source_tokens": ["In", "1975", "Barr", "##ie", "was", "directed", "by", "Lee", "Grant", "in", "the", "television", "movie", "`", "##`", "For", "The", "Use", "Of", "The", "Hall", "'", "##'", "as", "`", "##`", "Charlotte", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Barr", "##ie", "[unused2]", "[unused3]", "was", "directed", "[unused4]", "[unused5]", "by", "Lee", "Grant", "in", "the", "television", "movie", "In", "1975", "[unused6]", "[SEP]", "[unused1]", "Barr", "##ie", "[unused2]", "[unused3]", "was", "directed", "[unused4]", "[unused5]", "by", "Lee", "Grant", "in", "the", "television", "movie", "For", "The", "Use", "Of", "The", "Hall", "as", "Charlotte", "[unused6]", "[SEP]"]]}

input 131:  {"source": "In 1977 she appeared in two television films , as the mother of Lesley Ann Warren 's character in `` 79 Park Avenue '' and as Emily McPhail in `` Tell Me My Name '' .\n"}
prediction:  {"predictions": [[1, 1131, 2, 3, 1691, 4, 5, 1107, 1160, 1778, 2441, 1112, 1103, 1534, 1104, 26801, 5083, 5407, 112, 1116, 1959, 1107, 169, 28152, 5899, 1670, 3194, 112, 28131, 1105, 1112, 5590, 150, 1665, 2101, 10390, 1233, 1107, 169, 28152, 4630, 2508, 1422, 10208, 1130, 2449, 6, 102, 102, 102, 102, 1, 1131, 2, 3, 1691, 4, 5, 1107, 1160, 1778, 2441, 1112, 1103, 1534, 1104, 26801, 5083, 5407, 112, 1116, 1959, 1107, 5899, 1670, 3194, 1105, 1112, 5590, 150, 1665, 2101, 10390, 1233, 1107, 4630, 2508, 1422, 10208, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1691, 4, 5, 1107, 1160, 1778, 2441, 1112, 1103, 1534, 1104, 26801, 5083, 5407, 112, 1116, 1959, 1107, 5899, 1670, 3194, 1105, 1112, 5590, 150, 1665, 2101, 10390, 1233, 1107, 4630, 2508, 1422, 10208, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03554064407944679, -0.06884677708148956, -0.09537583589553833, -0.151037335395813, -0.15093863010406494, -0.15093863010406494, -0.15093863010406494, -0.15093863010406494, -0.15093863010406494, -0.15093863010406494], "metadata": {"source_tokens": ["In", "1977", "she", "appeared", "in", "two", "television", "films", ",", "as", "the", "mother", "of", "Lesley", "Ann", "Warren", "'", "##s", "character", "in", "`", "##`", "79", "Park", "Avenue", "'", "##'", "and", "as", "Emily", "M", "##c", "##P", "##hai", "##l", "in", "`", "##`", "Tell", "Me", "My", "Name", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "she", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "in", "two", "television", "films", "as", "the", "mother", "of", "Lesley", "Ann", "Warren", "'", "##s", "character", "in", "`", "##`", "79", "Park", "Avenue", "'", "##'", "and", "as", "Emily", "M", "##c", "##P", "##hai", "##l", "in", "`", "##`", "Tell", "Me", "My", "Name", "In", "1977", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "in", "two", "television", "films", "as", "the", "mother", "of", "Lesley", "Ann", "Warren", "'", "##s", "character", "in", "79", "Park", "Avenue", "and", "as", "Emily", "M", "##c", "##P", "##hai", "##l", "in", "Tell", "Me", "My", "Name", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "in", "two", "television", "films", "as", "the", "mother", "of", "Lesley", "Ann", "Warren", "'", "##s", "character", "in", "79", "Park", "Avenue", "and", "as", "Emily", "M", "##c", "##P", "##hai", "##l", "in", "Tell", "Me", "My", "Name", "[unused6]", "[SEP]"]]}

input 132:  {"source": "In 1987 , Rodan became president of the American Society for Bone and Mineral Research .\n"}
prediction:  {"predictions": [[1, 11945, 1389, 2, 3, 1245, 4, 5, 2084, 1104, 1103, 1237, 2015, 1111, 17722, 1105, 9139, 4412, 2713, 1130, 2164, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11945, 1389, 2, 3, 1245, 4, 5, 2084, 1111, 17722, 1105, 9139, 4412, 2713, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0023234409745782614, -0.0999206155538559, -0.07617378234863281, -0.0761713981628418, -0.0761713981628418, -0.0761713981628418, -0.0761713981628418, -0.0761713981628418, -0.0761713981628418, -0.0761713981628418], "metadata": {"source_tokens": ["In", "1987", ",", "Rod", "##an", "became", "president", "of", "the", "American", "Society", "for", "Bone", "and", "Mine", "##ral", "Research", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rod", "##an", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "president", "of", "the", "American", "Society", "for", "Bone", "and", "Mine", "##ral", "Research", "In", "1987", "[unused6]", "[SEP]", "[unused1]", "Rod", "##an", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "president", "for", "Bone", "and", "Mine", "##ral", "Research", "[unused6]", "[SEP]"]]}

input 133:  {"source": "In 1990 Kelsang Gyatso became also outspoken against the Geshe Studies Programme , and `` made the pursuit of his new programmes compulsory . ''\n"}
prediction:  {"predictions": [[1, 26835, 3447, 4993, 144, 2315, 2145, 1186, 2, 3, 1245, 1145, 4, 5, 25304, 1222, 1103, 144, 10654, 1162, 3829, 11512, 1130, 1997, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 3447, 4993, 144, 2315, 2145, 1186, 2, 3, 1189, 4, 5, 1103, 9542, 1104, 1117, 1207, 8473, 16472, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.024982012808322906, -0.056806400418281555, -0.28371942043304443, -0.339374303817749, -0.339374303817749, -0.339374303817749, -0.339374303817749, -0.339374303817749, -0.339374303817749, -0.339374303817749], "metadata": {"source_tokens": ["In", "1990", "Ke", "##ls", "##ang", "G", "##ya", "##ts", "##o", "became", "also", "outspoken", "against", "the", "G", "##esh", "##e", "Studies", "Programme", ",", "and", "`", "##`", "made", "the", "pursuit", "of", "his", "new", "programmes", "compulsory", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ke", "##ls", "##ang", "G", "##ya", "##ts", "##o", "[unused2]", "[unused3]", "became", "also", "[unused4]", "[unused5]", "outspoken", "against", "the", "G", "##esh", "##e", "Studies", "Programme", "In", "1990", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ls", "##ang", "G", "##ya", "##ts", "##o", "[unused2]", "[unused3]", "made", "[unused4]", "[unused5]", "the", "pursuit", "of", "his", "new", "programmes", "compulsory", "[unused6]", "[SEP]"]]}

input 134:  {"source": "In 2004 the Brumbies finished at the top of the Super 12 table , six points clear of the next best team .\n"}
prediction:  {"predictions": [[1, 1103, 139, 5697, 16751, 2, 3, 1845, 4, 5, 1120, 1103, 1499, 1104, 1103, 3198, 1367, 1952, 1130, 1516, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 139, 5697, 16751, 2, 3, 1845, 4, 5, 1120, 1103, 1499, 1104, 1103, 3198, 1367, 1952, 1565, 1827, 2330, 1104, 1103, 1397, 1436, 1264, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02463223971426487, -0.026959547773003578, -0.18954944610595703, -0.20771288871765137, -0.20771288871765137, -0.20771288871765137, -0.20771288871765137, -0.20771288871765137, -0.20771288871765137, -0.20771288871765137], "metadata": {"source_tokens": ["In", "2004", "the", "B", "##rum", "##bies", "finished", "at", "the", "top", "of", "the", "Super", "12", "table", ",", "six", "points", "clear", "of", "the", "next", "best", "team", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "B", "##rum", "##bies", "[unused2]", "[unused3]", "finished", "[unused4]", "[unused5]", "at", "the", "top", "of", "the", "Super", "12", "table", "In", "2004", "[unused6]", "[SEP]", "[unused1]", "the", "B", "##rum", "##bies", "[unused2]", "[unused3]", "finished", "[unused4]", "[unused5]", "at", "the", "top", "of", "the", "Super", "12", "table", "six", "points", "clear", "of", "the", "next", "best", "team", "[unused6]", "[SEP]"]]}

input 135:  {"source": "In 2006 they applied for National League Three , finishing in 5th place and qualifying for the play-offs , where they lost to St Albans Centurions .\n"}
prediction:  {"predictions": [[1, 1152, 2, 3, 3666, 4, 5, 1111, 1305, 1453, 2677, 1130, 1386, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1575, 4, 5, 1106, 1457, 24005, 2316, 24664, 2227, 27178, 1116, 1103, 1505, 28137, 18438, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 3666, 4, 5, 1111, 1305, 1453, 2677, 4416, 1107, 4025, 1282, 1105, 6045, 1111, 1103, 1505, 28137, 18438, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 3666, 4, 5, 1111, 1305, 1453, 2677, 4416, 1107, 4025, 1282, 1105, 6045, 1111, 1103, 1505, 28137, 18438, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 3666, 4, 5, 1111, 1305, 1453, 2677, 4416, 1107, 4025, 1282, 1105, 6045, 1111, 1103, 1505, 28137, 18438, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.019637953490018845, -0.010381762869656086, -0.09262911230325699, -0.31351733207702637, -0.10596486181020737, -0.11480563879013062, -0.22075462341308594, -0.26888442039489746, -0.26888442039489746, -0.26888442039489746], "metadata": {"source_tokens": ["In", "2006", "they", "applied", "for", "National", "League", "Three", ",", "finishing", "in", "5th", "place", "and", "qualifying", "for", "the", "play", "##-", "##offs", ",", "where", "they", "lost", "to", "St", "Alba", "##ns", "Ce", "##nt", "##urion", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "they", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "for", "National", "League", "Three", "In", "2006", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "lost", "[unused4]", "[unused5]", "to", "St", "Alba", "##ns", "Ce", "##nt", "##urion", "##s", "the", "play", "##-", "##offs", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "for", "National", "League", "Three", "finishing", "in", "5th", "place", "and", "qualifying", "for", "the", "play", "##-", "##offs", "[unused6]", "[SEP]"]]}

input 136:  {"source": "In 2007 , Sun announced `` Project Indiana '' with several goals , including providing an open source binary distribution of the OpenSolaris project , replacing SXDE .\n"}
prediction:  {"predictions": [[1, 3477, 2, 3, 1717, 4, 5, 4042, 4456, 1114, 1317, 2513, 117, 1259, 3558, 1126, 1501, 2674, 13480, 3735, 1104, 1103, 3353, 1708, 21459, 1548, 1933, 117, 5861, 156, 3190, 20427, 1130, 1384, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3477, 2, 3, 1717, 4, 5, 4042, 4456, 1114, 1317, 2513, 1259, 3558, 1126, 1501, 2674, 13480, 3735, 1104, 1103, 3353, 1708, 21459, 1548, 1933, 5861, 156, 3190, 20427, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3477, 2, 3, 1717, 4, 5, 4042, 4456, 1130, 1384, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3477, 2, 3, 1717, 4, 5, 4042, 4456, 1130, 1384, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03311631456017494, -0.06836292892694473, -0.14654883742332458, -0.15267516672611237, -0.26521289348602295, -0.2666419744491577, -0.2666419744491577, -0.2666419744491577, -0.2666419744491577, -0.2666419744491577], "metadata": {"source_tokens": ["In", "2007", ",", "Sun", "announced", "`", "##`", "Project", "Indiana", "'", "##'", "with", "several", "goals", ",", "including", "providing", "an", "open", "source", "binary", "distribution", "of", "the", "Open", "##S", "##olar", "##is", "project", ",", "replacing", "S", "##X", "##DE", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sun", "[unused2]", "[unused3]", "announced", "[unused4]", "[unused5]", "Project", "Indiana", "with", "several", "goals", ",", "including", "providing", "an", "open", "source", "binary", "distribution", "of", "the", "Open", "##S", "##olar", "##is", "project", ",", "replacing", "S", "##X", "##DE", "In", "2007", "[unused6]", "[SEP]", "[unused1]", "Sun", "[unused2]", "[unused3]", "announced", "[unused4]", "[unused5]", "Project", "Indiana", "with", "several", "goals", "including", "providing", "an", "open", "source", "binary", "distribution", "of", "the", "Open", "##S", "##olar", "##is", "project", "replacing", "S", "##X", "##DE", "[unused6]", "[SEP]", "[unused1]", "Sun", "[unused2]", "[unused3]", "announced", "[unused4]", "[unused5]", "Project", "Indiana", "In", "2007", "[unused6]", "[SEP]", "[unused1]", "Sun", "[unused2]", "[unused3]", "announced", "[unused4]", "[unused5]", "Project", "Indiana", "In", "2007", "[unused6]", "[SEP]"]]}

input 137:  {"source": "In 2010 , scam websites co-opted a photograph of her to promote health treatments , the ubiquitous `` 1 weird old tip '' belly fat diets , and penny auctions , unauthorized usage of which Theuriau was initially unaware .\n"}
prediction:  {"predictions": [[1, 188, 24282, 12045, 2, 3, 1884, 28137, 4184, 1906, 4, 5, 170, 10110, 1104, 1123, 1106, 4609, 2332, 14115, 1130, 1333, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 19700, 1358, 2, 3, 1108, 4, 5, 2786, 11987, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 188, 24282, 12045, 2, 3, 1884, 28137, 4184, 1906, 4, 5, 170, 10110, 1104, 1123, 1106, 4609, 2332, 14115, 1103, 190, 5567, 21594, 1361, 122, 6994, 1385, 5580, 7413, 7930, 10211, 1116, 1105, 24585, 11046, 1116, 8362, 24723, 13252, 2200, 7991, 8362, 24723, 13252, 2200, 7991, 8362, 24723, 13252, 102, 1, 188, 24282, 12045, 2, 3, 1884, 28137, 4184, 1906, 4, 5, 170, 10110, 1104, 1123, 1106, 4609, 2332, 14115, 1130, 1333, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 188, 24282, 12045, 2, 3, 1884, 28137, 4184, 1906, 4, 5, 170, 10110, 1104, 1123, 1106, 4609, 2332, 14115, 1130, 1333, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 188, 24282, 12045, 2, 3, 1884, 28137, 4184, 1906, 4, 5, 170, 10110, 1104, 1123, 1106, 4609, 2332, 14115, 1130, 1333, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02703450620174408, -0.0565793439745903, -0.07934387028217316, -0.10244917869567871, -0.10110485553741455, -0.1024470329284668, -0.2634916305541992, -0.2618436813354492, -0.2618436813354492, -0.2618436813354492], "metadata": {"source_tokens": ["In", "2010", ",", "s", "##cam", "websites", "co", "##-", "##op", "##ted", "a", "photograph", "of", "her", "to", "promote", "health", "treatments", ",", "the", "u", "##bi", "##quito", "##us", "`", "##`", "1", "weird", "old", "tip", "'", "##'", "belly", "fat", "diet", "##s", ",", "and", "penny", "auction", "##s", ",", "un", "##aut", "##hor", "##ized", "usage", "of", "which", "The", "##uria", "##u", "was", "initially", "unaware", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "s", "##cam", "websites", "[unused2]", "[unused3]", "co", "##-", "##op", "##ted", "[unused4]", "[unused5]", "a", "photograph", "of", "her", "to", "promote", "health", "treatments", "In", "2010", "[unused6]", "[SEP]", "[unused1]", "The", "##uria", "##u", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "initially", "unaware", "[unused6]", "[SEP]", "[unused1]", "s", "##cam", "websites", "[unused2]", "[unused3]", "co", "##-", "##op", "##ted", "[unused4]", "[unused5]", "a", "photograph", "of", "her", "to", "promote", "health", "treatments", "the", "u", "##bi", "##quito", "##us", "1", "weird", "old", "tip", "belly", "fat", "diet", "##s", "and", "penny", "auction", "##s", "un", "##aut", "##hor", "##ized", "usage", "un", "##aut", "##hor", "##ized", "usage", "un", "##aut", "##hor", "[SEP]", "[unused1]", "s", "##cam", "websites", "[unused2]", "[unused3]", "co", "##-", "##op", "##ted", "[unused4]", "[unused5]", "a", "photograph", "of", "her", "to", "promote", "health", "treatments", "In", "2010", "[unused6]", "[SEP]", "[unused1]", "s", "##cam", "websites", "[unused2]", "[unused3]", "co", "##-", "##op", "##ted", "[unused4]", "[unused5]", "a", "photograph", "of", "her", "to", "promote", "health", "treatments", "In", "2010", "[unused6]", "[SEP]", "[unused1]", "s", "##cam", "websites", "[unused2]", "[unused3]", "co", "##-", "##op", "##ted", "[unused4]", "[unused5]", "a", "photograph", "of", "her", "to", "promote", "health", "treatments", "In", "2010", "[unused6]", "[SEP]"]]}

input 138:  {"source": "In 2011 , major vendors launched several consumer-oriented motherboards using the Intel 6-series LGA 1155 chipset and AMD 9 Series AM3 + chipsets with UEFI .\n"}
prediction:  {"predictions": [[1, 1558, 19086, 2, 3, 2536, 4, 5, 1317, 8440, 28137, 9012, 22666, 1534, 13005, 1606, 1103, 15397, 127, 28137, 6906, 1905, 149, 10583, 10520, 1571, 13228, 2105, 1105, 6586, 2137, 130, 2768, 6586, 1495, 116, 13228, 6248, 1114, 158, 14663, 2240, 1130, 1349, 6, 102, 102, 102, 102, 102, 102, 1, 1558, 19086, 2, 3, 2536, 4, 5, 1317, 8440, 28137, 9012, 22666, 1534, 13005, 1606, 1103, 15397, 127, 28137, 6906, 1905, 149, 10583, 10520, 1571, 13228, 2105, 1105, 6586, 2137, 130, 2768, 6586, 1495, 116, 13228, 6248, 1114, 158, 14663, 2240, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1558, 19086, 2, 3, 2536, 4, 5, 1317, 8440, 28137, 9012, 22666, 1534, 13005, 1606, 1103, 15397, 127, 28137, 6906, 1905, 149, 10583, 10520, 1571, 13228, 2105, 1105, 6586, 2137, 130, 2768, 6586, 1495, 116, 13228, 6248, 1114, 158, 14663, 2240, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1558, 19086, 2, 3, 2536, 4, 5, 1317, 8440, 28137, 9012, 22666, 1534, 13005, 1606, 1103, 15397, 127, 28137, 6906, 1905, 149, 10583, 10520, 1571, 13228, 2105, 1105, 6586, 2137, 130, 2768, 6586, 1495, 116, 13228, 6248, 1114, 158, 14663, 2240, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1558, 19086, 2, 3, 2536, 4, 5, 1317, 8440, 28137, 9012, 22666, 1534, 13005, 1606, 1103, 15397, 127, 28137, 6906, 1905, 149, 10583, 10520, 1571, 13228, 2105, 1105, 6586, 2137, 130, 2768, 6586, 1495, 116, 13228, 6248, 1114, 158, 14663, 2240, 6, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013454629108309746, -0.036020439118146896, -0.045458998531103134, -0.05684323608875275, -0.05919225513935089, -0.2952539920806885, -0.29557347297668457, -0.29557347297668457, -0.29557347297668457, -0.29557347297668457], "metadata": {"source_tokens": ["In", "2011", ",", "major", "vendors", "launched", "several", "consumer", "##-", "##ori", "##ented", "mother", "##boards", "using", "the", "Intel", "6", "##-", "##ser", "##ies", "L", "##GA", "115", "##5", "chips", "##et", "and", "AM", "##D", "9", "Series", "AM", "##3", "+", "chips", "##ets", "with", "U", "##EF", "##I", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "major", "vendors", "[unused2]", "[unused3]", "launched", "[unused4]", "[unused5]", "several", "consumer", "##-", "##ori", "##ented", "mother", "##boards", "using", "the", "Intel", "6", "##-", "##ser", "##ies", "L", "##GA", "115", "##5", "chips", "##et", "and", "AM", "##D", "9", "Series", "AM", "##3", "+", "chips", "##ets", "with", "U", "##EF", "##I", "In", "2011", "[unused6]", "[SEP]", "[unused1]", "major", "vendors", "[unused2]", "[unused3]", "launched", "[unused4]", "[unused5]", "several", "consumer", "##-", "##ori", "##ented", "mother", "##boards", "using", "the", "Intel", "6", "##-", "##ser", "##ies", "L", "##GA", "115", "##5", "chips", "##et", "and", "AM", "##D", "9", "Series", "AM", "##3", "+", "chips", "##ets", "with", "U", "##EF", "##I", "[unused6]", "[SEP]", "[unused1]", "major", "vendors", "[unused2]", "[unused3]", "launched", "[unused4]", "[unused5]", "several", "consumer", "##-", "##ori", "##ented", "mother", "##boards", "using", "the", "Intel", "6", "##-", "##ser", "##ies", "L", "##GA", "115", "##5", "chips", "##et", "and", "AM", "##D", "9", "Series", "AM", "##3", "+", "chips", "##ets", "with", "U", "##EF", "##I", "[unused6]", "[SEP]", "[unused1]", "major", "vendors", "[unused2]", "[unused3]", "launched", "[unused4]", "[unused5]", "several", "consumer", "##-", "##ori", "##ented", "mother", "##boards", "using", "the", "Intel", "6", "##-", "##ser", "##ies", "L", "##GA", "115", "##5", "chips", "##et", "and", "AM", "##D", "9", "Series", "AM", "##3", "+", "chips", "##ets", "with", "U", "##EF", "##I", "[unused6]", "[SEP]", "[unused1]", "major", "vendors", "[unused2]", "[unused3]", "launched", "[unused4]", "[unused5]", "several", "consumer", "##-", "##ori", "##ented", "mother", "##boards", "using", "the", "Intel", "6", "##-", "##ser", "##ies", "L", "##GA", "115", "##5", "chips", "##et", "and", "AM", "##D", "9", "Series", "AM", "##3", "+", "chips", "##ets", "with", "U", "##EF", "##I", "[unused6]", "[SEP]"]]}

input 139:  {"source": "In 2012 , Bloomberg Businessweek voted San Francisco as America 's Best City .\n"}
prediction:  {"predictions": [[1, 25638, 3518, 21394, 2, 3, 4751, 4, 5, 1727, 2948, 1112, 1738, 112, 1116, 1798, 1392, 1130, 1368, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0014924549032002687, -0.07653951644897461, -0.07654213905334473, -0.07654213905334473, -0.07654213905334473, -0.07654213905334473, -0.07654213905334473, -0.07654213905334473, -0.07654213905334473, -0.07654213905334473], "metadata": {"source_tokens": ["In", "2012", ",", "Bloomberg", "Business", "##week", "voted", "San", "Francisco", "as", "America", "'", "##s", "Best", "City", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Bloomberg", "Business", "##week", "[unused2]", "[unused3]", "voted", "[unused4]", "[unused5]", "San", "Francisco", "as", "America", "'", "##s", "Best", "City", "In", "2012", "[unused6]", "[SEP]"]]}

input 140:  {"source": "In 54 BC , Marcus Perperna is mentioned as one of the consulars who bore testimony on behalf of Marcus Aemilius Scaurus at his trial .\n"}
prediction:  {"predictions": [[1, 6042, 14286, 3365, 1605, 2, 3, 1110, 3025, 4, 5, 1112, 1141, 1104, 1103, 17004, 7666, 1130, 4335, 3823, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 17004, 7666, 2, 3, 8475, 4, 5, 11405, 1113, 6261, 1104, 6042, 138, 5521, 18575, 1361, 20452, 19664, 1120, 1117, 3443, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.019064661115407944, -0.016834167763590813, -0.07703089714050293, -0.07705402374267578, -0.07705402374267578, -0.07705402374267578, -0.07705402374267578, -0.07705402374267578, -0.07705402374267578, -0.07705402374267578], "metadata": {"source_tokens": ["In", "54", "BC", ",", "Marcus", "Per", "##per", "##na", "is", "mentioned", "as", "one", "of", "the", "consul", "##ars", "who", "bore", "testimony", "on", "behalf", "of", "Marcus", "A", "##em", "##ili", "##us", "Sc", "##aurus", "at", "his", "trial", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Marcus", "Per", "##per", "##na", "[unused2]", "[unused3]", "is", "mentioned", "[unused4]", "[unused5]", "as", "one", "of", "the", "consul", "##ars", "In", "54", "BC", "[unused6]", "[SEP]", "[unused1]", "the", "consul", "##ars", "[unused2]", "[unused3]", "bore", "[unused4]", "[unused5]", "testimony", "on", "behalf", "of", "Marcus", "A", "##em", "##ili", "##us", "Sc", "##aurus", "at", "his", "trial", "[unused6]", "[SEP]"]]}

input 141:  {"source": "In Canada , there are two organizations that regulate university and collegiate athletics .\n"}
prediction:  {"predictions": [[1, 1160, 3722, 2, 3, 16146, 4, 5, 2755, 1105, 14532, 11645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1160, 3722, 1115, 16146, 2755, 1105, 14532, 11645, 2, 3, 1175, 1132, 4, 5, 1130, 1803, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0037095206789672375, -0.05456775054335594, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562], "metadata": {"source_tokens": ["In", "Canada", ",", "there", "are", "two", "organizations", "that", "regulate", "university", "and", "collegiate", "athletics", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "two", "organizations", "[unused2]", "[unused3]", "regulate", "[unused4]", "[unused5]", "university", "and", "collegiate", "athletics", "[unused6]", "[SEP]", "[unused1]", "two", "organizations", "that", "regulate", "university", "and", "collegiate", "athletics", "[unused2]", "[unused3]", "there", "are", "[unused4]", "[unused5]", "In", "Canada", "[unused6]", "[SEP]"]]}

input 142:  {"source": "In French , `` droit '' can mean `` the whole body of the Law '' , as in the motto `` dieu et mon droit , '' which is to say `` God and my whole body of Law . ''\n"}
prediction:  {"predictions": [[1, 173, 21418, 1204, 2, 3, 1169, 1928, 4, 5, 1103, 2006, 1404, 1104, 1103, 2601, 1130, 1497, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 13658, 2, 3, 1110, 4, 5, 1106, 1474, 169, 28152, 1875, 1105, 1139, 2006, 1404, 1104, 2601, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.040188491344451904, -0.07785964012145996, -0.27559852600097656, -0.31480348110198975, -0.31480348110198975, -0.31480348110198975, -0.31480348110198975, -0.31480348110198975, -0.31480348110198975, -0.31480348110198975], "metadata": {"source_tokens": ["In", "French", ",", "`", "##`", "d", "##roi", "##t", "'", "##'", "can", "mean", "`", "##`", "the", "whole", "body", "of", "the", "Law", "'", "##'", ",", "as", "in", "the", "motto", "`", "##`", "die", "##u", "et", "mon", "d", "##roi", "##t", ",", "'", "##'", "which", "is", "to", "say", "`", "##`", "God", "and", "my", "whole", "body", "of", "Law", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "d", "##roi", "##t", "[unused2]", "[unused3]", "can", "mean", "[unused4]", "[unused5]", "the", "whole", "body", "of", "the", "Law", "In", "French", "[unused6]", "[SEP]", "[unused1]", "the", "motto", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "to", "say", "`", "##`", "God", "and", "my", "whole", "body", "of", "Law", "[unused6]", "[SEP]"]]}

input 143:  {"source": "In Jewish Hebrew , the Samaritans are called `` Shomronim '' , while in Samaritan Hebrew they call themselves `` Shamerim '' .\n"}
prediction:  {"predictions": [[1, 1103, 2687, 7710, 5108, 1116, 2, 3, 1132, 1270, 4, 5, 156, 25453, 3484, 4060, 1130, 2778, 6235, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1840, 4, 5, 2310, 156, 25948, 10205, 1107, 2687, 7710, 5108, 6235, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.020770728588104248, -0.033720094710588455, -0.1264667510986328, -0.13041973114013672, -0.13041973114013672, -0.13041973114013672, -0.13041973114013672, -0.13041973114013672, -0.13041973114013672, -0.13041973114013672], "metadata": {"source_tokens": ["In", "Jewish", "Hebrew", ",", "the", "Sam", "##ari", "##tan", "##s", "are", "called", "`", "##`", "S", "##hom", "##ron", "##im", "'", "##'", ",", "while", "in", "Sam", "##ari", "##tan", "Hebrew", "they", "call", "themselves", "`", "##`", "S", "##hame", "##rim", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Sam", "##ari", "##tan", "##s", "[unused2]", "[unused3]", "are", "called", "[unused4]", "[unused5]", "S", "##hom", "##ron", "##im", "In", "Jewish", "Hebrew", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "call", "[unused4]", "[unused5]", "themselves", "S", "##hame", "##rim", "in", "Sam", "##ari", "##tan", "Hebrew", "[unused6]", "[SEP]"]]}

input 144:  {"source": "In Jewish belief , its fulfilment will be revealed in the cumulation of Creation , in the era of resurrection , in the physical World .\n"}
prediction:  {"predictions": [[1, 1157, 175, 19284, 2723, 1880, 2, 3, 1209, 1129, 3090, 4, 5, 1107, 1103, 16040, 6856, 1104, 19470, 1107, 1103, 3386, 1104, 26926, 1107, 1103, 2952, 1291, 1130, 2778, 6369, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1157, 175, 19284, 2723, 1880, 2, 3, 1209, 1129, 3090, 4, 5, 1107, 1103, 16040, 6856, 1104, 19470, 1107, 1103, 3386, 1104, 26926, 1107, 1103, 2952, 1291, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1157, 175, 19284, 2723, 1880, 2, 3, 1209, 1129, 3090, 4, 5, 1107, 1103, 16040, 6856, 1104, 19470, 1107, 1103, 3386, 1104, 26926, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.034198883920907974, -0.04013624042272568, -0.06434012949466705, -0.21135342121124268, -0.21187162399291992, -0.21187162399291992, -0.21187162399291992, -0.21187162399291992, -0.21187162399291992, -0.21187162399291992], "metadata": {"source_tokens": ["In", "Jewish", "belief", ",", "its", "f", "##ulf", "##il", "##ment", "will", "be", "revealed", "in", "the", "cum", "##ulation", "of", "Creation", ",", "in", "the", "era", "of", "resurrection", ",", "in", "the", "physical", "World", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "its", "f", "##ulf", "##il", "##ment", "[unused2]", "[unused3]", "will", "be", "revealed", "[unused4]", "[unused5]", "in", "the", "cum", "##ulation", "of", "Creation", "in", "the", "era", "of", "resurrection", "in", "the", "physical", "World", "In", "Jewish", "belief", "[unused6]", "[SEP]", "[unused1]", "its", "f", "##ulf", "##il", "##ment", "[unused2]", "[unused3]", "will", "be", "revealed", "[unused4]", "[unused5]", "in", "the", "cum", "##ulation", "of", "Creation", "in", "the", "era", "of", "resurrection", "in", "the", "physical", "World", "[unused6]", "[SEP]", "[unused1]", "its", "f", "##ulf", "##il", "##ment", "[unused2]", "[unused3]", "will", "be", "revealed", "[unused4]", "[unused5]", "in", "the", "cum", "##ulation", "of", "Creation", "in", "the", "era", "of", "resurrection", "[unused6]", "[SEP]"]]}

input 145:  {"source": "In June , Nasser took control of the interior ministry post from Naguib loyalist Sulayman Hafez , and pressured Naguib to conclude the abolition of the monarchy .\n"}
prediction:  {"predictions": [[1, 11896, 14607, 2, 3, 1261, 4, 5, 1654, 1104, 1103, 4604, 8382, 2112, 1121, 11896, 13830, 13292, 9125, 1776, 27040, 25939, 11679, 8124, 1584, 1130, 1340, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11896, 14607, 2, 3, 2997, 1181, 4, 5, 11896, 13830, 13292, 1106, 17581, 1103, 18304, 1104, 1103, 14358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11896, 14607, 2, 3, 1261, 4, 5, 1654, 1104, 1103, 4604, 8382, 2112, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11896, 13830, 13292, 2, 3, 1106, 17581, 4, 5, 1103, 18304, 1104, 1103, 14358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005490798503160477, -0.03579157590866089, -0.13486802577972412, -0.07000123709440231, -0.12350869178771973, -0.12350964546203613, -0.12350964546203613, -0.12350964546203613, -0.12350964546203613, -0.12350964546203613], "metadata": {"source_tokens": ["In", "June", ",", "Na", "##sser", "took", "control", "of", "the", "interior", "ministry", "post", "from", "Na", "##gu", "##ib", "loyal", "##ist", "Sul", "##ayman", "Ha", "##fe", "##z", ",", "and", "pressure", "##d", "Na", "##gu", "##ib", "to", "conclude", "the", "abolition", "of", "the", "monarchy", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "control", "of", "the", "interior", "ministry", "post", "from", "Na", "##gu", "##ib", "loyal", "##ist", "Sul", "##ayman", "Ha", "##fe", "##z", "In", "June", "[unused6]", "[SEP]", "[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "pressure", "##d", "[unused4]", "[unused5]", "Na", "##gu", "##ib", "to", "conclude", "the", "abolition", "of", "the", "monarchy", "[unused6]", "[SEP]", "[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "control", "of", "the", "interior", "ministry", "post", "[unused6]", "[SEP]", "[unused1]", "Na", "##gu", "##ib", "[unused2]", "[unused3]", "to", "conclude", "[unused4]", "[unused5]", "the", "abolition", "of", "the", "monarchy", "[unused6]", "[SEP]"]]}

input 146:  {"source": "In October 2009 it was confirmed that the Byrom Street cutting was a hitching and unhitching point for trains being cable hauled to Edge Hill via the Victoria Tunnel .\n"}
prediction:  {"predictions": [[1, 3918, 2, 3, 1217, 4, 5, 6095, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1650, 16071, 1715, 5910, 2, 3, 1108, 4, 5, 170, 1855, 7520, 1105, 8362, 17481, 7520, 1553, 1111, 3918, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 3659, 4, 5, 1115, 1103, 1650, 16071, 1715, 5910, 1108, 170, 1855, 7520, 1105, 8362, 17481, 7520, 1553, 1111, 3918, 1217, 6095, 13486, 1106, 10403, 2404, 2258, 1103, 3006, 12872, 1130, 1357, 1371, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6095, 2, 3, 13486, 4, 5, 1106, 10403, 2404, 2258, 1103, 3006, 12872, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.1603093147277832, -0.032847508788108826, -0.05769821256399155, -0.0947505533695221, -0.17524147033691406, -0.18276238441467285, -0.18276238441467285, -0.18276238441467285, -0.18276238441467285, -0.18276238441467285], "metadata": {"source_tokens": ["In", "October", "2009", "it", "was", "confirmed", "that", "the", "By", "##rom", "Street", "cutting", "was", "a", "hit", "##ching", "and", "un", "##hit", "##ching", "point", "for", "trains", "being", "cable", "hauled", "to", "Edge", "Hill", "via", "the", "Victoria", "Tunnel", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "trains", "[unused2]", "[unused3]", "being", "[unused4]", "[unused5]", "cable", "[unused6]", "[SEP]", "[unused1]", "the", "By", "##rom", "Street", "cutting", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "hit", "##ching", "and", "un", "##hit", "##ching", "point", "for", "trains", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "confirmed", "[unused4]", "[unused5]", "that", "the", "By", "##rom", "Street", "cutting", "was", "a", "hit", "##ching", "and", "un", "##hit", "##ching", "point", "for", "trains", "being", "cable", "hauled", "to", "Edge", "Hill", "via", "the", "Victoria", "Tunnel", "In", "October", "2009", "[unused6]", "[SEP]", "[unused1]", "cable", "[unused2]", "[unused3]", "hauled", "[unused4]", "[unused5]", "to", "Edge", "Hill", "via", "the", "Victoria", "Tunnel", "[unused6]", "[SEP]"]]}

input 147:  {"source": "In September 1941 , she joined the Women 's Auxiliary Air Force , working at the Department of the Chief of Air Staff as Assistant Section Officer for Intelligence duties , before being posted in July 1942 to Moreton-in-Marsh , where she was promoted to Section officer .\n"}
prediction:  {"predictions": [[1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1130, 1347, 3018, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1108, 3082, 4, 5, 1106, 6177, 2575, 3046, 1633, 28137, 1394, 28137, 2107, 7666, 1324, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1684, 1120, 1103, 1951, 1104, 1103, 2534, 1104, 1806, 5949, 1112, 5414, 6177, 4124, 1111, 7829, 5078, 1196, 1217, 6310, 1107, 1351, 2889, 1106, 3046, 1633, 28137, 1394, 28137, 2107, 7666, 1324, 6, 102, 102, 102, 102, 1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1684, 1120, 1103, 1951, 1104, 1103, 2534, 1104, 1806, 5949, 1112, 5414, 6177, 4124, 1111, 7829, 5078, 1196, 1217, 6310, 1107, 1351, 2889, 1106, 3046, 1633, 28137, 1394, 28137, 2107, 7666, 1324, 6, 102, 102, 102, 102, 1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1684, 1120, 1103, 1951, 1104, 1103, 2534, 1104, 1806, 5949, 1112, 5414, 6177, 4124, 1111, 7829, 5078, 1196, 1217, 6310, 1107, 1351, 2889, 1106, 3046, 1633, 28137, 1394, 28137, 2107, 7666, 1324, 6, 102, 102, 102, 102, 1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1684, 1120, 1103, 1951, 1104, 1103, 2534, 1104, 1806, 5949, 1112, 5414, 6177, 4124, 1111, 7829, 5078, 1196, 1217, 6310, 1107, 1351, 2889, 1106, 3046, 1633, 28137, 1394, 28137, 2107, 7666, 1324, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04667341709136963, -0.015102557837963104, -0.054228078573942184, -0.06670623272657394, -0.0781014934182167, -0.08349213749170303, -0.2904083728790283, -0.2971670627593994, -0.2971670627593994, -0.2971670627593994], "metadata": {"source_tokens": ["In", "September", "1941", ",", "she", "joined", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", ",", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", ",", "before", "being", "posted", "in", "July", "1942", "to", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", ",", "where", "she", "was", "promoted", "to", "Section", "officer", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "In", "September", "1941", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "was", "promoted", "[unused4]", "[unused5]", "to", "Section", "officer", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", "before", "being", "posted", "in", "July", "1942", "to", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", "before", "being", "posted", "in", "July", "1942", "to", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", "before", "being", "posted", "in", "July", "1942", "to", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", "before", "being", "posted", "in", "July", "1942", "to", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", "[unused6]", "[SEP]"]]}

input 148:  {"source": "In Van Howe 's study , all cases of meatal stenosis were among circumcised boys .\n"}
prediction:  {"predictions": [[1, 1155, 2740, 1104, 6092, 1348, 188, 5208, 11776, 2, 3, 1127, 4, 5, 1621, 172, 3161, 19172, 14636, 1181, 3287, 1130, 3605, 13724, 112, 1116, 2025, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0005340247298590839, -0.032907962799072266, -0.03268742561340332, -0.03268742561340332, -0.03268742561340332, -0.03268742561340332, -0.03268742561340332, -0.03268742561340332, -0.03268742561340332, -0.03268742561340332], "metadata": {"source_tokens": ["In", "Van", "Howe", "'", "##s", "study", ",", "all", "cases", "of", "meat", "##al", "s", "##ten", "##osis", "were", "among", "c", "##ir", "##cum", "##cise", "##d", "boys", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "all", "cases", "of", "meat", "##al", "s", "##ten", "##osis", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "among", "c", "##ir", "##cum", "##cise", "##d", "boys", "In", "Van", "Howe", "'", "##s", "study", "[unused6]", "[SEP]"]]}

input 149:  {"source": "In `` The Andromeda Strain '' , Michael Crichton 's first novel published under his real name , only two people exposed to a pathogenic extraterrestrial microbe survive .\n"}
prediction:  {"predictions": [[1, 1847, 140, 10886, 1633, 112, 1116, 1148, 2281, 2, 3, 1502, 4, 5, 1223, 1117, 1842, 1271, 1130, 169, 28152, 1109, 1262, 11457, 1810, 1457, 11098, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1178, 1160, 1234, 5490, 1106, 170, 3507, 17960, 3908, 2083, 14201, 13119, 17599, 3962, 2, 3, 5195, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1178, 1160, 1234, 5490, 1106, 170, 3507, 17960, 3908, 2083, 14201, 13119, 17599, 3962, 2, 3, 5195, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1178, 1160, 1234, 5490, 1106, 170, 3507, 17960, 3908, 2083, 14201, 13119, 17599, 3962, 2, 3, 5195, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03358347713947296, -0.026415424421429634, -0.06621498614549637, -0.07585844397544861, -0.26539814472198486, -0.2811448574066162, -0.2811448574066162, -0.2811448574066162, -0.2811448574066162, -0.2811448574066162], "metadata": {"source_tokens": ["In", "`", "##`", "The", "And", "##rome", "##da", "St", "##rain", "'", "##'", ",", "Michael", "C", "##rich", "##ton", "'", "##s", "first", "novel", "published", "under", "his", "real", "name", ",", "only", "two", "people", "exposed", "to", "a", "path", "##ogenic", "extra", "##ter", "##rest", "##rial", "micro", "##be", "survive", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Michael", "C", "##rich", "##ton", "'", "##s", "first", "novel", "[unused2]", "[unused3]", "published", "[unused4]", "[unused5]", "under", "his", "real", "name", "In", "`", "##`", "The", "And", "##rome", "##da", "St", "##rain", "[unused6]", "[SEP]", "[unused1]", "only", "two", "people", "exposed", "to", "a", "path", "##ogenic", "extra", "##ter", "##rest", "##rial", "micro", "##be", "[unused2]", "[unused3]", "survive", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "only", "two", "people", "exposed", "to", "a", "path", "##ogenic", "extra", "##ter", "##rest", "##rial", "micro", "##be", "[unused2]", "[unused3]", "survive", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "only", "two", "people", "exposed", "to", "a", "path", "##ogenic", "extra", "##ter", "##rest", "##rial", "micro", "##be", "[unused2]", "[unused3]", "survive", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 150:  {"source": "In a news post , Holkins stated that he reserved the right to bring Carl back any time Krahulik goes to France .\n"}
prediction:  {"predictions": [[1, 9800, 10493, 4935, 2, 3, 2202, 4, 5, 1115, 1119, 9142, 1103, 1268, 1106, 2498, 4804, 1171, 1251, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 148, 10659, 15818, 1377, 2, 3, 2947, 4, 5, 1106, 1699, 1251, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 9142, 4, 5, 1103, 1268, 1106, 2498, 4804, 1171, 1251, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9800, 10493, 4935, 2, 3, 2202, 4, 5, 1115, 1119, 9142, 1103, 1268, 1106, 2498, 4804, 1171, 1251, 1159, 148, 10659, 15818, 1377, 2947, 1106, 1699, 1130, 170, 2371, 2112, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.042110625654459, -0.038139812648296356, -0.061196357011795044, -0.059892863035202026, -0.12057685852050781, -0.12055349349975586, -0.12055349349975586, -0.12055349349975586, -0.12055349349975586, -0.12055349349975586], "metadata": {"source_tokens": ["In", "a", "news", "post", ",", "Ho", "##lk", "##ins", "stated", "that", "he", "reserved", "the", "right", "to", "bring", "Carl", "back", "any", "time", "K", "##rah", "##uli", "##k", "goes", "to", "France", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ho", "##lk", "##ins", "[unused2]", "[unused3]", "stated", "[unused4]", "[unused5]", "that", "he", "reserved", "the", "right", "to", "bring", "Carl", "back", "any", "time", "[unused6]", "[SEP]", "[unused1]", "K", "##rah", "##uli", "##k", "[unused2]", "[unused3]", "goes", "[unused4]", "[unused5]", "to", "France", "any", "time", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "reserved", "[unused4]", "[unused5]", "the", "right", "to", "bring", "Carl", "back", "any", "time", "[unused6]", "[SEP]", "[unused1]", "Ho", "##lk", "##ins", "[unused2]", "[unused3]", "stated", "[unused4]", "[unused5]", "that", "he", "reserved", "the", "right", "to", "bring", "Carl", "back", "any", "time", "K", "##rah", "##uli", "##k", "goes", "to", "France", "In", "a", "news", "post", "[unused6]", "[SEP]"]]}

input 151:  {"source": "In a typical case of substrate interference , a Language A occupies a given territory and another Language B arrives in the same territory .\n"}
prediction:  {"predictions": [[1, 170, 6828, 138, 2, 3, 14679, 4, 5, 170, 1549, 3441, 1105, 1330, 6828, 139, 8121, 1107, 1103, 1269, 3441, 1130, 170, 4701, 1692, 1104, 17498, 11364, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1330, 6828, 139, 2, 3, 8121, 4, 5, 1107, 1103, 1269, 3441, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027588453143835068, -0.002948419190943241, -0.04039812088012695, -0.03962135314941406, -0.03962135314941406, -0.03962135314941406, -0.03962135314941406, -0.03962135314941406, -0.03962135314941406, -0.03962135314941406], "metadata": {"source_tokens": ["In", "a", "typical", "case", "of", "substrate", "interference", ",", "a", "Language", "A", "occupies", "a", "given", "territory", "and", "another", "Language", "B", "arrives", "in", "the", "same", "territory", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "Language", "A", "[unused2]", "[unused3]", "occupies", "[unused4]", "[unused5]", "a", "given", "territory", "and", "another", "Language", "B", "arrives", "in", "the", "same", "territory", "In", "a", "typical", "case", "of", "substrate", "interference", "[unused6]", "[SEP]", "[unused1]", "another", "Language", "B", "[unused2]", "[unused3]", "arrives", "[unused4]", "[unused5]", "in", "the", "same", "territory", "[unused6]", "[SEP]"]]}

input 152:  {"source": "In addition , as John Cecil Masterman , chairman of the Twenty Committee , commented , `` If , for example , St Paul 's Cathedral were hit , it was useless and harmful to report that the bomb had descended upon a cinema in Islington , since the truth would inevitably get through to Germany ... ''\n"}
prediction:  {"predictions": [[1, 1287, 12091, 3257, 1399, 2, 3, 6454, 4, 5, 1409, 117, 1111, 1859, 117, 1457, 1795, 112, 1116, 5761, 1127, 1855, 117, 1122, 1108, 12277, 1105, 19403, 1106, 2592, 1115, 1103, 5985, 1125, 9026, 1852, 170, 7678, 1107, 2181, 21103, 117, 1290, 1103, 3062, 1156, 25315, 1243, 1194, 1106, 102, 1, 1287, 12091, 3257, 1399, 2, 3, 1110, 3931, 1104, 4, 5, 1103, 7714, 2341, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3062, 2, 3, 1156, 1243, 4, 5, 1194, 1106, 1860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1457, 1795, 112, 1116, 5761, 2, 3, 1127, 1855, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3062, 2, 3, 1156, 1243, 4, 5, 1194, 1106, 1860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3062, 2, 3, 1156, 1243, 4, 5, 1194, 1106, 1860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3062, 2, 3, 1156, 1243, 4, 5, 1194, 1106, 1860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3062, 2, 3, 1156, 1243, 4, 5, 1194, 1106, 1860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3062, 2, 3, 1156, 1243, 4, 5, 1194, 1106, 1860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3062, 2, 3, 1156, 1243, 4, 5, 1194, 1106, 1860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02771723084151745, -0.09386354684829712, -0.13987429440021515, -0.07567204535007477, -0.17015086114406586, -0.19012202322483063, -0.18264815211296082, -0.18063701689243317, -0.17769448459148407, -0.18855227530002594], "metadata": {"source_tokens": ["In", "addition", ",", "as", "John", "Cecil", "Master", "##man", ",", "chairman", "of", "the", "Twenty", "Committee", ",", "commented", ",", "`", "##`", "If", ",", "for", "example", ",", "St", "Paul", "'", "##s", "Cathedral", "were", "hit", ",", "it", "was", "useless", "and", "harmful", "to", "report", "that", "the", "bomb", "had", "descended", "upon", "a", "cinema", "in", "Is", "##lington", ",", "since", "the", "truth", "would", "inevitably", "get", "through", "to", "Germany", "...", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "John", "Cecil", "Master", "##man", "[unused2]", "[unused3]", "commented", "[unused4]", "[unused5]", "If", ",", "for", "example", ",", "St", "Paul", "'", "##s", "Cathedral", "were", "hit", ",", "it", "was", "useless", "and", "harmful", "to", "report", "that", "the", "bomb", "had", "descended", "upon", "a", "cinema", "in", "Is", "##lington", ",", "since", "the", "truth", "would", "inevitably", "get", "through", "to", "[SEP]", "[unused1]", "John", "Cecil", "Master", "##man", "[unused2]", "[unused3]", "is", "chairman", "of", "[unused4]", "[unused5]", "the", "Twenty", "Committee", "[unused6]", "[SEP]", "[unused1]", "the", "truth", "[unused2]", "[unused3]", "would", "get", "[unused4]", "[unused5]", "through", "to", "Germany", "[unused6]", "[SEP]", "[unused1]", "St", "Paul", "'", "##s", "Cathedral", "[unused2]", "[unused3]", "were", "hit", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "the", "truth", "[unused2]", "[unused3]", "would", "get", "[unused4]", "[unused5]", "through", "to", "Germany", "[unused6]", "[SEP]", "[unused1]", "the", "truth", "[unused2]", "[unused3]", "would", "get", "[unused4]", "[unused5]", "through", "to", "Germany", "[unused6]", "[SEP]", "[unused1]", "the", "truth", "[unused2]", "[unused3]", "would", "get", "[unused4]", "[unused5]", "through", "to", "Germany", "[unused6]", "[SEP]", "[unused1]", "the", "truth", "[unused2]", "[unused3]", "would", "get", "[unused4]", "[unused5]", "through", "to", "Germany", "[unused6]", "[SEP]", "[unused1]", "the", "truth", "[unused2]", "[unused3]", "would", "get", "[unused4]", "[unused5]", "through", "to", "Germany", "[unused6]", "[SEP]", "[unused1]", "the", "truth", "[unused2]", "[unused3]", "would", "get", "[unused4]", "[unused5]", "through", "to", "Germany", "[unused6]", "[SEP]"]]}

input 153:  {"source": "In athletics , Boston College left the Big East Conference and joined the Atlantic Coast Conference on July 1 , 2005 .\n"}
prediction:  {"predictions": [[1, 2859, 1531, 2, 3, 1286, 4, 5, 1103, 2562, 1689, 3047, 1130, 11645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2859, 1531, 2, 3, 1688, 4, 5, 1103, 3608, 3331, 3047, 1113, 1351, 122, 117, 1478, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2859, 1531, 2, 3, 1688, 4, 5, 1103, 3608, 3331, 3047, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2859, 1531, 2, 3, 1688, 4, 5, 1103, 3608, 3331, 3047, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.010212048888206482, -0.020184103399515152, -0.07272893935441971, -0.08566702902317047, -0.15086758136749268, -0.15119802951812744, -0.15119802951812744, -0.15119802951812744, -0.15119802951812744, -0.15119802951812744], "metadata": {"source_tokens": ["In", "athletics", ",", "Boston", "College", "left", "the", "Big", "East", "Conference", "and", "joined", "the", "Atlantic", "Coast", "Conference", "on", "July", "1", ",", "2005", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Boston", "College", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "the", "Big", "East", "Conference", "In", "athletics", "[unused6]", "[SEP]", "[unused1]", "Boston", "College", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Atlantic", "Coast", "Conference", "on", "July", "1", ",", "2005", "[unused6]", "[SEP]", "[unused1]", "Boston", "College", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Atlantic", "Coast", "Conference", "[unused6]", "[SEP]", "[unused1]", "Boston", "College", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Atlantic", "Coast", "Conference", "[unused6]", "[SEP]"]]}

input 154:  {"source": "In both cases this specialized function replaces the basic rifleman position in the fireteam .\n"}
prediction:  {"predictions": [[1, 1142, 7623, 3053, 2, 3, 22974, 4, 5, 1103, 3501, 6658, 1399, 1700, 1107, 1103, 1783, 1566, 2312, 1130, 1241, 2740, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0006794929504394531, -0.07638764381408691, -0.07639145851135254, -0.07639145851135254, -0.07639145851135254, -0.07639145851135254, -0.07639145851135254, -0.07639145851135254, -0.07639145851135254, -0.07639145851135254], "metadata": {"source_tokens": ["In", "both", "cases", "this", "specialized", "function", "replaces", "the", "basic", "rifle", "##man", "position", "in", "the", "fire", "##te", "##am", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "this", "specialized", "function", "[unused2]", "[unused3]", "replaces", "[unused4]", "[unused5]", "the", "basic", "rifle", "##man", "position", "in", "the", "fire", "##te", "##am", "In", "both", "cases", "[unused6]", "[SEP]"]]}

input 155:  {"source": "In fact , Condon , after seeing Hauptmann in a lineup at New York Police Department Greenwich Street Station told FBI Special Agent Turrou that Hauptmann was not `` John , '' the man to whom Condon claimed he passed the ransom money to in St. Raymond 's Cemetery .\n"}
prediction:  {"predictions": [[1, 16752, 3842, 2, 3, 1500, 4, 5, 8099, 3139, 9341, 17037, 13656, 1358, 1115, 11679, 4455, 21544, 1179, 1108, 1136, 1287, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16752, 3842, 2, 3, 2694, 4, 5, 1119, 2085, 1103, 25057, 1948, 1106, 1107, 1457, 28138, 7139, 112, 1116, 5501, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16752, 3842, 2, 3, 1500, 4, 5, 8099, 3139, 9341, 17037, 13656, 1358, 1115, 11679, 4455, 21544, 1179, 1108, 1136, 1287, 1170, 3195, 11679, 4455, 21544, 1179, 1107, 170, 10545, 1120, 1203, 1365, 3284, 1951, 14323, 1715, 2874, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16752, 3842, 2, 3, 1500, 4, 5, 8099, 3139, 9341, 17037, 13656, 1358, 1115, 11679, 4455, 21544, 1179, 1108, 1136, 1287, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16752, 3842, 2, 3, 1500, 4, 5, 8099, 3139, 9341, 17037, 13656, 1358, 1115, 11679, 4455, 21544, 1179, 1108, 1136, 1287, 1103, 1299, 1106, 2292, 16752, 3842, 2694, 1119, 2085, 1103, 25057, 1948, 1106, 1107, 1457, 28138, 7139, 112, 1116, 5501, 1170, 3195, 11679, 4455, 21544, 1179, 1107, 170, 102, 1, 16752, 3842, 2, 3, 1500, 4, 5, 8099, 3139, 9341, 17037, 13656, 1358, 1115, 11679, 4455, 21544, 1179, 1108, 1136, 1287, 1103, 1299, 1106, 2292, 16752, 3842, 2694, 1119, 2085, 1103, 25057, 1948, 1106, 1107, 1457, 28138, 7139, 112, 1116, 5501, 6, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.08817722648382187, -0.027585333213210106, -0.06185012310743332, -0.11781863123178482, -0.10497906804084778, -0.11976370215415955, -0.3478240966796875, -0.3486638069152832, -0.3486638069152832, -0.3486638069152832], "metadata": {"source_tokens": ["In", "fact", ",", "Con", "##don", ",", "after", "seeing", "Ha", "##up", "##tman", "##n", "in", "a", "lineup", "at", "New", "York", "Police", "Department", "Greenwich", "Street", "Station", "told", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "`", "##`", "John", ",", "'", "##'", "the", "man", "to", "whom", "Con", "##don", "claimed", "he", "passed", "the", "ransom", "money", "to", "in", "St", "##.", "Raymond", "'", "##s", "Cemetery", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Con", "##don", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "John", "[unused6]", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "claimed", "[unused4]", "[unused5]", "he", "passed", "the", "ransom", "money", "to", "in", "St", "##.", "Raymond", "'", "##s", "Cemetery", "[unused6]", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "John", "after", "seeing", "Ha", "##up", "##tman", "##n", "in", "a", "lineup", "at", "New", "York", "Police", "Department", "Greenwich", "Street", "Station", "[unused6]", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "John", "[unused6]", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "John", "the", "man", "to", "whom", "Con", "##don", "claimed", "he", "passed", "the", "ransom", "money", "to", "in", "St", "##.", "Raymond", "'", "##s", "Cemetery", "after", "seeing", "Ha", "##up", "##tman", "##n", "in", "a", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "John", "the", "man", "to", "whom", "Con", "##don", "claimed", "he", "passed", "the", "ransom", "money", "to", "in", "St", "##.", "Raymond", "'", "##s", "Cemetery", "[unused6]", "[SEP]"]]}

input 156:  {"source": "In its first six months , RCPO concluded 858 cases convictions in 88 % of cases .\n"}
prediction:  {"predictions": [[1, 25157, 23329, 2, 3, 4803, 4, 5, 4859, 1604, 2740, 22978, 1107, 5385, 110, 1104, 2740, 1130, 1157, 1148, 1565, 1808, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25157, 23329, 2, 3, 4803, 4, 5, 4859, 1604, 2740, 22978, 1107, 5385, 110, 1104, 2740, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0011410713195800781, -0.04848047345876694, -0.07646894454956055, -0.07646799087524414, -0.07646799087524414, -0.07646799087524414, -0.07646799087524414, -0.07646799087524414, -0.07646799087524414, -0.07646799087524414], "metadata": {"source_tokens": ["In", "its", "first", "six", "months", ",", "RC", "##PO", "concluded", "85", "##8", "cases", "convictions", "in", "88", "%", "of", "cases", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "RC", "##PO", "[unused2]", "[unused3]", "concluded", "[unused4]", "[unused5]", "85", "##8", "cases", "convictions", "in", "88", "%", "of", "cases", "In", "its", "first", "six", "months", "[unused6]", "[SEP]", "[unused1]", "RC", "##PO", "[unused2]", "[unused3]", "concluded", "[unused4]", "[unused5]", "85", "##8", "cases", "convictions", "in", "88", "%", "of", "cases", "[unused6]", "[SEP]"]]}

input 157:  {"source": "In modern classifications , it is often treated as a subfamily of the Glyphipterigidae family .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 1110, 5165, 4, 5, 1112, 170, 11548, 1104, 1103, 144, 1193, 27008, 6451, 9866, 5389, 5598, 1266, 1130, 2030, 5393, 1116, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00129702256526798, -0.12401318550109863, -0.12596678733825684, -0.12596678733825684, -0.12596678733825684, -0.12596678733825684, -0.12596678733825684, -0.12596678733825684, -0.12596678733825684, -0.12596678733825684], "metadata": {"source_tokens": ["In", "modern", "classification", "##s", ",", "it", "is", "often", "treated", "as", "a", "subfamily", "of", "the", "G", "##ly", "##phi", "##pt", "##eri", "##gi", "##dae", "family", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "is", "treated", "[unused4]", "[unused5]", "as", "a", "subfamily", "of", "the", "G", "##ly", "##phi", "##pt", "##eri", "##gi", "##dae", "family", "In", "modern", "classification", "##s", "often", "[unused6]", "[SEP]"]]}

input 158:  {"source": "In more recent years , this policy has apparently relaxed somewhat .\n"}
prediction:  {"predictions": [[1, 1142, 2818, 2, 3, 1144, 4547, 8000, 4, 5, 4742, 1130, 1167, 2793, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01994851790368557, -0.021998882293701172, -0.022007465362548828, -0.022007465362548828, -0.022007465362548828, -0.022007465362548828, -0.022007465362548828, -0.022007465362548828, -0.022007465362548828, -0.022007465362548828], "metadata": {"source_tokens": ["In", "more", "recent", "years", ",", "this", "policy", "has", "apparently", "relaxed", "somewhat", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "this", "policy", "[unused2]", "[unused3]", "has", "apparently", "relaxed", "[unused4]", "[unused5]", "somewhat", "In", "more", "recent", "years", "[unused6]", "[SEP]"]]}

input 159:  {"source": "In order to support planned TRAX expansion , UTA ordered 77 Siemens S70 light rail vehicles from Siemens AG .\n"}
prediction:  {"predictions": [[1, 158, 9159, 2, 3, 2802, 4, 5, 5581, 24824, 156, 20829, 1609, 4356, 4011, 1121, 24824, 14731, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 158, 9159, 2, 3, 2802, 4, 5, 5581, 24824, 156, 20829, 1609, 4356, 4011, 1130, 1546, 1106, 1619, 2919, 157, 9664, 3190, 4298, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00123682024423033, -0.030265629291534424, -0.23885583877563477, -0.2680180072784424, -0.2680180072784424, -0.2680180072784424, -0.2680180072784424, -0.2680180072784424, -0.2680180072784424, -0.2680180072784424], "metadata": {"source_tokens": ["In", "order", "to", "support", "planned", "T", "##RA", "##X", "expansion", ",", "U", "##TA", "ordered", "77", "Siemens", "S", "##70", "light", "rail", "vehicles", "from", "Siemens", "AG", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "U", "##TA", "[unused2]", "[unused3]", "ordered", "[unused4]", "[unused5]", "77", "Siemens", "S", "##70", "light", "rail", "vehicles", "from", "Siemens", "AG", "[unused6]", "[SEP]", "[unused1]", "U", "##TA", "[unused2]", "[unused3]", "ordered", "[unused4]", "[unused5]", "77", "Siemens", "S", "##70", "light", "rail", "vehicles", "In", "order", "to", "support", "planned", "T", "##RA", "##X", "expansion", "[unused6]", "[SEP]"]]}

input 160:  {"source": "In particular , Cyprinidae of southwestern North America have been severely affected ; a considerable number went entirely extinct after settlement by Europeans .\n"}
prediction:  {"predictions": [[1, 170, 5602, 1295, 2, 3, 1355, 4, 5, 3665, 8256, 1170, 3433, 1118, 13810, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 27688, 1643, 19764, 5598, 1104, 10231, 1456, 1738, 2, 3, 1138, 1151, 8669, 4634, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03812307491898537, -0.011282977648079395, -0.032202959060668945, -0.032202959060668945, -0.032202959060668945, -0.032202959060668945, -0.032202959060668945, -0.032202959060668945, -0.032202959060668945, -0.032202959060668945], "metadata": {"source_tokens": ["In", "particular", ",", "Cy", "##p", "##rini", "##dae", "of", "southwestern", "North", "America", "have", "been", "severely", "affected", ";", "a", "considerable", "number", "went", "entirely", "extinct", "after", "settlement", "by", "Europeans", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "considerable", "number", "[unused2]", "[unused3]", "went", "[unused4]", "[unused5]", "entirely", "extinct", "after", "settlement", "by", "Europeans", "[unused6]", "[SEP]", "[unused1]", "Cy", "##p", "##rini", "##dae", "of", "southwestern", "North", "America", "[unused2]", "[unused3]", "have", "been", "severely", "affected", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 161:  {"source": "In the 1901 election , after which the Oppositionists under George Leake were able to form a minority government , Frank Wilson , formerly the member for Canning , won the seat .\n"}
prediction:  {"predictions": [[1, 2748, 3425, 2, 3, 1281, 4, 5, 1103, 1946, 1130, 1103, 5064, 1728, 1170, 1134, 1103, 16475, 3681, 1223, 1667, 12958, 2391, 1127, 1682, 1106, 1532, 170, 7309, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 16475, 3681, 1223, 1667, 12958, 2391, 2, 3, 1127, 4, 5, 1682, 1106, 1532, 170, 7309, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2748, 3425, 2, 3, 1110, 4, 5, 3147, 1103, 1420, 1111, 2825, 3381, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017011798918247223, -0.033514827489852905, -0.08725788444280624, -0.1470930576324463, -0.14970731735229492, -0.14970731735229492, -0.14970731735229492, -0.14970731735229492, -0.14970731735229492, -0.14970731735229492], "metadata": {"source_tokens": ["In", "the", "1901", "election", ",", "after", "which", "the", "Opposition", "##ists", "under", "George", "Lea", "##ke", "were", "able", "to", "form", "a", "minority", "government", ",", "Frank", "Wilson", ",", "formerly", "the", "member", "for", "Can", "##ning", ",", "won", "the", "seat", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Frank", "Wilson", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "the", "seat", "In", "the", "1901", "election", "after", "which", "the", "Opposition", "##ists", "under", "George", "Lea", "##ke", "were", "able", "to", "form", "a", "minority", "government", "[unused6]", "[SEP]", "[unused1]", "the", "Opposition", "##ists", "under", "George", "Lea", "##ke", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "able", "to", "form", "a", "minority", "government", "[unused6]", "[SEP]", "[unused1]", "Frank", "Wilson", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "formerly", "the", "member", "for", "Can", "##ning", "[unused6]", "[SEP]"]]}

input 162:  {"source": "In the 1960s and 70s most of Kabul 's economy depended on tourism .\n"}
prediction:  {"predictions": [[1, 1211, 1104, 23321, 112, 1116, 4190, 2, 3, 18520, 4, 5, 1113, 8668, 1130, 1103, 3266, 1105, 19025, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0007316895644180477, -0.04057049751281738, -0.03805112838745117, -0.03805112838745117, -0.03805112838745117, -0.03805112838745117, -0.03805112838745117, -0.03805112838745117, -0.03805112838745117, -0.03805112838745117], "metadata": {"source_tokens": ["In", "the", "1960s", "and", "70s", "most", "of", "Kabul", "'", "##s", "economy", "depended", "on", "tourism", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "most", "of", "Kabul", "'", "##s", "economy", "[unused2]", "[unused3]", "depended", "[unused4]", "[unused5]", "on", "tourism", "In", "the", "1960s", "and", "70s", "[unused6]", "[SEP]"]]}

input 163:  {"source": "In the 1986 television series `` War and Remembrance '' , Johns took the role of the senior Nazi SS officer Adolf Eichmann .\n"}
prediction:  {"predictions": [[1, 11673, 2, 3, 1261, 4, 5, 1103, 1648, 1104, 1103, 2682, 5755, 6663, 2575, 1130, 1103, 2177, 1778, 1326, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11673, 2, 3, 1261, 4, 5, 1103, 1648, 1104, 1103, 2682, 5755, 6663, 2575, 12670, 142, 7255, 4119, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01998434215784073, -0.04749618098139763, -0.03232145309448242, -0.03224682807922363, -0.03224682807922363, -0.03224682807922363, -0.03224682807922363, -0.03224682807922363, -0.03224682807922363, -0.03224682807922363], "metadata": {"source_tokens": ["In", "the", "1986", "television", "series", "`", "##`", "War", "and", "Re", "##membrance", "'", "##'", ",", "Johns", "took", "the", "role", "of", "the", "senior", "Nazi", "SS", "officer", "Adolf", "E", "##ich", "##mann", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Johns", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "the", "role", "of", "the", "senior", "Nazi", "SS", "officer", "In", "the", "1986", "television", "series", "[unused6]", "[SEP]", "[unused1]", "Johns", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "the", "role", "of", "the", "senior", "Nazi", "SS", "officer", "Adolf", "E", "##ich", "##mann", "[unused6]", "[SEP]"]]}

input 164:  {"source": "In the Civil War , he advocated strong prosecution of the Union War effort , the end of slavery , and civil rights for freed African Americans .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 11971, 4, 5, 2012, 12369, 1104, 1103, 1913, 1414, 3098, 117, 1103, 1322, 1104, 9401, 117, 1105, 2987, 2266, 1111, 11485, 2170, 4038, 1130, 1103, 3145, 1414, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 11971, 4, 5, 2012, 12369, 1104, 1103, 1913, 1414, 3098, 1103, 1322, 1104, 9401, 1105, 2987, 2266, 1111, 11485, 2170, 4038, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02556597627699375, -0.04489274322986603, -0.1367497444152832, -0.14992427825927734, -0.14992427825927734, -0.14992427825927734, -0.14992427825927734, -0.14992427825927734, -0.14992427825927734, -0.14992427825927734], "metadata": {"source_tokens": ["In", "the", "Civil", "War", ",", "he", "advocated", "strong", "prosecution", "of", "the", "Union", "War", "effort", ",", "the", "end", "of", "slavery", ",", "and", "civil", "rights", "for", "freed", "African", "Americans", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "advocated", "[unused4]", "[unused5]", "strong", "prosecution", "of", "the", "Union", "War", "effort", ",", "the", "end", "of", "slavery", ",", "and", "civil", "rights", "for", "freed", "African", "Americans", "In", "the", "Civil", "War", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "advocated", "[unused4]", "[unused5]", "strong", "prosecution", "of", "the", "Union", "War", "effort", "the", "end", "of", "slavery", "and", "civil", "rights", "for", "freed", "African", "Americans", "[unused6]", "[SEP]"]]}

input 165:  {"source": "In the Crimean War , the 5th Dragoon Guards formed part of the Heavy Cavalry Brigade and was sent to the Black Sea in 1854 .\n"}
prediction:  {"predictions": [[1, 1103, 4025, 1987, 19308, 1320, 9696, 2, 3, 1824, 4, 5, 1226, 1104, 1103, 10580, 9312, 4292, 1130, 1103, 22442, 1414, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4025, 1987, 19308, 1320, 9696, 2, 3, 1108, 1850, 4, 5, 1106, 1103, 2117, 3017, 1107, 8023, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4025, 1987, 19308, 1320, 9696, 2, 3, 1108, 1850, 4, 5, 1106, 1103, 2117, 3017, 1107, 8023, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009630834683775902, -0.013805125840008259, -0.09111000597476959, -0.12442255020141602, -0.12375402450561523, -0.12375402450561523, -0.12375402450561523, -0.12375402450561523, -0.12375402450561523, -0.12375402450561523], "metadata": {"source_tokens": ["In", "the", "Crimean", "War", ",", "the", "5th", "Dr", "##ago", "##on", "Guards", "formed", "part", "of", "the", "Heavy", "Cavalry", "Brigade", "and", "was", "sent", "to", "the", "Black", "Sea", "in", "1854", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "5th", "Dr", "##ago", "##on", "Guards", "[unused2]", "[unused3]", "formed", "[unused4]", "[unused5]", "part", "of", "the", "Heavy", "Cavalry", "Brigade", "In", "the", "Crimean", "War", "[unused6]", "[SEP]", "[unused1]", "the", "5th", "Dr", "##ago", "##on", "Guards", "[unused2]", "[unused3]", "was", "sent", "[unused4]", "[unused5]", "to", "the", "Black", "Sea", "in", "1854", "[unused6]", "[SEP]", "[unused1]", "the", "5th", "Dr", "##ago", "##on", "Guards", "[unused2]", "[unused3]", "was", "sent", "[unused4]", "[unused5]", "to", "the", "Black", "Sea", "in", "1854", "[unused6]", "[SEP]"]]}

input 166:  {"source": "In the early 19th century the Welsh Methodists broke away from the Anglican church and established their own denomination , now the Presbyterian Church of Wales .\n"}
prediction:  {"predictions": [[1, 1103, 5447, 8580, 1116, 2, 3, 2795, 4, 5, 1283, 1121, 1103, 9137, 1749, 1130, 1103, 1346, 2835, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 5447, 8580, 1116, 2, 3, 1628, 4, 5, 1147, 1319, 20493, 1208, 1103, 10091, 1722, 1104, 2717, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 5447, 8580, 1116, 2, 3, 1628, 4, 5, 1147, 1319, 20493, 1130, 1103, 1346, 2835, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 5447, 8580, 1116, 2, 3, 1628, 4, 5, 1147, 1319, 20493, 1130, 1103, 1346, 2835, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 5447, 8580, 1116, 2, 3, 1628, 4, 5, 1147, 1319, 20493, 1130, 1103, 1346, 2835, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04372650012373924, -0.039271194487810135, -0.06893882155418396, -0.0731278508901596, -0.08268661797046661, -0.2123163938522339, -0.21231484413146973, -0.21231484413146973, -0.21231484413146973, -0.21231484413146973], "metadata": {"source_tokens": ["In", "the", "early", "19th", "century", "the", "Welsh", "Methodist", "##s", "broke", "away", "from", "the", "Anglican", "church", "and", "established", "their", "own", "denomination", ",", "now", "the", "Presbyterian", "Church", "of", "Wales", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Welsh", "Methodist", "##s", "[unused2]", "[unused3]", "broke", "[unused4]", "[unused5]", "away", "from", "the", "Anglican", "church", "In", "the", "early", "19th", "century", "[unused6]", "[SEP]", "[unused1]", "the", "Welsh", "Methodist", "##s", "[unused2]", "[unused3]", "established", "[unused4]", "[unused5]", "their", "own", "denomination", "now", "the", "Presbyterian", "Church", "of", "Wales", "[unused6]", "[SEP]", "[unused1]", "the", "Welsh", "Methodist", "##s", "[unused2]", "[unused3]", "established", "[unused4]", "[unused5]", "their", "own", "denomination", "In", "the", "early", "19th", "century", "[unused6]", "[SEP]", "[unused1]", "the", "Welsh", "Methodist", "##s", "[unused2]", "[unused3]", "established", "[unused4]", "[unused5]", "their", "own", "denomination", "In", "the", "early", "19th", "century", "[unused6]", "[SEP]", "[unused1]", "the", "Welsh", "Methodist", "##s", "[unused2]", "[unused3]", "established", "[unused4]", "[unused5]", "their", "own", "denomination", "In", "the", "early", "19th", "century", "[unused6]", "[SEP]"]]}

input 167:  {"source": "In the north and east inhabitants speak Bumthangkha , and in the extreme southeast Khengkha is spoken .\n"}
prediction:  {"predictions": [[1, 148, 10436, 1403, 14457, 2, 3, 1110, 4606, 4, 5, 1107, 1103, 6122, 5038, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4131, 2, 3, 2936, 4, 5, 139, 1818, 22252, 1403, 14457, 1130, 1103, 1564, 1105, 1746, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005866735242307186, -0.10288192331790924, -0.07749223709106445, -0.07680964469909668, -0.07680964469909668, -0.07680964469909668, -0.07680964469909668, -0.07680964469909668, -0.07680964469909668, -0.07680964469909668], "metadata": {"source_tokens": ["In", "the", "north", "and", "east", "inhabitants", "speak", "B", "##um", "##than", "##g", "##kha", ",", "and", "in", "the", "extreme", "southeast", "K", "##hen", "##g", "##kha", "is", "spoken", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "K", "##hen", "##g", "##kha", "[unused2]", "[unused3]", "is", "spoken", "[unused4]", "[unused5]", "in", "the", "extreme", "southeast", "[unused6]", "[SEP]", "[unused1]", "inhabitants", "[unused2]", "[unused3]", "speak", "[unused4]", "[unused5]", "B", "##um", "##than", "##g", "##kha", "In", "the", "north", "and", "east", "[unused6]", "[SEP]"]]}

input 168:  {"source": "In the winter of 1976 , Knievel was scheduled for a major jump in Chicago , Illinois .\n"}
prediction:  {"predictions": [[1, 148, 5213, 12559, 2, 3, 1108, 4533, 4, 5, 1111, 170, 1558, 5152, 1107, 2290, 1130, 1103, 3701, 1104, 2402, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 148, 5213, 12559, 2, 3, 1108, 4533, 4, 5, 1111, 170, 1558, 5152, 1107, 2290, 3461, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.003137090941891074, -0.03511706739664078, -0.07660961151123047, -0.07660579681396484, -0.07660579681396484, -0.07660579681396484, -0.07660579681396484, -0.07660579681396484, -0.07660579681396484, -0.07660579681396484], "metadata": {"source_tokens": ["In", "the", "winter", "of", "1976", ",", "K", "##nie", "##vel", "was", "scheduled", "for", "a", "major", "jump", "in", "Chicago", ",", "Illinois", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "K", "##nie", "##vel", "[unused2]", "[unused3]", "was", "scheduled", "[unused4]", "[unused5]", "for", "a", "major", "jump", "in", "Chicago", "In", "the", "winter", "of", "1976", "[unused6]", "[SEP]", "[unused1]", "K", "##nie", "##vel", "[unused2]", "[unused3]", "was", "scheduled", "[unused4]", "[unused5]", "for", "a", "major", "jump", "in", "Chicago", "Illinois", "[unused6]", "[SEP]"]]}

input 169:  {"source": "In this explanation the purpose of Creation is that `` God desired a dwelling place in the lower realms '' - it is man who transforms the mundane , lowest World into an abode for God 's essence .\n"}
prediction:  {"predictions": [[1, 1103, 3007, 1104, 19470, 2, 3, 1110, 4, 5, 1115, 169, 28152, 1875, 8759, 170, 13835, 1282, 1107, 1103, 2211, 9695, 1116, 112, 28131, 118, 1122, 1110, 1299, 1130, 1142, 7108, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1299, 2, 3, 24573, 4, 5, 1103, 182, 22902, 1673, 117, 6905, 1291, 1154, 1126, 170, 4043, 2007, 1111, 1875, 112, 1116, 12661, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1875, 2, 3, 8759, 4, 5, 170, 13835, 1282, 1107, 1103, 2211, 9695, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1299, 2, 3, 24573, 4, 5, 1103, 182, 22902, 1673, 117, 6905, 1291, 1154, 1126, 170, 4043, 2007, 1111, 1875, 112, 1116, 12661, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023524869233369827, -0.032804664224386215, -0.05805090442299843, -0.11829735338687897, -0.2122892141342163, -0.2123098373413086, -0.2123098373413086, -0.2123098373413086, -0.2123098373413086, -0.2123098373413086], "metadata": {"source_tokens": ["In", "this", "explanation", "the", "purpose", "of", "Creation", "is", "that", "`", "##`", "God", "desired", "a", "dwelling", "place", "in", "the", "lower", "realm", "##s", "'", "##'", "-", "it", "is", "man", "who", "transforms", "the", "m", "##unda", "##ne", ",", "lowest", "World", "into", "an", "a", "##bo", "##de", "for", "God", "'", "##s", "essence", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "purpose", "of", "Creation", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "that", "`", "##`", "God", "desired", "a", "dwelling", "place", "in", "the", "lower", "realm", "##s", "'", "##'", "-", "it", "is", "man", "In", "this", "explanation", "[unused6]", "[SEP]", "[unused1]", "man", "[unused2]", "[unused3]", "transforms", "[unused4]", "[unused5]", "the", "m", "##unda", "##ne", ",", "lowest", "World", "into", "an", "a", "##bo", "##de", "for", "God", "'", "##s", "essence", "[unused6]", "[SEP]", "[unused1]", "God", "[unused2]", "[unused3]", "desired", "[unused4]", "[unused5]", "a", "dwelling", "place", "in", "the", "lower", "realm", "##s", "[unused6]", "[SEP]", "[unused1]", "man", "[unused2]", "[unused3]", "transforms", "[unused4]", "[unused5]", "the", "m", "##unda", "##ne", ",", "lowest", "World", "into", "an", "a", "##bo", "##de", "for", "God", "'", "##s", "essence", "[unused6]", "[SEP]"]]}

input 170:  {"source": "In those years , he began to collaborate with some newspapers .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1310, 4, 5, 1106, 23200, 1114, 1199, 6195, 1130, 1343, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005736687686294317, -0.07592391967773438, -0.07592463493347168, -0.07592463493347168, -0.07592463493347168, -0.07592463493347168, -0.07592463493347168, -0.07592463493347168, -0.07592463493347168, -0.07592463493347168], "metadata": {"source_tokens": ["In", "those", "years", ",", "he", "began", "to", "collaborate", "with", "some", "newspapers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "to", "collaborate", "with", "some", "newspapers", "In", "those", "years", "[unused6]", "[SEP]"]]}

input 171:  {"source": "Initially flying the A-4B Skyhawk , the squadron later transitioned to the A-4L Skyhawk .\n"}
prediction:  {"predictions": [[1, 1103, 5780, 2, 3, 26974, 4, 5, 1106, 1103, 138, 28137, 1527, 2162, 5751, 19952, 7245, 3754, 1103, 138, 28137, 1527, 2064, 5751, 19952, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 5780, 2, 3, 26974, 4, 5, 1106, 1103, 138, 28137, 1527, 2162, 5751, 19952, 7245, 3754, 1103, 138, 28137, 1527, 2064, 5751, 19952, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0023645933251827955, -0.044667668640613556, -0.07640504837036133, -0.0764007568359375, -0.0764007568359375, -0.0764007568359375, -0.0764007568359375, -0.0764007568359375, -0.0764007568359375, -0.0764007568359375], "metadata": {"source_tokens": ["Initially", "flying", "the", "A", "##-", "##4", "##B", "Sky", "##hawk", ",", "the", "squadron", "later", "transitioned", "to", "the", "A", "##-", "##4", "##L", "Sky", "##hawk", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "squadron", "[unused2]", "[unused3]", "transitioned", "[unused4]", "[unused5]", "to", "the", "A", "##-", "##4", "##L", "Sky", "##hawk", "Initially", "flying", "the", "A", "##-", "##4", "##B", "Sky", "##hawk", "later", "[unused6]", "[SEP]", "[unused1]", "the", "squadron", "[unused2]", "[unused3]", "transitioned", "[unused4]", "[unused5]", "to", "the", "A", "##-", "##4", "##L", "Sky", "##hawk", "Initially", "flying", "the", "A", "##-", "##4", "##B", "Sky", "##hawk", "[unused6]", "[SEP]"]]}

input 172:  {"source": "Initially his chances of surviving were thought to be no better than 50-50 .\n"}
prediction:  {"predictions": [[1, 1117, 9820, 1104, 5932, 2, 3, 1106, 1129, 4, 5, 1185, 1618, 1190, 1851, 28137, 11049, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 9820, 1104, 5932, 2, 3, 1127, 1354, 4, 5, 7245, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.029678545892238617, -0.034493956714868546, -0.032296180725097656, -0.03228044509887695, -0.03228044509887695, -0.03228044509887695, -0.03228044509887695, -0.03228044509887695, -0.03228044509887695, -0.03228044509887695], "metadata": {"source_tokens": ["Initially", "his", "chances", "of", "surviving", "were", "thought", "to", "be", "no", "better", "than", "50", "##-", "##50", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "his", "chances", "of", "surviving", "[unused2]", "[unused3]", "to", "be", "[unused4]", "[unused5]", "no", "better", "than", "50", "##-", "##50", "[unused6]", "[SEP]", "[unused1]", "his", "chances", "of", "surviving", "[unused2]", "[unused3]", "were", "thought", "[unused4]", "[unused5]", "Initially", "[unused6]", "[SEP]"]]}

input 173:  {"source": "It has long hind legs and a long , slender , scaly tail that it uses to communicate by making drumming noises .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1144, 4, 5, 1263, 24856, 2584, 1105, 170, 1263, 117, 11226, 117, 188, 7867, 1183, 5287, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1263, 117, 11226, 117, 188, 7867, 1183, 5287, 2, 3, 2745, 4, 5, 1106, 10621, 1118, 1543, 27025, 16256, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007060955744236708, -0.029946129769086838, -0.07632064819335938, -0.07631850242614746, -0.07631850242614746, -0.07631850242614746, -0.07631850242614746, -0.07631850242614746, -0.07631850242614746, -0.07631850242614746], "metadata": {"source_tokens": ["It", "has", "long", "hind", "legs", "and", "a", "long", ",", "slender", ",", "s", "##cal", "##y", "tail", "that", "it", "uses", "to", "communicate", "by", "making", "drumming", "noises", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "long", "hind", "legs", "and", "a", "long", ",", "slender", ",", "s", "##cal", "##y", "tail", "[unused6]", "[SEP]", "[unused1]", "a", "long", ",", "slender", ",", "s", "##cal", "##y", "tail", "[unused2]", "[unused3]", "uses", "[unused4]", "[unused5]", "to", "communicate", "by", "making", "drumming", "noises", "[unused6]", "[SEP]"]]}

input 174:  {"source": "It is essentially the same as the dialect spoken in Xiamen , and is unintelligible with Standard Chinese .\n"}
prediction:  {"predictions": [[1, 1103, 9222, 2, 3, 4606, 4, 5, 1107, 20802, 16470, 1179, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1110, 4, 5, 7588, 1103, 1269, 1112, 1103, 9222, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1110, 4, 5, 8362, 10879, 12164, 12192, 1114, 6433, 1922, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014543167315423489, -0.0822627991437912, -0.043809615075588226, -0.038726806640625, -0.03879880905151367, -0.03879880905151367, -0.03879880905151367, -0.03879880905151367, -0.03879880905151367, -0.03879880905151367], "metadata": {"source_tokens": ["It", "is", "essentially", "the", "same", "as", "the", "dialect", "spoken", "in", "Xi", "##ame", "##n", ",", "and", "is", "un", "##int", "##elli", "##gible", "with", "Standard", "Chinese", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "dialect", "[unused2]", "[unused3]", "spoken", "[unused4]", "[unused5]", "in", "Xi", "##ame", "##n", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "essentially", "the", "same", "as", "the", "dialect", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "un", "##int", "##elli", "##gible", "with", "Standard", "Chinese", "[unused6]", "[SEP]"]]}

input 175:  {"source": "It is not really passable , and must be done on foot if attempted .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1110, 1136, 4, 5, 1541, 2789, 1895, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1538, 1129, 1694, 4, 5, 1113, 2555, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1538, 1129, 1694, 4, 5, 1113, 2555, 1191, 3867, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02781967632472515, -0.046630777418613434, -0.07187966257333755, -0.038543701171875, -0.038575172424316406, -0.038575172424316406, -0.038575172424316406, -0.038575172424316406, -0.038575172424316406, -0.038575172424316406], "metadata": {"source_tokens": ["It", "is", "not", "really", "pass", "##able", ",", "and", "must", "be", "done", "on", "foot", "if", "attempted", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "is", "not", "[unused4]", "[unused5]", "really", "pass", "##able", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "must", "be", "done", "[unused4]", "[unused5]", "on", "foot", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "must", "be", "done", "[unused4]", "[unused5]", "on", "foot", "if", "attempted", "[unused6]", "[SEP]"]]}

input 176:  {"source": "It is part of the Surrey Hills Area of Outstanding Beauty and situated on the Green Sand Way .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1110, 4, 5, 1226, 1104, 1103, 9757, 5377, 3894, 1104, 7196, 10764, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 3629, 4, 5, 1113, 1103, 2565, 16377, 4714, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0018931494560092688, -0.04077482223510742, -0.0002765655517578125, -0.00027751922607421875, -0.00027751922607421875, -0.00027751922607421875, -0.00027751922607421875, -0.00027751922607421875, -0.00027751922607421875, -0.00027751922607421875], "metadata": {"source_tokens": ["It", "is", "part", "of", "the", "Surrey", "Hills", "Area", "of", "Outstanding", "Beauty", "and", "situated", "on", "the", "Green", "Sand", "Way", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "part", "of", "the", "Surrey", "Hills", "Area", "of", "Outstanding", "Beauty", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "situated", "[unused4]", "[unused5]", "on", "the", "Green", "Sand", "Way", "[unused6]", "[SEP]"]]}

input 177:  {"source": "It should be noted that these numbers are inclusive of any of the childminders own children .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1431, 1129, 2382, 4, 5, 1115, 1292, 2849, 1132, 21783, 1104, 1251, 1104, 1103, 2027, 22448, 1468, 1319, 1482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1292, 2849, 2, 3, 1132, 4, 5, 21783, 1104, 1251, 1104, 1103, 2027, 22448, 1468, 1319, 1482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005553289782255888, -0.023841118440032005, -0.0002751350402832031, -0.0002751350402832031, -0.0002751350402832031, -0.0002751350402832031, -0.0002751350402832031, -0.0002751350402832031, -0.0002751350402832031, -0.0002751350402832031], "metadata": {"source_tokens": ["It", "should", "be", "noted", "that", "these", "numbers", "are", "inclusive", "of", "any", "of", "the", "child", "##mind", "##ers", "own", "children", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "should", "be", "noted", "[unused4]", "[unused5]", "that", "these", "numbers", "are", "inclusive", "of", "any", "of", "the", "child", "##mind", "##ers", "own", "children", "[unused6]", "[SEP]", "[unused1]", "these", "numbers", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "inclusive", "of", "any", "of", "the", "child", "##mind", "##ers", "own", "children", "[unused6]", "[SEP]"]]}

input 178:  {"source": "It was chosen in 1901 because it was a triangulation station at the junction of the trancontinental triangulation arc of 1899 on the 39th parallel north and the triangulation arc along the 98th meridian west that was near the geographic center of the contiguous United States .\n"}
prediction:  {"predictions": [[1, 1103, 5103, 1582, 1143, 10132, 1811, 1745, 2, 3, 1108, 4, 5, 1485, 1103, 13351, 2057, 1104, 1103, 14255, 3121, 22928, 1244, 1311, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1108, 3468, 4, 5, 1107, 5064, 1272, 1122, 1108, 170, 189, 5476, 13830, 6840, 1466, 1120, 1103, 6698, 1104, 1103, 189, 4047, 25442, 1348, 189, 5476, 13830, 6840, 10591, 1104, 5493, 1113, 1103, 25235, 5504, 1564, 1105, 1103, 189, 5476, 13830, 6840, 10591, 1373, 1103, 5103, 102, 1, 1122, 2, 3, 1108, 4, 5, 170, 189, 5476, 13830, 6840, 1466, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 170, 189, 5476, 13830, 6840, 1466, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 170, 189, 5476, 13830, 6840, 1466, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 170, 189, 5476, 13830, 6840, 1466, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 170, 189, 5476, 13830, 6840, 1466, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 170, 189, 5476, 13830, 6840, 1466, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 170, 189, 5476, 13830, 6840, 1466, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 170, 189, 5476, 13830, 6840, 1466, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005405580159276724, -0.02039378322660923, -0.08615630120038986, -0.12563128769397736, -0.12622033059597015, -0.15256929397583008, -0.15072010457515717, -0.14268510043621063, -0.15006880462169647, -0.1557392030954361], "metadata": {"source_tokens": ["It", "was", "chosen", "in", "1901", "because", "it", "was", "a", "t", "##rian", "##gu", "##lation", "station", "at", "the", "junction", "of", "the", "t", "##ran", "##continent", "##al", "t", "##rian", "##gu", "##lation", "arc", "of", "1899", "on", "the", "39th", "parallel", "north", "and", "the", "t", "##rian", "##gu", "##lation", "arc", "along", "the", "98", "##th", "me", "##rid", "##ian", "west", "that", "was", "near", "the", "geographic", "center", "of", "the", "con", "##ti", "##guous", "United", "States", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "98", "##th", "me", "##rid", "##ian", "west", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "near", "the", "geographic", "center", "of", "the", "con", "##ti", "##guous", "United", "States", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "was", "chosen", "[unused4]", "[unused5]", "in", "1901", "because", "it", "was", "a", "t", "##rian", "##gu", "##lation", "station", "at", "the", "junction", "of", "the", "t", "##ran", "##continent", "##al", "t", "##rian", "##gu", "##lation", "arc", "of", "1899", "on", "the", "39th", "parallel", "north", "and", "the", "t", "##rian", "##gu", "##lation", "arc", "along", "the", "98", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "t", "##rian", "##gu", "##lation", "station", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "t", "##rian", "##gu", "##lation", "station", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "t", "##rian", "##gu", "##lation", "station", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "t", "##rian", "##gu", "##lation", "station", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "t", "##rian", "##gu", "##lation", "station", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "t", "##rian", "##gu", "##lation", "station", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "t", "##rian", "##gu", "##lation", "station", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "t", "##rian", "##gu", "##lation", "station", "[unused6]", "[SEP]"]]}

input 179:  {"source": "It was named for Gen. Eleazer Wheelock Ripley , an officer in the War of 1812 , who was mainly remembered for the Battle of Lundy 's Lane and the Siege of Fort Erie , in 1814 .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1108, 1417, 4, 5, 1111, 9198, 28138, 2896, 4490, 6198, 19754, 5559, 155, 9717, 1926, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9198, 28138, 2896, 4490, 6198, 19754, 5559, 155, 9717, 1926, 2, 3, 1108, 2871, 3801, 4, 5, 1111, 1103, 2651, 1104, 24232, 1183, 112, 1116, 5319, 1105, 1103, 14214, 1104, 3144, 13717, 1107, 10943, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9198, 28138, 2896, 4490, 6198, 19754, 5559, 155, 9717, 1926, 2, 3, 1110, 1126, 2575, 1107, 4, 5, 1103, 1414, 1104, 9601, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013697703368961811, -0.027976667508482933, -0.01872939057648182, -0.12366199493408203, -0.1236107349395752, -0.1236107349395752, -0.1236107349395752, -0.1236107349395752, -0.1236107349395752, -0.1236107349395752], "metadata": {"source_tokens": ["It", "was", "named", "for", "Gen", "##.", "El", "##ea", "##zer", "Wheel", "##ock", "R", "##ip", "##ley", ",", "an", "officer", "in", "the", "War", "of", "1812", ",", "who", "was", "mainly", "remembered", "for", "the", "Battle", "of", "Lund", "##y", "'", "##s", "Lane", "and", "the", "Siege", "of", "Fort", "Erie", ",", "in", "1814", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "was", "named", "[unused4]", "[unused5]", "for", "Gen", "##.", "El", "##ea", "##zer", "Wheel", "##ock", "R", "##ip", "##ley", "[unused6]", "[SEP]", "[unused1]", "Gen", "##.", "El", "##ea", "##zer", "Wheel", "##ock", "R", "##ip", "##ley", "[unused2]", "[unused3]", "was", "mainly", "remembered", "[unused4]", "[unused5]", "for", "the", "Battle", "of", "Lund", "##y", "'", "##s", "Lane", "and", "the", "Siege", "of", "Fort", "Erie", "in", "1814", "[unused6]", "[SEP]", "[unused1]", "Gen", "##.", "El", "##ea", "##zer", "Wheel", "##ock", "R", "##ip", "##ley", "[unused2]", "[unused3]", "is", "an", "officer", "in", "[unused4]", "[unused5]", "the", "War", "of", "1812", "[unused6]", "[SEP]"]]}

input 180:  {"source": "It was originally aimed at mature entrants to the teaching profession , who could not afford to give up work and undertake a traditional method of teacher training such as the PGCE .\n"}
prediction:  {"predictions": [[1, 1103, 3679, 9545, 2, 3, 1180, 1136, 8658, 4, 5, 1106, 1660, 1146, 1250, 1105, 17778, 170, 2361, 3442, 1104, 3218, 2013, 1216, 1112, 1103, 153, 13478, 2036, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1108, 5850, 4, 5, 1120, 9881, 4035, 4487, 5240, 1106, 1103, 3679, 9545, 2034, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3679, 9545, 2, 3, 1180, 1136, 8658, 4, 5, 1106, 17778, 170, 2361, 3442, 1104, 3218, 2013, 1216, 1112, 1103, 153, 13478, 2036, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03513060882687569, -0.02304009720683098, -0.041597623378038406, -0.21200084686279297, -0.21489441394805908, -0.21489441394805908, -0.21489441394805908, -0.21489441394805908, -0.21489441394805908, -0.21489441394805908], "metadata": {"source_tokens": ["It", "was", "originally", "aimed", "at", "mature", "en", "##tra", "##nts", "to", "the", "teaching", "profession", ",", "who", "could", "not", "afford", "to", "give", "up", "work", "and", "undertake", "a", "traditional", "method", "of", "teacher", "training", "such", "as", "the", "P", "##GC", "##E", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "teaching", "profession", "[unused2]", "[unused3]", "could", "not", "afford", "[unused4]", "[unused5]", "to", "give", "up", "work", "and", "undertake", "a", "traditional", "method", "of", "teacher", "training", "such", "as", "the", "P", "##GC", "##E", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "was", "aimed", "[unused4]", "[unused5]", "at", "mature", "en", "##tra", "##nts", "to", "the", "teaching", "profession", "originally", "[unused6]", "[SEP]", "[unused1]", "the", "teaching", "profession", "[unused2]", "[unused3]", "could", "not", "afford", "[unused4]", "[unused5]", "to", "undertake", "a", "traditional", "method", "of", "teacher", "training", "such", "as", "the", "P", "##GC", "##E", "[unused6]", "[SEP]"]]}

input 181:  {"source": "Its cultivation even declined in favour of the Asian species , which was introduced to East Africa early in the common era and spread westward .\n"}
prediction:  {"predictions": [[1, 2098, 13958, 2, 3, 1256, 5799, 4, 5, 1107, 7511, 1104, 1103, 3141, 1530, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3141, 1530, 2, 3, 1108, 2234, 4, 5, 1106, 1689, 2201, 1346, 1107, 1103, 1887, 3386, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3141, 1530, 2, 3, 2819, 17222, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.045404769480228424, -0.02020508423447609, -0.08023019880056381, -0.032205820083618164, -0.032204389572143555, -0.032204389572143555, -0.032204389572143555, -0.032204389572143555, -0.032204389572143555, -0.032204389572143555], "metadata": {"source_tokens": ["Its", "cultivation", "even", "declined", "in", "favour", "of", "the", "Asian", "species", ",", "which", "was", "introduced", "to", "East", "Africa", "early", "in", "the", "common", "era", "and", "spread", "westward", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Its", "cultivation", "[unused2]", "[unused3]", "even", "declined", "[unused4]", "[unused5]", "in", "favour", "of", "the", "Asian", "species", "[unused6]", "[SEP]", "[unused1]", "the", "Asian", "species", "[unused2]", "[unused3]", "was", "introduced", "[unused4]", "[unused5]", "to", "East", "Africa", "early", "in", "the", "common", "era", "[unused6]", "[SEP]", "[unused1]", "the", "Asian", "species", "[unused2]", "[unused3]", "spread", "westward", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 182:  {"source": "JAL introduced jet service on the Fukuoka-Tokyo route in 1961 .\n"}
prediction:  {"predictions": [[1, 147, 12507, 2, 3, 2234, 4, 5, 8319, 1555, 1113, 1103, 14763, 4786, 9865, 28137, 1942, 5926, 7490, 2438, 1107, 2920, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00026047229766845703, -0.07613277435302734, -0.07612133026123047, -0.07612133026123047, -0.07612133026123047, -0.07612133026123047, -0.07612133026123047, -0.07612133026123047, -0.07612133026123047, -0.07612133026123047], "metadata": {"source_tokens": ["J", "##AL", "introduced", "jet", "service", "on", "the", "Fu", "##ku", "##oka", "##-", "##T", "##ok", "##yo", "route", "in", "1961", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "J", "##AL", "[unused2]", "[unused3]", "introduced", "[unused4]", "[unused5]", "jet", "service", "on", "the", "Fu", "##ku", "##oka", "##-", "##T", "##ok", "##yo", "route", "in", "1961", "[unused6]", "[SEP]"]]}

input 183:  {"source": "James Arthur Hogue is a US impostor who most famously entered Princeton University by posing as a self-taught orphan .\n"}
prediction:  {"predictions": [[1, 1600, 3456, 9800, 7222, 2, 3, 1110, 4, 5, 170, 1646, 24034, 15540, 1766, 1150, 1211, 20025, 2242, 8845, 1239, 1118, 23614, 1112, 170, 2191, 28137, 1777, 11266, 25298, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1646, 24034, 15540, 1766, 2, 3, 1211, 20025, 2242, 4, 5, 8845, 1239, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1646, 24034, 15540, 1766, 2, 3, 2242, 4, 5, 8845, 1239, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014921117573976517, -0.006733348127454519, -0.10726185142993927, -0.295428991317749, -0.2412424087524414, -0.2412424087524414, -0.2412424087524414, -0.2412424087524414, -0.2412424087524414, -0.2412424087524414], "metadata": {"source_tokens": ["James", "Arthur", "Ho", "##gue", "is", "a", "US", "imp", "##ost", "##or", "who", "most", "famously", "entered", "Princeton", "University", "by", "posing", "as", "a", "self", "##-", "##ta", "##ught", "orphan", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "James", "Arthur", "Ho", "##gue", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "US", "imp", "##ost", "##or", "who", "most", "famously", "entered", "Princeton", "University", "by", "posing", "as", "a", "self", "##-", "##ta", "##ught", "orphan", "[unused6]", "[SEP]", "[unused1]", "a", "US", "imp", "##ost", "##or", "[unused2]", "[unused3]", "most", "famously", "entered", "[unused4]", "[unused5]", "Princeton", "University", "[unused6]", "[SEP]", "[unused1]", "a", "US", "imp", "##ost", "##or", "[unused2]", "[unused3]", "entered", "[unused4]", "[unused5]", "Princeton", "University", "[unused6]", "[SEP]"]]}

input 184:  {"source": "John Stewart and Guy Gardner brought down New Warworld and the Yellow Central Power Battery , which were detonated next to the Anti-Monitor , and contained by a shield created by hundreds of Green Lanterns to contain the explosion ; even this was not enough to kill him .\n"}
prediction:  {"predictions": [[1, 1287, 5272, 1105, 6173, 11817, 2, 3, 1814, 1205, 4, 5, 1203, 1414, 13070, 1105, 1103, 8278, 1970, 3794, 11537, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 7292, 2, 3, 1687, 4, 5, 1118, 5229, 1104, 2565, 23999, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 8278, 1970, 3794, 11537, 2, 3, 1127, 1260, 1633, 2913, 4, 5, 1397, 1106, 1103, 8329, 28137, 2107, 11153, 2772, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1256, 1142, 2, 3, 1108, 1136, 4, 5, 1536, 1106, 2311, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1287, 5272, 1105, 6173, 11817, 2, 3, 1814, 1205, 4, 5, 1203, 1414, 13070, 1105, 1103, 8278, 1970, 3794, 11537, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1287, 5272, 1105, 6173, 11817, 2, 3, 1814, 1205, 4, 5, 1203, 1414, 13070, 1105, 1103, 8278, 1970, 3794, 11537, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1287, 5272, 1105, 6173, 11817, 2, 3, 1814, 1205, 4, 5, 1203, 1414, 13070, 1105, 1103, 8278, 1970, 3794, 11537, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1287, 5272, 1105, 6173, 11817, 2, 3, 1814, 1205, 4, 5, 1203, 1414, 13070, 1105, 1103, 8278, 1970, 3794, 11537, 6, 102, 102, 1, 1287, 5272, 1105, 6173, 11817, 2, 3, 1814, 1205, 4, 5, 1203, 1414, 13070, 1105, 1103, 8278, 1970, 3794, 11537, 6, 102, 102, 1, 1287, 5272, 1105, 6173, 11817, 2, 3, 1814, 1205, 4, 5, 1203, 1414, 13070, 1105, 1103, 8278, 1970, 3794, 11537, 6, 102, 102]], "predicted_log_probs": [-0.04968111589550972, -0.05050315707921982, -0.04797251895070076, -0.07011115550994873, -0.07349095493555069, -0.08504656702280045, -0.1027880534529686, -0.10792180895805359, -0.11358750611543655, -0.11873253434896469], "metadata": {"source_tokens": ["John", "Stewart", "and", "Guy", "Gardner", "brought", "down", "New", "War", "##world", "and", "the", "Yellow", "Central", "Power", "Battery", ",", "which", "were", "de", "##ton", "##ated", "next", "to", "the", "Anti", "##-", "##M", "##oni", "##tor", ",", "and", "contained", "by", "a", "shield", "created", "by", "hundreds", "of", "Green", "Lantern", "##s", "to", "contain", "the", "explosion", ";", "even", "this", "was", "not", "enough", "to", "kill", "him", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "John", "Stewart", "and", "Guy", "Gardner", "[unused2]", "[unused3]", "brought", "down", "[unused4]", "[unused5]", "New", "War", "##world", "and", "the", "Yellow", "Central", "Power", "Battery", "[unused6]", "[SEP]", "[unused1]", "a", "shield", "[unused2]", "[unused3]", "created", "[unused4]", "[unused5]", "by", "hundreds", "of", "Green", "Lantern", "##s", "[unused6]", "[SEP]", "[unused1]", "the", "Yellow", "Central", "Power", "Battery", "[unused2]", "[unused3]", "were", "de", "##ton", "##ated", "[unused4]", "[unused5]", "next", "to", "the", "Anti", "##-", "##M", "##oni", "##tor", "[unused6]", "[SEP]", "[unused1]", "even", "this", "[unused2]", "[unused3]", "was", "not", "[unused4]", "[unused5]", "enough", "to", "kill", "him", "[unused6]", "[SEP]", "[unused1]", "John", "Stewart", "and", "Guy", "Gardner", "[unused2]", "[unused3]", "brought", "down", "[unused4]", "[unused5]", "New", "War", "##world", "and", "the", "Yellow", "Central", "Power", "Battery", "[unused6]", "[SEP]", "[unused1]", "John", "Stewart", "and", "Guy", "Gardner", "[unused2]", "[unused3]", "brought", "down", "[unused4]", "[unused5]", "New", "War", "##world", "and", "the", "Yellow", "Central", "Power", "Battery", "[unused6]", "[SEP]", "[unused1]", "John", "Stewart", "and", "Guy", "Gardner", "[unused2]", "[unused3]", "brought", "down", "[unused4]", "[unused5]", "New", "War", "##world", "and", "the", "Yellow", "Central", "Power", "Battery", "[unused6]", "[SEP]", "[unused1]", "John", "Stewart", "and", "Guy", "Gardner", "[unused2]", "[unused3]", "brought", "down", "[unused4]", "[unused5]", "New", "War", "##world", "and", "the", "Yellow", "Central", "Power", "Battery", "[unused6]", "[SEP]", "[unused1]", "John", "Stewart", "and", "Guy", "Gardner", "[unused2]", "[unused3]", "brought", "down", "[unused4]", "[unused5]", "New", "War", "##world", "and", "the", "Yellow", "Central", "Power", "Battery", "[unused6]", "[SEP]", "[unused1]", "John", "Stewart", "and", "Guy", "Gardner", "[unused2]", "[unused3]", "brought", "down", "[unused4]", "[unused5]", "New", "War", "##world", "and", "the", "Yellow", "Central", "Power", "Battery", "[unused6]", "[SEP]"]]}

input 185:  {"source": "Johns also appeared as an Imperial Officer in the 1980 `` Star Wars sequel '' , `` The Empire Strikes Back '' .\n"}
prediction:  {"predictions": [[1, 11673, 2, 3, 1691, 4, 5, 1112, 1126, 4849, 4124, 1107, 1103, 2253, 169, 28152, 2537, 6238, 8047, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2813, 2, 3, 15425, 1116, 4388, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03269423916935921, -0.08721127361059189, -0.032198429107666016, -0.032198429107666016, -0.032198429107666016, -0.032198429107666016, -0.032198429107666016, -0.032198429107666016, -0.032198429107666016, -0.032198429107666016], "metadata": {"source_tokens": ["Johns", "also", "appeared", "as", "an", "Imperial", "Officer", "in", "the", "1980", "`", "##`", "Star", "Wars", "sequel", "'", "##'", ",", "`", "##`", "The", "Empire", "Strike", "##s", "Back", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Johns", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "as", "an", "Imperial", "Officer", "in", "the", "1980", "`", "##`", "Star", "Wars", "sequel", "[unused6]", "[SEP]", "[unused1]", "The", "Empire", "[unused2]", "[unused3]", "Strike", "##s", "Back", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 186:  {"source": "Keats 's long and expensive medical training with Hammond and at Guy 's Hospital led his family to assume he would pursue a lifelong career in medicine , assuring financial security , and it seems that at this point Keats had a genuine desire to become a doctor .\n"}
prediction:  {"predictions": [[1, 26835, 9971, 112, 1116, 1263, 1105, 5865, 2657, 2013, 1114, 11425, 1105, 1120, 6173, 112, 1116, 3355, 2, 3, 1521, 4, 5, 1117, 1266, 1106, 7568, 1119, 1156, 6799, 170, 14497, 1578, 1107, 5182, 117, 3919, 6660, 2798, 2699, 117, 1105, 1122, 3093, 1115, 1120, 1142, 1553, 6, 102, 102, 1, 26835, 9971, 2, 3, 1125, 4, 5, 170, 10416, 4232, 1106, 1561, 170, 3995, 1120, 1142, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 9971, 2, 3, 1125, 4, 5, 170, 10416, 4232, 1106, 1561, 170, 3995, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 9971, 112, 1116, 1263, 1105, 5865, 2657, 2013, 1114, 11425, 1105, 1120, 6173, 112, 1116, 3355, 2, 3, 1521, 4, 5, 1117, 1266, 1106, 7568, 1119, 1156, 6799, 170, 14497, 1578, 1107, 5182, 3919, 6660, 2798, 2699, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 9971, 112, 1116, 1263, 1105, 5865, 2657, 2013, 1114, 11425, 1105, 1120, 6173, 112, 1116, 3355, 2, 3, 1521, 4, 5, 1117, 1266, 1106, 7568, 1119, 1156, 6799, 170, 14497, 1578, 1107, 5182, 3919, 6660, 2798, 2699, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 9971, 2, 3, 1125, 4, 5, 170, 10416, 4232, 1106, 1561, 170, 3995, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 9971, 112, 1116, 1263, 1105, 5865, 2657, 2013, 1114, 11425, 1105, 1120, 6173, 112, 1116, 3355, 2, 3, 1521, 4, 5, 1117, 1266, 1106, 7568, 1119, 1156, 6799, 170, 14497, 1578, 1107, 5182, 3919, 6660, 2798, 2699, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03884294256567955, -0.03994737192988396, -0.1310761719942093, -0.07489395886659622, -0.09154260158538818, -0.18994012475013733, -0.10406320542097092, -0.31244826316833496, -0.312636137008667, -0.312636137008667], "metadata": {"source_tokens": ["Ke", "##ats", "'", "##s", "long", "and", "expensive", "medical", "training", "with", "Hammond", "and", "at", "Guy", "'", "##s", "Hospital", "led", "his", "family", "to", "assume", "he", "would", "pursue", "a", "lifelong", "career", "in", "medicine", ",", "ass", "##uring", "financial", "security", ",", "and", "it", "seems", "that", "at", "this", "point", "Ke", "##ats", "had", "a", "genuine", "desire", "to", "become", "a", "doctor", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ke", "##ats", "'", "##s", "long", "and", "expensive", "medical", "training", "with", "Hammond", "and", "at", "Guy", "'", "##s", "Hospital", "[unused2]", "[unused3]", "led", "[unused4]", "[unused5]", "his", "family", "to", "assume", "he", "would", "pursue", "a", "lifelong", "career", "in", "medicine", ",", "ass", "##uring", "financial", "security", ",", "and", "it", "seems", "that", "at", "this", "point", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ats", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "genuine", "desire", "to", "become", "a", "doctor", "at", "this", "point", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ats", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "genuine", "desire", "to", "become", "a", "doctor", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ats", "'", "##s", "long", "and", "expensive", "medical", "training", "with", "Hammond", "and", "at", "Guy", "'", "##s", "Hospital", "[unused2]", "[unused3]", "led", "[unused4]", "[unused5]", "his", "family", "to", "assume", "he", "would", "pursue", "a", "lifelong", "career", "in", "medicine", "ass", "##uring", "financial", "security", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ats", "'", "##s", "long", "and", "expensive", "medical", "training", "with", "Hammond", "and", "at", "Guy", "'", "##s", "Hospital", "[unused2]", "[unused3]", "led", "[unused4]", "[unused5]", "his", "family", "to", "assume", "he", "would", "pursue", "a", "lifelong", "career", "in", "medicine", "ass", "##uring", "financial", "security", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ats", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "genuine", "desire", "to", "become", "a", "doctor", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ats", "'", "##s", "long", "and", "expensive", "medical", "training", "with", "Hammond", "and", "at", "Guy", "'", "##s", "Hospital", "[unused2]", "[unused3]", "led", "[unused4]", "[unused5]", "his", "family", "to", "assume", "he", "would", "pursue", "a", "lifelong", "career", "in", "medicine", "ass", "##uring", "financial", "security", "[unused6]", "[SEP]"]]}

input 187:  {"source": "Keibler then asked for time off to appear on `` Dancing with the Stars '' .\n"}
prediction:  {"predictions": [[1, 26835, 5225, 1197, 2, 3, 1455, 4, 5, 1111, 1159, 1228, 1106, 2845, 1113, 169, 28152, 13234, 1114, 1103, 6200, 1173, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 5225, 1197, 2, 3, 1455, 4, 5, 1111, 1159, 1106, 2845, 1113, 13234, 1114, 1103, 6200, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.018194863572716713, -0.08894060552120209, -0.07799243927001953, -0.07895946502685547, -0.07895946502685547, -0.07895946502685547, -0.07895946502685547, -0.07895946502685547, -0.07895946502685547, -0.07895946502685547], "metadata": {"source_tokens": ["Ke", "##ible", "##r", "then", "asked", "for", "time", "off", "to", "appear", "on", "`", "##`", "Dancing", "with", "the", "Stars", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ke", "##ible", "##r", "[unused2]", "[unused3]", "asked", "[unused4]", "[unused5]", "for", "time", "off", "to", "appear", "on", "`", "##`", "Dancing", "with", "the", "Stars", "then", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ible", "##r", "[unused2]", "[unused3]", "asked", "[unused4]", "[unused5]", "for", "time", "to", "appear", "on", "Dancing", "with", "the", "Stars", "[unused6]", "[SEP]"]]}

input 188:  {"source": "Kim graduated from Ballard High School in Louisville , Kentucky , in 1989 and from Oberlin College in Ohio in 1993 where he double-majored in Government and English and played for the varsity lacrosse team .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 2702, 28137, 1918, 5077, 4359, 4, 5, 1107, 2384, 1105, 1483, 1949, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4246, 2, 3, 3024, 4, 5, 1121, 24241, 1693, 1323, 1107, 11595, 1107, 2056, 1105, 1121, 152, 3169, 2836, 1531, 1107, 3197, 1107, 1949, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1307, 4, 5, 1111, 1103, 17611, 21135, 1264, 1949, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.12918256223201752, -0.07715057581663132, -0.06798195838928223, -0.34349584579467773, -0.2883260250091553, -0.2883260250091553, -0.2883260250091553, -0.2883260250091553, -0.2883260250091553, -0.2883260250091553], "metadata": {"source_tokens": ["Kim", "graduated", "from", "Ballard", "High", "School", "in", "Louisville", ",", "Kentucky", ",", "in", "1989", "and", "from", "O", "##ber", "##lin", "College", "in", "Ohio", "in", "1993", "where", "he", "double", "##-", "##ma", "##jo", "##red", "in", "Government", "and", "English", "and", "played", "for", "the", "varsity", "lacrosse", "team", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "double", "##-", "##ma", "##jo", "##red", "[unused4]", "[unused5]", "in", "Government", "and", "English", "1993", "[unused6]", "[SEP]", "[unused1]", "Kim", "[unused2]", "[unused3]", "graduated", "[unused4]", "[unused5]", "from", "Ballard", "High", "School", "in", "Louisville", "in", "1989", "and", "from", "O", "##ber", "##lin", "College", "in", "Ohio", "in", "1993", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "for", "the", "varsity", "lacrosse", "team", "1993", "[unused6]", "[SEP]"]]}

input 189:  {"source": "Kostabi 's other releases include : `` Songs For Sumera '' , `` New Alliance '' and `` The Spectre Of Modernism '' .\n"}
prediction:  {"predictions": [[1, 19892, 8419, 5567, 112, 1116, 1168, 6596, 2, 3, 1511, 4, 5, 6080, 1370, 15463, 4027, 1161, 112, 28131, 117, 169, 28152, 1203, 5643, 112, 28131, 1105, 169, 28152, 1109, 156, 26426, 1874, 2096, 4825, 1863, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.011500501073896885, -0.03856182098388672, -0.038562774658203125, -0.038562774658203125, -0.038562774658203125, -0.038562774658203125, -0.038562774658203125, -0.038562774658203125, -0.038562774658203125, -0.038562774658203125], "metadata": {"source_tokens": ["Ko", "##sta", "##bi", "'", "##s", "other", "releases", "include", ":", "`", "##`", "Songs", "For", "Su", "##mer", "##a", "'", "##'", ",", "`", "##`", "New", "Alliance", "'", "##'", "and", "`", "##`", "The", "S", "##pect", "##re", "Of", "Modern", "##ism", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ko", "##sta", "##bi", "'", "##s", "other", "releases", "[unused2]", "[unused3]", "include", "[unused4]", "[unused5]", "Songs", "For", "Su", "##mer", "##a", "'", "##'", ",", "`", "##`", "New", "Alliance", "'", "##'", "and", "`", "##`", "The", "S", "##pect", "##re", "Of", "Modern", "##ism", "[unused6]", "[SEP]"]]}

input 190:  {"source": "Langford kept Walcott at a distance with his longer reach and used his footwork to evade all of Walcott 's attacks .\n"}
prediction:  {"predictions": [[1, 12431, 2821, 2, 3, 2023, 4, 5, 160, 1348, 11627, 1120, 170, 2462, 1114, 1117, 2039, 2519, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12431, 2821, 2, 3, 1215, 4, 5, 1117, 2555, 5361, 1106, 174, 27923, 1155, 1104, 160, 1348, 11627, 112, 1116, 3690, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12431, 2821, 2, 3, 1215, 4, 5, 1117, 2555, 5361, 1106, 174, 27923, 1155, 1104, 160, 1348, 11627, 112, 1116, 3690, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12431, 2821, 2, 3, 1215, 4, 5, 1117, 2555, 5361, 1106, 174, 27923, 1155, 1104, 160, 1348, 11627, 112, 1116, 3690, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12431, 2821, 2, 3, 1215, 4, 5, 1117, 2555, 5361, 1106, 174, 27923, 1155, 1104, 160, 1348, 11627, 112, 1116, 3690, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013627910986542702, -0.01632031798362732, -0.05899930000305176, -0.07067876309156418, -0.07413521409034729, -0.19197702407836914, -0.209539532661438, -0.209539532661438, -0.209539532661438, -0.209539532661438], "metadata": {"source_tokens": ["Lang", "##ford", "kept", "W", "##al", "##cott", "at", "a", "distance", "with", "his", "longer", "reach", "and", "used", "his", "foot", "##work", "to", "e", "##vade", "all", "of", "W", "##al", "##cott", "'", "##s", "attacks", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Lang", "##ford", "[unused2]", "[unused3]", "kept", "[unused4]", "[unused5]", "W", "##al", "##cott", "at", "a", "distance", "with", "his", "longer", "reach", "[unused6]", "[SEP]", "[unused1]", "Lang", "##ford", "[unused2]", "[unused3]", "used", "[unused4]", "[unused5]", "his", "foot", "##work", "to", "e", "##vade", "all", "of", "W", "##al", "##cott", "'", "##s", "attacks", "[unused6]", "[SEP]", "[unused1]", "Lang", "##ford", "[unused2]", "[unused3]", "used", "[unused4]", "[unused5]", "his", "foot", "##work", "to", "e", "##vade", "all", "of", "W", "##al", "##cott", "'", "##s", "attacks", "[unused6]", "[SEP]", "[unused1]", "Lang", "##ford", "[unused2]", "[unused3]", "used", "[unused4]", "[unused5]", "his", "foot", "##work", "to", "e", "##vade", "all", "of", "W", "##al", "##cott", "'", "##s", "attacks", "[unused6]", "[SEP]", "[unused1]", "Lang", "##ford", "[unused2]", "[unused3]", "used", "[unused4]", "[unused5]", "his", "foot", "##work", "to", "e", "##vade", "all", "of", "W", "##al", "##cott", "'", "##s", "attacks", "[unused6]", "[SEP]"]]}

input 191:  {"source": "Language B then begins to supplant language A : the speakers of Language A abandon their own language in favor of the other language , generally because they believe that it will help them achieve certain goals within government , the workplace , and in social settings .\n"}
prediction:  {"predictions": [[1, 6828, 139, 2, 3, 3471, 4, 5, 1106, 28117, 8661, 9180, 1846, 138, 1173, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 7417, 1104, 6828, 138, 2, 3, 11092, 4, 5, 1147, 1319, 1846, 1107, 5010, 1104, 1103, 1168, 1846, 2412, 1272, 1152, 2059, 1115, 1122, 1209, 1494, 1172, 5515, 2218, 2513, 1439, 1433, 117, 1103, 19328, 117, 1105, 1107, 1934, 11106, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1209, 1494, 4, 5, 1172, 5515, 2218, 2513, 1439, 1433, 117, 1103, 19328, 117, 1105, 1107, 1934, 11106, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1172, 2, 3, 5515, 4, 5, 2218, 2513, 1439, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 7417, 1104, 6828, 138, 2, 3, 11092, 4, 5, 1147, 1319, 1846, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05164852738380432, -0.04612072929739952, -0.11093121021986008, -0.22858725488185883, -0.16741429269313812, -0.34217119216918945, -0.34143733978271484, -0.34143733978271484, -0.34143733978271484, -0.34143733978271484], "metadata": {"source_tokens": ["Language", "B", "then", "begins", "to", "su", "##pp", "##lant", "language", "A", ":", "the", "speakers", "of", "Language", "A", "abandon", "their", "own", "language", "in", "favor", "of", "the", "other", "language", ",", "generally", "because", "they", "believe", "that", "it", "will", "help", "them", "achieve", "certain", "goals", "within", "government", ",", "the", "workplace", ",", "and", "in", "social", "settings", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Language", "B", "[unused2]", "[unused3]", "begins", "[unused4]", "[unused5]", "to", "su", "##pp", "##lant", "language", "A", "then", "[unused6]", "[SEP]", "[unused1]", "the", "speakers", "of", "Language", "A", "[unused2]", "[unused3]", "abandon", "[unused4]", "[unused5]", "their", "own", "language", "in", "favor", "of", "the", "other", "language", "generally", "because", "they", "believe", "that", "it", "will", "help", "them", "achieve", "certain", "goals", "within", "government", ",", "the", "workplace", ",", "and", "in", "social", "settings", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "will", "help", "[unused4]", "[unused5]", "them", "achieve", "certain", "goals", "within", "government", ",", "the", "workplace", ",", "and", "in", "social", "settings", "[unused6]", "[SEP]", "[unused1]", "them", "[unused2]", "[unused3]", "achieve", "[unused4]", "[unused5]", "certain", "goals", "within", "government", "[unused6]", "[SEP]", "[unused1]", "the", "speakers", "of", "Language", "A", "[unused2]", "[unused3]", "abandon", "[unused4]", "[unused5]", "their", "own", "language", "[unused6]", "[SEP]"]]}

input 192:  {"source": "Lemmy believes that if Will Reid Dick had not been there , they could have worked through the problems , but ended up exchanging a few words and Clarke left the studio .\n"}
prediction:  {"predictions": [[1, 3180, 16211, 2, 3, 6616, 4, 5, 1115, 1191, 3100, 8721, 6416, 1125, 1136, 1151, 1175, 117, 1152, 1180, 1138, 1589, 1194, 1103, 2645, 117, 1133, 2207, 1146, 4252, 23286, 170, 1374, 1734, 1105, 7949, 1286, 1103, 2362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1180, 1138, 1589, 4, 5, 1194, 1103, 2645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7949, 2, 3, 1286, 4, 5, 1103, 2362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 2207, 1146, 4, 5, 4252, 23286, 170, 1374, 1734, 1105, 7949, 1286, 1103, 2362, 1191, 3100, 8721, 6416, 1125, 1136, 1151, 1175, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0058166165836155415, -0.07800962030887604, -0.09675616770982742, -0.10676117986440659, -0.1365678310394287, -0.21165621280670166, -0.21165621280670166, -0.21165621280670166, -0.21165621280670166, -0.21165621280670166], "metadata": {"source_tokens": ["Le", "##mmy", "believes", "that", "if", "Will", "Reid", "Dick", "had", "not", "been", "there", ",", "they", "could", "have", "worked", "through", "the", "problems", ",", "but", "ended", "up", "ex", "##changing", "a", "few", "words", "and", "Clarke", "left", "the", "studio", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Le", "##mmy", "[unused2]", "[unused3]", "believes", "[unused4]", "[unused5]", "that", "if", "Will", "Reid", "Dick", "had", "not", "been", "there", ",", "they", "could", "have", "worked", "through", "the", "problems", ",", "but", "ended", "up", "ex", "##changing", "a", "few", "words", "and", "Clarke", "left", "the", "studio", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "could", "have", "worked", "[unused4]", "[unused5]", "through", "the", "problems", "[unused6]", "[SEP]", "[unused1]", "Clarke", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "the", "studio", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "ended", "up", "[unused4]", "[unused5]", "ex", "##changing", "a", "few", "words", "and", "Clarke", "left", "the", "studio", "if", "Will", "Reid", "Dick", "had", "not", "been", "there", "[unused6]", "[SEP]"]]}

input 193:  {"source": "Lens subluxation is also seen in dogs and is characterized by a partial displacement of the lens .\n"}
prediction:  {"predictions": [[1, 22824, 1116, 4841, 24796, 1891, 2, 3, 1110, 1145, 1562, 4, 5, 1107, 6363, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 22824, 1116, 4841, 24796, 1891, 2, 3, 1110, 6858, 4, 5, 1118, 170, 7597, 15167, 1104, 1103, 11039, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.010466103442013264, -0.0018533064285293221, -0.006298065185546875, -0.007403850555419922, -0.007403850555419922, -0.007403850555419922, -0.007403850555419922, -0.007403850555419922, -0.007403850555419922, -0.007403850555419922], "metadata": {"source_tokens": ["Len", "##s", "sub", "##lux", "##ation", "is", "also", "seen", "in", "dogs", "and", "is", "characterized", "by", "a", "partial", "displacement", "of", "the", "lens", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Len", "##s", "sub", "##lux", "##ation", "[unused2]", "[unused3]", "is", "also", "seen", "[unused4]", "[unused5]", "in", "dogs", "[unused6]", "[SEP]", "[unused1]", "Len", "##s", "sub", "##lux", "##ation", "[unused2]", "[unused3]", "is", "characterized", "[unused4]", "[unused5]", "by", "a", "partial", "displacement", "of", "the", "lens", "[unused6]", "[SEP]"]]}

input 194:  {"source": "Li Hongzhi began his public teachings of Falun Gong on 13 May 1992 in Changchun , and subsequently gave lectures and taught Falun Gong exercises across China .\n"}
prediction:  {"predictions": [[1, 5255, 3475, 23239, 2, 3, 1310, 4, 5, 1117, 1470, 12815, 1104, 143, 1348, 3488, 23703, 1113, 1492, 1318, 1924, 1107, 11497, 17143, 1179, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5255, 3475, 23239, 2, 3, 1522, 4, 5, 9548, 2886, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5255, 3475, 23239, 2, 3, 3188, 4, 5, 143, 1348, 3488, 23703, 11536, 1506, 1975, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006287751253694296, -0.10776103287935257, -0.05564339458942413, -0.3426854610443115, -0.3141970634460449, -0.3141970634460449, -0.3141970634460449, -0.3141970634460449, -0.3141970634460449, -0.3141970634460449], "metadata": {"source_tokens": ["Li", "Hong", "##zhi", "began", "his", "public", "teachings", "of", "F", "##al", "##un", "Gong", "on", "13", "May", "1992", "in", "Chang", "##chu", "##n", ",", "and", "subsequently", "gave", "lectures", "and", "taught", "F", "##al", "##un", "Gong", "exercises", "across", "China", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Li", "Hong", "##zhi", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "his", "public", "teachings", "of", "F", "##al", "##un", "Gong", "on", "13", "May", "1992", "in", "Chang", "##chu", "##n", "[unused6]", "[SEP]", "[unused1]", "Li", "Hong", "##zhi", "[unused2]", "[unused3]", "gave", "[unused4]", "[unused5]", "lectures", "subsequently", "[unused6]", "[SEP]", "[unused1]", "Li", "Hong", "##zhi", "[unused2]", "[unused3]", "taught", "[unused4]", "[unused5]", "F", "##al", "##un", "Gong", "exercises", "across", "China", "[unused6]", "[SEP]"]]}

input 195:  {"source": "Like other BBC content of the mid-1990s , it often lampooned the low-budget quality of satellite television available in the UK at the time .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 11140, 6931, 1174, 4, 5, 1103, 1822, 28137, 7925, 8484, 1204, 3068, 1104, 5989, 1778, 1907, 1107, 1103, 1993, 1120, 1103, 1159, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 11140, 6931, 1174, 4, 5, 1103, 1822, 28137, 7925, 8484, 1204, 3068, 1104, 5989, 1778, 1907, 1120, 1103, 1159, 2409, 1168, 3173, 3438, 1104, 1103, 2286, 28137, 16382, 21500, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 11140, 6931, 1174, 4, 5, 1103, 1822, 28137, 7925, 8484, 1204, 3068, 1104, 5989, 1778, 1907, 1120, 1103, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 11140, 6931, 1174, 4, 5, 1103, 1822, 28137, 7925, 8484, 1204, 3068, 1104, 5989, 1778, 1907, 1120, 1103, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.002230954822152853, -0.04412320256233215, -0.07689521461725235, -0.2922646999359131, -0.11005230993032455, -0.14726710319519043, -0.14995217323303223, -0.14995217323303223, -0.14995217323303223, -0.14995217323303223], "metadata": {"source_tokens": ["Like", "other", "BBC", "content", "of", "the", "mid", "##-", "##19", "##90", "##s", ",", "it", "often", "lamp", "##oon", "##ed", "the", "low", "##-", "##bu", "##dge", "##t", "quality", "of", "satellite", "television", "available", "in", "the", "UK", "at", "the", "time", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "lamp", "##oon", "##ed", "[unused4]", "[unused5]", "the", "low", "##-", "##bu", "##dge", "##t", "quality", "of", "satellite", "television", "available", "in", "the", "UK", "at", "the", "time", "often", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "lamp", "##oon", "##ed", "[unused4]", "[unused5]", "the", "low", "##-", "##bu", "##dge", "##t", "quality", "of", "satellite", "television", "available", "at", "the", "time", "Like", "other", "BBC", "content", "of", "the", "mid", "##-", "##19", "##90", "##s", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "lamp", "##oon", "##ed", "[unused4]", "[unused5]", "the", "low", "##-", "##bu", "##dge", "##t", "quality", "of", "satellite", "television", "available", "at", "the", "time", "[unused6]", "[SEP]"]]}

input 196:  {"source": "Luke Robert Ravenstahl is an American politician who served as the 59th Mayor of Pittsburgh from 2006 until 2014 .\n"}
prediction:  {"predictions": [[1, 4599, 1823, 21848, 24401, 1233, 2, 3, 1110, 4, 5, 1126, 1237, 2931, 1150, 1462, 1112, 1103, 4589, 1582, 4643, 1104, 5610, 1121, 1386, 1235, 1387, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1126, 1237, 2931, 2, 3, 1462, 4, 5, 1112, 1103, 4589, 1582, 4643, 1104, 5610, 1121, 1386, 1235, 1387, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.001525952946394682, -0.012698921374976635, -0.12355685234069824, -0.12357425689697266, -0.12357425689697266, -0.12357425689697266, -0.12357425689697266, -0.12357425689697266, -0.12357425689697266, -0.12357425689697266], "metadata": {"source_tokens": ["Luke", "Robert", "Ravens", "##tah", "##l", "is", "an", "American", "politician", "who", "served", "as", "the", "59", "##th", "Mayor", "of", "Pittsburgh", "from", "2006", "until", "2014", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Luke", "Robert", "Ravens", "##tah", "##l", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "American", "politician", "who", "served", "as", "the", "59", "##th", "Mayor", "of", "Pittsburgh", "from", "2006", "until", "2014", "[unused6]", "[SEP]", "[unused1]", "an", "American", "politician", "[unused2]", "[unused3]", "served", "[unused4]", "[unused5]", "as", "the", "59", "##th", "Mayor", "of", "Pittsburgh", "from", "2006", "until", "2014", "[unused6]", "[SEP]"]]}

input 197:  {"source": "Males had a median income of $ 28,750 versus $ 16,250 for females .\n"}
prediction:  {"predictions": [[1, 7689, 2, 3, 1125, 4, 5, 170, 3151, 2467, 1104, 109, 1743, 28136, 26253, 1568, 6055, 109, 1479, 28136, 17600, 1568, 1111, 3032, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00013996577763464302, -0.000278472900390625, -0.0002770423889160156, -0.0002770423889160156, -0.0002770423889160156, -0.0002770423889160156, -0.0002770423889160156, -0.0002770423889160156, -0.0002770423889160156, -0.0002770423889160156], "metadata": {"source_tokens": ["Males", "had", "a", "median", "income", "of", "$", "28", "##,", "##75", "##0", "versus", "$", "16", "##,", "##25", "##0", "for", "females", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Males", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "median", "income", "of", "$", "28", "##,", "##75", "##0", "versus", "$", "16", "##,", "##25", "##0", "for", "females", "[unused6]", "[SEP]"]]}

input 198:  {"source": "Males had a median income of $ 36,016 versus $ 32,679 for females .\n"}
prediction:  {"predictions": [[1, 7689, 2, 3, 1125, 4, 5, 170, 3151, 2467, 1104, 109, 3164, 28136, 24400, 1545, 6055, 109, 2724, 28136, 1545, 1559, 1580, 1111, 3032, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00016546693223062903, -0.0005083084106445312, -0.0005960464477539062, -0.0005960464477539062, -0.0005960464477539062, -0.0005960464477539062, -0.0005960464477539062, -0.0005960464477539062, -0.0005960464477539062, -0.0005960464477539062], "metadata": {"source_tokens": ["Males", "had", "a", "median", "income", "of", "$", "36", "##,", "##01", "##6", "versus", "$", "32", "##,", "##6", "##7", "##9", "for", "females", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Males", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "median", "income", "of", "$", "36", "##,", "##01", "##6", "versus", "$", "32", "##,", "##6", "##7", "##9", "for", "females", "[unused6]", "[SEP]"]]}

input 199:  {"source": "Many are surgically removed for aesthetics and relief of psychosocial burden , but larger ones are also excised for prevention of cancer , although the benefit is impossible to assess for any individual patient .\n"}
prediction:  {"predictions": [[1, 1103, 5257, 2, 3, 1110, 4, 5, 4763, 1106, 15187, 1111, 1251, 2510, 5351, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2610, 3200, 2, 3, 1132, 1145, 4252, 14636, 1181, 4, 5, 1111, 13347, 1104, 4182, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2408, 2, 3, 1132, 13467, 1193, 2856, 4, 5, 1111, 27456, 1105, 3893, 1104, 15604, 21155, 22354, 12562, 11904, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2610, 3200, 2, 3, 1132, 4252, 14636, 1181, 4, 5, 1111, 13347, 1104, 4182, 1780, 1103, 5257, 1110, 4763, 1106, 15187, 1111, 1251, 2510, 5351, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.021769538521766663, -0.043837327510118484, -0.024436766281723976, -0.06856250017881393, -0.1401660442352295, -0.1326286792755127, -0.1326286792755127, -0.1326286792755127, -0.1326286792755127, -0.1326286792755127], "metadata": {"source_tokens": ["Many", "are", "surgical", "##ly", "removed", "for", "aesthetics", "and", "relief", "of", "ps", "##ych", "##oso", "##cial", "burden", ",", "but", "larger", "ones", "are", "also", "ex", "##cise", "##d", "for", "prevention", "of", "cancer", ",", "although", "the", "benefit", "is", "impossible", "to", "assess", "for", "any", "individual", "patient", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "benefit", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "impossible", "to", "assess", "for", "any", "individual", "patient", "[unused6]", "[SEP]", "[unused1]", "larger", "ones", "[unused2]", "[unused3]", "are", "also", "ex", "##cise", "##d", "[unused4]", "[unused5]", "for", "prevention", "of", "cancer", "[unused6]", "[SEP]", "[unused1]", "Many", "[unused2]", "[unused3]", "are", "surgical", "##ly", "removed", "[unused4]", "[unused5]", "for", "aesthetics", "and", "relief", "of", "ps", "##ych", "##oso", "##cial", "burden", "[unused6]", "[SEP]", "[unused1]", "larger", "ones", "[unused2]", "[unused3]", "are", "ex", "##cise", "##d", "[unused4]", "[unused5]", "for", "prevention", "of", "cancer", "although", "the", "benefit", "is", "impossible", "to", "assess", "for", "any", "individual", "patient", "[unused6]", "[SEP]"]]}

input 200:  {"source": "Many overseas Chinese whose ancestors came from the Quanzhou area , especially those in Southeast Asia , often speak mainly Hokkien at home .\n"}
prediction:  {"predictions": [[1, 2408, 7474, 1922, 2, 3, 1338, 4, 5, 1121, 1103, 154, 8734, 10753, 1298, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2408, 7474, 1922, 2, 3, 2936, 2871, 4, 5, 9800, 1377, 11334, 1179, 1120, 1313, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2408, 7474, 1922, 2, 3, 2936, 4, 5, 2871, 9800, 1377, 11334, 1179, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017070602625608444, -0.06688862293958664, -0.1490507274866104, -0.1344897747039795, -0.12538623809814453, -0.12538623809814453, -0.12538623809814453, -0.12538623809814453, -0.12538623809814453, -0.12538623809814453], "metadata": {"source_tokens": ["Many", "overseas", "Chinese", "whose", "ancestors", "came", "from", "the", "Q", "##uan", "##zhou", "area", ",", "especially", "those", "in", "Southeast", "Asia", ",", "often", "speak", "mainly", "Ho", "##k", "##kie", "##n", "at", "home", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Many", "overseas", "Chinese", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "from", "the", "Q", "##uan", "##zhou", "area", "[unused6]", "[SEP]", "[unused1]", "Many", "overseas", "Chinese", "[unused2]", "[unused3]", "speak", "mainly", "[unused4]", "[unused5]", "Ho", "##k", "##kie", "##n", "at", "home", "often", "[unused6]", "[SEP]", "[unused1]", "Many", "overseas", "Chinese", "[unused2]", "[unused3]", "speak", "[unused4]", "[unused5]", "mainly", "Ho", "##k", "##kie", "##n", "[unused6]", "[SEP]"]]}

input 201:  {"source": "Meanwhile , the Mason City Division continued to operate as usual .\n"}
prediction:  {"predictions": [[1, 1103, 6287, 1392, 1784, 2, 3, 1598, 4, 5, 5459, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6287, 1392, 1784, 2, 3, 1106, 4732, 4, 5, 1112, 4400, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06875492632389069, -0.02385537698864937, -0.03853559494018555, -0.03853893280029297, -0.03853893280029297, -0.03853893280029297, -0.03853893280029297, -0.03853893280029297, -0.03853893280029297, -0.03853893280029297], "metadata": {"source_tokens": ["Meanwhile", ",", "the", "Mason", "City", "Division", "continued", "to", "operate", "as", "usual", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Mason", "City", "Division", "[unused2]", "[unused3]", "continued", "[unused4]", "[unused5]", "Meanwhile", "[unused6]", "[SEP]", "[unused1]", "the", "Mason", "City", "Division", "[unused2]", "[unused3]", "to", "operate", "[unused4]", "[unused5]", "as", "usual", "[unused6]", "[SEP]"]]}

input 202:  {"source": "Models , taking into account the size and room number of the barrack blocks in the Gorgan Wall forts and likely occupation density , produce figures between 15,000 and 36,000 soldiers .\n"}
prediction:  {"predictions": [[1, 24025, 117, 1781, 1154, 3300, 1103, 2060, 1105, 1395, 1295, 1104, 1103, 2927, 21580, 5511, 1107, 1103, 3414, 21061, 6250, 17725, 1105, 2620, 5846, 3476, 2, 3, 3133, 4, 5, 3736, 1206, 1405, 28136, 7629, 1568, 1105, 3164, 28136, 7629, 1568, 2803, 6, 102, 102, 102, 102, 102, 102, 102, 1, 24025, 2, 3, 3133, 3736, 4, 5, 1206, 1405, 28136, 7629, 1568, 1105, 3164, 28136, 7629, 1568, 2803, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00739195104688406, -0.09449861943721771, -0.33578407764434814, -0.3381751775741577, -0.3381751775741577, -0.3381751775741577, -0.3381751775741577, -0.3381751775741577, -0.3381751775741577, -0.3381751775741577], "metadata": {"source_tokens": ["Models", ",", "taking", "into", "account", "the", "size", "and", "room", "number", "of", "the", "bar", "##rack", "blocks", "in", "the", "Go", "##rgan", "Wall", "forts", "and", "likely", "occupation", "density", ",", "produce", "figures", "between", "15", "##,", "##00", "##0", "and", "36", "##,", "##00", "##0", "soldiers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Models", ",", "taking", "into", "account", "the", "size", "and", "room", "number", "of", "the", "bar", "##rack", "blocks", "in", "the", "Go", "##rgan", "Wall", "forts", "and", "likely", "occupation", "density", "[unused2]", "[unused3]", "produce", "[unused4]", "[unused5]", "figures", "between", "15", "##,", "##00", "##0", "and", "36", "##,", "##00", "##0", "soldiers", "[unused6]", "[SEP]", "[unused1]", "Models", "[unused2]", "[unused3]", "produce", "figures", "[unused4]", "[unused5]", "between", "15", "##,", "##00", "##0", "and", "36", "##,", "##00", "##0", "soldiers", "[unused6]", "[SEP]"]]}

input 203:  {"source": "Modern educational methods were more widely spread throughout the Empire , and the country embarked on a development scheme and plans for modernization , tempered by Ethiopian traditions , and within the framework of the ancient monarchical structure of the state .\n"}
prediction:  {"predictions": [[1, 4825, 4339, 4069, 2, 3, 1127, 4, 5, 1167, 3409, 2819, 2032, 1103, 2813, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1583, 2, 3, 11322, 4, 5, 1113, 170, 1718, 5471, 1105, 2714, 1111, 25145, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1583, 2, 3, 11322, 4, 5, 1113, 170, 1718, 5471, 1105, 2714, 1111, 25145, 26030, 1118, 15845, 7181, 1105, 1439, 1103, 8297, 1104, 1103, 2890, 14390, 4571, 2401, 1104, 1103, 1352, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1583, 2, 3, 11322, 4, 5, 1113, 170, 1718, 5471, 1105, 2714, 1111, 25145, 26030, 1118, 15845, 7181, 1105, 1439, 1103, 8297, 1104, 1103, 2890, 14390, 4571, 2401, 1104, 1103, 1352, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06748068332672119, -0.038695234805345535, -0.0487787202000618, -0.2970541715621948, -0.06266505271196365, -0.1500626802444458, -0.15092122554779053, -0.15092122554779053, -0.15092122554779053, -0.15092122554779053], "metadata": {"source_tokens": ["Modern", "educational", "methods", "were", "more", "widely", "spread", "throughout", "the", "Empire", ",", "and", "the", "country", "embarked", "on", "a", "development", "scheme", "and", "plans", "for", "modernization", ",", "tempered", "by", "Ethiopian", "traditions", ",", "and", "within", "the", "framework", "of", "the", "ancient", "monarch", "##ical", "structure", "of", "the", "state", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Modern", "educational", "methods", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "more", "widely", "spread", "throughout", "the", "Empire", "[unused6]", "[SEP]", "[unused1]", "the", "country", "[unused2]", "[unused3]", "embarked", "[unused4]", "[unused5]", "on", "a", "development", "scheme", "and", "plans", "for", "modernization", "[unused6]", "[SEP]", "[unused1]", "the", "country", "[unused2]", "[unused3]", "embarked", "[unused4]", "[unused5]", "on", "a", "development", "scheme", "and", "plans", "for", "modernization", "tempered", "by", "Ethiopian", "traditions", "and", "within", "the", "framework", "of", "the", "ancient", "monarch", "##ical", "structure", "of", "the", "state", "[unused6]", "[SEP]"]]}

input 204:  {"source": "Modernity has been blended without sacrificing on the traditional Buddhist ethos .\n"}
prediction:  {"predictions": [[1, 4825, 1785, 2, 3, 1144, 1151, 22357, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4825, 1785, 2, 3, 1144, 1151, 22357, 4, 5, 1443, 21718, 1665, 2047, 21361, 1158, 1113, 1103, 2361, 7558, 3084, 15342, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006961355451494455, -0.04744814708828926, -0.00138092041015625, -0.0015959739685058594, -0.0015959739685058594, -0.0015959739685058594, -0.0015959739685058594, -0.0015959739685058594, -0.0015959739685058594, -0.0015959739685058594], "metadata": {"source_tokens": ["Modern", "##ity", "has", "been", "blended", "without", "sa", "##c", "##ri", "##fic", "##ing", "on", "the", "traditional", "Buddhist", "et", "##hos", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Modern", "##ity", "[unused2]", "[unused3]", "has", "been", "blended", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Modern", "##ity", "[unused2]", "[unused3]", "has", "been", "blended", "[unused4]", "[unused5]", "without", "sa", "##c", "##ri", "##fic", "##ing", "on", "the", "traditional", "Buddhist", "et", "##hos", "[unused6]", "[SEP]"]]}

input 205:  {"source": "Modification of the river began in earnest with the arrival of the Florida East Coast Railway in Miami in 1896 .\n"}
prediction:  {"predictions": [[1, 12556, 3309, 11531, 1104, 1103, 2186, 2, 3, 1310, 4, 5, 1107, 21304, 1114, 1103, 4870, 1104, 1103, 2631, 1689, 3331, 2847, 1107, 4916, 1107, 5645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0004238671390339732, -0.2363135814666748, -0.2668952941894531, -0.2668952941894531, -0.2668952941894531, -0.2668952941894531, -0.2668952941894531, -0.2668952941894531, -0.2668952941894531, -0.2668952941894531], "metadata": {"source_tokens": ["Mo", "##di", "##fication", "of", "the", "river", "began", "in", "earnest", "with", "the", "arrival", "of", "the", "Florida", "East", "Coast", "Railway", "in", "Miami", "in", "1896", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mo", "##di", "##fication", "of", "the", "river", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "in", "earnest", "with", "the", "arrival", "of", "the", "Florida", "East", "Coast", "Railway", "in", "Miami", "in", "1896", "[unused6]", "[SEP]"]]}

input 206:  {"source": "Moore briefly dropped Marciano in the second round , but Marciano recovered and knocked Moore down five times , knocking him out in the ninth to retain the belt .\n"}
prediction:  {"predictions": [[1, 4673, 2, 3, 2434, 4, 5, 25663, 2728, 1107, 1103, 1248, 1668, 4016, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25663, 2728, 2, 3, 6203, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25663, 2728, 2, 3, 6011, 1205, 4, 5, 1421, 1551, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25663, 2728, 2, 3, 6011, 4673, 1205, 4, 5, 1421, 1551, 10760, 1140, 1149, 1107, 1103, 6948, 1106, 8983, 1103, 5614, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25663, 2728, 2, 3, 6011, 4, 5, 4673, 1205, 1421, 1551, 10760, 1140, 1149, 1107, 1103, 6948, 1106, 8983, 1103, 5614, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25663, 2728, 2, 3, 6011, 4, 5, 4673, 1205, 1421, 1551, 10760, 1140, 1149, 1107, 1103, 6948, 1106, 8983, 1103, 5614, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03648533672094345, -0.06420479714870453, -0.12043549120426178, -0.11642860621213913, -0.12564487755298615, -0.14263050258159637, -0.21213197708129883, -0.21213185787200928, -0.21213185787200928, -0.21213185787200928], "metadata": {"source_tokens": ["Moore", "briefly", "dropped", "Marcia", "##no", "in", "the", "second", "round", ",", "but", "Marcia", "##no", "recovered", "and", "knocked", "Moore", "down", "five", "times", ",", "knocking", "him", "out", "in", "the", "ninth", "to", "retain", "the", "belt", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Moore", "[unused2]", "[unused3]", "dropped", "[unused4]", "[unused5]", "Marcia", "##no", "in", "the", "second", "round", "briefly", "[unused6]", "[SEP]", "[unused1]", "Marcia", "##no", "[unused2]", "[unused3]", "recovered", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Marcia", "##no", "[unused2]", "[unused3]", "knocked", "down", "[unused4]", "[unused5]", "five", "times", "[unused6]", "[SEP]", "[unused1]", "Marcia", "##no", "[unused2]", "[unused3]", "knocked", "Moore", "down", "[unused4]", "[unused5]", "five", "times", "knocking", "him", "out", "in", "the", "ninth", "to", "retain", "the", "belt", "[unused6]", "[SEP]", "[unused1]", "Marcia", "##no", "[unused2]", "[unused3]", "knocked", "[unused4]", "[unused5]", "Moore", "down", "five", "times", "knocking", "him", "out", "in", "the", "ninth", "to", "retain", "the", "belt", "[unused6]", "[SEP]", "[unused1]", "Marcia", "##no", "[unused2]", "[unused3]", "knocked", "[unused4]", "[unused5]", "Moore", "down", "five", "times", "knocking", "him", "out", "in", "the", "ninth", "to", "retain", "the", "belt", "[unused6]", "[SEP]"]]}

input 207:  {"source": "Much of the station remains in the disused subway but there is no public access .\n"}
prediction:  {"predictions": [[1, 6335, 1104, 1103, 1466, 2, 3, 2606, 4, 5, 1107, 1103, 4267, 26097, 14790, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1185, 1470, 2469, 2, 3, 1175, 1110, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0021478990092873573, -0.03537610173225403, -0.021979331970214844, -0.021983623504638672, -0.021983623504638672, -0.021983623504638672, -0.021983623504638672, -0.021983623504638672, -0.021983623504638672, -0.021983623504638672], "metadata": {"source_tokens": ["Much", "of", "the", "station", "remains", "in", "the", "di", "##sused", "subway", "but", "there", "is", "no", "public", "access", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Much", "of", "the", "station", "[unused2]", "[unused3]", "remains", "[unused4]", "[unused5]", "in", "the", "di", "##sused", "subway", "[unused6]", "[SEP]", "[unused1]", "no", "public", "access", "[unused2]", "[unused3]", "there", "is", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 208:  {"source": "Muhammad ibn Abu Bakr was a pious Muslim who supported the Imam of his time , Ali ibn Abi Talib , even though his sister Aisha opposed ` Ali in the battle of Jamal , Ibn Abu Bakr was faithful to his stepfather .\n"}
prediction:  {"predictions": [[1, 6710, 10452, 8158, 18757, 1377, 1197, 2, 3, 1108, 4, 5, 170, 185, 4179, 4360, 1150, 2726, 1103, 21765, 1104, 1117, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 2104, 2, 3, 4151, 4, 5, 4149, 1107, 1103, 2321, 1104, 27440, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 14340, 8158, 18757, 1377, 1197, 2, 3, 1108, 4, 5, 12969, 1106, 1117, 24133, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 1159, 2, 3, 1110, 4, 5, 4149, 10452, 138, 5567, 22515, 2646, 1830, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 14340, 8158, 18757, 1377, 1197, 2, 3, 1108, 4, 5, 12969, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 14340, 8158, 18757, 1377, 1197, 2, 3, 1108, 4, 5, 12969, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6710, 10452, 8158, 18757, 1377, 1197, 2, 3, 1108, 4, 5, 170, 185, 4179, 4360, 1256, 1463, 1117, 2104, 19294, 5480, 4151, 4149, 1107, 1103, 2321, 1104, 27440, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 14340, 8158, 18757, 1377, 1197, 2, 3, 1108, 4, 5, 12969, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06521538645029068, -0.1230582743883133, -0.04810025170445442, -0.13192026317119598, -0.1919606775045395, -0.22062580287456512, -0.12106974422931671, -0.1871456354856491, -0.21264493465423584, -0.2126842737197876], "metadata": {"source_tokens": ["Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "was", "a", "p", "##ious", "Muslim", "who", "supported", "the", "Imam", "of", "his", "time", ",", "Ali", "ibn", "A", "##bi", "Ta", "##li", "##b", ",", "even", "though", "his", "sister", "Ai", "##sha", "opposed", "`", "Ali", "in", "the", "battle", "of", "Jamal", ",", "Ibn", "Abu", "Ba", "##k", "##r", "was", "faithful", "to", "his", "stepfather", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "p", "##ious", "Muslim", "who", "supported", "the", "Imam", "of", "his", "time", "[unused6]", "[SEP]", "[unused1]", "his", "sister", "[unused2]", "[unused3]", "opposed", "[unused4]", "[unused5]", "Ali", "in", "the", "battle", "of", "Jamal", "[unused6]", "[SEP]", "[unused1]", "Ibn", "Abu", "Ba", "##k", "##r", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "faithful", "to", "his", "stepfather", "[unused6]", "[SEP]", "[unused1]", "his", "time", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Ali", "ibn", "A", "##bi", "Ta", "##li", "##b", "[unused6]", "[SEP]", "[unused1]", "Ibn", "Abu", "Ba", "##k", "##r", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "faithful", "[unused6]", "[SEP]", "[unused1]", "Ibn", "Abu", "Ba", "##k", "##r", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "faithful", "[unused6]", "[SEP]", "[unused1]", "Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "p", "##ious", "Muslim", "even", "though", "his", "sister", "Ai", "##sha", "opposed", "Ali", "in", "the", "battle", "of", "Jamal", "[unused6]", "[SEP]", "[unused1]", "Ibn", "Abu", "Ba", "##k", "##r", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "faithful", "[unused6]", "[SEP]"]]}

input 209:  {"source": "Names like John Berks , Gary Edwards , Frank Sanders , Robin Alexander , Darryl Jooste , George Wayne and David Gresham all started out at LM Radio before moving to other stations such as Swazi Music Radio , Radio 702 , Springbok Radio and other SABC stations , 2JJ and Capital 604 .\n"}
prediction:  {"predictions": [[1, 13313, 1176, 1287, 4108, 18416, 117, 4926, 6847, 117, 2748, 12195, 117, 5981, 2792, 117, 25389, 8125, 15540, 1162, 117, 1667, 5489, 1105, 1681, 144, 21298, 2312, 2, 3, 1408, 1149, 4, 5, 1120, 149, 2107, 2664, 1196, 2232, 1106, 1168, 2930, 1216, 1112, 156, 3624, 5303, 1953, 2664, 102, 1, 13313, 1176, 1287, 4108, 18416, 4926, 6847, 2748, 12195, 5981, 2792, 25389, 8125, 15540, 1162, 1667, 5489, 1105, 1681, 144, 21298, 2312, 2, 3, 1408, 1149, 4, 5, 1120, 149, 2107, 2664, 1196, 2232, 1106, 1168, 2930, 1216, 1112, 156, 3624, 5303, 1953, 2664, 2664, 3102, 1477, 5350, 4043, 102, 1, 13313, 1176, 1287, 4108, 18416, 4926, 6847, 2748, 12195, 5981, 2792, 25389, 8125, 15540, 1162, 1667, 5489, 1105, 1681, 144, 21298, 2312, 2, 3, 1408, 1149, 4, 5, 1120, 149, 2107, 2664, 1196, 2232, 1106, 1168, 2930, 1216, 1112, 156, 3624, 5303, 1953, 2664, 2664, 3102, 1477, 5350, 4043, 102, 1, 13313, 1176, 1287, 4108, 18416, 4926, 6847, 2748, 12195, 5981, 2792, 25389, 8125, 15540, 1162, 1667, 5489, 1105, 1681, 144, 21298, 2312, 2, 3, 1408, 1149, 4, 5, 1120, 149, 2107, 2664, 1196, 2232, 1106, 1168, 2930, 1216, 1112, 156, 3624, 5303, 1953, 2664, 2664, 3102, 1477, 5350, 4043, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.015546688809990883, -0.05796460062265396, -0.06420359015464783, -0.0852975845336914, -0.30036234855651855, -0.3049662113189697, -0.30506062507629395, -0.30506062507629395, -0.30506062507629395, -0.30506062507629395], "metadata": {"source_tokens": ["Names", "like", "John", "Be", "##rks", ",", "Gary", "Edwards", ",", "Frank", "Sanders", ",", "Robin", "Alexander", ",", "Darryl", "Jo", "##ost", "##e", ",", "George", "Wayne", "and", "David", "G", "##resh", "##am", "all", "started", "out", "at", "L", "##M", "Radio", "before", "moving", "to", "other", "stations", "such", "as", "S", "##wa", "##zi", "Music", "Radio", ",", "Radio", "70", "##2", ",", "Spring", "##bo", "##k", "Radio", "and", "other", "SA", "##BC", "stations", ",", "2", "##J", "##J", "and", "Capital", "60", "##4", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Names", "like", "John", "Be", "##rks", ",", "Gary", "Edwards", ",", "Frank", "Sanders", ",", "Robin", "Alexander", ",", "Darryl", "Jo", "##ost", "##e", ",", "George", "Wayne", "and", "David", "G", "##resh", "##am", "[unused2]", "[unused3]", "started", "out", "[unused4]", "[unused5]", "at", "L", "##M", "Radio", "before", "moving", "to", "other", "stations", "such", "as", "S", "##wa", "##zi", "Music", "Radio", "[SEP]", "[unused1]", "Names", "like", "John", "Be", "##rks", "Gary", "Edwards", "Frank", "Sanders", "Robin", "Alexander", "Darryl", "Jo", "##ost", "##e", "George", "Wayne", "and", "David", "G", "##resh", "##am", "[unused2]", "[unused3]", "started", "out", "[unused4]", "[unused5]", "at", "L", "##M", "Radio", "before", "moving", "to", "other", "stations", "such", "as", "S", "##wa", "##zi", "Music", "Radio", "Radio", "70", "##2", "Spring", "##bo", "[SEP]", "[unused1]", "Names", "like", "John", "Be", "##rks", "Gary", "Edwards", "Frank", "Sanders", "Robin", "Alexander", "Darryl", "Jo", "##ost", "##e", "George", "Wayne", "and", "David", "G", "##resh", "##am", "[unused2]", "[unused3]", "started", "out", "[unused4]", "[unused5]", "at", "L", "##M", "Radio", "before", "moving", "to", "other", "stations", "such", "as", "S", "##wa", "##zi", "Music", "Radio", "Radio", "70", "##2", "Spring", "##bo", "[SEP]", "[unused1]", "Names", "like", "John", "Be", "##rks", "Gary", "Edwards", "Frank", "Sanders", "Robin", "Alexander", "Darryl", "Jo", "##ost", "##e", "George", "Wayne", "and", "David", "G", "##resh", "##am", "[unused2]", "[unused3]", "started", "out", "[unused4]", "[unused5]", "at", "L", "##M", "Radio", "before", "moving", "to", "other", "stations", "such", "as", "S", "##wa", "##zi", "Music", "Radio", "Radio", "70", "##2", "Spring", "##bo", "[SEP]"]]}

input 210:  {"source": "Newhan split the season between Triple-A Round Rock , where he hit .308 .\n"}
prediction:  {"predictions": [[1, 1203, 3822, 2, 3, 3325, 4, 5, 1103, 1265, 1206, 9457, 28137, 1592, 4200, 2977, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1855, 4, 5, 119, 13144, 1604, 9457, 28137, 1592, 4200, 2977, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009698178619146347, -0.015752596780657768, -0.02147817611694336, -0.021636486053466797, -0.021636486053466797, -0.021636486053466797, -0.021636486053466797, -0.021636486053466797, -0.021636486053466797, -0.021636486053466797], "metadata": {"source_tokens": ["New", "##han", "split", "the", "season", "between", "Triple", "##-", "##A", "Round", "Rock", ",", "where", "he", "hit", ".", "##30", "##8", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "New", "##han", "[unused2]", "[unused3]", "split", "[unused4]", "[unused5]", "the", "season", "between", "Triple", "##-", "##A", "Round", "Rock", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "hit", "[unused4]", "[unused5]", ".", "##30", "##8", "Triple", "##-", "##A", "Round", "Rock", "[unused6]", "[SEP]"]]}

input 211:  {"source": "Next morning , the race left the city on the way to the Pyrenees and stopped in the suburb of Gradignan , in the university area of La House .\n"}
prediction:  {"predictions": [[1, 1103, 1886, 2, 3, 1286, 4, 5, 1103, 1331, 1113, 1103, 1236, 1106, 1103, 153, 10930, 27075, 5893, 2106, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1886, 2, 3, 2141, 4, 5, 1107, 1103, 7144, 1104, 144, 9871, 11368, 1389, 1107, 1103, 2755, 1298, 1104, 2001, 1585, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1886, 2, 3, 1286, 4, 5, 1103, 1331, 1113, 1103, 1236, 1106, 1103, 153, 10930, 27075, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1886, 2, 3, 1286, 4, 5, 1103, 1331, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1886, 2, 3, 1286, 4, 5, 1103, 1331, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1886, 2, 3, 1286, 4, 5, 1103, 1331, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023225925862789154, -0.02446066401898861, -0.103846475481987, -0.18062274158000946, -0.18229961395263672, -0.20982103049755096, -0.2751452922821045, -0.27234339714050293, -0.27234339714050293, -0.27234339714050293], "metadata": {"source_tokens": ["Next", "morning", ",", "the", "race", "left", "the", "city", "on", "the", "way", "to", "the", "P", "##yre", "##nees", "and", "stopped", "in", "the", "suburb", "of", "G", "##rad", "##ign", "##an", ",", "in", "the", "university", "area", "of", "La", "House", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "race", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "the", "city", "on", "the", "way", "to", "the", "P", "##yre", "##nees", "Next", "morning", "[unused6]", "[SEP]", "[unused1]", "the", "race", "[unused2]", "[unused3]", "stopped", "[unused4]", "[unused5]", "in", "the", "suburb", "of", "G", "##rad", "##ign", "##an", "in", "the", "university", "area", "of", "La", "House", "[unused6]", "[SEP]", "[unused1]", "the", "race", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "the", "city", "on", "the", "way", "to", "the", "P", "##yre", "##nees", "[unused6]", "[SEP]", "[unused1]", "the", "race", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "the", "city", "[unused6]", "[SEP]", "[unused1]", "the", "race", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "the", "city", "[unused6]", "[SEP]", "[unused1]", "the", "race", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "the", "city", "[unused6]", "[SEP]"]]}

input 212:  {"source": "No announcement from UTV was made about the decision to close the station earlier than planned .\n"}
prediction:  {"predictions": [[1, 1302, 8679, 1121, 158, 7073, 2, 3, 1108, 1189, 4, 5, 1164, 1103, 2383, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1302, 8679, 1121, 158, 7073, 2, 3, 1108, 1189, 4, 5, 1164, 1103, 2383, 1106, 1601, 1103, 1466, 2206, 1190, 2919, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007717805914580822, -0.013820330612361431, -0.04360771179199219, -0.0411992073059082, -0.0411992073059082, -0.0411992073059082, -0.0411992073059082, -0.0411992073059082, -0.0411992073059082, -0.0411992073059082], "metadata": {"source_tokens": ["No", "announcement", "from", "U", "##TV", "was", "made", "about", "the", "decision", "to", "close", "the", "station", "earlier", "than", "planned", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "No", "announcement", "from", "U", "##TV", "[unused2]", "[unused3]", "was", "made", "[unused4]", "[unused5]", "about", "the", "decision", "[unused6]", "[SEP]", "[unused1]", "No", "announcement", "from", "U", "##TV", "[unused2]", "[unused3]", "was", "made", "[unused4]", "[unused5]", "about", "the", "decision", "to", "close", "the", "station", "earlier", "than", "planned", "[unused6]", "[SEP]"]]}

input 213:  {"source": "Noatak has a gravel public airstrip and is primarily reached by air .\n"}
prediction:  {"predictions": [[1, 1302, 6575, 1377, 2, 3, 1144, 4, 5, 170, 11898, 1470, 15692, 19091, 1643, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1302, 6575, 1377, 2, 3, 1110, 3120, 1680, 4, 5, 1118, 1586, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005057769827544689, -0.00292493705637753, -0.013056278228759766, -0.013649940490722656, -0.013649940490722656, -0.013649940490722656, -0.013649940490722656, -0.013649940490722656, -0.013649940490722656, -0.013649940490722656], "metadata": {"source_tokens": ["No", "##ata", "##k", "has", "a", "gravel", "public", "airs", "##tri", "##p", "and", "is", "primarily", "reached", "by", "air", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "No", "##ata", "##k", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "a", "gravel", "public", "airs", "##tri", "##p", "[unused6]", "[SEP]", "[unused1]", "No", "##ata", "##k", "[unused2]", "[unused3]", "is", "primarily", "reached", "[unused4]", "[unused5]", "by", "air", "[unused6]", "[SEP]"]]}

input 214:  {"source": "Not everyone completely trusted Vakama 's vision - Matau was particularly frustrated at following what he considered the delusions of a `` fire-spitter '' - but with nothing else to go on they decided to track the Matoran down .\n"}
prediction:  {"predictions": [[1, 1753, 2490, 2, 3, 9373, 4, 5, 159, 11747, 1918, 112, 1116, 4152, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1879, 1106, 1854, 4, 5, 1103, 25702, 15186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 28044, 1358, 2, 3, 1108, 4, 5, 2521, 11010, 1120, 1378, 1184, 1119, 1737, 1103, 3687, 27262, 1104, 170, 169, 28152, 1783, 28137, 20080, 25608, 1197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1879, 4, 5, 1106, 1854, 1103, 25702, 15186, 1205, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1737, 4, 5, 1103, 3687, 27262, 1104, 170, 169, 28152, 1783, 28137, 20080, 25608, 1197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1720, 1950, 2, 3, 1106, 1301, 4, 5, 1113, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1879, 4, 5, 1106, 1854, 1103, 25702, 15186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1879, 4, 5, 1106, 1854, 1103, 25702, 15186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1879, 4, 5, 1106, 1854, 1103, 25702, 15186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.08030569553375244, -0.15103872120380402, -0.08603158593177795, -0.2143266648054123, -0.09487736225128174, -0.24293720722198486, -0.19843484461307526, -0.19743594527244568, -0.20221564173698425, -0.2630181312561035], "metadata": {"source_tokens": ["Not", "everyone", "completely", "trusted", "V", "##aka", "##ma", "'", "##s", "vision", "-", "Mata", "##u", "was", "particularly", "frustrated", "at", "following", "what", "he", "considered", "the", "del", "##usions", "of", "a", "`", "##`", "fire", "##-", "##sp", "##itte", "##r", "'", "##'", "-", "but", "with", "nothing", "else", "to", "go", "on", "they", "decided", "to", "track", "the", "Mat", "##oran", "down", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Not", "everyone", "[unused2]", "[unused3]", "trusted", "[unused4]", "[unused5]", "V", "##aka", "##ma", "'", "##s", "vision", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "decided", "to", "track", "[unused4]", "[unused5]", "the", "Mat", "##oran", "[unused6]", "[SEP]", "[unused1]", "Mata", "##u", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "particularly", "frustrated", "at", "following", "what", "he", "considered", "the", "del", "##usions", "of", "a", "`", "##`", "fire", "##-", "##sp", "##itte", "##r", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "decided", "[unused4]", "[unused5]", "to", "track", "the", "Mat", "##oran", "down", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "considered", "[unused4]", "[unused5]", "the", "del", "##usions", "of", "a", "`", "##`", "fire", "##-", "##sp", "##itte", "##r", "[unused6]", "[SEP]", "[unused1]", "nothing", "else", "[unused2]", "[unused3]", "to", "go", "[unused4]", "[unused5]", "on", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "decided", "[unused4]", "[unused5]", "to", "track", "the", "Mat", "##oran", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "decided", "[unused4]", "[unused5]", "to", "track", "the", "Mat", "##oran", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "decided", "[unused4]", "[unused5]", "to", "track", "the", "Mat", "##oran", "[unused6]", "[SEP]"]]}

input 215:  {"source": "Nothing is known for certain about his life before about 1580 , but contemporary or near-contemporary accounts suggest that he was brought up as a member of the Church of Scotland , spent some time in Argyll before leaving for the Continent , and was converted to Catholicism in Spain .\n"}
prediction:  {"predictions": [[1, 3793, 1137, 1485, 28137, 7235, 18408, 18876, 3113, 5756, 2, 3, 5996, 4, 5, 1115, 1119, 1108, 1814, 1146, 1112, 170, 1420, 1104, 1103, 1722, 1104, 3030, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4302, 2, 3, 1110, 1227, 4, 5, 1111, 2218, 1164, 1117, 1297, 1196, 1164, 18960, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1814, 1146, 4, 5, 1112, 170, 1420, 1104, 1103, 1722, 1104, 3030, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1814, 1146, 4, 5, 1112, 170, 1420, 1104, 1103, 1722, 1104, 3030, 2097, 1199, 1159, 1107, 138, 17292, 2339, 1196, 2128, 1111, 1103, 16752, 24123, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1814, 1146, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1814, 1146, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1814, 1146, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1814, 1146, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1814, 1146, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1814, 1146, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04697622358798981, -0.029609667137265205, -0.07333669066429138, -0.07939507812261581, -0.1713983118534088, -0.20110563933849335, -0.21145296096801758, -0.21120037138462067, -0.20996609330177307, -0.20245428383350372], "metadata": {"source_tokens": ["Nothing", "is", "known", "for", "certain", "about", "his", "life", "before", "about", "158", "##0", ",", "but", "contemporary", "or", "near", "##-", "##con", "##tem", "##por", "##ary", "accounts", "suggest", "that", "he", "was", "brought", "up", "as", "a", "member", "of", "the", "Church", "of", "Scotland", ",", "spent", "some", "time", "in", "A", "##rgy", "##ll", "before", "leaving", "for", "the", "Con", "##tinent", ",", "and", "was", "converted", "to", "Catholicism", "in", "Spain", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "contemporary", "or", "near", "##-", "##con", "##tem", "##por", "##ary", "accounts", "[unused2]", "[unused3]", "suggest", "[unused4]", "[unused5]", "that", "he", "was", "brought", "up", "as", "a", "member", "of", "the", "Church", "of", "Scotland", "[unused6]", "[SEP]", "[unused1]", "Nothing", "[unused2]", "[unused3]", "is", "known", "[unused4]", "[unused5]", "for", "certain", "about", "his", "life", "before", "about", "158", "##0", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "brought", "up", "[unused4]", "[unused5]", "as", "a", "member", "of", "the", "Church", "of", "Scotland", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "brought", "up", "[unused4]", "[unused5]", "as", "a", "member", "of", "the", "Church", "of", "Scotland", "spent", "some", "time", "in", "A", "##rgy", "##ll", "before", "leaving", "for", "the", "Con", "##tinent", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "brought", "up", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "brought", "up", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "brought", "up", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "brought", "up", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "brought", "up", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "brought", "up", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 216:  {"source": "Obviously the epilogue was not an afterthought supplied too late for the English edition , for it is referred to in `` The Castaway '' : `` in the sequel of the narrative , it will then be seen what like abandonment befell myself . ''\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 1209, 1129, 1562, 4, 5, 1184, 1176, 25356, 1129, 27610, 1991, 1107, 1103, 8047, 1104, 1103, 8195, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 174, 8508, 12733, 2, 3, 1108, 1136, 4, 5, 1126, 1170, 1582, 26960, 7694, 1315, 1523, 1111, 1103, 1483, 2596, 117, 1111, 1122, 1110, 2752, 1106, 1107, 169, 28152, 1109, 21452, 7138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1209, 1129, 1562, 4, 5, 1184, 1176, 25356, 1129, 27610, 1991, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1209, 1129, 1562, 4, 5, 1184, 1176, 25356, 1129, 27610, 1991, 1173, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 2752, 4, 5, 1106, 1107, 1107, 1107, 1109, 21452, 7138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1209, 1129, 1562, 4, 5, 1184, 1176, 25356, 1129, 27610, 1991, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1209, 1129, 1562, 4, 5, 1184, 1176, 25356, 1129, 27610, 1991, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04651513695716858, -0.07412413507699966, -0.14125579595565796, -0.1370965838432312, -0.2291461080312729, -0.1448390930891037, -0.15015049278736115, -0.21299326419830322, -0.21292734146118164, -0.21292734146118164], "metadata": {"source_tokens": ["Obviously", "the", "e", "##pi", "##logue", "was", "not", "an", "after", "##th", "##ought", "supplied", "too", "late", "for", "the", "English", "edition", ",", "for", "it", "is", "referred", "to", "in", "`", "##`", "The", "Cast", "##away", "'", "##'", ":", "`", "##`", "in", "the", "sequel", "of", "the", "narrative", ",", "it", "will", "then", "be", "seen", "what", "like", "abandonment", "be", "##fell", "myself", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "will", "be", "seen", "[unused4]", "[unused5]", "what", "like", "abandonment", "be", "##fell", "myself", "in", "the", "sequel", "of", "the", "narrative", "[unused6]", "[SEP]", "[unused1]", "the", "e", "##pi", "##logue", "[unused2]", "[unused3]", "was", "not", "[unused4]", "[unused5]", "an", "after", "##th", "##ought", "supplied", "too", "late", "for", "the", "English", "edition", ",", "for", "it", "is", "referred", "to", "in", "`", "##`", "The", "Cast", "##away", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "will", "be", "seen", "[unused4]", "[unused5]", "what", "like", "abandonment", "be", "##fell", "myself", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "will", "be", "seen", "[unused4]", "[unused5]", "what", "like", "abandonment", "be", "##fell", "myself", "then", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "referred", "[unused4]", "[unused5]", "to", "in", "in", "in", "The", "Cast", "##away", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "will", "be", "seen", "[unused4]", "[unused5]", "what", "like", "abandonment", "be", "##fell", "myself", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "will", "be", "seen", "[unused4]", "[unused5]", "what", "like", "abandonment", "be", "##fell", "myself", "[unused6]", "[SEP]"]]}

input 217:  {"source": "Of the rest of the population , there was 1 individual who belonged to the Christian Catholic faith .\n"}
prediction:  {"predictions": [[1, 122, 2510, 2, 3, 5609, 4, 5, 1106, 1103, 2131, 2336, 5228, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00047238668776117265, -0.03882646560668945, -0.038758277893066406, -0.038758277893066406, -0.038758277893066406, -0.038758277893066406, -0.038758277893066406, -0.038758277893066406, -0.038758277893066406, -0.038758277893066406], "metadata": {"source_tokens": ["Of", "the", "rest", "of", "the", "population", ",", "there", "was", "1", "individual", "who", "belonged", "to", "the", "Christian", "Catholic", "faith", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "1", "individual", "[unused2]", "[unused3]", "belonged", "[unused4]", "[unused5]", "to", "the", "Christian", "Catholic", "faith", "[unused6]", "[SEP]"]]}

input 218:  {"source": "On 16 June 1944 , British double agent `` Garbo '' was requested by his German controllers to give information on the sites and times of V-1 impacts , with similar requests made to the other German agents in Britain , `` Brutus '' and `` Tate '' .\n"}
prediction:  {"predictions": [[1, 1418, 2702, 3677, 2, 3, 1108, 6792, 4, 5, 1118, 1117, 1528, 25747, 1106, 1660, 1869, 1113, 1103, 3911, 1105, 1551, 1104, 159, 28137, 1475, 15791, 1212, 1479, 1340, 2782, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1861, 11458, 2, 3, 1189, 4, 5, 1106, 1103, 1168, 1528, 5789, 1107, 2855, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1418, 2702, 3677, 144, 1813, 4043, 2, 3, 1108, 6792, 4, 5, 1118, 1117, 1528, 25747, 1106, 1660, 1869, 1113, 1103, 3911, 1105, 1551, 1104, 159, 28137, 1475, 15791, 1114, 1861, 11458, 1189, 1106, 1103, 1168, 1528, 5789, 1107, 2855, 139, 5082, 4814, 1105, 9727, 6, 102, 102, 102, 102, 1, 1418, 2702, 3677, 144, 1813, 4043, 2, 3, 1108, 6792, 4, 5, 1118, 1117, 1528, 25747, 1106, 1660, 1869, 1113, 1103, 3911, 1105, 1551, 1104, 159, 28137, 1475, 15791, 1114, 1861, 11458, 1189, 1106, 1103, 1168, 1528, 5789, 1107, 2855, 139, 5082, 4814, 1105, 9727, 6, 102, 102, 102, 102, 1, 1418, 2702, 3677, 144, 1813, 4043, 2, 3, 1108, 6792, 4, 5, 1118, 1117, 1528, 25747, 1106, 1660, 1869, 1113, 1103, 3911, 1105, 1551, 1104, 159, 28137, 1475, 15791, 1114, 1861, 11458, 1189, 1106, 1103, 1168, 1528, 5789, 1107, 2855, 139, 5082, 4814, 1105, 9727, 6, 102, 102, 102, 102, 1, 1418, 2702, 3677, 144, 1813, 4043, 2, 3, 1108, 6792, 4, 5, 1118, 1117, 1528, 25747, 1106, 1660, 1869, 1113, 1103, 3911, 1105, 1551, 1104, 159, 28137, 1475, 15791, 1114, 1861, 11458, 1189, 1106, 1103, 1168, 1528, 5789, 1107, 2855, 139, 5082, 4814, 1105, 9727, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0670434981584549, -0.038370974361896515, -0.06088588014245033, -0.07103271782398224, -0.08404054492712021, -0.08946899324655533, -0.29849934577941895, -0.29186296463012695, -0.29186296463012695, -0.29186296463012695], "metadata": {"source_tokens": ["On", "16", "June", "1944", ",", "British", "double", "agent", "`", "##`", "G", "##ar", "##bo", "'", "##'", "was", "requested", "by", "his", "German", "controllers", "to", "give", "information", "on", "the", "sites", "and", "times", "of", "V", "##-", "##1", "impacts", ",", "with", "similar", "requests", "made", "to", "the", "other", "German", "agents", "in", "Britain", ",", "`", "##`", "B", "##ru", "##tus", "'", "##'", "and", "`", "##`", "Tate", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "British", "double", "agent", "[unused2]", "[unused3]", "was", "requested", "[unused4]", "[unused5]", "by", "his", "German", "controllers", "to", "give", "information", "on", "the", "sites", "and", "times", "of", "V", "##-", "##1", "impacts", "On", "16", "June", "1944", "[unused6]", "[SEP]", "[unused1]", "similar", "requests", "[unused2]", "[unused3]", "made", "[unused4]", "[unused5]", "to", "the", "other", "German", "agents", "in", "Britain", "[unused6]", "[SEP]", "[unused1]", "British", "double", "agent", "G", "##ar", "##bo", "[unused2]", "[unused3]", "was", "requested", "[unused4]", "[unused5]", "by", "his", "German", "controllers", "to", "give", "information", "on", "the", "sites", "and", "times", "of", "V", "##-", "##1", "impacts", "with", "similar", "requests", "made", "to", "the", "other", "German", "agents", "in", "Britain", "B", "##ru", "##tus", "and", "Tate", "[unused6]", "[SEP]", "[unused1]", "British", "double", "agent", "G", "##ar", "##bo", "[unused2]", "[unused3]", "was", "requested", "[unused4]", "[unused5]", "by", "his", "German", "controllers", "to", "give", "information", "on", "the", "sites", "and", "times", "of", "V", "##-", "##1", "impacts", "with", "similar", "requests", "made", "to", "the", "other", "German", "agents", "in", "Britain", "B", "##ru", "##tus", "and", "Tate", "[unused6]", "[SEP]", "[unused1]", "British", "double", "agent", "G", "##ar", "##bo", "[unused2]", "[unused3]", "was", "requested", "[unused4]", "[unused5]", "by", "his", "German", "controllers", "to", "give", "information", "on", "the", "sites", "and", "times", "of", "V", "##-", "##1", "impacts", "with", "similar", "requests", "made", "to", "the", "other", "German", "agents", "in", "Britain", "B", "##ru", "##tus", "and", "Tate", "[unused6]", "[SEP]", "[unused1]", "British", "double", "agent", "G", "##ar", "##bo", "[unused2]", "[unused3]", "was", "requested", "[unused4]", "[unused5]", "by", "his", "German", "controllers", "to", "give", "information", "on", "the", "sites", "and", "times", "of", "V", "##-", "##1", "impacts", "with", "similar", "requests", "made", "to", "the", "other", "German", "agents", "in", "Britain", "B", "##ru", "##tus", "and", "Tate", "[unused6]", "[SEP]"]]}

input 219:  {"source": "On May 13 , 2010 , Yost was named manager of the Kansas City Royals , replacing Trey Hillman .\n"}
prediction:  {"predictions": [[1, 14941, 2050, 2, 3, 1108, 1417, 4, 5, 2618, 1104, 1103, 4312, 1392, 17692, 1212, 1318, 1492, 117, 1333, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 14941, 2050, 2, 3, 1108, 1417, 4, 5, 2618, 1104, 1103, 4312, 1392, 17692, 5861, 15558, 2404, 1399, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01918610744178295, -0.028417740017175674, -0.07617759704589844, -0.07630419731140137, -0.07630419731140137, -0.07630419731140137, -0.07630419731140137, -0.07630419731140137, -0.07630419731140137, -0.07630419731140137], "metadata": {"source_tokens": ["On", "May", "13", ",", "2010", ",", "Yo", "##st", "was", "named", "manager", "of", "the", "Kansas", "City", "Royals", ",", "replacing", "Trey", "Hill", "##man", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Yo", "##st", "[unused2]", "[unused3]", "was", "named", "[unused4]", "[unused5]", "manager", "of", "the", "Kansas", "City", "Royals", "On", "May", "13", ",", "2010", "[unused6]", "[SEP]", "[unused1]", "Yo", "##st", "[unused2]", "[unused3]", "was", "named", "[unused4]", "[unused5]", "manager", "of", "the", "Kansas", "City", "Royals", "replacing", "Trey", "Hill", "##man", "[unused6]", "[SEP]"]]}

input 220:  {"source": "On May 15 , 2007 , XM suspended Opie & Anthony for 30 days , in response to a broadcast featuring a homeless man who wandered into the studio .\n"}
prediction:  {"predictions": [[1, 161, 2107, 2, 3, 6232, 4, 5, 9126, 1663, 111, 4140, 1111, 1476, 1552, 1212, 1318, 1405, 117, 1384, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 3012, 2, 3, 3022, 4, 5, 170, 12501, 1299, 1150, 13668, 1154, 1103, 2362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 161, 2107, 2, 3, 6232, 4, 5, 9126, 1663, 111, 4140, 1111, 1476, 1552, 1107, 2593, 1106, 170, 3012, 3022, 170, 12501, 1299, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 161, 2107, 2, 3, 6232, 4, 5, 9126, 1663, 111, 4140, 1111, 1476, 1552, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 161, 2107, 2, 3, 6232, 4, 5, 9126, 1663, 111, 4140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 161, 2107, 2, 3, 6232, 4, 5, 9126, 1663, 111, 4140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 161, 2107, 2, 3, 6232, 4, 5, 9126, 1663, 111, 4140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04575842246413231, -0.020971188321709633, -0.055317964404821396, -0.11854241788387299, -0.13043878972530365, -0.1390114724636078, -0.1498924344778061, -0.2590315341949463, -0.2613157033920288, -0.2613157033920288], "metadata": {"source_tokens": ["On", "May", "15", ",", "2007", ",", "X", "##M", "suspended", "Op", "##ie", "&", "Anthony", "for", "30", "days", ",", "in", "response", "to", "a", "broadcast", "featuring", "a", "homeless", "man", "who", "wandered", "into", "the", "studio", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "X", "##M", "[unused2]", "[unused3]", "suspended", "[unused4]", "[unused5]", "Op", "##ie", "&", "Anthony", "for", "30", "days", "On", "May", "15", ",", "2007", "[unused6]", "[SEP]", "[unused1]", "a", "broadcast", "[unused2]", "[unused3]", "featuring", "[unused4]", "[unused5]", "a", "homeless", "man", "who", "wandered", "into", "the", "studio", "[unused6]", "[SEP]", "[unused1]", "X", "##M", "[unused2]", "[unused3]", "suspended", "[unused4]", "[unused5]", "Op", "##ie", "&", "Anthony", "for", "30", "days", "in", "response", "to", "a", "broadcast", "featuring", "a", "homeless", "man", "[unused6]", "[SEP]", "[unused1]", "X", "##M", "[unused2]", "[unused3]", "suspended", "[unused4]", "[unused5]", "Op", "##ie", "&", "Anthony", "for", "30", "days", "[unused6]", "[SEP]", "[unused1]", "X", "##M", "[unused2]", "[unused3]", "suspended", "[unused4]", "[unused5]", "Op", "##ie", "&", "Anthony", "[unused6]", "[SEP]", "[unused1]", "X", "##M", "[unused2]", "[unused3]", "suspended", "[unused4]", "[unused5]", "Op", "##ie", "&", "Anthony", "[unused6]", "[SEP]", "[unused1]", "X", "##M", "[unused2]", "[unused3]", "suspended", "[unused4]", "[unused5]", "Op", "##ie", "&", "Anthony", "[unused6]", "[SEP]"]]}

input 221:  {"source": "On November 2 , 2005 , Brown ended his contract early and left the federal government .\n"}
prediction:  {"predictions": [[1, 2671, 2, 3, 2207, 4, 5, 1117, 2329, 1346, 1105, 1286, 1103, 2877, 1433, 1212, 1379, 123, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2671, 2, 3, 1286, 4, 5, 1103, 2877, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.024066735059022903, -0.03587636351585388, -0.07604551315307617, -0.07604598999023438, -0.07604598999023438, -0.07604598999023438, -0.07604598999023438, -0.07604598999023438, -0.07604598999023438, -0.07604598999023438], "metadata": {"source_tokens": ["On", "November", "2", ",", "2005", ",", "Brown", "ended", "his", "contract", "early", "and", "left", "the", "federal", "government", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Brown", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "his", "contract", "early", "and", "left", "the", "federal", "government", "On", "November", "2", "[unused6]", "[SEP]", "[unused1]", "Brown", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "the", "federal", "government", "[unused6]", "[SEP]"]]}

input 222:  {"source": "One candidate is a wreck at the western end of Manitoulin Island in Lake Huron , with another wreck near Escanaba , Michigan , also proposed .\n"}
prediction:  {"predictions": [[1, 1448, 3234, 2, 3, 1110, 4, 5, 170, 13573, 1120, 1103, 2466, 1322, 1104, 2268, 8383, 19001, 2054, 1107, 2161, 24289, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1330, 13573, 1485, 142, 26996, 1605, 2822, 2, 3, 3000, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1448, 3234, 2, 3, 1110, 4, 5, 170, 13573, 1114, 1330, 13573, 1485, 142, 26996, 1605, 2822, 1145, 3000, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014997233636677265, -0.05368328094482422, -0.11921051144599915, -0.14975976943969727, -0.14908480644226074, -0.14908480644226074, -0.14908480644226074, -0.14908480644226074, -0.14908480644226074, -0.14908480644226074], "metadata": {"source_tokens": ["One", "candidate", "is", "a", "wreck", "at", "the", "western", "end", "of", "Man", "##ito", "##ulin", "Island", "in", "Lake", "Huron", ",", "with", "another", "wreck", "near", "E", "##sca", "##na", "##ba", ",", "Michigan", ",", "also", "proposed", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "One", "candidate", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "wreck", "at", "the", "western", "end", "of", "Man", "##ito", "##ulin", "Island", "in", "Lake", "Huron", "[unused6]", "[SEP]", "[unused1]", "another", "wreck", "near", "E", "##sca", "##na", "##ba", "[unused2]", "[unused3]", "proposed", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "One", "candidate", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "wreck", "with", "another", "wreck", "near", "E", "##sca", "##na", "##ba", "also", "proposed", "[unused6]", "[SEP]"]]}

input 223:  {"source": "One example could be `` Time '' , the fifth song from Pink Floyd 's 1973 album `` The Dark Side Of The Moon '' , which contains a reprise of `` Breathe '' , the first song of the same album .\n"}
prediction:  {"predictions": [[1, 1448, 1859, 2, 3, 1180, 1129, 4, 5, 2614, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10763, 12450, 112, 1116, 2478, 1312, 2, 3, 2515, 4, 5, 170, 1231, 16874, 1104, 169, 28152, 139, 18709, 1162, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1448, 1859, 2, 3, 1180, 1129, 4, 5, 2614, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1448, 1859, 2, 3, 1180, 1129, 4, 5, 2614, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.09100556373596191, -0.041131217032670975, -0.2408422976732254, -0.22841696441173553, -0.1324758529663086, -0.13115549087524414, -0.13115549087524414, -0.13115549087524414, -0.13115549087524414, -0.13115549087524414], "metadata": {"source_tokens": ["One", "example", "could", "be", "`", "##`", "Time", "'", "##'", ",", "the", "fifth", "song", "from", "Pink", "Floyd", "'", "##s", "1973", "album", "`", "##`", "The", "Dark", "Side", "Of", "The", "Moon", "'", "##'", ",", "which", "contains", "a", "re", "##prise", "of", "`", "##`", "B", "##reath", "##e", "'", "##'", ",", "the", "first", "song", "of", "the", "same", "album", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "One", "example", "[unused2]", "[unused3]", "could", "be", "[unused4]", "[unused5]", "Time", "[unused6]", "[SEP]", "[unused1]", "Pink", "Floyd", "'", "##s", "1973", "album", "[unused2]", "[unused3]", "contains", "[unused4]", "[unused5]", "a", "re", "##prise", "of", "`", "##`", "B", "##reath", "##e", "[unused6]", "[SEP]", "[unused1]", "One", "example", "[unused2]", "[unused3]", "could", "be", "[unused4]", "[unused5]", "Time", "[unused6]", "[SEP]", "[unused1]", "One", "example", "[unused2]", "[unused3]", "could", "be", "[unused4]", "[unused5]", "Time", "[unused6]", "[SEP]"]]}

input 224:  {"source": "Only Ballard and Williams are left after Sergeant Jericho and the other officers , along with the two train operators , are killed when they try to finish the fight .\n"}
prediction:  {"predictions": [[1, 2809, 24241, 1105, 2902, 2, 3, 1132, 1286, 4, 5, 1170, 7908, 18545, 1105, 1103, 1168, 3099, 117, 1373, 1114, 1103, 1160, 2669, 9298, 117, 1132, 1841, 1165, 1152, 2222, 1106, 3146, 1103, 2147, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 2222, 4, 5, 1106, 3146, 1103, 2147, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7908, 18545, 1105, 1103, 1168, 3099, 2, 3, 1132, 1841, 4, 5, 1165, 1152, 2222, 1106, 3146, 1103, 2147, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009378579445183277, -0.10183688253164291, -0.06785833090543747, -0.03854846954345703, -0.038546085357666016, -0.038546085357666016, -0.038546085357666016, -0.038546085357666016, -0.038546085357666016, -0.038546085357666016], "metadata": {"source_tokens": ["Only", "Ballard", "and", "Williams", "are", "left", "after", "Sergeant", "Jericho", "and", "the", "other", "officers", ",", "along", "with", "the", "two", "train", "operators", ",", "are", "killed", "when", "they", "try", "to", "finish", "the", "fight", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Only", "Ballard", "and", "Williams", "[unused2]", "[unused3]", "are", "left", "[unused4]", "[unused5]", "after", "Sergeant", "Jericho", "and", "the", "other", "officers", ",", "along", "with", "the", "two", "train", "operators", ",", "are", "killed", "when", "they", "try", "to", "finish", "the", "fight", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "try", "[unused4]", "[unused5]", "to", "finish", "the", "fight", "[unused6]", "[SEP]", "[unused1]", "Sergeant", "Jericho", "and", "the", "other", "officers", "[unused2]", "[unused3]", "are", "killed", "[unused4]", "[unused5]", "when", "they", "try", "to", "finish", "the", "fight", "[unused6]", "[SEP]"]]}

input 225:  {"source": "Opponents of religious freedom sometimes referred to it as `` Rogue 's Island '' , and Cotton Mather called it `` the sewer of New England . ''\n"}
prediction:  {"predictions": [[1, 9126, 25387, 1104, 2689, 4438, 2, 3, 2752, 4, 5, 1106, 1122, 1112, 169, 28152, 20481, 112, 1116, 2054, 2121, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12871, 15112, 1200, 2, 3, 1270, 4, 5, 1122, 1103, 27635, 1104, 1203, 1652, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02883128449320793, -0.01418689452111721, -0.0766458511352539, -0.07665324211120605, -0.07665324211120605, -0.07665324211120605, -0.07665324211120605, -0.07665324211120605, -0.07665324211120605, -0.07665324211120605], "metadata": {"source_tokens": ["Op", "##ponents", "of", "religious", "freedom", "sometimes", "referred", "to", "it", "as", "`", "##`", "Rogue", "'", "##s", "Island", "'", "##'", ",", "and", "Cotton", "Math", "##er", "called", "it", "`", "##`", "the", "sewer", "of", "New", "England", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Op", "##ponents", "of", "religious", "freedom", "[unused2]", "[unused3]", "referred", "[unused4]", "[unused5]", "to", "it", "as", "`", "##`", "Rogue", "'", "##s", "Island", "sometimes", "[unused6]", "[SEP]", "[unused1]", "Cotton", "Math", "##er", "[unused2]", "[unused3]", "called", "[unused4]", "[unused5]", "it", "the", "sewer", "of", "New", "England", "[unused6]", "[SEP]"]]}

input 226:  {"source": "Originally , Hank McCoy retains the basic features of a normal human alongside a generally simian physiology equivalent to that of a Great Ape .\n"}
prediction:  {"predictions": [[1, 8902, 17061, 2, 3, 15208, 4, 5, 1103, 3501, 1956, 1104, 170, 2999, 1769, 3338, 170, 2412, 27466, 19111, 25445, 4976, 1106, 1115, 1104, 170, 2038, 138, 3186, 5798, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8902, 17061, 2, 3, 15208, 4, 5, 1103, 3501, 1956, 1104, 170, 2999, 1769, 1106, 1115, 1104, 170, 2038, 138, 3186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005010008811950684, -0.34438395500183105, -0.07823655754327774, -0.20908784866333008, -0.21104824542999268, -0.21104824542999268, -0.21104824542999268, -0.21104824542999268, -0.21104824542999268, -0.21104824542999268], "metadata": {"source_tokens": ["Originally", ",", "Hank", "McCoy", "retains", "the", "basic", "features", "of", "a", "normal", "human", "alongside", "a", "generally", "si", "##mian", "physiology", "equivalent", "to", "that", "of", "a", "Great", "A", "##pe", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hank", "McCoy", "[unused2]", "[unused3]", "retains", "[unused4]", "[unused5]", "the", "basic", "features", "of", "a", "normal", "human", "alongside", "a", "generally", "si", "##mian", "physiology", "equivalent", "to", "that", "of", "a", "Great", "A", "##pe", "Originally", "[unused6]", "[SEP]"]]}

input 227:  {"source": "Other signs of lens subluxation include mild conjunctival redness , vitreous humour degeneration , prolapse of the vitreous into the anterior chamber , and an increase or decrease of anterior chamber depth .\n"}
prediction:  {"predictions": [[1, 2189, 5300, 1104, 11039, 4841, 24796, 1891, 2, 3, 1511, 4, 5, 10496, 14255, 20327, 15895, 1894, 1757, 117, 191, 2875, 1874, 2285, 19311, 1260, 27054, 6108, 117, 5250, 16046, 2217, 1104, 1103, 191, 2875, 1874, 2285, 1154, 1103, 16557, 5383, 117, 1105, 1126, 2773, 1137, 9711, 1104, 16557, 102, 1, 2189, 5300, 1104, 11039, 4841, 24796, 1891, 2, 3, 1511, 4, 5, 10496, 14255, 20327, 15895, 1894, 1757, 191, 2875, 1874, 2285, 19311, 1260, 27054, 6108, 5250, 16046, 2217, 1104, 1103, 191, 2875, 1874, 2285, 1154, 1103, 16557, 5383, 1105, 1126, 2773, 1137, 9711, 1104, 16557, 5383, 5415, 6, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0037585741374641657, -0.028309665620326996, -0.11955380439758301, -0.11974954605102539, -0.11974954605102539, -0.11974954605102539, -0.11974954605102539, -0.11974954605102539, -0.11974954605102539, -0.11974954605102539], "metadata": {"source_tokens": ["Other", "signs", "of", "lens", "sub", "##lux", "##ation", "include", "mild", "con", "##junct", "##ival", "red", "##ness", ",", "v", "##it", "##re", "##ous", "humour", "de", "##gene", "##ration", ",", "pro", "##lap", "##se", "of", "the", "v", "##it", "##re", "##ous", "into", "the", "anterior", "chamber", ",", "and", "an", "increase", "or", "decrease", "of", "anterior", "chamber", "depth", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Other", "signs", "of", "lens", "sub", "##lux", "##ation", "[unused2]", "[unused3]", "include", "[unused4]", "[unused5]", "mild", "con", "##junct", "##ival", "red", "##ness", ",", "v", "##it", "##re", "##ous", "humour", "de", "##gene", "##ration", ",", "pro", "##lap", "##se", "of", "the", "v", "##it", "##re", "##ous", "into", "the", "anterior", "chamber", ",", "and", "an", "increase", "or", "decrease", "of", "anterior", "[SEP]", "[unused1]", "Other", "signs", "of", "lens", "sub", "##lux", "##ation", "[unused2]", "[unused3]", "include", "[unused4]", "[unused5]", "mild", "con", "##junct", "##ival", "red", "##ness", "v", "##it", "##re", "##ous", "humour", "de", "##gene", "##ration", "pro", "##lap", "##se", "of", "the", "v", "##it", "##re", "##ous", "into", "the", "anterior", "chamber", "and", "an", "increase", "or", "decrease", "of", "anterior", "chamber", "depth", "[unused6]", "[SEP]"]]}

input 228:  {"source": "Pakistan Chrome Mines Ltd. is a mining company incorporated in the Islamic Republic of Pakistan .\n"}
prediction:  {"predictions": [[1, 3658, 20394, 11457, 18946, 4492, 2, 3, 1110, 4, 5, 170, 5463, 1419, 4572, 1107, 1103, 4769, 2250, 1104, 3658, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0013551556039601564, -0.0385890007019043, -0.03850579261779785, -0.03850579261779785, -0.03850579261779785, -0.03850579261779785, -0.03850579261779785, -0.03850579261779785, -0.03850579261779785, -0.03850579261779785], "metadata": {"source_tokens": ["Pakistan", "Ch", "##rome", "Mines", "Ltd", "##.", "is", "a", "mining", "company", "incorporated", "in", "the", "Islamic", "Republic", "of", "Pakistan", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pakistan", "Ch", "##rome", "Mines", "Ltd", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "mining", "company", "incorporated", "in", "the", "Islamic", "Republic", "of", "Pakistan", "[unused6]", "[SEP]"]]}

input 229:  {"source": "Parental investment is any expenditure of resources to benefit one offspring .\n"}
prediction:  {"predictions": [[1, 19585, 17759, 1348, 5151, 2, 3, 1110, 4, 5, 1251, 24106, 1104, 3979, 1106, 5257, 1141, 14416, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03353269770741463, -0.00023698806762695312, -0.00030040740966796875, -0.00030040740966796875, -0.00030040740966796875, -0.00030040740966796875, -0.00030040740966796875, -0.00030040740966796875, -0.00030040740966796875, -0.00030040740966796875], "metadata": {"source_tokens": ["Pa", "##rent", "##al", "investment", "is", "any", "expenditure", "of", "resources", "to", "benefit", "one", "offspring", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pa", "##rent", "##al", "investment", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "any", "expenditure", "of", "resources", "to", "benefit", "one", "offspring", "[unused6]", "[SEP]"]]}

input 230:  {"source": "Piffaro generally performs a concert series of four to five concerts a year in Philadelphia , in addition to touring throughout the United States , Canada , Europe and elsewhere .\n"}
prediction:  {"predictions": [[1, 21902, 3101, 14452, 2, 3, 2412, 10383, 4, 5, 170, 3838, 1326, 1104, 1300, 1106, 1421, 6460, 170, 1214, 1107, 3562, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21902, 3101, 14452, 2, 3, 10383, 4, 5, 170, 3838, 1326, 1104, 1300, 1106, 1421, 6460, 170, 1214, 1107, 1901, 1106, 7048, 2032, 1103, 1244, 1311, 1803, 1980, 1105, 6890, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21902, 3101, 14452, 2, 3, 10383, 4, 5, 170, 3838, 1326, 1104, 1300, 1106, 1421, 6460, 170, 1214, 1107, 1901, 1106, 7048, 2032, 1103, 1244, 1311, 1803, 1980, 1105, 6890, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006351770367473364, -0.03400978818535805, -0.06156681478023529, -0.1566983461380005, -0.15880048274993896, -0.15880048274993896, -0.15880048274993896, -0.15880048274993896, -0.15880048274993896, -0.15880048274993896], "metadata": {"source_tokens": ["Pi", "##ff", "##aro", "generally", "performs", "a", "concert", "series", "of", "four", "to", "five", "concerts", "a", "year", "in", "Philadelphia", ",", "in", "addition", "to", "touring", "throughout", "the", "United", "States", ",", "Canada", ",", "Europe", "and", "elsewhere", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pi", "##ff", "##aro", "[unused2]", "[unused3]", "generally", "performs", "[unused4]", "[unused5]", "a", "concert", "series", "of", "four", "to", "five", "concerts", "a", "year", "in", "Philadelphia", "[unused6]", "[SEP]", "[unused1]", "Pi", "##ff", "##aro", "[unused2]", "[unused3]", "performs", "[unused4]", "[unused5]", "a", "concert", "series", "of", "four", "to", "five", "concerts", "a", "year", "in", "addition", "to", "touring", "throughout", "the", "United", "States", "Canada", "Europe", "and", "elsewhere", "[unused6]", "[SEP]", "[unused1]", "Pi", "##ff", "##aro", "[unused2]", "[unused3]", "performs", "[unused4]", "[unused5]", "a", "concert", "series", "of", "four", "to", "five", "concerts", "a", "year", "in", "addition", "to", "touring", "throughout", "the", "United", "States", "Canada", "Europe", "and", "elsewhere", "[unused6]", "[SEP]"]]}

input 231:  {"source": "Plants have been planted marking parts of the foundations of the castle , so the positions of some of the buildings can still be inferred .\n"}
prediction:  {"predictions": [[1, 1103, 3638, 1104, 1199, 1104, 1103, 2275, 2, 3, 1169, 1129, 1107, 26025, 4, 5, 1253, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25880, 2, 3, 1138, 1151, 8100, 4, 5, 10079, 2192, 1104, 1103, 11217, 1104, 1103, 3804, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02582651749253273, -0.03248177841305733, -0.03854799270629883, -0.03854846954345703, -0.03854846954345703, -0.03854846954345703, -0.03854846954345703, -0.03854846954345703, -0.03854846954345703, -0.03854846954345703], "metadata": {"source_tokens": ["Plants", "have", "been", "planted", "marking", "parts", "of", "the", "foundations", "of", "the", "castle", ",", "so", "the", "positions", "of", "some", "of", "the", "buildings", "can", "still", "be", "in", "##ferred", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "positions", "of", "some", "of", "the", "buildings", "[unused2]", "[unused3]", "can", "be", "in", "##ferred", "[unused4]", "[unused5]", "still", "[unused6]", "[SEP]", "[unused1]", "Plants", "[unused2]", "[unused3]", "have", "been", "planted", "[unused4]", "[unused5]", "marking", "parts", "of", "the", "foundations", "of", "the", "castle", "[unused6]", "[SEP]"]]}

input 232:  {"source": "Prior to the 2012 season , the Royals signed Yost to a contract extension through the 2013 season .\n"}
prediction:  {"predictions": [[1, 1103, 17692, 2, 3, 1878, 4, 5, 14941, 2050, 1106, 170, 2329, 4973, 1194, 1103, 1381, 1265, 4602, 1106, 1103, 1368, 1265, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 17692, 2, 3, 1878, 4, 5, 14941, 2050, 1106, 170, 2329, 4973, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 17692, 2, 3, 1878, 4, 5, 14941, 2050, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 17692, 2, 3, 1878, 4, 5, 14941, 2050, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006117486860603094, -0.07501401752233505, -0.14102376997470856, -0.15444906055927277, -0.28776752948760986, -0.30708885192871094, -0.30708885192871094, -0.30708885192871094, -0.30708885192871094, -0.30708885192871094], "metadata": {"source_tokens": ["Prior", "to", "the", "2012", "season", ",", "the", "Royals", "signed", "Yo", "##st", "to", "a", "contract", "extension", "through", "the", "2013", "season", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Royals", "[unused2]", "[unused3]", "signed", "[unused4]", "[unused5]", "Yo", "##st", "to", "a", "contract", "extension", "through", "the", "2013", "season", "Prior", "to", "the", "2012", "season", "[unused6]", "[SEP]", "[unused1]", "the", "Royals", "[unused2]", "[unused3]", "signed", "[unused4]", "[unused5]", "Yo", "##st", "to", "a", "contract", "extension", "[unused6]", "[SEP]", "[unused1]", "the", "Royals", "[unused2]", "[unused3]", "signed", "[unused4]", "[unused5]", "Yo", "##st", "[unused6]", "[SEP]", "[unused1]", "the", "Royals", "[unused2]", "[unused3]", "signed", "[unused4]", "[unused5]", "Yo", "##st", "[unused6]", "[SEP]"]]}

input 233:  {"source": "Prior to the Playmaker tool , the Player could only call one of four available `` hot routes . ''\n"}
prediction:  {"predictions": [[1, 1103, 5348, 2, 3, 1180, 1178, 1840, 4, 5, 1141, 1104, 1300, 1907, 169, 28152, 2633, 5441, 4602, 1106, 1103, 6060, 8085, 6806, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0011022367980331182, -0.03999137878417969, -0.0391542911529541, -0.0391542911529541, -0.0391542911529541, -0.0391542911529541, -0.0391542911529541, -0.0391542911529541, -0.0391542911529541, -0.0391542911529541], "metadata": {"source_tokens": ["Prior", "to", "the", "Play", "##maker", "tool", ",", "the", "Player", "could", "only", "call", "one", "of", "four", "available", "`", "##`", "hot", "routes", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Player", "[unused2]", "[unused3]", "could", "only", "call", "[unused4]", "[unused5]", "one", "of", "four", "available", "`", "##`", "hot", "routes", "Prior", "to", "the", "Play", "##maker", "tool", "[unused6]", "[SEP]"]]}

input 234:  {"source": "Proliferative nodules are usually biopsied and are regularly but not systematically found to be benign .\n"}
prediction:  {"predictions": [[1, 5096, 14430, 15306, 6873, 11806, 2, 3, 1132, 4, 5, 1932, 25128, 3491, 4830, 1932, 25128, 3491, 4830, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5096, 14430, 15306, 6873, 11806, 2, 3, 1132, 1136, 25923, 1276, 4, 5, 1106, 1129, 26181, 11368, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.09296716004610062, -0.06798981130123138, -0.07632565498352051, -0.07632589340209961, -0.07632589340209961, -0.07632589340209961, -0.07632589340209961, -0.07632589340209961, -0.07632589340209961, -0.07632589340209961], "metadata": {"source_tokens": ["Pro", "##life", "##rative", "nod", "##ules", "are", "usually", "bio", "##ps", "##ied", "and", "are", "regularly", "but", "not", "systematically", "found", "to", "be", "ben", "##ign", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pro", "##life", "##rative", "nod", "##ules", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "usually", "bio", "##ps", "##ied", "usually", "bio", "##ps", "##ied", "[unused6]", "[SEP]", "[unused1]", "Pro", "##life", "##rative", "nod", "##ules", "[unused2]", "[unused3]", "are", "not", "systematically", "found", "[unused4]", "[unused5]", "to", "be", "ben", "##ign", "[unused6]", "[SEP]"]]}

input 235:  {"source": "RedHat engineers identified problems with ProPolice though , and in 2005 re-implemented stack-smashing protection for inclusion in GCC 4.1 .\n"}
prediction:  {"predictions": [[1, 2156, 3048, 2980, 9067, 2, 3, 3626, 4, 5, 2645, 1114, 5096, 2101, 14987, 1162, 1463, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2156, 3048, 2980, 9067, 2, 3, 3626, 4, 5, 2645, 1114, 5096, 2101, 14987, 1162, 1105, 1107, 1478, 1231, 28137, 4060, 7136, 24674, 10926, 28137, 24557, 12802, 3636, 1111, 10838, 1107, 144, 12096, 125, 28138, 1475, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.021553942933678627, -0.04464980959892273, -0.14709234237670898, -0.12560415267944336, -0.12560415267944336, -0.12560415267944336, -0.12560415267944336, -0.12560415267944336, -0.12560415267944336, -0.12560415267944336], "metadata": {"source_tokens": ["Red", "##H", "##at", "engineers", "identified", "problems", "with", "Pro", "##P", "##olic", "##e", "though", ",", "and", "in", "2005", "re", "##-", "##im", "##ple", "##mented", "stack", "##-", "##sma", "##shing", "protection", "for", "inclusion", "in", "G", "##CC", "4", "##.", "##1", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Red", "##H", "##at", "engineers", "[unused2]", "[unused3]", "identified", "[unused4]", "[unused5]", "problems", "with", "Pro", "##P", "##olic", "##e", "though", "[unused6]", "[SEP]", "[unused1]", "Red", "##H", "##at", "engineers", "[unused2]", "[unused3]", "identified", "[unused4]", "[unused5]", "problems", "with", "Pro", "##P", "##olic", "##e", "and", "in", "2005", "re", "##-", "##im", "##ple", "##mented", "stack", "##-", "##sma", "##shing", "protection", "for", "inclusion", "in", "G", "##CC", "4", "##.", "##1", "[unused6]", "[SEP]"]]}

input 236:  {"source": "Reptiles identified during surveys include marbled geckos on both island groups while the following are limited to the main island in the Northern group - four-toed earless skink , bull skinks and western brown snakes .\n"}
prediction:  {"predictions": [[1, 20777, 23677, 1116, 2, 3, 3626, 4, 5, 1219, 13634, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20777, 23677, 1116, 3626, 1219, 13634, 2, 3, 1511, 4, 5, 8004, 1181, 176, 14021, 2155, 1113, 1241, 2248, 2114, 1229, 1103, 1378, 1132, 2609, 1106, 1103, 1514, 2248, 1107, 1103, 2579, 1372, 118, 1300, 28137, 2430, 1174, 26593, 5800, 2241, 1377, 117, 12200, 2241, 4616, 1105, 2466, 3058, 102, 1, 1103, 1378, 2, 3, 1132, 2609, 4, 5, 1106, 1103, 1514, 2248, 1107, 1103, 2579, 1372, 118, 1300, 28137, 2430, 1174, 26593, 5800, 2241, 1377, 117, 12200, 2241, 4616, 1105, 2466, 3058, 14986, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03015166148543358, -0.02642856352031231, -0.028078939765691757, -0.12432384490966797, -0.12433028221130371, -0.12433028221130371, -0.12433028221130371, -0.12433028221130371, -0.12433028221130371, -0.12433028221130371], "metadata": {"source_tokens": ["Rep", "##tile", "##s", "identified", "during", "surveys", "include", "marble", "##d", "g", "##eck", "##os", "on", "both", "island", "groups", "while", "the", "following", "are", "limited", "to", "the", "main", "island", "in", "the", "Northern", "group", "-", "four", "##-", "##to", "##ed", "earl", "##ess", "skin", "##k", ",", "bull", "skin", "##ks", "and", "western", "brown", "snakes", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rep", "##tile", "##s", "[unused2]", "[unused3]", "identified", "[unused4]", "[unused5]", "during", "surveys", "[unused6]", "[SEP]", "[unused1]", "Rep", "##tile", "##s", "identified", "during", "surveys", "[unused2]", "[unused3]", "include", "[unused4]", "[unused5]", "marble", "##d", "g", "##eck", "##os", "on", "both", "island", "groups", "while", "the", "following", "are", "limited", "to", "the", "main", "island", "in", "the", "Northern", "group", "-", "four", "##-", "##to", "##ed", "earl", "##ess", "skin", "##k", ",", "bull", "skin", "##ks", "and", "western", "brown", "[SEP]", "[unused1]", "the", "following", "[unused2]", "[unused3]", "are", "limited", "[unused4]", "[unused5]", "to", "the", "main", "island", "in", "the", "Northern", "group", "-", "four", "##-", "##to", "##ed", "earl", "##ess", "skin", "##k", ",", "bull", "skin", "##ks", "and", "western", "brown", "snakes", "[unused6]", "[SEP]"]]}

input 237:  {"source": "Results like these indicate acoustic mimicry complexes , both Batesian and Mullerian , may be widespread in the auditory world .\n"}
prediction:  {"predictions": [[1, 16005, 1176, 1292, 2, 3, 5057, 4, 5, 6659, 27180, 1616, 16575, 117, 1241, 11197, 1811, 1105, 27418, 1811, 117, 1336, 1129, 6506, 1107, 1103, 23097, 4649, 1362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6659, 27180, 1616, 16575, 2, 3, 1336, 1129, 4, 5, 6506, 1107, 1103, 23097, 4649, 1362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.002765955403447151, -0.03376638889312744, -0.022003173828125, -0.022003173828125, -0.022003173828125, -0.022003173828125, -0.022003173828125, -0.022003173828125, -0.022003173828125, -0.022003173828125], "metadata": {"source_tokens": ["Results", "like", "these", "indicate", "acoustic", "mimic", "##ry", "complexes", ",", "both", "Bates", "##ian", "and", "Muller", "##ian", ",", "may", "be", "widespread", "in", "the", "audit", "##ory", "world", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Results", "like", "these", "[unused2]", "[unused3]", "indicate", "[unused4]", "[unused5]", "acoustic", "mimic", "##ry", "complexes", ",", "both", "Bates", "##ian", "and", "Muller", "##ian", ",", "may", "be", "widespread", "in", "the", "audit", "##ory", "world", "[unused6]", "[SEP]", "[unused1]", "acoustic", "mimic", "##ry", "complexes", "[unused2]", "[unused3]", "may", "be", "[unused4]", "[unused5]", "widespread", "in", "the", "audit", "##ory", "world", "[unused6]", "[SEP]"]]}

input 238:  {"source": "Returning home , Ballard delivers her report , which her superiors refuse to believe .\n"}
prediction:  {"predictions": [[1, 24241, 2, 3, 19603, 4, 5, 1123, 2592, 117, 1134, 1123, 26917, 10250, 1106, 2059, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0024331409949809313, -0.0398709774017334, -0.047507286071777344, -0.047507286071777344, -0.047507286071777344, -0.047507286071777344, -0.047507286071777344, -0.047507286071777344, -0.047507286071777344, -0.047507286071777344], "metadata": {"source_tokens": ["Returning", "home", ",", "Ballard", "delivers", "her", "report", ",", "which", "her", "superiors", "refuse", "to", "believe", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ballard", "[unused2]", "[unused3]", "delivers", "[unused4]", "[unused5]", "her", "report", ",", "which", "her", "superiors", "refuse", "to", "believe", "[unused6]", "[SEP]"]]}

input 239:  {"source": "Robert Charles `` Jack '' Russell , MBE , is a retired English international cricketer , now known for his abilities as an artist , as a cricket wicketkeeping coach , and a football goalkeeping coach .\n"}
prediction:  {"predictions": [[1, 1823, 1889, 169, 28152, 2132, 112, 28131, 5023, 2, 3, 1110, 4, 5, 170, 2623, 1483, 1835, 9469, 117, 1208, 1227, 1111, 1117, 7134, 1112, 1126, 2360, 117, 1112, 170, 5428, 13386, 14692, 2154, 117, 1105, 170, 1709, 2273, 14692, 2154, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 2623, 1483, 1835, 9469, 2, 3, 1227, 4, 5, 1111, 1117, 7134, 1112, 1126, 2360, 1208, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.011712946929037571, -0.023922313004732132, -0.12394309043884277, -0.12430167198181152, -0.12430167198181152, -0.12430167198181152, -0.12430167198181152, -0.12430167198181152, -0.12430167198181152, -0.12430167198181152], "metadata": {"source_tokens": ["Robert", "Charles", "`", "##`", "Jack", "'", "##'", "Russell", ",", "MBE", ",", "is", "a", "retired", "English", "international", "cricketer", ",", "now", "known", "for", "his", "abilities", "as", "an", "artist", ",", "as", "a", "cricket", "wicket", "##keeping", "coach", ",", "and", "a", "football", "goal", "##keeping", "coach", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Robert", "Charles", "`", "##`", "Jack", "'", "##'", "Russell", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "retired", "English", "international", "cricketer", ",", "now", "known", "for", "his", "abilities", "as", "an", "artist", ",", "as", "a", "cricket", "wicket", "##keeping", "coach", ",", "and", "a", "football", "goal", "##keeping", "coach", "[unused6]", "[SEP]", "[unused1]", "a", "retired", "English", "international", "cricketer", "[unused2]", "[unused3]", "known", "[unused4]", "[unused5]", "for", "his", "abilities", "as", "an", "artist", "now", "[unused6]", "[SEP]"]]}

input 240:  {"source": "Rosen argues that one of the most important provisions of the Constitution in Exile is limitations on the interstate commerce clause , which were undermined by the Supreme Court 's `` expansive interpretation of Congress 's power to regulate interstate commerce ... extended to include any activities that might affect commerce indirectly '' during the New Deal .\n"}
prediction:  {"predictions": [[1, 24580, 2, 3, 8935, 4, 5, 1115, 1141, 1104, 1103, 1211, 1696, 8939, 1104, 1103, 5317, 1107, 16409, 4759, 1110, 13004, 1113, 1103, 20905, 10678, 13620, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 20905, 10678, 13620, 2, 3, 1127, 1223, 15842, 4, 5, 1118, 1103, 3732, 2031, 112, 1116, 169, 28152, 4252, 10224, 8788, 7628, 1104, 2757, 112, 1116, 1540, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1251, 2619, 2, 3, 1547, 6975, 4, 5, 10678, 18814, 1219, 1103, 1203, 15361, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1141, 1104, 1103, 1211, 1696, 8939, 1104, 1103, 5317, 1107, 16409, 4759, 2, 3, 1110, 4, 5, 13004, 1113, 1103, 20905, 10678, 13620, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 20905, 10678, 13620, 2, 3, 1127, 1223, 15842, 4, 5, 1118, 1103, 3732, 2031, 112, 1116, 4252, 10224, 8788, 7628, 1104, 2757, 112, 1116, 1540, 1106, 16146, 20905, 10678, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3732, 2031, 112, 1116, 169, 28152, 4252, 10224, 8788, 7628, 1104, 2757, 112, 1116, 1540, 2, 3, 1106, 1511, 4, 5, 1251, 2619, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.015613230876624584, -0.03711085394024849, -0.07373704761266708, -0.09570781141519547, -0.13614138960838318, -0.153252512216568, -0.29061055183410645, -0.29041361808776855, -0.29041361808776855, -0.29041361808776855], "metadata": {"source_tokens": ["Rosen", "argues", "that", "one", "of", "the", "most", "important", "provisions", "of", "the", "Constitution", "in", "Ex", "##ile", "is", "limitations", "on", "the", "interstate", "commerce", "clause", ",", "which", "were", "under", "##mined", "by", "the", "Supreme", "Court", "'", "##s", "`", "##`", "ex", "##pan", "##sive", "interpretation", "of", "Congress", "'", "##s", "power", "to", "regulate", "interstate", "commerce", "...", "extended", "to", "include", "any", "activities", "that", "might", "affect", "commerce", "indirectly", "'", "##'", "during", "the", "New", "Deal", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rosen", "[unused2]", "[unused3]", "argues", "[unused4]", "[unused5]", "that", "one", "of", "the", "most", "important", "provisions", "of", "the", "Constitution", "in", "Ex", "##ile", "is", "limitations", "on", "the", "interstate", "commerce", "clause", "[unused6]", "[SEP]", "[unused1]", "the", "interstate", "commerce", "clause", "[unused2]", "[unused3]", "were", "under", "##mined", "[unused4]", "[unused5]", "by", "the", "Supreme", "Court", "'", "##s", "`", "##`", "ex", "##pan", "##sive", "interpretation", "of", "Congress", "'", "##s", "power", "[unused6]", "[SEP]", "[unused1]", "any", "activities", "[unused2]", "[unused3]", "might", "affect", "[unused4]", "[unused5]", "commerce", "indirectly", "during", "the", "New", "Deal", "[unused6]", "[SEP]", "[unused1]", "one", "of", "the", "most", "important", "provisions", "of", "the", "Constitution", "in", "Ex", "##ile", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "limitations", "on", "the", "interstate", "commerce", "clause", "[unused6]", "[SEP]", "[unused1]", "the", "interstate", "commerce", "clause", "[unused2]", "[unused3]", "were", "under", "##mined", "[unused4]", "[unused5]", "by", "the", "Supreme", "Court", "'", "##s", "ex", "##pan", "##sive", "interpretation", "of", "Congress", "'", "##s", "power", "to", "regulate", "interstate", "commerce", "[unused6]", "[SEP]", "[unused1]", "the", "Supreme", "Court", "'", "##s", "`", "##`", "ex", "##pan", "##sive", "interpretation", "of", "Congress", "'", "##s", "power", "[unused2]", "[unused3]", "to", "include", "[unused4]", "[unused5]", "any", "activities", "[unused6]", "[SEP]"]]}

input 241:  {"source": "San Francisco 's diversity of cultures along with its eccentricities are so great that they have greatly influenced the country and the world at large over the years .\n"}
prediction:  {"predictions": [[1, 1727, 2948, 112, 1116, 9531, 1104, 8708, 1373, 1114, 1157, 20276, 4233, 2, 3, 1132, 4, 5, 1177, 1632, 1115, 1152, 1138, 5958, 4401, 1103, 1583, 1105, 1103, 1362, 1120, 1415, 1166, 1103, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1138, 4401, 4, 5, 1103, 1583, 1105, 1103, 1362, 1120, 1415, 1166, 1103, 1201, 5958, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004736729431897402, -0.03246765956282616, -0.07646560668945312, -0.07646679878234863, -0.07646679878234863, -0.07646679878234863, -0.07646679878234863, -0.07646679878234863, -0.07646679878234863, -0.07646679878234863], "metadata": {"source_tokens": ["San", "Francisco", "'", "##s", "diversity", "of", "cultures", "along", "with", "its", "eccentric", "##ities", "are", "so", "great", "that", "they", "have", "greatly", "influenced", "the", "country", "and", "the", "world", "at", "large", "over", "the", "years", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "San", "Francisco", "'", "##s", "diversity", "of", "cultures", "along", "with", "its", "eccentric", "##ities", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "so", "great", "that", "they", "have", "greatly", "influenced", "the", "country", "and", "the", "world", "at", "large", "over", "the", "years", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "have", "influenced", "[unused4]", "[unused5]", "the", "country", "and", "the", "world", "at", "large", "over", "the", "years", "greatly", "[unused6]", "[SEP]"]]}

input 242:  {"source": "Scarpetta returns to Virginia in `` Trace '' , convincing herself that she was fired from her position , at the request of her replacement , Dr. Joel Marcus .\n"}
prediction:  {"predictions": [[1, 20452, 1813, 12924, 1777, 2, 3, 5166, 4, 5, 1106, 2550, 1107, 169, 28152, 22681, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1123, 5627, 2, 3, 1110, 4, 5, 1987, 28138, 8773, 6042, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20452, 1813, 12924, 1777, 2, 3, 5166, 1106, 2550, 13870, 4, 5, 1941, 1115, 1131, 1108, 4294, 1121, 1123, 1700, 117, 1120, 1103, 4566, 1104, 1123, 5627, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.08679425716400146, -0.05585305020213127, -0.08021581172943115, -0.3356616497039795, -0.21709036827087402, -0.21709036827087402, -0.21709036827087402, -0.21709036827087402, -0.21709036827087402, -0.21709036827087402], "metadata": {"source_tokens": ["Sc", "##ar", "##pet", "##ta", "returns", "to", "Virginia", "in", "`", "##`", "Trace", "'", "##'", ",", "convincing", "herself", "that", "she", "was", "fired", "from", "her", "position", ",", "at", "the", "request", "of", "her", "replacement", ",", "Dr", "##.", "Joel", "Marcus", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sc", "##ar", "##pet", "##ta", "[unused2]", "[unused3]", "returns", "[unused4]", "[unused5]", "to", "Virginia", "in", "`", "##`", "Trace", "[unused6]", "[SEP]", "[unused1]", "her", "replacement", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Dr", "##.", "Joel", "Marcus", "[unused6]", "[SEP]", "[unused1]", "Sc", "##ar", "##pet", "##ta", "[unused2]", "[unused3]", "returns", "to", "Virginia", "convincing", "[unused4]", "[unused5]", "herself", "that", "she", "was", "fired", "from", "her", "position", ",", "at", "the", "request", "of", "her", "replacement", "[unused6]", "[SEP]"]]}

input 243:  {"source": "Several isomers of octene are known , depending on the position and the geometry of the double bond in the carbon chain .\n"}
prediction:  {"predictions": [[1, 3728, 1110, 23806, 1116, 1104, 184, 5822, 7582, 2, 3, 1132, 1227, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3728, 1110, 23806, 1116, 1104, 184, 5822, 7582, 2, 3, 5763, 4, 5, 1113, 1103, 1700, 1105, 1103, 12053, 1104, 1103, 2702, 7069, 1107, 1103, 6302, 4129, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02063184604048729, -0.011229073628783226, -0.022003173828125, -0.022003173828125, -0.022003173828125, -0.022003173828125, -0.022003173828125, -0.022003173828125, -0.022003173828125, -0.022003173828125], "metadata": {"source_tokens": ["Several", "is", "##omer", "##s", "of", "o", "##ct", "##ene", "are", "known", ",", "depending", "on", "the", "position", "and", "the", "geometry", "of", "the", "double", "bond", "in", "the", "carbon", "chain", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Several", "is", "##omer", "##s", "of", "o", "##ct", "##ene", "[unused2]", "[unused3]", "are", "known", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Several", "is", "##omer", "##s", "of", "o", "##ct", "##ene", "[unused2]", "[unused3]", "depending", "[unused4]", "[unused5]", "on", "the", "position", "and", "the", "geometry", "of", "the", "double", "bond", "in", "the", "carbon", "chain", "[unused6]", "[SEP]"]]}

input 244:  {"source": "She died in October 1915 of a heart attack .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 1452, 4, 5, 1107, 1357, 4135, 1104, 170, 1762, 2035, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1153, 2, 3, 1452, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1153, 2, 3, 1452, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0001932382583618164, -0.0059611136093735695, -0.04776303842663765, -0.04787588119506836, -0.047873497009277344, -0.047873497009277344, -0.047873497009277344, -0.047873497009277344, -0.047873497009277344, -0.047873497009277344], "metadata": {"source_tokens": ["She", "died", "in", "October", "1915", "of", "a", "heart", "attack", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "died", "[unused4]", "[unused5]", "in", "October", "1915", "of", "a", "heart", "attack", "[unused6]", "[SEP]", "[unused1]", "She", "[unused2]", "[unused3]", "died", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "She", "[unused2]", "[unused3]", "died", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 245:  {"source": "She provided an audio commentary for the episode on the DVD release of the show 's third series alongside David Tennant .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 2136, 4, 5, 1126, 6056, 9068, 1111, 1103, 2004, 1113, 1103, 4173, 1836, 1104, 1103, 1437, 112, 1116, 1503, 1326, 3338, 1681, 5157, 14618, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0016787766944617033, -0.1894775629043579, -0.21314287185668945, -0.21314287185668945, -0.21314287185668945, -0.21314287185668945, -0.21314287185668945, -0.21314287185668945, -0.21314287185668945, -0.21314287185668945], "metadata": {"source_tokens": ["She", "provided", "an", "audio", "commentary", "for", "the", "episode", "on", "the", "DVD", "release", "of", "the", "show", "'", "##s", "third", "series", "alongside", "David", "Ten", "##nant", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "provided", "[unused4]", "[unused5]", "an", "audio", "commentary", "for", "the", "episode", "on", "the", "DVD", "release", "of", "the", "show", "'", "##s", "third", "series", "alongside", "David", "Ten", "##nant", "[unused6]", "[SEP]"]]}

input 246:  {"source": "She published more than 15 research publications , including International Journals , International Conferences , National Conferences , workshops and seminars .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 1502, 4, 5, 1167, 1190, 1405, 1844, 5873, 117, 1259, 1570, 3603, 1116, 117, 1570, 3047, 1116, 117, 1305, 3047, 1116, 117, 10158, 1105, 19898, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007948670536279678, -0.02187967300415039, -0.021986007690429688, -0.021986007690429688, -0.021986007690429688, -0.021986007690429688, -0.021986007690429688, -0.021986007690429688, -0.021986007690429688, -0.021986007690429688], "metadata": {"source_tokens": ["She", "published", "more", "than", "15", "research", "publications", ",", "including", "International", "Journal", "##s", ",", "International", "Conference", "##s", ",", "National", "Conference", "##s", ",", "workshops", "and", "seminars", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "published", "[unused4]", "[unused5]", "more", "than", "15", "research", "publications", ",", "including", "International", "Journal", "##s", ",", "International", "Conference", "##s", ",", "National", "Conference", "##s", ",", "workshops", "and", "seminars", "[unused6]", "[SEP]"]]}

input 247:  {"source": "She returned to that Thames River base 9 February 1931 and for the remainder of the decade served as a training ship primarily for the Submarine School at New London and occasionally for NROTC units in the southern New England area .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 1608, 4, 5, 1106, 1115, 11055, 1595, 2259, 130, 1428, 3916, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6311, 1104, 1103, 4967, 2, 3, 1462, 4, 5, 1112, 170, 2013, 2062, 3120, 1111, 1103, 26399, 1323, 1120, 1203, 1498, 1105, 5411, 1111, 151, 21564, 9481, 2338, 1107, 1103, 2359, 1203, 1652, 1298, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1153, 2, 3, 1608, 4, 5, 1106, 1115, 11055, 1595, 2259, 130, 1428, 3916, 1105, 1111, 1103, 6311, 1104, 1103, 4967, 1462, 1112, 170, 2013, 2062, 3120, 1111, 1103, 26399, 1323, 1120, 1203, 1498, 1105, 5411, 1111, 151, 21564, 9481, 2338, 1107, 1103, 2359, 1203, 1652, 1298, 6, 102, 102, 1, 1153, 2, 3, 1608, 4, 5, 1106, 1115, 11055, 1595, 2259, 130, 1428, 3916, 1105, 1111, 1103, 6311, 1104, 1103, 4967, 1462, 1112, 170, 2013, 2062, 3120, 1111, 1103, 26399, 1323, 1120, 1203, 1498, 1105, 5411, 1111, 151, 21564, 9481, 2338, 1107, 1103, 2359, 1203, 1652, 1298, 6, 102, 102, 1, 1153, 2, 3, 1608, 4, 5, 1106, 1115, 11055, 1595, 2259, 130, 1428, 3916, 1105, 1111, 1103, 6311, 1104, 1103, 4967, 1462, 1112, 170, 2013, 2062, 3120, 1111, 1103, 26399, 1323, 1120, 1203, 1498, 1105, 5411, 1111, 151, 21564, 9481, 2338, 1107, 1103, 2359, 1203, 1652, 1298, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.055889517068862915, -0.051035474985837936, -0.05242520198225975, -0.061727847903966904, -0.07395569980144501, -0.2133723497390747, -0.21335577964782715, -0.21335577964782715, -0.21335577964782715, -0.21335577964782715], "metadata": {"source_tokens": ["She", "returned", "to", "that", "Thames", "River", "base", "9", "February", "1931", "and", "for", "the", "remainder", "of", "the", "decade", "served", "as", "a", "training", "ship", "primarily", "for", "the", "Submarine", "School", "at", "New", "London", "and", "occasionally", "for", "N", "##RO", "##TC", "units", "in", "the", "southern", "New", "England", "area", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "returned", "[unused4]", "[unused5]", "to", "that", "Thames", "River", "base", "9", "February", "1931", "[unused6]", "[SEP]", "[unused1]", "the", "remainder", "of", "the", "decade", "[unused2]", "[unused3]", "served", "[unused4]", "[unused5]", "as", "a", "training", "ship", "primarily", "for", "the", "Submarine", "School", "at", "New", "London", "and", "occasionally", "for", "N", "##RO", "##TC", "units", "in", "the", "southern", "New", "England", "area", "[unused6]", "[SEP]", "[unused1]", "She", "[unused2]", "[unused3]", "returned", "[unused4]", "[unused5]", "to", "that", "Thames", "River", "base", "9", "February", "1931", "and", "for", "the", "remainder", "of", "the", "decade", "served", "as", "a", "training", "ship", "primarily", "for", "the", "Submarine", "School", "at", "New", "London", "and", "occasionally", "for", "N", "##RO", "##TC", "units", "in", "the", "southern", "New", "England", "area", "[unused6]", "[SEP]", "[unused1]", "She", "[unused2]", "[unused3]", "returned", "[unused4]", "[unused5]", "to", "that", "Thames", "River", "base", "9", "February", "1931", "and", "for", "the", "remainder", "of", "the", "decade", "served", "as", "a", "training", "ship", "primarily", "for", "the", "Submarine", "School", "at", "New", "London", "and", "occasionally", "for", "N", "##RO", "##TC", "units", "in", "the", "southern", "New", "England", "area", "[unused6]", "[SEP]", "[unused1]", "She", "[unused2]", "[unused3]", "returned", "[unused4]", "[unused5]", "to", "that", "Thames", "River", "base", "9", "February", "1931", "and", "for", "the", "remainder", "of", "the", "decade", "served", "as", "a", "training", "ship", "primarily", "for", "the", "Submarine", "School", "at", "New", "London", "and", "occasionally", "for", "N", "##RO", "##TC", "units", "in", "the", "southern", "New", "England", "area", "[unused6]", "[SEP]"]]}

input 248:  {"source": "She was ordered to be rebuilt on 9 March 1724 , and was taken in hand at Deptford Dockyard by Master Shipwright Richard Stacey .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 1108, 2802, 4, 5, 1106, 1129, 6669, 1113, 130, 1345, 19639, 1527, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1153, 2, 3, 1108, 1678, 4, 5, 1107, 1289, 1120, 3177, 6451, 2821, 20115, 8624, 1118, 3257, 12863, 12723, 2055, 21807, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1153, 2, 3, 1106, 1129, 6669, 4, 5, 1113, 130, 1345, 19639, 1527, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009960746392607689, -0.01745755411684513, -0.07941269874572754, -0.11949634552001953, -0.11947965621948242, -0.11947965621948242, -0.11947965621948242, -0.11947965621948242, -0.11947965621948242, -0.11947965621948242], "metadata": {"source_tokens": ["She", "was", "ordered", "to", "be", "rebuilt", "on", "9", "March", "172", "##4", ",", "and", "was", "taken", "in", "hand", "at", "De", "##pt", "##ford", "Dock", "##yard", "by", "Master", "Ship", "##wright", "Richard", "Stacey", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "was", "ordered", "[unused4]", "[unused5]", "to", "be", "rebuilt", "on", "9", "March", "172", "##4", "[unused6]", "[SEP]", "[unused1]", "She", "[unused2]", "[unused3]", "was", "taken", "[unused4]", "[unused5]", "in", "hand", "at", "De", "##pt", "##ford", "Dock", "##yard", "by", "Master", "Ship", "##wright", "Richard", "Stacey", "[unused6]", "[SEP]", "[unused1]", "She", "[unused2]", "[unused3]", "to", "be", "rebuilt", "[unused4]", "[unused5]", "on", "9", "March", "172", "##4", "[unused6]", "[SEP]"]]}

input 249:  {"source": "Shea was born on September 5 , 1900 in San Francisco , California .\n"}
prediction:  {"predictions": [[1, 18352, 2, 3, 1108, 1255, 4, 5, 1113, 1347, 126, 1107, 1727, 2948, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07413212209939957, -0.03220009803771973, -0.03224444389343262, -0.03224444389343262, -0.03224444389343262, -0.03224444389343262, -0.03224444389343262, -0.03224444389343262, -0.03224444389343262, -0.03224444389343262], "metadata": {"source_tokens": ["Shea", "was", "born", "on", "September", "5", ",", "1900", "in", "San", "Francisco", ",", "California", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Shea", "[unused2]", "[unused3]", "was", "born", "[unused4]", "[unused5]", "on", "September", "5", "in", "San", "Francisco", "[unused6]", "[SEP]"]]}

input 250:  {"source": "Since joining the competition in 1908 , Richmond has won ten premierships , the most recent victory being in 1980 .\n"}
prediction:  {"predictions": [[1, 6110, 2, 3, 1144, 1281, 4, 5, 1995, 18262, 1116, 1967, 4577, 1103, 2208, 1107, 4536, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1211, 2793, 2681, 2, 3, 1217, 4, 5, 1107, 2253, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03301377221941948, -0.007355791982263327, -0.03219866752624512, -0.032198429107666016, -0.032198429107666016, -0.032198429107666016, -0.032198429107666016, -0.032198429107666016, -0.032198429107666016, -0.032198429107666016], "metadata": {"source_tokens": ["Since", "joining", "the", "competition", "in", "1908", ",", "Richmond", "has", "won", "ten", "premiership", "##s", ",", "the", "most", "recent", "victory", "being", "in", "1980", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Richmond", "[unused2]", "[unused3]", "has", "won", "[unused4]", "[unused5]", "ten", "premiership", "##s", "Since", "joining", "the", "competition", "in", "1908", "[unused6]", "[SEP]", "[unused1]", "the", "most", "recent", "victory", "[unused2]", "[unused3]", "being", "[unused4]", "[unused5]", "in", "1980", "[unused6]", "[SEP]"]]}

input 251:  {"source": "Sometimes extra payments were specified by which a freed slave could liberate himself from these residual duties .\n"}
prediction:  {"predictions": [[1, 3908, 10772, 2, 3, 1127, 9467, 4, 5, 1118, 1134, 170, 11485, 6748, 1180, 181, 24851, 2193, 1471, 1121, 1292, 25399, 5078, 5875, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 11485, 6748, 2, 3, 1180, 181, 24851, 2193, 4, 5, 1471, 1121, 1292, 25399, 5078, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.001513737952336669, -0.006334035191684961, -0.038555145263671875, -0.03857994079589844, -0.03857994079589844, -0.03857994079589844, -0.03857994079589844, -0.03857994079589844, -0.03857994079589844, -0.03857994079589844], "metadata": {"source_tokens": ["Sometimes", "extra", "payments", "were", "specified", "by", "which", "a", "freed", "slave", "could", "l", "##iber", "##ate", "himself", "from", "these", "residual", "duties", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "extra", "payments", "[unused2]", "[unused3]", "were", "specified", "[unused4]", "[unused5]", "by", "which", "a", "freed", "slave", "could", "l", "##iber", "##ate", "himself", "from", "these", "residual", "duties", "Sometimes", "[unused6]", "[SEP]", "[unused1]", "a", "freed", "slave", "[unused2]", "[unused3]", "could", "l", "##iber", "##ate", "[unused4]", "[unused5]", "himself", "from", "these", "residual", "duties", "[unused6]", "[SEP]"]]}

input 252:  {"source": "Specifically , knowledge and interest in the event affects the level of personal importance for the individual , which also affects the individual 's level of emotional arousal .\n"}
prediction:  {"predictions": [[1, 1103, 2510, 2, 3, 13974, 4, 5, 1103, 2510, 112, 1116, 1634, 1104, 6438, 21019, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3044, 1105, 2199, 1107, 1103, 1856, 2, 3, 13974, 4, 5, 1103, 1634, 1104, 2357, 4495, 1111, 1103, 2510, 21325, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0185333713889122, -0.06377814710140228, -0.038506507873535156, -0.038451194763183594, -0.038451194763183594, -0.038451194763183594, -0.038451194763183594, -0.038451194763183594, -0.038451194763183594, -0.038451194763183594], "metadata": {"source_tokens": ["Specifically", ",", "knowledge", "and", "interest", "in", "the", "event", "affects", "the", "level", "of", "personal", "importance", "for", "the", "individual", ",", "which", "also", "affects", "the", "individual", "'", "##s", "level", "of", "emotional", "arousal", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "individual", "[unused2]", "[unused3]", "affects", "[unused4]", "[unused5]", "the", "individual", "'", "##s", "level", "of", "emotional", "arousal", "[unused6]", "[SEP]", "[unused1]", "knowledge", "and", "interest", "in", "the", "event", "[unused2]", "[unused3]", "affects", "[unused4]", "[unused5]", "the", "level", "of", "personal", "importance", "for", "the", "individual", "Specifically", "[unused6]", "[SEP]"]]}

input 253:  {"source": "Spennymoor Town F.C. are the main local football team and won the FA Carlsberg Vase , after winning 2-1 in the final at Wembley Stadium against Tunbridge Wells in May 2013 .\n"}
prediction:  {"predictions": [[1, 156, 11741, 3382, 19216, 2779, 143, 28138, 1658, 28138, 2, 3, 1132, 4, 5, 1103, 1514, 1469, 1709, 1264, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 156, 11741, 3382, 19216, 2779, 143, 28138, 1658, 28138, 2, 3, 1281, 4, 5, 1103, 6820, 4804, 19945, 159, 6530, 1170, 2183, 123, 28137, 1475, 1107, 1103, 1509, 1120, 17593, 3339, 1222, 17037, 24416, 7909, 1107, 1318, 1381, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 156, 11741, 3382, 19216, 2779, 143, 28138, 1658, 28138, 2, 3, 1281, 4, 5, 1103, 6820, 4804, 19945, 159, 6530, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 156, 11741, 3382, 19216, 2779, 143, 28138, 1658, 28138, 2, 3, 1281, 4, 5, 1103, 6820, 4804, 19945, 159, 6530, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02107449620962143, -0.01299954205751419, -0.041581571102142334, -0.06573627144098282, -0.316550612449646, -0.30444538593292236, -0.30444538593292236, -0.30444538593292236, -0.30444538593292236, -0.30444538593292236], "metadata": {"source_tokens": ["S", "##pen", "##ny", "##moor", "Town", "F", "##.", "##C", "##.", "are", "the", "main", "local", "football", "team", "and", "won", "the", "FA", "Carl", "##sberg", "V", "##ase", ",", "after", "winning", "2", "##-", "##1", "in", "the", "final", "at", "Wembley", "Stadium", "against", "Tu", "##nbridge", "Wells", "in", "May", "2013", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "S", "##pen", "##ny", "##moor", "Town", "F", "##.", "##C", "##.", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "the", "main", "local", "football", "team", "[unused6]", "[SEP]", "[unused1]", "S", "##pen", "##ny", "##moor", "Town", "F", "##.", "##C", "##.", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "the", "FA", "Carl", "##sberg", "V", "##ase", "after", "winning", "2", "##-", "##1", "in", "the", "final", "at", "Wembley", "Stadium", "against", "Tu", "##nbridge", "Wells", "in", "May", "2013", "[unused6]", "[SEP]", "[unused1]", "S", "##pen", "##ny", "##moor", "Town", "F", "##.", "##C", "##.", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "the", "FA", "Carl", "##sberg", "V", "##ase", "[unused6]", "[SEP]", "[unused1]", "S", "##pen", "##ny", "##moor", "Town", "F", "##.", "##C", "##.", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "the", "FA", "Carl", "##sberg", "V", "##ase", "[unused6]", "[SEP]"]]}

input 254:  {"source": "Sukhum functioned as the capital of the `` Union treaty '' Abkhaz Soviet Socialist Republic associated with the Georgian SSR from 1921 until 1931 , when it became the capital of the Abkhazian Autonomous Soviet Socialist Republic within the Georgian SSR .\n"}
prediction:  {"predictions": [[1, 15463, 9862, 1818, 2, 3, 22937, 4, 5, 1112, 1103, 2364, 1104, 1103, 169, 28152, 1913, 7274, 112, 28131, 138, 1830, 14457, 1584, 2461, 7365, 2250, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1245, 4, 5, 1103, 2364, 1104, 1103, 138, 1830, 14457, 12432, 1179, 16742, 2461, 7365, 2250, 1439, 1103, 8832, 22916, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 15463, 9862, 1818, 2, 3, 22937, 4, 5, 1112, 1103, 2364, 1104, 1103, 1913, 7274, 138, 1830, 14457, 1584, 2461, 7365, 2250, 2628, 1114, 1103, 8832, 22916, 1121, 4085, 1235, 3916, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 15463, 9862, 1818, 2, 3, 22937, 4, 5, 1112, 1103, 2364, 1104, 1103, 1913, 7274, 138, 1830, 14457, 1584, 2461, 7365, 2250, 2628, 1114, 1103, 8832, 22916, 1121, 4085, 1235, 3916, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 15463, 9862, 1818, 2, 3, 22937, 4, 5, 1112, 1103, 2364, 1104, 1103, 1913, 7274, 138, 1830, 14457, 1584, 2461, 7365, 2250, 2628, 1114, 1103, 8832, 22916, 1121, 4085, 1235, 3916, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 15463, 9862, 1818, 2, 3, 22937, 4, 5, 1112, 1103, 2364, 1104, 1103, 1913, 7274, 138, 1830, 14457, 1584, 2461, 7365, 2250, 2628, 1114, 1103, 8832, 22916, 1121, 4085, 1235, 3916, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04026508703827858, -0.051951128989458084, -0.07486584782600403, -0.08954580873250961, -0.08970297873020172, -0.09001676738262177, -0.23453259468078613, -0.2312166690826416, -0.2312166690826416, -0.2312166690826416], "metadata": {"source_tokens": ["Su", "##kh", "##um", "functioned", "as", "the", "capital", "of", "the", "`", "##`", "Union", "treaty", "'", "##'", "A", "##b", "##kha", "##z", "Soviet", "Socialist", "Republic", "associated", "with", "the", "Georgian", "SSR", "from", "1921", "until", "1931", ",", "when", "it", "became", "the", "capital", "of", "the", "A", "##b", "##kha", "##zia", "##n", "Autonomous", "Soviet", "Socialist", "Republic", "within", "the", "Georgian", "SSR", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Su", "##kh", "##um", "[unused2]", "[unused3]", "functioned", "[unused4]", "[unused5]", "as", "the", "capital", "of", "the", "`", "##`", "Union", "treaty", "'", "##'", "A", "##b", "##kha", "##z", "Soviet", "Socialist", "Republic", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "the", "capital", "of", "the", "A", "##b", "##kha", "##zia", "##n", "Autonomous", "Soviet", "Socialist", "Republic", "within", "the", "Georgian", "SSR", "[unused6]", "[SEP]", "[unused1]", "Su", "##kh", "##um", "[unused2]", "[unused3]", "functioned", "[unused4]", "[unused5]", "as", "the", "capital", "of", "the", "Union", "treaty", "A", "##b", "##kha", "##z", "Soviet", "Socialist", "Republic", "associated", "with", "the", "Georgian", "SSR", "from", "1921", "until", "1931", "[unused6]", "[SEP]", "[unused1]", "Su", "##kh", "##um", "[unused2]", "[unused3]", "functioned", "[unused4]", "[unused5]", "as", "the", "capital", "of", "the", "Union", "treaty", "A", "##b", "##kha", "##z", "Soviet", "Socialist", "Republic", "associated", "with", "the", "Georgian", "SSR", "from", "1921", "until", "1931", "[unused6]", "[SEP]", "[unused1]", "Su", "##kh", "##um", "[unused2]", "[unused3]", "functioned", "[unused4]", "[unused5]", "as", "the", "capital", "of", "the", "Union", "treaty", "A", "##b", "##kha", "##z", "Soviet", "Socialist", "Republic", "associated", "with", "the", "Georgian", "SSR", "from", "1921", "until", "1931", "[unused6]", "[SEP]", "[unused1]", "Su", "##kh", "##um", "[unused2]", "[unused3]", "functioned", "[unused4]", "[unused5]", "as", "the", "capital", "of", "the", "Union", "treaty", "A", "##b", "##kha", "##z", "Soviet", "Socialist", "Republic", "associated", "with", "the", "Georgian", "SSR", "from", "1921", "until", "1931", "[unused6]", "[SEP]"]]}

input 255:  {"source": "Superboy-Prime , seeing an opportunity to defeat the now-weakened Anti-Monitor , flew through the Anti-Monitor 's chest and hurled his shattered body into space .\n"}
prediction:  {"predictions": [[1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 4843, 4, 5, 1194, 1103, 8329, 28137, 7921, 9899, 3540, 8329, 28137, 2107, 11153, 2772, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 27060, 4, 5, 1117, 11670, 1404, 1154, 2000, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 4843, 4, 5, 3195, 1126, 3767, 1106, 3326, 1103, 1208, 28137, 7921, 9899, 3540, 8329, 28137, 2107, 11153, 2772, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 27060, 4, 5, 1117, 11670, 1404, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.045736704021692276, -0.03807670995593071, -0.10362705588340759, -0.1020592600107193, -0.30780506134033203, -0.317385196685791, -0.317385196685791, -0.317385196685791, -0.317385196685791, -0.317385196685791], "metadata": {"source_tokens": ["Super", "##boy", "##-", "##P", "##rim", "##e", ",", "seeing", "an", "opportunity", "to", "defeat", "the", "now", "##-", "##we", "##ake", "##ned", "Anti", "##-", "##M", "##oni", "##tor", ",", "flew", "through", "the", "Anti", "##-", "##M", "##oni", "##tor", "'", "##s", "chest", "and", "hurled", "his", "shattered", "body", "into", "space", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "flew", "[unused4]", "[unused5]", "through", "the", "Anti", "##-", "##we", "##ake", "##ned", "Anti", "##-", "##M", "##oni", "##tor", "[unused6]", "[SEP]", "[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "hurled", "[unused4]", "[unused5]", "his", "shattered", "body", "into", "space", "[unused6]", "[SEP]", "[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "flew", "[unused4]", "[unused5]", "seeing", "an", "opportunity", "to", "defeat", "the", "now", "##-", "##we", "##ake", "##ned", "Anti", "##-", "##M", "##oni", "##tor", "[unused6]", "[SEP]", "[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "hurled", "[unused4]", "[unused5]", "his", "shattered", "body", "[unused6]", "[SEP]"]]}

Batch 2 Test Time =  94.31025123596191  s
g_f_logprobs : 0.24672484397888184
Decodertime : 0.00016736984252929688
Decodertime : 0.00018787384033203125
g_f_logprobs : 0.05881071090698242
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.05867719650268555
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.4517972469329834
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.061697959899902344
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.058943986892700195
Decodertime : 0.00018668174743652344
g_f_logprobs : 0.05878448486328125
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.05876564979553223
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.05873560905456543
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.298830509185791
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.06176280975341797
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.05891609191894531
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.05887246131896973
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.058797359466552734
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.0587465763092041
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.2989623546600342
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.061812639236450195
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.058917999267578125
Decodertime : 0.000156402587890625
g_f_logprobs : 0.05883479118347168
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.05883312225341797
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.05870556831359863
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.298969030380249
Decodertime : 0.00014829635620117188
g_f_logprobs : 0.061794281005859375
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.058875322341918945
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.05885148048400879
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.05877518653869629
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.05874300003051758
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.2988448143005371
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.06207704544067383
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.05887866020202637
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.05881023406982422
Decodertime : 0.0001842975616455078
g_f_logprobs : 0.058717966079711914
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.05873298645019531
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.2990438938140869
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.062096357345581055
Decodertime : 0.00017023086547851562
g_f_logprobs : 0.05885457992553711
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.05886697769165039
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.058739662170410156
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.05873274803161621
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.2991299629211426
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.06204843521118164
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.058899641036987305
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.05878639221191406
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.05877232551574707
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.05871844291687012
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.29895472526550293
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.06212472915649414
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.05886411666870117
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.058794498443603516
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.05876445770263672
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.05874896049499512
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.29900240898132324
beam_search_time: 15.268364191055298 s
g_f_logprobs : 0.06183671951293945
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.037728071212768555
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.08192920684814453
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.32344865798950195
Decodertime : 0.0001747608184814453
g_f_logprobs : 0.32335448265075684
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.32337522506713867
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.32337427139282227
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.03791069984436035
beam_search_time: 4.120690107345581 s
Decodertime : 0.0001804828643798828
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.09574317932128906
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.09565114974975586
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.5814530849456787
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.09906673431396484
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.09601449966430664
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.09582185745239258
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.09564995765686035
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.340024471282959
beam_search_time: 0.9259779453277588 s
input 128:  {"source": "In 1972 , he won from Yakutpura and later in 1978 , again from Charminar .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1281, 4, 5, 1121, 14680, 4786, 1204, 24790, 1105, 1224, 1107, 2406, 1254, 1121, 24705, 9019, 2983, 1197, 1130, 2388, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1281, 4, 5, 1121, 14680, 4786, 1204, 24790, 1105, 1224, 1107, 2406, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.07893616706132889, -0.13336487114429474, -0.1441507339477539, -0.1439669132232666, -0.1439669132232666, -0.1439669132232666, -0.1439669132232666, -0.1439669132232666, -0.1439669132232666, -0.1439669132232666], "metadata": {"source_tokens": ["In", "1972", ",", "he", "won", "from", "Ya", "##ku", "##t", "##pura", "and", "later", "in", "1978", ",", "again", "from", "Cha", "##rm", "##ina", "##r", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "from", "Ya", "##ku", "##t", "##pura", "and", "later", "in", "1978", "again", "from", "Cha", "##rm", "##ina", "##r", "In", "1972", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "from", "Ya", "##ku", "##t", "##pura", "and", "later", "in", "1978", "[unused6]", "[SEP]"]]}

input 129:  {"source": "In 1972 , researchers found metallic conductivity in the charge-transfer complex TTF-TCNQ .\n"}
prediction:  {"predictions": [[1, 6962, 2, 3, 1276, 4, 5, 13256, 5880, 6366, 1107, 1103, 2965, 28137, 4487, 2316, 6732, 2703, 157, 22169, 28137, 9481, 2249, 4880, 1130, 2388, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0012753435876220465, -0.12729454040527344, -0.12865376472473145, -0.12865376472473145, -0.12865376472473145, -0.12865376472473145, -0.12865376472473145, -0.12865376472473145, -0.12865376472473145, -0.12865376472473145], "metadata": {"source_tokens": ["In", "1972", ",", "researchers", "found", "metallic", "conduct", "##ivity", "in", "the", "charge", "##-", "##tra", "##ns", "##fer", "complex", "T", "##TF", "##-", "##TC", "##N", "##Q", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "researchers", "[unused2]", "[unused3]", "found", "[unused4]", "[unused5]", "metallic", "conduct", "##ivity", "in", "the", "charge", "##-", "##tra", "##ns", "##fer", "complex", "T", "##TF", "##-", "##TC", "##N", "##Q", "In", "1972", "[unused6]", "[SEP]"]]}

input 130:  {"source": "In 1975 Barrie was directed by Lee Grant in the television movie `` For The Use Of The Hall '' as `` Charlotte '' .\n"}
prediction:  {"predictions": [[1, 21715, 1663, 2, 3, 1108, 2002, 4, 5, 1118, 2499, 4468, 1107, 1103, 1778, 2523, 1370, 1109, 11696, 2096, 1109, 1944, 112, 28131, 1112, 169, 28152, 5204, 1130, 2429, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.05186090245842934, -0.17910027503967285, -0.17990756034851074, -0.17990756034851074, -0.17990756034851074, -0.17990756034851074, -0.17990756034851074, -0.17990756034851074, -0.17990756034851074, -0.17990756034851074], "metadata": {"source_tokens": ["In", "1975", "Barr", "##ie", "was", "directed", "by", "Lee", "Grant", "in", "the", "television", "movie", "`", "##`", "For", "The", "Use", "Of", "The", "Hall", "'", "##'", "as", "`", "##`", "Charlotte", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Barr", "##ie", "[unused2]", "[unused3]", "was", "directed", "[unused4]", "[unused5]", "by", "Lee", "Grant", "in", "the", "television", "movie", "For", "The", "Use", "Of", "The", "Hall", "'", "##'", "as", "`", "##`", "Charlotte", "In", "1975", "[unused6]", "[SEP]"]]}

input 131:  {"source": "In 1977 she appeared in two television films , as the mother of Lesley Ann Warren 's character in `` 79 Park Avenue '' and as Emily McPhail in `` Tell Me My Name '' .\n"}
prediction:  {"predictions": [[1, 1131, 2, 3, 1691, 4, 5, 1107, 1160, 1778, 2441, 1112, 1103, 1534, 1104, 26801, 5083, 5407, 112, 1116, 1959, 1107, 5899, 1670, 3194, 1105, 1112, 5590, 150, 1665, 2101, 10390, 1233, 1107, 169, 28152, 4630, 2508, 1422, 10208, 1130, 2449, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1691, 4, 5, 1107, 1160, 1778, 2441, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04346664994955063, -0.1242528036236763, -0.1437664031982422, -0.14320945739746094, -0.14320945739746094, -0.14320945739746094, -0.14320945739746094, -0.14320945739746094, -0.14320945739746094, -0.14320945739746094], "metadata": {"source_tokens": ["In", "1977", "she", "appeared", "in", "two", "television", "films", ",", "as", "the", "mother", "of", "Lesley", "Ann", "Warren", "'", "##s", "character", "in", "`", "##`", "79", "Park", "Avenue", "'", "##'", "and", "as", "Emily", "M", "##c", "##P", "##hai", "##l", "in", "`", "##`", "Tell", "Me", "My", "Name", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "she", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "in", "two", "television", "films", "as", "the", "mother", "of", "Lesley", "Ann", "Warren", "'", "##s", "character", "in", "79", "Park", "Avenue", "and", "as", "Emily", "M", "##c", "##P", "##hai", "##l", "in", "`", "##`", "Tell", "Me", "My", "Name", "In", "1977", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "in", "two", "television", "films", "[unused6]", "[SEP]"]]}

input 132:  {"source": "In 1987 , Rodan became president of the American Society for Bone and Mineral Research .\n"}
prediction:  {"predictions": [[1, 11945, 1389, 2, 3, 1245, 4, 5, 2084, 1104, 1103, 1237, 2015, 1111, 17722, 1105, 9139, 4412, 2713, 1130, 2164, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0012651525903493166, -0.1659843921661377, -0.14969277381896973, -0.14969277381896973, -0.14969277381896973, -0.14969277381896973, -0.14969277381896973, -0.14969277381896973, -0.14969277381896973, -0.14969277381896973], "metadata": {"source_tokens": ["In", "1987", ",", "Rod", "##an", "became", "president", "of", "the", "American", "Society", "for", "Bone", "and", "Mine", "##ral", "Research", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rod", "##an", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "president", "of", "the", "American", "Society", "for", "Bone", "and", "Mine", "##ral", "Research", "In", "1987", "[unused6]", "[SEP]"]]}

input 133:  {"source": "In 1990 Kelsang Gyatso became also outspoken against the Geshe Studies Programme , and `` made the pursuit of his new programmes compulsory . ''\n"}
prediction:  {"predictions": [[1, 26835, 3447, 4993, 144, 2315, 2145, 1186, 2, 3, 1245, 1145, 4, 5, 25304, 1222, 1103, 144, 10654, 1162, 3829, 11512, 1130, 1997, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 3447, 4993, 144, 2315, 2145, 1186, 2, 3, 1189, 4, 5, 1103, 9542, 1104, 1117, 1207, 8473, 16472, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.021769065409898758, -0.050648439675569534, -0.15634703636169434, -0.15446734428405762, -0.15446734428405762, -0.15446734428405762, -0.15446734428405762, -0.15446734428405762, -0.15446734428405762, -0.15446734428405762], "metadata": {"source_tokens": ["In", "1990", "Ke", "##ls", "##ang", "G", "##ya", "##ts", "##o", "became", "also", "outspoken", "against", "the", "G", "##esh", "##e", "Studies", "Programme", ",", "and", "`", "##`", "made", "the", "pursuit", "of", "his", "new", "programmes", "compulsory", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ke", "##ls", "##ang", "G", "##ya", "##ts", "##o", "[unused2]", "[unused3]", "became", "also", "[unused4]", "[unused5]", "outspoken", "against", "the", "G", "##esh", "##e", "Studies", "Programme", "In", "1990", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ls", "##ang", "G", "##ya", "##ts", "##o", "[unused2]", "[unused3]", "made", "[unused4]", "[unused5]", "the", "pursuit", "of", "his", "new", "programmes", "compulsory", "[unused6]", "[SEP]"]]}

input 134:  {"source": "In 2004 the Brumbies finished at the top of the Super 12 table , six points clear of the next best team .\n"}
prediction:  {"predictions": [[1, 1103, 139, 5697, 16751, 2, 3, 1845, 4, 5, 1120, 1103, 1499, 1104, 1103, 3198, 1367, 1952, 1130, 1516, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 139, 5697, 16751, 2, 3, 1845, 4, 5, 1120, 1103, 1499, 1104, 1103, 3198, 1367, 1952, 1565, 1827, 2330, 1104, 1103, 1397, 1436, 1264, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02985907718539238, -0.030117103829979897, -0.22250056266784668, -0.22127985954284668, -0.22127985954284668, -0.22127985954284668, -0.22127985954284668, -0.22127985954284668, -0.22127985954284668, -0.22127985954284668], "metadata": {"source_tokens": ["In", "2004", "the", "B", "##rum", "##bies", "finished", "at", "the", "top", "of", "the", "Super", "12", "table", ",", "six", "points", "clear", "of", "the", "next", "best", "team", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "B", "##rum", "##bies", "[unused2]", "[unused3]", "finished", "[unused4]", "[unused5]", "at", "the", "top", "of", "the", "Super", "12", "table", "In", "2004", "[unused6]", "[SEP]", "[unused1]", "the", "B", "##rum", "##bies", "[unused2]", "[unused3]", "finished", "[unused4]", "[unused5]", "at", "the", "top", "of", "the", "Super", "12", "table", "six", "points", "clear", "of", "the", "next", "best", "team", "[unused6]", "[SEP]"]]}

input 135:  {"source": "In 2006 they applied for National League Three , finishing in 5th place and qualifying for the play-offs , where they lost to St Albans Centurions .\n"}
prediction:  {"predictions": [[1, 1152, 2, 3, 3666, 4, 5, 1111, 1305, 1453, 2677, 1130, 1386, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1575, 4, 5, 1106, 1457, 24005, 2316, 24664, 2227, 27178, 1116, 1103, 1505, 28137, 18438, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 3666, 4, 5, 1111, 1305, 1453, 2677, 4416, 1107, 4025, 1282, 1105, 6045, 1111, 1103, 1505, 28137, 18438, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 3666, 4, 5, 1111, 1305, 1453, 2677, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.055466845631599426, -0.014962654560804367, -0.1469961702823639, -0.3082852363586426, -0.1825944036245346, -0.22267603874206543, -0.22267580032348633, -0.22267580032348633, -0.22267580032348633, -0.22267580032348633], "metadata": {"source_tokens": ["In", "2006", "they", "applied", "for", "National", "League", "Three", ",", "finishing", "in", "5th", "place", "and", "qualifying", "for", "the", "play", "##-", "##offs", ",", "where", "they", "lost", "to", "St", "Alba", "##ns", "Ce", "##nt", "##urion", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "they", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "for", "National", "League", "Three", "In", "2006", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "lost", "[unused4]", "[unused5]", "to", "St", "Alba", "##ns", "Ce", "##nt", "##urion", "##s", "the", "play", "##-", "##offs", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "for", "National", "League", "Three", "finishing", "in", "5th", "place", "and", "qualifying", "for", "the", "play", "##-", "##offs", "[unused6]", "[SEP]"]]}

input 136:  {"source": "In 2007 , Sun announced `` Project Indiana '' with several goals , including providing an open source binary distribution of the OpenSolaris project , replacing SXDE .\n"}
prediction:  {"predictions": [[1, 3477, 2, 3, 1717, 4, 5, 4042, 4456, 1114, 1317, 2513, 117, 1259, 3558, 1126, 1501, 2674, 13480, 3735, 1104, 1103, 3353, 1708, 21459, 1548, 1933, 1130, 1384, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3477, 2, 3, 1717, 4, 5, 4042, 4456, 1114, 1317, 2513, 1259, 3558, 1126, 1501, 2674, 13480, 3735, 1104, 1103, 3353, 1708, 21459, 1548, 1933, 5861, 156, 3190, 20427, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.01948048174381256, -0.028054408729076385, -0.22266483306884766, -0.22270679473876953, -0.22270679473876953, -0.22270679473876953, -0.22270679473876953, -0.22270679473876953, -0.22270679473876953, -0.22270679473876953], "metadata": {"source_tokens": ["In", "2007", ",", "Sun", "announced", "`", "##`", "Project", "Indiana", "'", "##'", "with", "several", "goals", ",", "including", "providing", "an", "open", "source", "binary", "distribution", "of", "the", "Open", "##S", "##olar", "##is", "project", ",", "replacing", "S", "##X", "##DE", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sun", "[unused2]", "[unused3]", "announced", "[unused4]", "[unused5]", "Project", "Indiana", "with", "several", "goals", ",", "including", "providing", "an", "open", "source", "binary", "distribution", "of", "the", "Open", "##S", "##olar", "##is", "project", "In", "2007", "[unused6]", "[SEP]", "[unused1]", "Sun", "[unused2]", "[unused3]", "announced", "[unused4]", "[unused5]", "Project", "Indiana", "with", "several", "goals", "including", "providing", "an", "open", "source", "binary", "distribution", "of", "the", "Open", "##S", "##olar", "##is", "project", "replacing", "S", "##X", "##DE", "[unused6]", "[SEP]"]]}

input 137:  {"source": "In 2010 , scam websites co-opted a photograph of her to promote health treatments , the ubiquitous `` 1 weird old tip '' belly fat diets , and penny auctions , unauthorized usage of which Theuriau was initially unaware .\n"}
prediction:  {"predictions": [[1, 188, 24282, 12045, 2, 3, 1884, 28137, 4184, 1906, 4, 5, 170, 10110, 1104, 1123, 1106, 4609, 2332, 14115, 117, 1103, 190, 5567, 21594, 1361, 169, 28152, 122, 6994, 1385, 5580, 112, 28131, 7413, 7930, 10211, 1116, 117, 1105, 24585, 11046, 1116, 117, 8362, 24723, 13252, 2200, 7991, 1130, 102, 1, 1109, 19700, 1358, 2, 3, 1108, 4, 5, 2786, 11987, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 188, 24282, 12045, 2, 3, 1884, 28137, 4184, 1906, 4, 5, 170, 10110, 1104, 1123, 1106, 4609, 2332, 14115, 1130, 1333, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 188, 24282, 12045, 2, 3, 1884, 28137, 4184, 1906, 4, 5, 170, 10110, 1104, 1123, 1106, 4609, 2332, 14115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.058609914034605026, -0.08232006430625916, -0.05521012842655182, -0.10260140150785446, -0.22286605834960938, -0.22286701202392578, -0.22286701202392578, -0.22286701202392578, -0.22286701202392578, -0.22286701202392578], "metadata": {"source_tokens": ["In", "2010", ",", "s", "##cam", "websites", "co", "##-", "##op", "##ted", "a", "photograph", "of", "her", "to", "promote", "health", "treatments", ",", "the", "u", "##bi", "##quito", "##us", "`", "##`", "1", "weird", "old", "tip", "'", "##'", "belly", "fat", "diet", "##s", ",", "and", "penny", "auction", "##s", ",", "un", "##aut", "##hor", "##ized", "usage", "of", "which", "The", "##uria", "##u", "was", "initially", "unaware", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "s", "##cam", "websites", "[unused2]", "[unused3]", "co", "##-", "##op", "##ted", "[unused4]", "[unused5]", "a", "photograph", "of", "her", "to", "promote", "health", "treatments", ",", "the", "u", "##bi", "##quito", "##us", "`", "##`", "1", "weird", "old", "tip", "'", "##'", "belly", "fat", "diet", "##s", ",", "and", "penny", "auction", "##s", ",", "un", "##aut", "##hor", "##ized", "usage", "In", "[SEP]", "[unused1]", "The", "##uria", "##u", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "initially", "unaware", "[unused6]", "[SEP]", "[unused1]", "s", "##cam", "websites", "[unused2]", "[unused3]", "co", "##-", "##op", "##ted", "[unused4]", "[unused5]", "a", "photograph", "of", "her", "to", "promote", "health", "treatments", "In", "2010", "[unused6]", "[SEP]", "[unused1]", "s", "##cam", "websites", "[unused2]", "[unused3]", "co", "##-", "##op", "##ted", "[unused4]", "[unused5]", "a", "photograph", "of", "her", "to", "promote", "health", "treatments", "[unused6]", "[SEP]"]]}

input 138:  {"source": "In 2011 , major vendors launched several consumer-oriented motherboards using the Intel 6-series LGA 1155 chipset and AMD 9 Series AM3 + chipsets with UEFI .\n"}
prediction:  {"predictions": [[1, 1558, 19086, 2, 3, 2536, 4, 5, 1317, 8440, 28137, 9012, 22666, 1534, 13005, 1606, 1103, 15397, 127, 28137, 6906, 1905, 149, 10583, 10520, 1571, 13228, 2105, 1105, 6586, 2137, 130, 2768, 6586, 1495, 116, 13228, 6248, 1114, 158, 14663, 2240, 1130, 1349, 6, 102, 102, 102, 102, 102, 102, 1, 1558, 19086, 2, 3, 2536, 4, 5, 1317, 8440, 28137, 9012, 22666, 1534, 13005, 1606, 1103, 15397, 127, 28137, 6906, 1905, 149, 10583, 10520, 1571, 13228, 2105, 1105, 6586, 2137, 130, 2768, 6586, 1495, 116, 13228, 6248, 1114, 158, 14663, 2240, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1558, 19086, 2, 3, 2536, 4, 5, 1317, 8440, 28137, 9012, 22666, 1534, 13005, 1606, 1103, 15397, 127, 28137, 6906, 1905, 149, 10583, 10520, 1571, 13228, 2105, 1105, 6586, 2137, 130, 2768, 6586, 1495, 116, 13228, 6248, 1114, 158, 14663, 2240, 6, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.009802582673728466, -0.02977004088461399, -0.04704022407531738, -0.22269964218139648, -0.22269964218139648, -0.22269964218139648, -0.22269964218139648, -0.22269964218139648, -0.22269964218139648, -0.22269964218139648], "metadata": {"source_tokens": ["In", "2011", ",", "major", "vendors", "launched", "several", "consumer", "##-", "##ori", "##ented", "mother", "##boards", "using", "the", "Intel", "6", "##-", "##ser", "##ies", "L", "##GA", "115", "##5", "chips", "##et", "and", "AM", "##D", "9", "Series", "AM", "##3", "+", "chips", "##ets", "with", "U", "##EF", "##I", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "major", "vendors", "[unused2]", "[unused3]", "launched", "[unused4]", "[unused5]", "several", "consumer", "##-", "##ori", "##ented", "mother", "##boards", "using", "the", "Intel", "6", "##-", "##ser", "##ies", "L", "##GA", "115", "##5", "chips", "##et", "and", "AM", "##D", "9", "Series", "AM", "##3", "+", "chips", "##ets", "with", "U", "##EF", "##I", "In", "2011", "[unused6]", "[SEP]", "[unused1]", "major", "vendors", "[unused2]", "[unused3]", "launched", "[unused4]", "[unused5]", "several", "consumer", "##-", "##ori", "##ented", "mother", "##boards", "using", "the", "Intel", "6", "##-", "##ser", "##ies", "L", "##GA", "115", "##5", "chips", "##et", "and", "AM", "##D", "9", "Series", "AM", "##3", "+", "chips", "##ets", "with", "U", "##EF", "##I", "[unused6]", "[SEP]", "[unused1]", "major", "vendors", "[unused2]", "[unused3]", "launched", "[unused4]", "[unused5]", "several", "consumer", "##-", "##ori", "##ented", "mother", "##boards", "using", "the", "Intel", "6", "##-", "##ser", "##ies", "L", "##GA", "115", "##5", "chips", "##et", "and", "AM", "##D", "9", "Series", "AM", "##3", "+", "chips", "##ets", "with", "U", "##EF", "##I", "[unused6]", "[SEP]"]]}

input 139:  {"source": "In 2012 , Bloomberg Businessweek voted San Francisco as America 's Best City .\n"}
prediction:  {"predictions": [[1, 25638, 3518, 21394, 2, 3, 4751, 4, 5, 1727, 2948, 1112, 1738, 112, 1116, 1798, 1392, 1130, 1368, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.001488027162849903, -0.09817385673522949, -0.14614057540893555, -0.14614057540893555, -0.14614057540893555, -0.14614057540893555, -0.14614057540893555, -0.14614057540893555, -0.14614057540893555, -0.14614057540893555], "metadata": {"source_tokens": ["In", "2012", ",", "Bloomberg", "Business", "##week", "voted", "San", "Francisco", "as", "America", "'", "##s", "Best", "City", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Bloomberg", "Business", "##week", "[unused2]", "[unused3]", "voted", "[unused4]", "[unused5]", "San", "Francisco", "as", "America", "'", "##s", "Best", "City", "In", "2012", "[unused6]", "[SEP]"]]}

input 140:  {"source": "In 54 BC , Marcus Perperna is mentioned as one of the consulars who bore testimony on behalf of Marcus Aemilius Scaurus at his trial .\n"}
prediction:  {"predictions": [[1, 6042, 14286, 3365, 1605, 2, 3, 1110, 3025, 4, 5, 1112, 1141, 1104, 1103, 17004, 7666, 1130, 4335, 3823, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 17004, 7666, 2, 3, 8475, 4, 5, 11405, 1113, 6261, 1104, 6042, 138, 5521, 18575, 1361, 20452, 19664, 1120, 1117, 3443, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.017418958246707916, -0.015591006726026535, -0.0736544132232666, -0.1447594165802002, -0.1447594165802002, -0.1447594165802002, -0.1447594165802002, -0.1447594165802002, -0.1447594165802002, -0.1447594165802002], "metadata": {"source_tokens": ["In", "54", "BC", ",", "Marcus", "Per", "##per", "##na", "is", "mentioned", "as", "one", "of", "the", "consul", "##ars", "who", "bore", "testimony", "on", "behalf", "of", "Marcus", "A", "##em", "##ili", "##us", "Sc", "##aurus", "at", "his", "trial", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Marcus", "Per", "##per", "##na", "[unused2]", "[unused3]", "is", "mentioned", "[unused4]", "[unused5]", "as", "one", "of", "the", "consul", "##ars", "In", "54", "BC", "[unused6]", "[SEP]", "[unused1]", "the", "consul", "##ars", "[unused2]", "[unused3]", "bore", "[unused4]", "[unused5]", "testimony", "on", "behalf", "of", "Marcus", "A", "##em", "##ili", "##us", "Sc", "##aurus", "at", "his", "trial", "[unused6]", "[SEP]"]]}

input 141:  {"source": "In Canada , there are two organizations that regulate university and collegiate athletics .\n"}
prediction:  {"predictions": [[1, 1160, 3722, 2, 3, 16146, 4, 5, 2755, 1105, 14532, 11645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1160, 3722, 2, 3, 16146, 4, 5, 2755, 1105, 14532, 11645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0017441681120544672, -0.08912646770477295, -0.2618417739868164, -0.2532970905303955, -0.2532970905303955, -0.2532970905303955, -0.2532970905303955, -0.2532970905303955, -0.2532970905303955, -0.2532970905303955], "metadata": {"source_tokens": ["In", "Canada", ",", "there", "are", "two", "organizations", "that", "regulate", "university", "and", "collegiate", "athletics", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "two", "organizations", "[unused2]", "[unused3]", "regulate", "[unused4]", "[unused5]", "university", "and", "collegiate", "athletics", "[unused6]", "[SEP]", "[unused1]", "two", "organizations", "[unused2]", "[unused3]", "regulate", "[unused4]", "[unused5]", "university", "and", "collegiate", "athletics", "[unused6]", "[SEP]"]]}

input 142:  {"source": "In French , `` droit '' can mean `` the whole body of the Law '' , as in the motto `` dieu et mon droit , '' which is to say `` God and my whole body of Law . ''\n"}
prediction:  {"predictions": [[1, 173, 21418, 1204, 2, 3, 1169, 1928, 4, 5, 1103, 2006, 1404, 1104, 1103, 2601, 1112, 1107, 1103, 13658, 2939, 1358, 3084, 19863, 173, 21418, 1204, 1130, 1497, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 13658, 169, 28152, 2939, 1358, 3084, 19863, 173, 21418, 1204, 2, 3, 1110, 4, 5, 1106, 1474, 169, 28152, 1875, 1105, 1139, 2006, 1404, 1104, 2601, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.07238469272851944, -0.031920015811920166, -0.23521804809570312, -0.23261666297912598, -0.23261666297912598, -0.23261666297912598, -0.23261666297912598, -0.23261666297912598, -0.23261666297912598, -0.23261666297912598], "metadata": {"source_tokens": ["In", "French", ",", "`", "##`", "d", "##roi", "##t", "'", "##'", "can", "mean", "`", "##`", "the", "whole", "body", "of", "the", "Law", "'", "##'", ",", "as", "in", "the", "motto", "`", "##`", "die", "##u", "et", "mon", "d", "##roi", "##t", ",", "'", "##'", "which", "is", "to", "say", "`", "##`", "God", "and", "my", "whole", "body", "of", "Law", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "d", "##roi", "##t", "[unused2]", "[unused3]", "can", "mean", "[unused4]", "[unused5]", "the", "whole", "body", "of", "the", "Law", "as", "in", "the", "motto", "die", "##u", "et", "mon", "d", "##roi", "##t", "In", "French", "[unused6]", "[SEP]", "[unused1]", "the", "motto", "`", "##`", "die", "##u", "et", "mon", "d", "##roi", "##t", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "to", "say", "`", "##`", "God", "and", "my", "whole", "body", "of", "Law", "[unused6]", "[SEP]"]]}

input 143:  {"source": "In Jewish Hebrew , the Samaritans are called `` Shomronim '' , while in Samaritan Hebrew they call themselves `` Shamerim '' .\n"}
prediction:  {"predictions": [[1, 1103, 2687, 7710, 5108, 1116, 2, 3, 1132, 1270, 4, 5, 156, 25453, 3484, 4060, 1130, 2778, 6235, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1840, 4, 5, 2310, 156, 25948, 10205, 1107, 2687, 7710, 5108, 6235, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.024302681908011436, -0.023383544757962227, -0.15532803535461426, -0.2522459030151367, -0.2522456645965576, -0.2522459030151367, -0.2522459030151367, -0.2522459030151367, -0.2522459030151367, -0.2522459030151367], "metadata": {"source_tokens": ["In", "Jewish", "Hebrew", ",", "the", "Sam", "##ari", "##tan", "##s", "are", "called", "`", "##`", "S", "##hom", "##ron", "##im", "'", "##'", ",", "while", "in", "Sam", "##ari", "##tan", "Hebrew", "they", "call", "themselves", "`", "##`", "S", "##hame", "##rim", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Sam", "##ari", "##tan", "##s", "[unused2]", "[unused3]", "are", "called", "[unused4]", "[unused5]", "S", "##hom", "##ron", "##im", "In", "Jewish", "Hebrew", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "call", "[unused4]", "[unused5]", "themselves", "S", "##hame", "##rim", "in", "Sam", "##ari", "##tan", "Hebrew", "[unused6]", "[SEP]"]]}

input 144:  {"source": "In Jewish belief , its fulfilment will be revealed in the cumulation of Creation , in the era of resurrection , in the physical World .\n"}
prediction:  {"predictions": [[1, 1157, 175, 19284, 2723, 1880, 2, 3, 1209, 1129, 3090, 4, 5, 1107, 1103, 16040, 6856, 1104, 19470, 1107, 1103, 3386, 1104, 26926, 1107, 1103, 2952, 1291, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1157, 175, 19284, 2723, 1880, 2, 3, 1209, 1129, 3090, 4, 5, 1107, 1103, 16040, 6856, 1104, 19470, 1107, 1103, 3386, 1104, 26926, 1130, 2778, 6369, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04943753778934479, -0.06356871873140335, -0.14531683921813965, -0.14516425132751465, -0.14516425132751465, -0.14516425132751465, -0.14516425132751465, -0.14516425132751465, -0.14516425132751465, -0.14516425132751465], "metadata": {"source_tokens": ["In", "Jewish", "belief", ",", "its", "f", "##ulf", "##il", "##ment", "will", "be", "revealed", "in", "the", "cum", "##ulation", "of", "Creation", ",", "in", "the", "era", "of", "resurrection", ",", "in", "the", "physical", "World", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "its", "f", "##ulf", "##il", "##ment", "[unused2]", "[unused3]", "will", "be", "revealed", "[unused4]", "[unused5]", "in", "the", "cum", "##ulation", "of", "Creation", "in", "the", "era", "of", "resurrection", "in", "the", "physical", "World", "[unused6]", "[SEP]", "[unused1]", "its", "f", "##ulf", "##il", "##ment", "[unused2]", "[unused3]", "will", "be", "revealed", "[unused4]", "[unused5]", "in", "the", "cum", "##ulation", "of", "Creation", "in", "the", "era", "of", "resurrection", "In", "Jewish", "belief", "[unused6]", "[SEP]"]]}

input 145:  {"source": "In June , Nasser took control of the interior ministry post from Naguib loyalist Sulayman Hafez , and pressured Naguib to conclude the abolition of the monarchy .\n"}
prediction:  {"predictions": [[1, 11896, 14607, 2, 3, 1261, 4, 5, 1654, 1104, 1103, 4604, 8382, 2112, 1121, 11896, 13830, 13292, 9125, 1776, 27040, 25939, 11679, 8124, 1584, 1130, 1340, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11896, 14607, 2, 3, 2997, 1181, 4, 5, 11896, 13830, 13292, 1106, 17581, 1103, 18304, 1104, 1103, 14358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11896, 14607, 2, 3, 1106, 17581, 4, 5, 1103, 18304, 1104, 1103, 14358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.01801111362874508, -0.0055401511490345, -0.04971660301089287, -0.16435527801513672, -0.16129064559936523, -0.16129064559936523, -0.16129064559936523, -0.16129064559936523, -0.16129064559936523, -0.16129064559936523], "metadata": {"source_tokens": ["In", "June", ",", "Na", "##sser", "took", "control", "of", "the", "interior", "ministry", "post", "from", "Na", "##gu", "##ib", "loyal", "##ist", "Sul", "##ayman", "Ha", "##fe", "##z", ",", "and", "pressure", "##d", "Na", "##gu", "##ib", "to", "conclude", "the", "abolition", "of", "the", "monarchy", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "control", "of", "the", "interior", "ministry", "post", "from", "Na", "##gu", "##ib", "loyal", "##ist", "Sul", "##ayman", "Ha", "##fe", "##z", "In", "June", "[unused6]", "[SEP]", "[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "pressure", "##d", "[unused4]", "[unused5]", "Na", "##gu", "##ib", "to", "conclude", "the", "abolition", "of", "the", "monarchy", "[unused6]", "[SEP]", "[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "to", "conclude", "[unused4]", "[unused5]", "the", "abolition", "of", "the", "monarchy", "[unused6]", "[SEP]"]]}

input 146:  {"source": "In October 2009 it was confirmed that the Byrom Street cutting was a hitching and unhitching point for trains being cable hauled to Edge Hill via the Victoria Tunnel .\n"}
prediction:  {"predictions": [[1, 1103, 1650, 16071, 1715, 5910, 2, 3, 1108, 4, 5, 170, 1855, 7520, 1105, 8362, 17481, 7520, 1553, 1111, 3918, 1217, 6095, 13486, 1106, 10403, 2404, 2258, 1103, 3006, 12872, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3918, 2, 3, 1217, 4, 5, 6095, 13486, 1106, 10403, 2404, 2258, 1103, 3006, 12872, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 3659, 4, 5, 1115, 1103, 1650, 16071, 1715, 5910, 1108, 170, 1855, 7520, 1105, 8362, 17481, 7520, 1553, 1111, 3918, 1217, 6095, 13486, 1106, 10403, 2404, 2258, 1103, 3006, 12872, 1130, 1357, 1371, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03316439688205719, -0.08342123031616211, -0.0429387167096138, -0.22266125679016113, -0.22266101837158203, -0.22266101837158203, -0.22266101837158203, -0.22266101837158203, -0.22266101837158203, -0.22266101837158203], "metadata": {"source_tokens": ["In", "October", "2009", "it", "was", "confirmed", "that", "the", "By", "##rom", "Street", "cutting", "was", "a", "hit", "##ching", "and", "un", "##hit", "##ching", "point", "for", "trains", "being", "cable", "hauled", "to", "Edge", "Hill", "via", "the", "Victoria", "Tunnel", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "By", "##rom", "Street", "cutting", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "hit", "##ching", "and", "un", "##hit", "##ching", "point", "for", "trains", "being", "cable", "hauled", "to", "Edge", "Hill", "via", "the", "Victoria", "Tunnel", "[unused6]", "[SEP]", "[unused1]", "trains", "[unused2]", "[unused3]", "being", "[unused4]", "[unused5]", "cable", "hauled", "to", "Edge", "Hill", "via", "the", "Victoria", "Tunnel", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "confirmed", "[unused4]", "[unused5]", "that", "the", "By", "##rom", "Street", "cutting", "was", "a", "hit", "##ching", "and", "un", "##hit", "##ching", "point", "for", "trains", "being", "cable", "hauled", "to", "Edge", "Hill", "via", "the", "Victoria", "Tunnel", "In", "October", "2009", "[unused6]", "[SEP]"]]}

input 147:  {"source": "In September 1941 , she joined the Women 's Auxiliary Air Force , working at the Department of the Chief of Air Staff as Assistant Section Officer for Intelligence duties , before being posted in July 1942 to Moreton-in-Marsh , where she was promoted to Section officer .\n"}
prediction:  {"predictions": [[1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1130, 1347, 3018, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1108, 3082, 4, 5, 1106, 6177, 2575, 3046, 1633, 28137, 1394, 28137, 2107, 7666, 1324, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1684, 1120, 1103, 1951, 1104, 1103, 2534, 1104, 1806, 5949, 1112, 5414, 6177, 4124, 1111, 7829, 5078, 1196, 1217, 6310, 1107, 1351, 2889, 1106, 3046, 1633, 28137, 1394, 28137, 2107, 7666, 1324, 6, 102, 102, 102, 102, 1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1684, 1120, 1103, 1951, 1104, 1103, 2534, 1104, 1806, 5949, 1112, 5414, 6177, 4124, 1111, 7829, 5078, 1196, 1217, 6310, 1107, 1351, 2889, 1106, 3046, 1633, 28137, 1394, 28137, 2107, 7666, 1324, 6, 102, 102, 1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1684, 1120, 1103, 1951, 1104, 1103, 2534, 1104, 1806, 5949, 1112, 5414, 6177, 4124, 1111, 7829, 5078, 1196, 1217, 6310, 1107, 1351, 2889, 1106, 3046, 1633, 28137, 1394, 28137, 2107, 7666, 1324, 6, 102, 102, 1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1684, 1120, 1103, 1951, 1104, 1103, 2534, 1104, 1806, 5949, 1112, 5414, 6177, 4124, 1111, 7829, 5078, 1196, 1217, 6310, 1107, 1351, 2889, 1106, 3046, 1633, 28137, 1394, 28137, 2107, 7666, 1324, 6, 102, 102, 1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1684, 1120, 1103, 1951, 1104, 1103, 2534, 1104, 1806, 5949, 1112, 5414, 6177, 4124, 1111, 7829, 5078, 1196, 1217, 6310, 1107, 1351, 2889, 1106, 3046, 1633, 28137, 1394, 28137, 2107, 7666, 1324, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1131, 2, 3, 1688, 4, 5, 1103, 2453, 112, 1116, 18102, 1806, 2300, 1684, 1120, 1103, 1951, 1104, 1103, 2534, 1104, 1806, 5949, 1112, 5414, 6177, 4124, 1111, 7829, 5078, 1196, 1217, 6310, 1107, 1351, 2889, 1106, 3046, 1633, 28137, 1394, 28137, 2107, 7666, 1324, 6, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.05402301996946335, -0.025266917422413826, -0.027440065518021584, -0.03723004832863808, -0.044162359088659286, -0.05034884810447693, -0.0631779208779335, -0.32706356048583984, -0.07213719934225082, -0.22284412384033203], "metadata": {"source_tokens": ["In", "September", "1941", ",", "she", "joined", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", ",", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", ",", "before", "being", "posted", "in", "July", "1942", "to", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", ",", "where", "she", "was", "promoted", "to", "Section", "officer", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "In", "September", "1941", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "was", "promoted", "[unused4]", "[unused5]", "to", "Section", "officer", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", "before", "being", "posted", "in", "July", "1942", "to", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", "before", "being", "posted", "in", "July", "1942", "to", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", "before", "being", "posted", "in", "July", "1942", "to", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", "before", "being", "posted", "in", "July", "1942", "to", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", "[unused6]", "[SEP]", "[unused1]", "she", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Women", "'", "##s", "Auxiliary", "Air", "Force", "working", "at", "the", "Department", "of", "the", "Chief", "of", "Air", "Staff", "as", "Assistant", "Section", "Officer", "for", "Intelligence", "duties", "before", "being", "posted", "in", "July", "1942", "to", "More", "##ton", "##-", "##in", "##-", "##M", "##ars", "##h", "[unused6]", "[SEP]"]]}

input 148:  {"source": "In Van Howe 's study , all cases of meatal stenosis were among circumcised boys .\n"}
prediction:  {"predictions": [[1, 1155, 2740, 1104, 6092, 1348, 188, 5208, 11776, 2, 3, 1127, 4, 5, 1621, 172, 3161, 19172, 14636, 1181, 3287, 1130, 3605, 13724, 112, 1116, 2025, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0007334413239732385, -0.22268009185791016, -0.22267842292785645, -0.22267842292785645, -0.22267842292785645, -0.22267842292785645, -0.22267842292785645, -0.22267842292785645, -0.22267842292785645, -0.22267842292785645], "metadata": {"source_tokens": ["In", "Van", "Howe", "'", "##s", "study", ",", "all", "cases", "of", "meat", "##al", "s", "##ten", "##osis", "were", "among", "c", "##ir", "##cum", "##cise", "##d", "boys", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "all", "cases", "of", "meat", "##al", "s", "##ten", "##osis", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "among", "c", "##ir", "##cum", "##cise", "##d", "boys", "In", "Van", "Howe", "'", "##s", "study", "[unused6]", "[SEP]"]]}

input 149:  {"source": "In `` The Andromeda Strain '' , Michael Crichton 's first novel published under his real name , only two people exposed to a pathogenic extraterrestrial microbe survive .\n"}
prediction:  {"predictions": [[1, 1847, 140, 10886, 1633, 112, 1116, 1148, 2281, 2, 3, 1502, 4, 5, 1223, 1117, 1842, 1271, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1178, 1160, 1234, 5490, 1106, 170, 3507, 17960, 3908, 2083, 14201, 13119, 17599, 3962, 2, 3, 5195, 4, 5, 1130, 169, 28152, 1109, 1262, 11457, 1810, 1457, 11098, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1178, 1160, 1234, 2, 3, 5490, 4, 5, 1106, 170, 3507, 17960, 3908, 2083, 14201, 13119, 17599, 3962, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.031976938247680664, -0.035935815423727036, -0.04604126140475273, -0.14506244659423828, -0.14504551887512207, -0.14504551887512207, -0.14504551887512207, -0.14504551887512207, -0.14504551887512207, -0.14504551887512207], "metadata": {"source_tokens": ["In", "`", "##`", "The", "And", "##rome", "##da", "St", "##rain", "'", "##'", ",", "Michael", "C", "##rich", "##ton", "'", "##s", "first", "novel", "published", "under", "his", "real", "name", ",", "only", "two", "people", "exposed", "to", "a", "path", "##ogenic", "extra", "##ter", "##rest", "##rial", "micro", "##be", "survive", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Michael", "C", "##rich", "##ton", "'", "##s", "first", "novel", "[unused2]", "[unused3]", "published", "[unused4]", "[unused5]", "under", "his", "real", "name", "[unused6]", "[SEP]", "[unused1]", "only", "two", "people", "exposed", "to", "a", "path", "##ogenic", "extra", "##ter", "##rest", "##rial", "micro", "##be", "[unused2]", "[unused3]", "survive", "[unused4]", "[unused5]", "In", "`", "##`", "The", "And", "##rome", "##da", "St", "##rain", "[unused6]", "[SEP]", "[unused1]", "only", "two", "people", "[unused2]", "[unused3]", "exposed", "[unused4]", "[unused5]", "to", "a", "path", "##ogenic", "extra", "##ter", "##rest", "##rial", "micro", "##be", "[unused6]", "[SEP]"]]}

input 150:  {"source": "In a news post , Holkins stated that he reserved the right to bring Carl back any time Krahulik goes to France .\n"}
prediction:  {"predictions": [[1, 9800, 10493, 4935, 2, 3, 2202, 4, 5, 1115, 1119, 9142, 1103, 1268, 1106, 2498, 4804, 1171, 1251, 1159, 148, 10659, 15818, 1377, 2947, 1106, 1699, 1130, 170, 2371, 2112, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 9142, 4, 5, 1103, 1268, 1106, 2498, 4804, 1171, 1251, 1159, 148, 10659, 15818, 1377, 2947, 1106, 1699, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 148, 10659, 15818, 1377, 2, 3, 2947, 4, 5, 1106, 1699, 1251, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03939631208777428, -0.053268253803253174, -0.03629203885793686, -0.24283790588378906, -0.22470426559448242, -0.22470426559448242, -0.22470426559448242, -0.22470426559448242, -0.22470426559448242, -0.22470426559448242], "metadata": {"source_tokens": ["In", "a", "news", "post", ",", "Ho", "##lk", "##ins", "stated", "that", "he", "reserved", "the", "right", "to", "bring", "Carl", "back", "any", "time", "K", "##rah", "##uli", "##k", "goes", "to", "France", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ho", "##lk", "##ins", "[unused2]", "[unused3]", "stated", "[unused4]", "[unused5]", "that", "he", "reserved", "the", "right", "to", "bring", "Carl", "back", "any", "time", "K", "##rah", "##uli", "##k", "goes", "to", "France", "In", "a", "news", "post", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "reserved", "[unused4]", "[unused5]", "the", "right", "to", "bring", "Carl", "back", "any", "time", "K", "##rah", "##uli", "##k", "goes", "to", "France", "[unused6]", "[SEP]", "[unused1]", "K", "##rah", "##uli", "##k", "[unused2]", "[unused3]", "goes", "[unused4]", "[unused5]", "to", "France", "any", "time", "[unused6]", "[SEP]"]]}

input 151:  {"source": "In a typical case of substrate interference , a Language A occupies a given territory and another Language B arrives in the same territory .\n"}
prediction:  {"predictions": [[1, 1330, 6828, 139, 2, 3, 8121, 4, 5, 1107, 1103, 1269, 3441, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 6828, 138, 2, 3, 14679, 4, 5, 170, 1549, 3441, 1130, 170, 4701, 1692, 1104, 17498, 11364, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.044492483139038086, -0.004976675845682621, -0.05116105079650879, -0.055756330490112305, -0.055756330490112305, -0.055756330490112305, -0.055756330490112305, -0.055756330490112305, -0.055756330490112305, -0.055756330490112305], "metadata": {"source_tokens": ["In", "a", "typical", "case", "of", "substrate", "interference", ",", "a", "Language", "A", "occupies", "a", "given", "territory", "and", "another", "Language", "B", "arrives", "in", "the", "same", "territory", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "another", "Language", "B", "[unused2]", "[unused3]", "arrives", "[unused4]", "[unused5]", "in", "the", "same", "territory", "[unused6]", "[SEP]", "[unused1]", "a", "Language", "A", "[unused2]", "[unused3]", "occupies", "[unused4]", "[unused5]", "a", "given", "territory", "In", "a", "typical", "case", "of", "substrate", "interference", "[unused6]", "[SEP]"]]}

input 152:  {"source": "In addition , as John Cecil Masterman , chairman of the Twenty Committee , commented , `` If , for example , St Paul 's Cathedral were hit , it was useless and harmful to report that the bomb had descended upon a cinema in Islington , since the truth would inevitably get through to Germany ... ''\n"}
prediction:  {"predictions": [[1, 1287, 12091, 3257, 1399, 2, 3, 6454, 4, 5, 1409, 117, 1111, 1859, 117, 1457, 1795, 112, 1116, 5761, 1127, 1855, 117, 1122, 1108, 12277, 1105, 19403, 1106, 2592, 1115, 1103, 5985, 1125, 9026, 1852, 170, 7678, 1107, 2181, 21103, 117, 1290, 1103, 3062, 1156, 25315, 1243, 1194, 1106, 102, 1, 1287, 12091, 3257, 1399, 2, 3, 1110, 3931, 1104, 4, 5, 1103, 7714, 2341, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3062, 2, 3, 1156, 1243, 4, 5, 1194, 1106, 1860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1457, 1795, 112, 1116, 5761, 2, 3, 1127, 1855, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 12277, 1105, 19403, 1106, 2592, 1115, 1103, 5985, 1125, 9026, 1852, 170, 7678, 1107, 2181, 21103, 1290, 1103, 3062, 1156, 25315, 1243, 1194, 1106, 1860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3062, 2, 3, 1156, 1243, 4, 5, 1194, 1106, 1860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 12277, 1105, 19403, 1106, 2592, 1115, 1103, 5985, 1125, 9026, 1852, 170, 7678, 1107, 2181, 21103, 1290, 1103, 3062, 1156, 25315, 1243, 1194, 1106, 1860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 12277, 1105, 19403, 1106, 2592, 1115, 1103, 5985, 1125, 9026, 1852, 170, 7678, 1107, 2181, 21103, 1290, 1103, 3062, 1156, 25315, 1243, 1194, 1106, 1860, 6, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 12277, 1105, 19403, 1106, 2592, 1115, 1103, 5985, 1125, 9026, 1852, 170, 7678, 1107, 2181, 21103, 1290, 1103, 3062, 1156, 25315, 1243, 1194, 1106, 1860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03408430889248848, -0.07105477899312973, -0.10656072944402695, -0.0891563892364502, -0.07510025054216385, -0.18094952404499054, -0.08515915274620056, -0.09547077119350433, -0.11236212402582169, -0.2316901683807373], "metadata": {"source_tokens": ["In", "addition", ",", "as", "John", "Cecil", "Master", "##man", ",", "chairman", "of", "the", "Twenty", "Committee", ",", "commented", ",", "`", "##`", "If", ",", "for", "example", ",", "St", "Paul", "'", "##s", "Cathedral", "were", "hit", ",", "it", "was", "useless", "and", "harmful", "to", "report", "that", "the", "bomb", "had", "descended", "upon", "a", "cinema", "in", "Is", "##lington", ",", "since", "the", "truth", "would", "inevitably", "get", "through", "to", "Germany", "...", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "John", "Cecil", "Master", "##man", "[unused2]", "[unused3]", "commented", "[unused4]", "[unused5]", "If", ",", "for", "example", ",", "St", "Paul", "'", "##s", "Cathedral", "were", "hit", ",", "it", "was", "useless", "and", "harmful", "to", "report", "that", "the", "bomb", "had", "descended", "upon", "a", "cinema", "in", "Is", "##lington", ",", "since", "the", "truth", "would", "inevitably", "get", "through", "to", "[SEP]", "[unused1]", "John", "Cecil", "Master", "##man", "[unused2]", "[unused3]", "is", "chairman", "of", "[unused4]", "[unused5]", "the", "Twenty", "Committee", "[unused6]", "[SEP]", "[unused1]", "the", "truth", "[unused2]", "[unused3]", "would", "get", "[unused4]", "[unused5]", "through", "to", "Germany", "[unused6]", "[SEP]", "[unused1]", "St", "Paul", "'", "##s", "Cathedral", "[unused2]", "[unused3]", "were", "hit", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "useless", "and", "harmful", "to", "report", "that", "the", "bomb", "had", "descended", "upon", "a", "cinema", "in", "Is", "##lington", "since", "the", "truth", "would", "inevitably", "get", "through", "to", "Germany", "[unused6]", "[SEP]", "[unused1]", "the", "truth", "[unused2]", "[unused3]", "would", "get", "[unused4]", "[unused5]", "through", "to", "Germany", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "useless", "and", "harmful", "to", "report", "that", "the", "bomb", "had", "descended", "upon", "a", "cinema", "in", "Is", "##lington", "since", "the", "truth", "would", "inevitably", "get", "through", "to", "Germany", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "useless", "and", "harmful", "to", "report", "that", "the", "bomb", "had", "descended", "upon", "a", "cinema", "in", "Is", "##lington", "since", "the", "truth", "would", "inevitably", "get", "through", "to", "Germany", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "useless", "and", "harmful", "to", "report", "that", "the", "bomb", "had", "descended", "upon", "a", "cinema", "in", "Is", "##lington", "since", "the", "truth", "would", "inevitably", "get", "through", "to", "Germany", "[unused6]", "[SEP]"]]}

input 153:  {"source": "In athletics , Boston College left the Big East Conference and joined the Atlantic Coast Conference on July 1 , 2005 .\n"}
prediction:  {"predictions": [[1, 2859, 1531, 2, 3, 1286, 4, 5, 1103, 2562, 1689, 3047, 1130, 11645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2859, 1531, 2, 3, 1688, 4, 5, 1103, 3608, 3331, 3047, 1113, 1351, 122, 117, 1478, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2859, 1531, 2, 3, 1688, 4, 5, 1103, 3608, 3331, 3047, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.016796737909317017, -0.008190161548554897, -0.0776330828666687, -0.14433884620666504, -0.14160609245300293, -0.14160609245300293, -0.14160609245300293, -0.14160609245300293, -0.14160609245300293, -0.14160609245300293], "metadata": {"source_tokens": ["In", "athletics", ",", "Boston", "College", "left", "the", "Big", "East", "Conference", "and", "joined", "the", "Atlantic", "Coast", "Conference", "on", "July", "1", ",", "2005", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Boston", "College", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "the", "Big", "East", "Conference", "In", "athletics", "[unused6]", "[SEP]", "[unused1]", "Boston", "College", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Atlantic", "Coast", "Conference", "on", "July", "1", ",", "2005", "[unused6]", "[SEP]", "[unused1]", "Boston", "College", "[unused2]", "[unused3]", "joined", "[unused4]", "[unused5]", "the", "Atlantic", "Coast", "Conference", "[unused6]", "[SEP]"]]}

input 154:  {"source": "In both cases this specialized function replaces the basic rifleman position in the fireteam .\n"}
prediction:  {"predictions": [[1, 1142, 7623, 3053, 2, 3, 22974, 4, 5, 1103, 3501, 6658, 1399, 1700, 1107, 1103, 1783, 1566, 2312, 1130, 1241, 2740, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0012056430568918586, -0.17106270790100098, -0.30310988426208496, -0.30310988426208496, -0.30310988426208496, -0.30310988426208496, -0.30310988426208496, -0.30310988426208496, -0.30310988426208496, -0.30310988426208496], "metadata": {"source_tokens": ["In", "both", "cases", "this", "specialized", "function", "replaces", "the", "basic", "rifle", "##man", "position", "in", "the", "fire", "##te", "##am", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "this", "specialized", "function", "[unused2]", "[unused3]", "replaces", "[unused4]", "[unused5]", "the", "basic", "rifle", "##man", "position", "in", "the", "fire", "##te", "##am", "In", "both", "cases", "[unused6]", "[SEP]"]]}

input 155:  {"source": "In fact , Condon , after seeing Hauptmann in a lineup at New York Police Department Greenwich Street Station told FBI Special Agent Turrou that Hauptmann was not `` John , '' the man to whom Condon claimed he passed the ransom money to in St. Raymond 's Cemetery .\n"}
prediction:  {"predictions": [[1, 16752, 3842, 2, 3, 1500, 4, 5, 8099, 3139, 9341, 17037, 13656, 1358, 1115, 11679, 4455, 21544, 1179, 1108, 1136, 169, 28152, 1287, 117, 112, 28131, 1103, 1299, 1170, 3195, 11679, 4455, 21544, 1179, 1107, 170, 10545, 1120, 1203, 1365, 3284, 1951, 14323, 1715, 2874, 6, 102, 102, 102, 102, 1, 16752, 3842, 2, 3, 2694, 4, 5, 1119, 2085, 1103, 25057, 1948, 1106, 1107, 1457, 28138, 7139, 112, 1116, 5501, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16752, 3842, 2, 3, 1500, 4, 5, 8099, 3139, 9341, 17037, 13656, 1358, 1115, 11679, 4455, 21544, 1179, 1108, 1136, 1287, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16752, 3842, 2, 3, 1500, 4, 5, 8099, 3139, 9341, 17037, 13656, 1358, 1115, 11679, 4455, 21544, 1179, 1108, 1136, 1287, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16752, 3842, 2, 3, 1500, 4, 5, 8099, 3139, 9341, 17037, 13656, 1358, 1115, 11679, 4455, 21544, 1179, 1108, 1136, 1287, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16752, 3842, 2, 3, 1500, 4, 5, 8099, 3139, 9341, 17037, 13656, 1358, 1115, 11679, 4455, 21544, 1179, 1108, 1136, 1287, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16752, 3842, 2, 3, 1500, 4, 5, 8099, 3139, 9341, 17037, 13656, 1358, 1115, 11679, 4455, 21544, 1179, 1108, 1136, 1287, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0400560237467289, -0.015427462756633759, -0.08206551522016525, -0.09012941271066666, -0.09404506534337997, -0.09410881996154785, -0.11138719320297241, -0.22275352478027344, -0.22275495529174805, -0.22275495529174805], "metadata": {"source_tokens": ["In", "fact", ",", "Con", "##don", ",", "after", "seeing", "Ha", "##up", "##tman", "##n", "in", "a", "lineup", "at", "New", "York", "Police", "Department", "Greenwich", "Street", "Station", "told", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "`", "##`", "John", ",", "'", "##'", "the", "man", "to", "whom", "Con", "##don", "claimed", "he", "passed", "the", "ransom", "money", "to", "in", "St", "##.", "Raymond", "'", "##s", "Cemetery", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Con", "##don", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "`", "##`", "John", ",", "'", "##'", "the", "man", "after", "seeing", "Ha", "##up", "##tman", "##n", "in", "a", "lineup", "at", "New", "York", "Police", "Department", "Greenwich", "Street", "Station", "[unused6]", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "claimed", "[unused4]", "[unused5]", "he", "passed", "the", "ransom", "money", "to", "in", "St", "##.", "Raymond", "'", "##s", "Cemetery", "[unused6]", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "John", "[unused6]", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "John", "[unused6]", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "John", "[unused6]", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "John", "[unused6]", "[SEP]", "[unused1]", "Con", "##don", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "FBI", "Special", "Agent", "Tu", "##rro", "##u", "that", "Ha", "##up", "##tman", "##n", "was", "not", "John", "[unused6]", "[SEP]"]]}

input 156:  {"source": "In its first six months , RCPO concluded 858 cases convictions in 88 % of cases .\n"}
prediction:  {"predictions": [[1, 25157, 23329, 2, 3, 4803, 4, 5, 4859, 1604, 2740, 22978, 1107, 5385, 110, 1104, 2740, 1130, 1157, 1148, 1565, 1808, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25157, 23329, 2, 3, 4803, 4, 5, 4859, 1604, 2740, 22978, 1107, 5385, 110, 1104, 2740, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0013162890681996942, -0.028089730069041252, -0.21535038948059082, -0.22729110717773438, -0.22729110717773438, -0.22729110717773438, -0.22729110717773438, -0.22729110717773438, -0.22729110717773438, -0.22729110717773438], "metadata": {"source_tokens": ["In", "its", "first", "six", "months", ",", "RC", "##PO", "concluded", "85", "##8", "cases", "convictions", "in", "88", "%", "of", "cases", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "RC", "##PO", "[unused2]", "[unused3]", "concluded", "[unused4]", "[unused5]", "85", "##8", "cases", "convictions", "in", "88", "%", "of", "cases", "In", "its", "first", "six", "months", "[unused6]", "[SEP]", "[unused1]", "RC", "##PO", "[unused2]", "[unused3]", "concluded", "[unused4]", "[unused5]", "85", "##8", "cases", "convictions", "in", "88", "%", "of", "cases", "[unused6]", "[SEP]"]]}

input 157:  {"source": "In modern classifications , it is often treated as a subfamily of the Glyphipterigidae family .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 1110, 5165, 4, 5, 1112, 170, 11548, 1104, 1103, 144, 1193, 27008, 6451, 9866, 5389, 5598, 1266, 1130, 2030, 5393, 1116, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 5165, 4, 5, 1112, 170, 11548, 1104, 1103, 144, 1193, 27008, 6451, 9866, 5389, 5598, 1266, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.002006735187023878, -0.015033550560474396, -0.21543335914611816, -0.21538829803466797, -0.21538829803466797, -0.21538829803466797, -0.21538829803466797, -0.21538829803466797, -0.21538829803466797, -0.21538829803466797], "metadata": {"source_tokens": ["In", "modern", "classification", "##s", ",", "it", "is", "often", "treated", "as", "a", "subfamily", "of", "the", "G", "##ly", "##phi", "##pt", "##eri", "##gi", "##dae", "family", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "is", "treated", "[unused4]", "[unused5]", "as", "a", "subfamily", "of", "the", "G", "##ly", "##phi", "##pt", "##eri", "##gi", "##dae", "family", "In", "modern", "classification", "##s", "often", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "treated", "[unused4]", "[unused5]", "as", "a", "subfamily", "of", "the", "G", "##ly", "##phi", "##pt", "##eri", "##gi", "##dae", "family", "[unused6]", "[SEP]"]]}

input 158:  {"source": "In more recent years , this policy has apparently relaxed somewhat .\n"}
prediction:  {"predictions": [[1, 1142, 2818, 2, 3, 1144, 4547, 8000, 4, 5, 4742, 1130, 1167, 2793, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0017944504506886005, -0.005045413970947266, -0.005057334899902344, -0.005057334899902344, -0.005057334899902344, -0.005057334899902344, -0.005057334899902344, -0.005057334899902344, -0.005057334899902344, -0.005057334899902344], "metadata": {"source_tokens": ["In", "more", "recent", "years", ",", "this", "policy", "has", "apparently", "relaxed", "somewhat", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "this", "policy", "[unused2]", "[unused3]", "has", "apparently", "relaxed", "[unused4]", "[unused5]", "somewhat", "In", "more", "recent", "years", "[unused6]", "[SEP]"]]}

input 159:  {"source": "In order to support planned TRAX expansion , UTA ordered 77 Siemens S70 light rail vehicles from Siemens AG .\n"}
prediction:  {"predictions": [[1, 158, 9159, 2, 3, 2802, 4, 5, 5581, 24824, 156, 20829, 1609, 4356, 4011, 1121, 24824, 14731, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 158, 9159, 2, 3, 2802, 4, 5, 5581, 24824, 156, 20829, 1609, 4356, 4011, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0016812800895422697, -0.046895839273929596, -0.22265195846557617, -0.22265124320983887, -0.22265124320983887, -0.22265124320983887, -0.22265124320983887, -0.22265124320983887, -0.22265124320983887, -0.22265124320983887], "metadata": {"source_tokens": ["In", "order", "to", "support", "planned", "T", "##RA", "##X", "expansion", ",", "U", "##TA", "ordered", "77", "Siemens", "S", "##70", "light", "rail", "vehicles", "from", "Siemens", "AG", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "U", "##TA", "[unused2]", "[unused3]", "ordered", "[unused4]", "[unused5]", "77", "Siemens", "S", "##70", "light", "rail", "vehicles", "from", "Siemens", "AG", "[unused6]", "[SEP]", "[unused1]", "U", "##TA", "[unused2]", "[unused3]", "ordered", "[unused4]", "[unused5]", "77", "Siemens", "S", "##70", "light", "rail", "vehicles", "[unused6]", "[SEP]"]]}

input 160:  {"source": "In particular , Cyprinidae of southwestern North America have been severely affected ; a considerable number went entirely extinct after settlement by Europeans .\n"}
prediction:  {"predictions": [[1, 170, 5602, 1295, 2, 3, 1355, 4, 5, 3665, 8256, 1170, 3433, 1118, 13810, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 27688, 1643, 19764, 5598, 1104, 10231, 1456, 1738, 2, 3, 1138, 1151, 8669, 4634, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.022190935909748077, -0.0017456129426136613, -0.1304309368133545, -0.13219785690307617, -0.13219809532165527, -0.13219785690307617, -0.13219785690307617, -0.13219809532165527, -0.13219809532165527, -0.13219785690307617], "metadata": {"source_tokens": ["In", "particular", ",", "Cy", "##p", "##rini", "##dae", "of", "southwestern", "North", "America", "have", "been", "severely", "affected", ";", "a", "considerable", "number", "went", "entirely", "extinct", "after", "settlement", "by", "Europeans", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "considerable", "number", "[unused2]", "[unused3]", "went", "[unused4]", "[unused5]", "entirely", "extinct", "after", "settlement", "by", "Europeans", "[unused6]", "[SEP]", "[unused1]", "Cy", "##p", "##rini", "##dae", "of", "southwestern", "North", "America", "[unused2]", "[unused3]", "have", "been", "severely", "affected", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 161:  {"source": "In the 1901 election , after which the Oppositionists under George Leake were able to form a minority government , Frank Wilson , formerly the member for Canning , won the seat .\n"}
prediction:  {"predictions": [[1, 2748, 3425, 2, 3, 1281, 4, 5, 1103, 1946, 1130, 1103, 5064, 1728, 1170, 1134, 1103, 16475, 3681, 1223, 1667, 12958, 2391, 1127, 1682, 1106, 1532, 170, 7309, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 16475, 3681, 1223, 1667, 12958, 2391, 2, 3, 1127, 4, 5, 1682, 1106, 1532, 170, 7309, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2748, 3425, 2, 3, 1110, 4, 5, 3147, 1103, 1420, 1111, 2825, 3381, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.019482702016830444, -0.039266593754291534, -0.061977483332157135, -0.14468026161193848, -0.14482808113098145, -0.14482808113098145, -0.14482808113098145, -0.14482808113098145, -0.14482808113098145, -0.14482808113098145], "metadata": {"source_tokens": ["In", "the", "1901", "election", ",", "after", "which", "the", "Opposition", "##ists", "under", "George", "Lea", "##ke", "were", "able", "to", "form", "a", "minority", "government", ",", "Frank", "Wilson", ",", "formerly", "the", "member", "for", "Can", "##ning", ",", "won", "the", "seat", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Frank", "Wilson", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "the", "seat", "In", "the", "1901", "election", "after", "which", "the", "Opposition", "##ists", "under", "George", "Lea", "##ke", "were", "able", "to", "form", "a", "minority", "government", "[unused6]", "[SEP]", "[unused1]", "the", "Opposition", "##ists", "under", "George", "Lea", "##ke", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "able", "to", "form", "a", "minority", "government", "[unused6]", "[SEP]", "[unused1]", "Frank", "Wilson", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "formerly", "the", "member", "for", "Can", "##ning", "[unused6]", "[SEP]"]]}

input 162:  {"source": "In the 1960s and 70s most of Kabul 's economy depended on tourism .\n"}
prediction:  {"predictions": [[1, 1211, 1104, 23321, 112, 1116, 4190, 2, 3, 18520, 4, 5, 1113, 8668, 1130, 1103, 3266, 1105, 19025, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0016907226527109742, -0.10659933090209961, -0.09964275360107422, -0.09964275360107422, -0.09964275360107422, -0.09964275360107422, -0.09964275360107422, -0.09964275360107422, -0.09964275360107422, -0.09964275360107422], "metadata": {"source_tokens": ["In", "the", "1960s", "and", "70s", "most", "of", "Kabul", "'", "##s", "economy", "depended", "on", "tourism", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "most", "of", "Kabul", "'", "##s", "economy", "[unused2]", "[unused3]", "depended", "[unused4]", "[unused5]", "on", "tourism", "In", "the", "1960s", "and", "70s", "[unused6]", "[SEP]"]]}

input 163:  {"source": "In the 1986 television series `` War and Remembrance '' , Johns took the role of the senior Nazi SS officer Adolf Eichmann .\n"}
prediction:  {"predictions": [[1, 11673, 2, 3, 1261, 4, 5, 1103, 1648, 1104, 1103, 2682, 5755, 6663, 2575, 1130, 1103, 2177, 1778, 1326, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03044433519244194, -0.24386096000671387, -0.31473565101623535, -0.31473565101623535, -0.31473565101623535, -0.31473565101623535, -0.31473565101623535, -0.31473565101623535, -0.31473565101623535, -0.31473565101623535], "metadata": {"source_tokens": ["In", "the", "1986", "television", "series", "`", "##`", "War", "and", "Re", "##membrance", "'", "##'", ",", "Johns", "took", "the", "role", "of", "the", "senior", "Nazi", "SS", "officer", "Adolf", "E", "##ich", "##mann", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Johns", "[unused2]", "[unused3]", "took", "[unused4]", "[unused5]", "the", "role", "of", "the", "senior", "Nazi", "SS", "officer", "In", "the", "1986", "television", "series", "[unused6]", "[SEP]"]]}

input 164:  {"source": "In the Civil War , he advocated strong prosecution of the Union War effort , the end of slavery , and civil rights for freed African Americans .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 11971, 4, 5, 2012, 12369, 1104, 1103, 1913, 1414, 3098, 117, 1103, 1322, 1104, 9401, 117, 1105, 2987, 2266, 1111, 11485, 2170, 4038, 1130, 1103, 3145, 1414, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 11971, 4, 5, 2012, 12369, 1104, 1103, 1913, 1414, 3098, 1103, 1322, 1104, 9401, 1105, 2987, 2266, 1111, 11485, 2170, 4038, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.014324801042675972, -0.03884139657020569, -0.14451074600219727, -0.14452505111694336, -0.14452505111694336, -0.14452505111694336, -0.14452505111694336, -0.14452505111694336, -0.14452505111694336, -0.14452505111694336], "metadata": {"source_tokens": ["In", "the", "Civil", "War", ",", "he", "advocated", "strong", "prosecution", "of", "the", "Union", "War", "effort", ",", "the", "end", "of", "slavery", ",", "and", "civil", "rights", "for", "freed", "African", "Americans", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "advocated", "[unused4]", "[unused5]", "strong", "prosecution", "of", "the", "Union", "War", "effort", ",", "the", "end", "of", "slavery", ",", "and", "civil", "rights", "for", "freed", "African", "Americans", "In", "the", "Civil", "War", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "advocated", "[unused4]", "[unused5]", "strong", "prosecution", "of", "the", "Union", "War", "effort", "the", "end", "of", "slavery", "and", "civil", "rights", "for", "freed", "African", "Americans", "[unused6]", "[SEP]"]]}

input 165:  {"source": "In the Crimean War , the 5th Dragoon Guards formed part of the Heavy Cavalry Brigade and was sent to the Black Sea in 1854 .\n"}
prediction:  {"predictions": [[1, 1103, 4025, 1987, 19308, 1320, 9696, 2, 3, 1824, 4, 5, 1226, 1104, 1103, 10580, 9312, 4292, 1130, 1103, 22442, 1414, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4025, 1987, 19308, 1320, 9696, 2, 3, 1108, 1850, 4, 5, 1106, 1103, 2117, 3017, 1107, 8023, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4025, 1987, 19308, 1320, 9696, 2, 3, 1824, 4, 5, 1226, 1104, 1103, 10580, 9312, 4292, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.025741925463080406, -0.005129117518663406, -0.042781680822372437, -0.06563305854797363, -0.06716489791870117, -0.06716489791870117, -0.06716489791870117, -0.06716489791870117, -0.06716489791870117, -0.06716489791870117], "metadata": {"source_tokens": ["In", "the", "Crimean", "War", ",", "the", "5th", "Dr", "##ago", "##on", "Guards", "formed", "part", "of", "the", "Heavy", "Cavalry", "Brigade", "and", "was", "sent", "to", "the", "Black", "Sea", "in", "1854", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "5th", "Dr", "##ago", "##on", "Guards", "[unused2]", "[unused3]", "formed", "[unused4]", "[unused5]", "part", "of", "the", "Heavy", "Cavalry", "Brigade", "In", "the", "Crimean", "War", "[unused6]", "[SEP]", "[unused1]", "the", "5th", "Dr", "##ago", "##on", "Guards", "[unused2]", "[unused3]", "was", "sent", "[unused4]", "[unused5]", "to", "the", "Black", "Sea", "in", "1854", "[unused6]", "[SEP]", "[unused1]", "the", "5th", "Dr", "##ago", "##on", "Guards", "[unused2]", "[unused3]", "formed", "[unused4]", "[unused5]", "part", "of", "the", "Heavy", "Cavalry", "Brigade", "[unused6]", "[SEP]"]]}

input 166:  {"source": "In the early 19th century the Welsh Methodists broke away from the Anglican church and established their own denomination , now the Presbyterian Church of Wales .\n"}
prediction:  {"predictions": [[1, 1103, 5447, 8580, 1116, 2, 3, 1628, 4, 5, 1147, 1319, 20493, 1130, 1103, 1346, 2835, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 5447, 8580, 1116, 2, 3, 2795, 4, 5, 1283, 1121, 1103, 9137, 1749, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 5447, 8580, 1116, 2, 3, 1628, 4, 5, 1147, 1319, 20493, 1208, 1103, 10091, 1722, 1104, 2717, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04883516952395439, -0.09619829058647156, -0.052295785397291183, -0.22265410423278809, -0.2226572036743164, -0.2226572036743164, -0.2226572036743164, -0.2226572036743164, -0.2226572036743164, -0.2226572036743164], "metadata": {"source_tokens": ["In", "the", "early", "19th", "century", "the", "Welsh", "Methodist", "##s", "broke", "away", "from", "the", "Anglican", "church", "and", "established", "their", "own", "denomination", ",", "now", "the", "Presbyterian", "Church", "of", "Wales", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Welsh", "Methodist", "##s", "[unused2]", "[unused3]", "established", "[unused4]", "[unused5]", "their", "own", "denomination", "In", "the", "early", "19th", "century", "[unused6]", "[SEP]", "[unused1]", "the", "Welsh", "Methodist", "##s", "[unused2]", "[unused3]", "broke", "[unused4]", "[unused5]", "away", "from", "the", "Anglican", "church", "[unused6]", "[SEP]", "[unused1]", "the", "Welsh", "Methodist", "##s", "[unused2]", "[unused3]", "established", "[unused4]", "[unused5]", "their", "own", "denomination", "now", "the", "Presbyterian", "Church", "of", "Wales", "[unused6]", "[SEP]"]]}

input 167:  {"source": "In the north and east inhabitants speak Bumthangkha , and in the extreme southeast Khengkha is spoken .\n"}
prediction:  {"predictions": [[1, 148, 10436, 1403, 14457, 2, 3, 1110, 4606, 4, 5, 1107, 1103, 6122, 5038, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4131, 2, 3, 2936, 4, 5, 139, 1818, 22252, 1403, 14457, 1130, 1103, 1564, 1105, 1746, 4131, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.008027076721191406, -0.11319778114557266, -0.18855023384094238, -0.20078563690185547, -0.20078563690185547, -0.20078563690185547, -0.20078563690185547, -0.20078563690185547, -0.20078563690185547, -0.20078563690185547], "metadata": {"source_tokens": ["In", "the", "north", "and", "east", "inhabitants", "speak", "B", "##um", "##than", "##g", "##kha", ",", "and", "in", "the", "extreme", "southeast", "K", "##hen", "##g", "##kha", "is", "spoken", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "K", "##hen", "##g", "##kha", "[unused2]", "[unused3]", "is", "spoken", "[unused4]", "[unused5]", "in", "the", "extreme", "southeast", "[unused6]", "[SEP]", "[unused1]", "inhabitants", "[unused2]", "[unused3]", "speak", "[unused4]", "[unused5]", "B", "##um", "##than", "##g", "##kha", "In", "the", "north", "and", "east", "inhabitants", "[unused6]", "[SEP]"]]}

input 168:  {"source": "In the winter of 1976 , Knievel was scheduled for a major jump in Chicago , Illinois .\n"}
prediction:  {"predictions": [[1, 148, 5213, 12559, 2, 3, 1108, 4533, 4, 5, 1111, 170, 1558, 5152, 1107, 2290, 1130, 1103, 3701, 1104, 2402, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.000957717071287334, -0.2226393222808838, -0.2226390838623047, -0.2226390838623047, -0.2226390838623047, -0.2226390838623047, -0.2226390838623047, -0.2226390838623047, -0.2226390838623047, -0.2226390838623047], "metadata": {"source_tokens": ["In", "the", "winter", "of", "1976", ",", "K", "##nie", "##vel", "was", "scheduled", "for", "a", "major", "jump", "in", "Chicago", ",", "Illinois", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "K", "##nie", "##vel", "[unused2]", "[unused3]", "was", "scheduled", "[unused4]", "[unused5]", "for", "a", "major", "jump", "in", "Chicago", "In", "the", "winter", "of", "1976", "[unused6]", "[SEP]"]]}

input 169:  {"source": "In this explanation the purpose of Creation is that `` God desired a dwelling place in the lower realms '' - it is man who transforms the mundane , lowest World into an abode for God 's essence .\n"}
prediction:  {"predictions": [[1, 1103, 3007, 1104, 19470, 2, 3, 1110, 4, 5, 1115, 169, 28152, 1875, 8759, 170, 13835, 1282, 1107, 1103, 2211, 9695, 1116, 112, 28131, 118, 1122, 1110, 1299, 1130, 1142, 7108, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 4, 5, 1299, 1150, 24573, 1103, 182, 22902, 1673, 117, 6905, 1291, 1154, 1126, 170, 4043, 2007, 1111, 1875, 112, 1116, 12661, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1875, 2, 3, 8759, 4, 5, 170, 13835, 1282, 1107, 1103, 2211, 9695, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1299, 2, 3, 24573, 4, 5, 1103, 182, 22902, 1673, 117, 6905, 1291, 1154, 1126, 170, 4043, 2007, 1111, 1875, 112, 1116, 12661, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02026228792965412, -0.03933388367295265, -0.05716514587402344, -0.04602854698896408, -0.1525113582611084, -0.15243268013000488, -0.15243268013000488, -0.15243268013000488, -0.15243268013000488, -0.15243268013000488], "metadata": {"source_tokens": ["In", "this", "explanation", "the", "purpose", "of", "Creation", "is", "that", "`", "##`", "God", "desired", "a", "dwelling", "place", "in", "the", "lower", "realm", "##s", "'", "##'", "-", "it", "is", "man", "who", "transforms", "the", "m", "##unda", "##ne", ",", "lowest", "World", "into", "an", "a", "##bo", "##de", "for", "God", "'", "##s", "essence", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "purpose", "of", "Creation", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "that", "`", "##`", "God", "desired", "a", "dwelling", "place", "in", "the", "lower", "realm", "##s", "'", "##'", "-", "it", "is", "man", "In", "this", "explanation", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "man", "who", "transforms", "the", "m", "##unda", "##ne", ",", "lowest", "World", "into", "an", "a", "##bo", "##de", "for", "God", "'", "##s", "essence", "[unused6]", "[SEP]", "[unused1]", "God", "[unused2]", "[unused3]", "desired", "[unused4]", "[unused5]", "a", "dwelling", "place", "in", "the", "lower", "realm", "##s", "[unused6]", "[SEP]", "[unused1]", "man", "[unused2]", "[unused3]", "transforms", "[unused4]", "[unused5]", "the", "m", "##unda", "##ne", ",", "lowest", "World", "into", "an", "a", "##bo", "##de", "for", "God", "'", "##s", "essence", "[unused6]", "[SEP]"]]}

input 170:  {"source": "In those years , he began to collaborate with some newspapers .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1310, 4, 5, 1106, 23200, 1114, 1199, 6195, 1130, 1343, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.003903164528310299, -0.17086362838745117, -0.17130064964294434, -0.17130064964294434, -0.17130064964294434, -0.17130064964294434, -0.17130064964294434, -0.17130064964294434, -0.17130064964294434, -0.17130064964294434], "metadata": {"source_tokens": ["In", "those", "years", ",", "he", "began", "to", "collaborate", "with", "some", "newspapers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "to", "collaborate", "with", "some", "newspapers", "In", "those", "years", "[unused6]", "[SEP]"]]}

input 171:  {"source": "Initially flying the A-4B Skyhawk , the squadron later transitioned to the A-4L Skyhawk .\n"}
prediction:  {"predictions": [[1, 1103, 5780, 2, 3, 26974, 4, 5, 1106, 1103, 138, 28137, 1527, 2162, 5751, 19952, 7245, 3754, 1103, 138, 28137, 1527, 2064, 5751, 19952, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 5780, 2, 3, 26974, 4, 5, 1106, 1103, 138, 28137, 1527, 2162, 5751, 19952, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0008025554125197232, -0.023963795974850655, -0.22278070449829102, -0.22277164459228516, -0.22277164459228516, -0.22277164459228516, -0.22277164459228516, -0.22277164459228516, -0.22277164459228516, -0.22277164459228516], "metadata": {"source_tokens": ["Initially", "flying", "the", "A", "##-", "##4", "##B", "Sky", "##hawk", ",", "the", "squadron", "later", "transitioned", "to", "the", "A", "##-", "##4", "##L", "Sky", "##hawk", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "squadron", "[unused2]", "[unused3]", "transitioned", "[unused4]", "[unused5]", "to", "the", "A", "##-", "##4", "##L", "Sky", "##hawk", "Initially", "flying", "the", "A", "##-", "##4", "##B", "Sky", "##hawk", "later", "[unused6]", "[SEP]", "[unused1]", "the", "squadron", "[unused2]", "[unused3]", "transitioned", "[unused4]", "[unused5]", "to", "the", "A", "##-", "##4", "##L", "Sky", "##hawk", "[unused6]", "[SEP]"]]}

input 172:  {"source": "Initially his chances of surviving were thought to be no better than 50-50 .\n"}
prediction:  {"predictions": [[1, 1117, 9820, 1104, 5932, 2, 3, 1106, 1129, 4, 5, 1185, 1618, 1190, 1851, 28137, 11049, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 9820, 1104, 5932, 2, 3, 1127, 1354, 4, 5, 7245, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03395657613873482, -0.0433209203183651, -0.051763057708740234, -0.051763057708740234, -0.051763057708740234, -0.051763057708740234, -0.051763057708740234, -0.051763057708740234, -0.051763057708740234, -0.051763057708740234], "metadata": {"source_tokens": ["Initially", "his", "chances", "of", "surviving", "were", "thought", "to", "be", "no", "better", "than", "50", "##-", "##50", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "his", "chances", "of", "surviving", "[unused2]", "[unused3]", "to", "be", "[unused4]", "[unused5]", "no", "better", "than", "50", "##-", "##50", "[unused6]", "[SEP]", "[unused1]", "his", "chances", "of", "surviving", "[unused2]", "[unused3]", "were", "thought", "[unused4]", "[unused5]", "Initially", "[unused6]", "[SEP]"]]}

input 173:  {"source": "It has long hind legs and a long , slender , scaly tail that it uses to communicate by making drumming noises .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1144, 4, 5, 1263, 24856, 2584, 1105, 170, 1263, 117, 11226, 117, 188, 7867, 1183, 5287, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1263, 117, 11226, 117, 188, 7867, 1183, 5287, 2, 3, 2745, 4, 5, 1106, 10621, 1118, 1543, 27025, 16256, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.01234631147235632, -0.032471656799316406, -0.05042672157287598, -0.05114412307739258, -0.05114412307739258, -0.05114412307739258, -0.05114412307739258, -0.05114412307739258, -0.05114412307739258, -0.05114412307739258], "metadata": {"source_tokens": ["It", "has", "long", "hind", "legs", "and", "a", "long", ",", "slender", ",", "s", "##cal", "##y", "tail", "that", "it", "uses", "to", "communicate", "by", "making", "drumming", "noises", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "long", "hind", "legs", "and", "a", "long", ",", "slender", ",", "s", "##cal", "##y", "tail", "[unused6]", "[SEP]", "[unused1]", "a", "long", ",", "slender", ",", "s", "##cal", "##y", "tail", "[unused2]", "[unused3]", "uses", "[unused4]", "[unused5]", "to", "communicate", "by", "making", "drumming", "noises", "[unused6]", "[SEP]"]]}

input 174:  {"source": "It is essentially the same as the dialect spoken in Xiamen , and is unintelligible with Standard Chinese .\n"}
prediction:  {"predictions": [[1, 1103, 9222, 2, 3, 4606, 4, 5, 1107, 20802, 16470, 1179, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1110, 4, 5, 7588, 1103, 1269, 1112, 1103, 9222, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1110, 4, 5, 8362, 10879, 12164, 12192, 1114, 6433, 1922, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.006365248002111912, -0.06120329722762108, -0.0362490639090538, -0.055849313735961914, -0.058841705322265625, -0.058841705322265625, -0.058841705322265625, -0.058841705322265625, -0.058841705322265625, -0.058841705322265625], "metadata": {"source_tokens": ["It", "is", "essentially", "the", "same", "as", "the", "dialect", "spoken", "in", "Xi", "##ame", "##n", ",", "and", "is", "un", "##int", "##elli", "##gible", "with", "Standard", "Chinese", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "dialect", "[unused2]", "[unused3]", "spoken", "[unused4]", "[unused5]", "in", "Xi", "##ame", "##n", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "essentially", "the", "same", "as", "the", "dialect", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "un", "##int", "##elli", "##gible", "with", "Standard", "Chinese", "[unused6]", "[SEP]"]]}

input 175:  {"source": "It is not really passable , and must be done on foot if attempted .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1110, 1136, 4, 5, 1541, 2789, 1895, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1538, 1129, 1694, 4, 5, 1113, 2555, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.021985705941915512, -0.046342987567186356, -0.29538512229919434, -0.289762020111084, -0.289762020111084, -0.289762020111084, -0.289762020111084, -0.289762020111084, -0.289762020111084, -0.289762020111084], "metadata": {"source_tokens": ["It", "is", "not", "really", "pass", "##able", ",", "and", "must", "be", "done", "on", "foot", "if", "attempted", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "is", "not", "[unused4]", "[unused5]", "really", "pass", "##able", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "must", "be", "done", "[unused4]", "[unused5]", "on", "foot", "[unused6]", "[SEP]"]]}

input 176:  {"source": "It is part of the Surrey Hills Area of Outstanding Beauty and situated on the Green Sand Way .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1110, 4, 5, 1226, 1104, 1103, 9757, 5377, 3894, 1104, 7196, 10764, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 3629, 4, 5, 1113, 1103, 2565, 16377, 4714, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.00406681839376688, -0.03503837063908577, -0.0016446113586425781, -0.0016398429870605469, -0.0016398429870605469, -0.0016398429870605469, -0.0016398429870605469, -0.0016398429870605469, -0.0016398429870605469, -0.0016398429870605469], "metadata": {"source_tokens": ["It", "is", "part", "of", "the", "Surrey", "Hills", "Area", "of", "Outstanding", "Beauty", "and", "situated", "on", "the", "Green", "Sand", "Way", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "part", "of", "the", "Surrey", "Hills", "Area", "of", "Outstanding", "Beauty", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "situated", "[unused4]", "[unused5]", "on", "the", "Green", "Sand", "Way", "[unused6]", "[SEP]"]]}

input 177:  {"source": "It should be noted that these numbers are inclusive of any of the childminders own children .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1431, 1129, 2382, 4, 5, 1115, 1292, 2849, 1132, 21783, 1104, 1251, 1104, 1103, 2027, 22448, 1468, 1319, 1482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02837441861629486, -0.08093976974487305, -0.054080963134765625, -0.054080963134765625, -0.054080963134765625, -0.054080963134765625, -0.054080963134765625, -0.054080963134765625, -0.054080963134765625, -0.054080963134765625], "metadata": {"source_tokens": ["It", "should", "be", "noted", "that", "these", "numbers", "are", "inclusive", "of", "any", "of", "the", "child", "##mind", "##ers", "own", "children", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "should", "be", "noted", "[unused4]", "[unused5]", "that", "these", "numbers", "are", "inclusive", "of", "any", "of", "the", "child", "##mind", "##ers", "own", "children", "[unused6]", "[SEP]"]]}

input 178:  {"source": "It was chosen in 1901 because it was a triangulation station at the junction of the trancontinental triangulation arc of 1899 on the 39th parallel north and the triangulation arc along the 98th meridian west that was near the geographic center of the contiguous United States .\n"}
prediction:  {"predictions": [[1, 1103, 5103, 1582, 1143, 10132, 1811, 1745, 2, 3, 1108, 4, 5, 1485, 1103, 13351, 2057, 1104, 1103, 14255, 3121, 22928, 1244, 1311, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 1108, 3468, 4, 5, 1107, 5064, 1272, 1122, 1108, 170, 189, 5476, 13830, 6840, 1466, 1120, 1103, 6698, 1104, 1103, 189, 4047, 25442, 1348, 189, 5476, 13830, 6840, 10591, 1104, 5493, 1113, 1103, 25235, 5504, 1564, 1105, 1103, 189, 5476, 13830, 6840, 10591, 1373, 1103, 5103, 102, 1, 1122, 2, 3, 1108, 4, 5, 170, 189, 5476, 13830, 6840, 1466, 1120, 1103, 6698, 1104, 1103, 189, 4047, 25442, 1348, 189, 5476, 13830, 6840, 10591, 1104, 5493, 1113, 1103, 25235, 5504, 1564, 1105, 1103, 189, 5476, 13830, 6840, 10591, 1373, 1103, 5103, 1582, 1143, 10132, 1811, 1745, 6, 102, 1, 1122, 2, 3, 1108, 4, 5, 170, 189, 5476, 13830, 6840, 1466, 1120, 1103, 6698, 1104, 1103, 189, 4047, 25442, 1348, 189, 5476, 13830, 6840, 10591, 1104, 5493, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 170, 189, 5476, 13830, 6840, 1466, 1120, 1103, 6698, 1104, 1103, 189, 4047, 25442, 1348, 189, 5476, 13830, 6840, 10591, 1104, 5493, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.011960207484662533, -0.02214227057993412, -0.020439686253666878, -0.051015738397836685, -0.07038454711437225, -0.2227306365966797, -0.22272920608520508, -0.22272920608520508, -0.22272920608520508, -0.22272920608520508], "metadata": {"source_tokens": ["It", "was", "chosen", "in", "1901", "because", "it", "was", "a", "t", "##rian", "##gu", "##lation", "station", "at", "the", "junction", "of", "the", "t", "##ran", "##continent", "##al", "t", "##rian", "##gu", "##lation", "arc", "of", "1899", "on", "the", "39th", "parallel", "north", "and", "the", "t", "##rian", "##gu", "##lation", "arc", "along", "the", "98", "##th", "me", "##rid", "##ian", "west", "that", "was", "near", "the", "geographic", "center", "of", "the", "con", "##ti", "##guous", "United", "States", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "98", "##th", "me", "##rid", "##ian", "west", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "near", "the", "geographic", "center", "of", "the", "con", "##ti", "##guous", "United", "States", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "was", "chosen", "[unused4]", "[unused5]", "in", "1901", "because", "it", "was", "a", "t", "##rian", "##gu", "##lation", "station", "at", "the", "junction", "of", "the", "t", "##ran", "##continent", "##al", "t", "##rian", "##gu", "##lation", "arc", "of", "1899", "on", "the", "39th", "parallel", "north", "and", "the", "t", "##rian", "##gu", "##lation", "arc", "along", "the", "98", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "t", "##rian", "##gu", "##lation", "station", "at", "the", "junction", "of", "the", "t", "##ran", "##continent", "##al", "t", "##rian", "##gu", "##lation", "arc", "of", "1899", "on", "the", "39th", "parallel", "north", "and", "the", "t", "##rian", "##gu", "##lation", "arc", "along", "the", "98", "##th", "me", "##rid", "##ian", "west", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "t", "##rian", "##gu", "##lation", "station", "at", "the", "junction", "of", "the", "t", "##ran", "##continent", "##al", "t", "##rian", "##gu", "##lation", "arc", "of", "1899", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "t", "##rian", "##gu", "##lation", "station", "at", "the", "junction", "of", "the", "t", "##ran", "##continent", "##al", "t", "##rian", "##gu", "##lation", "arc", "of", "1899", "[unused6]", "[SEP]"]]}

g_f_logprobs : 0.07342529296875
input 179:  {"source": "It was named for Gen. Eleazer Wheelock Ripley , an officer in the War of 1812 , who was mainly remembered for the Battle of Lundy 's Lane and the Siege of Fort Erie , in 1814 .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1108, 1417, 4, 5, 1111, 9198, 28138, 2896, 4490, 6198, 19754, 5559, 155, 9717, 1926, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9198, 28138, 2896, 4490, 6198, 19754, 5559, 155, 9717, 1926, 2, 3, 1110, 4, 5, 1126, 2575, 1107, 1103, 1414, 1104, 9601, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9198, 28138, 2896, 4490, 6198, 19754, 5559, 155, 9717, 1926, 2, 3, 1108, 3801, 4, 5, 1111, 1103, 2651, 1104, 24232, 1183, 112, 1116, 5319, 1105, 1103, 14214, 1104, 3144, 13717, 1107, 10943, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9198, 28138, 2896, 4490, 6198, 19754, 5559, 155, 9717, 1926, 2, 3, 1108, 3801, 4, 5, 1111, 1103, 2651, 1104, 24232, 1183, 112, 1116, 5319, 1105, 1103, 14214, 1104, 3144, 13717, 1107, 10943, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.007813794538378716, -0.03579912707209587, -0.036497458815574646, -0.05646026134490967, -0.22388291358947754, -0.22357654571533203, -0.22357654571533203, -0.22357654571533203, -0.22357654571533203, -0.22357654571533203], "metadata": {"source_tokens": ["It", "was", "named", "for", "Gen", "##.", "El", "##ea", "##zer", "Wheel", "##ock", "R", "##ip", "##ley", ",", "an", "officer", "in", "the", "War", "of", "1812", ",", "who", "was", "mainly", "remembered", "for", "the", "Battle", "of", "Lund", "##y", "'", "##s", "Lane", "and", "the", "Siege", "of", "Fort", "Erie", ",", "in", "1814", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "was", "named", "[unused4]", "[unused5]", "for", "Gen", "##.", "El", "##ea", "##zer", "Wheel", "##ock", "R", "##ip", "##ley", "[unused6]", "[SEP]", "[unused1]", "Gen", "##.", "El", "##ea", "##zer", "Wheel", "##ock", "R", "##ip", "##ley", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "officer", "in", "the", "War", "of", "1812", "[unused6]", "[SEP]", "[unused1]", "Gen", "##.", "El", "##ea", "##zer", "Wheel", "##ock", "R", "##ip", "##ley", "[unused2]", "[unused3]", "was", "remembered", "[unused4]", "[unused5]", "for", "the", "Battle", "of", "Lund", "##y", "'", "##s", "Lane", "and", "the", "Siege", "of", "Fort", "Erie", "in", "1814", "[unused6]", "[SEP]", "[unused1]", "Gen", "##.", "El", "##ea", "##zer", "Wheel", "##ock", "R", "##ip", "##ley", "[unused2]", "[unused3]", "was", "remembered", "[unused4]", "[unused5]", "for", "the", "Battle", "of", "Lund", "##y", "'", "##s", "Lane", "and", "the", "Siege", "of", "Fort", "Erie", "in", "1814", "[unused6]", "[SEP]"]]}

input 180:  {"source": "It was originally aimed at mature entrants to the teaching profession , who could not afford to give up work and undertake a traditional method of teacher training such as the PGCE .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1108, 5850, 4, 5, 1120, 9881, 4035, 4487, 5240, 1106, 1103, 3679, 9545, 2034, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3679, 9545, 2, 3, 1180, 1136, 8658, 4, 5, 1106, 1660, 1146, 1250, 1105, 17778, 170, 2361, 3442, 1104, 3218, 2013, 1216, 1112, 1103, 153, 13478, 2036, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3679, 9545, 2, 3, 1180, 1136, 8658, 4, 5, 1106, 1660, 1146, 1250, 1105, 17778, 170, 2361, 3442, 1104, 3218, 2013, 1216, 1112, 1103, 153, 13478, 2036, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.026718026027083397, -0.009004096500575542, -0.06510400772094727, -0.2281954288482666, -0.24338126182556152, -0.24338126182556152, -0.24338126182556152, -0.24338126182556152, -0.24338126182556152, -0.24338126182556152], "metadata": {"source_tokens": ["It", "was", "originally", "aimed", "at", "mature", "en", "##tra", "##nts", "to", "the", "teaching", "profession", ",", "who", "could", "not", "afford", "to", "give", "up", "work", "and", "undertake", "a", "traditional", "method", "of", "teacher", "training", "such", "as", "the", "P", "##GC", "##E", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "was", "aimed", "[unused4]", "[unused5]", "at", "mature", "en", "##tra", "##nts", "to", "the", "teaching", "profession", "originally", "[unused6]", "[SEP]", "[unused1]", "the", "teaching", "profession", "[unused2]", "[unused3]", "could", "not", "afford", "[unused4]", "[unused5]", "to", "give", "up", "work", "and", "undertake", "a", "traditional", "method", "of", "teacher", "training", "such", "as", "the", "P", "##GC", "##E", "[unused6]", "[SEP]", "[unused1]", "the", "teaching", "profession", "[unused2]", "[unused3]", "could", "not", "afford", "[unused4]", "[unused5]", "to", "give", "up", "work", "and", "undertake", "a", "traditional", "method", "of", "teacher", "training", "such", "as", "the", "P", "##GC", "##E", "[unused6]", "[SEP]"]]}

input 181:  {"source": "Its cultivation even declined in favour of the Asian species , which was introduced to East Africa early in the common era and spread westward .\n"}
prediction:  {"predictions": [[1, 2098, 13958, 2, 3, 1256, 5799, 4, 5, 1107, 7511, 1104, 1103, 3141, 1530, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3141, 1530, 2, 3, 1108, 2234, 4, 5, 1106, 1689, 2201, 1346, 1107, 1103, 1887, 3386, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3141, 1530, 2, 3, 2819, 4, 5, 17222, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02116154134273529, -0.007877153344452381, -0.08665945380926132, -0.03310537338256836, -0.033310890197753906, -0.033310890197753906, -0.033310890197753906, -0.033310890197753906, -0.033310890197753906, -0.033310890197753906], "metadata": {"source_tokens": ["Its", "cultivation", "even", "declined", "in", "favour", "of", "the", "Asian", "species", ",", "which", "was", "introduced", "to", "East", "Africa", "early", "in", "the", "common", "era", "and", "spread", "westward", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Its", "cultivation", "[unused2]", "[unused3]", "even", "declined", "[unused4]", "[unused5]", "in", "favour", "of", "the", "Asian", "species", "[unused6]", "[SEP]", "[unused1]", "the", "Asian", "species", "[unused2]", "[unused3]", "was", "introduced", "[unused4]", "[unused5]", "to", "East", "Africa", "early", "in", "the", "common", "era", "[unused6]", "[SEP]", "[unused1]", "the", "Asian", "species", "[unused2]", "[unused3]", "spread", "[unused4]", "[unused5]", "westward", "[unused6]", "[SEP]"]]}

input 182:  {"source": "JAL introduced jet service on the Fukuoka-Tokyo route in 1961 .\n"}
prediction:  {"predictions": [[1, 147, 12507, 2, 3, 2234, 4, 5, 8319, 1555, 1113, 1103, 14763, 4786, 9865, 28137, 1942, 5926, 7490, 2438, 1107, 2920, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0007300774450413883, -0.10070347785949707, -0.13361263275146484, -0.13361263275146484, -0.13361263275146484, -0.13361263275146484, -0.13361263275146484, -0.13361263275146484, -0.13361263275146484, -0.13361263275146484], "metadata": {"source_tokens": ["J", "##AL", "introduced", "jet", "service", "on", "the", "Fu", "##ku", "##oka", "##-", "##T", "##ok", "##yo", "route", "in", "1961", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "J", "##AL", "[unused2]", "[unused3]", "introduced", "[unused4]", "[unused5]", "jet", "service", "on", "the", "Fu", "##ku", "##oka", "##-", "##T", "##ok", "##yo", "route", "in", "1961", "[unused6]", "[SEP]"]]}

Decodertime : 0.0002484321594238281
input 183:  {"source": "James Arthur Hogue is a US impostor who most famously entered Princeton University by posing as a self-taught orphan .\n"}
prediction:  {"predictions": [[1, 1600, 3456, 9800, 7222, 2, 3, 1110, 4, 5, 170, 1646, 24034, 15540, 1766, 1150, 1211, 20025, 2242, 8845, 1239, 1118, 23614, 1112, 170, 2191, 28137, 1777, 11266, 25298, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1646, 24034, 15540, 1766, 2, 3, 1211, 20025, 2242, 4, 5, 8845, 1239, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.018586378544569016, -0.005062971264123917, -0.22205352783203125, -0.19946861267089844, -0.19946861267089844, -0.19946885108947754, -0.19946861267089844, -0.19946861267089844, -0.19946861267089844, -0.19946861267089844], "metadata": {"source_tokens": ["James", "Arthur", "Ho", "##gue", "is", "a", "US", "imp", "##ost", "##or", "who", "most", "famously", "entered", "Princeton", "University", "by", "posing", "as", "a", "self", "##-", "##ta", "##ught", "orphan", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "James", "Arthur", "Ho", "##gue", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "US", "imp", "##ost", "##or", "who", "most", "famously", "entered", "Princeton", "University", "by", "posing", "as", "a", "self", "##-", "##ta", "##ught", "orphan", "[unused6]", "[SEP]", "[unused1]", "a", "US", "imp", "##ost", "##or", "[unused2]", "[unused3]", "most", "famously", "entered", "[unused4]", "[unused5]", "Princeton", "University", "[unused6]", "[SEP]"]]}

input 184:  {"source": "John Stewart and Guy Gardner brought down New Warworld and the Yellow Central Power Battery , which were detonated next to the Anti-Monitor , and contained by a shield created by hundreds of Green Lanterns to contain the explosion ; even this was not enough to kill him .\n"}
prediction:  {"predictions": [[1, 1287, 5272, 1105, 6173, 11817, 2, 3, 1814, 1205, 4, 5, 1203, 1414, 13070, 1105, 1103, 8278, 1970, 3794, 11537, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 8278, 1970, 3794, 11537, 2, 3, 1127, 1260, 1633, 2913, 4, 5, 1397, 1106, 1103, 8329, 28137, 2107, 11153, 2772, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 7292, 2, 3, 1687, 4, 5, 1118, 5229, 1104, 2565, 23999, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1256, 1142, 2, 3, 1108, 1136, 4, 5, 1536, 1106, 2311, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1256, 1142, 2, 3, 1108, 1136, 4, 5, 1536, 1106, 2311, 1140, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1203, 1414, 13070, 1105, 1103, 8278, 1970, 3794, 11537, 2, 3, 1127, 1260, 1633, 2913, 4, 5, 1397, 1106, 1103, 8329, 28137, 2107, 11153, 2772, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.051174260675907135, -0.05770758166909218, -0.0755726769566536, -0.03702240809798241, -0.13934296369552612, -0.11803575605154037, -0.22267961502075195, -0.22267842292785645, -0.22267842292785645, -0.22267842292785645], "metadata": {"source_tokens": ["John", "Stewart", "and", "Guy", "Gardner", "brought", "down", "New", "War", "##world", "and", "the", "Yellow", "Central", "Power", "Battery", ",", "which", "were", "de", "##ton", "##ated", "next", "to", "the", "Anti", "##-", "##M", "##oni", "##tor", ",", "and", "contained", "by", "a", "shield", "created", "by", "hundreds", "of", "Green", "Lantern", "##s", "to", "contain", "the", "explosion", ";", "even", "this", "was", "not", "enough", "to", "kill", "him", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "John", "Stewart", "and", "Guy", "Gardner", "[unused2]", "[unused3]", "brought", "down", "[unused4]", "[unused5]", "New", "War", "##world", "and", "the", "Yellow", "Central", "Power", "Battery", "[unused6]", "[SEP]", "[unused1]", "the", "Yellow", "Central", "Power", "Battery", "[unused2]", "[unused3]", "were", "de", "##ton", "##ated", "[unused4]", "[unused5]", "next", "to", "the", "Anti", "##-", "##M", "##oni", "##tor", "[unused6]", "[SEP]", "[unused1]", "a", "shield", "[unused2]", "[unused3]", "created", "[unused4]", "[unused5]", "by", "hundreds", "of", "Green", "Lantern", "##s", "[unused6]", "[SEP]", "[unused1]", "even", "this", "[unused2]", "[unused3]", "was", "not", "[unused4]", "[unused5]", "enough", "to", "kill", "him", "[unused6]", "[SEP]", "[unused1]", "even", "this", "[unused2]", "[unused3]", "was", "not", "[unused4]", "[unused5]", "enough", "to", "kill", "him", "[unused6]", "[SEP]", "[unused1]", "New", "War", "##world", "and", "the", "Yellow", "Central", "Power", "Battery", "[unused2]", "[unused3]", "were", "de", "##ton", "##ated", "[unused4]", "[unused5]", "next", "to", "the", "Anti", "##-", "##M", "##oni", "##tor", "[unused6]", "[SEP]"]]}

input 185:  {"source": "Johns also appeared as an Imperial Officer in the 1980 `` Star Wars sequel '' , `` The Empire Strikes Back '' .\n"}
prediction:  {"predictions": [[1, 11673, 2, 3, 1691, 4, 5, 1112, 1126, 4849, 4124, 1107, 1103, 2253, 169, 28152, 2537, 6238, 8047, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2813, 2, 3, 15425, 1116, 4388, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04301911219954491, -0.07520192116498947, -0.019559860229492188, -0.025246381759643555, -0.025246381759643555, -0.025246381759643555, -0.025246381759643555, -0.025246381759643555, -0.025246381759643555, -0.025246381759643555], "metadata": {"source_tokens": ["Johns", "also", "appeared", "as", "an", "Imperial", "Officer", "in", "the", "1980", "`", "##`", "Star", "Wars", "sequel", "'", "##'", ",", "`", "##`", "The", "Empire", "Strike", "##s", "Back", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Johns", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "as", "an", "Imperial", "Officer", "in", "the", "1980", "`", "##`", "Star", "Wars", "sequel", "[unused6]", "[SEP]", "[unused1]", "The", "Empire", "[unused2]", "[unused3]", "Strike", "##s", "Back", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 186:  {"source": "Keats 's long and expensive medical training with Hammond and at Guy 's Hospital led his family to assume he would pursue a lifelong career in medicine , assuring financial security , and it seems that at this point Keats had a genuine desire to become a doctor .\n"}
prediction:  {"predictions": [[1, 26835, 9971, 2, 3, 1125, 4, 5, 170, 10416, 4232, 1106, 1561, 170, 3995, 1120, 1142, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 9971, 112, 1116, 1263, 1105, 5865, 2657, 2013, 1114, 11425, 1105, 1120, 6173, 112, 1116, 3355, 2, 3, 1521, 4, 5, 1117, 1266, 1106, 7568, 1119, 1156, 6799, 170, 14497, 1578, 1107, 5182, 117, 3919, 6660, 2798, 2699, 117, 1105, 1122, 3093, 1115, 1120, 1142, 1553, 26835, 9971, 102, 1, 26835, 9971, 2, 3, 1125, 4, 5, 170, 10416, 4232, 1106, 1561, 170, 3995, 1120, 1142, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 9971, 2, 3, 1125, 4, 5, 170, 10416, 4232, 1106, 1561, 170, 3995, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 9971, 2, 3, 1125, 4, 5, 170, 10416, 4232, 1106, 1561, 170, 3995, 1120, 1142, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 9971, 2, 3, 1125, 4, 5, 170, 10416, 4232, 1106, 1561, 170, 3995, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 9971, 2, 3, 1125, 4, 5, 170, 10416, 4232, 1106, 1561, 170, 3995, 1120, 1142, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 9971, 2, 3, 1125, 4, 5, 170, 10416, 4232, 1106, 1561, 170, 3995, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.07105384021997452, -0.029145782813429832, -0.0811123251914978, -0.1040264442563057, -0.10608343780040741, -0.11305186152458191, -0.11898867785930634, -0.13015814125537872, -0.22323966026306152, -0.22398900985717773], "metadata": {"source_tokens": ["Ke", "##ats", "'", "##s", "long", "and", "expensive", "medical", "training", "with", "Hammond", "and", "at", "Guy", "'", "##s", "Hospital", "led", "his", "family", "to", "assume", "he", "would", "pursue", "a", "lifelong", "career", "in", "medicine", ",", "ass", "##uring", "financial", "security", ",", "and", "it", "seems", "that", "at", "this", "point", "Ke", "##ats", "had", "a", "genuine", "desire", "to", "become", "a", "doctor", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ke", "##ats", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "genuine", "desire", "to", "become", "a", "doctor", "at", "this", "point", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ats", "'", "##s", "long", "and", "expensive", "medical", "training", "with", "Hammond", "and", "at", "Guy", "'", "##s", "Hospital", "[unused2]", "[unused3]", "led", "[unused4]", "[unused5]", "his", "family", "to", "assume", "he", "would", "pursue", "a", "lifelong", "career", "in", "medicine", ",", "ass", "##uring", "financial", "security", ",", "and", "it", "seems", "that", "at", "this", "point", "Ke", "##ats", "[SEP]", "[unused1]", "Ke", "##ats", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "genuine", "desire", "to", "become", "a", "doctor", "at", "this", "point", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ats", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "genuine", "desire", "to", "become", "a", "doctor", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ats", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "genuine", "desire", "to", "become", "a", "doctor", "at", "this", "point", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ats", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "genuine", "desire", "to", "become", "a", "doctor", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ats", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "genuine", "desire", "to", "become", "a", "doctor", "at", "this", "point", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ats", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "genuine", "desire", "to", "become", "a", "doctor", "[unused6]", "[SEP]"]]}

input 187:  {"source": "Keibler then asked for time off to appear on `` Dancing with the Stars '' .\n"}
prediction:  {"predictions": [[1, 26835, 5225, 1197, 2, 3, 1455, 4, 5, 1111, 1159, 1228, 1106, 2845, 1113, 169, 28152, 13234, 1114, 1103, 6200, 1173, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.015568792819976807, -0.16061115264892578, -0.15751910209655762, -0.15751910209655762, -0.15751910209655762, -0.15751910209655762, -0.15751910209655762, -0.15751910209655762, -0.15751910209655762, -0.15751910209655762], "metadata": {"source_tokens": ["Ke", "##ible", "##r", "then", "asked", "for", "time", "off", "to", "appear", "on", "`", "##`", "Dancing", "with", "the", "Stars", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ke", "##ible", "##r", "[unused2]", "[unused3]", "asked", "[unused4]", "[unused5]", "for", "time", "off", "to", "appear", "on", "`", "##`", "Dancing", "with", "the", "Stars", "then", "[unused6]", "[SEP]"]]}

input 188:  {"source": "Kim graduated from Ballard High School in Louisville , Kentucky , in 1989 and from Oberlin College in Ohio in 1993 where he double-majored in Government and English and played for the varsity lacrosse team .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 2702, 28137, 1918, 5077, 4359, 4, 5, 1107, 2384, 1105, 1483, 1949, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4246, 2, 3, 3024, 4, 5, 1121, 24241, 1693, 1323, 1107, 11595, 1107, 2056, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1307, 4, 5, 1111, 1103, 17611, 21135, 1264, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.08754099160432816, -0.0725083202123642, -0.04932373762130737, -0.1907660961151123, -0.18712067604064941, -0.18712067604064941, -0.18712067604064941, -0.18712067604064941, -0.18712067604064941, -0.18712067604064941], "metadata": {"source_tokens": ["Kim", "graduated", "from", "Ballard", "High", "School", "in", "Louisville", ",", "Kentucky", ",", "in", "1989", "and", "from", "O", "##ber", "##lin", "College", "in", "Ohio", "in", "1993", "where", "he", "double", "##-", "##ma", "##jo", "##red", "in", "Government", "and", "English", "and", "played", "for", "the", "varsity", "lacrosse", "team", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "double", "##-", "##ma", "##jo", "##red", "[unused4]", "[unused5]", "in", "Government", "and", "English", "1993", "[unused6]", "[SEP]", "[unused1]", "Kim", "[unused2]", "[unused3]", "graduated", "[unused4]", "[unused5]", "from", "Ballard", "High", "School", "in", "Louisville", "in", "1989", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "for", "the", "varsity", "lacrosse", "team", "[unused6]", "[SEP]"]]}

input 189:  {"source": "Kostabi 's other releases include : `` Songs For Sumera '' , `` New Alliance '' and `` The Spectre Of Modernism '' .\n"}
prediction:  {"predictions": [[1, 19892, 8419, 5567, 112, 1116, 1168, 6596, 2, 3, 1511, 4, 5, 6080, 1370, 15463, 4027, 1161, 112, 28131, 117, 169, 28152, 1203, 5643, 112, 28131, 1105, 169, 28152, 1109, 156, 26426, 1874, 2096, 4825, 1863, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0027477587573230267, -0.02824091911315918, -0.028608322143554688, -0.028608322143554688, -0.028608322143554688, -0.028608322143554688, -0.028608322143554688, -0.028608322143554688, -0.028608322143554688, -0.028608322143554688], "metadata": {"source_tokens": ["Ko", "##sta", "##bi", "'", "##s", "other", "releases", "include", ":", "`", "##`", "Songs", "For", "Su", "##mer", "##a", "'", "##'", ",", "`", "##`", "New", "Alliance", "'", "##'", "and", "`", "##`", "The", "S", "##pect", "##re", "Of", "Modern", "##ism", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ko", "##sta", "##bi", "'", "##s", "other", "releases", "[unused2]", "[unused3]", "include", "[unused4]", "[unused5]", "Songs", "For", "Su", "##mer", "##a", "'", "##'", ",", "`", "##`", "New", "Alliance", "'", "##'", "and", "`", "##`", "The", "S", "##pect", "##re", "Of", "Modern", "##ism", "[unused6]", "[SEP]"]]}

input 190:  {"source": "Langford kept Walcott at a distance with his longer reach and used his footwork to evade all of Walcott 's attacks .\n"}
prediction:  {"predictions": [[1, 12431, 2821, 2, 3, 2023, 4, 5, 160, 1348, 11627, 1120, 170, 2462, 1114, 1117, 2039, 2519, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12431, 2821, 2, 3, 1215, 4, 5, 1117, 2555, 5361, 1106, 174, 27923, 1155, 1104, 160, 1348, 11627, 112, 1116, 3690, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12431, 2821, 2, 3, 2023, 4, 5, 160, 1348, 11627, 1120, 170, 2462, 1114, 1117, 2039, 2519, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02750692330300808, -0.003486181376501918, -0.12614679336547852, -0.26667189598083496, -0.2227611541748047, -0.2227611541748047, -0.2227611541748047, -0.2227611541748047, -0.2227611541748047, -0.2227611541748047], "metadata": {"source_tokens": ["Lang", "##ford", "kept", "W", "##al", "##cott", "at", "a", "distance", "with", "his", "longer", "reach", "and", "used", "his", "foot", "##work", "to", "e", "##vade", "all", "of", "W", "##al", "##cott", "'", "##s", "attacks", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Lang", "##ford", "[unused2]", "[unused3]", "kept", "[unused4]", "[unused5]", "W", "##al", "##cott", "at", "a", "distance", "with", "his", "longer", "reach", "[unused6]", "[SEP]", "[unused1]", "Lang", "##ford", "[unused2]", "[unused3]", "used", "[unused4]", "[unused5]", "his", "foot", "##work", "to", "e", "##vade", "all", "of", "W", "##al", "##cott", "'", "##s", "attacks", "[unused6]", "[SEP]", "[unused1]", "Lang", "##ford", "[unused2]", "[unused3]", "kept", "[unused4]", "[unused5]", "W", "##al", "##cott", "at", "a", "distance", "with", "his", "longer", "reach", "[unused6]", "[SEP]"]]}

input 191:  {"source": "Language B then begins to supplant language A : the speakers of Language A abandon their own language in favor of the other language , generally because they believe that it will help them achieve certain goals within government , the workplace , and in social settings .\n"}
prediction:  {"predictions": [[1, 1103, 7417, 1104, 6828, 138, 2, 3, 11092, 4, 5, 1147, 1319, 1846, 1107, 5010, 1104, 1103, 1168, 1846, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6828, 139, 2, 3, 3471, 4, 5, 1106, 28117, 8661, 9180, 1846, 138, 1173, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 2059, 4, 5, 1115, 1122, 1209, 1494, 1172, 5515, 2218, 2513, 1439, 1433, 117, 1103, 19328, 117, 1105, 1107, 1934, 11106, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 7417, 1104, 6828, 138, 2, 3, 11092, 4, 5, 1147, 1319, 1846, 1107, 5010, 1104, 1103, 1168, 1846, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 7417, 1104, 6828, 138, 2, 3, 11092, 4, 5, 1147, 1319, 1846, 1107, 5010, 1104, 1103, 1168, 1846, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 7417, 1104, 6828, 138, 2, 3, 11092, 4, 5, 1147, 1319, 1846, 1107, 5010, 1104, 1103, 1168, 1846, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 7417, 1104, 6828, 138, 2, 3, 11092, 4, 5, 1147, 1319, 1846, 1107, 5010, 1104, 1103, 1168, 1846, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.048468541353940964, -0.08725015074014664, -0.04515475779771805, -0.10486134886741638, -0.11567378044128418, -0.11851213127374649, -0.14120365679264069, -0.22265338897705078, -0.22265315055847168, -0.22265315055847168], "metadata": {"source_tokens": ["Language", "B", "then", "begins", "to", "su", "##pp", "##lant", "language", "A", ":", "the", "speakers", "of", "Language", "A", "abandon", "their", "own", "language", "in", "favor", "of", "the", "other", "language", ",", "generally", "because", "they", "believe", "that", "it", "will", "help", "them", "achieve", "certain", "goals", "within", "government", ",", "the", "workplace", ",", "and", "in", "social", "settings", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "speakers", "of", "Language", "A", "[unused2]", "[unused3]", "abandon", "[unused4]", "[unused5]", "their", "own", "language", "in", "favor", "of", "the", "other", "language", "[unused6]", "[SEP]", "[unused1]", "Language", "B", "[unused2]", "[unused3]", "begins", "[unused4]", "[unused5]", "to", "su", "##pp", "##lant", "language", "A", "then", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "believe", "[unused4]", "[unused5]", "that", "it", "will", "help", "them", "achieve", "certain", "goals", "within", "government", ",", "the", "workplace", ",", "and", "in", "social", "settings", "[unused6]", "[SEP]", "[unused1]", "the", "speakers", "of", "Language", "A", "[unused2]", "[unused3]", "abandon", "[unused4]", "[unused5]", "their", "own", "language", "in", "favor", "of", "the", "other", "language", "[unused6]", "[SEP]", "[unused1]", "the", "speakers", "of", "Language", "A", "[unused2]", "[unused3]", "abandon", "[unused4]", "[unused5]", "their", "own", "language", "in", "favor", "of", "the", "other", "language", "[unused6]", "[SEP]", "[unused1]", "the", "speakers", "of", "Language", "A", "[unused2]", "[unused3]", "abandon", "[unused4]", "[unused5]", "their", "own", "language", "in", "favor", "of", "the", "other", "language", "[unused6]", "[SEP]", "[unused1]", "the", "speakers", "of", "Language", "A", "[unused2]", "[unused3]", "abandon", "[unused4]", "[unused5]", "their", "own", "language", "in", "favor", "of", "the", "other", "language", "[unused6]", "[SEP]"]]}

input 192:  {"source": "Lemmy believes that if Will Reid Dick had not been there , they could have worked through the problems , but ended up exchanging a few words and Clarke left the studio .\n"}
prediction:  {"predictions": [[1, 3180, 16211, 2, 3, 6616, 4, 5, 1115, 1191, 3100, 8721, 6416, 1125, 1136, 1151, 1175, 117, 1152, 1180, 1138, 1589, 1194, 1103, 2645, 117, 1133, 2207, 1146, 4252, 23286, 170, 1374, 1734, 1105, 7949, 1286, 1103, 2362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1180, 1138, 1589, 4, 5, 1194, 1103, 2645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3100, 8721, 6416, 2, 3, 1125, 1136, 1151, 4, 5, 1175, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 2207, 1146, 4, 5, 4252, 23286, 170, 1374, 1734, 1105, 7949, 1286, 1103, 2362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.003154065227136016, -0.0935172364115715, -0.06140736863017082, -0.15720050036907196, -0.1722424030303955, -0.16322851181030273, -0.16322851181030273, -0.16322851181030273, -0.16322851181030273, -0.16322851181030273], "metadata": {"source_tokens": ["Le", "##mmy", "believes", "that", "if", "Will", "Reid", "Dick", "had", "not", "been", "there", ",", "they", "could", "have", "worked", "through", "the", "problems", ",", "but", "ended", "up", "ex", "##changing", "a", "few", "words", "and", "Clarke", "left", "the", "studio", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Le", "##mmy", "[unused2]", "[unused3]", "believes", "[unused4]", "[unused5]", "that", "if", "Will", "Reid", "Dick", "had", "not", "been", "there", ",", "they", "could", "have", "worked", "through", "the", "problems", ",", "but", "ended", "up", "ex", "##changing", "a", "few", "words", "and", "Clarke", "left", "the", "studio", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "could", "have", "worked", "[unused4]", "[unused5]", "through", "the", "problems", "[unused6]", "[SEP]", "[unused1]", "Will", "Reid", "Dick", "[unused2]", "[unused3]", "had", "not", "been", "[unused4]", "[unused5]", "there", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "ended", "up", "[unused4]", "[unused5]", "ex", "##changing", "a", "few", "words", "and", "Clarke", "left", "the", "studio", "[unused6]", "[SEP]"]]}

input 193:  {"source": "Lens subluxation is also seen in dogs and is characterized by a partial displacement of the lens .\n"}
prediction:  {"predictions": [[1, 22824, 1116, 4841, 24796, 1891, 2, 3, 1110, 6858, 4, 5, 1118, 170, 7597, 15167, 1104, 1103, 11039, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 22824, 1116, 4841, 24796, 1891, 2, 3, 1110, 1145, 1562, 4, 5, 1107, 6363, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.005505800247192383, -0.01985115371644497, -0.003314495086669922, -0.0033087730407714844, -0.0033087730407714844, -0.0033087730407714844, -0.0033087730407714844, -0.0033087730407714844, -0.0033087730407714844, -0.0033087730407714844], "metadata": {"source_tokens": ["Len", "##s", "sub", "##lux", "##ation", "is", "also", "seen", "in", "dogs", "and", "is", "characterized", "by", "a", "partial", "displacement", "of", "the", "lens", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Len", "##s", "sub", "##lux", "##ation", "[unused2]", "[unused3]", "is", "characterized", "[unused4]", "[unused5]", "by", "a", "partial", "displacement", "of", "the", "lens", "[unused6]", "[SEP]", "[unused1]", "Len", "##s", "sub", "##lux", "##ation", "[unused2]", "[unused3]", "is", "also", "seen", "[unused4]", "[unused5]", "in", "dogs", "[unused6]", "[SEP]"]]}

input 194:  {"source": "Li Hongzhi began his public teachings of Falun Gong on 13 May 1992 in Changchun , and subsequently gave lectures and taught Falun Gong exercises across China .\n"}
prediction:  {"predictions": [[1, 5255, 3475, 23239, 2, 3, 1310, 4, 5, 1117, 1470, 12815, 1104, 143, 1348, 3488, 23703, 1113, 1492, 1318, 1924, 1107, 11497, 17143, 1179, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5255, 3475, 23239, 2, 3, 1522, 4, 5, 9548, 2886, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5255, 3475, 23239, 2, 3, 3188, 4, 5, 143, 1348, 3488, 23703, 11536, 1506, 1975, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0148145891726017, -0.09632723033428192, -0.03899511322379112, -0.14490342140197754, -0.14490389823913574, -0.14490389823913574, -0.14490389823913574, -0.14490389823913574, -0.14490389823913574, -0.14490389823913574], "metadata": {"source_tokens": ["Li", "Hong", "##zhi", "began", "his", "public", "teachings", "of", "F", "##al", "##un", "Gong", "on", "13", "May", "1992", "in", "Chang", "##chu", "##n", ",", "and", "subsequently", "gave", "lectures", "and", "taught", "F", "##al", "##un", "Gong", "exercises", "across", "China", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Li", "Hong", "##zhi", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "his", "public", "teachings", "of", "F", "##al", "##un", "Gong", "on", "13", "May", "1992", "in", "Chang", "##chu", "##n", "[unused6]", "[SEP]", "[unused1]", "Li", "Hong", "##zhi", "[unused2]", "[unused3]", "gave", "[unused4]", "[unused5]", "lectures", "subsequently", "[unused6]", "[SEP]", "[unused1]", "Li", "Hong", "##zhi", "[unused2]", "[unused3]", "taught", "[unused4]", "[unused5]", "F", "##al", "##un", "Gong", "exercises", "across", "China", "[unused6]", "[SEP]"]]}

input 195:  {"source": "Like other BBC content of the mid-1990s , it often lampooned the low-budget quality of satellite television available in the UK at the time .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 11140, 6931, 1174, 4, 5, 1103, 1822, 28137, 7925, 8484, 1204, 3068, 1104, 5989, 1778, 1907, 1107, 1103, 1993, 1120, 1103, 1159, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 11140, 6931, 1174, 4, 5, 1103, 1822, 28137, 7925, 8484, 1204, 3068, 1104, 5989, 1778, 1907, 1107, 1103, 1993, 2409, 1168, 3173, 3438, 1104, 1103, 2286, 28137, 16382, 21500, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 11140, 6931, 1174, 4, 5, 1103, 1822, 28137, 7925, 8484, 1204, 3068, 1104, 5989, 1778, 1907, 1107, 1103, 1993, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.011710882186889648, -0.04224716126918793, -0.08271417021751404, -0.12555694580078125, -0.12553071975708008, -0.12553071975708008, -0.12553071975708008, -0.12553071975708008, -0.12553071975708008, -0.12553071975708008], "metadata": {"source_tokens": ["Like", "other", "BBC", "content", "of", "the", "mid", "##-", "##19", "##90", "##s", ",", "it", "often", "lamp", "##oon", "##ed", "the", "low", "##-", "##bu", "##dge", "##t", "quality", "of", "satellite", "television", "available", "in", "the", "UK", "at", "the", "time", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "lamp", "##oon", "##ed", "[unused4]", "[unused5]", "the", "low", "##-", "##bu", "##dge", "##t", "quality", "of", "satellite", "television", "available", "in", "the", "UK", "at", "the", "time", "often", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "lamp", "##oon", "##ed", "[unused4]", "[unused5]", "the", "low", "##-", "##bu", "##dge", "##t", "quality", "of", "satellite", "television", "available", "in", "the", "UK", "Like", "other", "BBC", "content", "of", "the", "mid", "##-", "##19", "##90", "##s", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "lamp", "##oon", "##ed", "[unused4]", "[unused5]", "the", "low", "##-", "##bu", "##dge", "##t", "quality", "of", "satellite", "television", "available", "in", "the", "UK", "[unused6]", "[SEP]"]]}

input 196:  {"source": "Luke Robert Ravenstahl is an American politician who served as the 59th Mayor of Pittsburgh from 2006 until 2014 .\n"}
prediction:  {"predictions": [[1, 4599, 1823, 21848, 24401, 1233, 2, 3, 1110, 4, 5, 1126, 1237, 2931, 1150, 1462, 1112, 1103, 4589, 1582, 4643, 1104, 5610, 1121, 1386, 1235, 1387, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1126, 1237, 2931, 2, 3, 1462, 4, 5, 1112, 1103, 4589, 1582, 4643, 1104, 5610, 1121, 1386, 1235, 1387, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.000767942110542208, -0.008519047871232033, -0.005461215972900391, -0.005314350128173828, -0.005314350128173828, -0.005314350128173828, -0.005314350128173828, -0.005314350128173828, -0.005314350128173828, -0.005314350128173828], "metadata": {"source_tokens": ["Luke", "Robert", "Ravens", "##tah", "##l", "is", "an", "American", "politician", "who", "served", "as", "the", "59", "##th", "Mayor", "of", "Pittsburgh", "from", "2006", "until", "2014", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Luke", "Robert", "Ravens", "##tah", "##l", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "American", "politician", "who", "served", "as", "the", "59", "##th", "Mayor", "of", "Pittsburgh", "from", "2006", "until", "2014", "[unused6]", "[SEP]", "[unused1]", "an", "American", "politician", "[unused2]", "[unused3]", "served", "[unused4]", "[unused5]", "as", "the", "59", "##th", "Mayor", "of", "Pittsburgh", "from", "2006", "until", "2014", "[unused6]", "[SEP]"]]}

input 197:  {"source": "Males had a median income of $ 28,750 versus $ 16,250 for females .\n"}
prediction:  {"predictions": [[1, 7689, 2, 3, 1125, 4, 5, 170, 3151, 2467, 1104, 109, 1743, 28136, 26253, 1568, 6055, 109, 1479, 28136, 17600, 1568, 1111, 3032, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0006655087927356362, -0.0017766952514648438, -0.0018129348754882812, -0.0018129348754882812, -0.0018129348754882812, -0.0018129348754882812, -0.0018129348754882812, -0.0018129348754882812, -0.0018129348754882812, -0.0018129348754882812], "metadata": {"source_tokens": ["Males", "had", "a", "median", "income", "of", "$", "28", "##,", "##75", "##0", "versus", "$", "16", "##,", "##25", "##0", "for", "females", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Males", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "median", "income", "of", "$", "28", "##,", "##75", "##0", "versus", "$", "16", "##,", "##25", "##0", "for", "females", "[unused6]", "[SEP]"]]}

input 198:  {"source": "Males had a median income of $ 36,016 versus $ 32,679 for females .\n"}
prediction:  {"predictions": [[1, 7689, 2, 3, 1125, 4, 5, 170, 3151, 2467, 1104, 109, 3164, 28136, 24400, 1545, 6055, 109, 2724, 28136, 1545, 1559, 1580, 1111, 3032, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.000656097021419555, -0.0018072128295898438, -0.0018205642700195312, -0.0018205642700195312, -0.0018205642700195312, -0.0018205642700195312, -0.0018205642700195312, -0.0018205642700195312, -0.0018205642700195312, -0.0018205642700195312], "metadata": {"source_tokens": ["Males", "had", "a", "median", "income", "of", "$", "36", "##,", "##01", "##6", "versus", "$", "32", "##,", "##6", "##7", "##9", "for", "females", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Males", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "median", "income", "of", "$", "36", "##,", "##01", "##6", "versus", "$", "32", "##,", "##6", "##7", "##9", "for", "females", "[unused6]", "[SEP]"]]}

input 199:  {"source": "Many are surgically removed for aesthetics and relief of psychosocial burden , but larger ones are also excised for prevention of cancer , although the benefit is impossible to assess for any individual patient .\n"}
prediction:  {"predictions": [[1, 1103, 5257, 2, 3, 1110, 4, 5, 4763, 1106, 15187, 1111, 1251, 2510, 5351, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2610, 3200, 2, 3, 1132, 1145, 4252, 14636, 1181, 4, 5, 1111, 13347, 1104, 4182, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2408, 2, 3, 1132, 13467, 1193, 2856, 4, 5, 1111, 27456, 1105, 3893, 1104, 15604, 21155, 22354, 12562, 11904, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03804884850978851, -0.04732882231473923, -0.015037617646157742, -0.2226552963256836, -0.2226557731628418, -0.2226557731628418, -0.2226557731628418, -0.2226557731628418, -0.2226557731628418, -0.2226557731628418], "metadata": {"source_tokens": ["Many", "are", "surgical", "##ly", "removed", "for", "aesthetics", "and", "relief", "of", "ps", "##ych", "##oso", "##cial", "burden", ",", "but", "larger", "ones", "are", "also", "ex", "##cise", "##d", "for", "prevention", "of", "cancer", ",", "although", "the", "benefit", "is", "impossible", "to", "assess", "for", "any", "individual", "patient", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "benefit", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "impossible", "to", "assess", "for", "any", "individual", "patient", "[unused6]", "[SEP]", "[unused1]", "larger", "ones", "[unused2]", "[unused3]", "are", "also", "ex", "##cise", "##d", "[unused4]", "[unused5]", "for", "prevention", "of", "cancer", "[unused6]", "[SEP]", "[unused1]", "Many", "[unused2]", "[unused3]", "are", "surgical", "##ly", "removed", "[unused4]", "[unused5]", "for", "aesthetics", "and", "relief", "of", "ps", "##ych", "##oso", "##cial", "burden", "[unused6]", "[SEP]"]]}

input 200:  {"source": "Many overseas Chinese whose ancestors came from the Quanzhou area , especially those in Southeast Asia , often speak mainly Hokkien at home .\n"}
prediction:  {"predictions": [[1, 2408, 7474, 1922, 2, 3, 1338, 4, 5, 1121, 1103, 154, 8734, 10753, 1298, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2408, 7474, 1922, 2, 3, 2936, 2871, 4, 5, 9800, 1377, 11334, 1179, 1120, 1313, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.01006378885358572, -0.03872907906770706, -0.1506500244140625, -0.16534900665283203, -0.16534900665283203, -0.16534924507141113, -0.16534900665283203, -0.16534900665283203, -0.16534900665283203, -0.16534924507141113], "metadata": {"source_tokens": ["Many", "overseas", "Chinese", "whose", "ancestors", "came", "from", "the", "Q", "##uan", "##zhou", "area", ",", "especially", "those", "in", "Southeast", "Asia", ",", "often", "speak", "mainly", "Ho", "##k", "##kie", "##n", "at", "home", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Many", "overseas", "Chinese", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "from", "the", "Q", "##uan", "##zhou", "area", "[unused6]", "[SEP]", "[unused1]", "Many", "overseas", "Chinese", "[unused2]", "[unused3]", "speak", "mainly", "[unused4]", "[unused5]", "Ho", "##k", "##kie", "##n", "at", "home", "often", "[unused6]", "[SEP]"]]}

input 201:  {"source": "Meanwhile , the Mason City Division continued to operate as usual .\n"}
prediction:  {"predictions": [[1, 1103, 6287, 1392, 1784, 2, 3, 1598, 4, 5, 1106, 4732, 1112, 4400, 5459, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03449906408786774, -0.018857955932617188, -0.023291826248168945, -0.023291826248168945, -0.023291826248168945, -0.023291826248168945, -0.023291826248168945, -0.023291826248168945, -0.023291826248168945, -0.023291826248168945], "metadata": {"source_tokens": ["Meanwhile", ",", "the", "Mason", "City", "Division", "continued", "to", "operate", "as", "usual", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Mason", "City", "Division", "[unused2]", "[unused3]", "continued", "[unused4]", "[unused5]", "to", "operate", "as", "usual", "Meanwhile", "[unused6]", "[SEP]"]]}

input 202:  {"source": "Models , taking into account the size and room number of the barrack blocks in the Gorgan Wall forts and likely occupation density , produce figures between 15,000 and 36,000 soldiers .\n"}
prediction:  {"predictions": [[1, 24025, 117, 1781, 1154, 3300, 1103, 2060, 1105, 1395, 1295, 1104, 1103, 2927, 21580, 5511, 1107, 1103, 3414, 21061, 6250, 17725, 1105, 2620, 5846, 3476, 2, 3, 3133, 4, 5, 3736, 1206, 1405, 28136, 7629, 1568, 1105, 3164, 28136, 7629, 1568, 2803, 6, 102, 102, 102, 102, 102, 102, 102, 1, 24025, 2, 3, 1781, 4, 5, 1154, 3300, 1103, 2060, 1105, 1395, 1295, 1104, 1103, 2927, 21580, 5511, 1107, 1103, 3414, 21061, 6250, 17725, 1105, 2620, 5846, 3476, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.009689702652394772, -0.026393713429570198, -0.01917266845703125, -0.02002692222595215, -0.02002692222595215, -0.02002692222595215, -0.02002692222595215, -0.02002692222595215, -0.02002692222595215, -0.02002692222595215], "metadata": {"source_tokens": ["Models", ",", "taking", "into", "account", "the", "size", "and", "room", "number", "of", "the", "bar", "##rack", "blocks", "in", "the", "Go", "##rgan", "Wall", "forts", "and", "likely", "occupation", "density", ",", "produce", "figures", "between", "15", "##,", "##00", "##0", "and", "36", "##,", "##00", "##0", "soldiers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Models", ",", "taking", "into", "account", "the", "size", "and", "room", "number", "of", "the", "bar", "##rack", "blocks", "in", "the", "Go", "##rgan", "Wall", "forts", "and", "likely", "occupation", "density", "[unused2]", "[unused3]", "produce", "[unused4]", "[unused5]", "figures", "between", "15", "##,", "##00", "##0", "and", "36", "##,", "##00", "##0", "soldiers", "[unused6]", "[SEP]", "[unused1]", "Models", "[unused2]", "[unused3]", "taking", "[unused4]", "[unused5]", "into", "account", "the", "size", "and", "room", "number", "of", "the", "bar", "##rack", "blocks", "in", "the", "Go", "##rgan", "Wall", "forts", "and", "likely", "occupation", "density", "[unused6]", "[SEP]"]]}

input 203:  {"source": "Modern educational methods were more widely spread throughout the Empire , and the country embarked on a development scheme and plans for modernization , tempered by Ethiopian traditions , and within the framework of the ancient monarchical structure of the state .\n"}
prediction:  {"predictions": [[1, 4825, 4339, 4069, 2, 3, 1127, 4, 5, 1167, 3409, 2819, 2032, 1103, 2813, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1583, 2, 3, 11322, 4, 5, 1113, 170, 1718, 5471, 1105, 2714, 1111, 25145, 117, 26030, 1118, 15845, 7181, 117, 1105, 1439, 1103, 8297, 1104, 1103, 2890, 14390, 4571, 2401, 1104, 1103, 1352, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.06787090003490448, -0.031146936118602753, -0.22297978401184082, -0.22276973724365234, -0.22276973724365234, -0.22276973724365234, -0.22276973724365234, -0.22276973724365234, -0.22276973724365234, -0.22276973724365234], "metadata": {"source_tokens": ["Modern", "educational", "methods", "were", "more", "widely", "spread", "throughout", "the", "Empire", ",", "and", "the", "country", "embarked", "on", "a", "development", "scheme", "and", "plans", "for", "modernization", ",", "tempered", "by", "Ethiopian", "traditions", ",", "and", "within", "the", "framework", "of", "the", "ancient", "monarch", "##ical", "structure", "of", "the", "state", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Modern", "educational", "methods", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "more", "widely", "spread", "throughout", "the", "Empire", "[unused6]", "[SEP]", "[unused1]", "the", "country", "[unused2]", "[unused3]", "embarked", "[unused4]", "[unused5]", "on", "a", "development", "scheme", "and", "plans", "for", "modernization", ",", "tempered", "by", "Ethiopian", "traditions", ",", "and", "within", "the", "framework", "of", "the", "ancient", "monarch", "##ical", "structure", "of", "the", "state", "[unused6]", "[SEP]"]]}

input 204:  {"source": "Modernity has been blended without sacrificing on the traditional Buddhist ethos .\n"}
prediction:  {"predictions": [[1, 4825, 1785, 2, 3, 1144, 1151, 22357, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4825, 1785, 2, 3, 1443, 21718, 1665, 2047, 21361, 1158, 4, 5, 1113, 1103, 2361, 7558, 3084, 15342, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.005496293306350708, -0.012666821479797363, -0.0015873908996582031, -0.0015869140625, -0.0015869140625, -0.0015869140625, -0.0015869140625, -0.0015869140625, -0.0015869140625, -0.0015869140625], "metadata": {"source_tokens": ["Modern", "##ity", "has", "been", "blended", "without", "sa", "##c", "##ri", "##fic", "##ing", "on", "the", "traditional", "Buddhist", "et", "##hos", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Modern", "##ity", "[unused2]", "[unused3]", "has", "been", "blended", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Modern", "##ity", "[unused2]", "[unused3]", "without", "sa", "##c", "##ri", "##fic", "##ing", "[unused4]", "[unused5]", "on", "the", "traditional", "Buddhist", "et", "##hos", "[unused6]", "[SEP]"]]}

input 205:  {"source": "Modification of the river began in earnest with the arrival of the Florida East Coast Railway in Miami in 1896 .\n"}
prediction:  {"predictions": [[1, 12556, 3309, 11531, 1104, 1103, 2186, 2, 3, 1310, 4, 5, 1107, 21304, 1114, 1103, 4870, 1104, 1103, 2631, 1689, 3331, 2847, 1107, 4916, 1107, 5645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0012365086004137993, -0.12518930435180664, -0.12511301040649414, -0.12511301040649414, -0.12511301040649414, -0.12511301040649414, -0.12511301040649414, -0.12511301040649414, -0.12511301040649414, -0.12511301040649414], "metadata": {"source_tokens": ["Mo", "##di", "##fication", "of", "the", "river", "began", "in", "earnest", "with", "the", "arrival", "of", "the", "Florida", "East", "Coast", "Railway", "in", "Miami", "in", "1896", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mo", "##di", "##fication", "of", "the", "river", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "in", "earnest", "with", "the", "arrival", "of", "the", "Florida", "East", "Coast", "Railway", "in", "Miami", "in", "1896", "[unused6]", "[SEP]"]]}

input 206:  {"source": "Moore briefly dropped Marciano in the second round , but Marciano recovered and knocked Moore down five times , knocking him out in the ninth to retain the belt .\n"}
prediction:  {"predictions": [[1, 25663, 2728, 2, 3, 6203, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4673, 2, 3, 2434, 4, 5, 25663, 2728, 1107, 1103, 1248, 1668, 4016, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25663, 2728, 2, 3, 6011, 1205, 4, 5, 1421, 1551, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25663, 2728, 2, 3, 6011, 1205, 4, 5, 1421, 1551, 10760, 1140, 1149, 1107, 1103, 6948, 1106, 8983, 1103, 5614, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.15434834361076355, -0.05216890200972557, -0.15188828110694885, -0.0921488106250763, -0.14250993728637695, -0.14285850524902344, -0.14285850524902344, -0.14285850524902344, -0.14285850524902344, -0.14285850524902344], "metadata": {"source_tokens": ["Moore", "briefly", "dropped", "Marcia", "##no", "in", "the", "second", "round", ",", "but", "Marcia", "##no", "recovered", "and", "knocked", "Moore", "down", "five", "times", ",", "knocking", "him", "out", "in", "the", "ninth", "to", "retain", "the", "belt", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Marcia", "##no", "[unused2]", "[unused3]", "recovered", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Moore", "[unused2]", "[unused3]", "dropped", "[unused4]", "[unused5]", "Marcia", "##no", "in", "the", "second", "round", "briefly", "[unused6]", "[SEP]", "[unused1]", "Marcia", "##no", "[unused2]", "[unused3]", "knocked", "down", "[unused4]", "[unused5]", "five", "times", "[unused6]", "[SEP]", "[unused1]", "Marcia", "##no", "[unused2]", "[unused3]", "knocked", "down", "[unused4]", "[unused5]", "five", "times", "knocking", "him", "out", "in", "the", "ninth", "to", "retain", "the", "belt", "[unused6]", "[SEP]"]]}

input 207:  {"source": "Much of the station remains in the disused subway but there is no public access .\n"}
prediction:  {"predictions": [[1, 6335, 1104, 1103, 1466, 2, 3, 2606, 4, 5, 1107, 1103, 4267, 26097, 14790, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1185, 1470, 2469, 2, 3, 1175, 1110, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.004519490525126457, -0.02477165125310421, -0.0023317337036132812, -0.002327442169189453, -0.002327442169189453, -0.002327442169189453, -0.002327442169189453, -0.002327442169189453, -0.002327442169189453, -0.002327442169189453], "metadata": {"source_tokens": ["Much", "of", "the", "station", "remains", "in", "the", "di", "##sused", "subway", "but", "there", "is", "no", "public", "access", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Much", "of", "the", "station", "[unused2]", "[unused3]", "remains", "[unused4]", "[unused5]", "in", "the", "di", "##sused", "subway", "[unused6]", "[SEP]", "[unused1]", "no", "public", "access", "[unused2]", "[unused3]", "there", "is", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 208:  {"source": "Muhammad ibn Abu Bakr was a pious Muslim who supported the Imam of his time , Ali ibn Abi Talib , even though his sister Aisha opposed ` Ali in the battle of Jamal , Ibn Abu Bakr was faithful to his stepfather .\n"}
prediction:  {"predictions": [[1, 6710, 10452, 8158, 18757, 1377, 1197, 2, 3, 1108, 4, 5, 170, 185, 4179, 4360, 1150, 2726, 1103, 21765, 1104, 1117, 1159, 117, 4149, 10452, 138, 5567, 22515, 2646, 1830, 117, 1256, 1463, 1117, 2104, 19294, 5480, 4151, 169, 4149, 1107, 1103, 2321, 1104, 27440, 117, 14340, 8158, 18757, 102, 1, 14340, 8158, 18757, 1377, 1197, 2, 3, 1108, 4, 5, 12969, 1106, 1117, 24133, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 185, 4179, 4360, 2, 3, 2726, 4, 5, 1103, 21765, 1104, 1117, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 1159, 2, 3, 1110, 4, 5, 4149, 10452, 138, 5567, 22515, 2646, 1830, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 2104, 19294, 5480, 2, 3, 4151, 4, 5, 4149, 1107, 1103, 2321, 1104, 27440, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03303378447890282, -0.0664752870798111, -0.0591847188770771, -0.0770176500082016, -0.06148923188447952, -0.14486980438232422, -0.14497160911560059, -0.14497160911560059, -0.14497160911560059, -0.14497160911560059], "metadata": {"source_tokens": ["Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "was", "a", "p", "##ious", "Muslim", "who", "supported", "the", "Imam", "of", "his", "time", ",", "Ali", "ibn", "A", "##bi", "Ta", "##li", "##b", ",", "even", "though", "his", "sister", "Ai", "##sha", "opposed", "`", "Ali", "in", "the", "battle", "of", "Jamal", ",", "Ibn", "Abu", "Ba", "##k", "##r", "was", "faithful", "to", "his", "stepfather", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Muhammad", "ibn", "Abu", "Ba", "##k", "##r", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "p", "##ious", "Muslim", "who", "supported", "the", "Imam", "of", "his", "time", ",", "Ali", "ibn", "A", "##bi", "Ta", "##li", "##b", ",", "even", "though", "his", "sister", "Ai", "##sha", "opposed", "`", "Ali", "in", "the", "battle", "of", "Jamal", ",", "Ibn", "Abu", "Ba", "[SEP]", "[unused1]", "Ibn", "Abu", "Ba", "##k", "##r", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "faithful", "to", "his", "stepfather", "[unused6]", "[SEP]", "[unused1]", "a", "p", "##ious", "Muslim", "[unused2]", "[unused3]", "supported", "[unused4]", "[unused5]", "the", "Imam", "of", "his", "time", "[unused6]", "[SEP]", "[unused1]", "his", "time", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Ali", "ibn", "A", "##bi", "Ta", "##li", "##b", "[unused6]", "[SEP]", "[unused1]", "his", "sister", "Ai", "##sha", "[unused2]", "[unused3]", "opposed", "[unused4]", "[unused5]", "Ali", "in", "the", "battle", "of", "Jamal", "[unused6]", "[SEP]"]]}

input 209:  {"source": "Names like John Berks , Gary Edwards , Frank Sanders , Robin Alexander , Darryl Jooste , George Wayne and David Gresham all started out at LM Radio before moving to other stations such as Swazi Music Radio , Radio 702 , Springbok Radio and other SABC stations , 2JJ and Capital 604 .\n"}
prediction:  {"predictions": [[1, 13313, 1176, 1287, 4108, 18416, 117, 4926, 6847, 117, 2748, 12195, 117, 5981, 2792, 117, 25389, 8125, 15540, 1162, 117, 1667, 5489, 1105, 1681, 144, 21298, 2312, 2, 3, 1408, 1149, 4, 5, 1120, 149, 2107, 2664, 1196, 2232, 1106, 1168, 2930, 1216, 1112, 156, 3624, 5303, 1953, 2664, 102, 1, 13313, 1176, 1287, 4108, 18416, 4926, 6847, 2748, 12195, 5981, 2792, 25389, 8125, 15540, 1162, 1667, 5489, 1105, 1681, 144, 21298, 2312, 2, 3, 1408, 1149, 4, 5, 1120, 149, 2107, 2664, 1196, 2232, 1106, 1168, 2930, 1216, 1112, 156, 3624, 5303, 1953, 2664, 2664, 3102, 1477, 5350, 4043, 102, 1, 13313, 1176, 1287, 4108, 18416, 4926, 6847, 2748, 12195, 5981, 2792, 25389, 8125, 15540, 1162, 1667, 5489, 1105, 1681, 144, 21298, 2312, 2, 3, 1408, 1149, 4, 5, 1120, 149, 2107, 2664, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.005288000218570232, -0.05835074186325073, -0.06255923956632614, -0.22276544570922852, -0.2227637767791748, -0.2227637767791748, -0.2227637767791748, -0.2227637767791748, -0.2227637767791748, -0.2227637767791748], "metadata": {"source_tokens": ["Names", "like", "John", "Be", "##rks", ",", "Gary", "Edwards", ",", "Frank", "Sanders", ",", "Robin", "Alexander", ",", "Darryl", "Jo", "##ost", "##e", ",", "George", "Wayne", "and", "David", "G", "##resh", "##am", "all", "started", "out", "at", "L", "##M", "Radio", "before", "moving", "to", "other", "stations", "such", "as", "S", "##wa", "##zi", "Music", "Radio", ",", "Radio", "70", "##2", ",", "Spring", "##bo", "##k", "Radio", "and", "other", "SA", "##BC", "stations", ",", "2", "##J", "##J", "and", "Capital", "60", "##4", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Names", "like", "John", "Be", "##rks", ",", "Gary", "Edwards", ",", "Frank", "Sanders", ",", "Robin", "Alexander", ",", "Darryl", "Jo", "##ost", "##e", ",", "George", "Wayne", "and", "David", "G", "##resh", "##am", "[unused2]", "[unused3]", "started", "out", "[unused4]", "[unused5]", "at", "L", "##M", "Radio", "before", "moving", "to", "other", "stations", "such", "as", "S", "##wa", "##zi", "Music", "Radio", "[SEP]", "[unused1]", "Names", "like", "John", "Be", "##rks", "Gary", "Edwards", "Frank", "Sanders", "Robin", "Alexander", "Darryl", "Jo", "##ost", "##e", "George", "Wayne", "and", "David", "G", "##resh", "##am", "[unused2]", "[unused3]", "started", "out", "[unused4]", "[unused5]", "at", "L", "##M", "Radio", "before", "moving", "to", "other", "stations", "such", "as", "S", "##wa", "##zi", "Music", "Radio", "Radio", "70", "##2", "Spring", "##bo", "[SEP]", "[unused1]", "Names", "like", "John", "Be", "##rks", "Gary", "Edwards", "Frank", "Sanders", "Robin", "Alexander", "Darryl", "Jo", "##ost", "##e", "George", "Wayne", "and", "David", "G", "##resh", "##am", "[unused2]", "[unused3]", "started", "out", "[unused4]", "[unused5]", "at", "L", "##M", "Radio", "[unused6]", "[SEP]"]]}

input 210:  {"source": "Newhan split the season between Triple-A Round Rock , where he hit .308 .\n"}
prediction:  {"predictions": [[1, 1203, 3822, 2, 3, 3325, 4, 5, 1103, 1265, 1206, 9457, 28137, 1592, 4200, 2977, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1855, 4, 5, 119, 13144, 1604, 9457, 28137, 1592, 4200, 2977, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.005003372672945261, -0.038537368178367615, -0.0019221305847167969, -0.0019693374633789062, -0.0019693374633789062, -0.0019693374633789062, -0.0019693374633789062, -0.0019693374633789062, -0.0019693374633789062, -0.0019693374633789062], "metadata": {"source_tokens": ["New", "##han", "split", "the", "season", "between", "Triple", "##-", "##A", "Round", "Rock", ",", "where", "he", "hit", ".", "##30", "##8", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "New", "##han", "[unused2]", "[unused3]", "split", "[unused4]", "[unused5]", "the", "season", "between", "Triple", "##-", "##A", "Round", "Rock", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "hit", "[unused4]", "[unused5]", ".", "##30", "##8", "Triple", "##-", "##A", "Round", "Rock", "[unused6]", "[SEP]"]]}

input 211:  {"source": "Next morning , the race left the city on the way to the Pyrenees and stopped in the suburb of Gradignan , in the university area of La House .\n"}
prediction:  {"predictions": [[1, 1103, 1886, 2, 3, 1286, 4, 5, 1103, 1331, 1113, 1103, 1236, 1106, 1103, 153, 10930, 27075, 5893, 2106, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1886, 2, 3, 2141, 4, 5, 1107, 1103, 7144, 1104, 144, 9871, 11368, 1389, 1107, 1103, 2755, 1298, 1104, 2001, 1585, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1886, 2, 3, 2141, 4, 5, 1107, 1103, 7144, 1104, 144, 9871, 11368, 1389, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03606799617409706, -0.026977140456438065, -0.044325146824121475, -0.22264933586120605, -0.22269129753112793, -0.22269129753112793, -0.22269129753112793, -0.22269129753112793, -0.22269129753112793, -0.22269129753112793], "metadata": {"source_tokens": ["Next", "morning", ",", "the", "race", "left", "the", "city", "on", "the", "way", "to", "the", "P", "##yre", "##nees", "and", "stopped", "in", "the", "suburb", "of", "G", "##rad", "##ign", "##an", ",", "in", "the", "university", "area", "of", "La", "House", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "race", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "the", "city", "on", "the", "way", "to", "the", "P", "##yre", "##nees", "Next", "morning", "[unused6]", "[SEP]", "[unused1]", "the", "race", "[unused2]", "[unused3]", "stopped", "[unused4]", "[unused5]", "in", "the", "suburb", "of", "G", "##rad", "##ign", "##an", "in", "the", "university", "area", "of", "La", "House", "[unused6]", "[SEP]", "[unused1]", "the", "race", "[unused2]", "[unused3]", "stopped", "[unused4]", "[unused5]", "in", "the", "suburb", "of", "G", "##rad", "##ign", "##an", "[unused6]", "[SEP]"]]}

input 212:  {"source": "No announcement from UTV was made about the decision to close the station earlier than planned .\n"}
prediction:  {"predictions": [[1, 1302, 8679, 1121, 158, 7073, 2, 3, 1108, 1189, 4, 5, 1164, 1103, 2383, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1302, 8679, 1121, 158, 7073, 2, 3, 1108, 1189, 4, 5, 1164, 1103, 2383, 1106, 1601, 1103, 1466, 2206, 1190, 2919, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.013700821436941624, -0.018190011382102966, -0.003512859344482422, -0.0035085678100585938, -0.0035085678100585938, -0.0035085678100585938, -0.0035085678100585938, -0.0035085678100585938, -0.0035085678100585938, -0.0035085678100585938], "metadata": {"source_tokens": ["No", "announcement", "from", "U", "##TV", "was", "made", "about", "the", "decision", "to", "close", "the", "station", "earlier", "than", "planned", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "No", "announcement", "from", "U", "##TV", "[unused2]", "[unused3]", "was", "made", "[unused4]", "[unused5]", "about", "the", "decision", "[unused6]", "[SEP]", "[unused1]", "No", "announcement", "from", "U", "##TV", "[unused2]", "[unused3]", "was", "made", "[unused4]", "[unused5]", "about", "the", "decision", "to", "close", "the", "station", "earlier", "than", "planned", "[unused6]", "[SEP]"]]}

input 213:  {"source": "Noatak has a gravel public airstrip and is primarily reached by air .\n"}
prediction:  {"predictions": [[1, 1302, 6575, 1377, 2, 3, 1144, 4, 5, 170, 11898, 1470, 15692, 19091, 1643, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1302, 6575, 1377, 2, 3, 1110, 3120, 1680, 4, 5, 1118, 1586, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02445930615067482, -0.004508821293711662, -0.003376483917236328, -0.0033826828002929688, -0.0033826828002929688, -0.0033826828002929688, -0.0033826828002929688, -0.0033826828002929688, -0.0033826828002929688, -0.0033826828002929688], "metadata": {"source_tokens": ["No", "##ata", "##k", "has", "a", "gravel", "public", "airs", "##tri", "##p", "and", "is", "primarily", "reached", "by", "air", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "No", "##ata", "##k", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "a", "gravel", "public", "airs", "##tri", "##p", "[unused6]", "[SEP]", "[unused1]", "No", "##ata", "##k", "[unused2]", "[unused3]", "is", "primarily", "reached", "[unused4]", "[unused5]", "by", "air", "[unused6]", "[SEP]"]]}

input 214:  {"source": "Not everyone completely trusted Vakama 's vision - Matau was particularly frustrated at following what he considered the delusions of a `` fire-spitter '' - but with nothing else to go on they decided to track the Matoran down .\n"}
prediction:  {"predictions": [[1, 1753, 2490, 2, 3, 9373, 4, 5, 159, 11747, 1918, 112, 1116, 4152, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 28044, 1358, 2, 3, 1108, 4, 5, 2521, 11010, 1120, 1378, 1184, 1119, 1737, 1103, 3687, 27262, 1104, 170, 169, 28152, 1783, 28137, 20080, 25608, 1197, 112, 28131, 118, 1133, 1114, 1720, 1950, 1106, 1301, 1113, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1879, 1205, 4, 5, 1103, 25702, 15186, 1205, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1737, 4, 5, 1103, 3687, 27262, 1104, 170, 169, 28152, 1783, 28137, 20080, 25608, 1197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.08325940370559692, -0.056415606290102005, -0.1547834724187851, -0.08721126616001129, -0.22268462181091309, -0.22268152236938477, -0.22268152236938477, -0.22268152236938477, -0.22268152236938477, -0.22268152236938477], "metadata": {"source_tokens": ["Not", "everyone", "completely", "trusted", "V", "##aka", "##ma", "'", "##s", "vision", "-", "Mata", "##u", "was", "particularly", "frustrated", "at", "following", "what", "he", "considered", "the", "del", "##usions", "of", "a", "`", "##`", "fire", "##-", "##sp", "##itte", "##r", "'", "##'", "-", "but", "with", "nothing", "else", "to", "go", "on", "they", "decided", "to", "track", "the", "Mat", "##oran", "down", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Not", "everyone", "[unused2]", "[unused3]", "trusted", "[unused4]", "[unused5]", "V", "##aka", "##ma", "'", "##s", "vision", "[unused6]", "[SEP]", "[unused1]", "Mata", "##u", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "particularly", "frustrated", "at", "following", "what", "he", "considered", "the", "del", "##usions", "of", "a", "`", "##`", "fire", "##-", "##sp", "##itte", "##r", "'", "##'", "-", "but", "with", "nothing", "else", "to", "go", "on", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "decided", "down", "[unused4]", "[unused5]", "the", "Mat", "##oran", "down", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "considered", "[unused4]", "[unused5]", "the", "del", "##usions", "of", "a", "`", "##`", "fire", "##-", "##sp", "##itte", "##r", "[unused6]", "[SEP]"]]}

input 215:  {"source": "Nothing is known for certain about his life before about 1580 , but contemporary or near-contemporary accounts suggest that he was brought up as a member of the Church of Scotland , spent some time in Argyll before leaving for the Continent , and was converted to Catholicism in Spain .\n"}
prediction:  {"predictions": [[1, 3793, 1137, 1485, 28137, 7235, 18408, 18876, 3113, 5756, 2, 3, 5996, 4, 5, 1115, 1119, 1108, 1814, 1146, 1112, 170, 1420, 1104, 1103, 1722, 1104, 3030, 117, 2097, 1199, 1159, 1107, 138, 17292, 2339, 1196, 2128, 1111, 1103, 16752, 24123, 117, 1105, 1108, 4213, 1106, 17164, 1107, 2722, 102, 1, 4302, 2, 3, 1110, 1227, 4, 5, 1111, 2218, 1164, 1117, 1297, 1196, 1164, 18960, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1814, 1146, 4, 5, 1112, 170, 1420, 1104, 1103, 1722, 1104, 3030, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1814, 1146, 4, 5, 1112, 170, 1420, 1104, 1103, 1722, 1104, 3030, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1814, 1146, 4, 5, 1112, 170, 1420, 1104, 1103, 1722, 1104, 3030, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1814, 1146, 4, 5, 1112, 170, 1420, 1104, 1103, 1722, 1104, 3030, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1814, 1146, 4, 5, 1112, 170, 1420, 1104, 1103, 1722, 1104, 3030, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.028778523206710815, -0.03081485442817211, -0.05345907807350159, -0.0773492082953453, -0.08735436201095581, -0.09139259159564972, -0.11028633266687393, -0.22273612022399902, -0.22273588180541992, -0.22273588180541992], "metadata": {"source_tokens": ["Nothing", "is", "known", "for", "certain", "about", "his", "life", "before", "about", "158", "##0", ",", "but", "contemporary", "or", "near", "##-", "##con", "##tem", "##por", "##ary", "accounts", "suggest", "that", "he", "was", "brought", "up", "as", "a", "member", "of", "the", "Church", "of", "Scotland", ",", "spent", "some", "time", "in", "A", "##rgy", "##ll", "before", "leaving", "for", "the", "Con", "##tinent", ",", "and", "was", "converted", "to", "Catholicism", "in", "Spain", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "contemporary", "or", "near", "##-", "##con", "##tem", "##por", "##ary", "accounts", "[unused2]", "[unused3]", "suggest", "[unused4]", "[unused5]", "that", "he", "was", "brought", "up", "as", "a", "member", "of", "the", "Church", "of", "Scotland", ",", "spent", "some", "time", "in", "A", "##rgy", "##ll", "before", "leaving", "for", "the", "Con", "##tinent", ",", "and", "was", "converted", "to", "Catholicism", "in", "Spain", "[SEP]", "[unused1]", "Nothing", "[unused2]", "[unused3]", "is", "known", "[unused4]", "[unused5]", "for", "certain", "about", "his", "life", "before", "about", "158", "##0", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "brought", "up", "[unused4]", "[unused5]", "as", "a", "member", "of", "the", "Church", "of", "Scotland", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "brought", "up", "[unused4]", "[unused5]", "as", "a", "member", "of", "the", "Church", "of", "Scotland", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "brought", "up", "[unused4]", "[unused5]", "as", "a", "member", "of", "the", "Church", "of", "Scotland", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "brought", "up", "[unused4]", "[unused5]", "as", "a", "member", "of", "the", "Church", "of", "Scotland", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "brought", "up", "[unused4]", "[unused5]", "as", "a", "member", "of", "the", "Church", "of", "Scotland", "[unused6]", "[SEP]"]]}

input 216:  {"source": "Obviously the epilogue was not an afterthought supplied too late for the English edition , for it is referred to in `` The Castaway '' : `` in the sequel of the narrative , it will then be seen what like abandonment befell myself . ''\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 1209, 1129, 1562, 4, 5, 1184, 1176, 25356, 1129, 27610, 1991, 1107, 1103, 8047, 1104, 1103, 8195, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 174, 8508, 12733, 2, 3, 1108, 1136, 4, 5, 1126, 1170, 1582, 26960, 7694, 1315, 1523, 1111, 1103, 1483, 2596, 1111, 1122, 1110, 2752, 1106, 1107, 169, 28152, 1109, 21452, 7138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 2752, 4, 5, 1106, 1107, 169, 28152, 1109, 21452, 7138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1209, 1129, 1562, 4, 5, 1184, 1176, 25356, 1129, 27610, 1991, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.07262619584798813, -0.07607758045196533, -0.09131529182195663, -0.1303737610578537, -0.22266554832458496, -0.22266530990600586, -0.22266530990600586, -0.22266530990600586, -0.22266530990600586, -0.22266530990600586], "metadata": {"source_tokens": ["Obviously", "the", "e", "##pi", "##logue", "was", "not", "an", "after", "##th", "##ought", "supplied", "too", "late", "for", "the", "English", "edition", ",", "for", "it", "is", "referred", "to", "in", "`", "##`", "The", "Cast", "##away", "'", "##'", ":", "`", "##`", "in", "the", "sequel", "of", "the", "narrative", ",", "it", "will", "then", "be", "seen", "what", "like", "abandonment", "be", "##fell", "myself", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "will", "be", "seen", "[unused4]", "[unused5]", "what", "like", "abandonment", "be", "##fell", "myself", "in", "the", "sequel", "of", "the", "narrative", "[unused6]", "[SEP]", "[unused1]", "the", "e", "##pi", "##logue", "[unused2]", "[unused3]", "was", "not", "[unused4]", "[unused5]", "an", "after", "##th", "##ought", "supplied", "too", "late", "for", "the", "English", "edition", "for", "it", "is", "referred", "to", "in", "`", "##`", "The", "Cast", "##away", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "referred", "[unused4]", "[unused5]", "to", "in", "`", "##`", "The", "Cast", "##away", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "will", "be", "seen", "[unused4]", "[unused5]", "what", "like", "abandonment", "be", "##fell", "myself", "[unused6]", "[SEP]"]]}

input 217:  {"source": "Of the rest of the population , there was 1 individual who belonged to the Christian Catholic faith .\n"}
prediction:  {"predictions": [[1, 122, 2510, 2, 3, 5609, 4, 5, 1106, 1103, 2131, 2336, 5228, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 122, 2510, 2, 3, 1175, 1108, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0011588732013478875, -0.11185109615325928, -0.0026216506958007812, -0.0026459693908691406, -0.0026459693908691406, -0.0026459693908691406, -0.0026459693908691406, -0.0026459693908691406, -0.0026459693908691406, -0.0026459693908691406], "metadata": {"source_tokens": ["Of", "the", "rest", "of", "the", "population", ",", "there", "was", "1", "individual", "who", "belonged", "to", "the", "Christian", "Catholic", "faith", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "1", "individual", "[unused2]", "[unused3]", "belonged", "[unused4]", "[unused5]", "to", "the", "Christian", "Catholic", "faith", "[unused6]", "[SEP]", "[unused1]", "1", "individual", "[unused2]", "[unused3]", "there", "was", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 218:  {"source": "On 16 June 1944 , British double agent `` Garbo '' was requested by his German controllers to give information on the sites and times of V-1 impacts , with similar requests made to the other German agents in Britain , `` Brutus '' and `` Tate '' .\n"}
prediction:  {"predictions": [[1, 1418, 2702, 3677, 169, 28152, 144, 1813, 4043, 2, 3, 1108, 6792, 4, 5, 1118, 1117, 1528, 25747, 1106, 1660, 1869, 1113, 1103, 3911, 1105, 1551, 1104, 159, 28137, 1475, 15791, 1212, 1479, 1340, 2782, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1861, 11458, 2, 3, 1189, 4, 5, 1106, 1103, 1168, 1528, 5789, 1107, 2855, 117, 169, 28152, 139, 5082, 4814, 112, 28131, 1105, 169, 28152, 9727, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1418, 2702, 3677, 144, 1813, 4043, 2, 3, 1108, 6792, 4, 5, 1118, 1117, 1528, 25747, 1106, 1660, 1869, 1113, 1103, 3911, 1105, 1551, 1104, 159, 28137, 1475, 15791, 1114, 1861, 11458, 1189, 1106, 1103, 1168, 1528, 5789, 1107, 2855, 139, 5082, 4814, 1105, 9727, 6, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.047509681433439255, -0.02960231713950634, -0.04759948328137398, -0.14447808265686035, -0.14415621757507324, -0.14415621757507324, -0.14415621757507324, -0.14415621757507324, -0.14415621757507324, -0.14415621757507324], "metadata": {"source_tokens": ["On", "16", "June", "1944", ",", "British", "double", "agent", "`", "##`", "G", "##ar", "##bo", "'", "##'", "was", "requested", "by", "his", "German", "controllers", "to", "give", "information", "on", "the", "sites", "and", "times", "of", "V", "##-", "##1", "impacts", ",", "with", "similar", "requests", "made", "to", "the", "other", "German", "agents", "in", "Britain", ",", "`", "##`", "B", "##ru", "##tus", "'", "##'", "and", "`", "##`", "Tate", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "British", "double", "agent", "`", "##`", "G", "##ar", "##bo", "[unused2]", "[unused3]", "was", "requested", "[unused4]", "[unused5]", "by", "his", "German", "controllers", "to", "give", "information", "on", "the", "sites", "and", "times", "of", "V", "##-", "##1", "impacts", "On", "16", "June", "1944", "[unused6]", "[SEP]", "[unused1]", "similar", "requests", "[unused2]", "[unused3]", "made", "[unused4]", "[unused5]", "to", "the", "other", "German", "agents", "in", "Britain", ",", "`", "##`", "B", "##ru", "##tus", "'", "##'", "and", "`", "##`", "Tate", "[unused6]", "[SEP]", "[unused1]", "British", "double", "agent", "G", "##ar", "##bo", "[unused2]", "[unused3]", "was", "requested", "[unused4]", "[unused5]", "by", "his", "German", "controllers", "to", "give", "information", "on", "the", "sites", "and", "times", "of", "V", "##-", "##1", "impacts", "with", "similar", "requests", "made", "to", "the", "other", "German", "agents", "in", "Britain", "B", "##ru", "##tus", "and", "Tate", "[unused6]", "[SEP]"]]}

input 219:  {"source": "On May 13 , 2010 , Yost was named manager of the Kansas City Royals , replacing Trey Hillman .\n"}
prediction:  {"predictions": [[1, 14941, 2050, 2, 3, 1108, 1417, 4, 5, 2618, 1104, 1103, 4312, 1392, 17692, 1212, 1318, 1492, 117, 1333, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 14941, 2050, 2, 3, 1108, 1417, 4, 5, 2618, 1104, 1103, 4312, 1392, 17692, 5861, 15558, 2404, 1399, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0281351488083601, -0.018102498725056648, -0.02824997901916504, -0.03433680534362793, -0.03433680534362793, -0.03433680534362793, -0.03433680534362793, -0.03433680534362793, -0.03433680534362793, -0.03433680534362793], "metadata": {"source_tokens": ["On", "May", "13", ",", "2010", ",", "Yo", "##st", "was", "named", "manager", "of", "the", "Kansas", "City", "Royals", ",", "replacing", "Trey", "Hill", "##man", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Yo", "##st", "[unused2]", "[unused3]", "was", "named", "[unused4]", "[unused5]", "manager", "of", "the", "Kansas", "City", "Royals", "On", "May", "13", ",", "2010", "[unused6]", "[SEP]", "[unused1]", "Yo", "##st", "[unused2]", "[unused3]", "was", "named", "[unused4]", "[unused5]", "manager", "of", "the", "Kansas", "City", "Royals", "replacing", "Trey", "Hill", "##man", "[unused6]", "[SEP]"]]}

input 220:  {"source": "On May 15 , 2007 , XM suspended Opie & Anthony for 30 days , in response to a broadcast featuring a homeless man who wandered into the studio .\n"}
prediction:  {"predictions": [[1, 170, 3012, 2, 3, 3022, 4, 5, 170, 12501, 1299, 1150, 13668, 1154, 1103, 2362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 161, 2107, 2, 3, 6232, 4, 5, 9126, 1663, 111, 4140, 1111, 1476, 1552, 1107, 2593, 1106, 170, 3012, 1212, 1318, 1405, 117, 1384, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 161, 2107, 2, 3, 6232, 4, 5, 9126, 1663, 111, 4140, 1111, 1476, 1552, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 12501, 1299, 2, 3, 13668, 4, 5, 1154, 1103, 2362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.030919339507818222, -0.057937342673540115, -0.09483729302883148, -0.06692396849393845, -0.14175128936767578, -0.14171290397644043, -0.14171290397644043, -0.14171290397644043, -0.14171290397644043, -0.14171290397644043], "metadata": {"source_tokens": ["On", "May", "15", ",", "2007", ",", "X", "##M", "suspended", "Op", "##ie", "&", "Anthony", "for", "30", "days", ",", "in", "response", "to", "a", "broadcast", "featuring", "a", "homeless", "man", "who", "wandered", "into", "the", "studio", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "broadcast", "[unused2]", "[unused3]", "featuring", "[unused4]", "[unused5]", "a", "homeless", "man", "who", "wandered", "into", "the", "studio", "[unused6]", "[SEP]", "[unused1]", "X", "##M", "[unused2]", "[unused3]", "suspended", "[unused4]", "[unused5]", "Op", "##ie", "&", "Anthony", "for", "30", "days", "in", "response", "to", "a", "broadcast", "On", "May", "15", ",", "2007", "[unused6]", "[SEP]", "[unused1]", "X", "##M", "[unused2]", "[unused3]", "suspended", "[unused4]", "[unused5]", "Op", "##ie", "&", "Anthony", "for", "30", "days", "[unused6]", "[SEP]", "[unused1]", "a", "homeless", "man", "[unused2]", "[unused3]", "wandered", "[unused4]", "[unused5]", "into", "the", "studio", "[unused6]", "[SEP]"]]}

input 221:  {"source": "On November 2 , 2005 , Brown ended his contract early and left the federal government .\n"}
prediction:  {"predictions": [[1, 2671, 2, 3, 2207, 4, 5, 1117, 2329, 1346, 1212, 1379, 123, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2671, 2, 3, 1286, 4, 5, 1103, 2877, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.07826074212789536, -0.02982933260500431, -0.10239815711975098, -0.12612700462341309, -0.12612700462341309, -0.12612700462341309, -0.12612700462341309, -0.12612700462341309, -0.12612700462341309, -0.12612700462341309], "metadata": {"source_tokens": ["On", "November", "2", ",", "2005", ",", "Brown", "ended", "his", "contract", "early", "and", "left", "the", "federal", "government", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Brown", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "his", "contract", "early", "On", "November", "2", "[unused6]", "[SEP]", "[unused1]", "Brown", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "the", "federal", "government", "[unused6]", "[SEP]"]]}

input 222:  {"source": "One candidate is a wreck at the western end of Manitoulin Island in Lake Huron , with another wreck near Escanaba , Michigan , also proposed .\n"}
prediction:  {"predictions": [[1, 1448, 3234, 2, 3, 1110, 4, 5, 170, 13573, 1120, 1103, 2466, 1322, 1104, 2268, 8383, 19001, 2054, 1107, 2161, 24289, 117, 1114, 1330, 13573, 1485, 142, 26996, 1605, 2822, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1330, 13573, 1485, 142, 26996, 1605, 2822, 2, 3, 1110, 4, 5, 3312, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1330, 13573, 1485, 142, 26996, 1605, 2822, 2, 3, 1145, 3000, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.040564898401498795, -0.11811044067144394, -0.08860153704881668, -0.026836156845092773, -0.026835918426513672, -0.026835918426513672, -0.026835918426513672, -0.026835918426513672, -0.026835918426513672, -0.026835918426513672], "metadata": {"source_tokens": ["One", "candidate", "is", "a", "wreck", "at", "the", "western", "end", "of", "Man", "##ito", "##ulin", "Island", "in", "Lake", "Huron", ",", "with", "another", "wreck", "near", "E", "##sca", "##na", "##ba", ",", "Michigan", ",", "also", "proposed", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "One", "candidate", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "wreck", "at", "the", "western", "end", "of", "Man", "##ito", "##ulin", "Island", "in", "Lake", "Huron", ",", "with", "another", "wreck", "near", "E", "##sca", "##na", "##ba", "[unused6]", "[SEP]", "[unused1]", "another", "wreck", "near", "E", "##sca", "##na", "##ba", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Michigan", "[unused6]", "[SEP]", "[unused1]", "another", "wreck", "near", "E", "##sca", "##na", "##ba", "[unused2]", "[unused3]", "also", "proposed", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 223:  {"source": "One example could be `` Time '' , the fifth song from Pink Floyd 's 1973 album `` The Dark Side Of The Moon '' , which contains a reprise of `` Breathe '' , the first song of the same album .\n"}
prediction:  {"predictions": [[1, 1448, 1859, 2, 3, 1180, 1129, 4, 5, 2614, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10763, 12450, 112, 1116, 2478, 1312, 2, 3, 2515, 4, 5, 170, 1231, 16874, 1104, 169, 28152, 139, 18709, 1162, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2614, 2, 3, 1110, 4, 5, 1103, 3049, 1461, 1121, 10763, 12450, 112, 1116, 2478, 1312, 1109, 4753, 6383, 2096, 1109, 5148, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.048171598464250565, -0.06396612524986267, -0.05159522965550423, -0.22270584106445312, -0.2227015495300293, -0.2227015495300293, -0.2227015495300293, -0.2227015495300293, -0.2227015495300293, -0.2227015495300293], "metadata": {"source_tokens": ["One", "example", "could", "be", "`", "##`", "Time", "'", "##'", ",", "the", "fifth", "song", "from", "Pink", "Floyd", "'", "##s", "1973", "album", "`", "##`", "The", "Dark", "Side", "Of", "The", "Moon", "'", "##'", ",", "which", "contains", "a", "re", "##prise", "of", "`", "##`", "B", "##reath", "##e", "'", "##'", ",", "the", "first", "song", "of", "the", "same", "album", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "One", "example", "[unused2]", "[unused3]", "could", "be", "[unused4]", "[unused5]", "Time", "[unused6]", "[SEP]", "[unused1]", "Pink", "Floyd", "'", "##s", "1973", "album", "[unused2]", "[unused3]", "contains", "[unused4]", "[unused5]", "a", "re", "##prise", "of", "`", "##`", "B", "##reath", "##e", "[unused6]", "[SEP]", "[unused1]", "Time", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "fifth", "song", "from", "Pink", "Floyd", "'", "##s", "1973", "album", "The", "Dark", "Side", "Of", "The", "Moon", "[unused6]", "[SEP]"]]}

input 224:  {"source": "Only Ballard and Williams are left after Sergeant Jericho and the other officers , along with the two train operators , are killed when they try to finish the fight .\n"}
prediction:  {"predictions": [[1, 2809, 24241, 1105, 2902, 2, 3, 1132, 1286, 4, 5, 1170, 7908, 18545, 1105, 1103, 1168, 3099, 117, 1373, 1114, 1103, 1160, 2669, 9298, 117, 1132, 1841, 1165, 1152, 2222, 1106, 3146, 1103, 2147, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7908, 18545, 1105, 1103, 1168, 3099, 2, 3, 1132, 1841, 4, 5, 1165, 1152, 2222, 1106, 3146, 1103, 2147, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.008607557974755764, -0.0639871135354042, -0.22408413887023926, -0.22325348854064941, -0.22325348854064941, -0.22325348854064941, -0.22325348854064941, -0.22325348854064941, -0.22325348854064941, -0.22325348854064941], "metadata": {"source_tokens": ["Only", "Ballard", "and", "Williams", "are", "left", "after", "Sergeant", "Jericho", "and", "the", "other", "officers", ",", "along", "with", "the", "two", "train", "operators", ",", "are", "killed", "when", "they", "try", "to", "finish", "the", "fight", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Only", "Ballard", "and", "Williams", "[unused2]", "[unused3]", "are", "left", "[unused4]", "[unused5]", "after", "Sergeant", "Jericho", "and", "the", "other", "officers", ",", "along", "with", "the", "two", "train", "operators", ",", "are", "killed", "when", "they", "try", "to", "finish", "the", "fight", "[unused6]", "[SEP]", "[unused1]", "Sergeant", "Jericho", "and", "the", "other", "officers", "[unused2]", "[unused3]", "are", "killed", "[unused4]", "[unused5]", "when", "they", "try", "to", "finish", "the", "fight", "[unused6]", "[SEP]"]]}

input 225:  {"source": "Opponents of religious freedom sometimes referred to it as `` Rogue 's Island '' , and Cotton Mather called it `` the sewer of New England . ''\n"}
prediction:  {"predictions": [[1, 12871, 15112, 1200, 2, 3, 1270, 4, 5, 1122, 1103, 27635, 1104, 1203, 1652, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9126, 25387, 1104, 2689, 4438, 2, 3, 2752, 4, 5, 1106, 1122, 1112, 20481, 112, 1116, 2054, 2121, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04462786391377449, -0.029559198766946793, -0.14504003524780273, -0.14504003524780273, -0.14504003524780273, -0.14504003524780273, -0.14504003524780273, -0.14504003524780273, -0.14504003524780273, -0.14504003524780273], "metadata": {"source_tokens": ["Op", "##ponents", "of", "religious", "freedom", "sometimes", "referred", "to", "it", "as", "`", "##`", "Rogue", "'", "##s", "Island", "'", "##'", ",", "and", "Cotton", "Math", "##er", "called", "it", "`", "##`", "the", "sewer", "of", "New", "England", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Cotton", "Math", "##er", "[unused2]", "[unused3]", "called", "[unused4]", "[unused5]", "it", "the", "sewer", "of", "New", "England", "[unused6]", "[SEP]", "[unused1]", "Op", "##ponents", "of", "religious", "freedom", "[unused2]", "[unused3]", "referred", "[unused4]", "[unused5]", "to", "it", "as", "Rogue", "'", "##s", "Island", "sometimes", "[unused6]", "[SEP]"]]}

input 226:  {"source": "Originally , Hank McCoy retains the basic features of a normal human alongside a generally simian physiology equivalent to that of a Great Ape .\n"}
prediction:  {"predictions": [[1, 8902, 17061, 2, 3, 15208, 4, 5, 1103, 3501, 1956, 1104, 170, 2999, 1769, 3338, 170, 2412, 27466, 19111, 25445, 4976, 1106, 1115, 1104, 170, 2038, 138, 3186, 5798, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8902, 17061, 2, 3, 15208, 4, 5, 1103, 3501, 1956, 1104, 170, 2999, 1769, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.004071593284606934, -0.053503163158893585, -0.16342878341674805, -0.1484851837158203, -0.1484851837158203, -0.1484851837158203, -0.1484851837158203, -0.1484851837158203, -0.1484851837158203, -0.1484851837158203], "metadata": {"source_tokens": ["Originally", ",", "Hank", "McCoy", "retains", "the", "basic", "features", "of", "a", "normal", "human", "alongside", "a", "generally", "si", "##mian", "physiology", "equivalent", "to", "that", "of", "a", "Great", "A", "##pe", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hank", "McCoy", "[unused2]", "[unused3]", "retains", "[unused4]", "[unused5]", "the", "basic", "features", "of", "a", "normal", "human", "alongside", "a", "generally", "si", "##mian", "physiology", "equivalent", "to", "that", "of", "a", "Great", "A", "##pe", "Originally", "[unused6]", "[SEP]", "[unused1]", "Hank", "McCoy", "[unused2]", "[unused3]", "retains", "[unused4]", "[unused5]", "the", "basic", "features", "of", "a", "normal", "human", "[unused6]", "[SEP]"]]}

input 227:  {"source": "Other signs of lens subluxation include mild conjunctival redness , vitreous humour degeneration , prolapse of the vitreous into the anterior chamber , and an increase or decrease of anterior chamber depth .\n"}
prediction:  {"predictions": [[1, 2189, 5300, 1104, 11039, 4841, 24796, 1891, 2, 3, 1511, 4, 5, 10496, 14255, 20327, 15895, 1894, 1757, 117, 191, 2875, 1874, 2285, 19311, 1260, 27054, 6108, 117, 5250, 16046, 2217, 1104, 1103, 191, 2875, 1874, 2285, 1154, 1103, 16557, 5383, 117, 1105, 1126, 2773, 1137, 9711, 1104, 16557, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0029302549082785845, -0.22315478324890137, -0.22318410873413086, -0.22318410873413086, -0.22318410873413086, -0.22318410873413086, -0.22318410873413086, -0.22318410873413086, -0.22318410873413086, -0.22318410873413086], "metadata": {"source_tokens": ["Other", "signs", "of", "lens", "sub", "##lux", "##ation", "include", "mild", "con", "##junct", "##ival", "red", "##ness", ",", "v", "##it", "##re", "##ous", "humour", "de", "##gene", "##ration", ",", "pro", "##lap", "##se", "of", "the", "v", "##it", "##re", "##ous", "into", "the", "anterior", "chamber", ",", "and", "an", "increase", "or", "decrease", "of", "anterior", "chamber", "depth", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Other", "signs", "of", "lens", "sub", "##lux", "##ation", "[unused2]", "[unused3]", "include", "[unused4]", "[unused5]", "mild", "con", "##junct", "##ival", "red", "##ness", ",", "v", "##it", "##re", "##ous", "humour", "de", "##gene", "##ration", ",", "pro", "##lap", "##se", "of", "the", "v", "##it", "##re", "##ous", "into", "the", "anterior", "chamber", ",", "and", "an", "increase", "or", "decrease", "of", "anterior", "[SEP]"]]}

input 228:  {"source": "Pakistan Chrome Mines Ltd. is a mining company incorporated in the Islamic Republic of Pakistan .\n"}
prediction:  {"predictions": [[1, 3658, 20394, 11457, 18946, 4492, 2, 3, 1110, 4, 5, 170, 5463, 1419, 4572, 1107, 1103, 4769, 2250, 1104, 3658, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.007597498130053282, -0.0018553733825683594, -0.0018820762634277344, -0.0018820762634277344, -0.0018820762634277344, -0.0018820762634277344, -0.0018820762634277344, -0.0018820762634277344, -0.0018820762634277344, -0.0018820762634277344], "metadata": {"source_tokens": ["Pakistan", "Ch", "##rome", "Mines", "Ltd", "##.", "is", "a", "mining", "company", "incorporated", "in", "the", "Islamic", "Republic", "of", "Pakistan", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pakistan", "Ch", "##rome", "Mines", "Ltd", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "mining", "company", "incorporated", "in", "the", "Islamic", "Republic", "of", "Pakistan", "[unused6]", "[SEP]"]]}

input 229:  {"source": "Parental investment is any expenditure of resources to benefit one offspring .\n"}
prediction:  {"predictions": [[1, 19585, 17759, 1348, 5151, 2, 3, 1110, 4, 5, 1251, 24106, 1104, 3979, 1106, 5257, 1141, 14416, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0015919565921649337, -0.002819538116455078, -0.002838611602783203, -0.002838611602783203, -0.002838611602783203, -0.002838611602783203, -0.002838611602783203, -0.002838611602783203, -0.002838611602783203, -0.002838611602783203], "metadata": {"source_tokens": ["Pa", "##rent", "##al", "investment", "is", "any", "expenditure", "of", "resources", "to", "benefit", "one", "offspring", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pa", "##rent", "##al", "investment", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "any", "expenditure", "of", "resources", "to", "benefit", "one", "offspring", "[unused6]", "[SEP]"]]}

input 230:  {"source": "Piffaro generally performs a concert series of four to five concerts a year in Philadelphia , in addition to touring throughout the United States , Canada , Europe and elsewhere .\n"}
prediction:  {"predictions": [[1, 21902, 3101, 14452, 2, 3, 2412, 10383, 4, 5, 170, 3838, 1326, 1104, 1300, 1106, 1421, 6460, 170, 1214, 1107, 3562, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21902, 3101, 14452, 2, 3, 10383, 4, 5, 170, 3838, 1326, 1104, 1300, 1106, 1421, 6460, 170, 1214, 1107, 3562, 1107, 1901, 1106, 7048, 2032, 1103, 1244, 1311, 1803, 1980, 1105, 6890, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.012232865206897259, -0.018194865435361862, -0.21399521827697754, -0.2018735408782959, -0.2018735408782959, -0.2018735408782959, -0.2018735408782959, -0.2018735408782959, -0.2018735408782959, -0.2018735408782959], "metadata": {"source_tokens": ["Pi", "##ff", "##aro", "generally", "performs", "a", "concert", "series", "of", "four", "to", "five", "concerts", "a", "year", "in", "Philadelphia", ",", "in", "addition", "to", "touring", "throughout", "the", "United", "States", ",", "Canada", ",", "Europe", "and", "elsewhere", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pi", "##ff", "##aro", "[unused2]", "[unused3]", "generally", "performs", "[unused4]", "[unused5]", "a", "concert", "series", "of", "four", "to", "five", "concerts", "a", "year", "in", "Philadelphia", "[unused6]", "[SEP]", "[unused1]", "Pi", "##ff", "##aro", "[unused2]", "[unused3]", "performs", "[unused4]", "[unused5]", "a", "concert", "series", "of", "four", "to", "five", "concerts", "a", "year", "in", "Philadelphia", "in", "addition", "to", "touring", "throughout", "the", "United", "States", "Canada", "Europe", "and", "elsewhere", "[unused6]", "[SEP]"]]}

input 231:  {"source": "Plants have been planted marking parts of the foundations of the castle , so the positions of some of the buildings can still be inferred .\n"}
prediction:  {"predictions": [[1, 1103, 3638, 1104, 1199, 1104, 1103, 2275, 2, 3, 1169, 1129, 1107, 26025, 4, 5, 1253, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 25880, 2, 3, 1138, 1151, 8100, 4, 5, 10079, 2192, 1104, 1103, 11217, 1104, 1103, 3804, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.026149585843086243, -0.035390522330999374, -0.0625755786895752, -0.06347012519836426, -0.06347012519836426, -0.06347012519836426, -0.06347012519836426, -0.06347012519836426, -0.06347012519836426, -0.06347012519836426], "metadata": {"source_tokens": ["Plants", "have", "been", "planted", "marking", "parts", "of", "the", "foundations", "of", "the", "castle", ",", "so", "the", "positions", "of", "some", "of", "the", "buildings", "can", "still", "be", "in", "##ferred", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "positions", "of", "some", "of", "the", "buildings", "[unused2]", "[unused3]", "can", "be", "in", "##ferred", "[unused4]", "[unused5]", "still", "[unused6]", "[SEP]", "[unused1]", "Plants", "[unused2]", "[unused3]", "have", "been", "planted", "[unused4]", "[unused5]", "marking", "parts", "of", "the", "foundations", "of", "the", "castle", "[unused6]", "[SEP]"]]}

input 232:  {"source": "Prior to the 2012 season , the Royals signed Yost to a contract extension through the 2013 season .\n"}
prediction:  {"predictions": [[1, 1103, 17692, 2, 3, 1878, 4, 5, 14941, 2050, 1106, 170, 2329, 4973, 1194, 1103, 1381, 1265, 4602, 1106, 1103, 1368, 1265, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 17692, 2, 3, 1878, 4, 5, 14941, 2050, 1106, 170, 2329, 4973, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.006155419163405895, -0.08830218762159348, -0.22264504432678223, -0.22264432907104492, -0.22264432907104492, -0.22264432907104492, -0.22264432907104492, -0.22264432907104492, -0.22264432907104492, -0.22264432907104492], "metadata": {"source_tokens": ["Prior", "to", "the", "2012", "season", ",", "the", "Royals", "signed", "Yo", "##st", "to", "a", "contract", "extension", "through", "the", "2013", "season", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Royals", "[unused2]", "[unused3]", "signed", "[unused4]", "[unused5]", "Yo", "##st", "to", "a", "contract", "extension", "through", "the", "2013", "season", "Prior", "to", "the", "2012", "season", "[unused6]", "[SEP]", "[unused1]", "the", "Royals", "[unused2]", "[unused3]", "signed", "[unused4]", "[unused5]", "Yo", "##st", "to", "a", "contract", "extension", "[unused6]", "[SEP]"]]}

input 233:  {"source": "Prior to the Playmaker tool , the Player could only call one of four available `` hot routes . ''\n"}
prediction:  {"predictions": [[1, 1103, 5348, 2, 3, 1180, 1178, 1840, 4, 5, 1141, 1104, 1300, 1907, 169, 28152, 2633, 5441, 4602, 1106, 1103, 6060, 8085, 6806, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0008664223132655025, -0.0060710906982421875, -0.006072998046875, -0.006072998046875, -0.006072998046875, -0.006072998046875, -0.006072998046875, -0.006072998046875, -0.006072998046875, -0.006072998046875], "metadata": {"source_tokens": ["Prior", "to", "the", "Play", "##maker", "tool", ",", "the", "Player", "could", "only", "call", "one", "of", "four", "available", "`", "##`", "hot", "routes", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Player", "[unused2]", "[unused3]", "could", "only", "call", "[unused4]", "[unused5]", "one", "of", "four", "available", "`", "##`", "hot", "routes", "Prior", "to", "the", "Play", "##maker", "tool", "[unused6]", "[SEP]"]]}

input 234:  {"source": "Proliferative nodules are usually biopsied and are regularly but not systematically found to be benign .\n"}
prediction:  {"predictions": [[1, 5096, 14430, 15306, 6873, 11806, 2, 3, 1132, 4857, 4, 5, 1106, 1129, 26181, 11368, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5096, 14430, 15306, 6873, 11806, 2, 3, 1132, 1136, 25923, 1276, 4, 5, 1106, 1129, 26181, 11368, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5096, 14430, 15306, 6873, 11806, 2, 3, 1132, 25128, 3491, 4830, 4, 5, 1932, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.06538067013025284, -0.06799542903900146, -0.06475783884525299, -0.14503931999206543, -0.14503931999206543, -0.14503931999206543, -0.14503931999206543, -0.14503931999206543, -0.14503931999206543, -0.14503931999206543], "metadata": {"source_tokens": ["Pro", "##life", "##rative", "nod", "##ules", "are", "usually", "bio", "##ps", "##ied", "and", "are", "regularly", "but", "not", "systematically", "found", "to", "be", "ben", "##ign", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pro", "##life", "##rative", "nod", "##ules", "[unused2]", "[unused3]", "are", "regularly", "[unused4]", "[unused5]", "to", "be", "ben", "##ign", "[unused6]", "[SEP]", "[unused1]", "Pro", "##life", "##rative", "nod", "##ules", "[unused2]", "[unused3]", "are", "not", "systematically", "found", "[unused4]", "[unused5]", "to", "be", "ben", "##ign", "[unused6]", "[SEP]", "[unused1]", "Pro", "##life", "##rative", "nod", "##ules", "[unused2]", "[unused3]", "are", "bio", "##ps", "##ied", "[unused4]", "[unused5]", "usually", "[unused6]", "[SEP]"]]}

input 235:  {"source": "RedHat engineers identified problems with ProPolice though , and in 2005 re-implemented stack-smashing protection for inclusion in GCC 4.1 .\n"}
prediction:  {"predictions": [[1, 2156, 3048, 2980, 9067, 2, 3, 3626, 4, 5, 2645, 1114, 5096, 2101, 14987, 1162, 1463, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2156, 3048, 2980, 9067, 2, 3, 3626, 4, 5, 2645, 1114, 5096, 2101, 14987, 1162, 1105, 1231, 28137, 4060, 7136, 24674, 10926, 28137, 24557, 12802, 3636, 1111, 10838, 1107, 144, 12096, 125, 28138, 1475, 1107, 1478, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.01899656467139721, -0.06941401213407516, -0.22267889976501465, -0.22267913818359375, -0.22267913818359375, -0.22267913818359375, -0.22267913818359375, -0.22267913818359375, -0.22267913818359375, -0.22267913818359375], "metadata": {"source_tokens": ["Red", "##H", "##at", "engineers", "identified", "problems", "with", "Pro", "##P", "##olic", "##e", "though", ",", "and", "in", "2005", "re", "##-", "##im", "##ple", "##mented", "stack", "##-", "##sma", "##shing", "protection", "for", "inclusion", "in", "G", "##CC", "4", "##.", "##1", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Red", "##H", "##at", "engineers", "[unused2]", "[unused3]", "identified", "[unused4]", "[unused5]", "problems", "with", "Pro", "##P", "##olic", "##e", "though", "[unused6]", "[SEP]", "[unused1]", "Red", "##H", "##at", "engineers", "[unused2]", "[unused3]", "identified", "[unused4]", "[unused5]", "problems", "with", "Pro", "##P", "##olic", "##e", "and", "re", "##-", "##im", "##ple", "##mented", "stack", "##-", "##sma", "##shing", "protection", "for", "inclusion", "in", "G", "##CC", "4", "##.", "##1", "in", "2005", "[unused6]", "[SEP]"]]}

input 236:  {"source": "Reptiles identified during surveys include marbled geckos on both island groups while the following are limited to the main island in the Northern group - four-toed earless skink , bull skinks and western brown snakes .\n"}
prediction:  {"predictions": [[1, 20777, 23677, 1116, 3626, 1219, 13634, 2, 3, 1511, 4, 5, 8004, 1181, 176, 14021, 2155, 1113, 1241, 2248, 2114, 1229, 1103, 1378, 1132, 2609, 1106, 1103, 1514, 2248, 1107, 1103, 2579, 1372, 118, 1300, 28137, 2430, 1174, 26593, 5800, 2241, 1377, 117, 12200, 2241, 4616, 1105, 2466, 3058, 102, 1, 20777, 23677, 1116, 2, 3, 3626, 4, 5, 1219, 13634, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1378, 2, 3, 1132, 2609, 4, 5, 1106, 1103, 1514, 2248, 1107, 1103, 2579, 1372, 118, 1300, 28137, 2430, 1174, 26593, 5800, 2241, 1377, 117, 12200, 2241, 4616, 1105, 2466, 3058, 14986, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1378, 2, 3, 1132, 2609, 4, 5, 1106, 1103, 1514, 2248, 1107, 1103, 2579, 1372, 1300, 28137, 2430, 1174, 26593, 5800, 2241, 1377, 12200, 2241, 4616, 1105, 2466, 3058, 14986, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02212916687130928, -0.07837633043527603, -0.024769049137830734, -0.06607908755540848, -0.14723658561706543, -0.1486043930053711, -0.1486043930053711, -0.1486043930053711, -0.1486043930053711, -0.1486043930053711], "metadata": {"source_tokens": ["Rep", "##tile", "##s", "identified", "during", "surveys", "include", "marble", "##d", "g", "##eck", "##os", "on", "both", "island", "groups", "while", "the", "following", "are", "limited", "to", "the", "main", "island", "in", "the", "Northern", "group", "-", "four", "##-", "##to", "##ed", "earl", "##ess", "skin", "##k", ",", "bull", "skin", "##ks", "and", "western", "brown", "snakes", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rep", "##tile", "##s", "identified", "during", "surveys", "[unused2]", "[unused3]", "include", "[unused4]", "[unused5]", "marble", "##d", "g", "##eck", "##os", "on", "both", "island", "groups", "while", "the", "following", "are", "limited", "to", "the", "main", "island", "in", "the", "Northern", "group", "-", "four", "##-", "##to", "##ed", "earl", "##ess", "skin", "##k", ",", "bull", "skin", "##ks", "and", "western", "brown", "[SEP]", "[unused1]", "Rep", "##tile", "##s", "[unused2]", "[unused3]", "identified", "[unused4]", "[unused5]", "during", "surveys", "[unused6]", "[SEP]", "[unused1]", "the", "following", "[unused2]", "[unused3]", "are", "limited", "[unused4]", "[unused5]", "to", "the", "main", "island", "in", "the", "Northern", "group", "-", "four", "##-", "##to", "##ed", "earl", "##ess", "skin", "##k", ",", "bull", "skin", "##ks", "and", "western", "brown", "snakes", "[unused6]", "[SEP]", "[unused1]", "the", "following", "[unused2]", "[unused3]", "are", "limited", "[unused4]", "[unused5]", "to", "the", "main", "island", "in", "the", "Northern", "group", "four", "##-", "##to", "##ed", "earl", "##ess", "skin", "##k", "bull", "skin", "##ks", "and", "western", "brown", "snakes", "[unused6]", "[SEP]"]]}

input 237:  {"source": "Results like these indicate acoustic mimicry complexes , both Batesian and Mullerian , may be widespread in the auditory world .\n"}
prediction:  {"predictions": [[1, 16005, 1176, 1292, 2, 3, 5057, 4, 5, 6659, 27180, 1616, 16575, 117, 1241, 11197, 1811, 1105, 27418, 1811, 117, 1336, 1129, 6506, 1107, 1103, 23097, 4649, 1362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6659, 27180, 1616, 16575, 2, 3, 1336, 1129, 4, 5, 6506, 1107, 1103, 23097, 4649, 1362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0013007463421672583, -0.03984773904085159, -0.03341484069824219, -0.03426194190979004, -0.03426194190979004, -0.03426194190979004, -0.03426194190979004, -0.03426194190979004, -0.03426194190979004, -0.03426194190979004], "metadata": {"source_tokens": ["Results", "like", "these", "indicate", "acoustic", "mimic", "##ry", "complexes", ",", "both", "Bates", "##ian", "and", "Muller", "##ian", ",", "may", "be", "widespread", "in", "the", "audit", "##ory", "world", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Results", "like", "these", "[unused2]", "[unused3]", "indicate", "[unused4]", "[unused5]", "acoustic", "mimic", "##ry", "complexes", ",", "both", "Bates", "##ian", "and", "Muller", "##ian", ",", "may", "be", "widespread", "in", "the", "audit", "##ory", "world", "[unused6]", "[SEP]", "[unused1]", "acoustic", "mimic", "##ry", "complexes", "[unused2]", "[unused3]", "may", "be", "[unused4]", "[unused5]", "widespread", "in", "the", "audit", "##ory", "world", "[unused6]", "[SEP]"]]}

input 238:  {"source": "Returning home , Ballard delivers her report , which her superiors refuse to believe .\n"}
prediction:  {"predictions": [[1, 24241, 2, 3, 19603, 4, 5, 1123, 2592, 117, 1134, 1123, 26917, 10250, 1106, 2059, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0016442140331491828, -0.005170345306396484, -0.005611896514892578, -0.005611896514892578, -0.005611896514892578, -0.005611896514892578, -0.005611896514892578, -0.005611896514892578, -0.005611896514892578, -0.005611896514892578], "metadata": {"source_tokens": ["Returning", "home", ",", "Ballard", "delivers", "her", "report", ",", "which", "her", "superiors", "refuse", "to", "believe", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ballard", "[unused2]", "[unused3]", "delivers", "[unused4]", "[unused5]", "her", "report", ",", "which", "her", "superiors", "refuse", "to", "believe", "[unused6]", "[SEP]"]]}

input 239:  {"source": "Robert Charles `` Jack '' Russell , MBE , is a retired English international cricketer , now known for his abilities as an artist , as a cricket wicketkeeping coach , and a football goalkeeping coach .\n"}
prediction:  {"predictions": [[1, 1823, 1889, 169, 28152, 2132, 112, 28131, 5023, 2, 3, 1110, 4, 5, 170, 2623, 1483, 1835, 9469, 117, 1208, 1227, 1111, 1117, 7134, 1112, 1126, 2360, 117, 1112, 170, 5428, 13386, 14692, 2154, 117, 1105, 170, 1709, 2273, 14692, 2154, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 2623, 1483, 1835, 9469, 2, 3, 1227, 4, 5, 1111, 1117, 7134, 1112, 1126, 2360, 1112, 170, 5428, 13386, 14692, 2154, 1208, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.010061468929052353, -0.06384982168674469, -0.0763247013092041, -0.07822656631469727, -0.07822656631469727, -0.07822656631469727, -0.07822656631469727, -0.07822656631469727, -0.07822656631469727, -0.07822656631469727], "metadata": {"source_tokens": ["Robert", "Charles", "`", "##`", "Jack", "'", "##'", "Russell", ",", "MBE", ",", "is", "a", "retired", "English", "international", "cricketer", ",", "now", "known", "for", "his", "abilities", "as", "an", "artist", ",", "as", "a", "cricket", "wicket", "##keeping", "coach", ",", "and", "a", "football", "goal", "##keeping", "coach", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Robert", "Charles", "`", "##`", "Jack", "'", "##'", "Russell", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "retired", "English", "international", "cricketer", ",", "now", "known", "for", "his", "abilities", "as", "an", "artist", ",", "as", "a", "cricket", "wicket", "##keeping", "coach", ",", "and", "a", "football", "goal", "##keeping", "coach", "[unused6]", "[SEP]", "[unused1]", "a", "retired", "English", "international", "cricketer", "[unused2]", "[unused3]", "known", "[unused4]", "[unused5]", "for", "his", "abilities", "as", "an", "artist", "as", "a", "cricket", "wicket", "##keeping", "coach", "now", "[unused6]", "[SEP]"]]}

input 240:  {"source": "Rosen argues that one of the most important provisions of the Constitution in Exile is limitations on the interstate commerce clause , which were undermined by the Supreme Court 's `` expansive interpretation of Congress 's power to regulate interstate commerce ... extended to include any activities that might affect commerce indirectly '' during the New Deal .\n"}
prediction:  {"predictions": [[1, 24580, 2, 3, 8935, 4, 5, 1115, 1141, 1104, 1103, 1211, 1696, 8939, 1104, 1103, 5317, 1107, 16409, 4759, 1110, 13004, 1113, 1103, 20905, 10678, 13620, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 20905, 10678, 13620, 2, 3, 1127, 1223, 15842, 4, 5, 1118, 1103, 3732, 2031, 112, 1116, 169, 28152, 4252, 10224, 8788, 7628, 1104, 2757, 112, 1116, 1540, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1141, 1104, 1103, 1211, 1696, 8939, 1104, 1103, 5317, 1107, 16409, 4759, 2, 3, 1110, 4, 5, 13004, 1113, 1103, 20905, 10678, 13620, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1251, 2619, 2, 3, 1547, 6975, 4, 5, 10678, 18814, 112, 28131, 1219, 1103, 1203, 15361, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 20905, 10678, 13620, 2, 3, 1127, 1223, 15842, 4, 5, 1118, 1103, 3732, 2031, 112, 1116, 4252, 10224, 8788, 7628, 1104, 2757, 112, 1116, 1540, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 20905, 10678, 13620, 2, 3, 1127, 1223, 15842, 4, 5, 1118, 1103, 3732, 2031, 112, 1116, 4252, 10224, 8788, 7628, 1104, 2757, 112, 1116, 1540, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1141, 1104, 1103, 1211, 1696, 8939, 1104, 1103, 5317, 1107, 16409, 4759, 2, 3, 1110, 4, 5, 13004, 1113, 1103, 20905, 10678, 13620, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.022674961015582085, -0.02410832606256008, -0.034130651503801346, -0.08111307770013809, -0.07792788743972778, -0.08761264383792877, -0.07939695566892624, -0.22266721725463867, -0.22266745567321777, -0.22266745567321777], "metadata": {"source_tokens": ["Rosen", "argues", "that", "one", "of", "the", "most", "important", "provisions", "of", "the", "Constitution", "in", "Ex", "##ile", "is", "limitations", "on", "the", "interstate", "commerce", "clause", ",", "which", "were", "under", "##mined", "by", "the", "Supreme", "Court", "'", "##s", "`", "##`", "ex", "##pan", "##sive", "interpretation", "of", "Congress", "'", "##s", "power", "to", "regulate", "interstate", "commerce", "...", "extended", "to", "include", "any", "activities", "that", "might", "affect", "commerce", "indirectly", "'", "##'", "during", "the", "New", "Deal", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rosen", "[unused2]", "[unused3]", "argues", "[unused4]", "[unused5]", "that", "one", "of", "the", "most", "important", "provisions", "of", "the", "Constitution", "in", "Ex", "##ile", "is", "limitations", "on", "the", "interstate", "commerce", "clause", "[unused6]", "[SEP]", "[unused1]", "the", "interstate", "commerce", "clause", "[unused2]", "[unused3]", "were", "under", "##mined", "[unused4]", "[unused5]", "by", "the", "Supreme", "Court", "'", "##s", "`", "##`", "ex", "##pan", "##sive", "interpretation", "of", "Congress", "'", "##s", "power", "[unused6]", "[SEP]", "[unused1]", "one", "of", "the", "most", "important", "provisions", "of", "the", "Constitution", "in", "Ex", "##ile", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "limitations", "on", "the", "interstate", "commerce", "clause", "[unused6]", "[SEP]", "[unused1]", "any", "activities", "[unused2]", "[unused3]", "might", "affect", "[unused4]", "[unused5]", "commerce", "indirectly", "'", "##'", "during", "the", "New", "Deal", "[unused6]", "[SEP]", "[unused1]", "the", "interstate", "commerce", "clause", "[unused2]", "[unused3]", "were", "under", "##mined", "[unused4]", "[unused5]", "by", "the", "Supreme", "Court", "'", "##s", "ex", "##pan", "##sive", "interpretation", "of", "Congress", "'", "##s", "power", "[unused6]", "[SEP]", "[unused1]", "the", "interstate", "commerce", "clause", "[unused2]", "[unused3]", "were", "under", "##mined", "[unused4]", "[unused5]", "by", "the", "Supreme", "Court", "'", "##s", "ex", "##pan", "##sive", "interpretation", "of", "Congress", "'", "##s", "power", "[unused6]", "[SEP]", "[unused1]", "one", "of", "the", "most", "important", "provisions", "of", "the", "Constitution", "in", "Ex", "##ile", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "limitations", "on", "the", "interstate", "commerce", "clause", "[unused6]", "[SEP]"]]}

input 241:  {"source": "San Francisco 's diversity of cultures along with its eccentricities are so great that they have greatly influenced the country and the world at large over the years .\n"}
prediction:  {"predictions": [[1, 1727, 2948, 112, 1116, 9531, 1104, 8708, 1373, 1114, 1157, 20276, 4233, 2, 3, 1132, 4, 5, 1177, 1632, 1115, 1152, 1138, 5958, 4401, 1103, 1583, 1105, 1103, 1362, 1120, 1415, 1166, 1103, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1138, 4401, 4, 5, 1103, 1583, 1105, 1103, 1362, 1120, 1415, 1166, 1103, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.004416836425662041, -0.06190500408411026, -0.15923714637756348, -0.15566635131835938, -0.15566635131835938, -0.15566635131835938, -0.15566635131835938, -0.15566635131835938, -0.15566635131835938, -0.15566635131835938], "metadata": {"source_tokens": ["San", "Francisco", "'", "##s", "diversity", "of", "cultures", "along", "with", "its", "eccentric", "##ities", "are", "so", "great", "that", "they", "have", "greatly", "influenced", "the", "country", "and", "the", "world", "at", "large", "over", "the", "years", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "San", "Francisco", "'", "##s", "diversity", "of", "cultures", "along", "with", "its", "eccentric", "##ities", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "so", "great", "that", "they", "have", "greatly", "influenced", "the", "country", "and", "the", "world", "at", "large", "over", "the", "years", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "have", "influenced", "[unused4]", "[unused5]", "the", "country", "and", "the", "world", "at", "large", "over", "the", "years", "[unused6]", "[SEP]"]]}

input 242:  {"source": "Scarpetta returns to Virginia in `` Trace '' , convincing herself that she was fired from her position , at the request of her replacement , Dr. Joel Marcus .\n"}
prediction:  {"predictions": [[1, 20452, 1813, 12924, 1777, 2, 3, 5166, 4, 5, 1106, 2550, 1107, 169, 28152, 22681, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20452, 1813, 12924, 1777, 2, 3, 13870, 4, 5, 1941, 1115, 1131, 1108, 4294, 1121, 1123, 1700, 117, 1120, 1103, 4566, 1104, 1123, 5627, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1123, 5627, 2, 3, 1110, 4, 5, 1987, 28138, 8773, 6042, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0547446683049202, -0.06056337058544159, -0.05226290225982666, -0.22264885902404785, -0.22264838218688965, -0.22264838218688965, -0.22264838218688965, -0.22264838218688965, -0.22264838218688965, -0.22264838218688965], "metadata": {"source_tokens": ["Sc", "##ar", "##pet", "##ta", "returns", "to", "Virginia", "in", "`", "##`", "Trace", "'", "##'", ",", "convincing", "herself", "that", "she", "was", "fired", "from", "her", "position", ",", "at", "the", "request", "of", "her", "replacement", ",", "Dr", "##.", "Joel", "Marcus", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sc", "##ar", "##pet", "##ta", "[unused2]", "[unused3]", "returns", "[unused4]", "[unused5]", "to", "Virginia", "in", "`", "##`", "Trace", "[unused6]", "[SEP]", "[unused1]", "Sc", "##ar", "##pet", "##ta", "[unused2]", "[unused3]", "convincing", "[unused4]", "[unused5]", "herself", "that", "she", "was", "fired", "from", "her", "position", ",", "at", "the", "request", "of", "her", "replacement", "[unused6]", "[SEP]", "[unused1]", "her", "replacement", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Dr", "##.", "Joel", "Marcus", "[unused6]", "[SEP]"]]}

input 243:  {"source": "Several isomers of octene are known , depending on the position and the geometry of the double bond in the carbon chain .\n"}
prediction:  {"predictions": [[1, 3728, 1110, 23806, 1116, 1104, 184, 5822, 7582, 2, 3, 1132, 1227, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3728, 1110, 23806, 1116, 1104, 184, 5822, 7582, 2, 3, 5763, 4, 5, 1113, 1103, 1700, 1105, 1103, 12053, 1104, 1103, 2702, 7069, 1107, 1103, 6302, 4129, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.017213793471455574, -0.006108645815402269, -0.006583213806152344, -0.0063228607177734375, -0.0063228607177734375, -0.0063228607177734375, -0.0063228607177734375, -0.0063228607177734375, -0.0063228607177734375, -0.0063228607177734375], "metadata": {"source_tokens": ["Several", "is", "##omer", "##s", "of", "o", "##ct", "##ene", "are", "known", ",", "depending", "on", "the", "position", "and", "the", "geometry", "of", "the", "double", "bond", "in", "the", "carbon", "chain", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Several", "is", "##omer", "##s", "of", "o", "##ct", "##ene", "[unused2]", "[unused3]", "are", "known", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Several", "is", "##omer", "##s", "of", "o", "##ct", "##ene", "[unused2]", "[unused3]", "depending", "[unused4]", "[unused5]", "on", "the", "position", "and", "the", "geometry", "of", "the", "double", "bond", "in", "the", "carbon", "chain", "[unused6]", "[SEP]"]]}

input 244:  {"source": "She died in October 1915 of a heart attack .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 1452, 4, 5, 1107, 1357, 4135, 1104, 170, 1762, 2035, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1153, 2, 3, 1452, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.001061469316482544, -0.030212176963686943, -0.0028634071350097656, -0.0028672218322753906, -0.0028672218322753906, -0.0028672218322753906, -0.0028672218322753906, -0.0028672218322753906, -0.0028672218322753906, -0.0028672218322753906], "metadata": {"source_tokens": ["She", "died", "in", "October", "1915", "of", "a", "heart", "attack", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "died", "[unused4]", "[unused5]", "in", "October", "1915", "of", "a", "heart", "attack", "[unused6]", "[SEP]", "[unused1]", "She", "[unused2]", "[unused3]", "died", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 245:  {"source": "She provided an audio commentary for the episode on the DVD release of the show 's third series alongside David Tennant .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 2136, 4, 5, 1126, 6056, 9068, 1111, 1103, 2004, 1113, 1103, 4173, 1836, 1104, 1103, 1437, 112, 1116, 1503, 1326, 3338, 1681, 5157, 14618, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0015737017383798957, -0.18439006805419922, -0.15312862396240234, -0.15312862396240234, -0.15312862396240234, -0.15312862396240234, -0.15312862396240234, -0.15312862396240234, -0.15312862396240234, -0.15312862396240234], "metadata": {"source_tokens": ["She", "provided", "an", "audio", "commentary", "for", "the", "episode", "on", "the", "DVD", "release", "of", "the", "show", "'", "##s", "third", "series", "alongside", "David", "Ten", "##nant", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "provided", "[unused4]", "[unused5]", "an", "audio", "commentary", "for", "the", "episode", "on", "the", "DVD", "release", "of", "the", "show", "'", "##s", "third", "series", "alongside", "David", "Ten", "##nant", "[unused6]", "[SEP]"]]}

input 246:  {"source": "She published more than 15 research publications , including International Journals , International Conferences , National Conferences , workshops and seminars .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 1502, 4, 5, 1167, 1190, 1405, 1844, 5873, 117, 1259, 1570, 3603, 1116, 117, 1570, 3047, 1116, 117, 1305, 3047, 1116, 117, 10158, 1105, 19898, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0018205064116045833, -0.0030655860900878906, -0.0030908584594726562, -0.0030908584594726562, -0.0030908584594726562, -0.0030908584594726562, -0.0030908584594726562, -0.0030908584594726562, -0.0030908584594726562, -0.0030908584594726562], "metadata": {"source_tokens": ["She", "published", "more", "than", "15", "research", "publications", ",", "including", "International", "Journal", "##s", ",", "International", "Conference", "##s", ",", "National", "Conference", "##s", ",", "workshops", "and", "seminars", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "published", "[unused4]", "[unused5]", "more", "than", "15", "research", "publications", ",", "including", "International", "Journal", "##s", ",", "International", "Conference", "##s", ",", "National", "Conference", "##s", ",", "workshops", "and", "seminars", "[unused6]", "[SEP]"]]}

input 247:  {"source": "She returned to that Thames River base 9 February 1931 and for the remainder of the decade served as a training ship primarily for the Submarine School at New London and occasionally for NROTC units in the southern New England area .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 1608, 4, 5, 1106, 1115, 11055, 1595, 2259, 130, 1428, 3916, 1105, 1111, 1103, 6311, 1104, 1103, 4967, 1462, 1112, 170, 2013, 2062, 3120, 1111, 1103, 26399, 1323, 1120, 1203, 1498, 1105, 5411, 1111, 151, 21564, 9481, 2338, 1107, 1103, 2359, 1203, 1652, 1298, 6, 102, 102, 1, 1103, 6311, 1104, 1103, 4967, 2, 3, 1462, 4, 5, 1112, 170, 2013, 2062, 3120, 1111, 1103, 26399, 1323, 1120, 1203, 1498, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.031038565561175346, -0.06507018953561783, -0.14755725860595703, -0.20621466636657715, -0.20621466636657715, -0.20621466636657715, -0.20621466636657715, -0.20621466636657715, -0.20621466636657715, -0.20621466636657715], "metadata": {"source_tokens": ["She", "returned", "to", "that", "Thames", "River", "base", "9", "February", "1931", "and", "for", "the", "remainder", "of", "the", "decade", "served", "as", "a", "training", "ship", "primarily", "for", "the", "Submarine", "School", "at", "New", "London", "and", "occasionally", "for", "N", "##RO", "##TC", "units", "in", "the", "southern", "New", "England", "area", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "returned", "[unused4]", "[unused5]", "to", "that", "Thames", "River", "base", "9", "February", "1931", "and", "for", "the", "remainder", "of", "the", "decade", "served", "as", "a", "training", "ship", "primarily", "for", "the", "Submarine", "School", "at", "New", "London", "and", "occasionally", "for", "N", "##RO", "##TC", "units", "in", "the", "southern", "New", "England", "area", "[unused6]", "[SEP]", "[unused1]", "the", "remainder", "of", "the", "decade", "[unused2]", "[unused3]", "served", "[unused4]", "[unused5]", "as", "a", "training", "ship", "primarily", "for", "the", "Submarine", "School", "at", "New", "London", "[unused6]", "[SEP]"]]}

input 248:  {"source": "She was ordered to be rebuilt on 9 March 1724 , and was taken in hand at Deptford Dockyard by Master Shipwright Richard Stacey .\n"}
prediction:  {"predictions": [[1, 1153, 2, 3, 1108, 2802, 4, 5, 1106, 1129, 6669, 1113, 130, 1345, 19639, 1527, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1153, 2, 3, 1108, 1678, 4, 5, 1107, 1289, 1120, 3177, 6451, 2821, 20115, 8624, 1118, 3257, 12863, 12723, 2055, 21807, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.010305734351277351, -0.012071569450199604, -0.1535787582397461, -0.15495014190673828, -0.15495014190673828, -0.15495014190673828, -0.15495014190673828, -0.15495014190673828, -0.15495014190673828, -0.15495014190673828], "metadata": {"source_tokens": ["She", "was", "ordered", "to", "be", "rebuilt", "on", "9", "March", "172", "##4", ",", "and", "was", "taken", "in", "hand", "at", "De", "##pt", "##ford", "Dock", "##yard", "by", "Master", "Ship", "##wright", "Richard", "Stacey", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "She", "[unused2]", "[unused3]", "was", "ordered", "[unused4]", "[unused5]", "to", "be", "rebuilt", "on", "9", "March", "172", "##4", "[unused6]", "[SEP]", "[unused1]", "She", "[unused2]", "[unused3]", "was", "taken", "[unused4]", "[unused5]", "in", "hand", "at", "De", "##pt", "##ford", "Dock", "##yard", "by", "Master", "Ship", "##wright", "Richard", "Stacey", "[unused6]", "[SEP]"]]}

input 249:  {"source": "Shea was born on September 5 , 1900 in San Francisco , California .\n"}
prediction:  {"predictions": [[1, 18352, 2, 3, 1108, 1255, 4, 5, 1113, 1347, 126, 1107, 1727, 2948, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04519686847925186, -0.004343509674072266, -0.004364490509033203, -0.004364490509033203, -0.004364490509033203, -0.004364490509033203, -0.004364490509033203, -0.004364490509033203, -0.004364490509033203, -0.004364490509033203], "metadata": {"source_tokens": ["Shea", "was", "born", "on", "September", "5", ",", "1900", "in", "San", "Francisco", ",", "California", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Shea", "[unused2]", "[unused3]", "was", "born", "[unused4]", "[unused5]", "on", "September", "5", "in", "San", "Francisco", "[unused6]", "[SEP]"]]}

input 250:  {"source": "Since joining the competition in 1908 , Richmond has won ten premierships , the most recent victory being in 1980 .\n"}
prediction:  {"predictions": [[1, 1103, 1211, 2793, 2681, 2, 3, 1217, 4, 5, 1107, 2253, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6110, 2, 3, 1144, 1281, 4, 5, 1995, 18262, 1116, 1967, 4577, 1103, 2208, 1107, 4536, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03647012263536453, -0.006527386140078306, -0.18785858154296875, -0.19087004661560059, -0.19087004661560059, -0.19087004661560059, -0.19087004661560059, -0.19087004661560059, -0.19087004661560059, -0.19087004661560059], "metadata": {"source_tokens": ["Since", "joining", "the", "competition", "in", "1908", ",", "Richmond", "has", "won", "ten", "premiership", "##s", ",", "the", "most", "recent", "victory", "being", "in", "1980", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "most", "recent", "victory", "[unused2]", "[unused3]", "being", "[unused4]", "[unused5]", "in", "1980", "[unused6]", "[SEP]", "[unused1]", "Richmond", "[unused2]", "[unused3]", "has", "won", "[unused4]", "[unused5]", "ten", "premiership", "##s", "Since", "joining", "the", "competition", "in", "1908", "[unused6]", "[SEP]"]]}

input 251:  {"source": "Sometimes extra payments were specified by which a freed slave could liberate himself from these residual duties .\n"}
prediction:  {"predictions": [[1, 3908, 10772, 2, 3, 1127, 9467, 4, 5, 1118, 1134, 170, 11485, 6748, 1180, 181, 24851, 2193, 1471, 1121, 1292, 25399, 5078, 5875, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 11485, 6748, 2, 3, 1180, 181, 24851, 2193, 4, 5, 1471, 1121, 1292, 25399, 5078, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.009154045023024082, -0.0024862978607416153, -0.022404193878173828, -0.022402048110961914, -0.022402048110961914, -0.022402048110961914, -0.022402048110961914, -0.022402048110961914, -0.022402048110961914, -0.022402048110961914], "metadata": {"source_tokens": ["Sometimes", "extra", "payments", "were", "specified", "by", "which", "a", "freed", "slave", "could", "l", "##iber", "##ate", "himself", "from", "these", "residual", "duties", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "extra", "payments", "[unused2]", "[unused3]", "were", "specified", "[unused4]", "[unused5]", "by", "which", "a", "freed", "slave", "could", "l", "##iber", "##ate", "himself", "from", "these", "residual", "duties", "Sometimes", "[unused6]", "[SEP]", "[unused1]", "a", "freed", "slave", "[unused2]", "[unused3]", "could", "l", "##iber", "##ate", "[unused4]", "[unused5]", "himself", "from", "these", "residual", "duties", "[unused6]", "[SEP]"]]}

input 252:  {"source": "Specifically , knowledge and interest in the event affects the level of personal importance for the individual , which also affects the individual 's level of emotional arousal .\n"}
prediction:  {"predictions": [[1, 1103, 2510, 2, 3, 13974, 4, 5, 1103, 2510, 112, 1116, 1634, 1104, 6438, 21019, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3044, 1105, 2199, 1107, 1103, 1856, 2, 3, 13974, 4, 5, 1103, 1634, 1104, 2357, 4495, 1111, 1103, 2510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02523120492696762, -0.0355672687292099, -0.14504218101501465, -0.14504218101501465, -0.14504218101501465, -0.14504218101501465, -0.14504218101501465, -0.14504218101501465, -0.14504218101501465, -0.14504218101501465], "metadata": {"source_tokens": ["Specifically", ",", "knowledge", "and", "interest", "in", "the", "event", "affects", "the", "level", "of", "personal", "importance", "for", "the", "individual", ",", "which", "also", "affects", "the", "individual", "'", "##s", "level", "of", "emotional", "arousal", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "individual", "[unused2]", "[unused3]", "affects", "[unused4]", "[unused5]", "the", "individual", "'", "##s", "level", "of", "emotional", "arousal", "[unused6]", "[SEP]", "[unused1]", "knowledge", "and", "interest", "in", "the", "event", "[unused2]", "[unused3]", "affects", "[unused4]", "[unused5]", "the", "level", "of", "personal", "importance", "for", "the", "individual", "[unused6]", "[SEP]"]]}

input 253:  {"source": "Spennymoor Town F.C. are the main local football team and won the FA Carlsberg Vase , after winning 2-1 in the final at Wembley Stadium against Tunbridge Wells in May 2013 .\n"}
prediction:  {"predictions": [[1, 156, 11741, 3382, 19216, 2779, 143, 28138, 1658, 28138, 2, 3, 1132, 4, 5, 1103, 1514, 1469, 1709, 1264, 1105, 1281, 1103, 6820, 4804, 19945, 159, 6530, 1170, 2183, 123, 28137, 1475, 1107, 1103, 1509, 1120, 17593, 3339, 1222, 17037, 24416, 7909, 1107, 1318, 1381, 6, 102, 102, 102, 102, 1, 156, 11741, 3382, 19216, 2779, 143, 28138, 1658, 28138, 2, 3, 1281, 4, 5, 1103, 6820, 4804, 19945, 159, 6530, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 156, 11741, 3382, 19216, 2779, 143, 28138, 1658, 28138, 2, 3, 1281, 4, 5, 1103, 6820, 4804, 19945, 159, 6530, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03620164468884468, -0.009803217835724354, -0.05352338030934334, -0.2226879596710205, -0.2226884365081787, -0.2226884365081787, -0.2226884365081787, -0.2226884365081787, -0.2226884365081787, -0.2226884365081787], "metadata": {"source_tokens": ["S", "##pen", "##ny", "##moor", "Town", "F", "##.", "##C", "##.", "are", "the", "main", "local", "football", "team", "and", "won", "the", "FA", "Carl", "##sberg", "V", "##ase", ",", "after", "winning", "2", "##-", "##1", "in", "the", "final", "at", "Wembley", "Stadium", "against", "Tu", "##nbridge", "Wells", "in", "May", "2013", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "S", "##pen", "##ny", "##moor", "Town", "F", "##.", "##C", "##.", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "the", "main", "local", "football", "team", "and", "won", "the", "FA", "Carl", "##sberg", "V", "##ase", "after", "winning", "2", "##-", "##1", "in", "the", "final", "at", "Wembley", "Stadium", "against", "Tu", "##nbridge", "Wells", "in", "May", "2013", "[unused6]", "[SEP]", "[unused1]", "S", "##pen", "##ny", "##moor", "Town", "F", "##.", "##C", "##.", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "the", "FA", "Carl", "##sberg", "V", "##ase", "[unused6]", "[SEP]", "[unused1]", "S", "##pen", "##ny", "##moor", "Town", "F", "##.", "##C", "##.", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "the", "FA", "Carl", "##sberg", "V", "##ase", "[unused6]", "[SEP]"]]}

input 254:  {"source": "Sukhum functioned as the capital of the `` Union treaty '' Abkhaz Soviet Socialist Republic associated with the Georgian SSR from 1921 until 1931 , when it became the capital of the Abkhazian Autonomous Soviet Socialist Republic within the Georgian SSR .\n"}
prediction:  {"predictions": [[1, 15463, 9862, 1818, 2, 3, 22937, 4, 5, 1112, 1103, 2364, 1104, 1103, 169, 28152, 1913, 7274, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1245, 4, 5, 1103, 2364, 1104, 1103, 138, 1830, 14457, 12432, 1179, 16742, 2461, 7365, 2250, 1439, 1103, 8832, 22916, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 169, 28152, 1913, 7274, 112, 28131, 138, 1830, 14457, 1584, 2461, 7365, 2250, 2, 3, 2628, 4, 5, 1114, 1103, 8832, 22916, 1121, 4085, 1235, 3916, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.06599076092243195, -0.04487282782793045, -0.08518466353416443, -0.22288036346435547, -0.22287988662719727, -0.22287988662719727, -0.22287988662719727, -0.22287988662719727, -0.22287988662719727, -0.22287988662719727], "metadata": {"source_tokens": ["Su", "##kh", "##um", "functioned", "as", "the", "capital", "of", "the", "`", "##`", "Union", "treaty", "'", "##'", "A", "##b", "##kha", "##z", "Soviet", "Socialist", "Republic", "associated", "with", "the", "Georgian", "SSR", "from", "1921", "until", "1931", ",", "when", "it", "became", "the", "capital", "of", "the", "A", "##b", "##kha", "##zia", "##n", "Autonomous", "Soviet", "Socialist", "Republic", "within", "the", "Georgian", "SSR", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Su", "##kh", "##um", "[unused2]", "[unused3]", "functioned", "[unused4]", "[unused5]", "as", "the", "capital", "of", "the", "`", "##`", "Union", "treaty", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "the", "capital", "of", "the", "A", "##b", "##kha", "##zia", "##n", "Autonomous", "Soviet", "Socialist", "Republic", "within", "the", "Georgian", "SSR", "[unused6]", "[SEP]", "[unused1]", "the", "`", "##`", "Union", "treaty", "'", "##'", "A", "##b", "##kha", "##z", "Soviet", "Socialist", "Republic", "[unused2]", "[unused3]", "associated", "[unused4]", "[unused5]", "with", "the", "Georgian", "SSR", "from", "1921", "until", "1931", "[unused6]", "[SEP]"]]}

input 255:  {"source": "Superboy-Prime , seeing an opportunity to defeat the now-weakened Anti-Monitor , flew through the Anti-Monitor 's chest and hurled his shattered body into space .\n"}
prediction:  {"predictions": [[1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 4843, 4, 5, 1194, 1103, 8329, 28137, 2107, 11153, 2772, 112, 1116, 2229, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 27060, 4, 5, 1117, 11670, 1404, 1154, 2000, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 27060, 4, 5, 1117, 11670, 1404, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 27060, 4, 5, 1117, 11670, 1404, 1154, 2000, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 27060, 4, 5, 1117, 11670, 1404, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 27060, 4, 5, 1117, 11670, 1404, 1154, 2000, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 27060, 4, 5, 1117, 11670, 1404, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 27060, 4, 5, 1117, 11670, 1404, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3198, 9858, 28137, 2101, 10205, 1162, 2, 3, 27060, 4, 5, 1117, 11670, 1404, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02790546417236328, -0.013150886632502079, -0.12944437563419342, -0.14567668735980988, -0.13855692744255066, -0.1566196233034134, -0.13565021753311157, -0.13337668776512146, -0.15216092765331268, -0.29801464080810547], "metadata": {"source_tokens": ["Super", "##boy", "##-", "##P", "##rim", "##e", ",", "seeing", "an", "opportunity", "to", "defeat", "the", "now", "##-", "##we", "##ake", "##ned", "Anti", "##-", "##M", "##oni", "##tor", ",", "flew", "through", "the", "Anti", "##-", "##M", "##oni", "##tor", "'", "##s", "chest", "and", "hurled", "his", "shattered", "body", "into", "space", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "flew", "[unused4]", "[unused5]", "through", "the", "Anti", "##-", "##M", "##oni", "##tor", "'", "##s", "chest", "[unused6]", "[SEP]", "[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "hurled", "[unused4]", "[unused5]", "his", "shattered", "body", "into", "space", "[unused6]", "[SEP]", "[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "hurled", "[unused4]", "[unused5]", "his", "shattered", "body", "[unused6]", "[SEP]", "[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "hurled", "[unused4]", "[unused5]", "his", "shattered", "body", "into", "space", "[unused6]", "[SEP]", "[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "hurled", "[unused4]", "[unused5]", "his", "shattered", "body", "[unused6]", "[SEP]", "[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "hurled", "[unused4]", "[unused5]", "his", "shattered", "body", "into", "space", "[unused6]", "[SEP]", "[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "hurled", "[unused4]", "[unused5]", "his", "shattered", "body", "[unused6]", "[SEP]", "[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "hurled", "[unused4]", "[unused5]", "his", "shattered", "body", "[unused6]", "[SEP]", "[unused1]", "Super", "##boy", "##-", "##P", "##rim", "##e", "[unused2]", "[unused3]", "hurled", "[unused4]", "[unused5]", "his", "shattered", "body", "[unused6]", "[SEP]"]]}

Batch 2 Test Time =  99.19104361534119  s
g_f_logprobs : 0.06827902793884277
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.2602193355560303
Decodertime : 0.0001728534698486328
Decodertime : 0.0001709461212158203
g_f_logprobs : 0.058562517166137695
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.09451985359191895
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.05944705009460449
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.058640241622924805
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.0984656810760498
Decodertime : 0.00018072128295898438
g_f_logprobs : 0.059499263763427734
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.09689879417419434
Decodertime : 0.00016760826110839844
g_f_logprobs : 0.06023073196411133
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.05861997604370117
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.09827041625976562
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.06026721000671387
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.09685468673706055
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.05989861488342285
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.05852699279785156
Decodertime : 0.00018286705017089844
g_f_logprobs : 0.09907793998718262
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.0602569580078125
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.05860543251037598
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.09825849533081055
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.059569597244262695
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.09701228141784668
Decodertime : 0.00018978118896484375
g_f_logprobs : 0.060005903244018555
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.05854368209838867
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.09880352020263672
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.05952024459838867
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.05862879753112793
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.09845280647277832
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.05950570106506348
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.09696531295776367
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.059530019760131836
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.05859875679016113
Decodertime : 0.00016021728515625
g_f_logprobs : 0.09840106964111328
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.05892586708068848
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.05860161781311035
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.09874200820922852
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.05955338478088379
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.09693551063537598
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.059502601623535156
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.05862689018249512
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.09842181205749512
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.06024932861328125
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.09685015678405762
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.05991697311401367
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.05795931816101074
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.09910869598388672
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.05950784683227539
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.05861258506774902
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.09837913513183594
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.05952310562133789
Decodertime : 0.00017833709716796875
g_f_logprobs : 0.09698271751403809
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.059683799743652344
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.05854678153991699
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.09865808486938477
Decodertime : 0.000156402587890625
g_f_logprobs : 0.05949115753173828
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.0586092472076416
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.0983591079711914
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.05955862998962402
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.09706473350524902
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.05957174301147461
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.05863618850708008
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.09845519065856934
Decodertime : 0.00016021728515625
g_f_logprobs : 0.05949807167053223
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.05860638618469238
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.09837746620178223
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.060303449630737305
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.09683418273925781
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.0594937801361084
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.058664560317993164
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.09846162796020508
Decodertime : 0.000164031982421875
g_f_logprobs : 0.05948519706726074
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.09692502021789551
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.06015372276306152
Decodertime : 0.000156402587890625
g_f_logprobs : 0.05863618850708008
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.09828567504882812
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.059525251388549805
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.05867195129394531
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.09845089912414551
Decodertime : 0.00018477439880371094
g_f_logprobs : 0.06027793884277344
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.09676647186279297
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.05948972702026367
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.05865001678466797
beam_search_time: 3.052722215652466 s
g_f_logprobs : 0.16464829444885254
Decodertime : 0.0001513957977294922
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.31864261627197266
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.09779715538024902
Decodertime : 0.0001690387725830078
g_f_logprobs : 0.09701395034790039
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.09792637825012207
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.09708452224731445
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.09794092178344727
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.09701704978942871
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.09794092178344727
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.09696555137634277
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.09792661666870117
Decodertime : 0.00017571449279785156
g_f_logprobs : 0.09699153900146484
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.09708642959594727
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.0970761775970459
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.09709429740905762
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.09710979461669922
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.09798574447631836
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.0970773696899414
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.09792542457580566
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.09697604179382324
beam_search_time: 5.36675238609314 s
g_f_logprobs : 0.3763563632965088
Decodertime : 0.0001461505889892578
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.24809741973876953
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.14168810844421387
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.09797835350036621
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.09634613990783691
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.14353299140930176
Decodertime : 0.00016021728515625
g_f_logprobs : 0.09743928909301758
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.14118123054504395
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.09830355644226074
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.09657549858093262
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.1429581642150879
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.0983729362487793
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.14125418663024902
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.0983896255493164
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.09646940231323242
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.14292192459106445
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.09839081764221191
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.1411888599395752
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.09828448295593262
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.09656167030334473
Decodertime : 0.0001780986785888672
g_f_logprobs : 0.14290094375610352
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.09835004806518555
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.14131879806518555
Decodertime : 0.0001895427703857422
g_f_logprobs : 0.09839653968811035
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.14119172096252441
g_f_logprobs : 0.09643149375915527
Decodertime : 0.0001571178436279297
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.09742546081542969
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.14315080642700195
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.09830904006958008
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.14124703407287598
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.09801316261291504
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.09650397300720215
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.14346837997436523
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.09839844703674316
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.14128589630126953
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.09827733039855957
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.09653878211975098
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.14290618896484375
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.09774374961853027
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.14136791229248047
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.09768080711364746
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.09644579887390137
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.14317727088928223
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.09838700294494629
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.1412496566772461
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.09833240509033203
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.09657502174377441
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.1429135799407959
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.09835052490234375
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.14125299453735352
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.09778642654418945
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.14158368110656738
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.09806442260742188
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.09647560119628906
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.14346981048583984
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.09830117225646973
Decodertime : 0.0001838207244873047
g_f_logprobs : 0.14120745658874512
Decodertime : 0.000164031982421875
g_f_logprobs : 0.09834551811218262
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.09650063514709473
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.14282846450805664
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.09763312339782715
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.1412951946258545
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.09822869300842285
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.09651660919189453
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.14287877082824707
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.09757423400878906
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.14107537269592285
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.0975801944732666
beam_search_time: 5.40347146987915 s
g_f_logprobs : 0.5530362129211426
Decodertime : 0.00015234947204589844
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.15726590156555176
Decodertime : 0.000171661376953125
g_f_logprobs : 0.14218711853027344
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.14157652854919434
Decodertime : 0.00018835067749023438
g_f_logprobs : 0.14151430130004883
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.1415567398071289
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.14159703254699707
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.14165925979614258
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.14168715476989746
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.14148306846618652
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.1414964199066162
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.14159059524536133
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.1416611671447754
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.1415085792541504
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.14149856567382812
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.14162755012512207
Decodertime : 0.000164031982421875
g_f_logprobs : 0.14165496826171875
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.14135003089904785
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.14140009880065918
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.1416015625
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.14161205291748047
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.14151453971862793
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.14153718948364258
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.1416165828704834
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.14166021347045898
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.14148640632629395
Decodertime : 0.00017142295837402344
g_f_logprobs : 0.14144325256347656
Decodertime : 0.000156402587890625
g_f_logprobs : 0.14136719703674316
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.14147496223449707
Decodertime : 0.0001747608184814453
g_f_logprobs : 0.14083266258239746
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.14171791076660156
Decodertime : 0.0001697540283203125
g_f_logprobs : 0.14150190353393555
Decodertime : 0.000164031982421875
g_f_logprobs : 0.1415700912475586
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.14148902893066406
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.14154815673828125
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.1414804458618164
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.14146924018859863
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.14153385162353516
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.14153003692626953
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.14149999618530273
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.1415543556213379
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.1415550708770752
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.1415882110595703
Decodertime : 0.00016021728515625
g_f_logprobs : 0.14155817031860352
beam_search_time: 7.6120946407318115 s
g_f_logprobs : 0.21284222602844238
Decodertime : 0.0001544952392578125
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.6510252952575684
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.13979601860046387
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.18873381614685059
Decodertime : 0.00017070770263671875
g_f_logprobs : 0.14182114601135254
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.18553495407104492
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.14185547828674316
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.1855940818786621
Decodertime : 0.000152587890625
g_f_logprobs : 0.14169526100158691
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.1397383213043213
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.18743324279785156
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.14177346229553223
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.18551135063171387
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.14181971549987793
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.18575572967529297
Decodertime : 0.0001690387725830078
g_f_logprobs : 0.1418299674987793
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.13973069190979004
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.18735980987548828
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.14193224906921387
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.1857137680053711
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.1419072151184082
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.18561172485351562
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.1417536735534668
Decodertime : 0.00018143653869628906
g_f_logprobs : 0.13978981971740723
Decodertime : 0.00016021728515625
g_f_logprobs : 0.18753600120544434
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.14190459251403809
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.18567180633544922
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.14184832572937012
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.18557453155517578
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.14174556732177734
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.13979840278625488
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.18754053115844727
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.14189553260803223
Decodertime : 0.00016021728515625
g_f_logprobs : 0.18566298484802246
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.14122939109802246
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.18575763702392578
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.14172077178955078
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.13863801956176758
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.18810296058654785
Decodertime : 0.00021576881408691406
g_f_logprobs : 0.14205002784729004
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.18550801277160645
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.1422121524810791
Decodertime : 0.00021338462829589844
g_f_logprobs : 0.1851644515991211
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.1415691375732422
Decodertime : 0.00016021728515625
g_f_logprobs : 0.18564367294311523
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.1418311595916748
Decodertime : 0.00016021728515625
g_f_logprobs : 0.13979625701904297
Decodertime : 0.00016021728515625
g_f_logprobs : 0.18745160102844238
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.1418018341064453
beam_search_time: 7.742425441741943 s
g_f_logprobs : 0.49092936515808105
Decodertime : 0.00015115737915039062
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.38100290298461914
Decodertime : 0.00019502639770507812
g_f_logprobs : 0.1653001308441162
Decodertime : 0.00014495849609375
g_f_logprobs : 0.18538594245910645
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.16396260261535645
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.18550992012023926
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.1640160083770752
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.1620619297027588
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.18736672401428223
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.1640338897705078
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.18541979789733887
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.16397857666015625
Decodertime : 0.00018167495727539062
g_f_logprobs : 0.185532808303833
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.16411805152893066
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.18532848358154297
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.16388368606567383
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.18533706665039062
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.16392898559570312
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.18561625480651855
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.1640610694885254
Decodertime : 0.00016021728515625
g_f_logprobs : 0.18539118766784668
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.1639721393585205
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.16182374954223633
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.18709778785705566
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.16405892372131348
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.18554401397705078
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.16388654708862305
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.1852867603302002
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.16398978233337402
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.18538117408752441
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.1638660430908203
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.18557977676391602
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.16425609588623047
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.18540692329406738
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.1638352870941162
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.18538475036621094
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.16399121284484863
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.18525099754333496
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.16384625434875488
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.16125273704528809
Decodertime : 0.00017023086547851562
g_f_logprobs : 0.18834853172302246
Decodertime : 0.00018858909606933594
g_f_logprobs : 0.16421103477478027
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.185166597366333
Decodertime : 0.00017261505126953125
g_f_logprobs : 0.1640644073486328
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.1854555606842041
Decodertime : 0.00016999244689941406
g_f_logprobs : 0.16392207145690918
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.18540549278259277
Decodertime : 0.00019097328186035156
g_f_logprobs : 0.1640481948852539
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.18532228469848633
Decodertime : 0.00017070770263671875
g_f_logprobs : 0.16381335258483887
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.18538880348205566
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.1639871597290039
Decodertime : 0.00017905235290527344
g_f_logprobs : 0.18545889854431152
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.16397476196289062
Decodertime : 0.000164031982421875
g_f_logprobs : 0.16193532943725586
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.18720746040344238
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.1638643741607666
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.18532919883728027
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.1640334129333496
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.18538689613342285
Decodertime : 0.000164031982421875
g_f_logprobs : 0.16391992568969727
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.18558239936828613
beam_search_time: 9.893088102340698 s
g_f_logprobs : 0.5028812885284424
Decodertime : 0.00014591217041015625
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.5366215705871582
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.16222357749938965
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.23342013359069824
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.16434907913208008
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.22946739196777344
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.16458725929260254
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.16198039054870605
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.23122787475585938
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.1647186279296875
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.22971749305725098
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.1645205020904541
Decodertime : 0.00016021728515625
g_f_logprobs : 0.22968411445617676
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.16463017463684082
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.16206979751586914
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.2313399314880371
Decodertime : 0.000152587890625
g_f_logprobs : 0.1645827293395996
Decodertime : 0.00016021728515625
g_f_logprobs : 0.2294607162475586
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.1643974781036377
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.1621849536895752
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.23142361640930176
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.1646125316619873
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.22975564002990723
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.16429853439331055
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.23006749153137207
Decodertime : 0.00017189979553222656
g_f_logprobs : 0.16408562660217285
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.16234970092773438
Decodertime : 0.00018906593322753906
g_f_logprobs : 0.23152637481689453
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.1643836498260498
beam_search_time: 8.991079568862915 s
g_f_logprobs : 0.7441399097442627
Decodertime : 0.00016307830810546875
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.35779690742492676
Decodertime : 0.00017261505126953125
g_f_logprobs : 0.20975136756896973
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.2302701473236084
Decodertime : 0.00019884109497070312
g_f_logprobs : 0.20893335342407227
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.23010969161987305
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.2088947296142578
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.23020434379577637
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.2089223861694336
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.20668554306030273
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.2323317527770996
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.20915627479553223
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.230299711227417
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.20901155471801758
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.23028206825256348
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.20901250839233398
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.23017168045043945
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.20891737937927246
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.23013710975646973
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.2089693546295166
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.23012685775756836
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.2089548110961914
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.2301626205444336
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.2089846134185791
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.22984957695007324
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.20840907096862793
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.23023509979248047
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.20894980430603027
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.20647072792053223
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.2321469783782959
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.20912861824035645
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.23037099838256836
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.20896172523498535
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.23021507263183594
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.2090005874633789
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.22999286651611328
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.20872879028320312
Decodertime : 0.0002334117889404297
g_f_logprobs : 0.23032498359680176
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.20912504196166992
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.23011350631713867
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.20890188217163086
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.23015809059143066
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.20902466773986816
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.22939825057983398
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.20815730094909668
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.23013615608215332
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.2090010643005371
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.2301626205444336
Decodertime : 0.00017714500427246094
g_f_logprobs : 0.20894384384155273
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.2066035270690918
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.23223137855529785
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.20903539657592773
Decodertime : 0.00017404556274414062
g_f_logprobs : 0.23046159744262695
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.2089982032775879
beam_search_time: 5.892892122268677 s
g_f_logprobs : 0.4176454544067383
Decodertime : 0.00015211105346679688
Decodertime : 0.00017404556274414062
g_f_logprobs : 0.7052228450775146
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.2118668556213379
Decodertime : 0.0001780986785888672
g_f_logprobs : 0.23040461540222168
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.21088814735412598
Decodertime : 0.0001976490020751953
g_f_logprobs : 0.2304210662841797
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.2108619213104248
Decodertime : 0.00019049644470214844
g_f_logprobs : 0.23038792610168457
Decodertime : 0.000148773193359375
g_f_logprobs : 0.21089935302734375
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.23048114776611328
Decodertime : 0.0001690387725830078
g_f_logprobs : 0.21070241928100586
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.23015117645263672
Decodertime : 0.0001690387725830078
g_f_logprobs : 0.21076631546020508
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.2082202434539795
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.23214411735534668
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.21087360382080078
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.23029327392578125
Decodertime : 0.00018596649169921875
g_f_logprobs : 0.21021318435668945
Decodertime : 0.00014352798461914062
g_f_logprobs : 0.22989368438720703
Decodertime : 0.00016760826110839844
g_f_logprobs : 0.21087098121643066
Decodertime : 0.00017142295837402344
g_f_logprobs : 0.2304391860961914
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.21086978912353516
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.23016953468322754
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.2107677459716797
Decodertime : 0.00019431114196777344
g_f_logprobs : 0.23033714294433594
beam_search_time: 12.937086820602417 s
g_f_logprobs : 0.6001989841461182
Decodertime : 0.0001468658447265625
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.5494444370269775
Decodertime : 0.0001780986785888672
g_f_logprobs : 0.23153328895568848
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.21074271202087402
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.23005461692810059
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.21080875396728516
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.2301781177520752
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.21073365211486816
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.23021435737609863
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.21072602272033691
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.23012924194335938
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.20865249633789062
Decodertime : 0.00014448165893554688
g_f_logprobs : 0.20776844024658203
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.2324824333190918
Decodertime : 0.0001709461212158203
g_f_logprobs : 0.2107863426208496
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.23009634017944336
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.210892915725708
Decodertime : 0.000164031982421875
g_f_logprobs : 0.23032641410827637
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.21077704429626465
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.23018264770507812
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.2108907699584961
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.23029327392578125
Decodertime : 0.000148773193359375
g_f_logprobs : 0.21077442169189453
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.23024868965148926
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.2107703685760498
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.23011112213134766
Decodertime : 0.00014829635620117188
g_f_logprobs : 0.2106935977935791
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.2302258014678955
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.2107551097869873
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.23003625869750977
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.21045708656311035
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.23033356666564941
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.21083879470825195
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.20749616622924805
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.23145246505737305
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.21091461181640625
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.23030948638916016
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.210768461227417
Decodertime : 0.00019621849060058594
g_f_logprobs : 0.2303175926208496
Decodertime : 0.000148773193359375
g_f_logprobs : 0.21102356910705566
Decodertime : 0.00014448165893554688
g_f_logprobs : 0.23062515258789062
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.21083998680114746
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.23023438453674316
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.21081781387329102
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.23016905784606934
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.2106165885925293
Decodertime : 0.000164031982421875
g_f_logprobs : 0.23010802268981934
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.2107563018798828
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.23024511337280273
Decodertime : 0.00017690658569335938
g_f_logprobs : 0.2104048728942871
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.23009848594665527
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.21076226234436035
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.23014211654663086
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.21064138412475586
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.2301645278930664
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.21030187606811523
Decodertime : 0.00014448165893554688
g_f_logprobs : 0.20840191841125488
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.2330799102783203
Decodertime : 0.0001773834228515625
g_f_logprobs : 0.2103121280670166
Decodertime : 0.00017118453979492188
g_f_logprobs : 0.22980594635009766
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.21048259735107422
Decodertime : 0.00017142295837402344
g_f_logprobs : 0.22998452186584473
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.21091008186340332
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.2301945686340332
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.21071290969848633
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.23017525672912598
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.21076536178588867
Decodertime : 0.00017213821411132812
g_f_logprobs : 0.23031258583068848
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.21083784103393555
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.23022985458374023
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.21078824996948242
beam_search_time: 11.348697423934937 s
g_f_logprobs : 0.8666272163391113
Decodertime : 0.0001552104949951172
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.4201204776763916
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.25644421577453613
Decodertime : 0.00014495849609375
g_f_logprobs : 0.23119878768920898
Decodertime : 0.000152587890625
g_f_logprobs : 0.25553274154663086
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.23134779930114746
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.2556338310241699
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.23131775856018066
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.2556014060974121
Decodertime : 0.00017499923706054688
g_f_logprobs : 0.23131251335144043
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.25542306900024414
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.23118257522583008
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.25551462173461914
g_f_logprobs : 0.2283174991607666
Decodertime : 0.00016570091247558594
Decodertime : 0.00016117095947265625
g_f_logprobs : 0.23161530494689941
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.25853705406188965
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.2313520908355713
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.2555887699127197
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.23128414154052734
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.2555274963378906
Decodertime : 0.00014448165893554688
g_f_logprobs : 0.2312936782836914
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.255251407623291
Decodertime : 0.00016021728515625
g_f_logprobs : 0.23081350326538086
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.2556138038635254
Decodertime : 0.00014495849609375
g_f_logprobs : 0.23146653175354004
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.2557690143585205
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.23144936561584473
Decodertime : 0.00017118453979492188
g_f_logprobs : 0.2554662227630615
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.2311859130859375
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.2556147575378418
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.23128032684326172
beam_search_time: 12.463303804397583 s
g_f_logprobs : 1.0514047145843506
Decodertime : 0.0001704692840576172
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.2445087432861328
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.2567863464355469
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.24564862251281738
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.25574803352355957
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.24529170989990234
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.2551603317260742
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.24501895904541016
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.25484752655029297
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.24591374397277832
Decodertime : 0.000148773193359375
g_f_logprobs : 0.25597500801086426
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.24570107460021973
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.2554972171783447
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.24566006660461426
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.25563573837280273
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.24562931060791016
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.2554326057434082
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.24561142921447754
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.25563740730285645
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.24578332901000977
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.2555241584777832
Decodertime : 0.00016760826110839844
g_f_logprobs : 0.2455146312713623
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.2554612159729004
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.24540448188781738
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.2552487850189209
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.24537181854248047
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.25548362731933594
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.24588227272033691
Decodertime : 0.00015044212341308594
g_f_logprobs : 0.2556922435760498
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.24567794799804688
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.25562286376953125
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.24581146240234375
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.2556765079498291
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.24572515487670898
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.25563740730285645
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.24566864967346191
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.2553739547729492
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.24551177024841309
Decodertime : 0.00017070770263671875
g_f_logprobs : 0.2548971176147461
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.24504423141479492
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.2553267478942871
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.24534082412719727
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.25569748878479004
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.24581336975097656
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.25562596321105957
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.24576520919799805
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.2557563781738281
Decodertime : 0.00014472007751464844
g_f_logprobs : 0.24586176872253418
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.25441980361938477
Decodertime : 0.00014519691467285156
g_f_logprobs : 0.24456334114074707
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.2545480728149414
Decodertime : 0.00014495849609375
g_f_logprobs : 0.24214839935302734
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.24189496040344238
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.2576136589050293
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.24585270881652832
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.2557556629180908
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.24559569358825684
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.25546860694885254
Decodertime : 0.0001442432403564453
g_f_logprobs : 0.24575066566467285
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.25573301315307617
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.24551010131835938
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.2553834915161133
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.2460184097290039
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.2555990219116211
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.24544930458068848
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.2555539608001709
Decodertime : 0.00016999244689941406
g_f_logprobs : 0.24484992027282715
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.25475382804870605
Decodertime : 0.00014448165893554688
g_f_logprobs : 0.24553442001342773
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.25545740127563477
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.24568605422973633
beam_search_time: 8.907208919525146 s
g_f_logprobs : 0.2391357421875
beam_search_time: 13.658916473388672 s
Decodertime : 0.0002300739288330078
Decodertime : 0.00020265579223632812
g_f_logprobs : 0.32266688346862793
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.30009007453918457
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.27761054039001465
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.3003356456756592
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.27674198150634766
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.3011462688446045
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.27770400047302246
Decodertime : 0.0001761913299560547
g_f_logprobs : 0.30097365379333496
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.2776656150817871
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.30057239532470703
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.27711057662963867
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.2745542526245117
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.304293155670166
Decodertime : 0.00014901161193847656
g_f_logprobs : 0.277510404586792
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.30091333389282227
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.27751922607421875
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.30086541175842285
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.277508020401001
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.30087876319885254
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.2774074077606201
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.3008420467376709
Decodertime : 0.0001494884490966797
g_f_logprobs : 0.2774951457977295
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.3008725643157959
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.27712059020996094
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.29998159408569336
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.27898621559143066
Decodertime : 0.0001857280731201172
g_f_logprobs : 0.30150461196899414
Decodertime : 0.00021314620971679688
g_f_logprobs : 0.27635765075683594
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.30112338066101074
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.2774345874786377
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.3004019260406494
Decodertime : 0.00014781951904296875
g_f_logprobs : 0.2770988941192627
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.3009495735168457
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.27754688262939453
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.27420926094055176
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.30112791061401367
Decodertime : 0.00017118453979492188
g_f_logprobs : 0.27767348289489746
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.30179858207702637
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.2774009704589844
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.3008689880371094
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.27777719497680664
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.30107879638671875
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.2775402069091797
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.30102968215942383
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.2774007320404053
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.30079054832458496
Decodertime : 0.0001456737518310547
g_f_logprobs : 0.2776305675506592
Decodertime : 0.00017499923706054688
g_f_logprobs : 0.3007323741912842
Decodertime : 0.00014448165893554688
g_f_logprobs : 0.2771463394165039
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.3005337715148926
Decodertime : 0.0001461505889892578
g_f_logprobs : 0.27713537216186523
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.30071043968200684
Decodertime : 0.00014638900756835938
g_f_logprobs : 0.2767188549041748
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.3004171848297119
Decodertime : 0.0001468658447265625
g_f_logprobs : 0.27761054039001465
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.30083537101745605
Decodertime : 0.00014710426330566406
g_f_logprobs : 0.27729105949401855
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.3007476329803467
Decodertime : 0.00014543533325195312
g_f_logprobs : 0.2775893211364746
Decodertime : 0.00014972686767578125
g_f_logprobs : 0.2739529609680176
Decodertime : 0.0001697540283203125
g_f_logprobs : 0.30257272720336914
Decodertime : 0.00014591217041015625
g_f_logprobs : 0.2760133743286133
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.30060291290283203
Decodertime : 0.00017762184143066406
g_f_logprobs : 0.2776455879211426
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.30087828636169434
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.27639341354370117
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.29996538162231445
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.27773571014404297
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.30097270011901855
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.27762341499328613
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.30102109909057617
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.2775075435638428
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.3010125160217285
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.2775382995605469
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.3008582592010498
Decodertime : 0.00014925003051757812
g_f_logprobs : 0.27748584747314453
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.3007316589355469
Decodertime : 0.0001480579376220703
g_f_logprobs : 0.277332067489624
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.3005084991455078
Decodertime : 0.0001704692840576172
g_f_logprobs : 0.277193546295166
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.29999446868896484
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.27672457695007324
Decodertime : 0.00015020370483398438
g_f_logprobs : 0.30112338066101074
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.2775535583496094
beam_search_time: 12.32967734336853 s
g_f_logprobs : 0.9085633754730225
Decodertime : 0.0001583099365234375
Decodertime : 0.0001862049102783203
g_f_logprobs : 0.6435551643371582
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.31521058082580566
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.30087757110595703
Decodertime : 0.00017523765563964844
g_f_logprobs : 0.315441370010376
Decodertime : 0.0001900196075439453
g_f_logprobs : 0.3013160228729248
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.3148839473724365
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.3009216785430908
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.31555652618408203
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.3012557029724121
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.29794931411743164
Decodertime : 0.000152587890625
g_f_logprobs : 0.3184030055999756
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.3018622398376465
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.31555938720703125
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.30113816261291504
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.3154580593109131
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.30111217498779297
beam_search_time: 16.10136365890503 s
g_f_logprobs : 0.32277393341064453
Decodertime : 0.00019860267639160156
g_f_logprobs : 1.0669138431549072
Decodertime : 0.00015664100646972656
Decodertime : 0.00018167495727539062
g_f_logprobs : 0.6130857467651367
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.34535837173461914
Decodertime : 0.00016951560974121094
g_f_logprobs : 0.31586599349975586
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.3461031913757324
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.3163318634033203
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.31249547004699707
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.34892725944519043
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.31615352630615234
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.3460710048675537
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.316051721572876
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.34573936462402344
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.3164327144622803
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.3462860584259033
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.3156290054321289
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.3451375961303711
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.31599950790405273
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.34575462341308594
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.31554245948791504
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.3453493118286133
Decodertime : 0.00018286705017089844
g_f_logprobs : 0.3163130283355713
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.3458683490753174
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.31607723236083984
Decodertime : 0.00015091896057128906
g_f_logprobs : 0.345930814743042
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.31577062606811523
Decodertime : 0.00015163421630859375
g_f_logprobs : 0.34517335891723633
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.3157467842102051
beam_search_time: 8.369142770767212 s
g_f_logprobs : 0.658860445022583
Decodertime : 0.0001728534698486328
g_f_logprobs : 0.9976153373718262
Decodertime : 0.00017905235290527344
Decodertime : 0.00020742416381835938
g_f_logprobs : 0.326183557510376
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.3454132080078125
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.3304007053375244
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.3459334373474121
Decodertime : 0.000152587890625
g_f_logprobs : 0.33081960678100586
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.3461434841156006
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.3305673599243164
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.3459465503692627
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.33077049255371094
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.3460359573364258
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.330585241317749
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.34594297409057617
Decodertime : 0.00014829635620117188
g_f_logprobs : 0.33059096336364746
Decodertime : 0.0001499652862548828
g_f_logprobs : 0.3454103469848633
Decodertime : 0.00014734268188476562
g_f_logprobs : 0.3301570415496826
Decodertime : 0.0001506805419921875
g_f_logprobs : 0.3460562229156494
Decodertime : 0.0001475811004638672
g_f_logprobs : 0.3307952880859375
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.3461439609527588
beam_search_time: 8.967034816741943 s
> [0;32m/home/hbeyer/imojie-master/imojie/models/copy_seq2seq_bahdanu.py[0m(679)[0;36m_encode[0;34m()[0m
[0;32m    678 [0;31m        [0;31m# shape: (batch_size, max_input_sequence_length)[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m--> 679 [0;31m        [0msource_mask[0m [0;34m=[0m [0mutil[0m[0;34m.[0m[0mget_text_field_mask[0m[0;34m([0m[0msource_tokens[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m    680 [0;31m        [0;31m#t1 = time.time()[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0m
ipdb> 
Exiting Debugger.
g_f_logprobs : 0.5612256526947021
Decodertime : 0.000202178955078125
g_f_logprobs : 0.29828691482543945
Decodertime : 0.00025534629821777344
g_f_logprobs : 0.2149348258972168
Decodertime : 0.00024008750915527344
g_f_logprobs : 0.21425318717956543
Decodertime : 0.0002033710479736328
g_f_logprobs : 0.2074263095855713
Decodertime : 0.00018548965454101562
g_f_logprobs : 0.2079479694366455
Decodertime : 0.00017189979553222656
g_f_logprobs : 0.20752763748168945
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.20799016952514648
Decodertime : 0.00017023086547851562
g_f_logprobs : 0.2079026699066162
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.2078545093536377
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.2077198028564453
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.20772767066955566
Decodertime : 0.00019168853759765625
g_f_logprobs : 0.20754790306091309
Decodertime : 0.0001742839813232422
g_f_logprobs : 0.2077646255493164
beam_search_time: 6.384627342224121 s
input 256:  {"source": "Swinburne moves in his writing program from the philosophical to the theological , building his case rigorously .\n"}
prediction:  {"predictions": [[1, 156, 7445, 26980, 2, 3, 5279, 4, 5, 1107, 1117, 2269, 1788, 1121, 1103, 11388, 1106, 1103, 14757, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 156, 7445, 26980, 2, 3, 5279, 4, 5, 1107, 1117, 2269, 1788, 1121, 1103, 11388, 1106, 1103, 14757, 1459, 1117, 1692, 22112, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013257435522973537, -0.11177098006010056, -0.12795639038085938, -0.16735470294952393, -0.16735470294952393, -0.16735470294952393, -0.16735470294952393, -0.16735470294952393, -0.16735470294952393, -0.16735470294952393], "metadata": {"source_tokens": ["S", "##win", "##burne", "moves", "in", "his", "writing", "program", "from", "the", "philosophical", "to", "the", "theological", ",", "building", "his", "case", "rigorous", "##ly", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "S", "##win", "##burne", "[unused2]", "[unused3]", "moves", "[unused4]", "[unused5]", "in", "his", "writing", "program", "from", "the", "philosophical", "to", "the", "theological", "[unused6]", "[SEP]", "[unused1]", "S", "##win", "##burne", "[unused2]", "[unused3]", "moves", "[unused4]", "[unused5]", "in", "his", "writing", "program", "from", "the", "philosophical", "to", "the", "theological", "building", "his", "case", "rigorous", "##ly", "[unused6]", "[SEP]"]]}

input 257:  {"source": "Team Racing is a NASCAR Craftsman Truck Series team .\n"}
prediction:  {"predictions": [[1, 2649, 6770, 2, 3, 1110, 4, 5, 170, 11924, 26460, 1399, 19965, 2768, 1264, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00021491349616553634, -9.202957153320312e-05, -9.5367431640625e-05, -9.5367431640625e-05, -9.5367431640625e-05, -9.5367431640625e-05, -9.5367431640625e-05, -9.5367431640625e-05, -9.5367431640625e-05, -9.5367431640625e-05], "metadata": {"source_tokens": ["Team", "Racing", "is", "a", "NASCAR", "Crafts", "##man", "Truck", "Series", "team", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Team", "Racing", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "NASCAR", "Crafts", "##man", "Truck", "Series", "team", "[unused6]", "[SEP]"]]}

input 258:  {"source": "That same year saw an outbreak of plague in Venice , one that lasted two years and caused Franco to leave the city and to lose many of her possessions .\n"}
prediction:  {"predictions": [[1, 1337, 1269, 1214, 2, 3, 1486, 4, 5, 1126, 8010, 1104, 13824, 1107, 7433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1141, 2, 3, 5695, 4, 5, 1160, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1141, 2, 3, 2416, 4, 5, 9063, 1106, 1817, 1103, 1331, 1105, 1106, 3857, 1242, 1104, 1123, 14264, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9063, 2, 3, 1106, 1817, 4, 5, 1103, 1331, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008415951393544674, -0.06806585192680359, -0.03213924914598465, -0.12301427125930786, -0.12383246421813965, -0.12404942512512207, -0.12404942512512207, -0.12404942512512207, -0.12404942512512207, -0.12404942512512207], "metadata": {"source_tokens": ["That", "same", "year", "saw", "an", "outbreak", "of", "plague", "in", "Venice", ",", "one", "that", "lasted", "two", "years", "and", "caused", "Franco", "to", "leave", "the", "city", "and", "to", "lose", "many", "of", "her", "possessions", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "That", "same", "year", "[unused2]", "[unused3]", "saw", "[unused4]", "[unused5]", "an", "outbreak", "of", "plague", "in", "Venice", "[unused6]", "[SEP]", "[unused1]", "one", "[unused2]", "[unused3]", "lasted", "[unused4]", "[unused5]", "two", "years", "[unused6]", "[SEP]", "[unused1]", "one", "[unused2]", "[unused3]", "caused", "[unused4]", "[unused5]", "Franco", "to", "leave", "the", "city", "and", "to", "lose", "many", "of", "her", "possessions", "[unused6]", "[SEP]", "[unused1]", "Franco", "[unused2]", "[unused3]", "to", "leave", "[unused4]", "[unused5]", "the", "city", "[unused6]", "[SEP]"]]}

input 259:  {"source": "The 2nd Battalion of the 13th Light Infantry was raised at Winchester in January 1858 .\n"}
prediction:  {"predictions": [[1, 1109, 2518, 4244, 1104, 1103, 5435, 3935, 4155, 2, 3, 1108, 2120, 4, 5, 1120, 13043, 1107, 1356, 8109, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00023763830540701747, -0.00030040740966796875, -0.0002918243408203125, -0.0002918243408203125, -0.0002918243408203125, -0.0002918243408203125, -0.0002918243408203125, -0.0002918243408203125, -0.0002918243408203125, -0.0002918243408203125], "metadata": {"source_tokens": ["The", "2nd", "Battalion", "of", "the", "13th", "Light", "Infantry", "was", "raised", "at", "Winchester", "in", "January", "1858", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "2nd", "Battalion", "of", "the", "13th", "Light", "Infantry", "[unused2]", "[unused3]", "was", "raised", "[unused4]", "[unused5]", "at", "Winchester", "in", "January", "1858", "[unused6]", "[SEP]"]]}

input 260:  {"source": "The Acrolepiidae family of moths are also known as False Diamondback moths .\n"}
prediction:  {"predictions": [[1, 1109, 138, 1665, 13166, 8043, 19793, 1266, 1104, 16297, 2, 3, 1132, 1145, 1227, 4, 5, 1112, 143, 7264, 1162, 8549, 4197, 16297, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02085263840854168, -0.0008673667907714844, -0.0009584426879882812, -0.0009584426879882812, -0.0009584426879882812, -0.0009584426879882812, -0.0009584426879882812, -0.0009584426879882812, -0.0009584426879882812, -0.0009584426879882812], "metadata": {"source_tokens": ["The", "A", "##c", "##rol", "##ep", "##iidae", "family", "of", "moths", "are", "also", "known", "as", "F", "##als", "##e", "Diamond", "##back", "moths", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "A", "##c", "##rol", "##ep", "##iidae", "family", "of", "moths", "[unused2]", "[unused3]", "are", "also", "known", "[unused4]", "[unused5]", "as", "F", "##als", "##e", "Diamond", "##back", "moths", "[unused6]", "[SEP]"]]}

input 261:  {"source": "The Alarm are an alternative rock/new wave band that formed in Rhyl , North Wales , in 1981 .\n"}
prediction:  {"predictions": [[1, 1109, 2586, 20350, 2, 3, 1132, 4, 5, 1126, 4174, 2067, 28139, 1673, 2246, 4003, 1467, 1115, 1824, 1107, 155, 18873, 117, 1456, 2717, 117, 1107, 2358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1126, 4174, 2067, 28139, 1673, 2246, 4003, 1467, 2, 3, 1824, 4, 5, 1107, 155, 18873, 1107, 2358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0023120054975152016, -0.04009956121444702, -0.03220319747924805, -0.032202720642089844, -0.032202720642089844, -0.032202720642089844, -0.032202720642089844, -0.032202720642089844, -0.032202720642089844, -0.032202720642089844], "metadata": {"source_tokens": ["The", "Al", "##arm", "are", "an", "alternative", "rock", "##/", "##ne", "##w", "wave", "band", "that", "formed", "in", "R", "##hyl", ",", "North", "Wales", ",", "in", "1981", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Al", "##arm", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "an", "alternative", "rock", "##/", "##ne", "##w", "wave", "band", "that", "formed", "in", "R", "##hyl", ",", "North", "Wales", ",", "in", "1981", "[unused6]", "[SEP]", "[unused1]", "an", "alternative", "rock", "##/", "##ne", "##w", "wave", "band", "[unused2]", "[unused3]", "formed", "[unused4]", "[unused5]", "in", "R", "##hyl", "in", "1981", "[unused6]", "[SEP]"]]}

input 262:  {"source": "The Bourbons built additional reception rooms and reconstructed the Sala d'Ercole , named for its frescos depicted the mythological hero , Hercules .\n"}
prediction:  {"predictions": [[1, 1109, 19247, 1116, 2, 3, 1434, 4, 5, 2509, 7602, 4045, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 19247, 1116, 2, 3, 15755, 4, 5, 1103, 18613, 1161, 173, 28131, 2036, 19878, 9016, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 18613, 1161, 173, 28131, 2036, 19878, 9016, 2, 3, 1417, 4, 5, 1111, 1157, 175, 4894, 13538, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 24596, 6485, 2, 3, 1110, 4, 5, 16496, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02243587002158165, -0.05965442582964897, -0.05665137618780136, -0.06913602352142334, -0.03220677375793457, -0.03220677375793457, -0.03220677375793457, -0.03220677375793457, -0.03220677375793457, -0.03220677375793457], "metadata": {"source_tokens": ["The", "Bourbon", "##s", "built", "additional", "reception", "rooms", "and", "reconstructed", "the", "Sal", "##a", "d", "##'", "##E", "##rc", "##ole", ",", "named", "for", "its", "f", "##res", "##cos", "depicted", "the", "mythological", "hero", ",", "Hercules", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Bourbon", "##s", "[unused2]", "[unused3]", "built", "[unused4]", "[unused5]", "additional", "reception", "rooms", "[unused6]", "[SEP]", "[unused1]", "The", "Bourbon", "##s", "[unused2]", "[unused3]", "reconstructed", "[unused4]", "[unused5]", "the", "Sal", "##a", "d", "##'", "##E", "##rc", "##ole", "[unused6]", "[SEP]", "[unused1]", "the", "Sal", "##a", "d", "##'", "##E", "##rc", "##ole", "[unused2]", "[unused3]", "named", "[unused4]", "[unused5]", "for", "its", "f", "##res", "##cos", "[unused6]", "[SEP]", "[unused1]", "the", "mythological", "hero", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Hercules", "[unused6]", "[SEP]"]]}

input 263:  {"source": "The Bureau of Alcohol , Tobacco , Firearms and Explosives , formed in 1886 , is a federal law enforcement organization within the United States Department of Justice .\n"}
prediction:  {"predictions": [[1, 1109, 4447, 1104, 2586, 2528, 14084, 117, 25159, 117, 4266, 20350, 1116, 1105, 16409, 1643, 8867, 11355, 2, 3, 1110, 4, 5, 170, 2877, 1644, 7742, 2369, 1439, 1103, 1244, 1311, 1951, 1104, 3302, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4447, 1104, 2586, 2528, 14084, 117, 25159, 117, 4266, 20350, 1116, 1105, 16409, 1643, 8867, 11355, 2, 3, 1824, 4, 5, 1107, 6332, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.021881407126784325, -0.01995842158794403, -0.022086143493652344, -0.022086143493652344, -0.022086143493652344, -0.022086143493652344, -0.022086143493652344, -0.022086143493652344, -0.022086143493652344, -0.022086143493652344], "metadata": {"source_tokens": ["The", "Bureau", "of", "Al", "##co", "##hol", ",", "Tobacco", ",", "Fire", "##arm", "##s", "and", "Ex", "##p", "##los", "##ives", ",", "formed", "in", "1886", ",", "is", "a", "federal", "law", "enforcement", "organization", "within", "the", "United", "States", "Department", "of", "Justice", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Bureau", "of", "Al", "##co", "##hol", ",", "Tobacco", ",", "Fire", "##arm", "##s", "and", "Ex", "##p", "##los", "##ives", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "federal", "law", "enforcement", "organization", "within", "the", "United", "States", "Department", "of", "Justice", "[unused6]", "[SEP]", "[unused1]", "The", "Bureau", "of", "Al", "##co", "##hol", ",", "Tobacco", ",", "Fire", "##arm", "##s", "and", "Ex", "##p", "##los", "##ives", "[unused2]", "[unused3]", "formed", "[unused4]", "[unused5]", "in", "1886", "[unused6]", "[SEP]"]]}

input 264:  {"source": "The CRZ was organized by the Nepal and Indian members of the Naxalite movement , in a meeting at Siliguri in the Indian State of West Bengal during August 2001 .\n"}
prediction:  {"predictions": [[1, 1109, 15531, 5301, 2, 3, 1108, 3366, 4, 5, 1118, 1103, 7795, 1105, 1890, 1484, 1104, 1103, 11896, 20192, 21998, 2230, 1107, 170, 2309, 1120, 14159, 2646, 13830, 2047, 1107, 1103, 1890, 1426, 1104, 1537, 7756, 1219, 1360, 1630, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 15531, 5301, 2, 3, 1108, 3366, 4, 5, 1118, 1103, 7795, 1105, 1890, 1484, 1104, 1103, 11896, 20192, 21998, 2230, 1107, 170, 2309, 1120, 14159, 2646, 13830, 2047, 1107, 1103, 1890, 1426, 1104, 1537, 7756, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 15531, 5301, 2, 3, 1108, 3366, 4, 5, 1118, 1103, 7795, 1105, 1890, 1484, 1104, 1103, 11896, 20192, 21998, 2230, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 15531, 5301, 2, 3, 1108, 3366, 4, 5, 1118, 1103, 7795, 1105, 1890, 1484, 1104, 1103, 11896, 20192, 21998, 2230, 1107, 170, 2309, 1120, 14159, 2646, 13830, 2047, 1107, 1103, 1890, 1426, 1104, 1537, 7756, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014462224207818508, -0.030955828726291656, -0.2333592176437378, -0.04990185424685478, -0.06010806933045387, -0.1934971809387207, -0.20431733131408691, -0.20431733131408691, -0.20431733131408691, -0.20431733131408691], "metadata": {"source_tokens": ["The", "CR", "##Z", "was", "organized", "by", "the", "Nepal", "and", "Indian", "members", "of", "the", "Na", "##xa", "##lite", "movement", ",", "in", "a", "meeting", "at", "Si", "##li", "##gu", "##ri", "in", "the", "Indian", "State", "of", "West", "Bengal", "during", "August", "2001", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "CR", "##Z", "[unused2]", "[unused3]", "was", "organized", "[unused4]", "[unused5]", "by", "the", "Nepal", "and", "Indian", "members", "of", "the", "Na", "##xa", "##lite", "movement", "in", "a", "meeting", "at", "Si", "##li", "##gu", "##ri", "in", "the", "Indian", "State", "of", "West", "Bengal", "during", "August", "2001", "[unused6]", "[SEP]", "[unused1]", "The", "CR", "##Z", "[unused2]", "[unused3]", "was", "organized", "[unused4]", "[unused5]", "by", "the", "Nepal", "and", "Indian", "members", "of", "the", "Na", "##xa", "##lite", "movement", "in", "a", "meeting", "at", "Si", "##li", "##gu", "##ri", "in", "the", "Indian", "State", "of", "West", "Bengal", "[unused6]", "[SEP]"]]}

input 265:  {"source": "The Charles City equipment was transferred to Mason City to replace equipment burned in the November 24 , 1967 shop fire .\n"}
prediction:  {"predictions": [[1, 3204, 2, 3, 4562, 4, 5, 1107, 1103, 1379, 1572, 117, 2573, 4130, 1783, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1889, 1392, 3204, 2, 3, 1108, 3175, 4, 5, 1106, 6287, 1392, 1106, 4971, 3204, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027932241559028625, -0.01713530905544758, -0.03220653533935547, -0.03225350379943848, -0.03225350379943848, -0.03225350379943848, -0.03225350379943848, -0.03225350379943848, -0.03225350379943848, -0.03225350379943848], "metadata": {"source_tokens": ["The", "Charles", "City", "equipment", "was", "transferred", "to", "Mason", "City", "to", "replace", "equipment", "burned", "in", "the", "November", "24", ",", "1967", "shop", "fire", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "equipment", "[unused2]", "[unused3]", "burned", "[unused4]", "[unused5]", "in", "the", "November", "24", ",", "1967", "shop", "fire", "[unused6]", "[SEP]", "[unused1]", "The", "Charles", "City", "equipment", "[unused2]", "[unused3]", "was", "transferred", "[unused4]", "[unused5]", "to", "Mason", "City", "to", "replace", "equipment", "[unused6]", "[SEP]"]]}

input 266:  {"source": "The Hamburg Concathedral with chapterhouse and capitular residential courts formed a `` Cathedral Immunity District '' of the Prince-Archbishopric of Bremen too .\n"}
prediction:  {"predictions": [[1, 1109, 8339, 16752, 12650, 8961, 4412, 1114, 6073, 3255, 1105, 6707, 2875, 5552, 5198, 5333, 2, 3, 1824, 1315, 4, 5, 170, 169, 28152, 5761, 146, 6262, 22534, 1574, 112, 28131, 1104, 1103, 2558, 28137, 1592, 10340, 26652, 4184, 4907, 1104, 17339, 6, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013963609002530575, -0.12768888473510742, -0.12424778938293457, -0.12424778938293457, -0.12424778938293457, -0.12424778938293457, -0.12424778938293457, -0.12424778938293457, -0.12424778938293457, -0.12424778938293457], "metadata": {"source_tokens": ["The", "Hamburg", "Con", "##cat", "##hed", "##ral", "with", "chapter", "##house", "and", "cap", "##it", "##ular", "residential", "courts", "formed", "a", "`", "##`", "Cathedral", "I", "##mm", "##unity", "District", "'", "##'", "of", "the", "Prince", "##-", "##A", "##rch", "##bish", "##op", "##ric", "of", "Bremen", "too", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Hamburg", "Con", "##cat", "##hed", "##ral", "with", "chapter", "##house", "and", "cap", "##it", "##ular", "residential", "courts", "[unused2]", "[unused3]", "formed", "too", "[unused4]", "[unused5]", "a", "`", "##`", "Cathedral", "I", "##mm", "##unity", "District", "'", "##'", "of", "the", "Prince", "##-", "##A", "##rch", "##bish", "##op", "##ric", "of", "Bremen", "[unused6]", "[SEP]"]]}

input 267:  {"source": "The Main Street Tunnel , located in Welland , Ontario , Canada , is an underwater tunnel , carrying Niagara Road 27 and the unsigned designation of Highway 7146 under the Welland Canal .\n"}
prediction:  {"predictions": [[1, 1109, 4304, 1715, 12872, 2, 3, 1388, 4, 5, 1107, 2119, 5709, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4304, 1715, 12872, 2, 3, 1110, 4, 5, 1126, 13082, 5280, 117, 4004, 16351, 1914, 1765, 1105, 1103, 8362, 16173, 7970, 1104, 3580, 5729, 23435, 1223, 1103, 2119, 5709, 6327, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4304, 1715, 12872, 1388, 1107, 2119, 5709, 1803, 2, 3, 1110, 4, 5, 1126, 13082, 5280, 4004, 16351, 1914, 1765, 1105, 1103, 8362, 16173, 7970, 1104, 3580, 5729, 23435, 1223, 1103, 2119, 5709, 6327, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02097148820757866, -0.02794671803712845, -0.06994463503360748, -0.14893484115600586, -0.15479934215545654, -0.15479934215545654, -0.15479934215545654, -0.15479934215545654, -0.15479934215545654, -0.15479934215545654], "metadata": {"source_tokens": ["The", "Main", "Street", "Tunnel", ",", "located", "in", "Well", "##and", ",", "Ontario", ",", "Canada", ",", "is", "an", "underwater", "tunnel", ",", "carrying", "Niagara", "Road", "27", "and", "the", "un", "##signed", "designation", "of", "Highway", "71", "##46", "under", "the", "Well", "##and", "Canal", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Main", "Street", "Tunnel", "[unused2]", "[unused3]", "located", "[unused4]", "[unused5]", "in", "Well", "##and", "[unused6]", "[SEP]", "[unused1]", "The", "Main", "Street", "Tunnel", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "underwater", "tunnel", ",", "carrying", "Niagara", "Road", "27", "and", "the", "un", "##signed", "designation", "of", "Highway", "71", "##46", "under", "the", "Well", "##and", "Canal", "[unused6]", "[SEP]", "[unused1]", "The", "Main", "Street", "Tunnel", "located", "in", "Well", "##and", "Canada", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "underwater", "tunnel", "carrying", "Niagara", "Road", "27", "and", "the", "un", "##signed", "designation", "of", "Highway", "71", "##46", "under", "the", "Well", "##and", "Canal", "[unused6]", "[SEP]"]]}

input 268:  {"source": "The Nadvorna dynasty is notable inasmuch as many of its descendants become rebbes .\n"}
prediction:  {"predictions": [[1, 1109, 11896, 1181, 12198, 1605, 6107, 2, 3, 1110, 4, 5, 3385, 1107, 2225, 13601, 1732, 1112, 1242, 1104, 1157, 8395, 1561, 1231, 20584, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1242, 1104, 1157, 8395, 2, 3, 1561, 4, 5, 1231, 20584, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012584720738232136, -0.008662628941237926, -0.008665084838867188, -0.00877523422241211, -0.00877523422241211, -0.00877523422241211, -0.00877523422241211, -0.00877523422241211, -0.00877523422241211, -0.00877523422241211], "metadata": {"source_tokens": ["The", "Na", "##d", "##vor", "##na", "dynasty", "is", "notable", "in", "##as", "##mu", "##ch", "as", "many", "of", "its", "descendants", "become", "re", "##bbe", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Na", "##d", "##vor", "##na", "dynasty", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "notable", "in", "##as", "##mu", "##ch", "as", "many", "of", "its", "descendants", "become", "re", "##bbe", "##s", "[unused6]", "[SEP]", "[unused1]", "many", "of", "its", "descendants", "[unused2]", "[unused3]", "become", "[unused4]", "[unused5]", "re", "##bbe", "##s", "[unused6]", "[SEP]"]]}

input 269:  {"source": "The PAC bulletins were widely distributed at these meetings .\n"}
prediction:  {"predictions": [[1, 1109, 8544, 1658, 8417, 4935, 2, 3, 1127, 3409, 4901, 4, 5, 1120, 1292, 5845, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0002887513837777078, -0.0003609657287597656, -0.0002875328063964844, -0.0002875328063964844, -0.0002875328063964844, -0.0002875328063964844, -0.0002875328063964844, -0.0002875328063964844, -0.0002875328063964844, -0.0002875328063964844], "metadata": {"source_tokens": ["The", "PA", "##C", "bullet", "##ins", "were", "widely", "distributed", "at", "these", "meetings", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "PA", "##C", "bullet", "##ins", "[unused2]", "[unused3]", "were", "widely", "distributed", "[unused4]", "[unused5]", "at", "these", "meetings", "[unused6]", "[SEP]"]]}

input 270:  {"source": "The Persian contingent that was supposed to guard the defile soon abandoned it , and Alexander passed through without any problems .\n"}
prediction:  {"predictions": [[1, 1109, 3886, 17286, 2, 3, 1108, 3155, 4, 5, 1106, 3542, 1103, 19353, 4759, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 3886, 17286, 1115, 1108, 3155, 1106, 3542, 1103, 19353, 4759, 2, 3, 3928, 4, 5, 1122, 1770, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2792, 2, 3, 2085, 1194, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2792, 2, 3, 2085, 1194, 4, 5, 1443, 1251, 2645, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.049772709608078, -0.04761901870369911, -0.037940431386232376, -0.06640663743019104, -0.032830238342285156, -0.03306984901428223, -0.03306984901428223, -0.03306984901428223, -0.03306984901428223, -0.03306984901428223], "metadata": {"source_tokens": ["The", "Persian", "contingent", "that", "was", "supposed", "to", "guard", "the", "def", "##ile", "soon", "abandoned", "it", ",", "and", "Alexander", "passed", "through", "without", "any", "problems", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Persian", "contingent", "[unused2]", "[unused3]", "was", "supposed", "[unused4]", "[unused5]", "to", "guard", "the", "def", "##ile", "[unused6]", "[SEP]", "[unused1]", "The", "Persian", "contingent", "that", "was", "supposed", "to", "guard", "the", "def", "##ile", "[unused2]", "[unused3]", "abandoned", "[unused4]", "[unused5]", "it", "soon", "[unused6]", "[SEP]", "[unused1]", "Alexander", "[unused2]", "[unused3]", "passed", "through", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Alexander", "[unused2]", "[unused3]", "passed", "through", "[unused4]", "[unused5]", "without", "any", "problems", "[unused6]", "[SEP]"]]}

input 271:  {"source": "The Rev. William Alfred Quayle was honored by his alma mater , Baker University , with the degrees Litt.D .\n"}
prediction:  {"predictions": [[1, 1109, 6750, 28138, 1613, 5492, 154, 19925, 1513, 2, 3, 1108, 8817, 4, 5, 1118, 1117, 24095, 23662, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 24095, 23662, 2, 3, 1110, 4, 5, 5779, 1239, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 6750, 28138, 1613, 5492, 154, 19925, 1513, 2, 3, 1108, 8817, 4, 5, 1118, 1117, 24095, 23662, 1114, 1103, 4842, 5255, 3069, 28138, 2137, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.054155342280864716, -0.057548221200704575, -0.039995405822992325, -0.03863334655761719, -0.0386347770690918, -0.0386347770690918, -0.0386347770690918, -0.0386347770690918, -0.0386347770690918, -0.0386347770690918], "metadata": {"source_tokens": ["The", "Rev", "##.", "William", "Alfred", "Q", "##uay", "##le", "was", "honored", "by", "his", "alma", "mater", ",", "Baker", "University", ",", "with", "the", "degrees", "Li", "##tt", "##.", "##D", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Rev", "##.", "William", "Alfred", "Q", "##uay", "##le", "[unused2]", "[unused3]", "was", "honored", "[unused4]", "[unused5]", "by", "his", "alma", "mater", "[unused6]", "[SEP]", "[unused1]", "his", "alma", "mater", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Baker", "University", "[unused6]", "[SEP]", "[unused1]", "The", "Rev", "##.", "William", "Alfred", "Q", "##uay", "##le", "[unused2]", "[unused3]", "was", "honored", "[unused4]", "[unused5]", "by", "his", "alma", "mater", "with", "the", "degrees", "Li", "##tt", "##.", "##D", "[unused6]", "[SEP]"]]}

input 272:  {"source": "The River Stour Trust , formed in 1968 , has its headquarters in Sudbury , and a purpose built Visitor Centre located at Cornard Lock .\n"}
prediction:  {"predictions": [[1, 1109, 1595, 1457, 6334, 4623, 2, 3, 1824, 4, 5, 1107, 2477, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1595, 1457, 6334, 4623, 2, 3, 1144, 4, 5, 1157, 3834, 1107, 15463, 26837, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 159, 26868, 2772, 2961, 2, 3, 1388, 4, 5, 1120, 3291, 11782, 2956, 18292, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.049413759261369705, -0.02627597190439701, -0.04316315799951553, -0.03220796585083008, -0.03220844268798828, -0.03220844268798828, -0.03220844268798828, -0.03220844268798828, -0.03220844268798828, -0.03220844268798828], "metadata": {"source_tokens": ["The", "River", "St", "##our", "Trust", ",", "formed", "in", "1968", ",", "has", "its", "headquarters", "in", "Su", "##dbury", ",", "and", "a", "purpose", "built", "V", "##isi", "##tor", "Centre", "located", "at", "Co", "##rna", "##rd", "Lock", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "River", "St", "##our", "Trust", "[unused2]", "[unused3]", "formed", "[unused4]", "[unused5]", "in", "1968", "[unused6]", "[SEP]", "[unused1]", "The", "River", "St", "##our", "Trust", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "its", "headquarters", "in", "Su", "##dbury", "[unused6]", "[SEP]", "[unused1]", "V", "##isi", "##tor", "Centre", "[unused2]", "[unused3]", "located", "[unused4]", "[unused5]", "at", "Co", "##rna", "##rd", "Lock", "[unused6]", "[SEP]"]]}

input 273:  {"source": "The SAS killed a total of 14 Provisional Irish Republican Army and Irish National Liberation Army members at these locations .\n"}
prediction:  {"predictions": [[1, 1109, 25828, 2, 3, 1841, 4, 5, 170, 1703, 1104, 1489, 18639, 2600, 3215, 1740, 1105, 2600, 1305, 10912, 1740, 1484, 1120, 1292, 4541, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0007073790766298771, -0.0385441780090332, -0.042676448822021484, -0.042676448822021484, -0.042676448822021484, -0.042676448822021484, -0.042676448822021484, -0.042676448822021484, -0.042676448822021484, -0.042676448822021484], "metadata": {"source_tokens": ["The", "SAS", "killed", "a", "total", "of", "14", "Provisional", "Irish", "Republican", "Army", "and", "Irish", "National", "Liberation", "Army", "members", "at", "these", "locations", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "SAS", "[unused2]", "[unused3]", "killed", "[unused4]", "[unused5]", "a", "total", "of", "14", "Provisional", "Irish", "Republican", "Army", "and", "Irish", "National", "Liberation", "Army", "members", "at", "these", "locations", "[unused6]", "[SEP]"]]}

input 274:  {"source": "The Steinbrenner family added a monument to Monument Park on September 20 , 2010 to honor Steinbrenner .\n"}
prediction:  {"predictions": [[1, 1109, 14981, 9730, 27106, 1266, 2, 3, 1896, 4, 5, 170, 7020, 1106, 12267, 1670, 1113, 1347, 1406, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 14981, 9730, 27106, 1266, 2, 3, 1896, 4, 5, 170, 7020, 1106, 3874, 14981, 9730, 27106, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04165316000580788, -0.023321008309721947, -0.32778024673461914, -0.29397106170654297, -0.29397106170654297, -0.29397106170654297, -0.29397106170654297, -0.29397106170654297, -0.29397082328796387, -0.29397106170654297], "metadata": {"source_tokens": ["The", "Stein", "##bre", "##nner", "family", "added", "a", "monument", "to", "Monument", "Park", "on", "September", "20", ",", "2010", "to", "honor", "Stein", "##bre", "##nner", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Stein", "##bre", "##nner", "family", "[unused2]", "[unused3]", "added", "[unused4]", "[unused5]", "a", "monument", "to", "Monument", "Park", "on", "September", "20", "[unused6]", "[SEP]", "[unused1]", "The", "Stein", "##bre", "##nner", "family", "[unused2]", "[unused3]", "added", "[unused4]", "[unused5]", "a", "monument", "to", "honor", "Stein", "##bre", "##nner", "[unused6]", "[SEP]"]]}

input 275:  {"source": "The Summer Programs Office runs these programs , and many Wardlaw-Hartridge Students attend camp or classes over the summer .\n"}
prediction:  {"predictions": [[1, 1109, 2659, 18555, 3060, 2, 3, 2326, 4, 5, 1292, 2648, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1242, 5661, 9598, 28137, 3048, 9349, 8044, 6510, 2, 3, 4739, 4, 5, 3227, 1137, 3553, 1166, 1103, 2247, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023491723462939262, -0.0009441159199923277, -0.022001266479492188, -0.022001266479492188, -0.022001266479492188, -0.022001266479492188, -0.022001266479492188, -0.022001266479492188, -0.022001266479492188, -0.022001266479492188], "metadata": {"source_tokens": ["The", "Summer", "Programs", "Office", "runs", "these", "programs", ",", "and", "many", "Ward", "##law", "##-", "##H", "##art", "##ridge", "Students", "attend", "camp", "or", "classes", "over", "the", "summer", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Summer", "Programs", "Office", "[unused2]", "[unused3]", "runs", "[unused4]", "[unused5]", "these", "programs", "[unused6]", "[SEP]", "[unused1]", "many", "Ward", "##law", "##-", "##H", "##art", "##ridge", "Students", "[unused2]", "[unused3]", "attend", "[unused4]", "[unused5]", "camp", "or", "classes", "over", "the", "summer", "[unused6]", "[SEP]"]]}

input 276:  {"source": "The Triple-A Baseball National Championship Game was established in 2006 .\n"}
prediction:  {"predictions": [[1, 1109, 9457, 28137, 1592, 5079, 1305, 1935, 3497, 2, 3, 1108, 1628, 4, 5, 1107, 1386, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0003076352586504072, -0.0005321502685546875, -0.0005292892456054688, -0.0005292892456054688, -0.0005292892456054688, -0.0005292892456054688, -0.0005292892456054688, -0.0005292892456054688, -0.0005292892456054688, -0.0005292892456054688], "metadata": {"source_tokens": ["The", "Triple", "##-", "##A", "Baseball", "National", "Championship", "Game", "was", "established", "in", "2006", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Triple", "##-", "##A", "Baseball", "National", "Championship", "Game", "[unused2]", "[unused3]", "was", "established", "[unused4]", "[unused5]", "in", "2006", "[unused6]", "[SEP]"]]}

input 277:  {"source": "The Venezuelan government required that all private television stations dedicate at least 25 % of their airtime to programs created by community groups , non-profits , and other independent producers .\n"}
prediction:  {"predictions": [[1, 1109, 16128, 1433, 2, 3, 2320, 4, 5, 1115, 1155, 2029, 1778, 2930, 1260, 12892, 1120, 1655, 1512, 110, 1104, 1147, 1586, 4974, 1106, 2648, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2648, 2, 3, 1687, 4, 5, 1118, 1661, 2114, 117, 1664, 28137, 1643, 2180, 14067, 1116, 117, 1105, 1168, 2457, 6419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1155, 2029, 1778, 2930, 2, 3, 1260, 12892, 4, 5, 1120, 1655, 1512, 110, 1104, 1147, 1586, 4974, 1106, 2648, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017184456810355186, -0.016810905188322067, -0.015821099281311035, -0.14989638328552246, -0.1244039535522461, -0.1244039535522461, -0.1244039535522461, -0.1244039535522461, -0.1244039535522461, -0.1244039535522461], "metadata": {"source_tokens": ["The", "Venezuelan", "government", "required", "that", "all", "private", "television", "stations", "de", "##dicate", "at", "least", "25", "%", "of", "their", "air", "##time", "to", "programs", "created", "by", "community", "groups", ",", "non", "##-", "##p", "##ro", "##fit", "##s", ",", "and", "other", "independent", "producers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Venezuelan", "government", "[unused2]", "[unused3]", "required", "[unused4]", "[unused5]", "that", "all", "private", "television", "stations", "de", "##dicate", "at", "least", "25", "%", "of", "their", "air", "##time", "to", "programs", "[unused6]", "[SEP]", "[unused1]", "programs", "[unused2]", "[unused3]", "created", "[unused4]", "[unused5]", "by", "community", "groups", ",", "non", "##-", "##p", "##ro", "##fit", "##s", ",", "and", "other", "independent", "producers", "[unused6]", "[SEP]", "[unused1]", "all", "private", "television", "stations", "[unused2]", "[unused3]", "de", "##dicate", "[unused4]", "[unused5]", "at", "least", "25", "%", "of", "their", "air", "##time", "to", "programs", "[unused6]", "[SEP]"]]}

input 278:  {"source": "The Wilbur Cross Highway formerly ended in Sturbridge ; locals sometimes call Haynes Street and portions of Mashapaug Road `` Old Route 15 '' .\n"}
prediction:  {"predictions": [[1, 1109, 160, 2723, 19364, 3156, 3580, 2, 3, 2207, 4, 5, 1107, 1457, 2149, 6152, 3147, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10953, 2, 3, 1840, 4, 5, 24098, 1715, 1105, 8924, 1104, 7085, 5480, 4163, 9610, 1914, 169, 28152, 2476, 3320, 1405, 2121, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02000146172940731, -0.018050184473395348, -0.02201700210571289, -0.022017955780029297, -0.022017955780029297, -0.022017955780029297, -0.022017955780029297, -0.022017955780029297, -0.022017955780029297, -0.022017955780029297], "metadata": {"source_tokens": ["The", "W", "##il", "##bur", "Cross", "Highway", "formerly", "ended", "in", "St", "##ur", "##bridge", ";", "locals", "sometimes", "call", "Haynes", "Street", "and", "portions", "of", "Ma", "##sha", "##pa", "##ug", "Road", "`", "##`", "Old", "Route", "15", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "W", "##il", "##bur", "Cross", "Highway", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "in", "St", "##ur", "##bridge", "formerly", "[unused6]", "[SEP]", "[unused1]", "locals", "[unused2]", "[unused3]", "call", "[unused4]", "[unused5]", "Haynes", "Street", "and", "portions", "of", "Ma", "##sha", "##pa", "##ug", "Road", "`", "##`", "Old", "Route", "15", "sometimes", "[unused6]", "[SEP]"]]}

input 279:  {"source": "The `` Charleston Courier , '' founded in 1803 , and `` Charleston Daily News , '' founded in 1865 , merged to form the `` News and Courier '' in 1873 .\n"}
prediction:  {"predictions": [[1, 1109, 169, 28152, 10874, 3291, 16706, 2, 3, 1771, 4, 5, 1107, 12838, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10874, 5732, 3128, 2, 3, 4564, 4, 5, 1106, 1532, 1103, 169, 28152, 3128, 1105, 3291, 16706, 112, 28131, 1107, 7110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0498523972928524, -0.07108631730079651, -0.14995026588439941, -0.1495821475982666, -0.1495821475982666, -0.1495821475982666, -0.1495821475982666, -0.1495821475982666, -0.1495821475982666, -0.1495821475982666], "metadata": {"source_tokens": ["The", "`", "##`", "Charleston", "Co", "##urier", ",", "'", "##'", "founded", "in", "1803", ",", "and", "`", "##`", "Charleston", "Daily", "News", ",", "'", "##'", "founded", "in", "1865", ",", "merged", "to", "form", "the", "`", "##`", "News", "and", "Co", "##urier", "'", "##'", "in", "1873", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "`", "##`", "Charleston", "Co", "##urier", "[unused2]", "[unused3]", "founded", "[unused4]", "[unused5]", "in", "1803", "[unused6]", "[SEP]", "[unused1]", "Charleston", "Daily", "News", "[unused2]", "[unused3]", "merged", "[unused4]", "[unused5]", "to", "form", "the", "`", "##`", "News", "and", "Co", "##urier", "'", "##'", "in", "1873", "[unused6]", "[SEP]"]]}

input 280:  {"source": "The album , produced by Roy Thomas Baker , was promoted with American and European tours .\n"}
prediction:  {"predictions": [[1, 1109, 1312, 2, 3, 1666, 4, 5, 1118, 5396, 1819, 5779, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1312, 117, 1666, 1118, 5396, 1819, 5779, 2, 3, 1108, 3082, 4, 5, 1114, 1237, 1105, 1735, 8398, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004555225372314453, -0.009794316254556179, -0.00042057037353515625, -0.00039196014404296875, -0.00039196014404296875, -0.00039196014404296875, -0.00039196014404296875, -0.00039196014404296875, -0.00039196014404296875, -0.00039196014404296875], "metadata": {"source_tokens": ["The", "album", ",", "produced", "by", "Roy", "Thomas", "Baker", ",", "was", "promoted", "with", "American", "and", "European", "tours", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "album", "[unused2]", "[unused3]", "produced", "[unused4]", "[unused5]", "by", "Roy", "Thomas", "Baker", "[unused6]", "[SEP]", "[unused1]", "The", "album", ",", "produced", "by", "Roy", "Thomas", "Baker", "[unused2]", "[unused3]", "was", "promoted", "[unused4]", "[unused5]", "with", "American", "and", "European", "tours", "[unused6]", "[SEP]"]]}

input 281:  {"source": "The band also confirmed that the album would be self-released .\n"}
prediction:  {"predictions": [[1, 1109, 1467, 2, 3, 3659, 4, 5, 1115, 1103, 1312, 1156, 1129, 2191, 28137, 9261, 23860, 1181, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0007403373601846397, -0.03854799270629883, -0.046282291412353516, -0.046282291412353516, -0.046282291412353516, -0.046282291412353516, -0.046282291412353516, -0.046282291412353516, -0.046282291412353516, -0.046282291412353516], "metadata": {"source_tokens": ["The", "band", "also", "confirmed", "that", "the", "album", "would", "be", "self", "##-", "##rel", "##ease", "##d", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "band", "[unused2]", "[unused3]", "confirmed", "[unused4]", "[unused5]", "that", "the", "album", "would", "be", "self", "##-", "##rel", "##ease", "##d", "[unused6]", "[SEP]"]]}

input 282:  {"source": "The canal was dammed off from the river for most of the construction period .\n"}
prediction:  {"predictions": [[1, 1109, 7684, 2, 3, 1108, 6961, 4611, 1228, 4, 5, 1121, 1103, 2186, 1111, 1211, 1104, 1103, 2058, 1669, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0010263703297823668, -0.0008649826049804688, -0.0009517669677734375, -0.0009517669677734375, -0.0009517669677734375, -0.0009517669677734375, -0.0009517669677734375, -0.0009517669677734375, -0.0009517669677734375, -0.0009517669677734375], "metadata": {"source_tokens": ["The", "canal", "was", "dam", "##med", "off", "from", "the", "river", "for", "most", "of", "the", "construction", "period", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "canal", "[unused2]", "[unused3]", "was", "dam", "##med", "off", "[unused4]", "[unused5]", "from", "the", "river", "for", "most", "of", "the", "construction", "period", "[unused6]", "[SEP]"]]}

input 283:  {"source": "The car used in `` Stealth '' was a band member 's car , and recorded just outside the studio in the parking lot .\n"}
prediction:  {"predictions": [[1, 1109, 1610, 2, 3, 1215, 4, 5, 1107, 169, 28152, 1457, 13003, 1582, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1610, 1215, 1107, 169, 28152, 1457, 13003, 1582, 112, 28131, 2, 3, 1108, 4, 5, 170, 1467, 1420, 112, 1116, 1610, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1610, 1215, 1107, 169, 28152, 1457, 13003, 1582, 112, 28131, 1108, 170, 1467, 1420, 112, 1116, 1610, 2, 3, 1802, 4, 5, 1198, 1796, 1103, 2362, 1107, 1103, 5030, 1974, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.052214086055755615, -0.02915644645690918, -0.06314112991094589, -0.07366156578063965, -0.07603573799133301, -0.07603573799133301, -0.07603573799133301, -0.07603573799133301, -0.07603573799133301, -0.07603573799133301], "metadata": {"source_tokens": ["The", "car", "used", "in", "`", "##`", "St", "##eal", "##th", "'", "##'", "was", "a", "band", "member", "'", "##s", "car", ",", "and", "recorded", "just", "outside", "the", "studio", "in", "the", "parking", "lot", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "car", "[unused2]", "[unused3]", "used", "[unused4]", "[unused5]", "in", "`", "##`", "St", "##eal", "##th", "[unused6]", "[SEP]", "[unused1]", "The", "car", "used", "in", "`", "##`", "St", "##eal", "##th", "'", "##'", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "a", "band", "member", "'", "##s", "car", "[unused6]", "[SEP]", "[unused1]", "The", "car", "used", "in", "`", "##`", "St", "##eal", "##th", "'", "##'", "was", "a", "band", "member", "'", "##s", "car", "[unused2]", "[unused3]", "recorded", "[unused4]", "[unused5]", "just", "outside", "the", "studio", "in", "the", "parking", "lot", "[unused6]", "[SEP]"]]}

input 284:  {"source": "The city was founded by the Western Town Lot Company in 1880 , and originally named Nordland , with the platted streets given Norwegian names .\n"}
prediction:  {"predictions": [[1, 1103, 185, 23524, 1174, 4324, 2, 3, 1549, 4, 5, 4236, 2666, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1331, 2, 3, 1108, 1771, 4, 5, 1118, 1103, 2102, 2779, 19804, 1881, 1107, 6148, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1331, 2, 3, 1417, 4, 5, 14782, 1931, 2034, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.032569337636232376, -0.007100795395672321, -0.0806913897395134, -0.2740976810455322, -0.2733410596847534, -0.2733410596847534, -0.2733410596847534, -0.2733410596847534, -0.2733410596847534, -0.2733410596847534], "metadata": {"source_tokens": ["The", "city", "was", "founded", "by", "the", "Western", "Town", "Lot", "Company", "in", "1880", ",", "and", "originally", "named", "Nord", "##land", ",", "with", "the", "p", "##latt", "##ed", "streets", "given", "Norwegian", "names", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "p", "##latt", "##ed", "streets", "[unused2]", "[unused3]", "given", "[unused4]", "[unused5]", "Norwegian", "names", "[unused6]", "[SEP]", "[unused1]", "The", "city", "[unused2]", "[unused3]", "was", "founded", "[unused4]", "[unused5]", "by", "the", "Western", "Town", "Lot", "Company", "in", "1880", "[unused6]", "[SEP]", "[unused1]", "The", "city", "[unused2]", "[unused3]", "named", "[unused4]", "[unused5]", "Nord", "##land", "originally", "[unused6]", "[SEP]"]]}

input 285:  {"source": "The closest Watson ever got was when Republicans had 12 seats in the State House in 2003 .\n"}
prediction:  {"predictions": [[1, 1109, 7064, 7422, 1400, 2, 3, 1108, 4, 5, 1165, 11115, 1125, 1367, 3474, 1107, 1103, 1426, 1585, 1107, 1581, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11115, 2, 3, 1125, 4, 5, 1367, 3474, 1107, 1103, 1426, 1585, 1107, 1581, 1165, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 7064, 2, 3, 1400, 4, 5, 1518, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04018115997314453, -0.051098305732011795, -0.09955570846796036, -0.022027015686035156, -0.022027015686035156, -0.022027015686035156, -0.022027015686035156, -0.022027015686035156, -0.022027015686035156, -0.022027015686035156], "metadata": {"source_tokens": ["The", "closest", "Watson", "ever", "got", "was", "when", "Republicans", "had", "12", "seats", "in", "the", "State", "House", "in", "2003", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "closest", "Watson", "got", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "when", "Republicans", "had", "12", "seats", "in", "the", "State", "House", "in", "2003", "[unused6]", "[SEP]", "[unused1]", "Republicans", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "12", "seats", "in", "the", "State", "House", "in", "2003", "when", "[unused6]", "[SEP]", "[unused1]", "The", "closest", "[unused2]", "[unused3]", "got", "[unused4]", "[unused5]", "ever", "[unused6]", "[SEP]"]]}

input 286:  {"source": "The community is served by the United States Postal Service Hinsdale Post Office .\n"}
prediction:  {"predictions": [[1, 1109, 1661, 2, 3, 1110, 1462, 4, 5, 1118, 1103, 1244, 1311, 20976, 2516, 8790, 2316, 4319, 3799, 3060, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.000133341018226929, -0.00017595291137695312, -0.00018453598022460938, -0.00018453598022460938, -0.00018453598022460938, -0.00018453598022460938, -0.00018453598022460938, -0.00018453598022460938, -0.00018453598022460938, -0.00018453598022460938], "metadata": {"source_tokens": ["The", "community", "is", "served", "by", "the", "United", "States", "Postal", "Service", "Hi", "##ns", "##dale", "Post", "Office", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "community", "[unused2]", "[unused3]", "is", "served", "[unused4]", "[unused5]", "by", "the", "United", "States", "Postal", "Service", "Hi", "##ns", "##dale", "Post", "Office", "[unused6]", "[SEP]"]]}

input 287:  {"source": "The dialects they speak are similar but have different intonations .\n"}
prediction:  {"predictions": [[1, 1109, 12336, 2, 3, 1132, 4, 5, 1861, 1133, 1138, 1472, 1154, 9199, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 12336, 2, 3, 2936, 4, 5, 1152, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05863167345523834, -0.04152989387512207, -0.0004553794860839844, -0.0004858970642089844, -0.0004858970642089844, -0.0004858970642089844, -0.0004858970642089844, -0.0004858970642089844, -0.0004858970642089844, -0.0004858970642089844], "metadata": {"source_tokens": ["The", "dialects", "they", "speak", "are", "similar", "but", "have", "different", "into", "##nation", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "dialects", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "similar", "but", "have", "different", "into", "##nation", "##s", "[unused6]", "[SEP]", "[unused1]", "The", "dialects", "[unused2]", "[unused3]", "speak", "[unused4]", "[unused5]", "they", "[unused6]", "[SEP]"]]}

input 288:  {"source": "The diocese was originally erected as the Prefecture Apostolic of Hpyeng-yang on 17 March 1927 , and renamed as the Prefecture Apostolic of Peng-yang on 17 March 1929 .\n"}
prediction:  {"predictions": [[1, 1109, 9856, 2, 3, 1108, 6517, 4, 5, 1112, 1103, 8197, 14220, 1104, 145, 5005, 14429, 28137, 13490, 1113, 1542, 1345, 3951, 2034, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 9856, 2, 3, 3286, 4, 5, 1112, 1103, 8197, 14220, 1104, 23544, 1403, 28137, 13490, 1113, 1542, 1345, 3762, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02428603544831276, -0.0186837799847126, -0.3471883535385132, -0.3473320007324219, -0.3473320007324219, -0.3473320007324219, -0.3473320007324219, -0.3473320007324219, -0.3473320007324219, -0.3473320007324219], "metadata": {"source_tokens": ["The", "diocese", "was", "originally", "erected", "as", "the", "Prefecture", "Apostolic", "of", "H", "##py", "##eng", "##-", "##yang", "on", "17", "March", "1927", ",", "and", "renamed", "as", "the", "Prefecture", "Apostolic", "of", "Pen", "##g", "##-", "##yang", "on", "17", "March", "1929", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "diocese", "[unused2]", "[unused3]", "was", "erected", "[unused4]", "[unused5]", "as", "the", "Prefecture", "Apostolic", "of", "H", "##py", "##eng", "##-", "##yang", "on", "17", "March", "1927", "originally", "[unused6]", "[SEP]", "[unused1]", "The", "diocese", "[unused2]", "[unused3]", "renamed", "[unused4]", "[unused5]", "as", "the", "Prefecture", "Apostolic", "of", "Pen", "##g", "##-", "##yang", "on", "17", "March", "1929", "[unused6]", "[SEP]"]]}

input 289:  {"source": "The economy of Ostrov is based on food , electronic , and textile industries .\n"}
prediction:  {"predictions": [[1, 1109, 4190, 1104, 152, 21216, 1964, 2, 3, 1110, 1359, 4, 5, 1113, 2094, 117, 4828, 117, 1105, 14817, 7519, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0004662897263187915, -0.00020647048950195312, -0.00021028518676757812, -0.00021028518676757812, -0.00021028518676757812, -0.00021028518676757812, -0.00021028518676757812, -0.00021028518676757812, -0.00021028518676757812, -0.00021028518676757812], "metadata": {"source_tokens": ["The", "economy", "of", "O", "##stro", "##v", "is", "based", "on", "food", ",", "electronic", ",", "and", "textile", "industries", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "economy", "of", "O", "##stro", "##v", "[unused2]", "[unused3]", "is", "based", "[unused4]", "[unused5]", "on", "food", ",", "electronic", ",", "and", "textile", "industries", "[unused6]", "[SEP]"]]}

input 290:  {"source": "The engine had twin turbochargers , and produced an advertised at 5700 rpm and of torque on 8 lbs of boost .\n"}
prediction:  {"predictions": [[1, 1109, 2395, 2, 3, 1125, 4, 5, 5930, 189, 2149, 4043, 7147, 26206, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2395, 2, 3, 1666, 4, 5, 1126, 18428, 1120, 28081, 1568, 14804, 1105, 1104, 18756, 1113, 129, 24119, 1104, 14112, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0022816378623247147, -0.0042641013860702515, -0.034004926681518555, -0.034418582916259766, -0.034418582916259766, -0.034418582916259766, -0.034418582916259766, -0.034418582916259766, -0.034418582916259766, -0.034418582916259766], "metadata": {"source_tokens": ["The", "engine", "had", "twin", "t", "##ur", "##bo", "##cha", "##rger", "##s", ",", "and", "produced", "an", "advertised", "at", "570", "##0", "rpm", "and", "of", "torque", "on", "8", "lbs", "of", "boost", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "engine", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "twin", "t", "##ur", "##bo", "##cha", "##rger", "##s", "[unused6]", "[SEP]", "[unused1]", "The", "engine", "[unused2]", "[unused3]", "produced", "[unused4]", "[unused5]", "an", "advertised", "at", "570", "##0", "rpm", "and", "of", "torque", "on", "8", "lbs", "of", "boost", "[unused6]", "[SEP]"]]}

input 291:  {"source": "The ensemble also has extensive recordings with Deutsche Grammophon , Dorian Recordings , Newport Classic , Navona Records , and under their own label .\n"}
prediction:  {"predictions": [[1, 1109, 9525, 2, 3, 1144, 4, 5, 4154, 5982, 1114, 12054, 19891, 3702, 21250, 117, 17130, 13111, 117, 9168, 6667, 117, 11896, 19988, 1161, 2151, 117, 1105, 1223, 1147, 1319, 3107, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006330348085612059, -0.03220105171203613, -0.03220868110656738, -0.03220868110656738, -0.03220868110656738, -0.03220868110656738, -0.03220868110656738, -0.03220868110656738, -0.03220868110656738, -0.03220868110656738], "metadata": {"source_tokens": ["The", "ensemble", "also", "has", "extensive", "recordings", "with", "Deutsche", "Gram", "##mo", "##phon", ",", "Dorian", "Recordings", ",", "Newport", "Classic", ",", "Na", "##von", "##a", "Records", ",", "and", "under", "their", "own", "label", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "ensemble", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "extensive", "recordings", "with", "Deutsche", "Gram", "##mo", "##phon", ",", "Dorian", "Recordings", ",", "Newport", "Classic", ",", "Na", "##von", "##a", "Records", ",", "and", "under", "their", "own", "label", "[unused6]", "[SEP]"]]}

input 292:  {"source": "The establishment of a museum had first been planned in 1821 by the Philosophical Society of Australasia , and although specimens were collected , the Society folded in 1822 .\n"}
prediction:  {"predictions": [[1, 1103, 2015, 2, 3, 6443, 4, 5, 1107, 12439, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9985, 2, 3, 1127, 4465, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4544, 1104, 170, 3480, 2, 3, 1125, 1151, 2919, 4, 5, 1107, 11749, 1118, 1103, 24515, 2015, 1104, 27758, 16468, 22992, 1148, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.046404678374528885, -0.03510328382253647, -0.006148067768663168, -0.0322113037109375, -0.03221869468688965, -0.03221869468688965, -0.03221869468688965, -0.03221869468688965, -0.03221869468688965, -0.03221869468688965], "metadata": {"source_tokens": ["The", "establishment", "of", "a", "museum", "had", "first", "been", "planned", "in", "1821", "by", "the", "Philosophical", "Society", "of", "Au", "##stra", "##lasia", ",", "and", "although", "specimens", "were", "collected", ",", "the", "Society", "folded", "in", "1822", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Society", "[unused2]", "[unused3]", "folded", "[unused4]", "[unused5]", "in", "1822", "[unused6]", "[SEP]", "[unused1]", "specimens", "[unused2]", "[unused3]", "were", "collected", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "The", "establishment", "of", "a", "museum", "[unused2]", "[unused3]", "had", "been", "planned", "[unused4]", "[unused5]", "in", "1821", "by", "the", "Philosophical", "Society", "of", "Au", "##stra", "##lasia", "first", "[unused6]", "[SEP]"]]}

input 293:  {"source": "The extension of the University Library can be found on the second floor , and parking for 120 cars on the third to sixth floors .\n"}
prediction:  {"predictions": [[1, 1109, 4973, 1104, 1103, 1239, 3371, 2, 3, 1169, 1129, 1276, 4, 5, 1113, 1103, 1248, 1837, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4973, 1104, 1103, 1239, 3371, 2, 3, 1169, 1129, 1276, 4, 5, 1113, 1103, 1248, 1837, 1105, 5030, 1111, 5356, 3079, 1113, 1103, 1503, 1106, 3971, 7849, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0032227516639977694, -0.034644898027181625, -0.07625555992126465, -0.07632589340209961, -0.07632589340209961, -0.07632589340209961, -0.07632589340209961, -0.07632589340209961, -0.07632589340209961, -0.07632589340209961], "metadata": {"source_tokens": ["The", "extension", "of", "the", "University", "Library", "can", "be", "found", "on", "the", "second", "floor", ",", "and", "parking", "for", "120", "cars", "on", "the", "third", "to", "sixth", "floors", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "extension", "of", "the", "University", "Library", "[unused2]", "[unused3]", "can", "be", "found", "[unused4]", "[unused5]", "on", "the", "second", "floor", "[unused6]", "[SEP]", "[unused1]", "The", "extension", "of", "the", "University", "Library", "[unused2]", "[unused3]", "can", "be", "found", "[unused4]", "[unused5]", "on", "the", "second", "floor", "and", "parking", "for", "120", "cars", "on", "the", "third", "to", "sixth", "floors", "[unused6]", "[SEP]"]]}

input 294:  {"source": "The external gauge is usually readable directly , and most also incorporate an electronic sender to operate a fuel gauge on the dashboard .\n"}
prediction:  {"predictions": [[1, 1109, 6298, 7405, 2, 3, 1110, 2626, 4, 5, 1932, 2373, 1895, 2626, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1211, 2, 3, 13639, 4, 5, 1126, 4828, 3952, 1200, 1106, 4732, 170, 4251, 7405, 1113, 1103, 16605, 4015, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06779316812753677, -0.02188284881412983, -0.21438491344451904, -0.25304079055786133, -0.25304079055786133, -0.25304079055786133, -0.25304079055786133, -0.25304079055786133, -0.25304079055786133, -0.25304079055786133], "metadata": {"source_tokens": ["The", "external", "gauge", "is", "usually", "read", "##able", "directly", ",", "and", "most", "also", "incorporate", "an", "electronic", "send", "##er", "to", "operate", "a", "fuel", "gauge", "on", "the", "dash", "##board", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "external", "gauge", "[unused2]", "[unused3]", "is", "directly", "[unused4]", "[unused5]", "usually", "read", "##able", "directly", "[unused6]", "[SEP]", "[unused1]", "most", "[unused2]", "[unused3]", "incorporate", "[unused4]", "[unused5]", "an", "electronic", "send", "##er", "to", "operate", "a", "fuel", "gauge", "on", "the", "dash", "##board", "[unused6]", "[SEP]"]]}

input 295:  {"source": "The failure of 1st Armored to arrive intact and deploy as a single entity would have important consequences in later action against German forces in Tunisia .\n"}
prediction:  {"predictions": [[1, 1109, 4290, 1104, 2198, 22665, 1106, 6657, 9964, 1105, 23660, 1112, 170, 1423, 9127, 2, 3, 1156, 1138, 4, 5, 1696, 8421, 1107, 1224, 2168, 1222, 1528, 2088, 1107, 13772, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4290, 1104, 2198, 22665, 2, 3, 1106, 23660, 4, 5, 1112, 170, 1423, 9127, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4290, 1104, 2198, 22665, 2, 3, 1106, 6657, 4, 5, 9964, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017025601118803024, -0.03611646592617035, -0.07907786220312119, -0.03222346305847168, -0.032239437103271484, -0.032239437103271484, -0.032239437103271484, -0.032239437103271484, -0.032239437103271484, -0.032239437103271484], "metadata": {"source_tokens": ["The", "failure", "of", "1st", "Armored", "to", "arrive", "intact", "and", "deploy", "as", "a", "single", "entity", "would", "have", "important", "consequences", "in", "later", "action", "against", "German", "forces", "in", "Tunisia", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "failure", "of", "1st", "Armored", "to", "arrive", "intact", "and", "deploy", "as", "a", "single", "entity", "[unused2]", "[unused3]", "would", "have", "[unused4]", "[unused5]", "important", "consequences", "in", "later", "action", "against", "German", "forces", "in", "Tunisia", "[unused6]", "[SEP]", "[unused1]", "The", "failure", "of", "1st", "Armored", "[unused2]", "[unused3]", "to", "deploy", "[unused4]", "[unused5]", "as", "a", "single", "entity", "[unused6]", "[SEP]", "[unused1]", "The", "failure", "of", "1st", "Armored", "[unused2]", "[unused3]", "to", "arrive", "[unused4]", "[unused5]", "intact", "[unused6]", "[SEP]"]]}

input 296:  {"source": "The field at the Lake Elsinore Diamond is named the Pete Lehr Field .\n"}
prediction:  {"predictions": [[1, 1109, 1768, 1120, 1103, 2161, 2896, 10606, 4474, 8549, 2, 3, 1110, 1417, 4, 5, 1103, 6377, 3180, 8167, 3479, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0003267474821768701, -0.0002765655517578125, -0.00028228759765625, -0.00028228759765625, -0.00028228759765625, -0.00028228759765625, -0.00028228759765625, -0.00028228759765625, -0.00028228759765625, -0.00028228759765625], "metadata": {"source_tokens": ["The", "field", "at", "the", "Lake", "El", "##sin", "##ore", "Diamond", "is", "named", "the", "Pete", "Le", "##hr", "Field", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "field", "at", "the", "Lake", "El", "##sin", "##ore", "Diamond", "[unused2]", "[unused3]", "is", "named", "[unused4]", "[unused5]", "the", "Pete", "Le", "##hr", "Field", "[unused6]", "[SEP]"]]}

input 297:  {"source": "The first comes from when Sweden 's Royal Couple lived there during the 1992 Barcelona Summer Olympics .\n"}
prediction:  {"predictions": [[1, 1109, 1148, 2, 3, 2502, 4, 5, 1121, 1165, 3865, 112, 1116, 1787, 3291, 4455, 1513, 2077, 1175, 1219, 1103, 1924, 7120, 2659, 2932, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3865, 112, 1116, 1787, 3291, 4455, 1513, 2, 3, 2077, 4, 5, 1175, 1219, 1103, 1924, 7120, 2659, 2932, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007992462255060673, -0.010179645381867886, -0.032207489013671875, -0.03220820426940918, -0.03220820426940918, -0.03220820426940918, -0.03220820426940918, -0.03220820426940918, -0.03220820426940918, -0.03220820426940918], "metadata": {"source_tokens": ["The", "first", "comes", "from", "when", "Sweden", "'", "##s", "Royal", "Co", "##up", "##le", "lived", "there", "during", "the", "1992", "Barcelona", "Summer", "Olympics", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "first", "[unused2]", "[unused3]", "comes", "[unused4]", "[unused5]", "from", "when", "Sweden", "'", "##s", "Royal", "Co", "##up", "##le", "lived", "there", "during", "the", "1992", "Barcelona", "Summer", "Olympics", "[unused6]", "[SEP]", "[unused1]", "Sweden", "'", "##s", "Royal", "Co", "##up", "##le", "[unused2]", "[unused3]", "lived", "[unused4]", "[unused5]", "there", "during", "the", "1992", "Barcelona", "Summer", "Olympics", "[unused6]", "[SEP]"]]}

input 298:  {"source": "The first five laps would be added to the second part of the race and the overall result would be decided on aggregate .\n"}
prediction:  {"predictions": [[1, 1109, 1148, 1421, 11033, 2, 3, 1156, 1129, 1896, 4, 5, 1106, 1103, 1248, 1226, 1104, 1103, 1886, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2905, 1871, 2, 3, 1156, 1129, 1879, 4, 5, 1113, 9453, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04144779592752457, -0.005481211934238672, -0.0013203620910644531, -0.0013189315795898438, -0.0013189315795898438, -0.0013189315795898438, -0.0013189315795898438, -0.0013189315795898438, -0.0013189315795898438, -0.0013189315795898438], "metadata": {"source_tokens": ["The", "first", "five", "laps", "would", "be", "added", "to", "the", "second", "part", "of", "the", "race", "and", "the", "overall", "result", "would", "be", "decided", "on", "aggregate", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "first", "five", "laps", "[unused2]", "[unused3]", "would", "be", "added", "[unused4]", "[unused5]", "to", "the", "second", "part", "of", "the", "race", "[unused6]", "[SEP]", "[unused1]", "the", "overall", "result", "[unused2]", "[unused3]", "would", "be", "decided", "[unused4]", "[unused5]", "on", "aggregate", "[unused6]", "[SEP]"]]}

input 299:  {"source": "The first library in Huntington Beach opened in 1909 and has since evolved to a five location library system : Central , Main Street , Oak View , Helen Murphy , and Banning .\n"}
prediction:  {"predictions": [[1, 1109, 1148, 3340, 1107, 17390, 3808, 2, 3, 1533, 4, 5, 1107, 4818, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1148, 3340, 1107, 17390, 3808, 2, 3, 1144, 7601, 4, 5, 1106, 170, 1421, 2450, 3340, 1449, 1290, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1148, 3340, 1107, 17390, 3808, 2, 3, 1144, 7601, 4, 5, 1106, 170, 1421, 2450, 3340, 1449, 1970, 4304, 1715, 8957, 10344, 5673, 6528, 1105, 18393, 3381, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.020404867827892303, -0.010286200791597366, -0.056136082857847214, -0.07650160789489746, -0.07650423049926758, -0.07650423049926758, -0.07650423049926758, -0.07650423049926758, -0.07650423049926758, -0.07650423049926758], "metadata": {"source_tokens": ["The", "first", "library", "in", "Huntington", "Beach", "opened", "in", "1909", "and", "has", "since", "evolved", "to", "a", "five", "location", "library", "system", ":", "Central", ",", "Main", "Street", ",", "Oak", "View", ",", "Helen", "Murphy", ",", "and", "Ban", "##ning", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "first", "library", "in", "Huntington", "Beach", "[unused2]", "[unused3]", "opened", "[unused4]", "[unused5]", "in", "1909", "[unused6]", "[SEP]", "[unused1]", "The", "first", "library", "in", "Huntington", "Beach", "[unused2]", "[unused3]", "has", "evolved", "[unused4]", "[unused5]", "to", "a", "five", "location", "library", "system", "since", "[unused6]", "[SEP]", "[unused1]", "The", "first", "library", "in", "Huntington", "Beach", "[unused2]", "[unused3]", "has", "evolved", "[unused4]", "[unused5]", "to", "a", "five", "location", "library", "system", "Central", "Main", "Street", "Oak", "View", "Helen", "Murphy", "and", "Ban", "##ning", "[unused6]", "[SEP]"]]}

input 300:  {"source": "The following tour featured extensive dates in East Asia , where the group played Tokyo , Osaka , Fukuoka , and Southeast Asia including Jakarta , Manila as well as Singapore and Guam .\n"}
prediction:  {"predictions": [[1, 1109, 1378, 2465, 2, 3, 2081, 4, 5, 4154, 4595, 1107, 1689, 3165, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1372, 2, 3, 1307, 4, 5, 4839, 117, 13586, 117, 14763, 4786, 9865, 117, 1105, 8348, 3165, 1259, 15032, 117, 9002, 1112, 1218, 1112, 4478, 1105, 17256, 1689, 3165, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013634026050567627, -0.06123751029372215, -0.21323108673095703, -0.261965274810791, -0.261965274810791, -0.261965274810791, -0.261965274810791, -0.261965274810791, -0.261965274810791, -0.261965274810791], "metadata": {"source_tokens": ["The", "following", "tour", "featured", "extensive", "dates", "in", "East", "Asia", ",", "where", "the", "group", "played", "Tokyo", ",", "Osaka", ",", "Fu", "##ku", "##oka", ",", "and", "Southeast", "Asia", "including", "Jakarta", ",", "Manila", "as", "well", "as", "Singapore", "and", "Guam", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "following", "tour", "[unused2]", "[unused3]", "featured", "[unused4]", "[unused5]", "extensive", "dates", "in", "East", "Asia", "[unused6]", "[SEP]", "[unused1]", "the", "group", "[unused2]", "[unused3]", "played", "[unused4]", "[unused5]", "Tokyo", ",", "Osaka", ",", "Fu", "##ku", "##oka", ",", "and", "Southeast", "Asia", "including", "Jakarta", ",", "Manila", "as", "well", "as", "Singapore", "and", "Guam", "East", "Asia", "[unused6]", "[SEP]"]]}

input 301:  {"source": "The founder had pledged himself to honour the Blessed Virgin in a special manner .\n"}
prediction:  {"predictions": [[1, 1109, 3249, 2, 3, 1125, 18215, 4, 5, 1471, 1106, 6565, 1103, 16850, 6567, 1107, 170, 1957, 4758, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.000465114921098575, -0.019016265869140625, -0.021883487701416016, -0.021883487701416016, -0.021883487701416016, -0.021883487701416016, -0.021883487701416016, -0.021883487701416016, -0.021883487701416016, -0.021883487701416016], "metadata": {"source_tokens": ["The", "founder", "had", "pledged", "himself", "to", "honour", "the", "Blessed", "Virgin", "in", "a", "special", "manner", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "founder", "[unused2]", "[unused3]", "had", "pledged", "[unused4]", "[unused5]", "himself", "to", "honour", "the", "Blessed", "Virgin", "in", "a", "special", "manner", "[unused6]", "[SEP]"]]}

input 302:  {"source": "The fundraiser was successful , and the trip occurred from June through September of 2014 .\n"}
prediction:  {"predictions": [[1, 1109, 5841, 27014, 2, 3, 1108, 4, 5, 2265, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3868, 2, 3, 3296, 4, 5, 1121, 1340, 1194, 1347, 1104, 1387, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03383262827992439, -0.00560992956161499, -0.004399299621582031, -0.006748676300048828, -0.006748676300048828, -0.006748676300048828, -0.006748676300048828, -0.006748676300048828, -0.006748676300048828, -0.006748676300048828], "metadata": {"source_tokens": ["The", "fund", "##raiser", "was", "successful", ",", "and", "the", "trip", "occurred", "from", "June", "through", "September", "of", "2014", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "fund", "##raiser", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "successful", "[unused6]", "[SEP]", "[unused1]", "the", "trip", "[unused2]", "[unused3]", "occurred", "[unused4]", "[unused5]", "from", "June", "through", "September", "of", "2014", "[unused6]", "[SEP]"]]}

input 303:  {"source": "The fuselage had an oval cross-section and housed a water-cooled inverted-V V-12 engine .\n"}
prediction:  {"predictions": [[1, 1109, 13959, 2, 3, 1125, 4, 5, 1126, 13102, 2771, 28137, 25461, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 13959, 2, 3, 6960, 4, 5, 170, 1447, 28137, 2528, 9016, 1181, 22996, 28137, 2559, 159, 28137, 11964, 2395, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.011319859884679317, -0.0016671315534040332, -0.0038881301879882812, -0.004195213317871094, -0.004195213317871094, -0.004195213317871094, -0.004195213317871094, -0.004195213317871094, -0.004195213317871094, -0.004195213317871094], "metadata": {"source_tokens": ["The", "fuselage", "had", "an", "oval", "cross", "##-", "##section", "and", "housed", "a", "water", "##-", "##co", "##ole", "##d", "inverted", "##-", "##V", "V", "##-", "##12", "engine", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "fuselage", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "an", "oval", "cross", "##-", "##section", "[unused6]", "[SEP]", "[unused1]", "The", "fuselage", "[unused2]", "[unused3]", "housed", "[unused4]", "[unused5]", "a", "water", "##-", "##co", "##ole", "##d", "inverted", "##-", "##V", "V", "##-", "##12", "engine", "[unused6]", "[SEP]"]]}

input 304:  {"source": "The gauge sender is usually a magnetically coupled arrangement , with a float arm inside the tank rotating a magnet , which rotates an external gauge .\n"}
prediction:  {"predictions": [[1, 1109, 7405, 3952, 1200, 2, 3, 1110, 4, 5, 1932, 170, 8364, 2716, 11646, 6204, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 15666, 1981, 1656, 1103, 4890, 2, 3, 14362, 4, 5, 170, 24197, 117, 1134, 27905, 1116, 1126, 6298, 7405, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.034997448325157166, -0.032776035368442535, -0.07659363746643066, -0.07660222053527832, -0.07660222053527832, -0.07660222053527832, -0.07660222053527832, -0.07660222053527832, -0.07660222053527832, -0.07660222053527832], "metadata": {"source_tokens": ["The", "gauge", "send", "##er", "is", "usually", "a", "magnetic", "##ally", "coupled", "arrangement", ",", "with", "a", "float", "arm", "inside", "the", "tank", "rotating", "a", "magnet", ",", "which", "rotate", "##s", "an", "external", "gauge", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "gauge", "send", "##er", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "usually", "a", "magnetic", "##ally", "coupled", "arrangement", "[unused6]", "[SEP]", "[unused1]", "a", "float", "arm", "inside", "the", "tank", "[unused2]", "[unused3]", "rotating", "[unused4]", "[unused5]", "a", "magnet", ",", "which", "rotate", "##s", "an", "external", "gauge", "[unused6]", "[SEP]"]]}

input 305:  {"source": "The insurer sponsored the golf tournament known as the New Orleans Open beginning in 1981 .\n"}
prediction:  {"predictions": [[1, 1109, 22233, 26616, 2, 3, 5988, 4, 5, 1103, 7135, 2348, 1227, 1112, 1103, 1203, 5705, 3353, 2150, 1107, 2358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 7135, 2348, 2, 3, 1227, 4, 5, 1112, 1103, 1203, 5705, 3353, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.002090329769998789, -0.0350104458630085, -0.021999835968017578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578], "metadata": {"source_tokens": ["The", "ins", "##urer", "sponsored", "the", "golf", "tournament", "known", "as", "the", "New", "Orleans", "Open", "beginning", "in", "1981", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "ins", "##urer", "[unused2]", "[unused3]", "sponsored", "[unused4]", "[unused5]", "the", "golf", "tournament", "known", "as", "the", "New", "Orleans", "Open", "beginning", "in", "1981", "[unused6]", "[SEP]", "[unused1]", "the", "golf", "tournament", "[unused2]", "[unused3]", "known", "[unused4]", "[unused5]", "as", "the", "New", "Orleans", "Open", "[unused6]", "[SEP]"]]}

input 306:  {"source": "The lodge is open from mid-May to mid-October , with two weeks starting in the end of August reserved for the Dartmouth First-Year Trips .\n"}
prediction:  {"predictions": [[1, 1109, 14433, 2, 3, 1110, 4, 5, 1501, 1121, 2286, 28137, 2107, 4164, 1106, 2286, 28137, 2346, 5822, 21367, 1197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1160, 2277, 2, 3, 2547, 4, 5, 1107, 1103, 1322, 1104, 1360, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1160, 2277, 2547, 1107, 1103, 1322, 1104, 1360, 2, 3, 9142, 4, 5, 1111, 1103, 18069, 1752, 28137, 3663, 19386, 18752, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02022162266075611, -0.046776048839092255, -0.04277433454990387, -0.2720605134963989, -0.28746986389160156, -0.28746986389160156, -0.28746986389160156, -0.28746986389160156, -0.28746986389160156, -0.28746986389160156], "metadata": {"source_tokens": ["The", "lodge", "is", "open", "from", "mid", "##-", "##M", "##ay", "to", "mid", "##-", "##O", "##ct", "##obe", "##r", ",", "with", "two", "weeks", "starting", "in", "the", "end", "of", "August", "reserved", "for", "the", "Dartmouth", "First", "##-", "##Y", "##ear", "Trip", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "lodge", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "open", "from", "mid", "##-", "##M", "##ay", "to", "mid", "##-", "##O", "##ct", "##obe", "##r", "[unused6]", "[SEP]", "[unused1]", "two", "weeks", "[unused2]", "[unused3]", "starting", "[unused4]", "[unused5]", "in", "the", "end", "of", "August", "[unused6]", "[SEP]", "[unused1]", "two", "weeks", "starting", "in", "the", "end", "of", "August", "[unused2]", "[unused3]", "reserved", "[unused4]", "[unused5]", "for", "the", "Dartmouth", "First", "##-", "##Y", "##ear", "Trip", "##s", "[unused6]", "[SEP]"]]}

input 307:  {"source": "The opening credits sequence for the collection was directed by Hanada Daizaburo .\n"}
prediction:  {"predictions": [[1, 1109, 2280, 6459, 4954, 1111, 1103, 2436, 2, 3, 1108, 2002, 4, 5, 1118, 7699, 7971, 23084, 3293, 19364, 1186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0001797468721633777, -0.00016498565673828125, -0.00016546249389648438, -0.00016546249389648438, -0.00016546249389648438, -0.00016546249389648438, -0.00016546249389648438, -0.00016546249389648438, -0.00016546249389648438, -0.00016546249389648438], "metadata": {"source_tokens": ["The", "opening", "credits", "sequence", "for", "the", "collection", "was", "directed", "by", "Han", "##ada", "Dai", "##za", "##bur", "##o", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "opening", "credits", "sequence", "for", "the", "collection", "[unused2]", "[unused3]", "was", "directed", "[unused4]", "[unused5]", "by", "Han", "##ada", "Dai", "##za", "##bur", "##o", "[unused6]", "[SEP]"]]}

input 308:  {"source": "The permanent members are the provost , the Carl H. Pforzheimer University Professor and the deans or designees from the following Schools : the Faculty of Arts and Sciences , Harvard Business School , Harvard Law School and Harvard Medical School .\n"}
prediction:  {"predictions": [[1, 1109, 4088, 1484, 2, 3, 1132, 4, 5, 1103, 5250, 22287, 1204, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4088, 1484, 2, 3, 1132, 4, 5, 1103, 5250, 22287, 1204, 1103, 4804, 145, 28138, 153, 14467, 11819, 19263, 1239, 2986, 1105, 1103, 14445, 1116, 1137, 1902, 8870, 1121, 1103, 1378, 5722, 1103, 6694, 1104, 2334, 1105, 4052, 5051, 3518, 1323, 5051, 2601, 1323, 1105, 5051, 3875, 1323, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03122829645872116, -0.02578166127204895, -0.32151317596435547, -0.2109079360961914, -0.2109079360961914, -0.2109079360961914, -0.2109079360961914, -0.2109079360961914, -0.2109079360961914, -0.2109079360961914], "metadata": {"source_tokens": ["The", "permanent", "members", "are", "the", "pro", "##vos", "##t", ",", "the", "Carl", "H", "##.", "P", "##fo", "##rz", "##heimer", "University", "Professor", "and", "the", "dean", "##s", "or", "design", "##ees", "from", "the", "following", "Schools", ":", "the", "Faculty", "of", "Arts", "and", "Sciences", ",", "Harvard", "Business", "School", ",", "Harvard", "Law", "School", "and", "Harvard", "Medical", "School", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "permanent", "members", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "the", "pro", "##vos", "##t", "[unused6]", "[SEP]", "[unused1]", "The", "permanent", "members", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "the", "pro", "##vos", "##t", "the", "Carl", "H", "##.", "P", "##fo", "##rz", "##heimer", "University", "Professor", "and", "the", "dean", "##s", "or", "design", "##ees", "from", "the", "following", "Schools", "the", "Faculty", "of", "Arts", "and", "Sciences", "Harvard", "Business", "School", "Harvard", "Law", "School", "and", "Harvard", "Medical", "School", "[SEP]"]]}

input 309:  {"source": "The pillars in a line on its both sides are according to Doric or Greek style and their decorations are according to the Meenakshi Temple at Madurai in Tamil Nadu .\n"}
prediction:  {"predictions": [[1, 1109, 15592, 1107, 170, 1413, 1113, 1157, 1241, 3091, 2, 3, 1132, 4, 5, 2452, 1106, 2091, 4907, 1137, 2414, 1947, 1105, 1147, 15707, 1132, 2452, 1106, 1103, 2508, 7076, 4616, 3031, 4407, 1120, 10779, 17319, 1107, 5344, 10657, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 15592, 1107, 170, 1413, 1113, 1157, 1241, 3091, 2, 3, 1132, 4, 5, 2452, 1106, 2091, 4907, 1137, 2414, 1947, 1105, 1147, 15707, 1132, 2452, 1106, 1103, 2508, 7076, 4616, 3031, 4407, 1120, 10779, 17319, 1107, 5344, 10657, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.025586746633052826, -0.26626384258270264, -0.06575566530227661, -0.03253674507141113, -0.03255486488342285, -0.03255486488342285, -0.03255486488342285, -0.03255486488342285, -0.03255486488342285, -0.03255486488342285], "metadata": {"source_tokens": ["The", "pillars", "in", "a", "line", "on", "its", "both", "sides", "are", "according", "to", "Do", "##ric", "or", "Greek", "style", "and", "their", "decorations", "are", "according", "to", "the", "Me", "##ena", "##ks", "##hi", "Temple", "at", "Mad", "##urai", "in", "Tamil", "Nadu", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "pillars", "in", "a", "line", "on", "its", "both", "sides", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "according", "to", "Do", "##ric", "or", "Greek", "style", "and", "their", "decorations", "are", "according", "to", "the", "Me", "##ena", "##ks", "##hi", "Temple", "at", "Mad", "##urai", "in", "Tamil", "Nadu", "[unused6]", "[SEP]"]]}

input 310:  {"source": "The race is in mixed eights , and usually held in late February / early March .\n"}
prediction:  {"predictions": [[1, 1109, 1886, 2, 3, 1110, 4, 5, 1107, 3216, 2022, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1886, 2, 3, 1316, 4, 5, 1107, 1523, 1428, 120, 1346, 1345, 1932, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0014861481031402946, -0.013302767649292946, -0.021993637084960938, -0.021993637084960938, -0.021993637084960938, -0.021993637084960938, -0.021993637084960938, -0.021993637084960938, -0.021993637084960938, -0.021993637084960938], "metadata": {"source_tokens": ["The", "race", "is", "in", "mixed", "eight", "##s", ",", "and", "usually", "held", "in", "late", "February", "/", "early", "March", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "race", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "in", "mixed", "eight", "##s", "[unused6]", "[SEP]", "[unused1]", "The", "race", "[unused2]", "[unused3]", "held", "[unused4]", "[unused5]", "in", "late", "February", "/", "early", "March", "usually", "[unused6]", "[SEP]"]]}

input 311:  {"source": "The rapids at the head of the South Fork were removed in 1908 .\n"}
prediction:  {"predictions": [[1, 1109, 6099, 1116, 1120, 1103, 1246, 1104, 1103, 1375, 16384, 2, 3, 1127, 2856, 4, 5, 1107, 4536, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00023656799749005586, -0.00022077560424804688, -0.00023508071899414062, -0.00023508071899414062, -0.00023508071899414062, -0.00023508071899414062, -0.00023508071899414062, -0.00023508071899414062, -0.00023508071899414062, -0.00023508071899414062], "metadata": {"source_tokens": ["The", "rapid", "##s", "at", "the", "head", "of", "the", "South", "Fork", "were", "removed", "in", "1908", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "rapid", "##s", "at", "the", "head", "of", "the", "South", "Fork", "[unused2]", "[unused3]", "were", "removed", "[unused4]", "[unused5]", "in", "1908", "[unused6]", "[SEP]"]]}

input 312:  {"source": "The redesigned 2006 Ram SRT-10 came in Mineral Gray Metallic , Inferno Red , and Brilliant Black Crystal Clear Coat .\n"}
prediction:  {"predictions": [[1, 1109, 18382, 1386, 11447, 5833, 1942, 28137, 10424, 2, 3, 1338, 4, 5, 1107, 9139, 4412, 4823, 9953, 8031, 117, 1130, 24215, 2156, 117, 1105, 139, 11071, 13789, 2117, 9048, 15458, 3291, 2980, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.003018129849806428, -0.022025108337402344, -0.02202749252319336, -0.02202749252319336, -0.02202749252319336, -0.02202749252319336, -0.02202749252319336, -0.02202749252319336, -0.02202749252319336, -0.02202749252319336], "metadata": {"source_tokens": ["The", "redesigned", "2006", "Ram", "SR", "##T", "##-", "##10", "came", "in", "Mine", "##ral", "Gray", "Metal", "##lic", ",", "In", "##ferno", "Red", ",", "and", "B", "##rill", "##iant", "Black", "Crystal", "Clear", "Co", "##at", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "redesigned", "2006", "Ram", "SR", "##T", "##-", "##10", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "in", "Mine", "##ral", "Gray", "Metal", "##lic", ",", "In", "##ferno", "Red", ",", "and", "B", "##rill", "##iant", "Black", "Crystal", "Clear", "Co", "##at", "[unused6]", "[SEP]"]]}

input 313:  {"source": "The residue can be reprocessed for more dripping and strained through a cheesecloth lined sieve as an ingredient for a fine beef stock .\n"}
prediction:  {"predictions": [[1, 1109, 24456, 2, 3, 1169, 1129, 1231, 1643, 2180, 22371, 1174, 4, 5, 1111, 1167, 15224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 24456, 2, 3, 12448, 4, 5, 1194, 170, 9553, 25940, 7265, 27466, 19907, 1112, 1126, 24799, 1111, 170, 2503, 14413, 4482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 24456, 2, 3, 12448, 4, 5, 1194, 170, 9553, 25940, 7265, 27466, 19907, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.020461583510041237, -0.015893206000328064, -0.10667598247528076, -0.15079259872436523, -0.15075969696044922, -0.15075969696044922, -0.15075969696044922, -0.15075969696044922, -0.15075969696044922, -0.15075969696044922], "metadata": {"source_tokens": ["The", "residue", "can", "be", "re", "##p", "##ro", "##cess", "##ed", "for", "more", "dripping", "and", "strained", "through", "a", "cheese", "##cloth", "lined", "si", "##eve", "as", "an", "ingredient", "for", "a", "fine", "beef", "stock", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "residue", "[unused2]", "[unused3]", "can", "be", "re", "##p", "##ro", "##cess", "##ed", "[unused4]", "[unused5]", "for", "more", "dripping", "[unused6]", "[SEP]", "[unused1]", "The", "residue", "[unused2]", "[unused3]", "strained", "[unused4]", "[unused5]", "through", "a", "cheese", "##cloth", "lined", "si", "##eve", "as", "an", "ingredient", "for", "a", "fine", "beef", "stock", "[unused6]", "[SEP]", "[unused1]", "The", "residue", "[unused2]", "[unused3]", "strained", "[unused4]", "[unused5]", "through", "a", "cheese", "##cloth", "lined", "si", "##eve", "[unused6]", "[SEP]"]]}

input 314:  {"source": "The rest of the group reach a small shop , where Brady attempts to phone the Sheriff , but the crocodile breaks through a wall and devours Annabelle .\n"}
prediction:  {"predictions": [[1, 1109, 1832, 1104, 1103, 1372, 2, 3, 2519, 4, 5, 170, 1353, 4130, 117, 1187, 10004, 4021, 1106, 2179, 1103, 8133, 117, 1133, 1103, 172, 24198, 7610, 1194, 170, 2095, 1105, 1260, 17532, 1116, 28016, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 172, 24198, 2, 3, 7610, 4, 5, 1194, 170, 2095, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 172, 24198, 2, 3, 1260, 17532, 1116, 4, 5, 28016, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10004, 2, 3, 4021, 4, 5, 1106, 2179, 1103, 8133, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04051027074456215, -0.11118783801794052, -0.06989715248346329, -0.06954130530357361, -0.03220701217651367, -0.03220725059509277, -0.03220725059509277, -0.03220725059509277, -0.03220725059509277, -0.03220725059509277], "metadata": {"source_tokens": ["The", "rest", "of", "the", "group", "reach", "a", "small", "shop", ",", "where", "Brady", "attempts", "to", "phone", "the", "Sheriff", ",", "but", "the", "c", "##rocodile", "breaks", "through", "a", "wall", "and", "de", "##vour", "##s", "Annabelle", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "rest", "of", "the", "group", "[unused2]", "[unused3]", "reach", "[unused4]", "[unused5]", "a", "small", "shop", ",", "where", "Brady", "attempts", "to", "phone", "the", "Sheriff", ",", "but", "the", "c", "##rocodile", "breaks", "through", "a", "wall", "and", "de", "##vour", "##s", "Annabelle", "[unused6]", "[SEP]", "[unused1]", "the", "c", "##rocodile", "[unused2]", "[unused3]", "breaks", "[unused4]", "[unused5]", "through", "a", "wall", "[unused6]", "[SEP]", "[unused1]", "the", "c", "##rocodile", "[unused2]", "[unused3]", "de", "##vour", "##s", "[unused4]", "[unused5]", "Annabelle", "[unused6]", "[SEP]", "[unused1]", "Brady", "[unused2]", "[unused3]", "attempts", "[unused4]", "[unused5]", "to", "phone", "the", "Sheriff", "[unused6]", "[SEP]"]]}

input 315:  {"source": "The restrictions against eating meat and drinking wine , besides reducing a person 's pleasure , recall the cessation of the `` Korban Tamid '' and the `` Nesach Hayayin '' on the Temple Altar with the destruction of the Temple .\n"}
prediction:  {"predictions": [[1, 1109, 9118, 1222, 5497, 6092, 1105, 5464, 4077, 117, 8655, 7914, 170, 1825, 112, 1116, 4687, 2, 3, 9148, 4, 5, 1103, 172, 5800, 1891, 1104, 1103, 169, 28152, 19892, 23092, 22876, 2386, 112, 28131, 1105, 1103, 169, 28152, 151, 1279, 7291, 16164, 4164, 1394, 112, 28131, 1113, 1103, 102, 1, 1109, 9118, 1222, 5497, 6092, 1105, 5464, 4077, 8655, 7914, 170, 1825, 112, 1116, 4687, 2, 3, 9148, 4, 5, 1103, 172, 5800, 1891, 1104, 1103, 19892, 23092, 22876, 2386, 1105, 1103, 151, 1279, 7291, 16164, 4164, 1394, 1113, 1103, 4407, 14983, 1813, 1114, 1103, 5915, 1104, 1103, 4407, 102, 1, 1109, 9118, 1222, 5497, 6092, 1105, 5464, 4077, 8655, 7914, 170, 1825, 112, 1116, 4687, 2, 3, 9148, 4, 5, 1103, 172, 5800, 1891, 1104, 1103, 19892, 23092, 22876, 2386, 1105, 1103, 151, 1279, 7291, 16164, 4164, 1394, 1113, 1103, 4407, 14983, 1813, 1114, 1103, 5915, 1104, 1103, 4407, 102, 1, 1109, 9118, 1222, 5497, 6092, 1105, 5464, 4077, 8655, 7914, 170, 1825, 112, 1116, 4687, 2, 3, 9148, 4, 5, 1103, 172, 5800, 1891, 1104, 1103, 19892, 23092, 22876, 2386, 1105, 1103, 151, 1279, 7291, 16164, 4164, 1394, 1113, 1103, 4407, 14983, 1813, 1114, 1103, 5915, 1104, 1103, 4407, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009633822366595268, -0.022286320105195045, -0.033073145896196365, -0.039403948932886124, -0.12498307228088379, -0.12458157539367676, -0.12458562850952148, -0.12458562850952148, -0.12458562850952148, -0.12458562850952148], "metadata": {"source_tokens": ["The", "restrictions", "against", "eating", "meat", "and", "drinking", "wine", ",", "besides", "reducing", "a", "person", "'", "##s", "pleasure", ",", "recall", "the", "c", "##ess", "##ation", "of", "the", "`", "##`", "Ko", "##rban", "Tam", "##id", "'", "##'", "and", "the", "`", "##`", "N", "##es", "##ach", "Hay", "##ay", "##in", "'", "##'", "on", "the", "Temple", "Alt", "##ar", "with", "the", "destruction", "of", "the", "Temple", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "restrictions", "against", "eating", "meat", "and", "drinking", "wine", ",", "besides", "reducing", "a", "person", "'", "##s", "pleasure", "[unused2]", "[unused3]", "recall", "[unused4]", "[unused5]", "the", "c", "##ess", "##ation", "of", "the", "`", "##`", "Ko", "##rban", "Tam", "##id", "'", "##'", "and", "the", "`", "##`", "N", "##es", "##ach", "Hay", "##ay", "##in", "'", "##'", "on", "the", "[SEP]", "[unused1]", "The", "restrictions", "against", "eating", "meat", "and", "drinking", "wine", "besides", "reducing", "a", "person", "'", "##s", "pleasure", "[unused2]", "[unused3]", "recall", "[unused4]", "[unused5]", "the", "c", "##ess", "##ation", "of", "the", "Ko", "##rban", "Tam", "##id", "and", "the", "N", "##es", "##ach", "Hay", "##ay", "##in", "on", "the", "Temple", "Alt", "##ar", "with", "the", "destruction", "of", "the", "Temple", "[SEP]", "[unused1]", "The", "restrictions", "against", "eating", "meat", "and", "drinking", "wine", "besides", "reducing", "a", "person", "'", "##s", "pleasure", "[unused2]", "[unused3]", "recall", "[unused4]", "[unused5]", "the", "c", "##ess", "##ation", "of", "the", "Ko", "##rban", "Tam", "##id", "and", "the", "N", "##es", "##ach", "Hay", "##ay", "##in", "on", "the", "Temple", "Alt", "##ar", "with", "the", "destruction", "of", "the", "Temple", "[SEP]", "[unused1]", "The", "restrictions", "against", "eating", "meat", "and", "drinking", "wine", "besides", "reducing", "a", "person", "'", "##s", "pleasure", "[unused2]", "[unused3]", "recall", "[unused4]", "[unused5]", "the", "c", "##ess", "##ation", "of", "the", "Ko", "##rban", "Tam", "##id", "and", "the", "N", "##es", "##ach", "Hay", "##ay", "##in", "on", "the", "Temple", "Alt", "##ar", "with", "the", "destruction", "of", "the", "Temple", "[SEP]"]]}

input 316:  {"source": "The riders climbed off and began walking , shouting protests in general and in particular abuse at the race doctor , Pierre Dumas , whom some demanded should also take a test to see if he 'd been drinking wine or taking aspirin to make his own job easier .\n"}
prediction:  {"predictions": [[1, 1109, 9958, 2, 3, 5998, 1228, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 9958, 2, 3, 1310, 4, 5, 3179, 117, 11500, 7853, 1107, 1704, 1105, 1107, 2440, 6704, 1120, 1103, 1886, 3995, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 112, 1181, 1151, 5464, 4077, 1137, 1781, 4, 5, 1112, 8508, 4854, 1106, 1294, 1117, 1319, 2261, 5477, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 9958, 2, 3, 1310, 4, 5, 3179, 11500, 7853, 1107, 1704, 1105, 1107, 2440, 6704, 1120, 1103, 1886, 3995, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 9958, 2, 3, 1310, 4, 5, 3179, 11500, 7853, 1107, 1704, 1105, 1107, 2440, 6704, 1120, 1103, 1886, 3995, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 9958, 2, 3, 1310, 4, 5, 3179, 11500, 7853, 1107, 1704, 1105, 1107, 2440, 6704, 1120, 1103, 1886, 3995, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 9958, 2, 3, 1310, 4, 5, 3179, 11500, 7853, 1107, 1704, 1105, 1107, 2440, 6704, 1120, 1103, 1886, 3995, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 9958, 2, 3, 1310, 4, 5, 3179, 11500, 7853, 1107, 1704, 1105, 1107, 2440, 6704, 1120, 1103, 1886, 3995, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 9958, 2, 3, 1310, 4, 5, 3179, 11500, 7853, 1107, 1704, 1105, 1107, 2440, 6704, 1120, 1103, 1886, 3995, 6, 102, 102, 1, 1109, 9958, 2, 3, 1310, 4, 5, 3179, 11500, 7853, 1107, 1704, 1105, 1107, 2440, 6704, 1120, 1103, 1886, 3995, 6, 102, 102]], "predicted_log_probs": [-0.1342790275812149, -0.11713778227567673, -0.07719362527132034, -0.13245268166065216, -0.13533058762550354, -0.14457184076309204, -0.14608030021190643, -0.14952519536018372, -0.1545914113521576, -0.17301590740680695], "metadata": {"source_tokens": ["The", "riders", "climbed", "off", "and", "began", "walking", ",", "shouting", "protests", "in", "general", "and", "in", "particular", "abuse", "at", "the", "race", "doctor", ",", "Pierre", "Du", "##mas", ",", "whom", "some", "demanded", "should", "also", "take", "a", "test", "to", "see", "if", "he", "'", "##d", "been", "drinking", "wine", "or", "taking", "as", "##pi", "##rin", "to", "make", "his", "own", "job", "easier", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "riders", "[unused2]", "[unused3]", "climbed", "off", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "The", "riders", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "walking", ",", "shouting", "protests", "in", "general", "and", "in", "particular", "abuse", "at", "the", "race", "doctor", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "'", "##d", "been", "drinking", "wine", "or", "taking", "[unused4]", "[unused5]", "as", "##pi", "##rin", "to", "make", "his", "own", "job", "easier", "[unused6]", "[SEP]", "[unused1]", "The", "riders", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "walking", "shouting", "protests", "in", "general", "and", "in", "particular", "abuse", "at", "the", "race", "doctor", "[unused6]", "[SEP]", "[unused1]", "The", "riders", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "walking", "shouting", "protests", "in", "general", "and", "in", "particular", "abuse", "at", "the", "race", "doctor", "[unused6]", "[SEP]", "[unused1]", "The", "riders", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "walking", "shouting", "protests", "in", "general", "and", "in", "particular", "abuse", "at", "the", "race", "doctor", "[unused6]", "[SEP]", "[unused1]", "The", "riders", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "walking", "shouting", "protests", "in", "general", "and", "in", "particular", "abuse", "at", "the", "race", "doctor", "[unused6]", "[SEP]", "[unused1]", "The", "riders", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "walking", "shouting", "protests", "in", "general", "and", "in", "particular", "abuse", "at", "the", "race", "doctor", "[unused6]", "[SEP]", "[unused1]", "The", "riders", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "walking", "shouting", "protests", "in", "general", "and", "in", "particular", "abuse", "at", "the", "race", "doctor", "[unused6]", "[SEP]", "[unused1]", "The", "riders", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "walking", "shouting", "protests", "in", "general", "and", "in", "particular", "abuse", "at", "the", "race", "doctor", "[unused6]", "[SEP]"]]}

input 317:  {"source": "The second was named after former US President George H. W. Bush stayed aboard in November 1995 .\n"}
prediction:  {"predictions": [[1, 1109, 1248, 2, 3, 1108, 1417, 4, 5, 1170, 1393, 1646, 1697, 1667, 145, 28138, 160, 28138, 6096, 3523, 7161, 1107, 1379, 1876, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1667, 145, 28138, 160, 28138, 6096, 2, 3, 1110, 1697, 1104, 4, 5, 1393, 1646, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1667, 145, 28138, 160, 28138, 6096, 2, 3, 1110, 1697, 1104, 4, 5, 1393, 1646, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1393, 1646, 1697, 1667, 145, 28138, 160, 28138, 6096, 2, 3, 3523, 4, 5, 7161, 1107, 1379, 1876, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0013626172440126538, -0.06596854329109192, -0.07096333056688309, -0.08007878065109253, -0.03546595573425293, -0.03470873832702637, -0.03470873832702637, -0.03470873832702637, -0.03470873832702637, -0.03470873832702637], "metadata": {"source_tokens": ["The", "second", "was", "named", "after", "former", "US", "President", "George", "H", "##.", "W", "##.", "Bush", "stayed", "aboard", "in", "November", "1995", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "second", "[unused2]", "[unused3]", "was", "named", "[unused4]", "[unused5]", "after", "former", "US", "President", "George", "H", "##.", "W", "##.", "Bush", "stayed", "aboard", "in", "November", "1995", "[unused6]", "[SEP]", "[unused1]", "George", "H", "##.", "W", "##.", "Bush", "[unused2]", "[unused3]", "is", "President", "of", "[unused4]", "[unused5]", "former", "US", "[unused6]", "[SEP]", "[unused1]", "George", "H", "##.", "W", "##.", "Bush", "[unused2]", "[unused3]", "is", "President", "of", "[unused4]", "[unused5]", "former", "US", "[unused6]", "[SEP]", "[unused1]", "former", "US", "President", "George", "H", "##.", "W", "##.", "Bush", "[unused2]", "[unused3]", "stayed", "[unused4]", "[unused5]", "aboard", "in", "November", "1995", "[unused6]", "[SEP]"]]}

input 318:  {"source": "The second was titled `` Consider Her Ways '' and also starred Barrie as the lead named Jane Waterleigh .\n"}
prediction:  {"predictions": [[1, 1103, 1730, 2, 3, 1417, 4, 5, 4074, 4434, 12185, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1248, 2, 3, 1108, 3334, 4, 5, 25515, 1430, 24058, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1248, 2, 3, 4950, 4, 5, 21715, 1663, 1112, 1103, 1730, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006065442226827145, -0.14672735333442688, -0.04431959614157677, -0.032222747802734375, -0.03252077102661133, -0.03252077102661133, -0.03252077102661133, -0.03252077102661133, -0.03252077102661133, -0.03252077102661133], "metadata": {"source_tokens": ["The", "second", "was", "titled", "`", "##`", "Consider", "Her", "Ways", "'", "##'", "and", "also", "starred", "Barr", "##ie", "as", "the", "lead", "named", "Jane", "Water", "##leigh", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "lead", "[unused2]", "[unused3]", "named", "[unused4]", "[unused5]", "Jane", "Water", "##leigh", "[unused6]", "[SEP]", "[unused1]", "The", "second", "[unused2]", "[unused3]", "was", "titled", "[unused4]", "[unused5]", "Consider", "Her", "Ways", "[unused6]", "[SEP]", "[unused1]", "The", "second", "[unused2]", "[unused3]", "starred", "[unused4]", "[unused5]", "Barr", "##ie", "as", "the", "lead", "[unused6]", "[SEP]"]]}

input 319:  {"source": "The series of three constitutional amendments in 1933 severely curtailed the role of the Governor-General of the Irish Free State .\n"}
prediction:  {"predictions": [[1, 1109, 1326, 1104, 1210, 7950, 19696, 1107, 3698, 2, 3, 8669, 16408, 16242, 11908, 4, 5, 1103, 1648, 1104, 1103, 2958, 28137, 2349, 24475, 1348, 1104, 1103, 2600, 4299, 1426, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00039814459159970284, -0.022015094757080078, -0.022015094757080078, -0.022015094757080078, -0.022015094757080078, -0.022015094757080078, -0.022015094757080078, -0.022015094757080078, -0.022015094757080078, -0.022015094757080078], "metadata": {"source_tokens": ["The", "series", "of", "three", "constitutional", "amendments", "in", "1933", "severely", "cu", "##rta", "##iled", "the", "role", "of", "the", "Governor", "##-", "##G", "##ener", "##al", "of", "the", "Irish", "Free", "State", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "series", "of", "three", "constitutional", "amendments", "in", "1933", "[unused2]", "[unused3]", "severely", "cu", "##rta", "##iled", "[unused4]", "[unused5]", "the", "role", "of", "the", "Governor", "##-", "##G", "##ener", "##al", "of", "the", "Irish", "Free", "State", "[unused6]", "[SEP]"]]}

input 320:  {"source": "The site consists of three subterranean Grotto follies , constructed in the 18th century , split between two areas , one on the western side of the lake , at and one on the eastern side at .\n"}
prediction:  {"predictions": [[1, 1109, 1751, 2, 3, 2923, 4, 5, 1104, 1210, 4841, 2083, 18194, 1389, 144, 10595, 2430, 175, 12666, 1905, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1210, 4841, 2083, 18194, 1389, 144, 10595, 2430, 175, 12666, 1905, 2, 3, 3033, 4, 5, 1107, 1103, 4186, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1751, 2, 3, 2923, 4, 5, 1104, 1210, 4841, 2083, 18194, 1389, 144, 10595, 2430, 175, 12666, 1905, 3325, 1206, 1160, 1877, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1751, 2, 3, 2923, 4, 5, 1104, 1210, 4841, 2083, 18194, 1389, 144, 10595, 2430, 175, 12666, 1905, 3325, 1206, 1160, 1877, 1141, 1113, 1103, 2466, 1334, 1104, 1103, 3521, 1120, 1105, 1141, 1113, 1103, 2638, 1334, 1120, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014782038517296314, -0.006563191767781973, -0.09139110147953033, -0.06468461453914642, -0.2650318145751953, -0.26583611965179443, -0.26583611965179443, -0.26583611965179443, -0.26583611965179443, -0.26583611965179443], "metadata": {"source_tokens": ["The", "site", "consists", "of", "three", "sub", "##ter", "##rane", "##an", "G", "##rot", "##to", "f", "##oll", "##ies", ",", "constructed", "in", "the", "18th", "century", ",", "split", "between", "two", "areas", ",", "one", "on", "the", "western", "side", "of", "the", "lake", ",", "at", "and", "one", "on", "the", "eastern", "side", "at", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "site", "[unused2]", "[unused3]", "consists", "[unused4]", "[unused5]", "of", "three", "sub", "##ter", "##rane", "##an", "G", "##rot", "##to", "f", "##oll", "##ies", "[unused6]", "[SEP]", "[unused1]", "three", "sub", "##ter", "##rane", "##an", "G", "##rot", "##to", "f", "##oll", "##ies", "[unused2]", "[unused3]", "constructed", "[unused4]", "[unused5]", "in", "the", "18th", "century", "[unused6]", "[SEP]", "[unused1]", "The", "site", "[unused2]", "[unused3]", "consists", "[unused4]", "[unused5]", "of", "three", "sub", "##ter", "##rane", "##an", "G", "##rot", "##to", "f", "##oll", "##ies", "split", "between", "two", "areas", "[unused6]", "[SEP]", "[unused1]", "The", "site", "[unused2]", "[unused3]", "consists", "[unused4]", "[unused5]", "of", "three", "sub", "##ter", "##rane", "##an", "G", "##rot", "##to", "f", "##oll", "##ies", "split", "between", "two", "areas", "one", "on", "the", "western", "side", "of", "the", "lake", "at", "and", "one", "on", "the", "eastern", "side", "at", "[unused6]", "[SEP]"]]}

input 321:  {"source": "The staff provides a family-style , home-cooked dinner every night , which is attended not only by Dartmouth students , but by community members , Appalachian Trail thru-hikers , tourists , and even Dartmouth professors .\n"}
prediction:  {"predictions": [[1, 1109, 2546, 2, 3, 2790, 4, 5, 170, 1266, 28137, 19994, 117, 1313, 28137, 2528, 27499, 4014, 1451, 1480, 117, 1134, 1110, 2323, 1136, 1178, 1118, 18069, 1651, 117, 1133, 1118, 1661, 1484, 117, 21464, 6938, 28137, 3031, 8811, 117, 9061, 117, 1105, 1256, 18069, 14427, 6, 102, 102, 102, 1, 170, 1266, 28137, 19994, 117, 1313, 28137, 2528, 27499, 4014, 1451, 1480, 2, 3, 1110, 2323, 4, 5, 1136, 1178, 1118, 18069, 1651, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03670329973101616, -0.07712487131357193, -0.14779448509216309, -0.1380784511566162, -0.1380784511566162, -0.1380784511566162, -0.1380784511566162, -0.1380784511566162, -0.1380784511566162, -0.1380784511566162], "metadata": {"source_tokens": ["The", "staff", "provides", "a", "family", "##-", "##style", ",", "home", "##-", "##co", "##oked", "dinner", "every", "night", ",", "which", "is", "attended", "not", "only", "by", "Dartmouth", "students", ",", "but", "by", "community", "members", ",", "Appalachian", "Trail", "th", "##ru", "##-", "##hi", "##kers", ",", "tourists", ",", "and", "even", "Dartmouth", "professors", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "staff", "[unused2]", "[unused3]", "provides", "[unused4]", "[unused5]", "a", "family", "##-", "##style", ",", "home", "##-", "##co", "##oked", "dinner", "every", "night", ",", "which", "is", "attended", "not", "only", "by", "Dartmouth", "students", ",", "but", "by", "community", "members", ",", "Appalachian", "Trail", "##-", "##hi", "##kers", ",", "tourists", ",", "and", "even", "Dartmouth", "professors", "[unused6]", "[SEP]", "[unused1]", "a", "family", "##-", "##style", ",", "home", "##-", "##co", "##oked", "dinner", "every", "night", "[unused2]", "[unused3]", "is", "attended", "[unused4]", "[unused5]", "not", "only", "by", "Dartmouth", "students", "[unused6]", "[SEP]"]]}

input 322:  {"source": "The station has a concourse and ticket office area which was internally redesigned and reopened in mid-2012 .\n"}
prediction:  {"predictions": [[1, 1109, 1466, 2, 3, 1144, 4, 5, 170, 14255, 16461, 1105, 7260, 1701, 1298, 1134, 1108, 19266, 18382, 1105, 11996, 1107, 2286, 28137, 10973, 11964, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 14255, 16461, 1105, 7260, 1701, 1298, 2, 3, 1108, 19266, 18382, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 14255, 16461, 1105, 7260, 1701, 1298, 2, 3, 11996, 4, 5, 1107, 2286, 28137, 10973, 11964, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0013655169168487191, -0.03886929526925087, -0.006820648908615112, -0.02201700210571289, -0.022064208984375, -0.022064208984375, -0.022064208984375, -0.022064208984375, -0.022064208984375, -0.022064208984375], "metadata": {"source_tokens": ["The", "station", "has", "a", "con", "##course", "and", "ticket", "office", "area", "which", "was", "internally", "redesigned", "and", "reopened", "in", "mid", "##-", "##20", "##12", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "station", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "a", "con", "##course", "and", "ticket", "office", "area", "which", "was", "internally", "redesigned", "and", "reopened", "in", "mid", "##-", "##20", "##12", "[unused6]", "[SEP]", "[unused1]", "a", "con", "##course", "and", "ticket", "office", "area", "[unused2]", "[unused3]", "was", "internally", "redesigned", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "a", "con", "##course", "and", "ticket", "office", "area", "[unused2]", "[unused3]", "reopened", "[unused4]", "[unused5]", "in", "mid", "##-", "##20", "##12", "[unused6]", "[SEP]"]]}

input 323:  {"source": "The stations were both called `` Midsomer Norton and Welton '' ; under British Railways , the S&D station was renamed as Midsomer Norton South after a short period as Midsomer Norton Upper ; and is currently being restored with occasional open weekends with engines in steam .\n"}
prediction:  {"predictions": [[1, 1103, 156, 28130, 2137, 1466, 2, 3, 1108, 3286, 4, 5, 1112, 9825, 11743, 1197, 10685, 1375, 1170, 170, 1603, 1669, 1112, 9825, 11743, 1197, 10685, 5454, 1223, 1418, 9058, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2930, 2, 3, 1127, 1270, 4, 5, 9825, 11743, 1197, 10685, 1105, 1284, 13464, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 156, 28130, 2137, 1466, 2, 3, 1110, 1217, 5219, 4, 5, 1114, 7957, 1501, 14464, 1114, 4540, 1107, 5543, 1971, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2930, 2, 3, 1127, 1270, 4, 5, 9825, 11743, 1197, 10685, 1105, 1284, 13464, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03555956855416298, -0.04438092187047005, -0.0832541361451149, -0.0855315625667572, -0.3148813247680664, -0.31548118591308594, -0.31548118591308594, -0.31548118591308594, -0.31548118591308594, -0.31548118591308594], "metadata": {"source_tokens": ["The", "stations", "were", "both", "called", "`", "##`", "Mid", "##some", "##r", "Norton", "and", "We", "##lton", "'", "##'", ";", "under", "British", "Railways", ",", "the", "S", "##&", "##D", "station", "was", "renamed", "as", "Mid", "##some", "##r", "Norton", "South", "after", "a", "short", "period", "as", "Mid", "##some", "##r", "Norton", "Upper", ";", "and", "is", "currently", "being", "restored", "with", "occasional", "open", "weekends", "with", "engines", "in", "steam", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "S", "##&", "##D", "station", "[unused2]", "[unused3]", "was", "renamed", "[unused4]", "[unused5]", "as", "Mid", "##some", "##r", "Norton", "South", "after", "a", "short", "period", "as", "Mid", "##some", "##r", "Norton", "Upper", "under", "British", "Railways", "[unused6]", "[SEP]", "[unused1]", "The", "stations", "[unused2]", "[unused3]", "were", "called", "[unused4]", "[unused5]", "Mid", "##some", "##r", "Norton", "and", "We", "##lton", "[unused6]", "[SEP]", "[unused1]", "the", "S", "##&", "##D", "station", "[unused2]", "[unused3]", "is", "being", "restored", "[unused4]", "[unused5]", "with", "occasional", "open", "weekends", "with", "engines", "in", "steam", "currently", "[unused6]", "[SEP]", "[unused1]", "The", "stations", "[unused2]", "[unused3]", "were", "called", "[unused4]", "[unused5]", "Mid", "##some", "##r", "Norton", "and", "We", "##lton", "[unused6]", "[SEP]"]]}

input 324:  {"source": "The stock pot should be chilled and the solid lump of dripping which settles when chilled should be scraped clean and re-chilled for future use .\n"}
prediction:  {"predictions": [[1, 1109, 4482, 9814, 2, 3, 1431, 1129, 27278, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4600, 16401, 1104, 15224, 2, 3, 7098, 1116, 4, 5, 1165, 27278, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4600, 16401, 1104, 15224, 2, 3, 1431, 1129, 22384, 4, 5, 4044, 1105, 1231, 28137, 4313, 11572, 1111, 2174, 1329, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012801124714314938, -0.11723324656486511, -0.08170191198587418, -0.03838491439819336, -0.03852128982543945, -0.03852128982543945, -0.03852128982543945, -0.03852128982543945, -0.03852128982543945, -0.03852128982543945], "metadata": {"source_tokens": ["The", "stock", "pot", "should", "be", "chilled", "and", "the", "solid", "lump", "of", "dripping", "which", "settle", "##s", "when", "chilled", "should", "be", "scraped", "clean", "and", "re", "##-", "##chi", "##lled", "for", "future", "use", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "stock", "pot", "[unused2]", "[unused3]", "should", "be", "chilled", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "the", "solid", "lump", "of", "dripping", "[unused2]", "[unused3]", "settle", "##s", "[unused4]", "[unused5]", "when", "chilled", "[unused6]", "[SEP]", "[unused1]", "the", "solid", "lump", "of", "dripping", "[unused2]", "[unused3]", "should", "be", "scraped", "[unused4]", "[unused5]", "clean", "and", "re", "##-", "##chi", "##lled", "for", "future", "use", "[unused6]", "[SEP]"]]}

input 325:  {"source": "The suit alleged that they conspired to fix prices for e-books , and weaken Amazon.com 's position in the market , in violation of antitrust law .\n"}
prediction:  {"predictions": [[1, 1109, 4228, 2, 3, 6351, 4, 5, 1115, 1152, 14255, 20080, 24599, 1106, 8239, 7352, 1111, 174, 28137, 16429, 117, 1105, 25772, 9786, 28138, 8178, 112, 1116, 1700, 1107, 1103, 2319, 117, 1107, 11574, 1104, 2848, 18062, 8954, 1644, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 14255, 20080, 24599, 4, 5, 1106, 8239, 7352, 1111, 174, 28137, 16429, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 14255, 20080, 24599, 1106, 25772, 4, 5, 9786, 28138, 8178, 112, 1116, 1700, 1107, 1103, 2319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 14255, 20080, 24599, 4, 5, 1106, 8239, 7352, 1111, 174, 28137, 16429, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004136801231652498, -0.07667891681194305, -0.09628080576658249, -0.13268190622329712, -0.3032190799713135, -0.34751057624816895, -0.34751057624816895, -0.34751057624816895, -0.34751057624816895, -0.34751057624816895], "metadata": {"source_tokens": ["The", "suit", "alleged", "that", "they", "con", "##sp", "##ired", "to", "fix", "prices", "for", "e", "##-", "##books", ",", "and", "weaken", "Amazon", "##.", "##com", "'", "##s", "position", "in", "the", "market", ",", "in", "violation", "of", "anti", "##tr", "##ust", "law", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "suit", "[unused2]", "[unused3]", "alleged", "[unused4]", "[unused5]", "that", "they", "con", "##sp", "##ired", "to", "fix", "prices", "for", "e", "##-", "##books", ",", "and", "weaken", "Amazon", "##.", "##com", "'", "##s", "position", "in", "the", "market", ",", "in", "violation", "of", "anti", "##tr", "##ust", "law", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "con", "##sp", "##ired", "[unused4]", "[unused5]", "to", "fix", "prices", "for", "e", "##-", "##books", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "con", "##sp", "##ired", "to", "weaken", "[unused4]", "[unused5]", "Amazon", "##.", "##com", "'", "##s", "position", "in", "the", "market", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "con", "##sp", "##ired", "[unused4]", "[unused5]", "to", "fix", "prices", "for", "e", "##-", "##books", "[unused6]", "[SEP]"]]}

input 326:  {"source": "The third known version is part number 2189014-00-212 , with at least one model being produced in February 1993 .\n"}
prediction:  {"predictions": [[1, 1120, 1655, 1141, 2235, 2, 3, 1217, 1666, 4, 5, 1107, 1428, 1949, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1503, 1227, 1683, 2, 3, 1110, 4, 5, 1226, 1295, 22723, 21500, 17175, 28137, 7629, 28137, 18202, 1477, 117, 1114, 1120, 1655, 1141, 2235, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.029062271118164062, -0.03740955516695976, -0.022002696990966797, -0.022011756896972656, -0.022011756896972656, -0.022011756896972656, -0.022011756896972656, -0.022011756896972656, -0.022011756896972656, -0.022011756896972656], "metadata": {"source_tokens": ["The", "third", "known", "version", "is", "part", "number", "218", "##90", "##14", "##-", "##00", "##-", "##21", "##2", ",", "with", "at", "least", "one", "model", "being", "produced", "in", "February", "1993", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "at", "least", "one", "model", "[unused2]", "[unused3]", "being", "produced", "[unused4]", "[unused5]", "in", "February", "1993", "[unused6]", "[SEP]", "[unused1]", "The", "third", "known", "version", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "part", "number", "218", "##90", "##14", "##-", "##00", "##-", "##21", "##2", ",", "with", "at", "least", "one", "model", "[unused6]", "[SEP]"]]}

input 327:  {"source": "The town was previously served by a station on the Somerset and Dorset Railway but this closed in 1966 , and by a second station on the Bristol and North Somerset Railway at Welton in the valley .\n"}
prediction:  {"predictions": [[1, 1109, 1411, 2, 3, 1108, 1462, 4, 5, 1118, 170, 1466, 1113, 1103, 8860, 1105, 16180, 2847, 2331, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1142, 2, 3, 1804, 4, 5, 1107, 2678, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1142, 2, 3, 1804, 4, 5, 1107, 2678, 1105, 1118, 170, 1248, 1466, 1113, 1103, 6490, 1105, 1456, 8860, 2847, 1120, 1284, 13464, 1107, 1103, 4524, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1142, 2, 3, 1804, 4, 5, 1107, 2678, 1105, 1118, 170, 1248, 1466, 1113, 1103, 6490, 1105, 1456, 8860, 2847, 1120, 1284, 13464, 1107, 1103, 4524, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.015625879168510437, -0.014713493175804615, -0.03612344712018967, -0.08030258119106293, -0.14948248863220215, -0.1505495309829712, -0.1505495309829712, -0.1505495309829712, -0.1505495309829712, -0.1505495309829712], "metadata": {"source_tokens": ["The", "town", "was", "previously", "served", "by", "a", "station", "on", "the", "Somerset", "and", "Dorset", "Railway", "but", "this", "closed", "in", "1966", ",", "and", "by", "a", "second", "station", "on", "the", "Bristol", "and", "North", "Somerset", "Railway", "at", "We", "##lton", "in", "the", "valley", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "town", "[unused2]", "[unused3]", "was", "served", "[unused4]", "[unused5]", "by", "a", "station", "on", "the", "Somerset", "and", "Dorset", "Railway", "previously", "[unused6]", "[SEP]", "[unused1]", "this", "[unused2]", "[unused3]", "closed", "[unused4]", "[unused5]", "in", "1966", "[unused6]", "[SEP]", "[unused1]", "this", "[unused2]", "[unused3]", "closed", "[unused4]", "[unused5]", "in", "1966", "and", "by", "a", "second", "station", "on", "the", "Bristol", "and", "North", "Somerset", "Railway", "at", "We", "##lton", "in", "the", "valley", "[unused6]", "[SEP]", "[unused1]", "this", "[unused2]", "[unused3]", "closed", "[unused4]", "[unused5]", "in", "1966", "and", "by", "a", "second", "station", "on", "the", "Bristol", "and", "North", "Somerset", "Railway", "at", "We", "##lton", "in", "the", "valley", "[unused6]", "[SEP]"]]}

input 328:  {"source": "The very large piers at the crossing signify that there was once a tower .\n"}
prediction:  {"predictions": [[1, 1109, 1304, 1415, 23747, 1120, 1103, 4905, 2, 3, 2951, 6120, 4, 5, 1115, 1175, 1108, 1517, 170, 3590, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0011796518228948116, -0.03854179382324219, -0.03854179382324219, -0.03854179382324219, -0.03854179382324219, -0.03854179382324219, -0.03854179382324219, -0.03854179382324219, -0.03854179382324219, -0.03854179382324219], "metadata": {"source_tokens": ["The", "very", "large", "piers", "at", "the", "crossing", "sign", "##ify", "that", "there", "was", "once", "a", "tower", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "very", "large", "piers", "at", "the", "crossing", "[unused2]", "[unused3]", "sign", "##ify", "[unused4]", "[unused5]", "that", "there", "was", "once", "a", "tower", "[unused6]", "[SEP]"]]}

input 329:  {"source": "The video was the first ever to feature the use of dialogue .\n"}
prediction:  {"predictions": [[1, 1109, 1888, 2, 3, 1108, 4, 5, 1103, 1148, 1518, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1888, 2, 3, 1108, 4, 5, 1103, 1148, 1106, 2672, 1103, 1329, 1104, 8556, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.011707672849297523, -0.04264835640788078, -0.0008440017700195312, -0.0009608268737792969, -0.0009608268737792969, -0.0009608268737792969, -0.0009608268737792969, -0.0009608268737792969, -0.0009608268737792969, -0.0009608268737792969], "metadata": {"source_tokens": ["The", "video", "was", "the", "first", "ever", "to", "feature", "the", "use", "of", "dialogue", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "video", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "first", "ever", "[unused6]", "[SEP]", "[unused1]", "The", "video", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "first", "to", "feature", "the", "use", "of", "dialogue", "[unused6]", "[SEP]"]]}

input 330:  {"source": "Their mission was always for a specific mandate and lasted for a limited period .\n"}
prediction:  {"predictions": [[1, 2397, 2862, 2, 3, 1108, 4, 5, 1579, 1111, 170, 2747, 13515, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2397, 2862, 2, 3, 5695, 4, 5, 1111, 170, 2609, 1669, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.016381867229938507, -0.003902409691363573, -0.018430233001708984, -0.021425724029541016, -0.021425724029541016, -0.021425724029541016, -0.021425724029541016, -0.021425724029541016, -0.021425724029541016, -0.021425724029541016], "metadata": {"source_tokens": ["Their", "mission", "was", "always", "for", "a", "specific", "mandate", "and", "lasted", "for", "a", "limited", "period", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Their", "mission", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "always", "for", "a", "specific", "mandate", "[unused6]", "[SEP]", "[unused1]", "Their", "mission", "[unused2]", "[unused3]", "lasted", "[unused4]", "[unused5]", "for", "a", "limited", "period", "[unused6]", "[SEP]"]]}

input 331:  {"source": "Their numbers continued to increase each year as rumours about immigration restrictions appeared in much of the Cypriot media .\n"}
prediction:  {"predictions": [[1, 2397, 2849, 2, 3, 1598, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 23620, 1164, 9027, 9118, 2, 3, 1691, 4, 5, 1107, 1277, 1104, 1103, 20036, 2394, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2397, 2849, 2, 3, 1106, 2773, 4, 5, 1296, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.112762451171875, -0.027520451694726944, -0.017889242619276047, -0.03220248222351074, -0.03220248222351074, -0.03220248222351074, -0.03220248222351074, -0.03220248222351074, -0.03220248222351074, -0.03220248222351074], "metadata": {"source_tokens": ["Their", "numbers", "continued", "to", "increase", "each", "year", "as", "rumours", "about", "immigration", "restrictions", "appeared", "in", "much", "of", "the", "Cypriot", "media", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Their", "numbers", "[unused2]", "[unused3]", "continued", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "rumours", "about", "immigration", "restrictions", "[unused2]", "[unused3]", "appeared", "[unused4]", "[unused5]", "in", "much", "of", "the", "Cypriot", "media", "[unused6]", "[SEP]", "[unused1]", "Their", "numbers", "[unused2]", "[unused3]", "to", "increase", "[unused4]", "[unused5]", "each", "year", "[unused6]", "[SEP]"]]}

input 332:  {"source": "Then the fillets are put in a mix of olive oil , vinegar , sugar , garlic , chill peppers , and lots of parsley or celery .\n"}
prediction:  {"predictions": [[1, 1103, 5475, 6248, 2, 3, 1132, 1508, 4, 5, 1107, 170, 5495, 1104, 13552, 2949, 117, 23230, 5526, 117, 6656, 117, 24861, 117, 11824, 18700, 1116, 117, 1105, 7424, 1104, 14247, 8980, 1137, 172, 11194, 1616, 1599, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01192043162882328, -0.03220701217651367, -0.03220653533935547, -0.03220653533935547, -0.03220653533935547, -0.03220653533935547, -0.03220653533935547, -0.03220653533935547, -0.03220653533935547, -0.03220653533935547], "metadata": {"source_tokens": ["Then", "the", "fill", "##ets", "are", "put", "in", "a", "mix", "of", "olive", "oil", ",", "vine", "##gar", ",", "sugar", ",", "garlic", ",", "chill", "pepper", "##s", ",", "and", "lots", "of", "par", "##sley", "or", "c", "##ele", "##ry", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "fill", "##ets", "[unused2]", "[unused3]", "are", "put", "[unused4]", "[unused5]", "in", "a", "mix", "of", "olive", "oil", ",", "vine", "##gar", ",", "sugar", ",", "garlic", ",", "chill", "pepper", "##s", ",", "and", "lots", "of", "par", "##sley", "or", "c", "##ele", "##ry", "Then", "[unused6]", "[SEP]"]]}

input 333:  {"source": "There have been two crashes involving fatalities at the airfield since it was established .\n"}
prediction:  {"predictions": [[1, 1160, 21110, 2, 3, 5336, 4, 5, 23515, 1120, 1103, 11897, 1290, 1122, 1108, 1628, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 1628, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.016639867797493935, -0.06266407668590546, -0.024443626403808594, -0.024142742156982422, -0.024142742156982422, -0.024142742156982422, -0.024142742156982422, -0.024142742156982422, -0.024142742156982422, -0.024142742156982422], "metadata": {"source_tokens": ["There", "have", "been", "two", "crashes", "involving", "fatalities", "at", "the", "airfield", "since", "it", "was", "established", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "two", "crashes", "[unused2]", "[unused3]", "involving", "[unused4]", "[unused5]", "fatalities", "at", "the", "airfield", "since", "it", "was", "established", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "established", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 334:  {"source": "There used to be a Youth Hostel but it closed in October 2008 and the building has since reopened as Keld Lodge , a hotel with bar and restaurant .\n"}
prediction:  {"predictions": [[1, 1103, 1459, 2, 3, 1144, 11996, 4, 5, 1112, 26835, 5253, 9262, 1290, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 26835, 5253, 9262, 2, 3, 1110, 4, 5, 170, 3415, 1114, 2927, 1105, 4382, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1804, 4, 5, 1107, 1357, 1369, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.052043356001377106, -0.04399638995528221, -0.04028673842549324, -0.12043046951293945, -0.11019682884216309, -0.11019682884216309, -0.11019682884216309, -0.11019682884216309, -0.11019682884216309, -0.11019682884216309], "metadata": {"source_tokens": ["There", "used", "to", "be", "a", "Youth", "Host", "##el", "but", "it", "closed", "in", "October", "2008", "and", "the", "building", "has", "since", "reopened", "as", "Ke", "##ld", "Lodge", ",", "a", "hotel", "with", "bar", "and", "restaurant", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "building", "[unused2]", "[unused3]", "has", "reopened", "[unused4]", "[unused5]", "as", "Ke", "##ld", "Lodge", "since", "[unused6]", "[SEP]", "[unused1]", "Ke", "##ld", "Lodge", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "hotel", "with", "bar", "and", "restaurant", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "closed", "[unused4]", "[unused5]", "in", "October", "2008", "[unused6]", "[SEP]"]]}

input 335:  {"source": "There were 143 households out of which 30.1 % had children under the age of 18 living with them , 49.7 % were married couples living together , 11.9 % had a female householder with no husband present , and 36.4 % were non-families .\n"}
prediction:  {"predictions": [[1, 3164, 28138, 1527, 110, 2, 3, 1127, 4, 5, 1664, 28137, 8057, 3080, 7875, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1429, 28138, 1580, 110, 2, 3, 1125, 4, 5, 170, 2130, 7036, 1114, 1185, 2252, 1675, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3927, 28138, 1559, 110, 2, 3, 1127, 4, 5, 1597, 5509, 1690, 1487, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1476, 28138, 1475, 110, 2, 3, 1125, 4, 5, 1482, 1223, 1103, 1425, 1104, 1407, 1690, 1114, 1172, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 17025, 3065, 1149, 1104, 1134, 1476, 28138, 1475, 110, 1125, 1482, 1223, 1103, 1425, 1104, 1407, 1690, 1114, 1172, 2, 3, 1247, 1127, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023936577141284943, -0.0389229953289032, -0.12504860758781433, -0.14079754054546356, -0.14799129962921143, -0.27041351795196533, -0.27127039432525635, -0.27127039432525635, -0.27127039432525635, -0.27127039432525635], "metadata": {"source_tokens": ["There", "were", "143", "households", "out", "of", "which", "30", "##.", "##1", "%", "had", "children", "under", "the", "age", "of", "18", "living", "with", "them", ",", "49", "##.", "##7", "%", "were", "married", "couples", "living", "together", ",", "11", "##.", "##9", "%", "had", "a", "female", "householder", "with", "no", "husband", "present", ",", "and", "36", "##.", "##4", "%", "were", "non", "##-", "##fa", "##mi", "##lies", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "36", "##.", "##4", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "non", "##-", "##fa", "##mi", "##lies", "[unused6]", "[SEP]", "[unused1]", "11", "##.", "##9", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "female", "householder", "with", "no", "husband", "present", "[unused6]", "[SEP]", "[unused1]", "49", "##.", "##7", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "married", "couples", "living", "together", "[unused6]", "[SEP]", "[unused1]", "30", "##.", "##1", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "children", "under", "the", "age", "of", "18", "living", "with", "them", "[unused6]", "[SEP]", "[unused1]", "143", "households", "out", "of", "which", "30", "##.", "##1", "%", "had", "children", "under", "the", "age", "of", "18", "living", "with", "them", "[unused2]", "[unused3]", "There", "were", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 336:  {"source": "There were 47,604 households out of which 35.00 % had children under the age of 18 living with them , 56.30 % were married couples living together , 7.50 % had a female householder with no husband present , and 32.50 % were non-families .\n"}
prediction:  {"predictions": [[1, 2724, 28138, 11049, 110, 2, 3, 1127, 4, 5, 1664, 28137, 8057, 3080, 7875, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 128, 28138, 11049, 110, 2, 3, 1125, 4, 5, 170, 2130, 7036, 1114, 1185, 2252, 1675, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4376, 28138, 13144, 110, 2, 3, 1125, 4, 5, 1597, 5509, 1690, 1487, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2588, 28138, 7629, 110, 2, 3, 1125, 4, 5, 1482, 1223, 1103, 1425, 1104, 1407, 1690, 1114, 1172, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3862, 28136, 16480, 1527, 3065, 1149, 1104, 1134, 2588, 28138, 7629, 110, 1125, 1482, 1223, 1103, 1425, 1104, 1407, 1690, 1114, 1172, 2, 3, 1247, 1127, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 128, 28138, 11049, 110, 2, 3, 1125, 4, 5, 170, 2130, 7036, 1114, 1185, 2252, 1675, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.035432253032922745, -0.04354477673768997, -0.15925593674182892, -0.12468515336513519, -0.14774075150489807, -0.14075477421283722, -0.213057279586792, -0.2130732536315918, -0.2130732536315918, -0.2130732536315918], "metadata": {"source_tokens": ["There", "were", "47", "##,", "##60", "##4", "households", "out", "of", "which", "35", "##.", "##00", "%", "had", "children", "under", "the", "age", "of", "18", "living", "with", "them", ",", "56", "##.", "##30", "%", "were", "married", "couples", "living", "together", ",", "7", "##.", "##50", "%", "had", "a", "female", "householder", "with", "no", "husband", "present", ",", "and", "32", "##.", "##50", "%", "were", "non", "##-", "##fa", "##mi", "##lies", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "32", "##.", "##50", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "non", "##-", "##fa", "##mi", "##lies", "[unused6]", "[SEP]", "[unused1]", "7", "##.", "##50", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "female", "householder", "with", "no", "husband", "present", "[unused6]", "[SEP]", "[unused1]", "56", "##.", "##30", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "married", "couples", "living", "together", "[unused6]", "[SEP]", "[unused1]", "35", "##.", "##00", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "children", "under", "the", "age", "of", "18", "living", "with", "them", "[unused6]", "[SEP]", "[unused1]", "47", "##,", "##60", "##4", "households", "out", "of", "which", "35", "##.", "##00", "%", "had", "children", "under", "the", "age", "of", "18", "living", "with", "them", "[unused2]", "[unused3]", "There", "were", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "7", "##.", "##50", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "female", "householder", "with", "no", "husband", "present", "[unused6]", "[SEP]"]]}

input 337:  {"source": "There were 6,524 households out of which 35.3 % had children under the age of 18 living with them , 31.7 % were married couples living together , 31.5 % had a female householder with no husband present , and 30.6 % were non-families .\n"}
prediction:  {"predictions": [[1, 1476, 28138, 1545, 110, 2, 3, 1127, 4, 5, 1664, 28137, 8057, 3080, 7875, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1955, 28138, 1571, 110, 2, 3, 1125, 4, 5, 170, 2130, 7036, 1114, 1185, 2252, 1675, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1955, 28138, 1559, 110, 2, 3, 1127, 4, 5, 1597, 5509, 1690, 1487, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2588, 28138, 1495, 110, 2, 3, 1125, 4, 5, 1482, 1223, 1103, 1425, 1104, 1407, 1690, 1114, 1172, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1955, 28138, 1571, 110, 2, 3, 1125, 4, 5, 170, 2130, 7036, 1114, 1185, 2252, 1675, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1955, 28138, 1571, 110, 2, 3, 1125, 4, 5, 170, 2130, 7036, 1114, 1185, 2252, 1675, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03649730980396271, -0.027715757489204407, -0.12157343327999115, -0.118934266269207, -0.11247739940881729, -0.11899878084659576, -0.2124863862991333, -0.2125239372253418, -0.2125239372253418, -0.2125239372253418], "metadata": {"source_tokens": ["There", "were", "6", "##,", "##5", "##24", "households", "out", "of", "which", "35", "##.", "##3", "%", "had", "children", "under", "the", "age", "of", "18", "living", "with", "them", ",", "31", "##.", "##7", "%", "were", "married", "couples", "living", "together", ",", "31", "##.", "##5", "%", "had", "a", "female", "householder", "with", "no", "husband", "present", ",", "and", "30", "##.", "##6", "%", "were", "non", "##-", "##fa", "##mi", "##lies", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "30", "##.", "##6", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "non", "##-", "##fa", "##mi", "##lies", "[unused6]", "[SEP]", "[unused1]", "31", "##.", "##5", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "female", "householder", "with", "no", "husband", "present", "[unused6]", "[SEP]", "[unused1]", "31", "##.", "##7", "%", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "married", "couples", "living", "together", "[unused6]", "[SEP]", "[unused1]", "35", "##.", "##3", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "children", "under", "the", "age", "of", "18", "living", "with", "them", "[unused6]", "[SEP]", "[unused1]", "31", "##.", "##5", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "female", "householder", "with", "no", "husband", "present", "[unused6]", "[SEP]", "[unused1]", "31", "##.", "##5", "%", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "female", "householder", "with", "no", "husband", "present", "[unused6]", "[SEP]"]]}

input 338:  {"source": "These and other attempts supplied a bridge between the literature of the two languages .\n"}
prediction:  {"predictions": [[1, 1636, 1105, 1168, 4021, 2, 3, 7694, 4, 5, 170, 2738, 1206, 1103, 3783, 1104, 1103, 1160, 3483, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00029473076574504375, -0.00018358230590820312, -0.00018262863159179688, -0.00018262863159179688, -0.00018262863159179688, -0.00018262863159179688, -0.00018262863159179688, -0.00018262863159179688, -0.00018262863159179688, -0.00018262863159179688], "metadata": {"source_tokens": ["These", "and", "other", "attempts", "supplied", "a", "bridge", "between", "the", "literature", "of", "the", "two", "languages", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "These", "and", "other", "attempts", "[unused2]", "[unused3]", "supplied", "[unused4]", "[unused5]", "a", "bridge", "between", "the", "literature", "of", "the", "two", "languages", "[unused6]", "[SEP]"]]}

input 339:  {"source": "These are visually very similar to part number 2189014-00-211 , with the same AT style plug and chassis , silver label on the reverse bearing the AnyKey moniker , screws holding the keyboard together , macro programming requiring the control key , and lacking the AnyKey inscription on their face .\n"}
prediction:  {"predictions": [[1, 1103, 7936, 2, 3, 7343, 4, 5, 1103, 6291, 2428, 2254, 24395, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1636, 2, 3, 1132, 4, 5, 19924, 1304, 1861, 1106, 1226, 1295, 22723, 21500, 17175, 28137, 7629, 28137, 18202, 1475, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 23639, 2180, 4159, 2, 3, 8753, 4, 5, 1103, 1654, 2501, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1269, 13020, 1947, 15244, 1105, 12291, 2, 3, 13084, 1116, 2355, 4, 5, 1103, 9303, 1487, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1636, 2, 3, 1132, 4, 5, 1861, 1114, 1103, 1269, 13020, 1947, 15244, 1105, 12291, 2878, 3107, 1113, 1103, 7936, 7343, 1103, 6291, 2428, 2254, 24395, 13084, 1116, 2355, 1103, 9303, 1487, 23639, 2180, 4159, 8753, 1103, 1654, 2501, 1105, 11744, 1103, 6291, 2428, 2254, 9237, 1113, 1147, 1339, 102, 1, 1636, 2, 3, 1132, 4, 5, 1861, 1114, 1103, 1269, 13020, 1947, 15244, 1105, 12291, 2878, 3107, 1113, 1103, 7936, 7343, 1103, 6291, 2428, 2254, 24395, 13084, 1116, 2355, 1103, 9303, 1487, 23639, 2180, 4159, 8753, 1103, 1654, 2501, 1105, 11744, 1103, 6291, 2428, 2254, 9237, 1113, 1147, 1339, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07246573269367218, -0.06923817843198776, -0.08843737095594406, -0.09405864775180817, -0.07710915803909302, -0.09184735268354416, -0.25986719131469727, -0.2485058307647705, -0.2485058307647705, -0.2485058307647705], "metadata": {"source_tokens": ["These", "are", "visually", "very", "similar", "to", "part", "number", "218", "##90", "##14", "##-", "##00", "##-", "##21", "##1", ",", "with", "the", "same", "AT", "style", "plug", "and", "chassis", ",", "silver", "label", "on", "the", "reverse", "bearing", "the", "Any", "##K", "##ey", "moniker", ",", "screw", "##s", "holding", "the", "keyboard", "together", ",", "mac", "##ro", "programming", "requiring", "the", "control", "key", ",", "and", "lacking", "the", "Any", "##K", "##ey", "inscription", "on", "their", "face", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "reverse", "[unused2]", "[unused3]", "bearing", "[unused4]", "[unused5]", "the", "Any", "##K", "##ey", "moniker", "[unused6]", "[SEP]", "[unused1]", "These", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "visually", "very", "similar", "to", "part", "number", "218", "##90", "##14", "##-", "##00", "##-", "##21", "##1", "[unused6]", "[SEP]", "[unused1]", "mac", "##ro", "programming", "[unused2]", "[unused3]", "requiring", "[unused4]", "[unused5]", "the", "control", "key", "[unused6]", "[SEP]", "[unused1]", "the", "same", "AT", "style", "plug", "and", "chassis", "[unused2]", "[unused3]", "screw", "##s", "holding", "[unused4]", "[unused5]", "the", "keyboard", "together", "[unused6]", "[SEP]", "[unused1]", "These", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "similar", "with", "the", "same", "AT", "style", "plug", "and", "chassis", "silver", "label", "on", "the", "reverse", "bearing", "the", "Any", "##K", "##ey", "moniker", "screw", "##s", "holding", "the", "keyboard", "together", "mac", "##ro", "programming", "requiring", "the", "control", "key", "and", "lacking", "the", "Any", "##K", "##ey", "inscription", "on", "their", "face", "[SEP]", "[unused1]", "These", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "similar", "with", "the", "same", "AT", "style", "plug", "and", "chassis", "silver", "label", "on", "the", "reverse", "bearing", "the", "Any", "##K", "##ey", "moniker", "screw", "##s", "holding", "the", "keyboard", "together", "mac", "##ro", "programming", "requiring", "the", "control", "key", "and", "lacking", "the", "Any", "##K", "##ey", "inscription", "on", "their", "face", "[SEP]"]]}

input 340:  {"source": "These beams stem from a cosmic energy source called the `` Omega Effect '' .\n"}
prediction:  {"predictions": [[1, 170, 21545, 2308, 2674, 2, 3, 1270, 4, 5, 1103, 169, 28152, 17648, 27007, 112, 28131, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1636, 13903, 2, 3, 8175, 4, 5, 1121, 170, 21545, 2308, 2674, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07240064442157745, -0.0015202839858829975, -0.0002841949462890625, -0.0002875328063964844, -0.0002875328063964844, -0.0002875328063964844, -0.0002875328063964844, -0.0002875328063964844, -0.0002875328063964844, -0.0002875328063964844], "metadata": {"source_tokens": ["These", "beams", "stem", "from", "a", "cosmic", "energy", "source", "called", "the", "`", "##`", "Omega", "Effect", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "cosmic", "energy", "source", "[unused2]", "[unused3]", "called", "[unused4]", "[unused5]", "the", "`", "##`", "Omega", "Effect", "'", "##'", "[unused6]", "[SEP]", "[unused1]", "These", "beams", "[unused2]", "[unused3]", "stem", "[unused4]", "[unused5]", "from", "a", "cosmic", "energy", "source", "[unused6]", "[SEP]"]]}

input 341:  {"source": "These objects are thrown away if their screen projection is too small .\n"}
prediction:  {"predictions": [[1, 1636, 4546, 2, 3, 1132, 6358, 4, 5, 1283, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1147, 3251, 15178, 2, 3, 1110, 4, 5, 1315, 1353, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07561477273702621, -0.0027688767295330763, -0.0013456344604492188, -0.0013222694396972656, -0.0013222694396972656, -0.0013222694396972656, -0.0013222694396972656, -0.0013222694396972656, -0.0013222694396972656, -0.0013222694396972656], "metadata": {"source_tokens": ["These", "objects", "are", "thrown", "away", "if", "their", "screen", "projection", "is", "too", "small", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "These", "objects", "[unused2]", "[unused3]", "are", "thrown", "[unused4]", "[unused5]", "away", "[unused6]", "[SEP]", "[unused1]", "their", "screen", "projection", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "too", "small", "[unused6]", "[SEP]"]]}

input 342:  {"source": "These orientations allow easy movement , i.e. degrees of freedom , and thus lowers entropy minimally .\n"}
prediction:  {"predictions": [[1, 1636, 10592, 1116, 2, 3, 2621, 4, 5, 3123, 2230, 117, 178, 28138, 1162, 28138, 4842, 1104, 4438, 117, 1105, 2456, 2211, 1116, 4035, 25444, 10298, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03234945237636566, -0.07467818260192871, -0.07641124725341797, -0.07641124725341797, -0.07641124725341797, -0.07641124725341797, -0.07641124725341797, -0.07641124725341797, -0.07641124725341797, -0.07641124725341797], "metadata": {"source_tokens": ["These", "orientation", "##s", "allow", "easy", "movement", ",", "i", "##.", "##e", "##.", "degrees", "of", "freedom", ",", "and", "thus", "lower", "##s", "en", "##tropy", "minimal", "##ly", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "These", "orientation", "##s", "[unused2]", "[unused3]", "allow", "[unused4]", "[unused5]", "easy", "movement", ",", "i", "##.", "##e", "##.", "degrees", "of", "freedom", ",", "and", "thus", "lower", "##s", "en", "##tropy", "minimal", "##ly", "[unused6]", "[SEP]"]]}

input 343:  {"source": "These were often related to European conflict , as the Stuart Pretenders were aided and encouraged by Britain 's continental enemies for their own ends .\n"}
prediction:  {"predictions": [[1, 1636, 2, 3, 1127, 2272, 4, 5, 1106, 1735, 4139, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6395, 11689, 22910, 1468, 2, 3, 1127, 12340, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6395, 11689, 22910, 1468, 2, 3, 6182, 4, 5, 1118, 2855, 112, 1116, 10998, 6380, 1111, 1147, 1319, 3769, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04708695411682129, -0.0340617410838604, -0.026065099984407425, -0.21033871173858643, -0.21144723892211914, -0.21144723892211914, -0.21144723892211914, -0.21144723892211914, -0.21144723892211914, -0.21144723892211914], "metadata": {"source_tokens": ["These", "were", "often", "related", "to", "European", "conflict", ",", "as", "the", "Stuart", "Pre", "##tend", "##ers", "were", "aided", "and", "encouraged", "by", "Britain", "'", "##s", "continental", "enemies", "for", "their", "own", "ends", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "These", "[unused2]", "[unused3]", "were", "related", "[unused4]", "[unused5]", "to", "European", "conflict", "often", "[unused6]", "[SEP]", "[unused1]", "the", "Stuart", "Pre", "##tend", "##ers", "[unused2]", "[unused3]", "were", "aided", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "the", "Stuart", "Pre", "##tend", "##ers", "[unused2]", "[unused3]", "encouraged", "[unused4]", "[unused5]", "by", "Britain", "'", "##s", "continental", "enemies", "for", "their", "own", "ends", "[unused6]", "[SEP]"]]}

input 344:  {"source": "They beat Milligan 1-0 , Grand View 3-0 , Webber International 1-0 and Azusa Pacific 0-0 to win the NAIA National Championships .\n"}
prediction:  {"predictions": [[1, 1220, 2, 3, 3222, 4, 5, 7664, 10888, 122, 28137, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1220, 2, 3, 3222, 4, 5, 7664, 10888, 122, 28137, 1568, 1106, 1782, 1103, 151, 1592, 9984, 1305, 2708, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1220, 2, 3, 3222, 4, 5, 7664, 10888, 122, 28137, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06271088868379593, -0.11435434967279434, -0.20471809804439545, -0.27187585830688477, -0.27483177185058594, -0.27483177185058594, -0.27483177185058594, -0.27483177185058594, -0.27483177185058594, -0.27483177185058594], "metadata": {"source_tokens": ["They", "beat", "Mill", "##igan", "1", "##-", "##0", ",", "Grand", "View", "3", "##-", "##0", ",", "Webber", "International", "1", "##-", "##0", "and", "A", "##zu", "##sa", "Pacific", "0", "##-", "##0", "to", "win", "the", "N", "##A", "##IA", "National", "Championships", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "They", "[unused2]", "[unused3]", "beat", "[unused4]", "[unused5]", "Mill", "##igan", "1", "##-", "##0", "[unused6]", "[SEP]", "[unused1]", "They", "[unused2]", "[unused3]", "beat", "[unused4]", "[unused5]", "Mill", "##igan", "1", "##-", "##0", "to", "win", "the", "N", "##A", "##IA", "National", "Championships", "[unused6]", "[SEP]", "[unused1]", "They", "[unused2]", "[unused3]", "beat", "[unused4]", "[unused5]", "Mill", "##igan", "1", "##-", "##0", "[unused6]", "[SEP]"]]}

input 345:  {"source": "They have included some of the most dangerous assassins in the world including Lady Shiva , David Cain , and Merlyn .\n"}
prediction:  {"predictions": [[1, 1220, 2, 3, 1138, 1529, 4, 5, 1199, 1104, 1103, 1211, 4249, 27459, 1107, 1103, 1362, 1259, 2876, 12945, 117, 1681, 11753, 117, 1105, 2508, 25339, 1179, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0005368351703509688, -0.02149057388305664, -0.021993160247802734, -0.021993160247802734, -0.021993160247802734, -0.021993160247802734, -0.021993160247802734, -0.021993160247802734, -0.021993160247802734, -0.021993160247802734], "metadata": {"source_tokens": ["They", "have", "included", "some", "of", "the", "most", "dangerous", "assassins", "in", "the", "world", "including", "Lady", "Shiva", ",", "David", "Cain", ",", "and", "Me", "##rly", "##n", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "They", "[unused2]", "[unused3]", "have", "included", "[unused4]", "[unused5]", "some", "of", "the", "most", "dangerous", "assassins", "in", "the", "world", "including", "Lady", "Shiva", ",", "David", "Cain", ",", "and", "Me", "##rly", "##n", "[unused6]", "[SEP]"]]}

input 346:  {"source": "They usually go through a period of dormancy after flowering .\n"}
prediction:  {"predictions": [[1, 1220, 2, 3, 1301, 4, 5, 1194, 170, 1669, 1104, 22181, 10413, 1170, 11853, 1932, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0006028811330907047, -0.021995067596435547, -0.02199554443359375, -0.02199554443359375, -0.02199554443359375, -0.02199554443359375, -0.02199554443359375, -0.02199554443359375, -0.02199554443359375, -0.02199554443359375], "metadata": {"source_tokens": ["They", "usually", "go", "through", "a", "period", "of", "dorm", "##ancy", "after", "flowering", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "They", "[unused2]", "[unused3]", "go", "[unused4]", "[unused5]", "through", "a", "period", "of", "dorm", "##ancy", "after", "flowering", "usually", "[unused6]", "[SEP]"]]}

input 347:  {"source": "Third TV drama series was broadcast in 2008 - , featuring Mao Inoue as Anmitsu .\n"}
prediction:  {"predictions": [[1, 4180, 1794, 3362, 1326, 2, 3, 1108, 3012, 4, 5, 1107, 1369, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4180, 1794, 3362, 1326, 2, 3, 3022, 4, 5, 16922, 1130, 6094, 1162, 1112, 1760, 9084, 6385, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02357552759349346, -0.03369263932108879, -0.022012710571289062, -0.02201557159423828, -0.02201557159423828, -0.02201557159423828, -0.02201557159423828, -0.02201557159423828, -0.02201557159423828, -0.02201557159423828], "metadata": {"source_tokens": ["Third", "TV", "drama", "series", "was", "broadcast", "in", "2008", "-", ",", "featuring", "Mao", "In", "##ou", "##e", "as", "An", "##mit", "##su", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Third", "TV", "drama", "series", "[unused2]", "[unused3]", "was", "broadcast", "[unused4]", "[unused5]", "in", "2008", "[unused6]", "[SEP]", "[unused1]", "Third", "TV", "drama", "series", "[unused2]", "[unused3]", "featuring", "[unused4]", "[unused5]", "Mao", "In", "##ou", "##e", "as", "An", "##mit", "##su", "[unused6]", "[SEP]"]]}

input 348:  {"source": "This attire has also become popular with women of other communities .\n"}
prediction:  {"predictions": [[1, 1188, 22604, 2, 3, 1144, 1145, 1561, 4, 5, 1927, 1114, 1535, 1104, 1168, 3611, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00044065050315111876, -0.0002560615539550781, -0.00028705596923828125, -0.00028705596923828125, -0.00028705596923828125, -0.00028705596923828125, -0.00028705596923828125, -0.00028705596923828125, -0.00028705596923828125, -0.00028705596923828125], "metadata": {"source_tokens": ["This", "attire", "has", "also", "become", "popular", "with", "women", "of", "other", "communities", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "attire", "[unused2]", "[unused3]", "has", "also", "become", "[unused4]", "[unused5]", "popular", "with", "women", "of", "other", "communities", "[unused6]", "[SEP]"]]}

input 349:  {"source": "This can be further generalized by defining a Q-valued Euler characteristic for certain finite categories , a notion compatible with the Euler characteristics of graphs , orbifolds and posets mentioned above .\n"}
prediction:  {"predictions": [[1, 1188, 2, 3, 1169, 1129, 1748, 22214, 4, 5, 1118, 13682, 170, 154, 28137, 7501, 17226, 142, 8722, 1197, 7987, 1111, 2218, 10996, 6788, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21562, 117, 1137, 5567, 10787, 1116, 1105, 14131, 2145, 2, 3, 3025, 4, 5, 1807, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2218, 10996, 6788, 2, 3, 1110, 4, 5, 170, 9162, 12173, 1114, 1103, 142, 8722, 1197, 5924, 1104, 21562, 1137, 5567, 10787, 1116, 1105, 14131, 2145, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06400736421346664, -0.08603262156248093, -0.053679559379816055, -0.13989615440368652, -0.13959312438964844, -0.13959312438964844, -0.13959312438964844, -0.13959312438964844, -0.13959312438964844, -0.13959312438964844], "metadata": {"source_tokens": ["This", "can", "be", "further", "generalized", "by", "defining", "a", "Q", "##-", "##val", "##ued", "E", "##ule", "##r", "characteristic", "for", "certain", "finite", "categories", ",", "a", "notion", "compatible", "with", "the", "E", "##ule", "##r", "characteristics", "of", "graphs", ",", "or", "##bi", "##fold", "##s", "and", "pose", "##ts", "mentioned", "above", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "[unused2]", "[unused3]", "can", "be", "further", "generalized", "[unused4]", "[unused5]", "by", "defining", "a", "Q", "##-", "##val", "##ued", "E", "##ule", "##r", "characteristic", "for", "certain", "finite", "categories", "[unused6]", "[SEP]", "[unused1]", "graphs", ",", "or", "##bi", "##fold", "##s", "and", "pose", "##ts", "[unused2]", "[unused3]", "mentioned", "[unused4]", "[unused5]", "above", "[unused6]", "[SEP]", "[unused1]", "certain", "finite", "categories", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "notion", "compatible", "with", "the", "E", "##ule", "##r", "characteristics", "of", "graphs", "or", "##bi", "##fold", "##s", "and", "pose", "##ts", "[unused6]", "[SEP]"]]}

input 350:  {"source": "This change was soon picked up by Huguenot writers , who began to expand on Calvin and promote the idea of the sovereignty of the people , ideas to which Catholic writers and preachers responded fiercely .\n"}
prediction:  {"predictions": [[1, 1188, 1849, 2, 3, 1108, 3015, 1146, 4, 5, 1118, 20164, 7222, 12512, 5094, 1770, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20164, 7222, 12512, 5094, 2, 3, 1310, 4, 5, 1106, 7380, 1113, 11110, 1105, 4609, 1103, 1911, 1104, 1103, 13578, 1104, 1103, 1234, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2336, 5094, 1105, 18154, 1116, 2, 3, 5133, 17494, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20164, 7222, 12512, 5094, 2, 3, 1310, 4, 5, 1106, 4609, 1103, 1911, 1104, 1103, 13578, 1104, 1103, 1234, 4133, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20164, 7222, 12512, 5094, 2, 3, 1310, 4, 5, 1106, 4609, 1103, 1911, 1104, 1103, 13578, 1104, 1103, 1234, 4133, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02012745477259159, -0.06203890219330788, -0.08267617225646973, -0.09283561259508133, -0.10404402017593384, -0.26966023445129395, -0.2740299701690674, -0.2740299701690674, -0.2740299701690674, -0.2740299701690674], "metadata": {"source_tokens": ["This", "change", "was", "soon", "picked", "up", "by", "Hu", "##gue", "##not", "writers", ",", "who", "began", "to", "expand", "on", "Calvin", "and", "promote", "the", "idea", "of", "the", "sovereignty", "of", "the", "people", ",", "ideas", "to", "which", "Catholic", "writers", "and", "preacher", "##s", "responded", "fiercely", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "change", "[unused2]", "[unused3]", "was", "picked", "up", "[unused4]", "[unused5]", "by", "Hu", "##gue", "##not", "writers", "soon", "[unused6]", "[SEP]", "[unused1]", "Hu", "##gue", "##not", "writers", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "to", "expand", "on", "Calvin", "and", "promote", "the", "idea", "of", "the", "sovereignty", "of", "the", "people", "[unused6]", "[SEP]", "[unused1]", "Catholic", "writers", "and", "preacher", "##s", "[unused2]", "[unused3]", "responded", "fiercely", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Hu", "##gue", "##not", "writers", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "to", "promote", "the", "idea", "of", "the", "sovereignty", "of", "the", "people", "ideas", "[unused6]", "[SEP]", "[unused1]", "Hu", "##gue", "##not", "writers", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "to", "promote", "the", "idea", "of", "the", "sovereignty", "of", "the", "people", "ideas", "[unused6]", "[SEP]"]]}

input 351:  {"source": "This engine was equipped with an electronically controlled carburetor .\n"}
prediction:  {"predictions": [[1, 1188, 2395, 2, 3, 1108, 5440, 4, 5, 1114, 1126, 4828, 2716, 4013, 1610, 19364, 20713, 1197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00015635490126442164, -0.00016450881958007812, -0.000164031982421875, -0.000164031982421875, -0.000164031982421875, -0.000164031982421875, -0.000164031982421875, -0.000164031982421875, -0.000164031982421875, -0.000164031982421875], "metadata": {"source_tokens": ["This", "engine", "was", "equipped", "with", "an", "electronic", "##ally", "controlled", "car", "##bur", "##eto", "##r", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "engine", "[unused2]", "[unused3]", "was", "equipped", "[unused4]", "[unused5]", "with", "an", "electronic", "##ally", "controlled", "car", "##bur", "##eto", "##r", "[unused6]", "[SEP]"]]}

input 352:  {"source": "This had considerable implications for the Welsh language as it was the main language of the nonconformist churches in Wales .\n"}
prediction:  {"predictions": [[1, 1188, 2, 3, 1125, 4, 5, 5602, 14755, 1111, 1103, 5447, 1846, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1108, 4, 5, 1103, 1514, 1846, 1104, 1103, 1664, 7235, 13199, 1776, 5189, 1107, 2717, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.021636391058564186, -0.0020042373798787594, -0.07546329498291016, -0.07606315612792969, -0.07606315612792969, -0.07606315612792969, -0.07606315612792969, -0.07606315612792969, -0.07606315612792969, -0.07606315612792969], "metadata": {"source_tokens": ["This", "had", "considerable", "implications", "for", "the", "Welsh", "language", "as", "it", "was", "the", "main", "language", "of", "the", "non", "##con", "##form", "##ist", "churches", "in", "Wales", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "considerable", "implications", "for", "the", "Welsh", "language", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "main", "language", "of", "the", "non", "##con", "##form", "##ist", "churches", "in", "Wales", "[unused6]", "[SEP]"]]}

input 353:  {"source": "This is most common in Western countries in those with Barrett 's esophagus , and occurs in the cuboidal cells .\n"}
prediction:  {"predictions": [[1, 1188, 2, 3, 1110, 4, 5, 1211, 1887, 1107, 2102, 2182, 1107, 1343, 1114, 12908, 112, 1116, 13936, 4184, 2328, 12909, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1188, 2, 3, 4365, 4, 5, 1107, 1103, 16408, 4043, 13293, 3652, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0073526110500097275, -0.017467141151428223, -0.021851062774658203, -0.021831035614013672, -0.021831035614013672, -0.021831035614013672, -0.021831035614013672, -0.021831035614013672, -0.021831035614013672, -0.021831035614013672], "metadata": {"source_tokens": ["This", "is", "most", "common", "in", "Western", "countries", "in", "those", "with", "Barrett", "'", "##s", "es", "##op", "##ha", "##gus", ",", "and", "occurs", "in", "the", "cu", "##bo", "##idal", "cells", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "most", "common", "in", "Western", "countries", "in", "those", "with", "Barrett", "'", "##s", "es", "##op", "##ha", "##gus", "[unused6]", "[SEP]", "[unused1]", "This", "[unused2]", "[unused3]", "occurs", "[unused4]", "[unused5]", "in", "the", "cu", "##bo", "##idal", "cells", "[unused6]", "[SEP]"]]}

input 354:  {"source": "This line was extended east by the Prahran & Malvern Tramways Trust from Hawthorn Road to Darling Road , Malvern East on 13 November 1913 .\n"}
prediction:  {"predictions": [[1, 1188, 1413, 2, 3, 1108, 2925, 4, 5, 1746, 1118, 1103, 153, 10659, 4047, 111, 18880, 24472, 157, 4515, 8520, 4623, 1121, 26493, 1914, 1106, 12777, 1914, 1113, 1492, 1379, 4325, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1188, 1413, 2, 3, 1108, 2925, 4, 5, 1746, 1118, 1103, 153, 10659, 4047, 111, 18880, 24472, 157, 4515, 8520, 4623, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1188, 1413, 2, 3, 1108, 2925, 4, 5, 1746, 1118, 1103, 153, 10659, 4047, 111, 18880, 24472, 157, 4515, 8520, 4623, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1188, 1413, 2, 3, 1108, 2925, 4, 5, 1746, 1118, 1103, 153, 10659, 4047, 111, 18880, 24472, 157, 4515, 8520, 4623, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027968958020210266, -0.06556878238916397, -0.09343519061803818, -0.09852460771799088, -0.2718794345855713, -0.27071380615234375, -0.27071380615234375, -0.27071380615234375, -0.27071380615234375, -0.27071380615234375], "metadata": {"source_tokens": ["This", "line", "was", "extended", "east", "by", "the", "P", "##rah", "##ran", "&", "Mal", "##vern", "T", "##ram", "##ways", "Trust", "from", "Hawthorn", "Road", "to", "Darling", "Road", ",", "Mal", "##vern", "East", "on", "13", "November", "1913", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "line", "[unused2]", "[unused3]", "was", "extended", "[unused4]", "[unused5]", "east", "by", "the", "P", "##rah", "##ran", "&", "Mal", "##vern", "T", "##ram", "##ways", "Trust", "from", "Hawthorn", "Road", "to", "Darling", "Road", "on", "13", "November", "1913", "[unused6]", "[SEP]", "[unused1]", "This", "line", "[unused2]", "[unused3]", "was", "extended", "[unused4]", "[unused5]", "east", "by", "the", "P", "##rah", "##ran", "&", "Mal", "##vern", "T", "##ram", "##ways", "Trust", "[unused6]", "[SEP]", "[unused1]", "This", "line", "[unused2]", "[unused3]", "was", "extended", "[unused4]", "[unused5]", "east", "by", "the", "P", "##rah", "##ran", "&", "Mal", "##vern", "T", "##ram", "##ways", "Trust", "[unused6]", "[SEP]", "[unused1]", "This", "line", "[unused2]", "[unused3]", "was", "extended", "[unused4]", "[unused5]", "east", "by", "the", "P", "##rah", "##ran", "&", "Mal", "##vern", "T", "##ram", "##ways", "Trust", "[unused6]", "[SEP]"]]}

input 355:  {"source": "This mutation gives him superhuman strength , speed , reflexes , agility , flexibility , dexterity , coordination , balance , and endurance .\n"}
prediction:  {"predictions": [[1, 1188, 17895, 2, 3, 3114, 4, 5, 1140, 7688, 15319, 3220, 117, 2420, 117, 27820, 1279, 117, 170, 5389, 11796, 117, 18605, 117, 1260, 1775, 2083, 1785, 117, 14501, 117, 5233, 117, 1105, 20655, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.016123563051223755, -0.022020339965820312, -0.02201986312866211, -0.02201986312866211, -0.02201986312866211, -0.02201986312866211, -0.02201986312866211, -0.02201986312866211, -0.02201986312866211, -0.02201986312866211], "metadata": {"source_tokens": ["This", "mutation", "gives", "him", "super", "##human", "strength", ",", "speed", ",", "reflex", "##es", ",", "a", "##gi", "##lity", ",", "flexibility", ",", "de", "##x", "##ter", "##ity", ",", "coordination", ",", "balance", ",", "and", "endurance", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "mutation", "[unused2]", "[unused3]", "gives", "[unused4]", "[unused5]", "him", "super", "##human", "strength", ",", "speed", ",", "reflex", "##es", ",", "a", "##gi", "##lity", ",", "flexibility", ",", "de", "##x", "##ter", "##ity", ",", "coordination", ",", "balance", ",", "and", "endurance", "[unused6]", "[SEP]"]]}

input 356:  {"source": "This policy was , however , opposed by the miners who demanded that the inspections be carried out by experienced colliers .\n"}
prediction:  {"predictions": [[1, 1103, 13418, 2, 3, 5648, 4, 5, 1115, 1103, 11820, 1116, 1129, 2446, 1149, 1118, 4531, 1884, 14367, 1733, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1188, 2818, 2, 3, 1108, 4, 5, 1649, 4151, 1118, 1103, 13418, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 11820, 1116, 2, 3, 1129, 2446, 1149, 4, 5, 1118, 4531, 1884, 14367, 1733, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004211971536278725, -0.06090746074914932, -0.039545509964227676, -0.034820556640625, -0.034638404846191406, -0.034638404846191406, -0.034638404846191406, -0.034638404846191406, -0.034638404846191406, -0.034638404846191406], "metadata": {"source_tokens": ["This", "policy", "was", ",", "however", ",", "opposed", "by", "the", "miners", "who", "demanded", "that", "the", "inspection", "##s", "be", "carried", "out", "by", "experienced", "co", "##llie", "##rs", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "miners", "[unused2]", "[unused3]", "demanded", "[unused4]", "[unused5]", "that", "the", "inspection", "##s", "be", "carried", "out", "by", "experienced", "co", "##llie", "##rs", "[unused6]", "[SEP]", "[unused1]", "This", "policy", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "however", "opposed", "by", "the", "miners", "[unused6]", "[SEP]", "[unused1]", "the", "inspection", "##s", "[unused2]", "[unused3]", "be", "carried", "out", "[unused4]", "[unused5]", "by", "experienced", "co", "##llie", "##rs", "[unused6]", "[SEP]"]]}

input 357:  {"source": "To assist the pope in the many calls for his help and charity , Pascalina organized and led the `` Magazzino '' , a private papal charity office which employed up to 40 helpers and continued until 1959 .\n"}
prediction:  {"predictions": [[1, 19636, 2983, 2, 3, 3366, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 19636, 2983, 2, 3, 1521, 4, 5, 1103, 169, 28152, 7085, 2571, 15284, 2728, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 2029, 16701, 6630, 1701, 2, 3, 4071, 1146, 4, 5, 1106, 1969, 1494, 1468, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 2029, 16701, 6630, 1701, 2, 3, 1598, 4, 5, 1235, 3003, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.11689557880163193, -0.08246613293886185, -0.06219050660729408, -0.05589751526713371, -0.2964010238647461, -0.28272414207458496, -0.28272414207458496, -0.28272414207458496, -0.28272414207458496, -0.28272414207458496], "metadata": {"source_tokens": ["To", "assist", "the", "pope", "in", "the", "many", "calls", "for", "his", "help", "and", "charity", ",", "Pascal", "##ina", "organized", "and", "led", "the", "`", "##`", "Ma", "##ga", "##zzi", "##no", "'", "##'", ",", "a", "private", "papal", "charity", "office", "which", "employed", "up", "to", "40", "help", "##ers", "and", "continued", "until", "1959", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pascal", "##ina", "[unused2]", "[unused3]", "organized", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Pascal", "##ina", "[unused2]", "[unused3]", "led", "[unused4]", "[unused5]", "the", "`", "##`", "Ma", "##ga", "##zzi", "##no", "[unused6]", "[SEP]", "[unused1]", "a", "private", "papal", "charity", "office", "[unused2]", "[unused3]", "employed", "up", "[unused4]", "[unused5]", "to", "40", "help", "##ers", "[unused6]", "[SEP]", "[unused1]", "a", "private", "papal", "charity", "office", "[unused2]", "[unused3]", "continued", "[unused4]", "[unused5]", "until", "1959", "[unused6]", "[SEP]"]]}

input 358:  {"source": "To keep the family together , Michael asks his self-centered twin sister Lindsay , her husband Tobias and their daughter Maeby to live together in the Bluth model home with him and George Michael .\n"}
prediction:  {"predictions": [[1, 1847, 2, 3, 4390, 4, 5, 1117, 2191, 28137, 8298, 5686, 5930, 2104, 12218, 117, 1123, 2252, 18167, 1105, 1147, 1797, 12255, 2665, 1106, 1686, 1487, 1107, 1103, 15223, 1582, 2235, 1313, 1114, 1140, 1105, 1667, 1847, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1847, 2, 3, 4390, 4, 5, 1117, 2191, 28137, 8298, 5686, 5930, 2104, 12218, 1123, 2252, 18167, 1105, 1147, 1797, 12255, 2665, 1106, 1686, 1487, 1107, 1103, 15223, 1582, 2235, 1313, 1114, 1140, 1105, 1667, 1847, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04051949828863144, -0.10985593497753143, -0.2702674865722656, -0.297208309173584, -0.297208309173584, -0.297208309173584, -0.297208309173584, -0.297208309173584, -0.297208309173584, -0.297208309173584], "metadata": {"source_tokens": ["To", "keep", "the", "family", "together", ",", "Michael", "asks", "his", "self", "##-", "##cent", "##ered", "twin", "sister", "Lindsay", ",", "her", "husband", "Tobias", "and", "their", "daughter", "Mae", "##by", "to", "live", "together", "in", "the", "Blu", "##th", "model", "home", "with", "him", "and", "George", "Michael", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Michael", "[unused2]", "[unused3]", "asks", "[unused4]", "[unused5]", "his", "self", "##-", "##cent", "##ered", "twin", "sister", "Lindsay", ",", "her", "husband", "Tobias", "and", "their", "daughter", "Mae", "##by", "to", "live", "together", "in", "the", "Blu", "##th", "model", "home", "with", "him", "and", "George", "Michael", "[unused6]", "[SEP]", "[unused1]", "Michael", "[unused2]", "[unused3]", "asks", "[unused4]", "[unused5]", "his", "self", "##-", "##cent", "##ered", "twin", "sister", "Lindsay", "her", "husband", "Tobias", "and", "their", "daughter", "Mae", "##by", "to", "live", "together", "in", "the", "Blu", "##th", "model", "home", "with", "him", "and", "George", "Michael", "[unused6]", "[SEP]"]]}

input 359:  {"source": "To the Medieval school of Jewish Philosophy , that framed Judaism in light of Greek thought and human intellect , God the Infinite has no needs .\n"}
prediction:  {"predictions": [[1, 1103, 27526, 2, 3, 1144, 4, 5, 1185, 2993, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 15902, 1278, 1104, 2778, 8714, 2, 3, 10577, 4, 5, 14142, 1107, 1609, 1104, 2414, 1354, 1105, 1769, 1107, 7854, 18465, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.10155311971902847, -0.04205859825015068, -0.03220486640930176, -0.03220486640930176, -0.03220486640930176, -0.03220486640930176, -0.03220486640930176, -0.03220486640930176, -0.03220486640930176, -0.03220486640930176], "metadata": {"source_tokens": ["To", "the", "Medieval", "school", "of", "Jewish", "Philosophy", ",", "that", "framed", "Judaism", "in", "light", "of", "Greek", "thought", "and", "human", "in", "##tel", "##lect", ",", "God", "the", "Infinite", "has", "no", "needs", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Infinite", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "no", "needs", "[unused6]", "[SEP]", "[unused1]", "the", "Medieval", "school", "of", "Jewish", "Philosophy", "[unused2]", "[unused3]", "framed", "[unused4]", "[unused5]", "Judaism", "in", "light", "of", "Greek", "thought", "and", "human", "in", "##tel", "##lect", "[unused6]", "[SEP]"]]}

input 360:  {"source": "To the north , along and across the same border , live speakers of Lakha .\n"}
prediction:  {"predictions": [[1, 1706, 1103, 1564, 117, 1373, 1105, 1506, 1103, 1269, 3070, 2, 3, 1686, 4, 5, 7417, 1104, 2001, 14457, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.018974624574184418, -0.0014791488647460938, -0.0019030570983886719, -0.0019030570983886719, -0.0019030570983886719, -0.0019030570983886719, -0.0019030570983886719, -0.0019030570983886719, -0.0019030570983886719, -0.0019030570983886719], "metadata": {"source_tokens": ["To", "the", "north", ",", "along", "and", "across", "the", "same", "border", ",", "live", "speakers", "of", "La", "##kha", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "To", "the", "north", ",", "along", "and", "across", "the", "same", "border", "[unused2]", "[unused3]", "live", "[unused4]", "[unused5]", "speakers", "of", "La", "##kha", "[unused6]", "[SEP]"]]}

input 361:  {"source": "Total ` Fresh Food Story ' constructed at the end of the North Mall .\n"}
prediction:  {"predictions": [[1, 8653, 169, 15756, 6702, 5145, 2, 3, 3033, 4, 5, 1120, 1103, 1322, 1104, 1103, 1456, 11123, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014638662338256836, -0.00017309188842773438, -0.00017595291137695312, -0.00017595291137695312, -0.00017595291137695312, -0.00017595291137695312, -0.00017595291137695312, -0.00017595291137695312, -0.00017595291137695312, -0.00017595291137695312], "metadata": {"source_tokens": ["Total", "`", "Fresh", "Food", "Story", "'", "constructed", "at", "the", "end", "of", "the", "North", "Mall", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Total", "`", "Fresh", "Food", "Story", "[unused2]", "[unused3]", "constructed", "[unused4]", "[unused5]", "at", "the", "end", "of", "the", "North", "Mall", "[unused6]", "[SEP]"]]}

input 362:  {"source": "Transferred to Key West , Florida , on 1 June 1941 , `` R-11 '' continued her training ship duties throughout the remainder of her career .\n"}
prediction:  {"predictions": [[1, 155, 28137, 14541, 2, 3, 1598, 4, 5, 1123, 2013, 2062, 5078, 2032, 1103, 6311, 1104, 1123, 1578, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 155, 28137, 14541, 2, 3, 1598, 4, 5, 1123, 2013, 2062, 5078, 23489, 4359, 1106, 7443, 1537, 1113, 122, 1340, 3018, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.025143077597022057, -0.04986032471060753, -0.13572335243225098, -0.12772655487060547, -0.12772679328918457, -0.12772679328918457, -0.12772679328918457, -0.12772679328918457, -0.12772679328918457, -0.12772679328918457], "metadata": {"source_tokens": ["Transfer", "##red", "to", "Key", "West", ",", "Florida", ",", "on", "1", "June", "1941", ",", "`", "##`", "R", "##-", "##11", "'", "##'", "continued", "her", "training", "ship", "duties", "throughout", "the", "remainder", "of", "her", "career", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "R", "##-", "##11", "[unused2]", "[unused3]", "continued", "[unused4]", "[unused5]", "her", "training", "ship", "duties", "throughout", "the", "remainder", "of", "her", "career", "[unused6]", "[SEP]", "[unused1]", "R", "##-", "##11", "[unused2]", "[unused3]", "continued", "[unused4]", "[unused5]", "her", "training", "ship", "duties", "Transfer", "##red", "to", "Key", "West", "on", "1", "June", "1941", "[unused6]", "[SEP]"]]}

input 363:  {"source": "Trumbull was often incorrectly credited in print as being the sole special-effects creator for 2001 .\n"}
prediction:  {"predictions": [[1, 157, 5697, 17719, 2, 3, 1108, 21605, 5175, 4, 5, 1107, 5911, 1112, 1217, 1103, 6753, 1957, 28137, 11470, 11916, 1116, 9264, 1111, 1630, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 157, 5697, 17719, 2, 3, 1108, 5175, 4, 5, 1107, 5911, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007736376486718655, -0.11304674297571182, -0.23932623863220215, -0.2349226474761963, -0.2349226474761963, -0.2349226474761963, -0.2349226474761963, -0.2349226474761963, -0.2349226474761963, -0.2349226474761963], "metadata": {"source_tokens": ["T", "##rum", "##bull", "was", "often", "incorrectly", "credited", "in", "print", "as", "being", "the", "sole", "special", "##-", "##ef", "##fect", "##s", "creator", "for", "2001", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "T", "##rum", "##bull", "[unused2]", "[unused3]", "was", "incorrectly", "credited", "[unused4]", "[unused5]", "in", "print", "as", "being", "the", "sole", "special", "##-", "##ef", "##fect", "##s", "creator", "for", "2001", "often", "[unused6]", "[SEP]", "[unused1]", "T", "##rum", "##bull", "[unused2]", "[unused3]", "was", "credited", "[unused4]", "[unused5]", "in", "print", "[unused6]", "[SEP]"]]}

input 364:  {"source": "Twice divorced and currently married , Ladd is the mother of actress Laura Dern , by her ex-husband , actor Bruce Dern .\n"}
prediction:  {"predictions": [[1, 2001, 13976, 2, 3, 1110, 4, 5, 1103, 1534, 1104, 3647, 6273, 9682, 1179, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2001, 13976, 2, 3, 1110, 4, 5, 1103, 1534, 1118, 1123, 4252, 28137, 8827, 10198, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1123, 4252, 28137, 8827, 10198, 2, 3, 1110, 4, 5, 2811, 4767, 9682, 1179, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07433740049600601, -0.05353870615363121, -0.08496565371751785, -0.15093255043029785, -0.15091276168823242, -0.15091276168823242, -0.15091276168823242, -0.15091276168823242, -0.15091276168823242, -0.15091276168823242], "metadata": {"source_tokens": ["Twice", "divorced", "and", "currently", "married", ",", "La", "##dd", "is", "the", "mother", "of", "actress", "Laura", "Der", "##n", ",", "by", "her", "ex", "##-", "##hus", "##band", ",", "actor", "Bruce", "Der", "##n", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "La", "##dd", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "mother", "of", "actress", "Laura", "Der", "##n", "[unused6]", "[SEP]", "[unused1]", "La", "##dd", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "mother", "by", "her", "ex", "##-", "##hus", "##band", "[unused6]", "[SEP]", "[unused1]", "her", "ex", "##-", "##hus", "##band", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "actor", "Bruce", "Der", "##n", "[unused6]", "[SEP]"]]}

input 365:  {"source": "Two seats were won by the Labor-Progressive Party on its own with the re-election of A.A. MacLeod and J.B. Salsberg .\n"}
prediction:  {"predictions": [[1, 1960, 3474, 2, 3, 1127, 1281, 4, 5, 1118, 1103, 6314, 28137, 2101, 24081, 7370, 2109, 1786, 1113, 1157, 1319, 1114, 1103, 1231, 28137, 11194, 5796, 1104, 138, 28138, 1592, 28138, 6603, 18763, 1105, 147, 28138, 2064, 28138, 18613, 19945, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1960, 3474, 2, 3, 1127, 1281, 4, 5, 1118, 1103, 6314, 28137, 2101, 24081, 7370, 2109, 1786, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.015210071578621864, -0.06792836636304855, -0.12491869926452637, -0.12687015533447266, -0.12687015533447266, -0.12687015533447266, -0.12687015533447266, -0.12687015533447266, -0.12687015533447266, -0.12687015533447266], "metadata": {"source_tokens": ["Two", "seats", "were", "won", "by", "the", "Labor", "##-", "##P", "##rog", "##ress", "##ive", "Party", "on", "its", "own", "with", "the", "re", "##-", "##ele", "##ction", "of", "A", "##.", "##A", "##.", "Mac", "##Leod", "and", "J", "##.", "##B", "##.", "Sal", "##sberg", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Two", "seats", "[unused2]", "[unused3]", "were", "won", "[unused4]", "[unused5]", "by", "the", "Labor", "##-", "##P", "##rog", "##ress", "##ive", "Party", "on", "its", "own", "with", "the", "re", "##-", "##ele", "##ction", "of", "A", "##.", "##A", "##.", "Mac", "##Leod", "and", "J", "##.", "##B", "##.", "Sal", "##sberg", "[unused6]", "[SEP]", "[unused1]", "Two", "seats", "[unused2]", "[unused3]", "were", "won", "[unused4]", "[unused5]", "by", "the", "Labor", "##-", "##P", "##rog", "##ress", "##ive", "Party", "[unused6]", "[SEP]"]]}

input 366:  {"source": "Tyabb also has Tyabb Airport , a private airfield which has been operating for more than thirty years .\n"}
prediction:  {"predictions": [[1, 5331, 6639, 1830, 2, 3, 1144, 4, 5, 5331, 6639, 1830, 3369, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 2029, 11897, 2, 3, 1144, 1151, 3389, 4, 5, 1111, 1167, 1190, 3961, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.011281860060989857, -0.0008343524532392621, -0.009241580963134766, -0.009335041046142578, -0.009335041046142578, -0.009335041046142578, -0.009335041046142578, -0.009335041046142578, -0.009335041046142578, -0.009335041046142578], "metadata": {"source_tokens": ["Ty", "##ab", "##b", "also", "has", "Ty", "##ab", "##b", "Airport", ",", "a", "private", "airfield", "which", "has", "been", "operating", "for", "more", "than", "thirty", "years", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ty", "##ab", "##b", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "Ty", "##ab", "##b", "Airport", "[unused6]", "[SEP]", "[unused1]", "a", "private", "airfield", "[unused2]", "[unused3]", "has", "been", "operating", "[unused4]", "[unused5]", "for", "more", "than", "thirty", "years", "[unused6]", "[SEP]"]]}

input 367:  {"source": "US 258 intersects NC 222 in Fountain before entering Edgecombe County .\n"}
prediction:  {"predictions": [[1, 1646, 27434, 2, 3, 18585, 4, 5, 14056, 20640, 1107, 19873, 1196, 5273, 10403, 14231, 1391, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.001582296215929091, -0.0328826904296875, -0.03220725059509277, -0.03220725059509277, -0.03220725059509277, -0.03220725059509277, -0.03220725059509277, -0.03220725059509277, -0.03220725059509277, -0.03220725059509277], "metadata": {"source_tokens": ["US", "258", "intersects", "NC", "222", "in", "Fountain", "before", "entering", "Edge", "##combe", "County", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "US", "258", "[unused2]", "[unused3]", "intersects", "[unused4]", "[unused5]", "NC", "222", "in", "Fountain", "before", "entering", "Edge", "##combe", "County", "[unused6]", "[SEP]"]]}

input 368:  {"source": "Under the Comanche program , each company built different parts of the aircraft .\n"}
prediction:  {"predictions": [[1, 1296, 1419, 2, 3, 1434, 4, 5, 1472, 2192, 1104, 1103, 2163, 2831, 1103, 3291, 1399, 4386, 1788, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0011708850506693125, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562], "metadata": {"source_tokens": ["Under", "the", "Co", "##man", "##che", "program", ",", "each", "company", "built", "different", "parts", "of", "the", "aircraft", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "each", "company", "[unused2]", "[unused3]", "built", "[unused4]", "[unused5]", "different", "parts", "of", "the", "aircraft", "Under", "the", "Co", "##man", "##che", "program", "[unused6]", "[SEP]"]]}

input 369:  {"source": "Unlike Uncle Sam later , he is not a figure of authority but rather a yeoman who prefers his small beer and domestic peace , possessed of neither patriarchal power nor heroic defiance .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1110, 1136, 4, 5, 170, 2482, 1104, 3748, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 6798, 27085, 2, 3, 21042, 4, 5, 1117, 1353, 5298, 1105, 4500, 3519, 117, 8471, 1104, 4534, 27797, 1348, 1540, 4040, 17047, 27071, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.038249723613262177, -0.050539545714855194, -0.07632613182067871, -0.07632684707641602, -0.07632684707641602, -0.07632684707641602, -0.07632684707641602, -0.07632684707641602, -0.07632684707641602, -0.07632684707641602], "metadata": {"source_tokens": ["Unlike", "Uncle", "Sam", "later", ",", "he", "is", "not", "a", "figure", "of", "authority", "but", "rather", "a", "ye", "##oman", "who", "prefers", "his", "small", "beer", "and", "domestic", "peace", ",", "possessed", "of", "neither", "patriarch", "##al", "power", "nor", "heroic", "defiance", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "is", "not", "[unused4]", "[unused5]", "a", "figure", "of", "authority", "later", "[unused6]", "[SEP]", "[unused1]", "a", "ye", "##oman", "[unused2]", "[unused3]", "prefers", "[unused4]", "[unused5]", "his", "small", "beer", "and", "domestic", "peace", ",", "possessed", "of", "neither", "patriarch", "##al", "power", "nor", "heroic", "defiance", "[unused6]", "[SEP]"]]}

input 370:  {"source": "Unruly passengers are often put off here to be taken into custody .\n"}
prediction:  {"predictions": [[1, 12118, 23377, 4861, 2, 3, 1132, 1508, 1228, 4, 5, 1303, 1106, 1129, 1678, 1154, 9948, 1510, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03770601004362106, -0.03451871871948242, -0.03840494155883789, -0.03840494155883789, -0.03840494155883789, -0.03840494155883789, -0.03840494155883789, -0.03840494155883789, -0.03840494155883789, -0.03840494155883789], "metadata": {"source_tokens": ["Un", "##ruly", "passengers", "are", "often", "put", "off", "here", "to", "be", "taken", "into", "custody", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Un", "##ruly", "passengers", "[unused2]", "[unused3]", "are", "put", "off", "[unused4]", "[unused5]", "here", "to", "be", "taken", "into", "custody", "often", "[unused6]", "[SEP]"]]}

input 371:  {"source": "Wakeboarding is practiced by both men and women at the competitive level , but they compete in separate categories .\n"}
prediction:  {"predictions": [[1, 1152, 2, 3, 4845, 4, 5, 1107, 2767, 6788, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 13062, 24631, 2, 3, 1110, 8720, 4, 5, 1118, 1241, 1441, 1105, 1535, 1120, 1103, 6591, 1634, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.040995042771101, -0.0018168948590755463, -0.0002884864807128906, -0.0002894401550292969, -0.0002894401550292969, -0.0002894401550292969, -0.0002894401550292969, -0.0002894401550292969, -0.0002894401550292969, -0.0002894401550292969], "metadata": {"source_tokens": ["Wake", "##boarding", "is", "practiced", "by", "both", "men", "and", "women", "at", "the", "competitive", "level", ",", "but", "they", "compete", "in", "separate", "categories", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "they", "[unused2]", "[unused3]", "compete", "[unused4]", "[unused5]", "in", "separate", "categories", "[unused6]", "[SEP]", "[unused1]", "Wake", "##boarding", "[unused2]", "[unused3]", "is", "practiced", "[unused4]", "[unused5]", "by", "both", "men", "and", "women", "at", "the", "competitive", "level", "[unused6]", "[SEP]"]]}

input 372:  {"source": "Watson has served as Minority Leader since elected by his caucus in November 1998 .\n"}
prediction:  {"predictions": [[1, 7422, 2, 3, 1144, 1462, 4, 5, 1112, 26495, 7308, 1290, 1809, 1118, 1117, 27690, 1107, 1379, 1772, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004387781955301762, -0.03855323791503906, -0.03861427307128906, -0.03861427307128906, -0.03861427307128906, -0.03861427307128906, -0.03861427307128906, -0.03861427307128906, -0.03861427307128906, -0.03861427307128906], "metadata": {"source_tokens": ["Watson", "has", "served", "as", "Minority", "Leader", "since", "elected", "by", "his", "caucus", "in", "November", "1998", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Watson", "[unused2]", "[unused3]", "has", "served", "[unused4]", "[unused5]", "as", "Minority", "Leader", "since", "elected", "by", "his", "caucus", "in", "November", "1998", "[unused6]", "[SEP]"]]}

input 373:  {"source": "Watson was the founder and editor of `` newcritics.com , '' an online journal of media and arts criticism launched in January , 2007 and shuttered in June , 2009 .\n"}
prediction:  {"predictions": [[1, 7422, 2, 3, 1108, 4, 5, 1103, 3249, 1105, 3045, 1104, 169, 28152, 1207, 1665, 23862, 1116, 28138, 8178, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1126, 3294, 4897, 1104, 2394, 1105, 3959, 5879, 2, 3, 2536, 4, 5, 1107, 1356, 117, 1384, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7422, 2, 3, 1108, 4, 5, 1103, 3249, 1105, 3045, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7422, 2, 3, 1108, 4, 5, 1103, 3249, 1105, 3045, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7422, 2, 3, 1108, 4, 5, 1103, 3249, 1105, 3045, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7422, 2, 3, 1108, 4, 5, 1103, 3249, 1105, 3045, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.025329655036330223, -0.05690639093518257, -0.14252665638923645, -0.14671503007411957, -0.16407254338264465, -0.15769551694393158, -0.19332432746887207, -0.2213878631591797, -0.2213878631591797, -0.2213878631591797], "metadata": {"source_tokens": ["Watson", "was", "the", "founder", "and", "editor", "of", "`", "##`", "new", "##c", "##ritic", "##s", "##.", "##com", ",", "'", "##'", "an", "online", "journal", "of", "media", "and", "arts", "criticism", "launched", "in", "January", ",", "2007", "and", "shut", "##tered", "in", "June", ",", "2009", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Watson", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "founder", "and", "editor", "of", "`", "##`", "new", "##c", "##ritic", "##s", "##.", "##com", "[unused6]", "[SEP]", "[unused1]", "an", "online", "journal", "of", "media", "and", "arts", "criticism", "[unused2]", "[unused3]", "launched", "[unused4]", "[unused5]", "in", "January", ",", "2007", "[unused6]", "[SEP]", "[unused1]", "Watson", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "founder", "and", "editor", "[unused6]", "[SEP]", "[unused1]", "Watson", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "founder", "and", "editor", "[unused6]", "[SEP]", "[unused1]", "Watson", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "founder", "and", "editor", "[unused6]", "[SEP]", "[unused1]", "Watson", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "founder", "and", "editor", "[unused6]", "[SEP]"]]}

input 374:  {"source": "When Naguib began showing signs of independence from Nasser by distancing himself from the RCC 's land reform decrees and drawing closer to Egypt 's established political forces , namely the Wafd and the Brotherhood , Nasser resolved to depose him .\n"}
prediction:  {"predictions": [[1, 11896, 14607, 2, 3, 10456, 4, 5, 1106, 1260, 14811, 1140, 1332, 11896, 13830, 13292, 1310, 4000, 5300, 1104, 4574, 1121, 11896, 14607, 1118, 4267, 13946, 4869, 1471, 1121, 1103, 25157, 1658, 112, 1116, 1657, 5851, 11903, 1116, 1105, 4619, 2739, 1106, 4498, 112, 1116, 1628, 1741, 2088, 117, 102, 1, 11896, 13830, 13292, 2, 3, 1310, 4, 5, 4000, 5300, 1104, 4574, 1121, 11896, 14607, 1118, 4267, 13946, 4869, 1471, 1121, 1103, 25157, 1658, 112, 1116, 1657, 5851, 11903, 1116, 1105, 4619, 2739, 1106, 4498, 112, 1116, 1628, 1741, 2088, 8199, 1103, 160, 9823, 1181, 1105, 1103, 15831, 6, 102, 1, 11896, 14607, 2, 3, 10456, 4, 5, 1106, 1260, 14811, 1140, 1332, 11896, 13830, 13292, 1310, 4000, 5300, 1104, 4574, 1121, 11896, 14607, 1118, 4267, 13946, 4869, 1471, 1121, 1103, 25157, 1658, 112, 1116, 1657, 5851, 11903, 1116, 1105, 4619, 2739, 1106, 4498, 112, 1116, 1628, 1741, 2088, 8199, 102, 1, 11896, 13830, 13292, 2, 3, 1310, 4, 5, 4000, 5300, 1104, 4574, 1121, 11896, 14607, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11896, 13830, 13292, 2, 3, 1310, 4, 5, 4000, 5300, 1104, 4574, 1121, 11896, 14607, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11896, 13830, 13292, 2, 3, 1310, 4, 5, 4000, 5300, 1104, 4574, 1121, 11896, 14607, 1105, 4619, 2739, 1106, 4498, 112, 1116, 1628, 1741, 2088, 8199, 1103, 160, 9823, 1181, 1105, 1103, 15831, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11896, 13830, 13292, 2, 3, 1310, 4, 5, 4000, 5300, 1104, 4574, 1121, 11896, 14607, 1105, 4619, 2739, 1106, 4498, 112, 1116, 1628, 1741, 2088, 8199, 1103, 160, 9823, 1181, 1105, 1103, 15831, 6, 102, 102, 1, 11896, 14607, 2, 3, 10456, 4, 5, 1106, 1260, 14811, 1140, 1332, 11896, 13830, 13292, 1310, 4000, 5300, 1104, 4574, 1121, 11896, 14607, 1105, 4619, 2739, 1106, 4498, 112, 1116, 1628, 1741, 2088, 8199, 1103, 160, 9823, 1181, 1105, 1103, 15831, 6, 102, 102, 1, 11896, 13830, 13292, 2, 3, 1310, 4, 5, 4000, 5300, 1104, 4574, 1121, 11896, 14607, 6, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03720131143927574, -0.05201936140656471, -0.052462682127952576, -0.12802982330322266, -0.14348728954792023, -0.10004790872335434, -0.10401651263237, -0.0841255635023117, -0.179347962141037, -0.3026752471923828], "metadata": {"source_tokens": ["When", "Na", "##gu", "##ib", "began", "showing", "signs", "of", "independence", "from", "Na", "##sser", "by", "di", "##stan", "##cing", "himself", "from", "the", "RC", "##C", "'", "##s", "land", "reform", "decree", "##s", "and", "drawing", "closer", "to", "Egypt", "'", "##s", "established", "political", "forces", ",", "namely", "the", "W", "##af", "##d", "and", "the", "Brotherhood", ",", "Na", "##sser", "resolved", "to", "de", "##pose", "him", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "resolved", "[unused4]", "[unused5]", "to", "de", "##pose", "him", "When", "Na", "##gu", "##ib", "began", "showing", "signs", "of", "independence", "from", "Na", "##sser", "by", "di", "##stan", "##cing", "himself", "from", "the", "RC", "##C", "'", "##s", "land", "reform", "decree", "##s", "and", "drawing", "closer", "to", "Egypt", "'", "##s", "established", "political", "forces", ",", "[SEP]", "[unused1]", "Na", "##gu", "##ib", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "showing", "signs", "of", "independence", "from", "Na", "##sser", "by", "di", "##stan", "##cing", "himself", "from", "the", "RC", "##C", "'", "##s", "land", "reform", "decree", "##s", "and", "drawing", "closer", "to", "Egypt", "'", "##s", "established", "political", "forces", "namely", "the", "W", "##af", "##d", "and", "the", "Brotherhood", "[unused6]", "[SEP]", "[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "resolved", "[unused4]", "[unused5]", "to", "de", "##pose", "him", "When", "Na", "##gu", "##ib", "began", "showing", "signs", "of", "independence", "from", "Na", "##sser", "by", "di", "##stan", "##cing", "himself", "from", "the", "RC", "##C", "'", "##s", "land", "reform", "decree", "##s", "and", "drawing", "closer", "to", "Egypt", "'", "##s", "established", "political", "forces", "namely", "[SEP]", "[unused1]", "Na", "##gu", "##ib", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "showing", "signs", "of", "independence", "from", "Na", "##sser", "[unused6]", "[SEP]", "[unused1]", "Na", "##gu", "##ib", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "showing", "signs", "of", "independence", "from", "Na", "##sser", "[unused6]", "[SEP]", "[unused1]", "Na", "##gu", "##ib", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "showing", "signs", "of", "independence", "from", "Na", "##sser", "and", "drawing", "closer", "to", "Egypt", "'", "##s", "established", "political", "forces", "namely", "the", "W", "##af", "##d", "and", "the", "Brotherhood", "[unused6]", "[SEP]", "[unused1]", "Na", "##gu", "##ib", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "showing", "signs", "of", "independence", "from", "Na", "##sser", "and", "drawing", "closer", "to", "Egypt", "'", "##s", "established", "political", "forces", "namely", "the", "W", "##af", "##d", "and", "the", "Brotherhood", "[unused6]", "[SEP]", "[unused1]", "Na", "##sser", "[unused2]", "[unused3]", "resolved", "[unused4]", "[unused5]", "to", "de", "##pose", "him", "When", "Na", "##gu", "##ib", "began", "showing", "signs", "of", "independence", "from", "Na", "##sser", "and", "drawing", "closer", "to", "Egypt", "'", "##s", "established", "political", "forces", "namely", "the", "W", "##af", "##d", "and", "the", "Brotherhood", "[unused6]", "[SEP]", "[unused1]", "Na", "##gu", "##ib", "[unused2]", "[unused3]", "began", "[unused4]", "[unused5]", "showing", "signs", "of", "independence", "from", "Na", "##sser", "[unused6]", "[SEP]"]]}

input 375:  {"source": "When civilian government was introduced in Romblon by the Americans in 16 March 1901 , Banton was one of 11 new municipalities reinstated or created .\n"}
prediction:  {"predictions": [[1, 18393, 1633, 2, 3, 1108, 4, 5, 1141, 1104, 1429, 1207, 7473, 1332, 6688, 1433, 1108, 2234, 1107, 155, 20972, 4934, 1118, 1103, 4038, 1107, 1479, 1345, 5064, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1429, 1207, 7473, 2, 3, 1687, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6688, 1433, 2, 3, 1108, 2234, 4, 5, 1107, 155, 20972, 4934, 1118, 1103, 4038, 1107, 1479, 1345, 5064, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014232234098017216, -0.07004044204950333, -0.024350998923182487, -0.12112092971801758, -0.12116551399230957, -0.12116551399230957, -0.12116551399230957, -0.12116551399230957, -0.12116551399230957, -0.12116551399230957], "metadata": {"source_tokens": ["When", "civilian", "government", "was", "introduced", "in", "R", "##omb", "##lon", "by", "the", "Americans", "in", "16", "March", "1901", ",", "Ban", "##ton", "was", "one", "of", "11", "new", "municipalities", "reinstated", "or", "created", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ban", "##ton", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "one", "of", "11", "new", "municipalities", "When", "civilian", "government", "was", "introduced", "in", "R", "##omb", "##lon", "by", "the", "Americans", "in", "16", "March", "1901", "[unused6]", "[SEP]", "[unused1]", "11", "new", "municipalities", "[unused2]", "[unused3]", "created", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "civilian", "government", "[unused2]", "[unused3]", "was", "introduced", "[unused4]", "[unused5]", "in", "R", "##omb", "##lon", "by", "the", "Americans", "in", "16", "March", "1901", "[unused6]", "[SEP]"]]}

input 376:  {"source": "When the explosion tore through the hut , Stauffenberg was convinced that no one in the room could have survived .\n"}
prediction:  {"predictions": [[1, 1457, 3984, 15475, 8904, 2, 3, 1108, 5857, 4, 5, 1115, 1185, 1141, 1107, 1103, 1395, 1180, 1138, 4399, 1332, 1103, 7552, 9626, 1194, 1103, 16148, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1185, 1141, 1107, 1103, 1395, 2, 3, 1180, 1138, 4399, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 7552, 2, 3, 9626, 4, 5, 1194, 1103, 16148, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0008230209350585938, -0.011084174737334251, -0.048522867262363434, -0.02201223373413086, -0.022011756896972656, -0.022011756896972656, -0.022011756896972656, -0.022011756896972656, -0.022011756896972656, -0.022011756896972656], "metadata": {"source_tokens": ["When", "the", "explosion", "tore", "through", "the", "hut", ",", "St", "##au", "##ffe", "##nberg", "was", "convinced", "that", "no", "one", "in", "the", "room", "could", "have", "survived", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "St", "##au", "##ffe", "##nberg", "[unused2]", "[unused3]", "was", "convinced", "[unused4]", "[unused5]", "that", "no", "one", "in", "the", "room", "could", "have", "survived", "When", "the", "explosion", "tore", "through", "the", "hut", "[unused6]", "[SEP]", "[unused1]", "no", "one", "in", "the", "room", "[unused2]", "[unused3]", "could", "have", "survived", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "the", "explosion", "[unused2]", "[unused3]", "tore", "[unused4]", "[unused5]", "through", "the", "hut", "[unused6]", "[SEP]"]]}

input 377:  {"source": "While pursuing his MFA at Columbia in New York , Scieszka painted apartments .\n"}
prediction:  {"predictions": [[1, 20452, 1905, 1584, 1968, 2, 3, 4331, 4, 5, 10417, 1799, 12137, 1117, 150, 8842, 1120, 3132, 1107, 1203, 1365, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0018126446520909667, -0.03881645202636719, -0.03979897499084473, -0.03979897499084473, -0.03979897499084473, -0.03979897499084473, -0.03979897499084473, -0.03979897499084473, -0.03979897499084473, -0.03979897499084473], "metadata": {"source_tokens": ["While", "pursuing", "his", "M", "##FA", "at", "Columbia", "in", "New", "York", ",", "Sc", "##ies", "##z", "##ka", "painted", "apartments", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sc", "##ies", "##z", "##ka", "[unused2]", "[unused3]", "painted", "[unused4]", "[unused5]", "apartments", "While", "pursuing", "his", "M", "##FA", "at", "Columbia", "in", "New", "York", "[unused6]", "[SEP]"]]}

input 378:  {"source": "Why the `` Epilogue '' is missing is unknown .\n"}
prediction:  {"predictions": [[1, 2009, 1103, 169, 28152, 142, 8508, 12733, 112, 28131, 1110, 3764, 2, 3, 1110, 4, 5, 3655, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 169, 28152, 142, 8508, 12733, 2, 3, 1110, 3764, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.037741098552942276, -0.010733491741120815, -0.0014147758483886719, -0.001476287841796875, -0.001476287841796875, -0.001476287841796875, -0.001476287841796875, -0.001476287841796875, -0.001476287841796875, -0.001476287841796875], "metadata": {"source_tokens": ["Why", "the", "`", "##`", "E", "##pi", "##logue", "'", "##'", "is", "missing", "is", "unknown", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Why", "the", "`", "##`", "E", "##pi", "##logue", "'", "##'", "is", "missing", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "unknown", "[unused6]", "[SEP]", "[unused1]", "the", "`", "##`", "E", "##pi", "##logue", "[unused2]", "[unused3]", "is", "missing", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 379:  {"source": "Wide acceptance of zero-energy building technology may require more government incentives or building code regulations , the development of recognized standards , or significant increases in the cost of conventional energy .\n"}
prediction:  {"predictions": [[1, 15268, 10030, 1104, 6756, 28137, 24475, 4873, 1459, 2815, 2, 3, 1336, 4752, 4, 5, 1167, 1433, 24273, 1137, 1459, 3463, 7225, 117, 1103, 1718, 1104, 3037, 4473, 117, 1137, 2418, 6986, 1107, 1103, 2616, 1104, 7228, 2308, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009136621840298176, -0.038575172424316406, -0.038481712341308594, -0.038481712341308594, -0.038481712341308594, -0.038481712341308594, -0.038481712341308594, -0.038481712341308594, -0.038481712341308594, -0.038481712341308594], "metadata": {"source_tokens": ["Wide", "acceptance", "of", "zero", "##-", "##ener", "##gy", "building", "technology", "may", "require", "more", "government", "incentives", "or", "building", "code", "regulations", ",", "the", "development", "of", "recognized", "standards", ",", "or", "significant", "increases", "in", "the", "cost", "of", "conventional", "energy", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Wide", "acceptance", "of", "zero", "##-", "##ener", "##gy", "building", "technology", "[unused2]", "[unused3]", "may", "require", "[unused4]", "[unused5]", "more", "government", "incentives", "or", "building", "code", "regulations", ",", "the", "development", "of", "recognized", "standards", ",", "or", "significant", "increases", "in", "the", "cost", "of", "conventional", "energy", "[unused6]", "[SEP]"]]}

input 380:  {"source": "With no assigned task , the Cosmos expressed concern for what Battra might do .\n"}
prediction:  {"predictions": [[1, 1103, 3291, 18818, 2, 3, 4448, 4, 5, 4517, 1111, 1184, 21928, 4487, 1547, 1202, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21928, 4487, 2, 3, 1547, 1202, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0010579957161098719, -0.012582085095345974, -0.002823352813720703, -0.0028657913208007812, -0.0028657913208007812, -0.0028657913208007812, -0.0028657913208007812, -0.0028657913208007812, -0.0028657913208007812, -0.0028657913208007812], "metadata": {"source_tokens": ["With", "no", "assigned", "task", ",", "the", "Co", "##smos", "expressed", "concern", "for", "what", "Bat", "##tra", "might", "do", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Co", "##smos", "[unused2]", "[unused3]", "expressed", "[unused4]", "[unused5]", "concern", "for", "what", "Bat", "##tra", "might", "do", "[unused6]", "[SEP]", "[unused1]", "Bat", "##tra", "[unused2]", "[unused3]", "might", "do", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 381:  {"source": "With the help of Morena , the goddess of the underworld , she has captivated Yaromir .\n"}
prediction:  {"predictions": [[1, 1131, 2, 3, 1144, 6707, 3121, 18588, 4, 5, 14680, 16071, 3161, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3046, 1605, 2, 3, 1110, 1103, 9659, 1104, 4, 5, 1103, 23796, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01994173601269722, -0.004043059889227152, -0.021735191345214844, -0.021871089935302734, -0.021871089935302734, -0.021871089935302734, -0.021871089935302734, -0.021871089935302734, -0.021871089935302734, -0.021871089935302734], "metadata": {"source_tokens": ["With", "the", "help", "of", "More", "##na", ",", "the", "goddess", "of", "the", "underworld", ",", "she", "has", "cap", "##ti", "##vated", "Ya", "##rom", "##ir", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "she", "[unused2]", "[unused3]", "has", "cap", "##ti", "##vated", "[unused4]", "[unused5]", "Ya", "##rom", "##ir", "[unused6]", "[SEP]", "[unused1]", "More", "##na", "[unused2]", "[unused3]", "is", "the", "goddess", "of", "[unused4]", "[unused5]", "the", "underworld", "[unused6]", "[SEP]"]]}

input 382:  {"source": "With this act , Russia was officially transformed from an absolute monarchy into a constitutional one , though the exact extent of just `` how '' constitutional quickly became the subject of debate , based upon the emperor 's subsequent actions .\n"}
prediction:  {"predictions": [[1, 2733, 2, 3, 1108, 3184, 8272, 4, 5, 1121, 1126, 7846, 14358, 1154, 170, 7950, 1141, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2733, 2, 3, 1108, 8272, 4, 5, 1121, 1126, 7846, 14358, 1463, 1103, 6129, 6102, 1104, 1198, 169, 28152, 1293, 112, 28131, 7950, 1976, 1245, 1103, 2548, 1104, 5655, 117, 1359, 1852, 1103, 6821, 112, 1116, 4194, 3721, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7950, 2, 3, 1976, 1245, 4, 5, 1103, 2548, 1104, 5655, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.018527934327721596, -0.06664758920669556, -0.13135956227779388, -0.2938241958618164, -0.2815368175506592, -0.2815368175506592, -0.2815368175506592, -0.2815368175506592, -0.2815368175506592, -0.2815368175506592], "metadata": {"source_tokens": ["With", "this", "act", ",", "Russia", "was", "officially", "transformed", "from", "an", "absolute", "monarchy", "into", "a", "constitutional", "one", ",", "though", "the", "exact", "extent", "of", "just", "`", "##`", "how", "'", "##'", "constitutional", "quickly", "became", "the", "subject", "of", "debate", ",", "based", "upon", "the", "emperor", "'", "##s", "subsequent", "actions", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Russia", "[unused2]", "[unused3]", "was", "officially", "transformed", "[unused4]", "[unused5]", "from", "an", "absolute", "monarchy", "into", "a", "constitutional", "one", "[unused6]", "[SEP]", "[unused1]", "Russia", "[unused2]", "[unused3]", "was", "transformed", "[unused4]", "[unused5]", "from", "an", "absolute", "monarchy", "though", "the", "exact", "extent", "of", "just", "`", "##`", "how", "'", "##'", "constitutional", "quickly", "became", "the", "subject", "of", "debate", ",", "based", "upon", "the", "emperor", "'", "##s", "subsequent", "actions", "[unused6]", "[SEP]", "[unused1]", "constitutional", "[unused2]", "[unused3]", "quickly", "became", "[unused4]", "[unused5]", "the", "subject", "of", "debate", "[unused6]", "[SEP]"]]}

input 383:  {"source": "With versions in 1/48 , 1/72 , 1/96 , and 1/144 scale , Big Gun Model Warship combat clubs have rules that make provisions for cannon caliber and armor thickness to be scaled according to that which existed on the prototype vessel .\n"}
prediction:  {"predictions": [[1, 1115, 2, 3, 5131, 4, 5, 1113, 1103, 8933, 5832, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2562, 11274, 6747, 6238, 3157, 4127, 3514, 2, 3, 1138, 4, 5, 2995, 1115, 1294, 8939, 1111, 12136, 17836, 1105, 8526, 15830, 1106, 1129, 21297, 2452, 1106, 1115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2995, 2, 3, 1294, 4, 5, 8939, 1111, 12136, 17836, 1105, 8526, 15830, 1106, 1129, 21297, 2452, 1106, 1115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2562, 11274, 6747, 6238, 3157, 4127, 3514, 2, 3, 1138, 4, 5, 2995, 1556, 3827, 1107, 122, 28148, 28139, 1559, 1477, 1105, 122, 28139, 17175, 1527, 3418, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01753091812133789, -0.027136344462633133, -0.11918198317289352, -0.11122332513332367, -0.26711034774780273, -0.2678353786468506, -0.2678353786468506, -0.2678353786468506, -0.2678353786468506, -0.2678353786468506], "metadata": {"source_tokens": ["With", "versions", "in", "1", "##/", "##48", ",", "1", "##/", "##7", "##2", ",", "1", "##/", "##9", "##6", ",", "and", "1", "##/", "##14", "##4", "scale", ",", "Big", "Gun", "Model", "Wars", "##hip", "combat", "clubs", "have", "rules", "that", "make", "provisions", "for", "cannon", "caliber", "and", "armor", "thickness", "to", "be", "scaled", "according", "to", "that", "which", "existed", "on", "the", "prototype", "vessel", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "that", "[unused2]", "[unused3]", "existed", "[unused4]", "[unused5]", "on", "the", "prototype", "vessel", "[unused6]", "[SEP]", "[unused1]", "Big", "Gun", "Model", "Wars", "##hip", "combat", "clubs", "[unused2]", "[unused3]", "have", "[unused4]", "[unused5]", "rules", "that", "make", "provisions", "for", "cannon", "caliber", "and", "armor", "thickness", "to", "be", "scaled", "according", "to", "that", "[unused6]", "[SEP]", "[unused1]", "rules", "[unused2]", "[unused3]", "make", "[unused4]", "[unused5]", "provisions", "for", "cannon", "caliber", "and", "armor", "thickness", "to", "be", "scaled", "according", "to", "that", "[unused6]", "[SEP]", "[unused1]", "Big", "Gun", "Model", "Wars", "##hip", "combat", "clubs", "[unused2]", "[unused3]", "have", "[unused4]", "[unused5]", "rules", "With", "versions", "in", "1", "##\\", "##/", "##7", "##2", "and", "1", "##/", "##14", "##4", "scale", "[unused6]", "[SEP]"]]}

Batch 3 Test Time =  98.64178848266602  s
Decodertime : 0.0001766681671142578
g_f_logprobs : 0.03899407386779785
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.03900647163391113
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.03897500038146973
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.03896927833557129
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.03896069526672363
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.03892087936401367
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.03906726837158203
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.03901362419128418
Decodertime : 0.000156402587890625
g_f_logprobs : 0.038933753967285156
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.03905653953552246
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.03983163833618164
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.03905749320983887
Decodertime : 0.000152587890625
g_f_logprobs : 0.039073944091796875
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.03903532028198242
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.03902554512023926
Decodertime : 0.000152587890625
g_f_logprobs : 0.0389864444732666
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.038971662521362305
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.03897857666015625
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.03892350196838379
Decodertime : 0.00017881393432617188
g_f_logprobs : 0.03894329071044922
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.039057016372680664
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.03902626037597656
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.039083242416381836
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.03895759582519531
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.038968801498413086
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.039078474044799805
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.038953304290771484
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.03902721405029297
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.03898143768310547
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.039010047912597656
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.039045095443725586
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.038987159729003906
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.03892827033996582
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.03900766372680664
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.03900504112243652
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.03897547721862793
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.03911161422729492
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.03902435302734375
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.03899955749511719
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.038939714431762695
Decodertime : 0.00019049644470214844
g_f_logprobs : 0.03906536102294922
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.039093732833862305
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.03903317451477051
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.03908181190490723
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.03901171684265137
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.03899574279785156
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.03901481628417969
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.039034366607666016
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.03912353515625
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.03906393051147461
beam_search_time: 2.029860258102417 s
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.058101654052734375
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.0581967830657959
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.057970523834228516
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.05817770957946777
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.058098793029785156
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.05831170082092285
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.058004140853881836
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.0579984188079834
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.058104753494262695
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.0581355094909668
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.05815386772155762
Decodertime : 0.00018835067749023438
g_f_logprobs : 0.058107852935791016
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.05802273750305176
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.0583188533782959
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.05817365646362305
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.05803680419921875
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.0582425594329834
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.058234453201293945
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.05816936492919922
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.05841207504272461
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.05832862854003906
Decodertime : 0.000156402587890625
g_f_logprobs : 0.05811262130737305
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.05803871154785156
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.058176517486572266
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.0581209659576416
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.05818057060241699
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.05816364288330078
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.05813241004943848
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.0581972599029541
Decodertime : 0.000152587890625
g_f_logprobs : 0.058241844177246094
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.05819988250732422
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.05816841125488281
Decodertime : 0.00017523765563964844
g_f_logprobs : 0.05827665328979492
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.05817413330078125
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.05821418762207031
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.05803203582763672
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.05817699432373047
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.05824542045593262
Decodertime : 0.000152587890625
g_f_logprobs : 0.05808424949645996
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.05807352066040039
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.058086395263671875
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.058331966400146484
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.058153390884399414
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.058136701583862305
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.058115482330322266
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.05823063850402832
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.05812358856201172
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.05823540687561035
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.0582883358001709
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.05820178985595703
beam_search_time: 2.9869329929351807 s
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.0823509693145752
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.08181977272033691
Decodertime : 0.000164031982421875
g_f_logprobs : 0.08194279670715332
Decodertime : 0.00017523765563964844
g_f_logprobs : 0.0820913314819336
Decodertime : 0.000152587890625
g_f_logprobs : 0.0821237564086914
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.08236289024353027
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.08228039741516113
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.08210134506225586
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.08213663101196289
Decodertime : 0.0001697540283203125
g_f_logprobs : 0.08197474479675293
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.08217310905456543
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.08201742172241211
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.08214902877807617
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.08206558227539062
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.08199071884155273
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.08214378356933594
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.08212780952453613
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.08202362060546875
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.08213949203491211
Decodertime : 0.000152587890625
g_f_logprobs : 0.08208847045898438
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.08215951919555664
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.08219099044799805
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.08223366737365723
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.0821690559387207
Decodertime : 0.00017523765563964844
g_f_logprobs : 0.08220314979553223
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.0821843147277832
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.08214259147644043
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.08212137222290039
Decodertime : 0.000156402587890625
g_f_logprobs : 0.08218812942504883
Decodertime : 0.00016689300537109375
g_f_logprobs : 0.08206033706665039
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.08235692977905273
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.08213567733764648
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.08218193054199219
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.08261513710021973
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.0821375846862793
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.08212542533874512
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.08238697052001953
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.08231949806213379
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.08212757110595703
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.0823369026184082
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.08212161064147949
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.0821843147277832
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.08227968215942383
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.08212423324584961
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.08209776878356934
Decodertime : 0.0001742839813232422
g_f_logprobs : 0.08223652839660645
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.08225631713867188
Decodertime : 0.000152587890625
g_f_logprobs : 0.08207535743713379
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.08219051361083984
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.08231163024902344
beam_search_time: 4.187511920928955 s
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.11025810241699219
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.10941720008850098
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.10952091217041016
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.10974812507629395
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.10959458351135254
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.10955119132995605
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.10970306396484375
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.10972785949707031
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.10968017578125
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.10946249961853027
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.10961103439331055
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.10940289497375488
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.10942506790161133
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.10967469215393066
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.10954499244689941
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.10959649085998535
Decodertime : 0.0001747608184814453
g_f_logprobs : 0.10960984230041504
Decodertime : 0.000156402587890625
g_f_logprobs : 0.10983824729919434
Decodertime : 0.00017213821411132812
g_f_logprobs : 0.10950016975402832
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.10975503921508789
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.1095724105834961
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.10958409309387207
Decodertime : 0.000156402587890625
g_f_logprobs : 0.10938501358032227
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.10973787307739258
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.10971903800964355
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.10961747169494629
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.10945463180541992
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.11061358451843262
Decodertime : 0.0002155303955078125
g_f_logprobs : 0.10941672325134277
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.10947227478027344
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.10956501960754395
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.1097109317779541
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.10945367813110352
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.1102299690246582
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.1096653938293457
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.10956215858459473
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.10964655876159668
Decodertime : 0.00017452239990234375
g_f_logprobs : 0.10996127128601074
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.10952305793762207
Decodertime : 0.000152587890625
g_f_logprobs : 0.10969924926757812
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.10973787307739258
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.10963988304138184
Decodertime : 0.00017380714416503906
g_f_logprobs : 0.10960102081298828
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.10981416702270508
Decodertime : 0.000152587890625
g_f_logprobs : 0.10961318016052246
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.10966706275939941
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.1095726490020752
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.10975170135498047
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.11009764671325684
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.10967326164245605
beam_search_time: 5.564093112945557 s
Decodertime : 0.00016045570373535156
g_f_logprobs : 0.11012458801269531
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.10953950881958008
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.10931587219238281
Decodertime : 0.00016260147094726562
g_f_logprobs : 0.10965299606323242
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.10964035987854004
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.10947585105895996
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.10952448844909668
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.1095428466796875
Decodertime : 0.00017642974853515625
g_f_logprobs : 0.1094672679901123
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.10935020446777344
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.1093282699584961
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.10953712463378906
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.10941815376281738
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.10975837707519531
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.10996675491333008
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.10973215103149414
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.1108086109161377
Decodertime : 0.0001957416534423828
g_f_logprobs : 0.10965156555175781
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.10959744453430176
Decodertime : 0.00017261505126953125
g_f_logprobs : 0.10947465896606445
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.10948896408081055
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.10953354835510254
Decodertime : 0.0001697540283203125
g_f_logprobs : 0.1093909740447998
Decodertime : 0.000152587890625
g_f_logprobs : 0.10949325561523438
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.10955262184143066
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.10953688621520996
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.10972118377685547
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.10987591743469238
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.10966706275939941
Decodertime : 0.00018548965454101562
g_f_logprobs : 0.10943722724914551
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.10947775840759277
Decodertime : 0.000152587890625
g_f_logprobs : 0.10958218574523926
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.10957670211791992
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.10965490341186523
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.1097557544708252
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.10959243774414062
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.10950565338134766
Decodertime : 0.000152587890625
g_f_logprobs : 0.10996365547180176
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.10966300964355469
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.10979127883911133
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.1096494197845459
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.10976839065551758
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.1096200942993164
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.10983395576477051
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.10965490341186523
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.10972213745117188
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.10971903800964355
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.1097707748413086
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.10963082313537598
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.1099538803100586
beam_search_time: 5.563192367553711 s
Decodertime : 0.00018477439880371094
g_f_logprobs : 0.1349327564239502
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.13398528099060059
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.13407444953918457
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.13411760330200195
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.13429713249206543
Decodertime : 0.00018143653869628906
g_f_logprobs : 0.13420486450195312
Decodertime : 0.0001728534698486328
g_f_logprobs : 0.13448357582092285
Decodertime : 0.0001704692840576172
g_f_logprobs : 0.1341097354888916
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.13410162925720215
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.13405942916870117
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.13400745391845703
Decodertime : 0.0001690387725830078
g_f_logprobs : 0.13401484489440918
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.1339569091796875
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.134246826171875
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.13401460647583008
Decodertime : 0.000164031982421875
g_f_logprobs : 0.13400506973266602
Decodertime : 0.00017023086547851562
g_f_logprobs : 0.13391923904418945
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.13413310050964355
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.13401389122009277
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.13414669036865234
Decodertime : 0.000156402587890625
g_f_logprobs : 0.13430356979370117
Decodertime : 0.00018525123596191406
g_f_logprobs : 0.13396501541137695
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.1343080997467041
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.13457250595092773
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.13443279266357422
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.13424181938171387
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.13410115242004395
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.1341707706451416
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.1339411735534668
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.13492488861083984
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.13407158851623535
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.13419842720031738
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.13388752937316895
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.13399267196655273
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.13414549827575684
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.13422131538391113
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.134080171585083
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.1340804100036621
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.13399934768676758
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.13428735733032227
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.1340188980102539
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.13453054428100586
Decodertime : 0.000186920166015625
g_f_logprobs : 0.13398122787475586
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.13427734375
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.1343848705291748
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.13406848907470703
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.13404297828674316
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.13433218002319336
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.1342179775238037
Decodertime : 0.0001735687255859375
g_f_logprobs : 0.13439464569091797
beam_search_time: 6.7910614013671875 s
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.15685248374938965
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.15581393241882324
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.155534029006958
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.1555929183959961
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.15564990043640137
Decodertime : 0.00017189979553222656
g_f_logprobs : 0.15564942359924316
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.15551114082336426
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.15570902824401855
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.15553832054138184
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.15563225746154785
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.15546703338623047
Decodertime : 0.000156402587890625
g_f_logprobs : 0.1556706428527832
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.1557459831237793
Decodertime : 0.00018739700317382812
g_f_logprobs : 0.15608501434326172
Decodertime : 0.00015974044799804688
g_f_logprobs : 0.15572190284729004
Decodertime : 0.00016021728515625
g_f_logprobs : 0.15620708465576172
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.15586018562316895
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.1559925079345703
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.15585732460021973
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.15569591522216797
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.15557408332824707
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.15590929985046387
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.15575957298278809
Decodertime : 0.00017833709716796875
g_f_logprobs : 0.15613317489624023
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.1558680534362793
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.15620827674865723
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.15563702583312988
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.15606975555419922
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.15561413764953613
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.15602660179138184
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.15563154220581055
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.15598273277282715
Decodertime : 0.0001678466796875
g_f_logprobs : 0.15560388565063477
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.15619444847106934
Decodertime : 0.00018525123596191406
g_f_logprobs : 0.15583252906799316
beam_search_time: 5.511902093887329 s
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.15678834915161133
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.15561985969543457
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.15557599067687988
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.15543818473815918
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.15590310096740723
Decodertime : 0.000164031982421875
g_f_logprobs : 0.15559077262878418
Decodertime : 0.000152587890625
g_f_logprobs : 0.15561532974243164
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.15572619438171387
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.15625262260437012
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.1557149887084961
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.15583109855651855
Decodertime : 0.0001709461212158203
g_f_logprobs : 0.15565967559814453
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.15599775314331055
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.1558682918548584
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.15590214729309082
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.15557622909545898
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.1558849811553955
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.15561270713806152
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.1556236743927002
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.1556103229522705
Decodertime : 0.0001862049102783203
g_f_logprobs : 0.15581297874450684
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.15617632865905762
beam_search_time: 3.464266538619995 s
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.15698456764221191
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.1559126377105713
Decodertime : 0.00017380714416503906
g_f_logprobs : 0.15569853782653809
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.15585565567016602
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.15599775314331055
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.15570545196533203
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.15633368492126465
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.155778169631958
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.15595245361328125
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.15612196922302246
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.15613412857055664
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.15604948997497559
Decodertime : 0.0001614093780517578
g_f_logprobs : 0.1558980941772461
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.1558213233947754
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.1562492847442627
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.15601038932800293
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.1562643051147461
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.15587115287780762
Decodertime : 0.00016689300537109375
g_f_logprobs : 0.1558544635772705
Decodertime : 0.0001876354217529297
g_f_logprobs : 0.15603256225585938
beam_search_time: 3.153815984725952 s
Decodertime : 0.0001590251922607422
g_f_logprobs : 0.15694260597229004
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.15575432777404785
beam_search_time: 0.3159489631652832 s
input 384:  {"source": "Wright was the subject of `` This Is Your Life '' on two occasions : in May 1961 when he was surprised by Eamonn Andrews , and in January 1990 , when Michael Aspel surprised him at Thames Television 's Teddington Studios .\n"}
prediction:  {"predictions": [[1, 1847, 1249, 10522, 2, 3, 3753, 4, 5, 1140, 1120, 11055, 4552, 112, 1116, 6564, 18169, 5406, 1356, 1997, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5445, 2, 3, 1108, 4, 5, 1103, 2548, 1104, 169, 28152, 1188, 2181, 2353, 2583, 112, 28131, 1113, 1160, 6070, 131, 1107, 1318, 2920, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 3753, 4, 5, 1118, 142, 25902, 1179, 8946, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1847, 1249, 10522, 2, 3, 3753, 4, 5, 1140, 1120, 11055, 4552, 112, 1116, 6564, 18169, 5406, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1847, 1249, 10522, 2, 3, 3753, 4, 5, 1140, 1120, 11055, 4552, 112, 1116, 6564, 18169, 5406, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1847, 1249, 10522, 2, 3, 3753, 4, 5, 1140, 1120, 11055, 4552, 112, 1116, 6564, 18169, 5406, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1847, 1249, 10522, 2, 3, 3753, 4, 5, 1140, 1120, 11055, 4552, 112, 1116, 6564, 18169, 5406, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1847, 1249, 10522, 2, 3, 3753, 4, 5, 1140, 1120, 11055, 4552, 112, 1116, 6564, 18169, 5406, 6, 102, 102, 102, 102, 1, 1847, 1249, 10522, 2, 3, 3753, 4, 5, 1140, 1120, 11055, 4552, 112, 1116, 6564, 18169, 5406, 6, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.056029900908470154, -0.09951721876859665, -0.06708275526762009, -0.07962390780448914, -0.11380330473184586, -0.11954303085803986, -0.11766505241394043, -0.12378742545843124, -0.12895995378494263, -0.2812455892562866], "metadata": {"source_tokens": ["Wright", "was", "the", "subject", "of", "`", "##`", "This", "Is", "Your", "Life", "'", "##'", "on", "two", "occasions", ":", "in", "May", "1961", "when", "he", "was", "surprised", "by", "E", "##amon", "##n", "Andrews", ",", "and", "in", "January", "1990", ",", "when", "Michael", "As", "##pel", "surprised", "him", "at", "Thames", "Television", "'", "##s", "Ted", "##dington", "Studios", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Michael", "As", "##pel", "[unused2]", "[unused3]", "surprised", "[unused4]", "[unused5]", "him", "at", "Thames", "Television", "'", "##s", "Ted", "##dington", "Studios", "January", "1990", "[unused6]", "[SEP]", "[unused1]", "Wright", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "subject", "of", "`", "##`", "This", "Is", "Your", "Life", "'", "##'", "on", "two", "occasions", ":", "in", "May", "1961", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "surprised", "[unused4]", "[unused5]", "by", "E", "##amon", "##n", "Andrews", "[unused6]", "[SEP]", "[unused1]", "Michael", "As", "##pel", "[unused2]", "[unused3]", "surprised", "[unused4]", "[unused5]", "him", "at", "Thames", "Television", "'", "##s", "Ted", "##dington", "Studios", "[unused6]", "[SEP]", "[unused1]", "Michael", "As", "##pel", "[unused2]", "[unused3]", "surprised", "[unused4]", "[unused5]", "him", "at", "Thames", "Television", "'", "##s", "Ted", "##dington", "Studios", "[unused6]", "[SEP]", "[unused1]", "Michael", "As", "##pel", "[unused2]", "[unused3]", "surprised", "[unused4]", "[unused5]", "him", "at", "Thames", "Television", "'", "##s", "Ted", "##dington", "Studios", "[unused6]", "[SEP]", "[unused1]", "Michael", "As", "##pel", "[unused2]", "[unused3]", "surprised", "[unused4]", "[unused5]", "him", "at", "Thames", "Television", "'", "##s", "Ted", "##dington", "Studios", "[unused6]", "[SEP]", "[unused1]", "Michael", "As", "##pel", "[unused2]", "[unused3]", "surprised", "[unused4]", "[unused5]", "him", "at", "Thames", "Television", "'", "##s", "Ted", "##dington", "Studios", "[unused6]", "[SEP]", "[unused1]", "Michael", "As", "##pel", "[unused2]", "[unused3]", "surprised", "[unused4]", "[unused5]", "him", "at", "Thames", "Television", "'", "##s", "Ted", "##dington", "Studios", "[unused6]", "[SEP]"]]}

input 385:  {"source": "`` Black Water '' became one of the few records by any act released as a B-side to another Hot 100 hit `` before '' topping the Hot 100 itself .\n"}
prediction:  {"predictions": [[1, 2117, 4434, 2, 3, 1245, 4, 5, 1141, 1104, 1103, 1374, 3002, 1118, 1251, 2496, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1251, 2496, 2, 3, 1308, 4, 5, 1112, 170, 139, 28137, 5570, 1106, 1330, 4126, 1620, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2117, 4434, 2, 3, 1245, 4, 5, 1141, 1104, 1103, 1374, 3002, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2117, 4434, 2, 3, 1245, 4, 5, 1141, 1104, 1103, 1374, 3002, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2117, 4434, 2, 3, 1245, 4, 5, 1141, 1104, 1103, 1374, 3002, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02653556317090988, -0.04436592757701874, -0.13317756354808807, -0.16327457129955292, -0.18606208264827728, -0.2856004238128662, -0.2861306667327881, -0.2861306667327881, -0.2861306667327881, -0.2861306667327881], "metadata": {"source_tokens": ["`", "##`", "Black", "Water", "'", "##'", "became", "one", "of", "the", "few", "records", "by", "any", "act", "released", "as", "a", "B", "##-", "##side", "to", "another", "Hot", "100", "hit", "`", "##`", "before", "'", "##'", "topping", "the", "Hot", "100", "itself", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Black", "Water", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "one", "of", "the", "few", "records", "by", "any", "act", "[unused6]", "[SEP]", "[unused1]", "any", "act", "[unused2]", "[unused3]", "released", "[unused4]", "[unused5]", "as", "a", "B", "##-", "##side", "to", "another", "Hot", "100", "[unused6]", "[SEP]", "[unused1]", "Black", "Water", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "one", "of", "the", "few", "records", "[unused6]", "[SEP]", "[unused1]", "Black", "Water", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "one", "of", "the", "few", "records", "[unused6]", "[SEP]", "[unused1]", "Black", "Water", "[unused2]", "[unused3]", "became", "[unused4]", "[unused5]", "one", "of", "the", "few", "records", "[unused6]", "[SEP]"]]}

input 386:  {"source": "`` For a list of all medalists , please see the List of Great American Beer Festival medalists ''\n"}
prediction:  {"predictions": [[1, 4268, 2, 3, 1267, 4, 5, 1103, 5619, 1104, 2038, 1237, 16380, 2263, 15257, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02457955852150917, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562, -0.021997451782226562], "metadata": {"source_tokens": ["`", "##`", "For", "a", "list", "of", "all", "medalist", "##s", ",", "please", "see", "the", "List", "of", "Great", "American", "Beer", "Festival", "medalist", "##s", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "please", "[unused2]", "[unused3]", "see", "[unused4]", "[unused5]", "the", "List", "of", "Great", "American", "Beer", "Festival", "medalist", "##s", "[unused6]", "[SEP]"]]}

input 387:  {"source": "`` Greenfish '' was launched by the Electric Boat Co. , Groton , Conn. , 21 December 1945 ; sponsored by Mrs. Thomas J. Doyle ; and commissioned 7 June 1946 , Comdr. R. M. Metcalf commanding .\n"}
prediction:  {"predictions": [[1, 2565, 6529, 2, 3, 1108, 2536, 4, 5, 1118, 1103, 6763, 12936, 3291, 28138, 117, 144, 10595, 1320, 117, 16752, 1179, 28138, 117, 1626, 1382, 2481, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2565, 6529, 2, 3, 4156, 4, 5, 128, 1340, 3064, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2565, 6529, 2, 3, 1108, 2536, 4, 5, 1118, 1103, 6763, 12936, 3291, 28138, 144, 10595, 1320, 16752, 1179, 28138, 1626, 1382, 2481, 5988, 1118, 2823, 28138, 1819, 147, 28138, 11296, 5988, 1118, 2823, 28138, 1819, 147, 28138, 11296, 5988, 1118, 2823, 28138, 1819, 147, 28138, 11296, 5988, 1118, 102, 1, 2565, 6529, 2, 3, 1108, 2536, 4, 5, 1118, 1103, 6763, 12936, 3291, 28138, 144, 10595, 1320, 16752, 1179, 28138, 1626, 1382, 2481, 5988, 1118, 2823, 28138, 1819, 147, 28138, 11296, 5988, 1118, 2823, 28138, 1819, 147, 28138, 11296, 5988, 1118, 2823, 28138, 1819, 147, 28138, 11296, 5988, 1118, 102, 1, 2565, 6529, 2, 3, 1108, 2536, 4, 5, 1118, 1103, 6763, 12936, 3291, 28138, 144, 10595, 1320, 16752, 1179, 28138, 1626, 1382, 2481, 5988, 1118, 2823, 28138, 1819, 147, 28138, 11296, 5988, 1118, 2823, 28138, 1819, 147, 28138, 11296, 5988, 1118, 2823, 28138, 1819, 147, 28138, 11296, 5988, 1118, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.029724115505814552, -0.09414856880903244, -0.10662098228931427, -0.12470605969429016, -0.13008512556552887, -0.28946805000305176, -0.25048744678497314, -0.25048744678497314, -0.25048744678497314, -0.25048744678497314], "metadata": {"source_tokens": ["`", "##`", "Green", "##fish", "'", "##'", "was", "launched", "by", "the", "Electric", "Boat", "Co", "##.", ",", "G", "##rot", "##on", ",", "Con", "##n", "##.", ",", "21", "December", "1945", ";", "sponsored", "by", "Mrs", "##.", "Thomas", "J", "##.", "Doyle", ";", "and", "commissioned", "7", "June", "1946", ",", "Co", "##m", "##dr", "##.", "R", "##.", "M", "##.", "Met", "##cal", "##f", "commanding", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Green", "##fish", "[unused2]", "[unused3]", "was", "launched", "[unused4]", "[unused5]", "by", "the", "Electric", "Boat", "Co", "##.", ",", "G", "##rot", "##on", ",", "Con", "##n", "##.", ",", "21", "December", "1945", "[unused6]", "[SEP]", "[unused1]", "Green", "##fish", "[unused2]", "[unused3]", "commissioned", "[unused4]", "[unused5]", "7", "June", "1946", "[unused6]", "[SEP]", "[unused1]", "Green", "##fish", "[unused2]", "[unused3]", "was", "launched", "[unused4]", "[unused5]", "by", "the", "Electric", "Boat", "Co", "##.", "G", "##rot", "##on", "Con", "##n", "##.", "21", "December", "1945", "sponsored", "by", "Mrs", "##.", "Thomas", "J", "##.", "Doyle", "sponsored", "by", "Mrs", "##.", "Thomas", "J", "##.", "Doyle", "sponsored", "by", "Mrs", "##.", "Thomas", "J", "##.", "Doyle", "sponsored", "by", "[SEP]", "[unused1]", "Green", "##fish", "[unused2]", "[unused3]", "was", "launched", "[unused4]", "[unused5]", "by", "the", "Electric", "Boat", "Co", "##.", "G", "##rot", "##on", "Con", "##n", "##.", "21", "December", "1945", "sponsored", "by", "Mrs", "##.", "Thomas", "J", "##.", "Doyle", "sponsored", "by", "Mrs", "##.", "Thomas", "J", "##.", "Doyle", "sponsored", "by", "Mrs", "##.", "Thomas", "J", "##.", "Doyle", "sponsored", "by", "[SEP]", "[unused1]", "Green", "##fish", "[unused2]", "[unused3]", "was", "launched", "[unused4]", "[unused5]", "by", "the", "Electric", "Boat", "Co", "##.", "G", "##rot", "##on", "Con", "##n", "##.", "21", "December", "1945", "sponsored", "by", "Mrs", "##.", "Thomas", "J", "##.", "Doyle", "sponsored", "by", "Mrs", "##.", "Thomas", "J", "##.", "Doyle", "sponsored", "by", "Mrs", "##.", "Thomas", "J", "##.", "Doyle", "sponsored", "by", "[SEP]"]]}

input 388:  {"source": "`` It started from modest beginnings and became a gigantic charity '' .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1408, 4, 5, 1121, 11263, 19304, 1105, 1245, 170, 23275, 6630, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.05392864719033241, -0.021995067596435547, -0.021995067596435547, -0.021995067596435547, -0.021995067596435547, -0.021995067596435547, -0.021995067596435547, -0.021995067596435547, -0.021995067596435547, -0.021995067596435547], "metadata": {"source_tokens": ["`", "##`", "It", "started", "from", "modest", "beginnings", "and", "became", "a", "gigantic", "charity", "'", "##'", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "started", "[unused4]", "[unused5]", "from", "modest", "beginnings", "and", "became", "a", "gigantic", "charity", "[unused6]", "[SEP]"]]}

input 389:  {"source": "`` Le Griffon '' is reported to be the `` Holy Grail '' of Great Lakes shipwreck hunters .\n"}
prediction:  {"predictions": [[1, 3180, 144, 17387, 1320, 2, 3, 1110, 2103, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3180, 144, 17387, 1320, 2, 3, 1106, 1129, 4, 5, 1103, 169, 28152, 3930, 144, 12797, 112, 28131, 1104, 2038, 10180, 2062, 2246, 21486, 13202, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.012928079813718796, -0.0054413676261901855, -0.022035598754882812, -0.02203655242919922, -0.02203655242919922, -0.02203655242919922, -0.02203655242919922, -0.02203655242919922, -0.02203655242919922, -0.02203655242919922], "metadata": {"source_tokens": ["`", "##`", "Le", "G", "##riff", "##on", "'", "##'", "is", "reported", "to", "be", "the", "`", "##`", "Holy", "G", "##rail", "'", "##'", "of", "Great", "Lakes", "ship", "##w", "##reck", "hunters", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Le", "G", "##riff", "##on", "[unused2]", "[unused3]", "is", "reported", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Le", "G", "##riff", "##on", "[unused2]", "[unused3]", "to", "be", "[unused4]", "[unused5]", "the", "`", "##`", "Holy", "G", "##rail", "'", "##'", "of", "Great", "Lakes", "ship", "##w", "##reck", "hunters", "[unused6]", "[SEP]"]]}

input 390:  {"source": "`` See also : Grand Duke of Luxembourg , List of Prime Ministers of Luxembourg ''\n"}
prediction:  {"predictions": [[1, 2224, 3131, 1104, 10665, 2, 3, 1110, 4, 5, 5619, 1104, 3460, 15102, 1104, 10665, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.008650409057736397, -0.0018954277038574219, -0.0023703575134277344, -0.0023703575134277344, -0.0023703575134277344, -0.0023703575134277344, -0.0023703575134277344, -0.0023703575134277344, -0.0023703575134277344, -0.0023703575134277344], "metadata": {"source_tokens": ["`", "##`", "See", "also", ":", "Grand", "Duke", "of", "Luxembourg", ",", "List", "of", "Prime", "Ministers", "of", "Luxembourg", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Grand", "Duke", "of", "Luxembourg", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "List", "of", "Prime", "Ministers", "of", "Luxembourg", "[unused6]", "[SEP]"]]}

input 391:  {"source": "`` The Cure '' topped the online music sales charts .\n"}
prediction:  {"predictions": [[1, 1109, 27121, 2, 3, 9065, 4, 5, 1103, 3294, 1390, 3813, 5896, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.00028273265343159437, -0.00018024444580078125, -0.00017881393432617188, -0.00017881393432617188, -0.00017881393432617188, -0.00017881393432617188, -0.00017881393432617188, -0.00017881393432617188, -0.00017881393432617188, -0.00017881393432617188], "metadata": {"source_tokens": ["`", "##`", "The", "Cure", "'", "##'", "topped", "the", "online", "music", "sales", "charts", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Cure", "[unused2]", "[unused3]", "topped", "[unused4]", "[unused5]", "the", "online", "music", "sales", "charts", "[unused6]", "[SEP]"]]}

input 392:  {"source": "he was one of only a few concert organists worldwide who supported themselves exclusively by giving recitals , concerts and master classes , without any supplement from teaching or church position .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1108, 4, 5, 1141, 1104, 1178, 170, 1374, 3838, 19209, 1116, 4529, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1178, 170, 1374, 3838, 19209, 1116, 4529, 2, 3, 2726, 7097, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1178, 170, 1374, 3838, 19209, 1116, 4529, 2, 3, 2726, 4, 5, 2310, 1118, 2368, 1231, 6617, 22159, 6460, 1105, 3283, 3553, 1443, 1251, 15491, 1121, 3679, 1137, 1749, 1700, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.015196376480162144, -0.12551626563072205, -0.10106181353330612, -0.13192987442016602, -0.1486191749572754, -0.1486191749572754, -0.1486191749572754, -0.1486191749572754, -0.1486191749572754, -0.1486191749572754], "metadata": {"source_tokens": ["he", "was", "one", "of", "only", "a", "few", "concert", "organist", "##s", "worldwide", "who", "supported", "themselves", "exclusively", "by", "giving", "re", "##ci", "##tals", ",", "concerts", "and", "master", "classes", ",", "without", "any", "supplement", "from", "teaching", "or", "church", "position", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "one", "of", "only", "a", "few", "concert", "organist", "##s", "worldwide", "[unused6]", "[SEP]", "[unused1]", "only", "a", "few", "concert", "organist", "##s", "worldwide", "[unused2]", "[unused3]", "supported", "exclusively", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "only", "a", "few", "concert", "organist", "##s", "worldwide", "[unused2]", "[unused3]", "supported", "[unused4]", "[unused5]", "themselves", "by", "giving", "re", "##ci", "##tals", "concerts", "and", "master", "classes", "without", "any", "supplement", "from", "teaching", "or", "church", "position", "[unused6]", "[SEP]"]]}

input 393:  {"source": "$ 300 million of bonds due Nov. 16 , 1993 , with equity - purchase warrants , indicating a 3 3\\/4 % coupon at par via Nomura International Ltd .\n"}
prediction:  {"predictions": [[1, 109, 3127, 1550, 1104, 10150, 1496, 14152, 28138, 1479, 117, 1949, 117, 1114, 12288, 118, 4779, 13178, 1116, 2, 3, 7713, 4, 5, 170, 124, 124, 28139, 1527, 110, 8707, 1320, 1120, 14247, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 109, 3127, 1550, 1104, 10150, 1496, 14152, 4779, 13178, 1116, 2, 3, 7713, 4, 5, 170, 124, 124, 28148, 28139, 1527, 110, 8707, 1320, 1120, 14247, 2258, 1302, 14535, 1570, 4492, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.07858504354953766, -0.11006215214729309, -0.07690072059631348, -0.07691621780395508, -0.07691621780395508, -0.07691621780395508, -0.07691621780395508, -0.07691621780395508, -0.07691621780395508, -0.07691621780395508], "metadata": {"source_tokens": ["$", "300", "million", "of", "bonds", "due", "Nov", "##.", "16", ",", "1993", ",", "with", "equity", "-", "purchase", "warrant", "##s", ",", "indicating", "a", "3", "3", "##\\", "##/", "##4", "%", "coup", "##on", "at", "par", "via", "No", "##mura", "International", "Ltd", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "$", "300", "million", "of", "bonds", "due", "Nov", "##.", "16", ",", "1993", ",", "with", "equity", "-", "purchase", "warrant", "##s", "[unused2]", "[unused3]", "indicating", "[unused4]", "[unused5]", "a", "3", "3", "##/", "##4", "%", "coup", "##on", "at", "par", "[unused6]", "[SEP]", "[unused1]", "$", "300", "million", "of", "bonds", "due", "Nov", "purchase", "warrant", "##s", "[unused2]", "[unused3]", "indicating", "[unused4]", "[unused5]", "a", "3", "3", "##\\", "##/", "##4", "%", "coup", "##on", "at", "par", "via", "No", "##mura", "International", "Ltd", "[unused6]", "[SEP]"]]}

input 394:  {"source": "( Separately , the Senate last week passed a bill permitting execution of terrorists who kill Americans abroad . )\n"}
prediction:  {"predictions": [[1, 17219, 2, 3, 2311, 4, 5, 4038, 6629, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3279, 2, 3, 2085, 4, 5, 170, 4550, 28049, 7581, 1104, 17219, 1314, 1989, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.007110682316124439, -0.061383411288261414, -0.03478550910949707, -0.03226613998413086, -0.03226613998413086, -0.03226613998413086, -0.03226613998413086, -0.03226613998413086, -0.03226613998413086, -0.03226613998413086], "metadata": {"source_tokens": ["(", "Sep", "##arate", "##ly", ",", "the", "Senate", "last", "week", "passed", "a", "bill", "permitting", "execution", "of", "terrorists", "who", "kill", "Americans", "abroad", ".", ")"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "terrorists", "[unused2]", "[unused3]", "kill", "[unused4]", "[unused5]", "Americans", "abroad", "[unused6]", "[SEP]", "[unused1]", "the", "Senate", "[unused2]", "[unused3]", "passed", "[unused4]", "[unused5]", "a", "bill", "permitting", "execution", "of", "terrorists", "last", "week", "[unused6]", "[SEP]"]]}

input 395:  {"source": "A San Francisco lawyer , Mr. Panelli rowed religiously when he first got the machine , but , he complains , it left grease marks on his carpet , `` and it was boring .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 1108, 4, 5, 12533, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 19073, 1116, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1286, 4, 5, 176, 15691, 6216, 1113, 1117, 10797, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 1727, 2948, 4545, 2, 3, 5105, 1174, 2689, 1193, 4, 5, 1165, 1119, 1148, 1400, 1103, 3395, 1148, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1400, 4, 5, 1103, 3395, 1148, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.17457044124603271, -0.13306711614131927, -0.06324253976345062, -0.11099383234977722, -0.1127043142914772, -0.12952399253845215, -0.12860774993896484, -0.12860774993896484, -0.12860774993896484, -0.12860774993896484], "metadata": {"source_tokens": ["A", "San", "Francisco", "lawyer", ",", "Mr", "##.", "Panel", "##li", "row", "##ed", "religious", "##ly", "when", "he", "first", "got", "the", "machine", ",", "but", ",", "he", "complain", "##s", ",", "it", "left", "g", "##rease", "marks", "on", "his", "carpet", ",", "`", "##`", "and", "it", "was", "boring", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "boring", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "complain", "##s", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "left", "[unused4]", "[unused5]", "g", "##rease", "marks", "on", "his", "carpet", "[unused6]", "[SEP]", "[unused1]", "A", "San", "Francisco", "lawyer", "[unused2]", "[unused3]", "row", "##ed", "religious", "##ly", "[unused4]", "[unused5]", "when", "he", "first", "got", "the", "machine", "first", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "got", "[unused4]", "[unused5]", "the", "machine", "first", "[unused6]", "[SEP]"]]}

input 396:  {"source": "A half - dozen Soviet space officials , in Tokyo in July for an exhibit , stopped by to see their counterparts at the National Space Development Agency of Japan .\n"}
prediction:  {"predictions": [[1, 138, 1544, 118, 5955, 2461, 2000, 3878, 2, 3, 2141, 1118, 4, 5, 1106, 1267, 1147, 15289, 1120, 1103, 1305, 4525, 3273, 5571, 1104, 1999, 1107, 4839, 1107, 1351, 1111, 1126, 8245, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 1544, 118, 5955, 2461, 2000, 3878, 2, 3, 2141, 1118, 4, 5, 1106, 1267, 1147, 15289, 1120, 1103, 1305, 4525, 3273, 5571, 1104, 1999, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.05174410343170166, -0.08837591111660004, -0.07658720016479492, -0.07657814025878906, -0.07657814025878906, -0.07657814025878906, -0.07657814025878906, -0.07657814025878906, -0.07657814025878906, -0.07657814025878906], "metadata": {"source_tokens": ["A", "half", "-", "dozen", "Soviet", "space", "officials", ",", "in", "Tokyo", "in", "July", "for", "an", "exhibit", ",", "stopped", "by", "to", "see", "their", "counterparts", "at", "the", "National", "Space", "Development", "Agency", "of", "Japan", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "half", "-", "dozen", "Soviet", "space", "officials", "[unused2]", "[unused3]", "stopped", "by", "[unused4]", "[unused5]", "to", "see", "their", "counterparts", "at", "the", "National", "Space", "Development", "Agency", "of", "Japan", "in", "Tokyo", "in", "July", "for", "an", "exhibit", "[unused6]", "[SEP]", "[unused1]", "A", "half", "-", "dozen", "Soviet", "space", "officials", "[unused2]", "[unused3]", "stopped", "by", "[unused4]", "[unused5]", "to", "see", "their", "counterparts", "at", "the", "National", "Space", "Development", "Agency", "of", "Japan", "[unused6]", "[SEP]"]]}

input 397:  {"source": "A month ago , when Beatrice first filed to sell debt , the company had planned to offer $ 200 million of its senior subordinated reset notes at a yield of 12 3\\/4 % .\n"}
prediction:  {"predictions": [[1, 1103, 1419, 2, 3, 1125, 2919, 4, 5, 1106, 2906, 109, 2363, 1550, 1104, 1157, 2682, 16469, 1181, 1231, 9388, 3697, 1120, 170, 10972, 1104, 1367, 124, 28139, 1527, 110, 138, 2370, 2403, 1165, 16131, 1148, 5770, 1106, 4582, 6695, 1148, 5770, 1106, 4582, 6695, 1148, 5770, 1106, 4582, 102, 1, 16131, 2, 3, 5770, 4, 5, 1106, 4582, 6695, 1148, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1419, 2, 3, 1125, 2919, 4, 5, 1106, 2906, 109, 2363, 1550, 1104, 1157, 2682, 16469, 1181, 1231, 9388, 3697, 1120, 170, 10972, 1104, 1367, 124, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.06844301521778107, -0.06279917061328888, -0.21750704944133759, -0.21520864963531494, -0.2127542495727539, -0.2127542495727539, -0.2127542495727539, -0.2127542495727539, -0.2127542495727539, -0.2127542495727539], "metadata": {"source_tokens": ["A", "month", "ago", ",", "when", "Beatrice", "first", "filed", "to", "sell", "debt", ",", "the", "company", "had", "planned", "to", "offer", "$", "200", "million", "of", "its", "senior", "subordinate", "##d", "re", "##set", "notes", "at", "a", "yield", "of", "12", "3", "##\\", "##/", "##4", "%", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "company", "[unused2]", "[unused3]", "had", "planned", "[unused4]", "[unused5]", "to", "offer", "$", "200", "million", "of", "its", "senior", "subordinate", "##d", "re", "##set", "notes", "at", "a", "yield", "of", "12", "3", "##/", "##4", "%", "A", "month", "ago", "when", "Beatrice", "first", "filed", "to", "sell", "debt", "first", "filed", "to", "sell", "debt", "first", "filed", "to", "sell", "[SEP]", "[unused1]", "Beatrice", "[unused2]", "[unused3]", "filed", "[unused4]", "[unused5]", "to", "sell", "debt", "first", "[unused6]", "[SEP]", "[unused1]", "the", "company", "[unused2]", "[unused3]", "had", "planned", "[unused4]", "[unused5]", "to", "offer", "$", "200", "million", "of", "its", "senior", "subordinate", "##d", "re", "##set", "notes", "at", "a", "yield", "of", "12", "3", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "[SEP]"]]}

input 398:  {"source": "A similar technique is almost impossible to apply to other crops , such as cotton , soybeans and rice .\n"}
prediction:  {"predictions": [[1, 138, 1861, 5531, 2, 3, 1110, 4, 5, 1593, 4763, 1106, 6058, 1106, 1168, 8592, 117, 1216, 1112, 7825, 117, 1177, 1183, 3962, 5443, 1105, 7738, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.000645673368126154, -0.03558826446533203, -0.07566142082214355, -0.07566142082214355, -0.07566142082214355, -0.07566142082214355, -0.07566142082214355, -0.07566142082214355, -0.07566142082214355, -0.07566142082214355], "metadata": {"source_tokens": ["A", "similar", "technique", "is", "almost", "impossible", "to", "apply", "to", "other", "crops", ",", "such", "as", "cotton", ",", "so", "##y", "##be", "##ans", "and", "rice", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "similar", "technique", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "almost", "impossible", "to", "apply", "to", "other", "crops", ",", "such", "as", "cotton", ",", "so", "##y", "##be", "##ans", "and", "rice", "[unused6]", "[SEP]"]]}

input 399:  {"source": "A specialist is an exchange member designated to maintain a fair and orderly market in a specified stock .\n"}
prediction:  {"predictions": [[1, 138, 9131, 2, 3, 1110, 4, 5, 1126, 3670, 1420, 3574, 1106, 4731, 170, 4652, 1105, 28058, 2319, 1107, 170, 9467, 4482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1126, 3670, 1420, 2, 3, 3574, 4, 5, 1106, 4731, 170, 4652, 1105, 28058, 2319, 1107, 170, 9467, 4482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0005673122359439731, -0.33961784839630127, -0.02919849567115307, -0.009131431579589844, -0.00922393798828125, -0.00922393798828125, -0.00922393798828125, -0.00922393798828125, -0.00922393798828125, -0.00922393798828125], "metadata": {"source_tokens": ["A", "specialist", "is", "an", "exchange", "member", "designated", "to", "maintain", "a", "fair", "and", "orderly", "market", "in", "a", "specified", "stock", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "specialist", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "exchange", "member", "designated", "to", "maintain", "a", "fair", "and", "orderly", "market", "in", "a", "specified", "stock", "[unused6]", "[SEP]"]]}

input 400:  {"source": "A spokesman said HealthVest has paid two of the three banks it owed interest to in October and is in negotiations with the third bank .\n"}
prediction:  {"predictions": [[1, 138, 15465, 2, 3, 1163, 4, 5, 3225, 2559, 2556, 1144, 3004, 1160, 1104, 1103, 1210, 5482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1210, 5482, 2, 3, 12390, 4, 5, 2199, 1106, 1107, 1357, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3225, 2559, 2556, 2, 3, 1144, 3004, 4, 5, 1160, 1104, 1103, 1210, 5482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 4, 5, 1107, 7624, 1114, 1103, 1503, 3085, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.009666681289672852, -0.10006452351808548, -0.07929136604070663, -0.09052586555480957, -0.12405824661254883, -0.1240546703338623, -0.1240546703338623, -0.1240546703338623, -0.1240546703338623, -0.1240546703338623], "metadata": {"source_tokens": ["A", "spokesman", "said", "Health", "##V", "##est", "has", "paid", "two", "of", "the", "three", "banks", "it", "owed", "interest", "to", "in", "October", "and", "is", "in", "negotiations", "with", "the", "third", "bank", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "spokesman", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "Health", "##V", "##est", "has", "paid", "two", "of", "the", "three", "banks", "[unused6]", "[SEP]", "[unused1]", "the", "three", "banks", "[unused2]", "[unused3]", "owed", "[unused4]", "[unused5]", "interest", "to", "in", "October", "[unused6]", "[SEP]", "[unused1]", "Health", "##V", "##est", "[unused2]", "[unused3]", "has", "paid", "[unused4]", "[unused5]", "two", "of", "the", "three", "banks", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "in", "negotiations", "with", "the", "third", "bank", "[unused6]", "[SEP]"]]}

input 401:  {"source": "A state judge postponed a decision on a move by holders of Telerate Inc. to block the tender offer of Dow Jones & Co. for the 33 % of Telerate it does n't already own .\n"}
prediction:  {"predictions": [[1, 138, 1352, 3942, 2, 3, 16296, 4, 5, 170, 2383, 1113, 170, 1815, 1118, 14322, 1104, 11341, 5970, 1566, 3561, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1674, 183, 28131, 1204, 4, 5, 1640, 1319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 1352, 3942, 2, 3, 16296, 4, 5, 170, 2383, 1113, 170, 1815, 1106, 3510, 1103, 8886, 2906, 1104, 26535, 2690, 111, 3291, 28138, 1111, 1103, 3081, 110, 1104, 11341, 5970, 1566, 1122, 1674, 183, 28131, 1204, 1640, 1319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 138, 1352, 3942, 2, 3, 16296, 4, 5, 170, 2383, 1113, 170, 1815, 1106, 3510, 1103, 8886, 2906, 1104, 26535, 2690, 111, 3291, 28138, 1111, 1103, 3081, 110, 1104, 11341, 5970, 1566, 1122, 1674, 183, 28131, 1204, 1640, 1319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03721174970269203, -0.08426040410995483, -0.05223359540104866, -0.07283178716897964, -0.28850364685058594, -0.28963160514831543, -0.28963160514831543, -0.28963160514831543, -0.28963160514831543, -0.28963160514831543], "metadata": {"source_tokens": ["A", "state", "judge", "postponed", "a", "decision", "on", "a", "move", "by", "holders", "of", "Tel", "##era", "##te", "Inc", "##.", "to", "block", "the", "tender", "offer", "of", "Dow", "Jones", "&", "Co", "##.", "for", "the", "33", "%", "of", "Tel", "##era", "##te", "it", "does", "n", "##'", "##t", "already", "own", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "state", "judge", "[unused2]", "[unused3]", "postponed", "[unused4]", "[unused5]", "a", "decision", "on", "a", "move", "by", "holders", "of", "Tel", "##era", "##te", "Inc", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "does", "n", "##'", "##t", "[unused4]", "[unused5]", "already", "own", "[unused6]", "[SEP]", "[unused1]", "A", "state", "judge", "[unused2]", "[unused3]", "postponed", "[unused4]", "[unused5]", "a", "decision", "on", "a", "move", "to", "block", "the", "tender", "offer", "of", "Dow", "Jones", "&", "Co", "##.", "for", "the", "33", "%", "of", "Tel", "##era", "##te", "it", "does", "n", "##'", "##t", "already", "own", "[unused6]", "[SEP]", "[unused1]", "A", "state", "judge", "[unused2]", "[unused3]", "postponed", "[unused4]", "[unused5]", "a", "decision", "on", "a", "move", "to", "block", "the", "tender", "offer", "of", "Dow", "Jones", "&", "Co", "##.", "for", "the", "33", "%", "of", "Tel", "##era", "##te", "it", "does", "n", "##'", "##t", "already", "own", "[unused6]", "[SEP]"]]}

input 402:  {"source": "A surprising 78 % of people said they exercise regularly , up from 73 % in 1981 .\n"}
prediction:  {"predictions": [[1, 138, 11567, 5603, 110, 1104, 1234, 2, 3, 1163, 4, 5, 1152, 6730, 4857, 117, 1146, 1121, 5766, 110, 1107, 2358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.009751836769282818, -0.032390594482421875, -0.03225541114807129, -0.03225541114807129, -0.03225541114807129, -0.03225541114807129, -0.03225541114807129, -0.03225541114807129, -0.03225541114807129, -0.03225541114807129], "metadata": {"source_tokens": ["A", "surprising", "78", "%", "of", "people", "said", "they", "exercise", "regularly", ",", "up", "from", "73", "%", "in", "1981", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "A", "surprising", "78", "%", "of", "people", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "they", "exercise", "regularly", ",", "up", "from", "73", "%", "in", "1981", "[unused6]", "[SEP]"]]}

input 403:  {"source": "A year earlier UniFirst earned $ 2.4 million , or 24 cents a share adjusted for the split .\n"}
prediction:  {"predictions": [[1, 12118, 1182, 2271, 11836, 1204, 2, 3, 2829, 4, 5, 109, 123, 28138, 1527, 1550, 138, 1214, 2206, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 2934, 2, 3, 10491, 4, 5, 1111, 1103, 3325, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12118, 1182, 2271, 11836, 1204, 2, 3, 2829, 4, 5, 109, 123, 28138, 1527, 1550, 1137, 1572, 18748, 170, 2934, 10491, 1111, 1103, 3325, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.030016807839274406, -0.022984027862548828, -0.04880206286907196, -0.07784867286682129, -0.07784819602966309, -0.07784819602966309, -0.07784819602966309, -0.07784819602966309, -0.07784819602966309, -0.07784819602966309], "metadata": {"source_tokens": ["A", "year", "earlier", "Un", "##i", "##F", "##irs", "##t", "earned", "$", "2", "##.", "##4", "million", ",", "or", "24", "cents", "a", "share", "adjusted", "for", "the", "split", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Un", "##i", "##F", "##irs", "##t", "[unused2]", "[unused3]", "earned", "[unused4]", "[unused5]", "$", "2", "##.", "##4", "million", "A", "year", "earlier", "[unused6]", "[SEP]", "[unused1]", "a", "share", "[unused2]", "[unused3]", "adjusted", "[unused4]", "[unused5]", "for", "the", "split", "[unused6]", "[SEP]", "[unused1]", "Un", "##i", "##F", "##irs", "##t", "[unused2]", "[unused3]", "earned", "[unused4]", "[unused5]", "$", "2", "##.", "##4", "million", "or", "24", "cents", "a", "share", "adjusted", "for", "the", "split", "[unused6]", "[SEP]"]]}

input 404:  {"source": "About $ 70 billion is estimated to be tied up in the short - term money market , which acts both as a hedge against inflation for consumers and an accelerator of inflation and deficits for the government .\n"}
prediction:  {"predictions": [[1, 1103, 1603, 118, 1858, 1948, 2319, 2, 3, 4096, 4, 5, 1241, 1112, 170, 21610, 1222, 15503, 1111, 11060, 1105, 1126, 170, 26154, 1104, 15503, 1105, 16312, 1116, 1111, 1103, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3517, 109, 3102, 3775, 2, 3, 1110, 3555, 4, 5, 1106, 1129, 4353, 1146, 1107, 1103, 1603, 118, 1858, 1948, 2319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.010826864279806614, -0.016140149906277657, -0.07639336585998535, -0.07639169692993164, -0.07639169692993164, -0.07639169692993164, -0.07639169692993164, -0.07639169692993164, -0.07639169692993164, -0.07639169692993164], "metadata": {"source_tokens": ["About", "$", "70", "billion", "is", "estimated", "to", "be", "tied", "up", "in", "the", "short", "-", "term", "money", "market", ",", "which", "acts", "both", "as", "a", "hedge", "against", "inflation", "for", "consumers", "and", "an", "a", "##ccelerator", "of", "inflation", "and", "deficit", "##s", "for", "the", "government", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "short", "-", "term", "money", "market", "[unused2]", "[unused3]", "acts", "[unused4]", "[unused5]", "both", "as", "a", "hedge", "against", "inflation", "for", "consumers", "and", "an", "a", "##ccelerator", "of", "inflation", "and", "deficit", "##s", "for", "the", "government", "[unused6]", "[SEP]", "[unused1]", "About", "$", "70", "billion", "[unused2]", "[unused3]", "is", "estimated", "[unused4]", "[unused5]", "to", "be", "tied", "up", "in", "the", "short", "-", "term", "money", "market", "[unused6]", "[SEP]"]]}

input 405:  {"source": "According to one person familiar with the airline , the buy - out group -- led by United 's pilots union and UAL Chairman Stephen Wolf -- has begun billing UAL for fees and expenses it owes to investment bankers , law firms and banks .\n"}
prediction:  {"predictions": [[1, 1103, 4417, 118, 1149, 1372, 2, 3, 1521, 4, 5, 1118, 1244, 112, 1116, 8486, 3779, 1105, 158, 12507, 4284, 3620, 6499, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4417, 118, 1149, 1372, 2, 3, 1144, 4972, 4, 5, 4550, 1158, 158, 12507, 1111, 9942, 1105, 11928, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 27701, 4, 5, 1106, 5151, 15304, 1116, 117, 1644, 9780, 1105, 5482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4417, 118, 1149, 1372, 2, 3, 1144, 4972, 4, 5, 4550, 1158, 158, 12507, 1792, 1106, 1141, 1825, 4509, 1114, 1103, 8694, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.022212887182831764, -0.08410626649856567, -0.05896158516407013, -0.12766337394714355, -0.2123631238937378, -0.21237754821777344, -0.21237754821777344, -0.21237754821777344, -0.21237754821777344, -0.21237754821777344], "metadata": {"source_tokens": ["According", "to", "one", "person", "familiar", "with", "the", "airline", ",", "the", "buy", "-", "out", "group", "-", "##-", "led", "by", "United", "'", "##s", "pilots", "union", "and", "U", "##AL", "Chairman", "Stephen", "Wolf", "-", "##-", "has", "begun", "bill", "##ing", "U", "##AL", "for", "fees", "and", "expenses", "it", "owes", "to", "investment", "banker", "##s", ",", "law", "firms", "and", "banks", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "buy", "-", "out", "group", "[unused2]", "[unused3]", "led", "[unused4]", "[unused5]", "by", "United", "'", "##s", "pilots", "union", "and", "U", "##AL", "Chairman", "Stephen", "Wolf", "[unused6]", "[SEP]", "[unused1]", "the", "buy", "-", "out", "group", "[unused2]", "[unused3]", "has", "begun", "[unused4]", "[unused5]", "bill", "##ing", "U", "##AL", "for", "fees", "and", "expenses", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "owes", "[unused4]", "[unused5]", "to", "investment", "banker", "##s", ",", "law", "firms", "and", "banks", "[unused6]", "[SEP]", "[unused1]", "the", "buy", "-", "out", "group", "[unused2]", "[unused3]", "has", "begun", "[unused4]", "[unused5]", "bill", "##ing", "U", "##AL", "According", "to", "one", "person", "familiar", "with", "the", "airline", "[unused6]", "[SEP]"]]}

input 406:  {"source": "After practicing law locally , he was elected to his first 10 - year term as judge in 1971 ; in 1981 , he was effectively re - elected .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1108, 1809, 4, 5, 1106, 1117, 1148, 1275, 118, 1214, 1858, 1112, 3942, 1107, 2507, 1258, 13029, 1644, 6889, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1231, 118, 1809, 4, 5, 1107, 2358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1231, 118, 1809, 4, 5, 1107, 2358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1231, 118, 1809, 4, 5, 1107, 2358, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 1231, 118, 1809, 4, 5, 5877, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.012936532497406006, -0.042861249297857285, -0.09536294639110565, -0.15251652896404266, -0.1500190794467926, -0.07657337188720703, -0.07657361030578613, -0.07657361030578613, -0.07657361030578613, -0.07657361030578613], "metadata": {"source_tokens": ["After", "practicing", "law", "locally", ",", "he", "was", "elected", "to", "his", "first", "10", "-", "year", "term", "as", "judge", "in", "1971", ";", "in", "1981", ",", "he", "was", "effectively", "re", "-", "elected", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "was", "elected", "[unused4]", "[unused5]", "to", "his", "first", "10", "-", "year", "term", "as", "judge", "in", "1971", "After", "practicing", "law", "locally", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "re", "-", "elected", "[unused4]", "[unused5]", "in", "1981", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "re", "-", "elected", "[unused4]", "[unused5]", "in", "1981", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "re", "-", "elected", "[unused4]", "[unused5]", "in", "1981", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "re", "-", "elected", "[unused4]", "[unused5]", "effectively", "[unused6]", "[SEP]"]]}

input 407:  {"source": "After years of talking about selling in Japan , more and more U.S. companies are seriously pouring in .\n"}
prediction:  {"predictions": [[1, 1167, 1105, 1167, 158, 28138, 1708, 28138, 2557, 2, 3, 1132, 5536, 13587, 1107, 4, 5, 1258, 1201, 1104, 2520, 1164, 4147, 1107, 1999, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1167, 1105, 1167, 158, 28138, 1708, 28138, 2557, 2, 3, 1132, 13587, 1107, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.01747855357825756, -0.10588774085044861, -0.07641839981079102, -0.07641839981079102, -0.07641839981079102, -0.07641839981079102, -0.07641839981079102, -0.07641839981079102, -0.07641839981079102, -0.07641839981079102], "metadata": {"source_tokens": ["After", "years", "of", "talking", "about", "selling", "in", "Japan", ",", "more", "and", "more", "U", "##.", "##S", "##.", "companies", "are", "seriously", "pouring", "in", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "more", "and", "more", "U", "##.", "##S", "##.", "companies", "[unused2]", "[unused3]", "are", "seriously", "pouring", "in", "[unused4]", "[unused5]", "After", "years", "of", "talking", "about", "selling", "in", "Japan", "[unused6]", "[SEP]", "[unused1]", "more", "and", "more", "U", "##.", "##S", "##.", "companies", "[unused2]", "[unused3]", "are", "pouring", "in", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 408:  {"source": "Also , the premiums paid by the U.S. government on a purchase of copper for the U.S. Mint were lower than expected , and acted as a price depressant , analysts said .\n"}
prediction:  {"predictions": [[1, 1103, 16865, 1116, 3004, 1118, 1103, 158, 28138, 1708, 28138, 1433, 1113, 170, 4779, 1104, 7335, 1111, 1103, 158, 28138, 1708, 28138, 21192, 2, 3, 5376, 4, 5, 1112, 170, 3945, 1260, 11135, 2861, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 16865, 1116, 3004, 1118, 1103, 158, 28138, 1708, 28138, 1433, 1113, 170, 4779, 1104, 7335, 1111, 1103, 158, 28138, 1708, 28138, 21192, 2, 3, 1127, 4, 5, 2211, 1190, 2637, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 16865, 1116, 2, 3, 3004, 4, 5, 1118, 1103, 158, 28138, 1708, 28138, 1433, 1113, 170, 4779, 1104, 7335, 1111, 1103, 158, 28138, 1708, 28138, 21192, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 16865, 1116, 3004, 1118, 1103, 158, 28138, 1708, 28138, 1433, 1113, 170, 4779, 1104, 7335, 1111, 1103, 158, 28138, 1708, 28138, 21192, 2, 3, 1127, 4, 5, 2211, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 16865, 1116, 3004, 1118, 1103, 158, 28138, 1708, 28138, 1433, 1113, 170, 4779, 1104, 7335, 1111, 1103, 158, 28138, 1708, 28138, 21192, 2, 3, 1127, 4, 5, 2211, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.044054482132196426, -0.03759044036269188, -0.04322785139083862, -0.10343275964260101, -0.11542180180549622, -0.2511148452758789, -0.2636902332305908, -0.2636902332305908, -0.2636902332305908, -0.2636902332305908], "metadata": {"source_tokens": ["Also", ",", "the", "premium", "##s", "paid", "by", "the", "U", "##.", "##S", "##.", "government", "on", "a", "purchase", "of", "copper", "for", "the", "U", "##.", "##S", "##.", "Mint", "were", "lower", "than", "expected", ",", "and", "acted", "as", "a", "price", "de", "##press", "##ant", ",", "analysts", "said", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "premium", "##s", "paid", "by", "the", "U", "##.", "##S", "##.", "government", "on", "a", "purchase", "of", "copper", "for", "the", "U", "##.", "##S", "##.", "Mint", "[unused2]", "[unused3]", "acted", "[unused4]", "[unused5]", "as", "a", "price", "de", "##press", "##ant", "[unused6]", "[SEP]", "[unused1]", "the", "premium", "##s", "paid", "by", "the", "U", "##.", "##S", "##.", "government", "on", "a", "purchase", "of", "copper", "for", "the", "U", "##.", "##S", "##.", "Mint", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "lower", "than", "expected", "[unused6]", "[SEP]", "[unused1]", "the", "premium", "##s", "[unused2]", "[unused3]", "paid", "[unused4]", "[unused5]", "by", "the", "U", "##.", "##S", "##.", "government", "on", "a", "purchase", "of", "copper", "for", "the", "U", "##.", "##S", "##.", "Mint", "[unused6]", "[SEP]", "[unused1]", "the", "premium", "##s", "paid", "by", "the", "U", "##.", "##S", "##.", "government", "on", "a", "purchase", "of", "copper", "for", "the", "U", "##.", "##S", "##.", "Mint", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "lower", "[unused6]", "[SEP]", "[unused1]", "the", "premium", "##s", "paid", "by", "the", "U", "##.", "##S", "##.", "government", "on", "a", "purchase", "of", "copper", "for", "the", "U", "##.", "##S", "##.", "Mint", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "lower", "[unused6]", "[SEP]"]]}

input 409:  {"source": "Although Heathrow authorities have been watching a group of allegedly crooked baggage handlers for some time , the Gauguin may be `` lost . ''\n"}
prediction:  {"predictions": [[1, 1103, 144, 3984, 25913, 2, 3, 1336, 1129, 1575, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10640, 7596, 3912, 2, 3, 1138, 1151, 2903, 4, 5, 170, 1372, 1104, 9273, 19785, 23539, 4282, 1733, 1111, 1199, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 144, 3984, 25913, 2, 3, 1336, 1129, 1575, 4, 5, 1966, 10640, 7596, 3912, 1138, 1151, 2903, 170, 1372, 1104, 9273, 19785, 23539, 4282, 1733, 1111, 1199, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04299163818359375, -0.0020678688306361437, -0.03640105947852135, -0.12200188636779785, -0.12142753601074219, -0.12142753601074219, -0.12142753601074219, -0.12142753601074219, -0.12142753601074219, -0.12142753601074219], "metadata": {"source_tokens": ["Although", "Heath", "##row", "authorities", "have", "been", "watching", "a", "group", "of", "allegedly", "crooked", "baggage", "handle", "##rs", "for", "some", "time", ",", "the", "G", "##au", "##guin", "may", "be", "`", "##`", "lost", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "G", "##au", "##guin", "[unused2]", "[unused3]", "may", "be", "lost", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Heath", "##row", "authorities", "[unused2]", "[unused3]", "have", "been", "watching", "[unused4]", "[unused5]", "a", "group", "of", "allegedly", "crooked", "baggage", "handle", "##rs", "for", "some", "time", "[unused6]", "[SEP]", "[unused1]", "the", "G", "##au", "##guin", "[unused2]", "[unused3]", "may", "be", "lost", "[unused4]", "[unused5]", "Although", "Heath", "##row", "authorities", "have", "been", "watching", "a", "group", "of", "allegedly", "crooked", "baggage", "handle", "##rs", "for", "some", "time", "[unused6]", "[SEP]"]]}

input 410:  {"source": "Although Mr. Azoff wo n't produce films at first , it is possible that he could do so later , the sources said .\n"}
prediction:  {"predictions": [[1, 1103, 3509, 2, 3, 1163, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 138, 6112, 3101, 2, 3, 192, 1186, 183, 28131, 1204, 3133, 4, 5, 2441, 1120, 1148, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 4, 5, 1936, 1115, 1119, 1180, 1202, 1177, 1224, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.07356510311365128, -0.04148023575544357, -0.02451477199792862, -0.07679462432861328, -0.07680630683898926, -0.07680630683898926, -0.07680630683898926, -0.07680630683898926, -0.07680630683898926, -0.07680630683898926], "metadata": {"source_tokens": ["Although", "Mr", "##.", "A", "##zo", "##ff", "w", "##o", "n", "##'", "##t", "produce", "films", "at", "first", ",", "it", "is", "possible", "that", "he", "could", "do", "so", "later", ",", "the", "sources", "said", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "sources", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "A", "##zo", "##ff", "[unused2]", "[unused3]", "w", "##o", "n", "##'", "##t", "produce", "[unused4]", "[unused5]", "films", "at", "first", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "possible", "that", "he", "could", "do", "so", "later", "[unused6]", "[SEP]"]]}

input 411:  {"source": "Although no specific agreements are expected , Mr. Shevardnadze said `` that does n't mean they will be without an agenda . ''\n"}
prediction:  {"predictions": [[1, 1185, 2747, 11069, 2, 3, 1132, 2637, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 1153, 24698, 1605, 1181, 3171, 2, 3, 1163, 4, 5, 1115, 1674, 183, 28131, 1204, 1928, 1152, 1209, 1129, 1443, 1126, 12932, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1209, 1129, 4, 5, 1443, 1126, 12932, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.05795522406697273, -0.002054686890915036, -0.07124385237693787, -0.03223466873168945, -0.03223919868469238, -0.03223919868469238, -0.03223919868469238, -0.03223919868469238, -0.03223919868469238, -0.03223919868469238], "metadata": {"source_tokens": ["Although", "no", "specific", "agreements", "are", "expected", ",", "Mr", "##.", "She", "##vard", "##na", "##d", "##ze", "said", "`", "##`", "that", "does", "n", "##'", "##t", "mean", "they", "will", "be", "without", "an", "agenda", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "no", "specific", "agreements", "[unused2]", "[unused3]", "are", "expected", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "She", "##vard", "##na", "##d", "##ze", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "that", "does", "n", "##'", "##t", "mean", "they", "will", "be", "without", "an", "agenda", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "will", "be", "[unused4]", "[unused5]", "without", "an", "agenda", "[unused6]", "[SEP]"]]}

input 412:  {"source": "Although the Treasury will announce details of the November refunding tomorrow , it could be delayed if Congress and President Bush fail to increase the Treasury 's borrowing capacity .\n"}
prediction:  {"predictions": [[1, 1103, 11712, 2, 3, 1209, 15810, 4, 5, 4068, 1104, 1103, 1379, 1231, 14703, 17038, 4911, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1180, 1129, 8088, 4, 5, 1191, 2757, 1105, 1697, 6096, 8693, 1106, 2773, 1103, 11712, 112, 1116, 20055, 1158, 3211, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2757, 1105, 1697, 6096, 2, 3, 8693, 4, 5, 1106, 2773, 1103, 11712, 112, 1116, 20055, 1158, 3211, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.00944800116121769, -0.024981264024972916, -0.04157239571213722, -0.07290530204772949, -0.07655858993530273, -0.07655858993530273, -0.07655858993530273, -0.07655858993530273, -0.07655858993530273, -0.07655858993530273], "metadata": {"source_tokens": ["Although", "the", "Treasury", "will", "announce", "details", "of", "the", "November", "re", "##fu", "##nding", "tomorrow", ",", "it", "could", "be", "delayed", "if", "Congress", "and", "President", "Bush", "fail", "to", "increase", "the", "Treasury", "'", "##s", "borrow", "##ing", "capacity", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Treasury", "[unused2]", "[unused3]", "will", "announce", "[unused4]", "[unused5]", "details", "of", "the", "November", "re", "##fu", "##nding", "tomorrow", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "could", "be", "delayed", "[unused4]", "[unused5]", "if", "Congress", "and", "President", "Bush", "fail", "to", "increase", "the", "Treasury", "'", "##s", "borrow", "##ing", "capacity", "[unused6]", "[SEP]", "[unused1]", "Congress", "and", "President", "Bush", "[unused2]", "[unused3]", "fail", "[unused4]", "[unused5]", "to", "increase", "the", "Treasury", "'", "##s", "borrow", "##ing", "capacity", "[unused6]", "[SEP]"]]}

input 413:  {"source": "Among other things , they said , Mr. Azoff would develop musical acts for a new record label .\n"}
prediction:  {"predictions": [[1, 1152, 2, 3, 1163, 4, 5, 1828, 28138, 138, 6112, 3101, 1156, 3689, 2696, 4096, 1111, 170, 1207, 1647, 3107, 3841, 1168, 1614, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 138, 6112, 3101, 2, 3, 1156, 3689, 4, 5, 2696, 4096, 1111, 170, 1207, 1647, 3107, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.010831539519131184, -0.0022320463322103024, -0.041168212890625, -0.03432464599609375, -0.03432464599609375, -0.03432464599609375, -0.03432464599609375, -0.03432464599609375, -0.03432464599609375, -0.03432464599609375], "metadata": {"source_tokens": ["Among", "other", "things", ",", "they", "said", ",", "Mr", "##.", "A", "##zo", "##ff", "would", "develop", "musical", "acts", "for", "a", "new", "record", "label", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "they", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "Mr", "##.", "A", "##zo", "##ff", "would", "develop", "musical", "acts", "for", "a", "new", "record", "label", "Among", "other", "things", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "A", "##zo", "##ff", "[unused2]", "[unused3]", "would", "develop", "[unused4]", "[unused5]", "musical", "acts", "for", "a", "new", "record", "label", "[unused6]", "[SEP]"]]}

input 414:  {"source": "And , since the public has always been fascinated by gossip and voyeurism , reporters and editors will strain for creative angles to justify the inclusion of collateral facts about private lives including sexual activities and domestic relationships , activities of family members , and all matters about mental and physical health .\n"}
prediction:  {"predictions": [[1, 13509, 1105, 11884, 2, 3, 1209, 10512, 4, 5, 1111, 6228, 12879, 1106, 17422, 1103, 10838, 1104, 1884, 3848, 16719, 9193, 1164, 2029, 2491, 1259, 3785, 2619, 1105, 4500, 6085, 117, 2619, 1104, 1266, 1484, 117, 1105, 1155, 5218, 1164, 4910, 1105, 2952, 2332, 1290, 1103, 1470, 1144, 1579, 102, 1, 1103, 1470, 2, 3, 1144, 1151, 17136, 4, 5, 1118, 16378, 1105, 191, 7341, 8816, 1863, 1579, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 13509, 1105, 11884, 2, 3, 1209, 10512, 4, 5, 1111, 6228, 12879, 1106, 17422, 1103, 10838, 1104, 1884, 3848, 16719, 9193, 1164, 2029, 2491, 1259, 3785, 2619, 1105, 4500, 6085, 2619, 1104, 1266, 1484, 1105, 1155, 5218, 1164, 4910, 1105, 2952, 2332, 1290, 1103, 1470, 1144, 1579, 1151, 17136, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.024784613400697708, -0.04698166996240616, -0.04803668335080147, -0.3389322757720947, -0.33982157707214355, -0.33982157707214355, -0.33982157707214355, -0.33982157707214355, -0.33982157707214355, -0.33982157707214355], "metadata": {"source_tokens": ["And", ",", "since", "the", "public", "has", "always", "been", "fascinated", "by", "gossip", "and", "v", "##oy", "##eur", "##ism", ",", "reporters", "and", "editors", "will", "strain", "for", "creative", "angles", "to", "justify", "the", "inclusion", "of", "co", "##lla", "##teral", "facts", "about", "private", "lives", "including", "sexual", "activities", "and", "domestic", "relationships", ",", "activities", "of", "family", "members", ",", "and", "all", "matters", "about", "mental", "and", "physical", "health", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "reporters", "and", "editors", "[unused2]", "[unused3]", "will", "strain", "[unused4]", "[unused5]", "for", "creative", "angles", "to", "justify", "the", "inclusion", "of", "co", "##lla", "##teral", "facts", "about", "private", "lives", "including", "sexual", "activities", "and", "domestic", "relationships", ",", "activities", "of", "family", "members", ",", "and", "all", "matters", "about", "mental", "and", "physical", "health", "since", "the", "public", "has", "always", "[SEP]", "[unused1]", "the", "public", "[unused2]", "[unused3]", "has", "been", "fascinated", "[unused4]", "[unused5]", "by", "gossip", "and", "v", "##oy", "##eur", "##ism", "always", "[unused6]", "[SEP]", "[unused1]", "reporters", "and", "editors", "[unused2]", "[unused3]", "will", "strain", "[unused4]", "[unused5]", "for", "creative", "angles", "to", "justify", "the", "inclusion", "of", "co", "##lla", "##teral", "facts", "about", "private", "lives", "including", "sexual", "activities", "and", "domestic", "relationships", "activities", "of", "family", "members", "and", "all", "matters", "about", "mental", "and", "physical", "health", "since", "the", "public", "has", "always", "been", "fascinated", "[SEP]"]]}

input 415:  {"source": "And Dewar 's gave discounts on Scottish merchandise to people who sent in bottle labels .\n"}
prediction:  {"predictions": [[1, 1234, 2, 3, 1850, 4, 5, 1107, 5346, 11080, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3177, 7200, 112, 1116, 2, 3, 1522, 4, 5, 23290, 1116, 1113, 3250, 18349, 1106, 1234, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.019441604614257812, -0.009236065670847893, -0.0385441780090332, -0.03846120834350586, -0.03846120834350586, -0.03846120834350586, -0.03846120834350586, -0.03846120834350586, -0.03846120834350586, -0.03846120834350586], "metadata": {"source_tokens": ["And", "De", "##war", "'", "##s", "gave", "discount", "##s", "on", "Scottish", "merchandise", "to", "people", "who", "sent", "in", "bottle", "labels", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "people", "[unused2]", "[unused3]", "sent", "[unused4]", "[unused5]", "in", "bottle", "labels", "[unused6]", "[SEP]", "[unused1]", "De", "##war", "'", "##s", "[unused2]", "[unused3]", "gave", "[unused4]", "[unused5]", "discount", "##s", "on", "Scottish", "merchandise", "to", "people", "[unused6]", "[SEP]"]]}

input 416:  {"source": "And do n't expect many complete games by pitchers -- perhaps three out of 288 , laughs Mr. Fingers , the former Oakland reliever .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 19140, 9915, 2, 3, 1110, 4, 5, 1103, 1393, 8847, 16775, 1197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1202, 183, 28131, 1204, 5363, 1242, 2335, 1638, 1118, 26970, 2, 3, 12375, 4, 5, 1828, 28138, 19140, 9915, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02705727517604828, -0.09092963486909866, -0.11786317825317383, -0.11523175239562988, -0.11523175239562988, -0.11523175239562988, -0.11523175239562988, -0.11523175239562988, -0.11523175239562988, -0.11523175239562988], "metadata": {"source_tokens": ["And", "do", "n", "##'", "##t", "expect", "many", "complete", "games", "by", "pitchers", "-", "##-", "perhaps", "three", "out", "of", "288", ",", "laughs", "Mr", "##.", "Fin", "##gers", ",", "the", "former", "Oakland", "relieve", "##r", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Fin", "##gers", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "former", "Oakland", "relieve", "##r", "[unused6]", "[SEP]", "[unused1]", "do", "n", "##'", "##t", "expect", "many", "complete", "games", "by", "pitchers", "[unused2]", "[unused3]", "laughs", "[unused4]", "[unused5]", "Mr", "##.", "Fin", "##gers", "[unused6]", "[SEP]"]]}

input 417:  {"source": "And he got rid of low - margin businesses that just were n't making money for the company .\n"}
prediction:  {"predictions": [[1, 1822, 118, 7464, 5028, 2, 3, 1198, 1127, 183, 28131, 1204, 1543, 4, 5, 1948, 1111, 1103, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1400, 4, 5, 9297, 1104, 1822, 118, 7464, 5028, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02701173536479473, -0.0266147218644619, -0.02200603485107422, -0.02200603485107422, -0.02200603485107422, -0.02200603485107422, -0.02200603485107422, -0.02200603485107422, -0.02200603485107422, -0.02200603485107422], "metadata": {"source_tokens": ["And", "he", "got", "rid", "of", "low", "-", "margin", "businesses", "that", "just", "were", "n", "##'", "##t", "making", "money", "for", "the", "company", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "low", "-", "margin", "businesses", "[unused2]", "[unused3]", "just", "were", "n", "##'", "##t", "making", "[unused4]", "[unused5]", "money", "for", "the", "company", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "got", "[unused4]", "[unused5]", "rid", "of", "low", "-", "margin", "businesses", "[unused6]", "[SEP]"]]}

input 418:  {"source": "Annualized interest rates on certain investments as reported by the Federal Reserve Board on a weekly - average basis :\n"}
prediction:  {"predictions": [[1, 8451, 2200, 2199, 5600, 1113, 2218, 12372, 1112, 2103, 1118, 1103, 3467, 5081, 2464, 1113, 170, 5392, 118, 1903, 3142, 2, 3, 1110, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8451, 2200, 2199, 5600, 1113, 2218, 12372, 2, 3, 2103, 4, 5, 1118, 1103, 3467, 5081, 2464, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.06548146903514862, -0.09391861408948898, -0.032334327697753906, -0.03225874900817871, -0.03225874900817871, -0.03225874900817871, -0.03225874900817871, -0.03225874900817871, -0.03225874900817871, -0.03225874900817871], "metadata": {"source_tokens": ["Annual", "##ized", "interest", "rates", "on", "certain", "investments", "as", "reported", "by", "the", "Federal", "Reserve", "Board", "on", "a", "weekly", "-", "average", "basis", ":"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Annual", "##ized", "interest", "rates", "on", "certain", "investments", "as", "reported", "by", "the", "Federal", "Reserve", "Board", "on", "a", "weekly", "-", "average", "basis", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Annual", "##ized", "interest", "rates", "on", "certain", "investments", "[unused2]", "[unused3]", "reported", "[unused4]", "[unused5]", "by", "the", "Federal", "Reserve", "Board", "[unused6]", "[SEP]"]]}

input 419:  {"source": "As a result , he said he will examine the Marcos documents sought by the prosecutors to determine whether turning over the filings is self - incrimination .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1163, 4, 5, 1119, 1209, 11755, 1103, 15541, 4961, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 15541, 4961, 2, 3, 4110, 4, 5, 1118, 1103, 24987, 1106, 4959, 2480, 3219, 1166, 1103, 16504, 1116, 1110, 2191, 118, 1107, 1665, 10205, 9400, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1209, 11755, 4, 5, 1103, 15541, 4961, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3219, 1166, 1103, 16504, 1116, 2, 3, 1110, 4, 5, 2191, 1107, 1665, 10205, 9400, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02713894285261631, -0.045247651636600494, -0.11370077729225159, -0.08522103726863861, -0.07638001441955566, -0.07638096809387207, -0.07638096809387207, -0.07638096809387207, -0.07638096809387207, -0.07638096809387207], "metadata": {"source_tokens": ["As", "a", "result", ",", "he", "said", "he", "will", "examine", "the", "Marcos", "documents", "sought", "by", "the", "prosecutors", "to", "determine", "whether", "turning", "over", "the", "filing", "##s", "is", "self", "-", "in", "##c", "##rim", "##ination", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "he", "will", "examine", "the", "Marcos", "documents", "[unused6]", "[SEP]", "[unused1]", "the", "Marcos", "documents", "[unused2]", "[unused3]", "sought", "[unused4]", "[unused5]", "by", "the", "prosecutors", "to", "determine", "whether", "turning", "over", "the", "filing", "##s", "is", "self", "-", "in", "##c", "##rim", "##ination", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "will", "examine", "[unused4]", "[unused5]", "the", "Marcos", "documents", "[unused6]", "[SEP]", "[unused1]", "turning", "over", "the", "filing", "##s", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "self", "in", "##c", "##rim", "##ination", "[unused6]", "[SEP]"]]}

input 420:  {"source": "As of Sept. 30 , American Brands had 95.2 million shares outstanding .\n"}
prediction:  {"predictions": [[1, 1237, 12381, 1116, 2, 3, 1125, 4, 5, 4573, 28138, 1477, 1550, 6117, 6976, 1249, 1104, 20456, 28138, 1476, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03145463764667511, -0.03750753402709961, -0.03563332557678223, -0.03563332557678223, -0.03563332557678223, -0.03563332557678223, -0.03563332557678223, -0.03563332557678223, -0.03563332557678223, -0.03563332557678223], "metadata": {"source_tokens": ["As", "of", "Sept", "##.", "30", ",", "American", "Brand", "##s", "had", "95", "##.", "##2", "million", "shares", "outstanding", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "American", "Brand", "##s", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "95", "##.", "##2", "million", "shares", "outstanding", "As", "of", "Sept", "##.", "30", "[unused6]", "[SEP]"]]}

input 421:  {"source": "As the London trading session drew to a close , the market was still listening to the parliamentary debate on the economy , with new Chancellor of the Exchequer John Major expected to clarify his approach to the British economy and currency issues .\n"}
prediction:  {"predictions": [[1, 1103, 2319, 2, 3, 1108, 5578, 4, 5, 1106, 1103, 6774, 5655, 1113, 1103, 4190, 1249, 1103, 1498, 6157, 4912, 3583, 1106, 170, 1601, 1253, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1207, 8861, 1104, 1103, 16409, 4386, 19061, 1287, 2868, 2, 3, 2637, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1207, 8861, 1104, 1103, 16409, 4386, 19061, 1287, 2868, 2, 3, 1106, 172, 5815, 6120, 4, 5, 1117, 3136, 1106, 1103, 1418, 4190, 1105, 10202, 2492, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2319, 2, 3, 1108, 5578, 4, 5, 1106, 1103, 6774, 5655, 1113, 1103, 4190, 1114, 1207, 8861, 1104, 1103, 16409, 4386, 19061, 1287, 2868, 2637, 1106, 172, 5815, 6120, 1117, 3136, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2319, 2, 3, 1108, 5578, 4, 5, 1106, 1103, 6774, 5655, 1113, 1103, 4190, 1114, 1207, 8861, 1104, 1103, 16409, 4386, 19061, 1287, 2868, 2637, 1106, 172, 5815, 6120, 1117, 3136, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2319, 2, 3, 1108, 5578, 4, 5, 1106, 1103, 6774, 5655, 1113, 1103, 4190, 1114, 1207, 8861, 1104, 1103, 16409, 4386, 19061, 1287, 2868, 2637, 1106, 172, 5815, 6120, 1117, 3136, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.030926000326871872, -0.06365305185317993, -0.05135876685380936, -0.05700509995222092, -0.34706592559814453, -0.07664831727743149, -0.07696864753961563, -0.34265780448913574, -0.342057466506958, -0.342057466506958], "metadata": {"source_tokens": ["As", "the", "London", "trading", "session", "drew", "to", "a", "close", ",", "the", "market", "was", "still", "listening", "to", "the", "parliamentary", "debate", "on", "the", "economy", ",", "with", "new", "Chancellor", "of", "the", "Ex", "##che", "##quer", "John", "Major", "expected", "to", "c", "##lar", "##ify", "his", "approach", "to", "the", "British", "economy", "and", "currency", "issues", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "market", "[unused2]", "[unused3]", "was", "listening", "[unused4]", "[unused5]", "to", "the", "parliamentary", "debate", "on", "the", "economy", "As", "the", "London", "trading", "session", "drew", "to", "a", "close", "still", "[unused6]", "[SEP]", "[unused1]", "new", "Chancellor", "of", "the", "Ex", "##che", "##quer", "John", "Major", "[unused2]", "[unused3]", "expected", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "new", "Chancellor", "of", "the", "Ex", "##che", "##quer", "John", "Major", "[unused2]", "[unused3]", "to", "c", "##lar", "##ify", "[unused4]", "[unused5]", "his", "approach", "to", "the", "British", "economy", "and", "currency", "issues", "[unused6]", "[SEP]", "[unused1]", "the", "market", "[unused2]", "[unused3]", "was", "listening", "[unused4]", "[unused5]", "to", "the", "parliamentary", "debate", "on", "the", "economy", "with", "new", "Chancellor", "of", "the", "Ex", "##che", "##quer", "John", "Major", "expected", "to", "c", "##lar", "##ify", "his", "approach", "[unused6]", "[SEP]"]]}

input 422:  {"source": "At Giant Bicycle Inc. , Rancho Dominguez , Calif. , sales have tripled since the company entered the U.S. mountain - bike business in 1987 .\n"}
prediction:  {"predictions": [[1, 3813, 2, 3, 1138, 9225, 1181, 4, 5, 1290, 1103, 1419, 2242, 1103, 158, 28138, 1708, 28138, 3231, 118, 8295, 1671, 1107, 2164, 1335, 12510, 139, 1596, 21172, 3561, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1419, 2, 3, 2242, 4, 5, 1103, 158, 28138, 1708, 28138, 3231, 118, 8295, 1671, 1107, 2164, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12510, 139, 1596, 21172, 3561, 28138, 2, 3, 1110, 4, 5, 20864, 16727, 1158, 4175, 1584, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20864, 16727, 1158, 4175, 1584, 2, 3, 1110, 4, 5, 11917, 8914, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04134057089686394, -0.024135416373610497, -0.11099077761173248, -0.08993425220251083, -0.07688236236572266, -0.07688593864440918, -0.07688593864440918, -0.07688593864440918, -0.07688593864440918, -0.07688593864440918], "metadata": {"source_tokens": ["At", "Giant", "B", "##ic", "##ycle", "Inc", "##.", ",", "Rancho", "Dom", "##ing", "##ue", "##z", ",", "Cal", "##if", "##.", ",", "sales", "have", "triple", "##d", "since", "the", "company", "entered", "the", "U", "##.", "##S", "##.", "mountain", "-", "bike", "business", "in", "1987", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "sales", "[unused2]", "[unused3]", "have", "triple", "##d", "[unused4]", "[unused5]", "since", "the", "company", "entered", "the", "U", "##.", "##S", "##.", "mountain", "-", "bike", "business", "in", "1987", "At", "Giant", "B", "##ic", "##ycle", "Inc", "##.", "[unused6]", "[SEP]", "[unused1]", "the", "company", "[unused2]", "[unused3]", "entered", "[unused4]", "[unused5]", "the", "U", "##.", "##S", "##.", "mountain", "-", "bike", "business", "in", "1987", "[unused6]", "[SEP]", "[unused1]", "Giant", "B", "##ic", "##ycle", "Inc", "##.", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Rancho", "Dom", "##ing", "##ue", "##z", "[unused6]", "[SEP]", "[unused1]", "Rancho", "Dom", "##ing", "##ue", "##z", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Cal", "##if", "##.", "[unused6]", "[SEP]"]]}

input 423:  {"source": "At one point , almost all of the shares in the 20 - stock Major Market Index , which mimics the industrial average , were sharply higher .\n"}
prediction:  {"predictions": [[1, 1103, 1406, 118, 4482, 2868, 6923, 10146, 2, 3, 27180, 1116, 4, 5, 1103, 3924, 1903, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1593, 1155, 1104, 1103, 6117, 1107, 1103, 1406, 118, 4482, 2868, 6923, 10146, 2, 3, 1127, 4, 5, 8930, 2299, 1335, 1141, 1553, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03589982911944389, -0.0167864840477705, -0.07650327682495117, -0.07650113105773926, -0.07650113105773926, -0.07650113105773926, -0.07650113105773926, -0.07650113105773926, -0.07650113105773926, -0.07650113105773926], "metadata": {"source_tokens": ["At", "one", "point", ",", "almost", "all", "of", "the", "shares", "in", "the", "20", "-", "stock", "Major", "Market", "Index", ",", "which", "mimic", "##s", "the", "industrial", "average", ",", "were", "sharply", "higher", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "20", "-", "stock", "Major", "Market", "Index", "[unused2]", "[unused3]", "mimic", "##s", "[unused4]", "[unused5]", "the", "industrial", "average", "[unused6]", "[SEP]", "[unused1]", "almost", "all", "of", "the", "shares", "in", "the", "20", "-", "stock", "Major", "Market", "Index", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "sharply", "higher", "At", "one", "point", "[unused6]", "[SEP]"]]}

input 424:  {"source": "Avery Inc. said it completed the sale of Uniroyal Chemical Holding Co. to a group led by management of Uniroyal Chemical Co. , the unit 's main business .\n"}
prediction:  {"predictions": [[1, 170, 1372, 2, 3, 1521, 4, 5, 1118, 2635, 1104, 12118, 9992, 18543, 10957, 3291, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12274, 3561, 28138, 2, 3, 1163, 4, 5, 1122, 2063, 1103, 4688, 1104, 12118, 9992, 18543, 10957, 14382, 3291, 28138, 1106, 170, 1372, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12118, 9992, 18543, 10957, 3291, 28138, 2, 3, 1110, 4, 5, 1103, 2587, 112, 1116, 1514, 1671, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 2063, 4, 5, 1103, 4688, 1104, 12118, 9992, 18543, 10957, 14382, 3291, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.033069171011447906, -0.03477994352579117, -0.023432215675711632, -0.06355885416269302, -0.1314690113067627, -0.1362452507019043, -0.1362452507019043, -0.1362452507019043, -0.1362452507019043, -0.1362452507019043], "metadata": {"source_tokens": ["Avery", "Inc", "##.", "said", "it", "completed", "the", "sale", "of", "Un", "##iro", "##yal", "Chemical", "Holding", "Co", "##.", "to", "a", "group", "led", "by", "management", "of", "Un", "##iro", "##yal", "Chemical", "Co", "##.", ",", "the", "unit", "'", "##s", "main", "business", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "group", "[unused2]", "[unused3]", "led", "[unused4]", "[unused5]", "by", "management", "of", "Un", "##iro", "##yal", "Chemical", "Co", "##.", "[unused6]", "[SEP]", "[unused1]", "Avery", "Inc", "##.", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "completed", "the", "sale", "of", "Un", "##iro", "##yal", "Chemical", "Holding", "Co", "##.", "to", "a", "group", "[unused6]", "[SEP]", "[unused1]", "Un", "##iro", "##yal", "Chemical", "Co", "##.", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "unit", "'", "##s", "main", "business", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "completed", "[unused4]", "[unused5]", "the", "sale", "of", "Un", "##iro", "##yal", "Chemical", "Holding", "Co", "##.", "[unused6]", "[SEP]"]]}

input 425:  {"source": "Because patients require less attention from nurses and other staff , room charges are lower -- about $ 100 less per day than a regular room at the Vermont hospital .\n"}
prediction:  {"predictions": [[1, 4420, 2, 3, 4752, 4, 5, 1750, 2209, 1121, 13318, 1105, 1168, 2546, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1395, 4917, 2, 3, 1132, 4, 5, 2211, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1395, 4917, 2, 3, 1132, 4, 5, 2211, 1164, 109, 1620, 1750, 1679, 1285, 1190, 170, 2366, 1395, 1120, 1103, 8472, 2704, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.01207798719406128, -0.05799610912799835, -0.046736884862184525, -0.11993837356567383, -0.11895322799682617, -0.11895322799682617, -0.11895322799682617, -0.11895322799682617, -0.11895322799682617, -0.11895322799682617], "metadata": {"source_tokens": ["Because", "patients", "require", "less", "attention", "from", "nurses", "and", "other", "staff", ",", "room", "charges", "are", "lower", "-", "##-", "about", "$", "100", "less", "per", "day", "than", "a", "regular", "room", "at", "the", "Vermont", "hospital", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "patients", "[unused2]", "[unused3]", "require", "[unused4]", "[unused5]", "less", "attention", "from", "nurses", "and", "other", "staff", "[unused6]", "[SEP]", "[unused1]", "room", "charges", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "lower", "[unused6]", "[SEP]", "[unused1]", "room", "charges", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "lower", "about", "$", "100", "less", "per", "day", "than", "a", "regular", "room", "at", "the", "Vermont", "hospital", "[unused6]", "[SEP]"]]}

input 426:  {"source": "Between flashes , certain areas in subjects ' brains are jolted with a magnetic stimulator .\n"}
prediction:  {"predictions": [[1, 2218, 1877, 1107, 5174, 112, 16570, 2, 3, 1132, 26078, 1174, 4, 5, 1114, 170, 8364, 188, 3121, 13601, 13389, 3847, 18324, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.000626411463599652, -0.03853893280029297, -0.038542747497558594, -0.038542747497558594, -0.038542747497558594, -0.038542747497558594, -0.038542747497558594, -0.038542747497558594, -0.038542747497558594, -0.038542747497558594], "metadata": {"source_tokens": ["Between", "flashes", ",", "certain", "areas", "in", "subjects", "'", "brains", "are", "jolt", "##ed", "with", "a", "magnetic", "s", "##ti", "##mu", "##lator", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "certain", "areas", "in", "subjects", "'", "brains", "[unused2]", "[unused3]", "are", "jolt", "##ed", "[unused4]", "[unused5]", "with", "a", "magnetic", "s", "##ti", "##mu", "##lator", "Between", "flashes", "[unused6]", "[SEP]"]]}

input 427:  {"source": "Both reflect the dismissal of lower - level and shorter - tenure executives .\n"}
prediction:  {"predictions": [[1, 2695, 2, 3, 7977, 4, 5, 1103, 16373, 1104, 2211, 118, 1634, 1105, 7681, 118, 6999, 14011, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.00020837783813476562, -0.00016689300537109375, -0.0001678466796875, -0.0001678466796875, -0.0001678466796875, -0.0001678466796875, -0.0001678466796875, -0.0001678466796875, -0.0001678466796875, -0.0001678466796875], "metadata": {"source_tokens": ["Both", "reflect", "the", "dismissal", "of", "lower", "-", "level", "and", "shorter", "-", "tenure", "executives", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Both", "[unused2]", "[unused3]", "reflect", "[unused4]", "[unused5]", "the", "dismissal", "of", "lower", "-", "level", "and", "shorter", "-", "tenure", "executives", "[unused6]", "[SEP]"]]}

input 428:  {"source": "British government bonds ended moderately higher , encouraged by a steadier pound and a rise in British stocks .\n"}
prediction:  {"predictions": [[1, 1418, 1433, 10150, 2, 3, 2207, 4, 5, 19455, 2299, 6182, 1118, 170, 188, 12679, 2852, 10074, 1105, 170, 3606, 1107, 1418, 17901, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1418, 1433, 10150, 2, 3, 6182, 4, 5, 1118, 170, 188, 12679, 2852, 10074, 1105, 170, 3606, 1107, 1418, 17901, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0375506654381752, -0.030343133956193924, -0.021975994110107422, -0.02199554443359375, -0.02199554443359375, -0.02199554443359375, -0.02199554443359375, -0.02199554443359375, -0.02199554443359375, -0.02199554443359375], "metadata": {"source_tokens": ["British", "government", "bonds", "ended", "moderately", "higher", ",", "encouraged", "by", "a", "s", "##tead", "##ier", "pound", "and", "a", "rise", "in", "British", "stocks", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "British", "government", "bonds", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "moderately", "higher", "encouraged", "by", "a", "s", "##tead", "##ier", "pound", "and", "a", "rise", "in", "British", "stocks", "[unused6]", "[SEP]", "[unused1]", "British", "government", "bonds", "[unused2]", "[unused3]", "encouraged", "[unused4]", "[unused5]", "by", "a", "s", "##tead", "##ier", "pound", "and", "a", "rise", "in", "British", "stocks", "[unused6]", "[SEP]"]]}

input 429:  {"source": "But , with the state offering only $ 39,000 a year and California 's high standard of living , `` there are n't too many to choose from , '' says Brent Scott , a recruiting officer .\n"}
prediction:  {"predictions": [[1, 1103, 1352, 2, 3, 4733, 4, 5, 1178, 109, 3614, 28136, 7629, 1568, 170, 1214, 1105, 1756, 112, 1116, 1344, 2530, 1104, 1690, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 13150, 2796, 2, 3, 1110, 4, 5, 170, 16226, 2575, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1315, 1242, 1106, 4835, 1121, 2, 3, 1175, 1132, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1315, 1242, 1106, 4835, 1121, 2, 3, 1867, 4, 5, 13150, 2796, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.033115681260824203, -0.055611297488212585, -0.1366291493177414, -0.1318829506635666, -0.14819121360778809, -0.14667177200317383, -0.14667177200317383, -0.14667177200317383, -0.14667177200317383, -0.14667177200317383], "metadata": {"source_tokens": ["But", ",", "with", "the", "state", "offering", "only", "$", "39", "##,", "##00", "##0", "a", "year", "and", "California", "'", "##s", "high", "standard", "of", "living", ",", "`", "##`", "there", "are", "n", "##'", "##t", "too", "many", "to", "choose", "from", ",", "'", "##'", "says", "Brent", "Scott", ",", "a", "recruiting", "officer", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "state", "[unused2]", "[unused3]", "offering", "[unused4]", "[unused5]", "only", "$", "39", "##,", "##00", "##0", "a", "year", "and", "California", "'", "##s", "high", "standard", "of", "living", "[unused6]", "[SEP]", "[unused1]", "Brent", "Scott", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "recruiting", "officer", "[unused6]", "[SEP]", "[unused1]", "too", "many", "to", "choose", "from", "[unused2]", "[unused3]", "there", "are", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "too", "many", "to", "choose", "from", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Brent", "Scott", "[unused6]", "[SEP]"]]}

input 430:  {"source": "But although the golden share has been waived , a hostile bidder for Jaguar would still have to alter the British concern 's articles of association which ban shareholdings of more than 15 % .\n"}
prediction:  {"predictions": [[1, 1103, 5404, 2934, 2, 3, 1144, 1151, 17548, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 10518, 6875, 2692, 1111, 21694, 2, 3, 1106, 13000, 4, 5, 1103, 1418, 4517, 112, 1116, 4237, 1104, 3852, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 10518, 6875, 2692, 1111, 21694, 2, 3, 1156, 1138, 4, 5, 1106, 13000, 1103, 1418, 4517, 112, 1116, 4237, 1104, 3852, 1253, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1418, 4517, 112, 1116, 4237, 1104, 3852, 2, 3, 8214, 4, 5, 2934, 20139, 1116, 1104, 1167, 1190, 1405, 110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.07407202571630478, -0.0675995796918869, -0.039765093475580215, -0.040245238691568375, -0.0775306224822998, -0.07758855819702148, -0.07758855819702148, -0.07758855819702148, -0.07758855819702148, -0.07758855819702148], "metadata": {"source_tokens": ["But", "although", "the", "golden", "share", "has", "been", "waived", ",", "a", "hostile", "bid", "##der", "for", "Jaguar", "would", "still", "have", "to", "alter", "the", "British", "concern", "'", "##s", "articles", "of", "association", "which", "ban", "share", "##holding", "##s", "of", "more", "than", "15", "%", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "golden", "share", "[unused2]", "[unused3]", "has", "been", "waived", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "a", "hostile", "bid", "##der", "for", "Jaguar", "[unused2]", "[unused3]", "to", "alter", "[unused4]", "[unused5]", "the", "British", "concern", "'", "##s", "articles", "of", "association", "[unused6]", "[SEP]", "[unused1]", "a", "hostile", "bid", "##der", "for", "Jaguar", "[unused2]", "[unused3]", "would", "have", "[unused4]", "[unused5]", "to", "alter", "the", "British", "concern", "'", "##s", "articles", "of", "association", "still", "[unused6]", "[SEP]", "[unused1]", "the", "British", "concern", "'", "##s", "articles", "of", "association", "[unused2]", "[unused3]", "ban", "[unused4]", "[unused5]", "share", "##holding", "##s", "of", "more", "than", "15", "%", "[unused6]", "[SEP]"]]}

input 431:  {"source": "But amid the two dozen bureaucrats and secretaries sits only one real - life PC .\n"}
prediction:  {"predictions": [[1, 15872, 1103, 1160, 5955, 18561, 22292, 1105, 3318, 5927, 2, 3, 7250, 4, 5, 1178, 1141, 1842, 118, 1297, 7054, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0021042616572231054, -0.0009975433349609375, -0.0010318756103515625, -0.0010318756103515625, -0.0010318756103515625, -0.0010318756103515625, -0.0010318756103515625, -0.0010318756103515625, -0.0010318756103515625, -0.0010318756103515625], "metadata": {"source_tokens": ["But", "amid", "the", "two", "dozen", "bureau", "##crats", "and", "secret", "##aries", "sits", "only", "one", "real", "-", "life", "PC", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "amid", "the", "two", "dozen", "bureau", "##crats", "and", "secret", "##aries", "[unused2]", "[unused3]", "sits", "[unused4]", "[unused5]", "only", "one", "real", "-", "life", "PC", "[unused6]", "[SEP]"]]}

input 432:  {"source": "But fully 90 % of those polled felt they did n't need to belong to a health club .\n"}
prediction:  {"predictions": [[1, 3106, 3078, 110, 1104, 1343, 9590, 1174, 2, 3, 1464, 4, 5, 1152, 1225, 183, 28131, 1204, 1444, 1106, 6772, 1106, 170, 2332, 1526, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1225, 183, 28131, 1204, 1444, 4, 5, 1106, 6772, 1106, 170, 2332, 1526, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0010764643084257841, -0.26171088218688965, -0.036167632788419724, -0.022000789642333984, -0.02200174331665039, -0.02200174331665039, -0.02200174331665039, -0.02200174331665039, -0.02200174331665039, -0.02200174331665039], "metadata": {"source_tokens": ["But", "fully", "90", "%", "of", "those", "poll", "##ed", "felt", "they", "did", "n", "##'", "##t", "need", "to", "belong", "to", "a", "health", "club", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "fully", "90", "%", "of", "those", "poll", "##ed", "[unused2]", "[unused3]", "felt", "[unused4]", "[unused5]", "they", "did", "n", "##'", "##t", "need", "to", "belong", "to", "a", "health", "club", "[unused6]", "[SEP]"]]}

input 433:  {"source": "But he emphasized that new accounts , new sales , inquiries and subsequent sales of stock funds are all up this month from September 's level .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 13463, 4, 5, 1115, 1207, 5756, 117, 1207, 3813, 117, 1107, 24929, 1105, 4194, 3813, 1104, 4482, 4381, 1132, 1155, 1146, 1142, 2370, 1121, 1347, 112, 1116, 1634, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1207, 5756, 117, 1207, 3813, 117, 1107, 24929, 1105, 4194, 3813, 1104, 4482, 4381, 2, 3, 1132, 1146, 4, 5, 1142, 2370, 1121, 1347, 112, 1116, 1634, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0009685020777396858, -0.05655539780855179, -0.076446533203125, -0.07644295692443848, -0.07644295692443848, -0.07644295692443848, -0.07644295692443848, -0.07644295692443848, -0.07644295692443848, -0.07644295692443848], "metadata": {"source_tokens": ["But", "he", "emphasized", "that", "new", "accounts", ",", "new", "sales", ",", "in", "##quiries", "and", "subsequent", "sales", "of", "stock", "funds", "are", "all", "up", "this", "month", "from", "September", "'", "##s", "level", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "emphasized", "[unused4]", "[unused5]", "that", "new", "accounts", ",", "new", "sales", ",", "in", "##quiries", "and", "subsequent", "sales", "of", "stock", "funds", "are", "all", "up", "this", "month", "from", "September", "'", "##s", "level", "[unused6]", "[SEP]", "[unused1]", "new", "accounts", ",", "new", "sales", ",", "in", "##quiries", "and", "subsequent", "sales", "of", "stock", "funds", "[unused2]", "[unused3]", "are", "up", "[unused4]", "[unused5]", "this", "month", "from", "September", "'", "##s", "level", "[unused6]", "[SEP]"]]}

input 434:  {"source": "But it appears to be the sort of hold one makes while heading for the door .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 2691, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1106, 1129, 4, 5, 1103, 3271, 1104, 2080, 1141, 2228, 1229, 5312, 1111, 1103, 1442, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.031218528747558594, -0.017890669405460358, -0.038543701171875, -0.03863239288330078, -0.03863239288330078, -0.03863239288330078, -0.03863239288330078, -0.03863239288330078, -0.03863239288330078, -0.03863239288330078], "metadata": {"source_tokens": ["But", "it", "appears", "to", "be", "the", "sort", "of", "hold", "one", "makes", "while", "heading", "for", "the", "door", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "appears", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "to", "be", "[unused4]", "[unused5]", "the", "sort", "of", "hold", "one", "makes", "while", "heading", "for", "the", "door", "[unused6]", "[SEP]"]]}

input 435:  {"source": "But it does that at the cost of deepening the taxpayer 's exposure if the FHA is forced to pay for more loans going sour .\n"}
prediction:  {"predictions": [[1, 1167, 11453, 2, 3, 1280, 4, 5, 17948, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 143, 11612, 2, 3, 1110, 2257, 4, 5, 1106, 2653, 1111, 1167, 11453, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1674, 4, 5, 1115, 1120, 1103, 2616, 1104, 1996, 4777, 1103, 3641, 4163, 7904, 112, 1116, 7401, 1191, 1103, 143, 11612, 1110, 2257, 1106, 2653, 1111, 1167, 11453, 1280, 17948, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.12135913223028183, -0.05718041956424713, -0.026766804978251457, -0.12374162673950195, -0.12582850456237793, -0.12582850456237793, -0.12582850456237793, -0.12582850456237793, -0.12582850456237793, -0.12582850456237793], "metadata": {"source_tokens": ["But", "it", "does", "that", "at", "the", "cost", "of", "deep", "##ening", "the", "tax", "##pa", "##yer", "'", "##s", "exposure", "if", "the", "F", "##HA", "is", "forced", "to", "pay", "for", "more", "loans", "going", "sour", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "more", "loans", "[unused2]", "[unused3]", "going", "[unused4]", "[unused5]", "sour", "[unused6]", "[SEP]", "[unused1]", "the", "F", "##HA", "[unused2]", "[unused3]", "is", "forced", "[unused4]", "[unused5]", "to", "pay", "for", "more", "loans", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "does", "[unused4]", "[unused5]", "that", "at", "the", "cost", "of", "deep", "##ening", "the", "tax", "##pa", "##yer", "'", "##s", "exposure", "if", "the", "F", "##HA", "is", "forced", "to", "pay", "for", "more", "loans", "going", "sour", "[unused6]", "[SEP]"]]}

input 436:  {"source": "But then Judge O'Kicki often behaved like a man who would be king -- and , some say , an arrogant and abusive one .\n"}
prediction:  {"predictions": [[1, 5274, 152, 28131, 2428, 5345, 1182, 2, 3, 18492, 1181, 4, 5, 1176, 170, 1299, 1173, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1299, 2, 3, 1156, 1129, 4, 5, 2226, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1199, 2, 3, 1474, 4, 5, 1126, 17346, 1105, 22898, 1141, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04602467268705368, -0.021742770448327065, -0.06743825972080231, -0.07735419273376465, -0.07735943794250488, -0.07735943794250488, -0.07735943794250488, -0.07735943794250488, -0.07735943794250488, -0.07735943794250488], "metadata": {"source_tokens": ["But", "then", "Judge", "O", "##'", "##K", "##ick", "##i", "often", "behave", "##d", "like", "a", "man", "who", "would", "be", "king", "-", "##-", "and", ",", "some", "say", ",", "an", "arrogant", "and", "abusive", "one", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Judge", "O", "##'", "##K", "##ick", "##i", "[unused2]", "[unused3]", "behave", "##d", "[unused4]", "[unused5]", "like", "a", "man", "then", "[unused6]", "[SEP]", "[unused1]", "a", "man", "[unused2]", "[unused3]", "would", "be", "[unused4]", "[unused5]", "king", "[unused6]", "[SEP]", "[unused1]", "some", "[unused2]", "[unused3]", "say", "[unused4]", "[unused5]", "an", "arrogant", "and", "abusive", "one", "[unused6]", "[SEP]"]]}

input 437:  {"source": "But we can think of many reasons to stay out for the foreseeable future and well beyond .\n"}
prediction:  {"predictions": [[1, 1195, 2, 3, 1169, 1341, 4, 5, 1104, 1242, 3672, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1195, 2, 3, 1169, 1341, 4, 5, 1104, 1242, 3672, 1106, 2215, 1149, 1111, 1103, 24387, 18628, 1895, 2174, 1105, 1218, 2894, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.022649617865681648, -0.021989312022924423, -0.022021770477294922, -0.02208232879638672, -0.02208232879638672, -0.02208232879638672, -0.02208232879638672, -0.02208232879638672, -0.02208232879638672, -0.02208232879638672], "metadata": {"source_tokens": ["But", "we", "can", "think", "of", "many", "reasons", "to", "stay", "out", "for", "the", "fore", "##see", "##able", "future", "and", "well", "beyond", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "we", "[unused2]", "[unused3]", "can", "think", "[unused4]", "[unused5]", "of", "many", "reasons", "[unused6]", "[SEP]", "[unused1]", "we", "[unused2]", "[unused3]", "can", "think", "[unused4]", "[unused5]", "of", "many", "reasons", "to", "stay", "out", "for", "the", "fore", "##see", "##able", "future", "and", "well", "beyond", "[unused6]", "[SEP]"]]}

input 438:  {"source": "But when they arrived at the door , all were afraid to go in , fearing that they would be out of place .\n"}
prediction:  {"predictions": [[1, 1155, 2, 3, 1127, 4, 5, 3737, 1106, 1301, 1107, 1165, 1152, 2474, 1120, 1103, 1442, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 2474, 4, 5, 1120, 1103, 1442, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1155, 2, 3, 1127, 4, 5, 3737, 1106, 1301, 1107, 19424, 1115, 1152, 1156, 1129, 1149, 1104, 1282, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1155, 2, 3, 1127, 4, 5, 3737, 1106, 1301, 1107, 19424, 1115, 1152, 1156, 1129, 1149, 1104, 1282, 1165, 1152, 2474, 1120, 1103, 1442, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.06401006132364273, -0.03048495203256607, -0.14848847687244415, -0.12732703983783722, -0.12990665435791016, -0.13322734832763672, -0.13322710990905762, -0.13322710990905762, -0.13322710990905762, -0.13322710990905762], "metadata": {"source_tokens": ["But", "when", "they", "arrived", "at", "the", "door", ",", "all", "were", "afraid", "to", "go", "in", ",", "fearing", "that", "they", "would", "be", "out", "of", "place", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "all", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "afraid", "to", "go", "in", "when", "they", "arrived", "at", "the", "door", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "arrived", "[unused4]", "[unused5]", "at", "the", "door", "[unused6]", "[SEP]", "[unused1]", "all", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "afraid", "to", "go", "in", "fearing", "that", "they", "would", "be", "out", "of", "place", "[unused6]", "[SEP]", "[unused1]", "all", "[unused2]", "[unused3]", "were", "[unused4]", "[unused5]", "afraid", "to", "go", "in", "fearing", "that", "they", "would", "be", "out", "of", "place", "when", "they", "arrived", "at", "the", "door", "[unused6]", "[SEP]"]]}

input 439:  {"source": "But wire transfers from a standing account -- including those bigger than $ 10,000 -- are n't reported .\n"}
prediction:  {"predictions": [[1, 7700, 16845, 1121, 170, 2288, 3300, 118, 28137, 1259, 1343, 6706, 1190, 109, 1275, 28136, 7629, 1568, 2, 3, 1132, 183, 28131, 1204, 2103, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0012748200679197907, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578], "metadata": {"source_tokens": ["But", "wire", "transfers", "from", "a", "standing", "account", "-", "##-", "including", "those", "bigger", "than", "$", "10", "##,", "##00", "##0", "-", "##-", "are", "n", "##'", "##t", "reported", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "wire", "transfers", "from", "a", "standing", "account", "-", "##-", "including", "those", "bigger", "than", "$", "10", "##,", "##00", "##0", "[unused2]", "[unused3]", "are", "n", "##'", "##t", "reported", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 440:  {"source": "But yesterday , Mr. Carpenter said big institutional investors , which he would n't identify , `` told us they would n't do business with firms '' that continued to do index arbitrage for their own accounts .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 13190, 2, 3, 1163, 4, 5, 1992, 15040, 9660, 117, 1134, 1119, 1156, 183, 28131, 1204, 6183, 117, 169, 28152, 1500, 1366, 1152, 1156, 183, 28131, 1204, 1202, 1671, 1114, 9780, 8128, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9780, 2, 3, 1598, 4, 5, 1106, 1202, 7448, 170, 26281, 2875, 20240, 1111, 1147, 1319, 5756, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1992, 15040, 9660, 2, 3, 1500, 4, 5, 1366, 1152, 1156, 183, 28131, 1204, 1202, 1671, 1114, 9780, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1156, 183, 28131, 1204, 1202, 4, 5, 1671, 1114, 9780, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1156, 183, 28131, 1204, 1202, 4, 5, 1671, 1114, 9780, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1156, 183, 28131, 1204, 1202, 4, 5, 1671, 1114, 9780, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1156, 183, 28131, 1204, 1202, 4, 5, 1671, 1114, 9780, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1156, 183, 28131, 1204, 1202, 4, 5, 1671, 1114, 9780, 6, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1156, 183, 28131, 1204, 1202, 4, 5, 1671, 1114, 9780, 6, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03755687549710274, -0.037260644137859344, -0.09819082915782928, -0.08329795300960541, -0.11119308322668076, -0.1457120180130005, -0.15257960557937622, -0.15780168771743774, -0.17312070727348328, -0.21305537223815918], "metadata": {"source_tokens": ["But", "yesterday", ",", "Mr", "##.", "Carpenter", "said", "big", "institutional", "investors", ",", "which", "he", "would", "n", "##'", "##t", "identify", ",", "`", "##`", "told", "us", "they", "would", "n", "##'", "##t", "do", "business", "with", "firms", "'", "##'", "that", "continued", "to", "do", "index", "a", "##rb", "##it", "##rage", "for", "their", "own", "accounts", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Carpenter", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "big", "institutional", "investors", ",", "which", "he", "would", "n", "##'", "##t", "identify", ",", "`", "##`", "told", "us", "they", "would", "n", "##'", "##t", "do", "business", "with", "firms", "yesterday", "[unused6]", "[SEP]", "[unused1]", "firms", "[unused2]", "[unused3]", "continued", "[unused4]", "[unused5]", "to", "do", "index", "a", "##rb", "##it", "##rage", "for", "their", "own", "accounts", "[unused6]", "[SEP]", "[unused1]", "big", "institutional", "investors", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "us", "they", "would", "n", "##'", "##t", "do", "business", "with", "firms", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "would", "n", "##'", "##t", "do", "[unused4]", "[unused5]", "business", "with", "firms", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "would", "n", "##'", "##t", "do", "[unused4]", "[unused5]", "business", "with", "firms", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "would", "n", "##'", "##t", "do", "[unused4]", "[unused5]", "business", "with", "firms", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "would", "n", "##'", "##t", "do", "[unused4]", "[unused5]", "business", "with", "firms", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "would", "n", "##'", "##t", "do", "[unused4]", "[unused5]", "business", "with", "firms", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "would", "n", "##'", "##t", "do", "[unused4]", "[unused5]", "business", "with", "firms", "[unused6]", "[SEP]"]]}

input 441:  {"source": "But you ca n't dismiss Mr. Stoltzman 's music or his motives as merely commercial and lightweight .\n"}
prediction:  {"predictions": [[1, 1128, 2, 3, 11019, 183, 28131, 1204, 21728, 4, 5, 1828, 28138, 1457, 17772, 27277, 112, 1116, 1390, 1137, 1117, 18686, 1112, 5804, 2595, 1105, 14939, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.006478868890553713, -0.03235960006713867, -0.03221487998962402, -0.03221487998962402, -0.03221487998962402, -0.03221487998962402, -0.03221487998962402, -0.03221487998962402, -0.03221487998962402, -0.03221487998962402], "metadata": {"source_tokens": ["But", "you", "ca", "n", "##'", "##t", "dismiss", "Mr", "##.", "St", "##olt", "##zman", "'", "##s", "music", "or", "his", "motives", "as", "merely", "commercial", "and", "lightweight", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "you", "[unused2]", "[unused3]", "ca", "n", "##'", "##t", "dismiss", "[unused4]", "[unused5]", "Mr", "##.", "St", "##olt", "##zman", "'", "##s", "music", "or", "his", "motives", "as", "merely", "commercial", "and", "lightweight", "[unused6]", "[SEP]"]]}

input 442:  {"source": "By increasing the number of PCs it uses from 66 to 1,000 , Omron Tateishi Electronics Co. , of Kyoto , hopes not only to make certain tasks easier but also to transform the way the company is run .\n"}
prediction:  {"predictions": [[1, 1103, 1419, 2, 3, 1110, 1576, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 152, 1306, 3484, 9727, 20800, 13983, 3291, 28138, 2, 3, 7816, 4, 5, 1136, 1178, 1106, 1294, 2218, 8249, 5477, 1133, 1145, 1106, 11303, 1103, 1236, 1103, 1419, 1110, 1576, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7054, 1116, 2, 3, 2745, 4, 5, 1121, 5046, 1106, 122, 28136, 7629, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 152, 1306, 3484, 9727, 20800, 13983, 3291, 28138, 1104, 16083, 2, 3, 7816, 4, 5, 1136, 1178, 1106, 1294, 2218, 8249, 5477, 1133, 1145, 1106, 11303, 1103, 1236, 1650, 4138, 1103, 1295, 1104, 7054, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 152, 1306, 3484, 9727, 20800, 13983, 3291, 28138, 1104, 16083, 2, 3, 7816, 4, 5, 1136, 1178, 1106, 11303, 1103, 1236, 1103, 1419, 1110, 1576, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 152, 1306, 3484, 9727, 20800, 13983, 3291, 28138, 1104, 16083, 2, 3, 7816, 4, 5, 1136, 1178, 1106, 1294, 2218, 8249, 5477, 1133, 1145, 1106, 11303, 1103, 1236, 1103, 1419, 1110, 1576, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.09602858871221542, -0.11463989317417145, -0.06124989315867424, -0.1210198923945427, -0.19425521790981293, -0.16822099685668945, -0.2715871334075928, -0.2735217809677124, -0.2735217809677124, -0.2735217809677124], "metadata": {"source_tokens": ["By", "increasing", "the", "number", "of", "PC", "##s", "it", "uses", "from", "66", "to", "1", "##,", "##00", "##0", ",", "O", "##m", "##ron", "Tate", "##ishi", "Electronics", "Co", "##.", ",", "of", "Kyoto", ",", "hopes", "not", "only", "to", "make", "certain", "tasks", "easier", "but", "also", "to", "transform", "the", "way", "the", "company", "is", "run", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "company", "[unused2]", "[unused3]", "is", "run", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "O", "##m", "##ron", "Tate", "##ishi", "Electronics", "Co", "##.", "[unused2]", "[unused3]", "hopes", "[unused4]", "[unused5]", "not", "only", "to", "make", "certain", "tasks", "easier", "but", "also", "to", "transform", "the", "way", "the", "company", "is", "run", "[unused6]", "[SEP]", "[unused1]", "PC", "##s", "[unused2]", "[unused3]", "uses", "[unused4]", "[unused5]", "from", "66", "to", "1", "##,", "##00", "##0", "[unused6]", "[SEP]", "[unused1]", "O", "##m", "##ron", "Tate", "##ishi", "Electronics", "Co", "##.", "of", "Kyoto", "[unused2]", "[unused3]", "hopes", "[unused4]", "[unused5]", "not", "only", "to", "make", "certain", "tasks", "easier", "but", "also", "to", "transform", "the", "way", "By", "increasing", "the", "number", "of", "PC", "##s", "[unused6]", "[SEP]", "[unused1]", "O", "##m", "##ron", "Tate", "##ishi", "Electronics", "Co", "##.", "of", "Kyoto", "[unused2]", "[unused3]", "hopes", "[unused4]", "[unused5]", "not", "only", "to", "transform", "the", "way", "the", "company", "is", "run", "[unused6]", "[SEP]", "[unused1]", "O", "##m", "##ron", "Tate", "##ishi", "Electronics", "Co", "##.", "of", "Kyoto", "[unused2]", "[unused3]", "hopes", "[unused4]", "[unused5]", "not", "only", "to", "make", "certain", "tasks", "easier", "but", "also", "to", "transform", "the", "way", "the", "company", "is", "run", "[unused6]", "[SEP]"]]}

input 443:  {"source": "Coca - Cola Co. , aiming to boost soft - drink volume in Singapore , said it is discussing a joint venture with Fraser & Neave Ltd. , its bottling franchisee in that country .\n"}
prediction:  {"predictions": [[1, 19906, 118, 17492, 3291, 28138, 2, 3, 1163, 4, 5, 1122, 1110, 10751, 170, 4091, 7006, 1114, 9156, 111, 151, 4490, 2707, 4492, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 19906, 118, 17492, 3291, 28138, 2, 3, 1163, 1122, 1110, 10751, 4, 5, 170, 4091, 7006, 1114, 9156, 111, 151, 4490, 2707, 4492, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 19906, 118, 17492, 3291, 28138, 2, 3, 1163, 1122, 1110, 10751, 4, 5, 170, 4091, 7006, 1114, 9156, 111, 151, 4490, 2707, 4492, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 19906, 118, 17492, 3291, 28138, 2, 3, 1163, 1122, 1110, 10751, 4, 5, 170, 4091, 7006, 1114, 9156, 111, 151, 4490, 2707, 4492, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 19906, 118, 17492, 3291, 28138, 2, 3, 1163, 1122, 1110, 10751, 4, 5, 170, 4091, 7006, 1114, 9156, 111, 151, 4490, 2707, 4492, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 19906, 118, 17492, 3291, 28138, 2, 3, 1163, 4, 5, 1122, 1110, 10751, 170, 4091, 7006, 1114, 9156, 111, 151, 4490, 2707, 4492, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.011311637237668037, -0.051208022981882095, -0.05276971682906151, -0.0681668370962143, -0.0834188461303711, -0.09377864748239517, -0.25109076499938965, -0.25116848945617676, -0.25116848945617676, -0.25116848945617676], "metadata": {"source_tokens": ["Coca", "-", "Cola", "Co", "##.", ",", "aiming", "to", "boost", "soft", "-", "drink", "volume", "in", "Singapore", ",", "said", "it", "is", "discussing", "a", "joint", "venture", "with", "Fraser", "&", "N", "##ea", "##ve", "Ltd", "##.", ",", "its", "b", "##ott", "##ling", "franchise", "##e", "in", "that", "country", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Coca", "-", "Cola", "Co", "##.", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "is", "discussing", "a", "joint", "venture", "with", "Fraser", "&", "N", "##ea", "##ve", "Ltd", "##.", "[unused6]", "[SEP]", "[unused1]", "Coca", "-", "Cola", "Co", "##.", "[unused2]", "[unused3]", "said", "it", "is", "discussing", "[unused4]", "[unused5]", "a", "joint", "venture", "with", "Fraser", "&", "N", "##ea", "##ve", "Ltd", "##.", "[unused6]", "[SEP]", "[unused1]", "Coca", "-", "Cola", "Co", "##.", "[unused2]", "[unused3]", "said", "it", "is", "discussing", "[unused4]", "[unused5]", "a", "joint", "venture", "with", "Fraser", "&", "N", "##ea", "##ve", "Ltd", "##.", "[unused6]", "[SEP]", "[unused1]", "Coca", "-", "Cola", "Co", "##.", "[unused2]", "[unused3]", "said", "it", "is", "discussing", "[unused4]", "[unused5]", "a", "joint", "venture", "with", "Fraser", "&", "N", "##ea", "##ve", "Ltd", "##.", "[unused6]", "[SEP]", "[unused1]", "Coca", "-", "Cola", "Co", "##.", "[unused2]", "[unused3]", "said", "it", "is", "discussing", "[unused4]", "[unused5]", "a", "joint", "venture", "with", "Fraser", "&", "N", "##ea", "##ve", "Ltd", "##.", "[unused6]", "[SEP]", "[unused1]", "Coca", "-", "Cola", "Co", "##.", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "is", "discussing", "a", "joint", "venture", "with", "Fraser", "&", "N", "##ea", "##ve", "Ltd", "##.", "[unused6]", "[SEP]"]]}

input 444:  {"source": "Combined PC and work - station use in Japan will jump as much as 25 % annually over the next five years , according to some analysts , compared with about 10 % in the U.S. .\n"}
prediction:  {"predictions": [[1, 16544, 7054, 1105, 1250, 118, 1466, 1329, 1107, 1999, 2, 3, 1209, 5152, 4, 5, 1112, 1277, 1112, 1512, 110, 6089, 1166, 1103, 1397, 1421, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16544, 7054, 1105, 1250, 1466, 1329, 1107, 1999, 2, 3, 1209, 5152, 4, 5, 1112, 1277, 1112, 1512, 110, 2452, 1106, 1199, 22018, 3402, 1114, 1164, 1275, 110, 1107, 1103, 158, 28138, 1708, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16544, 7054, 1105, 1250, 1466, 1329, 1107, 1999, 2, 3, 1209, 5152, 4, 5, 1112, 1277, 1112, 1512, 110, 2452, 1106, 1199, 22018, 3402, 1114, 1164, 1275, 110, 1107, 1103, 158, 28138, 1708, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.01683392934501171, -0.04944651573896408, -0.0770951509475708, -0.2190265655517578, -0.238641619682312, -0.238641619682312, -0.238641619682312, -0.238641619682312, -0.238641619682312, -0.238641619682312], "metadata": {"source_tokens": ["Combined", "PC", "and", "work", "-", "station", "use", "in", "Japan", "will", "jump", "as", "much", "as", "25", "%", "annually", "over", "the", "next", "five", "years", ",", "according", "to", "some", "analysts", ",", "compared", "with", "about", "10", "%", "in", "the", "U", "##.", "##S", "##.", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Combined", "PC", "and", "work", "-", "station", "use", "in", "Japan", "[unused2]", "[unused3]", "will", "jump", "[unused4]", "[unused5]", "as", "much", "as", "25", "%", "annually", "over", "the", "next", "five", "years", "[unused6]", "[SEP]", "[unused1]", "Combined", "PC", "and", "work", "station", "use", "in", "Japan", "[unused2]", "[unused3]", "will", "jump", "[unused4]", "[unused5]", "as", "much", "as", "25", "%", "according", "to", "some", "analysts", "compared", "with", "about", "10", "%", "in", "the", "U", "##.", "##S", "##.", "[unused6]", "[SEP]", "[unused1]", "Combined", "PC", "and", "work", "station", "use", "in", "Japan", "[unused2]", "[unused3]", "will", "jump", "[unused4]", "[unused5]", "as", "much", "as", "25", "%", "according", "to", "some", "analysts", "compared", "with", "about", "10", "%", "in", "the", "U", "##.", "##S", "##.", "[unused6]", "[SEP]"]]}

input 445:  {"source": "Company officials said the current robust domestic demand that has been fueling sustained economic expansion helped push up sales of products like ships , steel structures , power systems and machinery and resulted in sharply higher profit .\n"}
prediction:  {"predictions": [[1, 1881, 3878, 2, 3, 1163, 4, 5, 1103, 1954, 17351, 4500, 4555, 1115, 1144, 1151, 4251, 1158, 8505, 2670, 4298, 2375, 4684, 1146, 3813, 1104, 2982, 1176, 2968, 117, 3649, 4413, 117, 1540, 2344, 1105, 11360, 1105, 3657, 1107, 8930, 2299, 5022, 6, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1954, 17351, 4500, 4555, 2, 3, 1144, 1151, 4251, 1158, 4, 5, 8505, 2670, 4298, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1954, 17351, 4500, 4555, 2, 3, 1144, 1151, 4251, 1158, 4, 5, 8505, 2670, 4298, 2375, 4684, 1146, 3813, 1104, 2982, 1176, 2968, 117, 3649, 4413, 117, 1540, 2344, 1105, 11360, 1105, 3657, 1107, 8930, 2299, 5022, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1954, 17351, 4500, 4555, 2, 3, 1144, 1151, 4251, 1158, 4, 5, 8505, 2670, 4298, 2375, 4684, 1146, 3813, 1104, 2982, 1176, 2968, 117, 3649, 4413, 117, 1540, 2344, 1105, 11360, 1105, 3657, 1107, 8930, 2299, 5022, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.018027646467089653, -0.07854960113763809, -0.09007733315229416, -0.22452831268310547, -0.11351336538791656, -0.2126626968383789, -0.2128450870513916, -0.2128450870513916, -0.2128450870513916, -0.2128450870513916], "metadata": {"source_tokens": ["Company", "officials", "said", "the", "current", "robust", "domestic", "demand", "that", "has", "been", "fuel", "##ing", "sustained", "economic", "expansion", "helped", "push", "up", "sales", "of", "products", "like", "ships", ",", "steel", "structures", ",", "power", "systems", "and", "machinery", "and", "resulted", "in", "sharply", "higher", "profit", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Company", "officials", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "current", "robust", "domestic", "demand", "that", "has", "been", "fuel", "##ing", "sustained", "economic", "expansion", "helped", "push", "up", "sales", "of", "products", "like", "ships", ",", "steel", "structures", ",", "power", "systems", "and", "machinery", "and", "resulted", "in", "sharply", "higher", "profit", "[unused6]", "[SEP]", "[unused1]", "the", "current", "robust", "domestic", "demand", "[unused2]", "[unused3]", "has", "been", "fuel", "##ing", "[unused4]", "[unused5]", "sustained", "economic", "expansion", "[unused6]", "[SEP]", "[unused1]", "the", "current", "robust", "domestic", "demand", "[unused2]", "[unused3]", "has", "been", "fuel", "##ing", "[unused4]", "[unused5]", "sustained", "economic", "expansion", "helped", "push", "up", "sales", "of", "products", "like", "ships", ",", "steel", "structures", ",", "power", "systems", "and", "machinery", "and", "resulted", "in", "sharply", "higher", "profit", "[unused6]", "[SEP]"]]}

input 446:  {"source": "Considered as a whole , Mr. Lane said , the filings required under the proposed rules `` will be at least as effective , if not more so , for investors following transactions . ''\n"}
prediction:  {"predictions": [[1, 1828, 28138, 5319, 2, 3, 1163, 4, 5, 1103, 16504, 1116, 2320, 1223, 1103, 3000, 2995, 169, 28152, 1209, 1129, 1120, 1655, 1112, 3903, 117, 1191, 1136, 1167, 1177, 117, 1111, 9660, 1378, 14409, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 16504, 1116, 2, 3, 2320, 4, 5, 1223, 1103, 3000, 2995, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 16504, 1116, 2320, 1223, 1103, 3000, 2995, 2, 3, 1209, 1129, 4, 5, 1120, 1655, 1112, 3903, 1191, 1136, 1167, 1177, 1111, 9660, 1378, 14409, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.017295103520154953, -0.06409347057342529, -0.0790630429983139, -0.1298215389251709, -0.13474512100219727, -0.13474512100219727, -0.13474512100219727, -0.13474512100219727, -0.13474512100219727, -0.13474512100219727], "metadata": {"source_tokens": ["Consider", "##ed", "as", "a", "whole", ",", "Mr", "##.", "Lane", "said", ",", "the", "filing", "##s", "required", "under", "the", "proposed", "rules", "`", "##`", "will", "be", "at", "least", "as", "effective", ",", "if", "not", "more", "so", ",", "for", "investors", "following", "transactions", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Lane", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "filing", "##s", "required", "under", "the", "proposed", "rules", "`", "##`", "will", "be", "at", "least", "as", "effective", ",", "if", "not", "more", "so", ",", "for", "investors", "following", "transactions", "[unused6]", "[SEP]", "[unused1]", "the", "filing", "##s", "[unused2]", "[unused3]", "required", "[unused4]", "[unused5]", "under", "the", "proposed", "rules", "[unused6]", "[SEP]", "[unused1]", "the", "filing", "##s", "required", "under", "the", "proposed", "rules", "[unused2]", "[unused3]", "will", "be", "[unused4]", "[unused5]", "at", "least", "as", "effective", "if", "not", "more", "so", "for", "investors", "following", "transactions", "[unused6]", "[SEP]"]]}

input 447:  {"source": "Crouched at shortstop , Bert Campaneris , once Oakland 's master thief , effortlessly scoops up a groundball and flips it to second .\n"}
prediction:  {"predictions": [[1, 15035, 5503, 6354, 4889, 2, 3, 3098, 8709, 188, 2528, 9706, 1146, 4, 5, 170, 1747, 5892, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 15035, 5503, 6354, 4889, 2, 3, 12785, 1116, 4, 5, 1122, 1106, 1248, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 15035, 5503, 6354, 4889, 2, 3, 12785, 1116, 4, 5, 1122, 140, 22454, 1174, 1120, 9330, 9870, 1517, 8847, 112, 1116, 3283, 16529, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.09191946685314178, -0.08772638440132141, -0.11162208765745163, -0.14775824546813965, -0.13675951957702637, -0.13675951957702637, -0.13675951957702637, -0.13675951957702637, -0.13675951957702637, -0.13675951957702637], "metadata": {"source_tokens": ["C", "##rouch", "##ed", "at", "shorts", "##top", ",", "Bert", "Camp", "##ane", "##ris", ",", "once", "Oakland", "'", "##s", "master", "thief", ",", "effort", "##lessly", "s", "##co", "##ops", "up", "a", "ground", "##ball", "and", "flip", "##s", "it", "to", "second", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Bert", "Camp", "##ane", "##ris", "[unused2]", "[unused3]", "effort", "##lessly", "s", "##co", "##ops", "up", "[unused4]", "[unused5]", "a", "ground", "##ball", "[unused6]", "[SEP]", "[unused1]", "Bert", "Camp", "##ane", "##ris", "[unused2]", "[unused3]", "flip", "##s", "[unused4]", "[unused5]", "it", "to", "second", "[unused6]", "[SEP]", "[unused1]", "Bert", "Camp", "##ane", "##ris", "[unused2]", "[unused3]", "flip", "##s", "[unused4]", "[unused5]", "it", "C", "##rouch", "##ed", "at", "shorts", "##top", "once", "Oakland", "'", "##s", "master", "thief", "[unused6]", "[SEP]"]]}

input 448:  {"source": "Daimler said it has had talks with Jaguar about possible joint ventures .\n"}
prediction:  {"predictions": [[1, 23084, 20465, 2, 3, 1163, 4, 5, 1122, 1144, 1125, 7430, 1114, 21694, 1164, 1936, 4091, 20135, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.00022363662719726562, -0.056464195251464844, -0.10364508628845215, -0.10364508628845215, -0.10364508628845215, -0.10364508628845215, -0.10364508628845215, -0.10364508628845215, -0.10364508628845215, -0.10364508628845215], "metadata": {"source_tokens": ["Dai", "##mler", "said", "it", "has", "had", "talks", "with", "Jaguar", "about", "possible", "joint", "ventures", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Dai", "##mler", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "has", "had", "talks", "with", "Jaguar", "about", "possible", "joint", "ventures", "[unused6]", "[SEP]"]]}

input 449:  {"source": "Despite the modest gains , traders said the market remains dull , with investors remaining cautiously on the sidelines .\n"}
prediction:  {"predictions": [[1, 14552, 2, 3, 1163, 4, 5, 1103, 2319, 2606, 10884, 117, 1114, 9660, 2735, 16828, 1113, 1103, 1334, 10443, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2319, 2, 3, 2606, 4, 5, 10884, 1114, 9660, 2735, 16828, 1113, 1103, 1334, 10443, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.005322044715285301, -0.13238193094730377, -0.03253960609436035, -0.03252220153808594, -0.03252220153808594, -0.03252220153808594, -0.03252220153808594, -0.03252220153808594, -0.03252220153808594, -0.03252220153808594], "metadata": {"source_tokens": ["Despite", "the", "modest", "gains", ",", "traders", "said", "the", "market", "remains", "dull", ",", "with", "investors", "remaining", "cautiously", "on", "the", "side", "##lines", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "traders", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "market", "remains", "dull", ",", "with", "investors", "remaining", "cautiously", "on", "the", "side", "##lines", "[unused6]", "[SEP]", "[unused1]", "the", "market", "[unused2]", "[unused3]", "remains", "[unused4]", "[unused5]", "dull", "with", "investors", "remaining", "cautiously", "on", "the", "side", "##lines", "[unused6]", "[SEP]"]]}

input 450:  {"source": "During the past 25 years , the number of balloonists ( those who have passed a Federal Aviation Authority lighter - than - air test ) have swelled from a couple hundred to several thousand , with some estimates running as high as 10,000 .\n"}
prediction:  {"predictions": [[1, 1103, 1295, 1104, 15758, 3681, 2, 3, 1138, 24201, 4, 5, 1121, 170, 2337, 2937, 1106, 1317, 4032, 1507, 1103, 1763, 1512, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1199, 10777, 2, 3, 1919, 4, 5, 1112, 1344, 1112, 1275, 28136, 7629, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1343, 2, 3, 1138, 2085, 4, 5, 170, 3467, 7650, 5987, 9310, 1190, 1586, 2774, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1295, 1104, 15758, 3681, 1343, 2, 3, 1138, 24201, 4, 5, 1121, 170, 2337, 2937, 1106, 1317, 4032, 1114, 1199, 10777, 1919, 1112, 1344, 1112, 1275, 28136, 7629, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1295, 1104, 15758, 3681, 1343, 2, 3, 1138, 24201, 4, 5, 1121, 170, 2337, 2937, 1106, 1317, 4032, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1295, 1104, 15758, 3681, 1343, 2, 3, 1138, 24201, 4, 5, 1121, 170, 2337, 2937, 1106, 1317, 4032, 1114, 1199, 10777, 1919, 1112, 1344, 1112, 1275, 28136, 7629, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04297289624810219, -0.021201105788350105, -0.06395870447158813, -0.09737563878297806, -0.15514391660690308, -0.1324089765548706, -0.32967352867126465, -0.3311828374862671, -0.3311828374862671, -0.3311828374862671], "metadata": {"source_tokens": ["During", "the", "past", "25", "years", ",", "the", "number", "of", "balloon", "##ists", "(", "those", "who", "have", "passed", "a", "Federal", "Aviation", "Authority", "lighter", "-", "than", "-", "air", "test", ")", "have", "swelled", "from", "a", "couple", "hundred", "to", "several", "thousand", ",", "with", "some", "estimates", "running", "as", "high", "as", "10", "##,", "##00", "##0", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "number", "of", "balloon", "##ists", "[unused2]", "[unused3]", "have", "swelled", "[unused4]", "[unused5]", "from", "a", "couple", "hundred", "to", "several", "thousand", "During", "the", "past", "25", "years", "[unused6]", "[SEP]", "[unused1]", "some", "estimates", "[unused2]", "[unused3]", "running", "[unused4]", "[unused5]", "as", "high", "as", "10", "##,", "##00", "##0", "[unused6]", "[SEP]", "[unused1]", "those", "[unused2]", "[unused3]", "have", "passed", "[unused4]", "[unused5]", "a", "Federal", "Aviation", "Authority", "lighter", "than", "air", "test", "[unused6]", "[SEP]", "[unused1]", "the", "number", "of", "balloon", "##ists", "those", "[unused2]", "[unused3]", "have", "swelled", "[unused4]", "[unused5]", "from", "a", "couple", "hundred", "to", "several", "thousand", "with", "some", "estimates", "running", "as", "high", "as", "10", "##,", "##00", "##0", "[unused6]", "[SEP]", "[unused1]", "the", "number", "of", "balloon", "##ists", "those", "[unused2]", "[unused3]", "have", "swelled", "[unused4]", "[unused5]", "from", "a", "couple", "hundred", "to", "several", "thousand", "[unused6]", "[SEP]", "[unused1]", "the", "number", "of", "balloon", "##ists", "those", "[unused2]", "[unused3]", "have", "swelled", "[unused4]", "[unused5]", "from", "a", "couple", "hundred", "to", "several", "thousand", "with", "some", "estimates", "running", "as", "high", "as", "10", "##,", "##00", "##0", "[unused6]", "[SEP]"]]}

input 451:  {"source": "Each company 's share of liability would be based on their share of the national DES market .\n"}
prediction:  {"predictions": [[1, 2994, 1419, 112, 1116, 2934, 1104, 15509, 2, 3, 1156, 1129, 1359, 4, 5, 1113, 1147, 2934, 1104, 1103, 1569, 18581, 1708, 2319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0001464531960664317, -0.0005192756652832031, -0.0005202293395996094, -0.0005202293395996094, -0.0005202293395996094, -0.0005202293395996094, -0.0005202293395996094, -0.0005202293395996094, -0.0005202293395996094, -0.0005202293395996094], "metadata": {"source_tokens": ["Each", "company", "'", "##s", "share", "of", "liability", "would", "be", "based", "on", "their", "share", "of", "the", "national", "DE", "##S", "market", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Each", "company", "'", "##s", "share", "of", "liability", "[unused2]", "[unused3]", "would", "be", "based", "[unused4]", "[unused5]", "on", "their", "share", "of", "the", "national", "DE", "##S", "market", "[unused6]", "[SEP]"]]}

input 452:  {"source": "Earlier this year , Blackstone Group , a New York investment bank , had no trouble selling out a special $ 570 million mortgage - securities trust it created for Japanese investors .\n"}
prediction:  {"predictions": [[1, 21861, 4793, 1990, 2, 3, 1125, 4, 5, 1185, 3819, 4147, 1149, 170, 1957, 109, 28081, 1550, 16935, 118, 19313, 3496, 15993, 1142, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1957, 109, 28081, 1550, 16935, 118, 19313, 3496, 2, 3, 1687, 4, 5, 1111, 1983, 9660, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 21861, 4793, 1990, 2, 3, 1110, 4, 5, 170, 1203, 1365, 5151, 3085, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.006659432779997587, -0.02960921823978424, -0.04472287744283676, -0.11922359466552734, -0.1192476749420166, -0.1192476749420166, -0.1192476749420166, -0.1192476749420166, -0.1192476749420166, -0.1192476749420166], "metadata": {"source_tokens": ["Earlier", "this", "year", ",", "Blacks", "##tone", "Group", ",", "a", "New", "York", "investment", "bank", ",", "had", "no", "trouble", "selling", "out", "a", "special", "$", "570", "million", "mortgage", "-", "securities", "trust", "it", "created", "for", "Japanese", "investors", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Blacks", "##tone", "Group", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "no", "trouble", "selling", "out", "a", "special", "$", "570", "million", "mortgage", "-", "securities", "trust", "Earlier", "this", "year", "[unused6]", "[SEP]", "[unused1]", "a", "special", "$", "570", "million", "mortgage", "-", "securities", "trust", "[unused2]", "[unused3]", "created", "[unused4]", "[unused5]", "for", "Japanese", "investors", "[unused6]", "[SEP]", "[unused1]", "Blacks", "##tone", "Group", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "New", "York", "investment", "bank", "[unused6]", "[SEP]"]]}

input 453:  {"source": "Early in the morning Mr. Sider , an estate lawyer , pores over last wills and testaments .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 6383, 1197, 2, 3, 185, 12238, 4, 5, 1166, 1314, 1209, 1116, 1105, 2774, 11462, 1116, 4503, 1107, 1103, 2106, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 6383, 1197, 2, 3, 1110, 4, 5, 1126, 3327, 4545, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0047192382626235485, -0.01522709522396326, -0.07437968254089355, -0.07530641555786133, -0.07530641555786133, -0.07530641555786133, -0.07530641555786133, -0.07530641555786133, -0.07530641555786133, -0.07530641555786133], "metadata": {"source_tokens": ["Early", "in", "the", "morning", "Mr", "##.", "Side", "##r", ",", "an", "estate", "lawyer", ",", "p", "##ores", "over", "last", "will", "##s", "and", "test", "##ament", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Side", "##r", "[unused2]", "[unused3]", "p", "##ores", "[unused4]", "[unused5]", "over", "last", "will", "##s", "and", "test", "##ament", "##s", "Early", "in", "the", "morning", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "Side", "##r", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "estate", "lawyer", "[unused6]", "[SEP]"]]}

input 454:  {"source": "Edison Brothers Stores Inc. said it agreed to buy 229 Foxmoor women 's apparel stores from Foxmoor Specialty Stores Corp. , a unit of Dylex Ltd. of Toronto .\n"}
prediction:  {"predictions": [[1, 18221, 5216, 26811, 3561, 2, 3, 1163, 4, 5, 1122, 2675, 1106, 4417, 25325, 3977, 19216, 1535, 112, 1116, 12647, 24971, 4822, 1121, 3977, 19216, 3139, 2340, 26811, 13619, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 2675, 4, 5, 1106, 4417, 25325, 3977, 19216, 1535, 112, 1116, 12647, 24971, 4822, 1121, 3977, 19216, 3139, 2340, 26811, 13619, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3977, 19216, 3139, 2340, 26811, 13619, 2, 3, 1110, 4, 5, 170, 2587, 1104, 141, 12415, 1775, 4492, 28138, 1104, 3506, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 2675, 4, 5, 1106, 4417, 25325, 3977, 19216, 1535, 112, 1116, 12647, 24971, 4822, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04011252522468567, -0.09633274376392365, -0.07458239048719406, -0.08657348901033401, -0.15882205963134766, -0.16378331184387207, -0.16378331184387207, -0.16378331184387207, -0.16378331184387207, -0.16378331184387207], "metadata": {"source_tokens": ["Edison", "Brothers", "Stores", "Inc", "##.", "said", "it", "agreed", "to", "buy", "229", "Fox", "##moor", "women", "'", "##s", "app", "##arel", "stores", "from", "Fox", "##moor", "Special", "##ty", "Stores", "Corp", "##.", ",", "a", "unit", "of", "D", "##yle", "##x", "Ltd", "##.", "of", "Toronto", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Edison", "Brothers", "Stores", "Inc", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "agreed", "to", "buy", "229", "Fox", "##moor", "women", "'", "##s", "app", "##arel", "stores", "from", "Fox", "##moor", "Special", "##ty", "Stores", "Corp", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "buy", "229", "Fox", "##moor", "women", "'", "##s", "app", "##arel", "stores", "from", "Fox", "##moor", "Special", "##ty", "Stores", "Corp", "##.", "[unused6]", "[SEP]", "[unused1]", "Fox", "##moor", "Special", "##ty", "Stores", "Corp", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "unit", "of", "D", "##yle", "##x", "Ltd", "##.", "of", "Toronto", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "buy", "229", "Fox", "##moor", "women", "'", "##s", "app", "##arel", "stores", "[unused6]", "[SEP]"]]}

input 455:  {"source": "Employers could also pay a subminimum `` training wage '' for 90 days to new workers who are up to 19 years old , and then for another 90 days if the company institutes a specific training program for the newcomers .\n"}
prediction:  {"predictions": [[1, 1103, 1419, 2, 3, 19077, 4, 5, 170, 2747, 2013, 1788, 1111, 1103, 25551, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 18653, 1643, 26179, 1468, 2, 3, 1180, 2653, 4, 5, 170, 4841, 25685, 16268, 2013, 12634, 1111, 3078, 1552, 1106, 1207, 3239, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1207, 3239, 2, 3, 1132, 4, 5, 1146, 1106, 1627, 1201, 1385, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 18653, 1643, 26179, 1468, 2, 3, 1180, 2653, 4, 5, 170, 4841, 25685, 16268, 2013, 12634, 1111, 3078, 1552, 1105, 1173, 1111, 1330, 3078, 1552, 1191, 1103, 1419, 19077, 170, 2747, 2013, 1788, 1111, 1103, 25551, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 18653, 1643, 26179, 1468, 2, 3, 1180, 2653, 4, 5, 170, 4841, 25685, 16268, 2013, 12634, 1145, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 18653, 1643, 26179, 1468, 2, 3, 1180, 2653, 4, 5, 170, 4841, 25685, 16268, 2013, 12634, 1111, 3078, 1552, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 18653, 1643, 26179, 1468, 2, 3, 1180, 2653, 4, 5, 170, 4841, 25685, 16268, 2013, 12634, 1111, 3078, 1552, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.03751857578754425, -0.07811661064624786, -0.0519571453332901, -0.09462332725524902, -0.3047637939453125, -0.09633927047252655, -0.1266350895166397, -0.1458241194486618, -0.2608555555343628, -0.2621583938598633], "metadata": {"source_tokens": ["Em", "##p", "##loy", "##ers", "could", "also", "pay", "a", "sub", "##mini", "##mum", "`", "##`", "training", "wage", "'", "##'", "for", "90", "days", "to", "new", "workers", "who", "are", "up", "to", "19", "years", "old", ",", "and", "then", "for", "another", "90", "days", "if", "the", "company", "institutes", "a", "specific", "training", "program", "for", "the", "newcomer", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "company", "[unused2]", "[unused3]", "institutes", "[unused4]", "[unused5]", "a", "specific", "training", "program", "for", "the", "newcomer", "##s", "[unused6]", "[SEP]", "[unused1]", "Em", "##p", "##loy", "##ers", "[unused2]", "[unused3]", "could", "pay", "[unused4]", "[unused5]", "a", "sub", "##mini", "##mum", "training", "wage", "for", "90", "days", "to", "new", "workers", "[unused6]", "[SEP]", "[unused1]", "new", "workers", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "up", "to", "19", "years", "old", "[unused6]", "[SEP]", "[unused1]", "Em", "##p", "##loy", "##ers", "[unused2]", "[unused3]", "could", "pay", "[unused4]", "[unused5]", "a", "sub", "##mini", "##mum", "training", "wage", "for", "90", "days", "and", "then", "for", "another", "90", "days", "if", "the", "company", "institutes", "a", "specific", "training", "program", "for", "the", "newcomer", "##s", "[unused6]", "[SEP]"]]}

input 456:  {"source": "Ever since , the remaining members have been desperate for the United States to rejoin this dreadful group .\n"}
prediction:  {"predictions": [[1, 1103, 2735, 1484, 2, 3, 1138, 1151, 4, 5, 7127, 1111, 1103, 1244, 1311, 1106, 1231, 25665, 1142, 25671, 1372, 10006, 1290, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2735, 1484, 2, 3, 1138, 1151, 4, 5, 7127, 1106, 1231, 25665, 1142, 25671, 1372, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.003253073198720813, -0.0764811635017395, -0.07619619369506836, -0.1123969554901123, -0.1123969554901123, -0.1123969554901123, -0.1123969554901123, -0.1123969554901123, -0.1123969554901123, -0.1123969554901123], "metadata": {"source_tokens": ["Ever", "since", ",", "the", "remaining", "members", "have", "been", "desperate", "for", "the", "United", "States", "to", "re", "##join", "this", "dreadful", "group", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "remaining", "members", "[unused2]", "[unused3]", "have", "been", "[unused4]", "[unused5]", "desperate", "for", "the", "United", "States", "to", "re", "##join", "this", "dreadful", "group", "Ever", "since", "[unused6]", "[SEP]", "[unused1]", "the", "remaining", "members", "[unused2]", "[unused3]", "have", "been", "[unused4]", "[unused5]", "desperate", "to", "re", "##join", "this", "dreadful", "group", "[unused6]", "[SEP]"]]}

input 457:  {"source": "Feeling the naggings of a culture imperative , I promptly signed up .\n"}
prediction:  {"predictions": [[1, 146, 2, 3, 13796, 1878, 1146, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 146, 2, 3, 1878, 1146, 4, 5, 13085, 1103, 9468, 10932, 1116, 1104, 170, 2754, 24034, 21126, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.06206391006708145, -0.036873720586299896, -0.008797645568847656, -0.008796215057373047, -0.008796215057373047, -0.008796215057373047, -0.008796215057373047, -0.008796215057373047, -0.008796215057373047, -0.008796215057373047], "metadata": {"source_tokens": ["Feeling", "the", "na", "##gging", "##s", "of", "a", "culture", "imp", "##erative", ",", "I", "promptly", "signed", "up", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "I", "[unused2]", "[unused3]", "promptly", "signed", "up", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "I", "[unused2]", "[unused3]", "signed", "up", "[unused4]", "[unused5]", "Feeling", "the", "na", "##gging", "##s", "of", "a", "culture", "imp", "##erative", "[unused6]", "[SEP]"]]}

input 458:  {"source": "Few people in the advertising business have raised as many hackles as Alvin A. Achenbaum .\n"}
prediction:  {"predictions": [[1, 17751, 1234, 1107, 1103, 6437, 1671, 2, 3, 1138, 2120, 4, 5, 1112, 1242, 5871, 19053, 1116, 1112, 18577, 138, 28138, 138, 10415, 14318, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.00048315967433154583, -0.0006666183471679688, -0.0007710456848144531, -0.0007710456848144531, -0.0007710456848144531, -0.0007710456848144531, -0.0007710456848144531, -0.0007710456848144531, -0.0007710456848144531, -0.0007710456848144531], "metadata": {"source_tokens": ["Few", "people", "in", "the", "advertising", "business", "have", "raised", "as", "many", "ha", "##ckle", "##s", "as", "Alvin", "A", "##.", "A", "##chen", "##baum", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Few", "people", "in", "the", "advertising", "business", "[unused2]", "[unused3]", "have", "raised", "[unused4]", "[unused5]", "as", "many", "ha", "##ckle", "##s", "as", "Alvin", "A", "##.", "A", "##chen", "##baum", "[unused6]", "[SEP]"]]}

input 459:  {"source": "Finally , Mitsubishi Estate has no plans to interfere with Rockefeller 's management beyond taking a place on the board .\n"}
prediction:  {"predictions": [[1, 21450, 9765, 2, 3, 1144, 4, 5, 1185, 2714, 1106, 15891, 1114, 17768, 112, 1116, 2635, 2894, 1781, 170, 1282, 1113, 1103, 2313, 4428, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.003721405053511262, -0.2094428539276123, -0.31724441051483154, -0.31724441051483154, -0.31724441051483154, -0.31724441051483154, -0.31724441051483154, -0.31724441051483154, -0.31724441051483154, -0.31724441051483154], "metadata": {"source_tokens": ["Finally", ",", "Mitsubishi", "Estate", "has", "no", "plans", "to", "interfere", "with", "Rockefeller", "'", "##s", "management", "beyond", "taking", "a", "place", "on", "the", "board", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mitsubishi", "Estate", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "no", "plans", "to", "interfere", "with", "Rockefeller", "'", "##s", "management", "beyond", "taking", "a", "place", "on", "the", "board", "Finally", "[unused6]", "[SEP]"]]}

input 460:  {"source": "First Boston incurred millions of dollars of losses on Campeau securities it owned as well as on special securities it could n't sell .\n"}
prediction:  {"predictions": [[1, 1957, 19313, 2, 3, 1180, 183, 28131, 1204, 4582, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2859, 2, 3, 25240, 4, 5, 9215, 1104, 5860, 1104, 6053, 1113, 5503, 8221, 19313, 1752, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 2205, 1112, 1218, 1112, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.11281456798315048, -0.066945880651474, -0.1986551135778427, -0.15024805068969727, -0.1500227451324463, -0.1500227451324463, -0.1500227451324463, -0.1500227451324463, -0.1500227451324463, -0.1500227451324463], "metadata": {"source_tokens": ["First", "Boston", "incurred", "millions", "of", "dollars", "of", "losses", "on", "Camp", "##eau", "securities", "it", "owned", "as", "well", "as", "on", "special", "securities", "it", "could", "n", "##'", "##t", "sell", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "special", "securities", "[unused2]", "[unused3]", "could", "n", "##'", "##t", "sell", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Boston", "[unused2]", "[unused3]", "incurred", "[unused4]", "[unused5]", "millions", "of", "dollars", "of", "losses", "on", "Camp", "##eau", "securities", "First", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "owned", "as", "well", "as", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 461:  {"source": "For example , a passenger can fly from Chardon , Neb. , to Denver for as little as $ 89 to $ 109 , according to prices quoted by the company .\n"}
prediction:  {"predictions": [[1, 7352, 2, 3, 9129, 4, 5, 1118, 1103, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4059, 2, 3, 1169, 4689, 4, 5, 1121, 24705, 22528, 117, 151, 15581, 28138, 117, 1106, 7068, 1111, 1112, 1376, 1112, 109, 5840, 1106, 109, 11523, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4059, 2, 3, 1169, 4689, 4, 5, 1121, 24705, 22528, 151, 15581, 28138, 1370, 1859, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4059, 2, 3, 1169, 4689, 4, 5, 1121, 24705, 22528, 151, 15581, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4059, 2, 3, 1169, 4689, 4, 5, 1121, 24705, 22528, 151, 15581, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.004103580955415964, -0.05652334913611412, -0.13978269696235657, -0.1336812973022461, -0.1628795564174652, -0.2804124355316162, -0.2804884910583496, -0.2804884910583496, -0.2804884910583496, -0.2804884910583496], "metadata": {"source_tokens": ["For", "example", ",", "a", "passenger", "can", "fly", "from", "Cha", "##rdon", ",", "N", "##eb", "##.", ",", "to", "Denver", "for", "as", "little", "as", "$", "89", "to", "$", "109", ",", "according", "to", "prices", "quoted", "by", "the", "company", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "prices", "[unused2]", "[unused3]", "quoted", "[unused4]", "[unused5]", "by", "the", "company", "[unused6]", "[SEP]", "[unused1]", "a", "passenger", "[unused2]", "[unused3]", "can", "fly", "[unused4]", "[unused5]", "from", "Cha", "##rdon", ",", "N", "##eb", "##.", ",", "to", "Denver", "for", "as", "little", "as", "$", "89", "to", "$", "109", "[unused6]", "[SEP]", "[unused1]", "a", "passenger", "[unused2]", "[unused3]", "can", "fly", "[unused4]", "[unused5]", "from", "Cha", "##rdon", "N", "##eb", "##.", "For", "example", "[unused6]", "[SEP]", "[unused1]", "a", "passenger", "[unused2]", "[unused3]", "can", "fly", "[unused4]", "[unused5]", "from", "Cha", "##rdon", "N", "##eb", "##.", "[unused6]", "[SEP]", "[unused1]", "a", "passenger", "[unused2]", "[unused3]", "can", "fly", "[unused4]", "[unused5]", "from", "Cha", "##rdon", "N", "##eb", "##.", "[unused6]", "[SEP]"]]}

input 462:  {"source": "For the past five years , unions have n't managed to win wage increases as large as those granted to nonunion workers .\n"}
prediction:  {"predictions": [[1, 1343, 2, 3, 3609, 4, 5, 1106, 1664, 19698, 3239, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10230, 2, 3, 1138, 183, 28131, 1204, 2374, 4, 5, 1106, 1782, 12634, 6986, 1112, 1415, 1112, 1343, 1370, 1103, 1763, 1421, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10230, 2, 3, 1138, 183, 28131, 1204, 2374, 4, 5, 1106, 1782, 12634, 6986, 1112, 1415, 1112, 1343, 3609, 1106, 1664, 19698, 3239, 1370, 1103, 1763, 1421, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.017765559256076813, -0.048729244619607925, -0.33449625968933105, -0.09687577933073044, -0.11335182189941406, -0.11549758911132812, -0.11549758911132812, -0.11549758911132812, -0.11549758911132812, -0.11549758911132812], "metadata": {"source_tokens": ["For", "the", "past", "five", "years", ",", "unions", "have", "n", "##'", "##t", "managed", "to", "win", "wage", "increases", "as", "large", "as", "those", "granted", "to", "non", "##union", "workers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "those", "[unused2]", "[unused3]", "granted", "[unused4]", "[unused5]", "to", "non", "##union", "workers", "[unused6]", "[SEP]", "[unused1]", "unions", "[unused2]", "[unused3]", "have", "n", "##'", "##t", "managed", "[unused4]", "[unused5]", "to", "win", "wage", "increases", "as", "large", "as", "those", "For", "the", "past", "five", "years", "[unused6]", "[SEP]"]]}

input 463:  {"source": "For the record , Jeffrey Kaufman , an attorney for Fireman 's Fund , said he was `` rattled -- both literally and figuratively . ''\n"}
prediction:  {"predictions": [[1, 10708, 26517, 2, 3, 1163, 4, 5, 1119, 1108, 169, 28152, 21117, 118, 28137, 1241, 6290, 1105, 20497, 13830, 15306, 1193, 1370, 1103, 1647, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10708, 26517, 2, 3, 1110, 1126, 6507, 1111, 4, 5, 4266, 1399, 112, 1116, 6606, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1108, 21117, 4, 5, 1241, 6290, 1105, 20497, 13830, 15306, 1193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.007073790766298771, -0.011873536743223667, -0.07924681156873703, -0.12366986274719238, -0.12387657165527344, -0.12387657165527344, -0.12387657165527344, -0.12387657165527344, -0.12387657165527344, -0.12387657165527344], "metadata": {"source_tokens": ["For", "the", "record", ",", "Jeffrey", "Kaufman", ",", "an", "attorney", "for", "Fire", "##man", "'", "##s", "Fund", ",", "said", "he", "was", "`", "##`", "rattled", "-", "##-", "both", "literally", "and", "fi", "##gu", "##rative", "##ly", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Jeffrey", "Kaufman", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "he", "was", "`", "##`", "rattled", "-", "##-", "both", "literally", "and", "fi", "##gu", "##rative", "##ly", "For", "the", "record", "[unused6]", "[SEP]", "[unused1]", "Jeffrey", "Kaufman", "[unused2]", "[unused3]", "is", "an", "attorney", "for", "[unused4]", "[unused5]", "Fire", "##man", "'", "##s", "Fund", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "was", "rattled", "[unused4]", "[unused5]", "both", "literally", "and", "fi", "##gu", "##rative", "##ly", "[unused6]", "[SEP]"]]}

input 464:  {"source": "Ford Motor Co. said it is recalling about 3,600 of its 1990 - model Escorts because the windshield adhesive was improperly applied to some cars .\n"}
prediction:  {"predictions": [[1, 4100, 8226, 3291, 28138, 2, 3, 1163, 4, 5, 1122, 1110, 25839, 1164, 124, 28136, 16480, 1568, 1104, 1157, 1997, 118, 2235, 142, 11428, 13245, 1272, 1103, 21522, 8050, 23838, 1108, 24034, 26554, 1193, 3666, 1106, 1199, 3079, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 21522, 8050, 23838, 2, 3, 1108, 24034, 26554, 1193, 3666, 4, 5, 1106, 1199, 3079, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 25839, 4, 5, 1164, 124, 28136, 16480, 1568, 1104, 1157, 1997, 118, 2235, 142, 11428, 13245, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0054477364756166935, -0.02382788620889187, -0.03535686805844307, -0.07742142677307129, -0.07741022109985352, -0.07741022109985352, -0.07741022109985352, -0.07741022109985352, -0.07741022109985352, -0.07741022109985352], "metadata": {"source_tokens": ["Ford", "Motor", "Co", "##.", "said", "it", "is", "recalling", "about", "3", "##,", "##60", "##0", "of", "its", "1990", "-", "model", "E", "##sco", "##rts", "because", "the", "windshield", "ad", "##hesive", "was", "imp", "##roper", "##ly", "applied", "to", "some", "cars", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ford", "Motor", "Co", "##.", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "is", "recalling", "about", "3", "##,", "##60", "##0", "of", "its", "1990", "-", "model", "E", "##sco", "##rts", "because", "the", "windshield", "ad", "##hesive", "was", "imp", "##roper", "##ly", "applied", "to", "some", "cars", "[unused6]", "[SEP]", "[unused1]", "the", "windshield", "ad", "##hesive", "[unused2]", "[unused3]", "was", "imp", "##roper", "##ly", "applied", "[unused4]", "[unused5]", "to", "some", "cars", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "recalling", "[unused4]", "[unused5]", "about", "3", "##,", "##60", "##0", "of", "its", "1990", "-", "model", "E", "##sco", "##rts", "[unused6]", "[SEP]"]]}

input 465:  {"source": "Fraser & Neave , which also has interests in packaging , beer and dairy products , holds the Coke licenses for Malaysia and Brunei , where per - capita consumption is n't as high as in Singapore .\n"}
prediction:  {"predictions": [[1, 9156, 111, 151, 4490, 2707, 2, 3, 1144, 4, 5, 4740, 1107, 17019, 117, 5298, 1105, 14874, 2982, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9156, 111, 151, 4490, 2707, 2, 3, 3486, 4, 5, 1103, 19630, 17488, 1111, 5355, 1105, 20249, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1679, 118, 8008, 8160, 2, 3, 1110, 183, 28131, 1204, 4, 5, 1112, 1344, 1112, 1107, 4478, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04052960127592087, -0.015238309279084206, -0.07293327897787094, -0.07906484603881836, -0.08364725112915039, -0.08364725112915039, -0.08364725112915039, -0.08364725112915039, -0.08364725112915039, -0.08364725112915039], "metadata": {"source_tokens": ["Fraser", "&", "N", "##ea", "##ve", ",", "which", "also", "has", "interests", "in", "packaging", ",", "beer", "and", "dairy", "products", ",", "holds", "the", "Coke", "licenses", "for", "Malaysia", "and", "Brunei", ",", "where", "per", "-", "capita", "consumption", "is", "n", "##'", "##t", "as", "high", "as", "in", "Singapore", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Fraser", "&", "N", "##ea", "##ve", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "interests", "in", "packaging", ",", "beer", "and", "dairy", "products", "[unused6]", "[SEP]", "[unused1]", "Fraser", "&", "N", "##ea", "##ve", "[unused2]", "[unused3]", "holds", "[unused4]", "[unused5]", "the", "Coke", "licenses", "for", "Malaysia", "and", "Brunei", "[unused6]", "[SEP]", "[unused1]", "per", "-", "capita", "consumption", "[unused2]", "[unused3]", "is", "n", "##'", "##t", "[unused4]", "[unused5]", "as", "high", "as", "in", "Singapore", "[unused6]", "[SEP]"]]}

input 466:  {"source": "Hani Zayadi was appointed president and chief executive officer of this financially troubled department store chain , effective Nov. 15 , succeeding Frank Robertson , who is retiring early .\n"}
prediction:  {"predictions": [[1, 7699, 1182, 163, 12057, 3309, 2, 3, 1108, 1923, 4, 5, 2084, 1105, 2705, 3275, 2575, 1104, 1142, 14396, 12322, 2853, 2984, 4129, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2748, 9693, 2, 3, 1110, 8970, 4, 5, 1346, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1142, 14396, 12322, 2853, 2984, 4129, 2, 3, 1110, 4, 5, 3903, 14152, 28138, 1405, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04059300199151039, -0.019624575972557068, -0.07684902846813202, -0.07747673988342285, -0.07754683494567871, -0.07754683494567871, -0.07754683494567871, -0.07754683494567871, -0.07754683494567871, -0.07754683494567871], "metadata": {"source_tokens": ["Han", "##i", "Z", "##aya", "##di", "was", "appointed", "president", "and", "chief", "executive", "officer", "of", "this", "financially", "troubled", "department", "store", "chain", ",", "effective", "Nov", "##.", "15", ",", "succeeding", "Frank", "Robertson", ",", "who", "is", "retiring", "early", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Han", "##i", "Z", "##aya", "##di", "[unused2]", "[unused3]", "was", "appointed", "[unused4]", "[unused5]", "president", "and", "chief", "executive", "officer", "of", "this", "financially", "troubled", "department", "store", "chain", "[unused6]", "[SEP]", "[unused1]", "Frank", "Robertson", "[unused2]", "[unused3]", "is", "retiring", "[unused4]", "[unused5]", "early", "[unused6]", "[SEP]", "[unused1]", "this", "financially", "troubled", "department", "store", "chain", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "effective", "Nov", "##.", "15", "[unused6]", "[SEP]"]]}

input 467:  {"source": "He also contended that the plaintiffs failed to cite any legal authority that would justify such an injunction .\n"}
prediction:  {"predictions": [[1, 1251, 2732, 3748, 2, 3, 1156, 17422, 4, 5, 1216, 1126, 25905, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 14255, 21857, 4, 5, 1115, 1103, 23940, 1116, 2604, 1106, 172, 3150, 1251, 2732, 3748, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 23940, 1116, 2, 3, 2604, 4, 5, 1106, 172, 3150, 1251, 2732, 3748, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02330697327852249, -0.002144546713680029, -0.07883431017398834, -0.03854656219482422, -0.03856849670410156, -0.03856849670410156, -0.03856849670410156, -0.03856849670410156, -0.03856849670410156, -0.03856849670410156], "metadata": {"source_tokens": ["He", "also", "con", "##tended", "that", "the", "plaintiff", "##s", "failed", "to", "c", "##ite", "any", "legal", "authority", "that", "would", "justify", "such", "an", "injunction", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "any", "legal", "authority", "[unused2]", "[unused3]", "would", "justify", "[unused4]", "[unused5]", "such", "an", "injunction", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "con", "##tended", "[unused4]", "[unused5]", "that", "the", "plaintiff", "##s", "failed", "to", "c", "##ite", "any", "legal", "authority", "[unused6]", "[SEP]", "[unused1]", "the", "plaintiff", "##s", "[unused2]", "[unused3]", "failed", "[unused4]", "[unused5]", "to", "c", "##ite", "any", "legal", "authority", "[unused6]", "[SEP]"]]}

input 468:  {"source": "He also unfortunately illustrated this intricate , jazzy tapestry with Mr. Pearson 's images , this time of geometric or repeating objects , in a kitschy mirroring of the musical structure that was thoroughly distracting from Mr. Reich 's piece and Mr. Stoltzman 's elegant execution of it .\n"}
prediction:  {"predictions": [[1, 1103, 2696, 2401, 2, 3, 1108, 12678, 16989, 1158, 4, 5, 1121, 1828, 28138, 14994, 112, 1116, 2727, 1105, 1828, 28138, 1457, 17772, 27277, 112, 1116, 12002, 7581, 1104, 1122, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1145, 8292, 4, 5, 1142, 19360, 4888, 1183, 16200, 6013, 1114, 1828, 28138, 13079, 112, 1116, 4351, 1142, 1159, 1104, 16735, 1137, 16590, 4546, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 8292, 4, 5, 1142, 19360, 4888, 1183, 16200, 6013, 1114, 1828, 28138, 13079, 112, 1116, 4351, 1107, 170, 21195, 8992, 5220, 1158, 1104, 1103, 2696, 2401, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 8292, 4, 5, 1142, 19360, 4888, 1183, 16200, 6013, 1114, 1828, 28138, 13079, 112, 1116, 4351, 1142, 1159, 1104, 16735, 1137, 16590, 4546, 1107, 170, 21195, 8992, 5220, 1158, 1104, 1103, 2696, 2401, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 8292, 4, 5, 1142, 19360, 4888, 1183, 16200, 6013, 1114, 1828, 28138, 13079, 112, 1116, 4351, 1142, 1159, 1104, 16735, 1137, 16590, 4546, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 8292, 4, 5, 1142, 19360, 4888, 1183, 16200, 6013, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.023953445255756378, -0.13251914083957672, -0.09140872955322266, -0.10068138688802719, -0.14640656113624573, -0.18531115353107452, -0.21376407146453857, -0.21376430988311768, -0.21376430988311768, -0.21376430988311768], "metadata": {"source_tokens": ["He", "also", "unfortunately", "illustrated", "this", "intricate", ",", "jazz", "##y", "tapes", "##try", "with", "Mr", "##.", "Pearson", "'", "##s", "images", ",", "this", "time", "of", "geometric", "or", "repeating", "objects", ",", "in", "a", "kits", "##chy", "mirror", "##ing", "of", "the", "musical", "structure", "that", "was", "thoroughly", "distract", "##ing", "from", "Mr", "##.", "Reich", "'", "##s", "piece", "and", "Mr", "##.", "St", "##olt", "##zman", "'", "##s", "elegant", "execution", "of", "it", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "musical", "structure", "[unused2]", "[unused3]", "was", "thoroughly", "distract", "##ing", "[unused4]", "[unused5]", "from", "Mr", "##.", "Reich", "'", "##s", "piece", "and", "Mr", "##.", "St", "##olt", "##zman", "'", "##s", "elegant", "execution", "of", "it", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "also", "illustrated", "[unused4]", "[unused5]", "this", "intricate", "jazz", "##y", "tapes", "##try", "with", "Mr", "##.", "Pearson", "'", "##s", "images", "this", "time", "of", "geometric", "or", "repeating", "objects", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "illustrated", "[unused4]", "[unused5]", "this", "intricate", "jazz", "##y", "tapes", "##try", "with", "Mr", "##.", "Pearson", "'", "##s", "images", "in", "a", "kits", "##chy", "mirror", "##ing", "of", "the", "musical", "structure", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "illustrated", "[unused4]", "[unused5]", "this", "intricate", "jazz", "##y", "tapes", "##try", "with", "Mr", "##.", "Pearson", "'", "##s", "images", "this", "time", "of", "geometric", "or", "repeating", "objects", "in", "a", "kits", "##chy", "mirror", "##ing", "of", "the", "musical", "structure", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "illustrated", "[unused4]", "[unused5]", "this", "intricate", "jazz", "##y", "tapes", "##try", "with", "Mr", "##.", "Pearson", "'", "##s", "images", "this", "time", "of", "geometric", "or", "repeating", "objects", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "illustrated", "[unused4]", "[unused5]", "this", "intricate", "jazz", "##y", "tapes", "##try", "[unused6]", "[SEP]"]]}

input 469:  {"source": "He discovered a 75 - cent discrepancy in the charges made to various departments for computer time and traced it to a user named `` Hunter , '' who had no valid billing address .\n"}
prediction:  {"predictions": [[1, 170, 4795, 2, 3, 1417, 4, 5, 4242, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 2751, 4, 5, 170, 3453, 118, 9848, 6187, 1874, 10224, 3457, 1107, 1103, 4917, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4795, 2, 3, 1125, 4, 5, 1185, 9221, 4550, 1158, 4134, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 2751, 4, 5, 170, 3453, 118, 9848, 6187, 1874, 10224, 3457, 1107, 1103, 4917, 1189, 1106, 1672, 7844, 1111, 2775, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 2751, 4, 5, 170, 3453, 118, 9848, 6187, 1874, 10224, 3457, 1107, 1103, 4917, 1189, 1106, 1672, 7844, 1111, 2775, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 2751, 4, 5, 170, 3453, 118, 9848, 6187, 1874, 10224, 3457, 1107, 1103, 4917, 1189, 1106, 1672, 7844, 1111, 2775, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.08171293139457703, -0.06519999355077744, -0.07342012971639633, -0.08455414324998856, -0.09195059537887573, -0.0815696194767952, -0.32360410690307617, -0.279768705368042, -0.279768705368042, -0.279768705368042], "metadata": {"source_tokens": ["He", "discovered", "a", "75", "-", "cent", "disc", "##re", "##pan", "##cy", "in", "the", "charges", "made", "to", "various", "departments", "for", "computer", "time", "and", "traced", "it", "to", "a", "user", "named", "`", "##`", "Hunter", ",", "'", "##'", "who", "had", "no", "valid", "bill", "##ing", "address", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "user", "[unused2]", "[unused3]", "named", "[unused4]", "[unused5]", "Hunter", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "discovered", "[unused4]", "[unused5]", "a", "75", "-", "cent", "disc", "##re", "##pan", "##cy", "in", "the", "charges", "[unused6]", "[SEP]", "[unused1]", "a", "user", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "no", "valid", "bill", "##ing", "address", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "discovered", "[unused4]", "[unused5]", "a", "75", "-", "cent", "disc", "##re", "##pan", "##cy", "in", "the", "charges", "made", "to", "various", "departments", "for", "computer", "time", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "discovered", "[unused4]", "[unused5]", "a", "75", "-", "cent", "disc", "##re", "##pan", "##cy", "in", "the", "charges", "made", "to", "various", "departments", "for", "computer", "time", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "discovered", "[unused4]", "[unused5]", "a", "75", "-", "cent", "disc", "##re", "##pan", "##cy", "in", "the", "charges", "made", "to", "various", "departments", "for", "computer", "time", "[unused6]", "[SEP]"]]}

input 470:  {"source": "He has n't been able to replace the M'Bow cabal .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1144, 183, 28131, 1204, 1151, 4, 5, 1682, 1106, 4971, 1103, 150, 28131, 2064, 4064, 10347, 1348, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0016515254974365234, -0.026778221130371094, -0.03856372833251953, -0.03856372833251953, -0.03856372833251953, -0.03856372833251953, -0.03856372833251953, -0.03856372833251953, -0.03856372833251953, -0.03856372833251953], "metadata": {"source_tokens": ["He", "has", "n", "##'", "##t", "been", "able", "to", "replace", "the", "M", "##'", "##B", "##ow", "cab", "##al", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "has", "n", "##'", "##t", "been", "[unused4]", "[unused5]", "able", "to", "replace", "the", "M", "##'", "##B", "##ow", "cab", "##al", "[unused6]", "[SEP]"]]}

input 471:  {"source": "He said he expects the company to have $ 500 million in sales for this year .\n"}
prediction:  {"predictions": [[1, 1124, 2, 3, 1163, 4, 5, 1119, 27402, 1103, 1419, 1106, 1138, 109, 2260, 1550, 1107, 3813, 1111, 1142, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1419, 2, 3, 1106, 1138, 4, 5, 109, 2260, 1550, 1107, 3813, 1111, 1142, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0032281617168337107, -0.0465160608291626, -0.032381534576416016, -0.032300710678100586, -0.032300710678100586, -0.032300710678100586, -0.032300710678100586, -0.032300710678100586, -0.032300710678100586, -0.032300710678100586], "metadata": {"source_tokens": ["He", "said", "he", "expects", "the", "company", "to", "have", "$", "500", "million", "in", "sales", "for", "this", "year", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "He", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "he", "expects", "the", "company", "to", "have", "$", "500", "million", "in", "sales", "for", "this", "year", "[unused6]", "[SEP]", "[unused1]", "the", "company", "[unused2]", "[unused3]", "to", "have", "[unused4]", "[unused5]", "$", "500", "million", "in", "sales", "for", "this", "year", "[unused6]", "[SEP]"]]}

input 472:  {"source": "He sold them well below market value to raise cash `` to pay off mounting credit - card debts , '' incurred to buy presents for his girlfriend , his attorney , Philip Russell , told IFAR .\n"}
prediction:  {"predictions": [[1, 1117, 6507, 2, 3, 1500, 4, 5, 13729, 12426, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1962, 4, 5, 1172, 1218, 2071, 2319, 2860, 1106, 4693, 5948, 169, 28152, 1106, 2653, 1228, 17361, 4755, 118, 3621, 14689, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 6507, 2, 3, 1500, 4, 5, 13729, 12426, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1124, 2, 3, 1962, 4, 5, 1172, 2071, 2319, 2860, 1106, 4693, 5948, 1106, 2653, 1228, 17361, 4755, 118, 3621, 14689, 25240, 1106, 4417, 8218, 1111, 1117, 6124, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 6507, 2, 3, 1110, 6507, 1104, 4, 5, 1117, 6507, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1117, 6507, 2, 3, 1110, 4, 5, 4367, 5023, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04012283310294151, -0.10029274970293045, -0.17090801894664764, -0.1368313878774643, -0.3085215985774994, -0.271396666765213, -0.16220641136169434, -0.17010366916656494, -0.17010366916656494, -0.17010366916656494], "metadata": {"source_tokens": ["He", "sold", "them", "well", "below", "market", "value", "to", "raise", "cash", "`", "##`", "to", "pay", "off", "mounting", "credit", "-", "card", "debts", ",", "'", "##'", "incurred", "to", "buy", "presents", "for", "his", "girlfriend", ",", "his", "attorney", ",", "Philip", "Russell", ",", "told", "IF", "##AR", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "his", "attorney", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "IF", "##AR", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "sold", "[unused4]", "[unused5]", "them", "well", "below", "market", "value", "to", "raise", "cash", "`", "##`", "to", "pay", "off", "mounting", "credit", "-", "card", "debts", "[unused6]", "[SEP]", "[unused1]", "his", "attorney", "[unused2]", "[unused3]", "told", "[unused4]", "[unused5]", "IF", "##AR", "[unused6]", "[SEP]", "[unused1]", "He", "[unused2]", "[unused3]", "sold", "[unused4]", "[unused5]", "them", "below", "market", "value", "to", "raise", "cash", "to", "pay", "off", "mounting", "credit", "-", "card", "debts", "incurred", "to", "buy", "presents", "for", "his", "girlfriend", "[unused6]", "[SEP]", "[unused1]", "his", "attorney", "[unused2]", "[unused3]", "is", "attorney", "of", "[unused4]", "[unused5]", "his", "attorney", "[unused6]", "[SEP]", "[unused1]", "his", "attorney", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Philip", "Russell", "[unused6]", "[SEP]"]]}

input 473:  {"source": "Her recent report classifies the stock as a `` hold . ''\n"}
prediction:  {"predictions": [[1, 1430, 2793, 2592, 2, 3, 1705, 9387, 4, 5, 1103, 4482, 1112, 170, 169, 28152, 2080, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.001948507153429091, -0.0002617835998535156, -0.00027179718017578125, -0.00027179718017578125, -0.00027179718017578125, -0.00027179718017578125, -0.00027179718017578125, -0.00027179718017578125, -0.00027179718017578125, -0.00027179718017578125], "metadata": {"source_tokens": ["Her", "recent", "report", "class", "##ifies", "the", "stock", "as", "a", "`", "##`", "hold", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Her", "recent", "report", "[unused2]", "[unused3]", "class", "##ifies", "[unused4]", "[unused5]", "the", "stock", "as", "a", "`", "##`", "hold", "[unused6]", "[SEP]"]]}

input 474:  {"source": "Here are price trends on the world 's major stock markets , as calculated by Morgan Stanley Capital International Perspective , Geneva .\n"}
prediction:  {"predictions": [[1, 4461, 5481, 6299, 1570, 14286, 16776, 2, 3, 1110, 4, 5, 9571, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3945, 14652, 1113, 1103, 1362, 112, 1116, 1558, 4482, 5809, 2, 3, 3446, 1132, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04001258313655853, -0.07344446331262589, -0.12666797637939453, -0.13065481185913086, -0.13065481185913086, -0.13065481185913086, -0.13065481185913086, -0.13065481185913086, -0.13065481185913086, -0.13065481185913086], "metadata": {"source_tokens": ["Here", "are", "price", "trends", "on", "the", "world", "'", "##s", "major", "stock", "markets", ",", "as", "calculated", "by", "Morgan", "Stanley", "Capital", "International", "Per", "##spective", ",", "Geneva", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Morgan", "Stanley", "Capital", "International", "Per", "##spective", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Geneva", "[unused6]", "[SEP]", "[unused1]", "price", "trends", "on", "the", "world", "'", "##s", "major", "stock", "markets", "[unused2]", "[unused3]", "Here", "are", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 475:  {"source": "However , StatesWest is n't abandoning its pursuit of the much - larger Mesa .\n"}
prediction:  {"predictions": [[1, 1311, 2924, 2556, 2, 3, 1110, 183, 28131, 1204, 22634, 4, 5, 1157, 9542, 1104, 1103, 1277, 118, 2610, 18506, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.00025155238108709455, -0.0026502609252929688, -0.0029087066650390625, -0.0029087066650390625, -0.0029087066650390625, -0.0029087066650390625, -0.0029087066650390625, -0.0029087066650390625, -0.0029087066650390625, -0.0029087066650390625], "metadata": {"source_tokens": ["However", ",", "States", "##W", "##est", "is", "n", "##'", "##t", "abandoning", "its", "pursuit", "of", "the", "much", "-", "larger", "Mesa", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "States", "##W", "##est", "[unused2]", "[unused3]", "is", "n", "##'", "##t", "abandoning", "[unused4]", "[unused5]", "its", "pursuit", "of", "the", "much", "-", "larger", "Mesa", "[unused6]", "[SEP]"]]}

input 476:  {"source": "However , a Canadian Embassy official in Tel Aviv said that Canada was unlikely to sell the Candu heavy - water reactor to Israel since Israel has n't signed the Nuclear Non - Proliferation Treaty .\n"}
prediction:  {"predictions": [[1, 170, 2122, 13530, 2078, 1107, 11341, 12927, 2, 3, 1163, 4, 5, 1115, 1803, 1108, 9803, 1106, 4582, 1103, 2825, 7641, 2302, 118, 1447, 15056, 1106, 3103, 1290, 3103, 1144, 183, 28131, 1204, 1878, 1103, 11560, 7922, 118, 5096, 14430, 6108, 6599, 6, 102, 102, 102, 102, 102, 102, 102, 1, 3103, 2, 3, 1144, 183, 28131, 1204, 1878, 4, 5, 1103, 11560, 7922, 118, 5096, 14430, 6108, 6599, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1803, 2, 3, 1108, 4, 5, 9803, 1106, 4582, 1103, 2825, 7641, 2302, 118, 1447, 15056, 1106, 3103, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1803, 2, 3, 1108, 4, 5, 9803, 1106, 4582, 1103, 2825, 7641, 2302, 1447, 15056, 1106, 3103, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1803, 2, 3, 1108, 4, 5, 9803, 1106, 4582, 1103, 2825, 7641, 2302, 1447, 15056, 1106, 3103, 1290, 3103, 1144, 183, 28131, 1204, 1878, 1103, 11560, 7922, 5096, 14430, 6108, 6599, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.018986564129590988, -0.03521949425339699, -0.05536738038063049, -0.1813742220401764, -0.13114774227142334, -0.35090184211730957, -0.35013675689697266, -0.35013675689697266, -0.35013675689697266, -0.35013675689697266], "metadata": {"source_tokens": ["However", ",", "a", "Canadian", "Embassy", "official", "in", "Tel", "Aviv", "said", "that", "Canada", "was", "unlikely", "to", "sell", "the", "Can", "##du", "heavy", "-", "water", "reactor", "to", "Israel", "since", "Israel", "has", "n", "##'", "##t", "signed", "the", "Nuclear", "Non", "-", "Pro", "##life", "##ration", "Treaty", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "Canadian", "Embassy", "official", "in", "Tel", "Aviv", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "that", "Canada", "was", "unlikely", "to", "sell", "the", "Can", "##du", "heavy", "-", "water", "reactor", "to", "Israel", "since", "Israel", "has", "n", "##'", "##t", "signed", "the", "Nuclear", "Non", "-", "Pro", "##life", "##ration", "Treaty", "[unused6]", "[SEP]", "[unused1]", "Israel", "[unused2]", "[unused3]", "has", "n", "##'", "##t", "signed", "[unused4]", "[unused5]", "the", "Nuclear", "Non", "-", "Pro", "##life", "##ration", "Treaty", "[unused6]", "[SEP]", "[unused1]", "Canada", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "unlikely", "to", "sell", "the", "Can", "##du", "heavy", "-", "water", "reactor", "to", "Israel", "[unused6]", "[SEP]", "[unused1]", "Canada", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "unlikely", "to", "sell", "the", "Can", "##du", "heavy", "water", "reactor", "to", "Israel", "[unused6]", "[SEP]", "[unused1]", "Canada", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "unlikely", "to", "sell", "the", "Can", "##du", "heavy", "water", "reactor", "to", "Israel", "since", "Israel", "has", "n", "##'", "##t", "signed", "the", "Nuclear", "Non", "Pro", "##life", "##ration", "Treaty", "[unused6]", "[SEP]"]]}

input 477:  {"source": "However , the problem is that once most poison pills are adopted , they survive forever .\n"}
prediction:  {"predictions": [[1, 1103, 2463, 2, 3, 1110, 4, 5, 1115, 1517, 1211, 11539, 17029, 1132, 3399, 117, 1152, 5195, 5221, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1211, 11539, 17029, 2, 3, 1132, 3399, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 5195, 4, 5, 5221, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.000584903231356293, -0.04325598478317261, -0.07899345457553864, -0.022025585174560547, -0.022031784057617188, -0.022031784057617188, -0.022031784057617188, -0.022031784057617188, -0.022031784057617188, -0.022031784057617188], "metadata": {"source_tokens": ["However", ",", "the", "problem", "is", "that", "once", "most", "poison", "pills", "are", "adopted", ",", "they", "survive", "forever", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "problem", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "that", "once", "most", "poison", "pills", "are", "adopted", ",", "they", "survive", "forever", "[unused6]", "[SEP]", "[unused1]", "most", "poison", "pills", "[unused2]", "[unused3]", "are", "adopted", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "survive", "[unused4]", "[unused5]", "forever", "[unused6]", "[SEP]"]]}

input 478:  {"source": "Humana contends that $ 8,000 represents an extreme case and that its regular charge for lithotripsy is $ 4,900 .\n"}
prediction:  {"predictions": [[1, 4243, 1161, 2, 3, 14255, 22910, 1116, 4, 5, 1115, 109, 129, 28136, 7629, 1568, 5149, 1126, 6122, 1692, 1105, 1115, 1157, 2366, 2965, 1111, 4941, 12217, 16669, 5821, 1110, 109, 125, 28136, 21500, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 109, 129, 28136, 7629, 1568, 2, 3, 5149, 4, 5, 1126, 6122, 1692, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1157, 2366, 2965, 1111, 4941, 12217, 16669, 5821, 2, 3, 1110, 4, 5, 109, 125, 28136, 21500, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.007427692413330078, -0.03782593458890915, -0.019759802147746086, -0.02199411392211914, -0.022008419036865234, -0.022008419036865234, -0.022008419036865234, -0.022008419036865234, -0.022008419036865234, -0.022008419036865234], "metadata": {"source_tokens": ["Human", "##a", "con", "##tend", "##s", "that", "$", "8", "##,", "##00", "##0", "represents", "an", "extreme", "case", "and", "that", "its", "regular", "charge", "for", "lit", "##hot", "##rip", "##sy", "is", "$", "4", "##,", "##90", "##0", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Human", "##a", "[unused2]", "[unused3]", "con", "##tend", "##s", "[unused4]", "[unused5]", "that", "$", "8", "##,", "##00", "##0", "represents", "an", "extreme", "case", "and", "that", "its", "regular", "charge", "for", "lit", "##hot", "##rip", "##sy", "is", "$", "4", "##,", "##90", "##0", "[unused6]", "[SEP]", "[unused1]", "$", "8", "##,", "##00", "##0", "[unused2]", "[unused3]", "represents", "[unused4]", "[unused5]", "an", "extreme", "case", "[unused6]", "[SEP]", "[unused1]", "its", "regular", "charge", "for", "lit", "##hot", "##rip", "##sy", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "$", "4", "##,", "##90", "##0", "[unused6]", "[SEP]"]]}

input 479:  {"source": "Hungary 's Parliament voted to hold a national referendum on an election to fill the new post of president .\n"}
prediction:  {"predictions": [[1, 5169, 112, 1116, 2901, 2, 3, 4751, 4, 5, 1106, 2080, 170, 1569, 9905, 1113, 1126, 1728, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5169, 112, 1116, 2901, 2, 3, 4751, 4, 5, 1106, 2080, 170, 1569, 9905, 1113, 1126, 1728, 1106, 5475, 1103, 1207, 2112, 1104, 2084, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.05726539343595505, -0.02884301170706749, -0.04540610313415527, -0.0764162540435791, -0.0764162540435791, -0.0764162540435791, -0.0764162540435791, -0.0764162540435791, -0.0764162540435791, -0.0764162540435791], "metadata": {"source_tokens": ["Hungary", "'", "##s", "Parliament", "voted", "to", "hold", "a", "national", "referendum", "on", "an", "election", "to", "fill", "the", "new", "post", "of", "president", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Hungary", "'", "##s", "Parliament", "[unused2]", "[unused3]", "voted", "[unused4]", "[unused5]", "to", "hold", "a", "national", "referendum", "on", "an", "election", "[unused6]", "[SEP]", "[unused1]", "Hungary", "'", "##s", "Parliament", "[unused2]", "[unused3]", "voted", "[unused4]", "[unused5]", "to", "hold", "a", "national", "referendum", "on", "an", "election", "to", "fill", "the", "new", "post", "of", "president", "[unused6]", "[SEP]"]]}

input 480:  {"source": "I do n't think that is the case . ''\n"}
prediction:  {"predictions": [[1, 146, 2, 3, 1202, 183, 28131, 1204, 1341, 4, 5, 1115, 1110, 1103, 1692, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.004484064411371946, -0.0009102821350097656, -0.0010828971862792969, -0.0010828971862792969, -0.0010828971862792969, -0.0010828971862792969, -0.0010828971862792969, -0.0010828971862792969, -0.0010828971862792969, -0.0010828971862792969], "metadata": {"source_tokens": ["I", "do", "n", "##'", "##t", "think", "that", "is", "the", "case", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "I", "[unused2]", "[unused3]", "do", "n", "##'", "##t", "think", "[unused4]", "[unused5]", "that", "is", "the", "case", "[unused6]", "[SEP]"]]}

input 481:  {"source": "I was pleased to note that your Oct. 23 Centennial Journal item recognized the money - fund concept as one of the significant events of the past century .\n"}
prediction:  {"predictions": [[1, 146, 2, 3, 1108, 4, 5, 7229, 1106, 3805, 1115, 1240, 14125, 28138, 1695, 20988, 3603, 8926, 3037, 1103, 1948, 118, 5841, 3400, 1112, 1141, 1104, 1103, 2418, 1958, 1104, 1103, 1763, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1240, 14125, 28138, 1695, 20988, 3603, 8926, 2, 3, 3037, 4, 5, 1103, 1948, 118, 5841, 3400, 1112, 1141, 1104, 1103, 2418, 1958, 1104, 1103, 1763, 1432, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.013423522002995014, -0.0029727816581726074, -0.032213449478149414, -0.03221297264099121, -0.03221297264099121, -0.03221297264099121, -0.03221297264099121, -0.03221297264099121, -0.03221297264099121, -0.03221297264099121], "metadata": {"source_tokens": ["I", "was", "pleased", "to", "note", "that", "your", "Oct", "##.", "23", "Centennial", "Journal", "item", "recognized", "the", "money", "-", "fund", "concept", "as", "one", "of", "the", "significant", "events", "of", "the", "past", "century", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "I", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "pleased", "to", "note", "that", "your", "Oct", "##.", "23", "Centennial", "Journal", "item", "recognized", "the", "money", "-", "fund", "concept", "as", "one", "of", "the", "significant", "events", "of", "the", "past", "century", "[unused6]", "[SEP]", "[unused1]", "your", "Oct", "##.", "23", "Centennial", "Journal", "item", "[unused2]", "[unused3]", "recognized", "[unused4]", "[unused5]", "the", "money", "-", "fund", "concept", "as", "one", "of", "the", "significant", "events", "of", "the", "past", "century", "[unused6]", "[SEP]"]]}

input 482:  {"source": "If there 's something ' weird and it do n't look good .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 1202, 183, 28131, 1204, 1440, 4, 5, 1363, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0033736228942871094, -0.05314970016479492, -0.047064781188964844, -0.047064781188964844, -0.047064781188964844, -0.047064781188964844, -0.047064781188964844, -0.047064781188964844, -0.047064781188964844, -0.047064781188964844], "metadata": {"source_tokens": ["If", "there", "'", "##s", "something", "'", "weird", "and", "it", "do", "n", "##'", "##t", "look", "good", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "do", "n", "##'", "##t", "look", "[unused4]", "[unused5]", "good", "[unused6]", "[SEP]"]]}

input 483:  {"source": "In 1988 , a year and a half after Mrs. Marcos and her late husband , Ferdinand Marcos , the ousted president of the Philippines , fled the Philippines for Hawaii , they were charged with racketeering , conspiracy , obstruction of justice and mail fraud in a scheme in which they allegedly embezzled more than $ 100 million from their homeland .\n"}
prediction:  {"predictions": [[1, 1152, 2, 3, 9273, 9712, 3962, 21011, 1181, 4, 5, 1167, 1190, 109, 1620, 1550, 1121, 1147, 14764, 170, 5471, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1127, 4601, 4, 5, 1114, 16365, 16618, 5938, 117, 10758, 117, 184, 4832, 17993, 1104, 5299, 1105, 6346, 10258, 1107, 170, 5471, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9422, 15541, 2, 3, 6192, 4, 5, 1103, 4336, 1111, 6826, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 9273, 9712, 3962, 21011, 1181, 4, 5, 1167, 1190, 109, 1620, 1550, 1130, 2115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 9273, 9712, 3962, 21011, 1181, 4, 5, 1167, 1190, 109, 1620, 1550, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 9273, 9712, 3962, 21011, 1181, 4, 5, 1167, 1190, 109, 1620, 1550, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 9273, 9712, 3962, 21011, 1181, 4, 5, 1167, 1190, 109, 1620, 1550, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 9712, 3962, 21011, 1181, 4, 5, 1167, 1190, 109, 1620, 1550, 6, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 9712, 3962, 21011, 1181, 4, 5, 1167, 1190, 109, 1620, 1550, 6, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.04541986808180809, -0.05818258970975876, -0.14451466500759125, -0.15376584231853485, -0.1379670798778534, -0.1473400592803955, -0.15206247568130493, -0.16293303668498993, -0.16963301599025726, -0.2997133731842041], "metadata": {"source_tokens": ["In", "1988", ",", "a", "year", "and", "a", "half", "after", "Mrs", "##.", "Marcos", "and", "her", "late", "husband", ",", "Ferdinand", "Marcos", ",", "the", "ou", "##sted", "president", "of", "the", "Philippines", ",", "fled", "the", "Philippines", "for", "Hawaii", ",", "they", "were", "charged", "with", "rack", "##ete", "##ering", ",", "conspiracy", ",", "o", "##bs", "##truction", "of", "justice", "and", "mail", "fraud", "in", "a", "scheme", "in", "which", "they", "allegedly", "em", "##be", "##zzle", "##d", "more", "than", "$", "100", "million", "from", "their", "homeland", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "they", "[unused2]", "[unused3]", "allegedly", "em", "##be", "##zzle", "##d", "[unused4]", "[unused5]", "more", "than", "$", "100", "million", "from", "their", "homeland", "a", "scheme", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "were", "charged", "[unused4]", "[unused5]", "with", "rack", "##ete", "##ering", ",", "conspiracy", ",", "o", "##bs", "##truction", "of", "justice", "and", "mail", "fraud", "in", "a", "scheme", "[unused6]", "[SEP]", "[unused1]", "Ferdinand", "Marcos", "[unused2]", "[unused3]", "fled", "[unused4]", "[unused5]", "the", "Philippines", "for", "Hawaii", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "allegedly", "em", "##be", "##zzle", "##d", "[unused4]", "[unused5]", "more", "than", "$", "100", "million", "In", "1988", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "allegedly", "em", "##be", "##zzle", "##d", "[unused4]", "[unused5]", "more", "than", "$", "100", "million", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "allegedly", "em", "##be", "##zzle", "##d", "[unused4]", "[unused5]", "more", "than", "$", "100", "million", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "allegedly", "em", "##be", "##zzle", "##d", "[unused4]", "[unused5]", "more", "than", "$", "100", "million", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "em", "##be", "##zzle", "##d", "[unused4]", "[unused5]", "more", "than", "$", "100", "million", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "em", "##be", "##zzle", "##d", "[unused4]", "[unused5]", "more", "than", "$", "100", "million", "[unused6]", "[SEP]"]]}

input 484:  {"source": "In Japan , those functions account for only about a third of the software market .\n"}
prediction:  {"predictions": [[1, 1343, 4226, 2, 3, 3300, 4, 5, 1111, 1178, 1164, 170, 1503, 1104, 1103, 3594, 2319, 1130, 1999, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.00032974424539133906, -0.02199697494506836, -0.02199697494506836, -0.02199697494506836, -0.02199697494506836, -0.02199697494506836, -0.02199697494506836, -0.02199697494506836, -0.02199697494506836, -0.02199697494506836], "metadata": {"source_tokens": ["In", "Japan", ",", "those", "functions", "account", "for", "only", "about", "a", "third", "of", "the", "software", "market", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "those", "functions", "[unused2]", "[unused3]", "account", "[unused4]", "[unused5]", "for", "only", "about", "a", "third", "of", "the", "software", "market", "In", "Japan", "[unused6]", "[SEP]"]]}

input 485:  {"source": "In recent testimony on Capitol Hill , Treasury officials said they were considering the new reporting requirements , and the expected publication of the proposal in the Federal Register today is the first official step toward creating final regulations .\n"}
prediction:  {"predictions": [[1, 11712, 3878, 2, 3, 1163, 4, 5, 1152, 1127, 6103, 1103, 1207, 7516, 5420, 117, 1105, 1103, 2637, 4128, 1104, 1103, 5835, 1107, 1103, 3467, 4273, 2052, 1110, 1103, 1148, 2078, 2585, 1755, 3780, 1509, 7225, 1130, 2793, 11405, 1113, 9838, 2404, 6, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2637, 4128, 1104, 1103, 5835, 1107, 1103, 3467, 4273, 2, 3, 1110, 4, 5, 1103, 1148, 2078, 2585, 1755, 3780, 1509, 7225, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1127, 6103, 4, 5, 1103, 1207, 7516, 5420, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02142656408250332, -0.02952428348362446, -0.08843021094799042, -0.15003550052642822, -0.1506134271621704, -0.1506134271621704, -0.1506134271621704, -0.1506134271621704, -0.1506134271621704, -0.1506134271621704], "metadata": {"source_tokens": ["In", "recent", "testimony", "on", "Capitol", "Hill", ",", "Treasury", "officials", "said", "they", "were", "considering", "the", "new", "reporting", "requirements", ",", "and", "the", "expected", "publication", "of", "the", "proposal", "in", "the", "Federal", "Register", "today", "is", "the", "first", "official", "step", "toward", "creating", "final", "regulations", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Treasury", "officials", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "they", "were", "considering", "the", "new", "reporting", "requirements", ",", "and", "the", "expected", "publication", "of", "the", "proposal", "in", "the", "Federal", "Register", "today", "is", "the", "first", "official", "step", "toward", "creating", "final", "regulations", "In", "recent", "testimony", "on", "Capitol", "Hill", "[unused6]", "[SEP]", "[unused1]", "the", "expected", "publication", "of", "the", "proposal", "in", "the", "Federal", "Register", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "first", "official", "step", "toward", "creating", "final", "regulations", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "were", "considering", "[unused4]", "[unused5]", "the", "new", "reporting", "requirements", "[unused6]", "[SEP]"]]}

input 486:  {"source": "In the U.S. , more than half the PC software sold is either for spreadsheets or for database analysis , according to Lotus .\n"}
prediction:  {"predictions": [[1, 1167, 1190, 1544, 1103, 7054, 3594, 1962, 2, 3, 1110, 4, 5, 1719, 1111, 23237, 19989, 2145, 1137, 1111, 8539, 3622, 1130, 1103, 158, 28138, 1708, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1167, 1190, 1544, 1103, 7054, 3594, 2, 3, 1962, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1167, 1190, 1544, 1103, 7054, 3594, 1962, 2, 3, 1110, 4, 5, 1719, 2452, 1106, 15945, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.02372257225215435, -0.08631766587495804, -0.07406022399663925, -0.20956814289093018, -0.21016836166381836, -0.21016836166381836, -0.21016836166381836, -0.21016836166381836, -0.21016836166381836, -0.21016836166381836], "metadata": {"source_tokens": ["In", "the", "U", "##.", "##S", "##.", ",", "more", "than", "half", "the", "PC", "software", "sold", "is", "either", "for", "spreads", "##hee", "##ts", "or", "for", "database", "analysis", ",", "according", "to", "Lotus", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "more", "than", "half", "the", "PC", "software", "sold", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "either", "for", "spreads", "##hee", "##ts", "or", "for", "database", "analysis", "In", "the", "U", "##.", "##S", "##.", "[unused6]", "[SEP]", "[unused1]", "more", "than", "half", "the", "PC", "software", "[unused2]", "[unused3]", "sold", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "more", "than", "half", "the", "PC", "software", "sold", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "either", "according", "to", "Lotus", "[unused6]", "[SEP]"]]}

input 487:  {"source": "In the corporate market , an expected debt offering today by International Business Machines Corp. generated considerable attention .\n"}
prediction:  {"predictions": [[1, 1126, 2637, 6695, 4733, 2052, 1118, 1570, 3518, 7792, 1116, 13619, 2, 3, 6455, 4, 5, 5602, 2209, 1130, 1103, 6214, 2319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0033400345128029585, -0.09181928634643555, -0.09971952438354492, -0.09971952438354492, -0.09971952438354492, -0.09971952438354492, -0.09971952438354492, -0.09971952438354492, -0.09971952438354492, -0.09971952438354492], "metadata": {"source_tokens": ["In", "the", "corporate", "market", ",", "an", "expected", "debt", "offering", "today", "by", "International", "Business", "Machine", "##s", "Corp", "##.", "generated", "considerable", "attention", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "an", "expected", "debt", "offering", "today", "by", "International", "Business", "Machine", "##s", "Corp", "[unused2]", "[unused3]", "generated", "[unused4]", "[unused5]", "considerable", "attention", "In", "the", "corporate", "market", "[unused6]", "[SEP]"]]}

input 488:  {"source": "In the first nine months , profit rose 10 % to $ 313.2 million , or $ 3.89 a share , from $ 283.9 million , or $ 3.53 a share .\n"}
prediction:  {"predictions": [[1, 5022, 2, 3, 3152, 4, 5, 1275, 110, 1106, 109, 25620, 28138, 1477, 1550, 117, 1137, 109, 124, 28138, 1604, 1580, 170, 2934, 117, 1121, 109, 1743, 1495, 28138, 1580, 1550, 117, 1137, 109, 124, 28138, 24239, 170, 2934, 1130, 1103, 1148, 2551, 1808, 6, 102, 102, 102, 102, 102, 1, 5022, 2, 3, 3152, 4, 5, 1275, 110, 1106, 109, 25620, 28138, 1477, 1550, 1137, 109, 124, 28138, 1604, 1580, 170, 2934, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5022, 2, 3, 3152, 4, 5, 1275, 110, 1106, 109, 25620, 28138, 1477, 1550, 1137, 109, 124, 28138, 1604, 1580, 170, 2934, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5022, 2, 3, 3152, 4, 5, 1275, 110, 1130, 1103, 1148, 2551, 1808, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.026959210634231567, -0.09402687102556229, -0.11444548517465591, -0.32530367374420166, -0.1276119351387024, -0.2056065797805786, -0.20752835273742676, -0.20752835273742676, -0.20752835273742676, -0.20752835273742676], "metadata": {"source_tokens": ["In", "the", "first", "nine", "months", ",", "profit", "rose", "10", "%", "to", "$", "313", "##.", "##2", "million", ",", "or", "$", "3", "##.", "##8", "##9", "a", "share", ",", "from", "$", "28", "##3", "##.", "##9", "million", ",", "or", "$", "3", "##.", "##53", "a", "share", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "profit", "[unused2]", "[unused3]", "rose", "[unused4]", "[unused5]", "10", "%", "to", "$", "313", "##.", "##2", "million", ",", "or", "$", "3", "##.", "##8", "##9", "a", "share", ",", "from", "$", "28", "##3", "##.", "##9", "million", ",", "or", "$", "3", "##.", "##53", "a", "share", "In", "the", "first", "nine", "months", "[unused6]", "[SEP]", "[unused1]", "profit", "[unused2]", "[unused3]", "rose", "[unused4]", "[unused5]", "10", "%", "to", "$", "313", "##.", "##2", "million", "or", "$", "3", "##.", "##8", "##9", "a", "share", "[unused6]", "[SEP]", "[unused1]", "profit", "[unused2]", "[unused3]", "rose", "[unused4]", "[unused5]", "10", "%", "to", "$", "313", "##.", "##2", "million", "or", "$", "3", "##.", "##8", "##9", "a", "share", "[unused6]", "[SEP]"]]}

input 489:  {"source": "Indeed , the insurance adjusters had already bolted out of the courtroom .\n"}
prediction:  {"predictions": [[1, 1103, 5986, 14878, 1468, 2, 3, 1125, 19532, 4, 5, 1149, 1104, 1103, 23699, 1640, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0011064873542636633, -0.0025167465209960938, -0.0028057098388671875, -0.0028057098388671875, -0.0028057098388671875, -0.0028057098388671875, -0.0028057098388671875, -0.0028057098388671875, -0.0028057098388671875, -0.0028057098388671875], "metadata": {"source_tokens": ["Indeed", ",", "the", "insurance", "adjust", "##ers", "had", "already", "bolted", "out", "of", "the", "courtroom", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "insurance", "adjust", "##ers", "[unused2]", "[unused3]", "had", "bolted", "[unused4]", "[unused5]", "out", "of", "the", "courtroom", "already", "[unused6]", "[SEP]"]]}

input 490:  {"source": "Industrial Bank of Japan , which claims to be the biggest Japanese buyer of U.S. mortgage securities , says it will more than double its purchases this year , to an amount one official puts at several billion dollars .\n"}
prediction:  {"predictions": [[1, 7080, 2950, 1104, 1999, 2, 3, 1867, 4, 5, 1122, 1209, 1167, 1190, 2702, 1157, 18908, 1142, 1214, 117, 1106, 1126, 2971, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7080, 2950, 1104, 1999, 2, 3, 1106, 1129, 4, 5, 1103, 4583, 1983, 20315, 1104, 158, 28138, 1708, 28138, 16935, 19313, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1126, 2971, 2, 3, 8165, 4, 5, 1120, 1317, 3775, 5860, 1126, 2971, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7080, 2950, 1104, 1999, 2, 3, 1867, 4, 5, 1122, 1209, 1167, 1190, 2702, 1157, 18908, 1142, 1214, 1106, 1126, 2971, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7080, 2950, 1104, 1999, 2, 3, 1867, 4, 5, 1122, 1209, 1167, 1190, 2702, 1157, 18908, 1142, 1214, 1106, 1126, 2971, 1141, 2078, 8165, 1120, 1317, 3775, 5860, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.05218557268381119, -0.05263405665755272, -0.10029520094394684, -0.11205709725618362, -0.10059566050767899, -0.26136481761932373, -0.26395905017852783, -0.26395905017852783, -0.26395905017852783, -0.26395905017852783], "metadata": {"source_tokens": ["Industrial", "Bank", "of", "Japan", ",", "which", "claims", "to", "be", "the", "biggest", "Japanese", "buyer", "of", "U", "##.", "##S", "##.", "mortgage", "securities", ",", "says", "it", "will", "more", "than", "double", "its", "purchases", "this", "year", ",", "to", "an", "amount", "one", "official", "puts", "at", "several", "billion", "dollars", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Industrial", "Bank", "of", "Japan", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "it", "will", "more", "than", "double", "its", "purchases", "this", "year", ",", "to", "an", "amount", "[unused6]", "[SEP]", "[unused1]", "Industrial", "Bank", "of", "Japan", "[unused2]", "[unused3]", "to", "be", "[unused4]", "[unused5]", "the", "biggest", "Japanese", "buyer", "of", "U", "##.", "##S", "##.", "mortgage", "securities", "[unused6]", "[SEP]", "[unused1]", "an", "amount", "[unused2]", "[unused3]", "puts", "[unused4]", "[unused5]", "at", "several", "billion", "dollars", "an", "amount", "[unused6]", "[SEP]", "[unused1]", "Industrial", "Bank", "of", "Japan", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "it", "will", "more", "than", "double", "its", "purchases", "this", "year", "to", "an", "amount", "[unused6]", "[SEP]", "[unused1]", "Industrial", "Bank", "of", "Japan", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "it", "will", "more", "than", "double", "its", "purchases", "this", "year", "to", "an", "amount", "one", "official", "puts", "at", "several", "billion", "dollars", "[unused6]", "[SEP]"]]}

input 491:  {"source": "It came in London 's `` Big Bang '' 1986 deregulation ; and Toronto 's `` Little Bang '' the same year .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1338, 4, 5, 1107, 1498, 112, 1116, 169, 28152, 2562, 12926, 112, 28131, 2177, 4167, 12606, 6856, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.008578975684940815, -0.07609939575195312, -0.07610082626342773, -0.07610082626342773, -0.07610082626342773, -0.07610082626342773, -0.07610082626342773, -0.07610082626342773, -0.07610082626342773, -0.07610082626342773], "metadata": {"source_tokens": ["It", "came", "in", "London", "'", "##s", "`", "##`", "Big", "Bang", "'", "##'", "1986", "der", "##eg", "##ulation", ";", "and", "Toronto", "'", "##s", "`", "##`", "Little", "Bang", "'", "##'", "the", "same", "year", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "in", "London", "'", "##s", "`", "##`", "Big", "Bang", "'", "##'", "1986", "der", "##eg", "##ulation", "[unused6]", "[SEP]"]]}

input 492:  {"source": "It rose 4.8 % for the 12 months ended in June and 4.7 % in the 12 months ended in September 1988 .\n"}
prediction:  {"predictions": [[1, 1103, 1367, 1808, 2, 3, 2207, 4, 5, 1107, 1347, 2115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 3152, 4, 5, 125, 28138, 1604, 110, 1111, 1103, 1367, 1808, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 3152, 4, 5, 125, 28138, 1604, 110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.021713580936193466, -0.05004241317510605, -0.12638120353221893, -0.2697579860687256, -0.2690671682357788, -0.2690671682357788, -0.2690671682357788, -0.2690671682357788, -0.2690671682357788, -0.2690671682357788], "metadata": {"source_tokens": ["It", "rose", "4", "##.", "##8", "%", "for", "the", "12", "months", "ended", "in", "June", "and", "4", "##.", "##7", "%", "in", "the", "12", "months", "ended", "in", "September", "1988", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "12", "months", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "in", "September", "1988", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "rose", "[unused4]", "[unused5]", "4", "##.", "##8", "%", "for", "the", "12", "months", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "rose", "[unused4]", "[unused5]", "4", "##.", "##8", "%", "[unused6]", "[SEP]"]]}

input 493:  {"source": "It said CS First Boston `` has consistently been one of the most aggressive firms in merchant banking '' and that `` a very significant portion '' of the firm 's profit in recent years has come from merchant banking - related business .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1163, 4, 5, 24821, 1752, 2859, 169, 28152, 1144, 10887, 1151, 1141, 1104, 1103, 1211, 9233, 9780, 1107, 6800, 9339, 112, 28131, 1105, 1115, 169, 28152, 170, 1304, 2418, 3849, 112, 28131, 1104, 1103, 3016, 112, 1116, 5022, 1107, 2793, 1201, 1144, 1435, 1121, 6800, 9339, 102, 1, 170, 1304, 2418, 3849, 112, 28131, 1104, 1103, 3016, 112, 1116, 5022, 1107, 2793, 1201, 2, 3, 1144, 1435, 4, 5, 1121, 6800, 9339, 118, 2272, 1671, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 24821, 1752, 2859, 2, 3, 1144, 10887, 1151, 4, 5, 1141, 1104, 1103, 1211, 9233, 9780, 1107, 6800, 9339, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.020508628338575363, -0.02509288862347603, -0.07226114720106125, -0.15389955043792725, -0.15730500221252441, -0.15730500221252441, -0.15730500221252441, -0.15730500221252441, -0.15730500221252441, -0.15730500221252441], "metadata": {"source_tokens": ["It", "said", "CS", "First", "Boston", "`", "##`", "has", "consistently", "been", "one", "of", "the", "most", "aggressive", "firms", "in", "merchant", "banking", "'", "##'", "and", "that", "`", "##`", "a", "very", "significant", "portion", "'", "##'", "of", "the", "firm", "'", "##s", "profit", "in", "recent", "years", "has", "come", "from", "merchant", "banking", "-", "related", "business", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "CS", "First", "Boston", "`", "##`", "has", "consistently", "been", "one", "of", "the", "most", "aggressive", "firms", "in", "merchant", "banking", "'", "##'", "and", "that", "`", "##`", "a", "very", "significant", "portion", "'", "##'", "of", "the", "firm", "'", "##s", "profit", "in", "recent", "years", "has", "come", "from", "merchant", "banking", "[SEP]", "[unused1]", "a", "very", "significant", "portion", "'", "##'", "of", "the", "firm", "'", "##s", "profit", "in", "recent", "years", "[unused2]", "[unused3]", "has", "come", "[unused4]", "[unused5]", "from", "merchant", "banking", "-", "related", "business", "[unused6]", "[SEP]", "[unused1]", "CS", "First", "Boston", "[unused2]", "[unused3]", "has", "consistently", "been", "[unused4]", "[unused5]", "one", "of", "the", "most", "aggressive", "firms", "in", "merchant", "banking", "[unused6]", "[SEP]"]]}

input 494:  {"source": "It surged 2 3\\/4 to 6 on volume of more than 1.7 million shares after the company agreed to be acquired by Japan 's Chugai Pharmaceutical for about $ 110 million -- almost double the market price of Gen - Probe 's stock .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 20420, 4, 5, 123, 124, 28148, 28139, 1527, 1106, 127, 1113, 3884, 1104, 1167, 1190, 122, 28138, 1559, 1550, 6117, 1170, 1103, 1419, 2675, 1106, 1129, 2888, 1118, 1999, 112, 1116, 17144, 21347, 7642, 24275, 2093, 19748, 1111, 1164, 109, 6745, 1550, 1593, 2702, 1103, 2319, 102, 1, 1103, 1419, 2, 3, 2675, 4, 5, 1106, 1129, 2888, 1118, 1999, 112, 1116, 17144, 21347, 7642, 24275, 2093, 19748, 1111, 1164, 109, 6745, 1550, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 20420, 4, 5, 123, 124, 28148, 28139, 1527, 1106, 127, 1170, 1103, 1419, 2675, 1106, 1129, 2888, 1118, 1999, 112, 1116, 17144, 21347, 7642, 24275, 2093, 19748, 1111, 1164, 109, 6745, 1550, 1593, 2702, 1103, 2319, 3945, 1104, 9198, 5096, 3962, 112, 1116, 4482, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 20420, 4, 5, 123, 124, 28148, 28139, 1527, 1106, 127, 1170, 1103, 1419, 2675, 1106, 1129, 2888, 1118, 1999, 112, 1116, 17144, 21347, 7642, 24275, 2093, 19748, 1111, 1164, 109, 6745, 1550, 1593, 2702, 1103, 2319, 3945, 1104, 9198, 5096, 3962, 112, 1116, 4482, 6, 102, 102, 1, 1135, 2, 3, 20420, 4, 5, 123, 124, 28148, 28139, 1527, 1106, 127, 1170, 1103, 1419, 2675, 1106, 1129, 2888, 1118, 1999, 112, 1116, 17144, 21347, 7642, 24275, 2093, 19748, 1111, 1164, 109, 6745, 1550, 1593, 2702, 1103, 2319, 3945, 1104, 9198, 5096, 3962, 112, 1116, 4482, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.051131121814250946, -0.0560726635158062, -0.05633023753762245, -0.2611968517303467, -0.06714864075183868, -0.07593568414449692, -0.3096916675567627, -0.3025810718536377, -0.3025810718536377, -0.3025810718536377], "metadata": {"source_tokens": ["It", "surged", "2", "3", "##\\", "##/", "##4", "to", "6", "on", "volume", "of", "more", "than", "1", "##.", "##7", "million", "shares", "after", "the", "company", "agreed", "to", "be", "acquired", "by", "Japan", "'", "##s", "Chu", "##gai", "Ph", "##arma", "##ce", "##utical", "for", "about", "$", "110", "million", "-", "##-", "almost", "double", "the", "market", "price", "of", "Gen", "-", "Pro", "##be", "'", "##s", "stock", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "surged", "[unused4]", "[unused5]", "2", "3", "##\\", "##/", "##4", "to", "6", "on", "volume", "of", "more", "than", "1", "##.", "##7", "million", "shares", "after", "the", "company", "agreed", "to", "be", "acquired", "by", "Japan", "'", "##s", "Chu", "##gai", "Ph", "##arma", "##ce", "##utical", "for", "about", "$", "110", "million", "almost", "double", "the", "market", "[SEP]", "[unused1]", "the", "company", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "be", "acquired", "by", "Japan", "'", "##s", "Chu", "##gai", "Ph", "##arma", "##ce", "##utical", "for", "about", "$", "110", "million", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "surged", "[unused4]", "[unused5]", "2", "3", "##\\", "##/", "##4", "to", "6", "after", "the", "company", "agreed", "to", "be", "acquired", "by", "Japan", "'", "##s", "Chu", "##gai", "Ph", "##arma", "##ce", "##utical", "for", "about", "$", "110", "million", "almost", "double", "the", "market", "price", "of", "Gen", "Pro", "##be", "'", "##s", "stock", "[unused6]", "[SEP]"]]}

input 495:  {"source": "It was the most active of the 100 - share index at 8.3 million shares , 6.5 million of which were traded by midday .\n"}
prediction:  {"predictions": [[1, 1135, 2, 3, 1108, 4, 5, 1103, 1211, 2327, 1104, 1103, 1620, 118, 2934, 7448, 1120, 129, 28138, 1495, 1550, 6117, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 127, 28138, 1571, 1550, 1104, 1134, 2, 3, 1127, 6537, 4, 5, 1118, 2286, 6194, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.008889357559382915, -0.013686067424714565, -0.022008895874023438, -0.022006988525390625, -0.022006988525390625, -0.022006988525390625, -0.022006988525390625, -0.022006988525390625, -0.022006988525390625, -0.022006988525390625], "metadata": {"source_tokens": ["It", "was", "the", "most", "active", "of", "the", "100", "-", "share", "index", "at", "8", "##.", "##3", "million", "shares", ",", "6", "##.", "##5", "million", "of", "which", "were", "traded", "by", "mid", "##day", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "the", "most", "active", "of", "the", "100", "-", "share", "index", "at", "8", "##.", "##3", "million", "shares", "[unused6]", "[SEP]", "[unused1]", "6", "##.", "##5", "million", "of", "which", "[unused2]", "[unused3]", "were", "traded", "[unused4]", "[unused5]", "by", "mid", "##day", "[unused6]", "[SEP]"]]}

input 496:  {"source": "Jaguar 's own defenses against a hostile bid are weakened , analysts add , because fewer than 3 % of its shares are owned by employees and management .\n"}
prediction:  {"predictions": [[1, 21694, 112, 1116, 1319, 14192, 1222, 170, 10518, 6875, 2, 3, 1132, 12041, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 22018, 2, 3, 5194, 4, 5, 1272, 8307, 1190, 124, 110, 1104, 1157, 6117, 1132, 2205, 1118, 4570, 1105, 2635, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.028077377006411552, -0.01003431249409914, -0.032225608825683594, -0.07709050178527832, -0.07709050178527832, -0.07709050178527832, -0.07709050178527832, -0.07709050178527832, -0.07709050178527832, -0.07709050178527832], "metadata": {"source_tokens": ["Jaguar", "'", "##s", "own", "defenses", "against", "a", "hostile", "bid", "are", "weakened", ",", "analysts", "add", ",", "because", "fewer", "than", "3", "%", "of", "its", "shares", "are", "owned", "by", "employees", "and", "management", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Jaguar", "'", "##s", "own", "defenses", "against", "a", "hostile", "bid", "[unused2]", "[unused3]", "are", "weakened", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "analysts", "[unused2]", "[unused3]", "add", "[unused4]", "[unused5]", "because", "fewer", "than", "3", "%", "of", "its", "shares", "are", "owned", "by", "employees", "and", "management", "[unused6]", "[SEP]"]]}

input 497:  {"source": "Japanese office workers use PCs at half the rate of their European counterparts and one - third that of the Americans .\n"}
prediction:  {"predictions": [[1, 1983, 1701, 3239, 2, 3, 1329, 4, 5, 7054, 1116, 1120, 1544, 1103, 2603, 1104, 1147, 1735, 15289, 1105, 1141, 118, 1503, 1115, 1104, 1103, 4038, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.005857500713318586, -0.03850555419921875, -0.039305925369262695, -0.039305925369262695, -0.039305925369262695, -0.039305925369262695, -0.039305925369262695, -0.039305925369262695, -0.039305925369262695, -0.039305925369262695], "metadata": {"source_tokens": ["Japanese", "office", "workers", "use", "PC", "##s", "at", "half", "the", "rate", "of", "their", "European", "counterparts", "and", "one", "-", "third", "that", "of", "the", "Americans", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Japanese", "office", "workers", "[unused2]", "[unused3]", "use", "[unused4]", "[unused5]", "PC", "##s", "at", "half", "the", "rate", "of", "their", "European", "counterparts", "and", "one", "-", "third", "that", "of", "the", "Americans", "[unused6]", "[SEP]"]]}

input 498:  {"source": "Keeping the Japanese happy will be one of the most important tasks facing conservative leader Ernesto Ruffo when he takes office Nov. 1 , as the first opposition governor in Mexico 's modern history .\n"}
prediction:  {"predictions": [[1, 1103, 1211, 1696, 8249, 2, 3, 4749, 4, 5, 6588, 2301, 24918, 155, 9435, 1186, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 2274, 4, 5, 1701, 14152, 28138, 122, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 22049, 1103, 1983, 2816, 2, 3, 1209, 1129, 4, 5, 1141, 1104, 1103, 1211, 1696, 8249, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 2274, 4, 5, 1701, 14152, 28138, 122, 1112, 1103, 1148, 4078, 4066, 1107, 2470, 112, 1116, 2030, 1607, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.06105731427669525, -0.0654781386256218, -0.04665214195847511, -0.08807841688394547, -0.3174138069152832, -0.3457331657409668, -0.3457331657409668, -0.3457331657409668, -0.3457331657409668, -0.3457331657409668], "metadata": {"source_tokens": ["Keeping", "the", "Japanese", "happy", "will", "be", "one", "of", "the", "most", "important", "tasks", "facing", "conservative", "leader", "Ernesto", "R", "##uff", "##o", "when", "he", "takes", "office", "Nov", "##.", "1", ",", "as", "the", "first", "opposition", "governor", "in", "Mexico", "'", "##s", "modern", "history", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "most", "important", "tasks", "[unused2]", "[unused3]", "facing", "[unused4]", "[unused5]", "conservative", "leader", "Ernesto", "R", "##uff", "##o", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "takes", "[unused4]", "[unused5]", "office", "Nov", "##.", "1", "[unused6]", "[SEP]", "[unused1]", "Keeping", "the", "Japanese", "happy", "[unused2]", "[unused3]", "will", "be", "[unused4]", "[unused5]", "one", "of", "the", "most", "important", "tasks", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "takes", "[unused4]", "[unused5]", "office", "Nov", "##.", "1", "as", "the", "first", "opposition", "governor", "in", "Mexico", "'", "##s", "modern", "history", "[unused6]", "[SEP]"]]}

input 499:  {"source": "Labor costs are climbing at a far more rapid pace in the health care industry than in other industries .\n"}
prediction:  {"predictions": [[1, 6314, 4692, 2, 3, 1132, 8259, 4, 5, 1120, 170, 1677, 1167, 6099, 6418, 1107, 1103, 2332, 1920, 2380, 1190, 1107, 1168, 7519, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0004109602596145123, -0.0162200927734375, -0.0219268798828125, -0.0219268798828125, -0.0219268798828125, -0.0219268798828125, -0.0219268798828125, -0.0219268798828125, -0.0219268798828125, -0.0219268798828125], "metadata": {"source_tokens": ["Labor", "costs", "are", "climbing", "at", "a", "far", "more", "rapid", "pace", "in", "the", "health", "care", "industry", "than", "in", "other", "industries", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Labor", "costs", "[unused2]", "[unused3]", "are", "climbing", "[unused4]", "[unused5]", "at", "a", "far", "more", "rapid", "pace", "in", "the", "health", "care", "industry", "than", "in", "other", "industries", "[unused6]", "[SEP]"]]}

input 500:  {"source": "Meanwhile , at home , Mitsubishi has control of some major projects .\n"}
prediction:  {"predictions": [[1, 21450, 2, 3, 1144, 4, 5, 1654, 1104, 1199, 1558, 3203, 5459, 1120, 1313, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.029826872050762177, -0.02200937271118164, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578], "metadata": {"source_tokens": ["Meanwhile", ",", "at", "home", ",", "Mitsubishi", "has", "control", "of", "some", "major", "projects", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mitsubishi", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "control", "of", "some", "major", "projects", "Meanwhile", "at", "home", "[unused6]", "[SEP]"]]}

input 501:  {"source": "Medical cooperatives , among the most successful in the U.S.S.R. , are banned from providing general - practitioner services ( their main source of income ) , carrying out surgery , and treating cancer patients , drug addicts and pregnant women .\n"}
prediction:  {"predictions": [[1, 3875, 14561, 1116, 117, 1621, 1103, 1211, 2265, 1107, 1103, 158, 28138, 1708, 28138, 1708, 28138, 2069, 28138, 2, 3, 1132, 7548, 4, 5, 1121, 3558, 1704, 118, 22351, 1826, 113, 1147, 1514, 2674, 1104, 2467, 114, 117, 4004, 1149, 6059, 117, 1105, 12770, 4182, 4420, 117, 3850, 5194, 102, 1, 3875, 14561, 1116, 1621, 1103, 1211, 2265, 1107, 1103, 158, 28138, 1708, 28138, 1708, 28138, 2069, 28138, 2, 3, 1132, 7548, 4, 5, 1121, 3558, 1704, 118, 22351, 1826, 1147, 1514, 2674, 1104, 2467, 4004, 1149, 6059, 1105, 12770, 4182, 4420, 3850, 5194, 17882, 1116, 1105, 6391, 1535, 6, 102, 1, 3875, 14561, 1116, 1621, 1103, 1211, 2265, 1107, 1103, 158, 28138, 1708, 28138, 1708, 28138, 2069, 28138, 2, 3, 1132, 7548, 4, 5, 1121, 3558, 1704, 22351, 1826, 1147, 1514, 2674, 1104, 2467, 4004, 1149, 6059, 1105, 12770, 4182, 4420, 3850, 5194, 17882, 1116, 1105, 6391, 1535, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.024177107959985733, -0.0669456273317337, -0.05975325405597687, -0.26836061477661133, -0.268609881401062, -0.2686272859573364, -0.268627405166626, -0.268627405166626, -0.268627405166626, -0.268627405166626], "metadata": {"source_tokens": ["Medical", "cooperative", "##s", ",", "among", "the", "most", "successful", "in", "the", "U", "##.", "##S", "##.", "##S", "##.", "##R", "##.", ",", "are", "banned", "from", "providing", "general", "-", "practitioner", "services", "(", "their", "main", "source", "of", "income", ")", ",", "carrying", "out", "surgery", ",", "and", "treating", "cancer", "patients", ",", "drug", "add", "##ict", "##s", "and", "pregnant", "women", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Medical", "cooperative", "##s", ",", "among", "the", "most", "successful", "in", "the", "U", "##.", "##S", "##.", "##S", "##.", "##R", "##.", "[unused2]", "[unused3]", "are", "banned", "[unused4]", "[unused5]", "from", "providing", "general", "-", "practitioner", "services", "(", "their", "main", "source", "of", "income", ")", ",", "carrying", "out", "surgery", ",", "and", "treating", "cancer", "patients", ",", "drug", "add", "[SEP]", "[unused1]", "Medical", "cooperative", "##s", "among", "the", "most", "successful", "in", "the", "U", "##.", "##S", "##.", "##S", "##.", "##R", "##.", "[unused2]", "[unused3]", "are", "banned", "[unused4]", "[unused5]", "from", "providing", "general", "-", "practitioner", "services", "their", "main", "source", "of", "income", "carrying", "out", "surgery", "and", "treating", "cancer", "patients", "drug", "add", "##ict", "##s", "and", "pregnant", "women", "[unused6]", "[SEP]", "[unused1]", "Medical", "cooperative", "##s", "among", "the", "most", "successful", "in", "the", "U", "##.", "##S", "##.", "##S", "##.", "##R", "##.", "[unused2]", "[unused3]", "are", "banned", "[unused4]", "[unused5]", "from", "providing", "general", "practitioner", "services", "their", "main", "source", "of", "income", "carrying", "out", "surgery", "and", "treating", "cancer", "patients", "drug", "add", "##ict", "##s", "and", "pregnant", "women", "[unused6]", "[SEP]"]]}

input 502:  {"source": "Merrill said it continues to believe that `` the causes of excess market volatility are far more complex than any particular computer trading strategy .\n"}
prediction:  {"predictions": [[1, 17247, 2, 3, 1163, 4, 5, 1122, 3430, 1106, 2059, 1115, 169, 28152, 1103, 4680, 1104, 10116, 2319, 10857, 11745, 11796, 1132, 1677, 1167, 2703, 1190, 1251, 2440, 2775, 6157, 5564, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 4680, 1104, 10116, 2319, 10857, 11745, 11796, 2, 3, 1132, 4, 5, 1677, 1167, 2703, 1190, 1251, 2440, 2775, 6157, 5564, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0069973049685359, -0.009741130284965038, -0.03222966194152832, -0.032251834869384766, -0.032251834869384766, -0.032251834869384766, -0.032251834869384766, -0.032251834869384766, -0.032251834869384766, -0.032251834869384766], "metadata": {"source_tokens": ["Merrill", "said", "it", "continues", "to", "believe", "that", "`", "##`", "the", "causes", "of", "excess", "market", "vol", "##ati", "##lity", "are", "far", "more", "complex", "than", "any", "particular", "computer", "trading", "strategy", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Merrill", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "continues", "to", "believe", "that", "`", "##`", "the", "causes", "of", "excess", "market", "vol", "##ati", "##lity", "are", "far", "more", "complex", "than", "any", "particular", "computer", "trading", "strategy", "[unused6]", "[SEP]", "[unused1]", "the", "causes", "of", "excess", "market", "vol", "##ati", "##lity", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "far", "more", "complex", "than", "any", "particular", "computer", "trading", "strategy", "[unused6]", "[SEP]"]]}

input 503:  {"source": "Metromedia , headed by John W. Kluge , has interests in telecommunications , robotic painting , computer software , restaurants and entertainment .\n"}
prediction:  {"predictions": [[1, 6431, 16418, 2, 3, 2917, 4, 5, 1118, 1287, 160, 28138, 148, 16693, 1162, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6431, 16418, 2, 3, 1144, 4, 5, 4740, 1107, 17955, 117, 24628, 3504, 117, 2775, 3594, 117, 7724, 1105, 5936, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0034731135237962008, -0.017722267657518387, -0.007923126220703125, -0.008235454559326172, -0.008235454559326172, -0.008235454559326172, -0.008235454559326172, -0.008235454559326172, -0.008235454559326172, -0.008235454559326172], "metadata": {"source_tokens": ["Metro", "##media", ",", "headed", "by", "John", "W", "##.", "K", "##lug", "##e", ",", "has", "interests", "in", "telecommunications", ",", "robotic", "painting", ",", "computer", "software", ",", "restaurants", "and", "entertainment", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Metro", "##media", "[unused2]", "[unused3]", "headed", "[unused4]", "[unused5]", "by", "John", "W", "##.", "K", "##lug", "##e", "[unused6]", "[SEP]", "[unused1]", "Metro", "##media", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "interests", "in", "telecommunications", ",", "robotic", "painting", ",", "computer", "software", ",", "restaurants", "and", "entertainment", "[unused6]", "[SEP]"]]}

input 504:  {"source": "Milk sold to the nation 's dairy plants and dealers averaged $ 14.50 for each hundred pounds , up 50 cents from September and up $ 1.50 from October 1988 , the department said .\n"}
prediction:  {"predictions": [[1, 1103, 2853, 2, 3, 1163, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 18165, 2, 3, 1962, 4, 5, 1106, 1103, 3790, 112, 1116, 14874, 3546, 1105, 19499, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 18165, 1962, 1106, 1103, 3790, 112, 1116, 14874, 3546, 1105, 19499, 2, 3, 11445, 4, 5, 109, 1489, 28138, 11049, 1111, 1296, 2937, 6549, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 18165, 2, 3, 1962, 4, 5, 1106, 1103, 3790, 112, 1116, 14874, 3546, 1105, 19499, 11445, 109, 1489, 28138, 11049, 1111, 1296, 2937, 6549, 1146, 1851, 18748, 1121, 1347, 1105, 1146, 109, 122, 28138, 11049, 1121, 1357, 2115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 18165, 2, 3, 1962, 4, 5, 1106, 1103, 3790, 112, 1116, 14874, 3546, 1105, 19499, 11445, 109, 1489, 28138, 11049, 1111, 1296, 2937, 6549, 1146, 1851, 18748, 1121, 1347, 1105, 1146, 109, 122, 28138, 11049, 1121, 1357, 2115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.095521941781044, -0.07021474838256836, -0.049874141812324524, -0.08837847411632538, -0.10875912755727768, -0.21104705333709717, -0.21148896217346191, -0.21148896217346191, -0.21148896217346191, -0.21148896217346191], "metadata": {"source_tokens": ["Milk", "sold", "to", "the", "nation", "'", "##s", "dairy", "plants", "and", "dealers", "averaged", "$", "14", "##.", "##50", "for", "each", "hundred", "pounds", ",", "up", "50", "cents", "from", "September", "and", "up", "$", "1", "##.", "##50", "from", "October", "1988", ",", "the", "department", "said", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "department", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Milk", "[unused2]", "[unused3]", "sold", "[unused4]", "[unused5]", "to", "the", "nation", "'", "##s", "dairy", "plants", "and", "dealers", "[unused6]", "[SEP]", "[unused1]", "Milk", "sold", "to", "the", "nation", "'", "##s", "dairy", "plants", "and", "dealers", "[unused2]", "[unused3]", "averaged", "[unused4]", "[unused5]", "$", "14", "##.", "##50", "for", "each", "hundred", "pounds", "[unused6]", "[SEP]", "[unused1]", "Milk", "[unused2]", "[unused3]", "sold", "[unused4]", "[unused5]", "to", "the", "nation", "'", "##s", "dairy", "plants", "and", "dealers", "averaged", "$", "14", "##.", "##50", "for", "each", "hundred", "pounds", "up", "50", "cents", "from", "September", "and", "up", "$", "1", "##.", "##50", "from", "October", "1988", "[unused6]", "[SEP]", "[unused1]", "Milk", "[unused2]", "[unused3]", "sold", "[unused4]", "[unused5]", "to", "the", "nation", "'", "##s", "dairy", "plants", "and", "dealers", "averaged", "$", "14", "##.", "##50", "for", "each", "hundred", "pounds", "up", "50", "cents", "from", "September", "and", "up", "$", "1", "##.", "##50", "from", "October", "1988", "[unused6]", "[SEP]"]]}

input 505:  {"source": "Most yields on short - term jumbo CDs , those with denominations over $ 90,000 , also moved in the opposite direction of Treasury bill yields .\n"}
prediction:  {"predictions": [[1, 2082, 17376, 1113, 1603, 118, 1858, 179, 1818, 4043, 16881, 2, 3, 1427, 4, 5, 1107, 1103, 3714, 2447, 1104, 11712, 4550, 17376, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1603, 118, 1858, 179, 1818, 4043, 16881, 2, 3, 1110, 4, 5, 1343, 1114, 18857, 1166, 109, 3078, 28136, 7629, 1568, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.025853266939520836, -0.05688544735312462, -0.07657122611999512, -0.0765678882598877, -0.0765678882598877, -0.0765678882598877, -0.0765678882598877, -0.0765678882598877, -0.0765678882598877, -0.0765678882598877], "metadata": {"source_tokens": ["Most", "yields", "on", "short", "-", "term", "j", "##um", "##bo", "CDs", ",", "those", "with", "denominations", "over", "$", "90", "##,", "##00", "##0", ",", "also", "moved", "in", "the", "opposite", "direction", "of", "Treasury", "bill", "yields", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Most", "yields", "on", "short", "-", "term", "j", "##um", "##bo", "CDs", "[unused2]", "[unused3]", "moved", "[unused4]", "[unused5]", "in", "the", "opposite", "direction", "of", "Treasury", "bill", "yields", "[unused6]", "[SEP]", "[unused1]", "short", "-", "term", "j", "##um", "##bo", "CDs", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "those", "with", "denominations", "over", "$", "90", "##,", "##00", "##0", "[unused6]", "[SEP]"]]}

input 506:  {"source": "Mr. Guber and Mr. Peters also almost certainly would n't be able to participate in future sequels to `` Batman , '' the blockbuster hit they produced for Warner .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 144, 15209, 1197, 1105, 1828, 28138, 12648, 2, 3, 1156, 183, 28131, 1204, 1129, 4, 5, 1682, 1106, 4868, 1107, 2174, 8047, 1116, 1106, 169, 28152, 8622, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3510, 27338, 2, 3, 1855, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1666, 4, 5, 1111, 6049, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 144, 15209, 1197, 1105, 1828, 28138, 12648, 2, 3, 1156, 183, 28131, 1204, 1129, 4, 5, 1682, 1106, 4868, 1107, 2174, 8047, 1116, 1106, 8622, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 144, 15209, 1197, 1105, 1828, 28138, 12648, 2, 3, 1156, 183, 28131, 1204, 1129, 4, 5, 1682, 1106, 4868, 1107, 2174, 8047, 1116, 1106, 8622, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 144, 15209, 1197, 1105, 1828, 28138, 12648, 2, 3, 1156, 183, 28131, 1204, 1129, 4, 5, 1682, 1106, 4868, 1107, 2174, 8047, 1116, 1106, 8622, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.056762102991342545, -0.14441269636154175, -0.04569621384143829, -0.08094488829374313, -0.08880528807640076, -0.08900652080774307, -0.21296262741088867, -0.2129662036895752, -0.2129662036895752, -0.2129662036895752], "metadata": {"source_tokens": ["Mr", "##.", "G", "##ube", "##r", "and", "Mr", "##.", "Peters", "also", "almost", "certainly", "would", "n", "##'", "##t", "be", "able", "to", "participate", "in", "future", "sequel", "##s", "to", "`", "##`", "Batman", ",", "'", "##'", "the", "block", "##buster", "hit", "they", "produced", "for", "Warner", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "G", "##ube", "##r", "and", "Mr", "##.", "Peters", "[unused2]", "[unused3]", "would", "n", "##'", "##t", "be", "[unused4]", "[unused5]", "able", "to", "participate", "in", "future", "sequel", "##s", "to", "`", "##`", "Batman", "[unused6]", "[SEP]", "[unused1]", "the", "block", "##buster", "[unused2]", "[unused3]", "hit", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "produced", "[unused4]", "[unused5]", "for", "Warner", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "G", "##ube", "##r", "and", "Mr", "##.", "Peters", "[unused2]", "[unused3]", "would", "n", "##'", "##t", "be", "[unused4]", "[unused5]", "able", "to", "participate", "in", "future", "sequel", "##s", "to", "Batman", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "G", "##ube", "##r", "and", "Mr", "##.", "Peters", "[unused2]", "[unused3]", "would", "n", "##'", "##t", "be", "[unused4]", "[unused5]", "able", "to", "participate", "in", "future", "sequel", "##s", "to", "Batman", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "G", "##ube", "##r", "and", "Mr", "##.", "Peters", "[unused2]", "[unused3]", "would", "n", "##'", "##t", "be", "[unused4]", "[unused5]", "able", "to", "participate", "in", "future", "sequel", "##s", "to", "Batman", "[unused6]", "[SEP]"]]}

input 507:  {"source": "Mr. Mulford said reports of tension between the Treasury and Fed have been exaggerated , insisting that they involved `` nuances . ''\n"}
prediction:  {"predictions": [[1, 1828, 28138, 19569, 9654, 6944, 2, 3, 1163, 4, 5, 3756, 1104, 6646, 1206, 1103, 11712, 1105, 26356, 1138, 1151, 18088, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 19569, 9654, 6944, 2, 3, 1163, 3756, 1104, 6646, 1206, 1103, 11712, 1105, 26356, 1138, 1151, 18088, 25504, 4, 5, 1115, 1152, 2017, 169, 28152, 183, 8734, 7723, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 2017, 4, 5, 183, 8734, 7723, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.023657402023673058, -0.04868533834815025, -0.13019932806491852, -0.1399078369140625, -0.13996219635009766, -0.13996219635009766, -0.13996219635009766, -0.13996219635009766, -0.13996219635009766, -0.13996219635009766], "metadata": {"source_tokens": ["Mr", "##.", "Mu", "##lf", "##ord", "said", "reports", "of", "tension", "between", "the", "Treasury", "and", "Fed", "have", "been", "exaggerated", ",", "insisting", "that", "they", "involved", "`", "##`", "n", "##uan", "##ces", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Mu", "##lf", "##ord", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "reports", "of", "tension", "between", "the", "Treasury", "and", "Fed", "have", "been", "exaggerated", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "Mu", "##lf", "##ord", "[unused2]", "[unused3]", "said", "reports", "of", "tension", "between", "the", "Treasury", "and", "Fed", "have", "been", "exaggerated", "insisting", "[unused4]", "[unused5]", "that", "they", "involved", "`", "##`", "n", "##uan", "##ces", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "involved", "[unused4]", "[unused5]", "n", "##uan", "##ces", "[unused6]", "[SEP]"]]}

input 508:  {"source": "Mr. Phelan is an adroit diplomat who normally appears to be solidly in control of the Big Board 's factions .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 7642, 9945, 1179, 2, 3, 1110, 4, 5, 1126, 8050, 21418, 1204, 11608, 1150, 5156, 2691, 1106, 1129, 4600, 1193, 1107, 1654, 1104, 1103, 2562, 2464, 112, 1116, 14468, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1126, 8050, 21418, 1204, 11608, 2, 3, 1106, 1129, 4, 5, 4600, 1193, 1107, 1654, 1104, 1103, 2562, 2464, 112, 1116, 14468, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1126, 8050, 21418, 1204, 11608, 2, 3, 5156, 2691, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0007433085120283067, -0.03323912248015404, -0.05515069514513016, -0.03553295135498047, -0.03436636924743652, -0.03436636924743652, -0.03436636924743652, -0.03436636924743652, -0.03436636924743652, -0.03436636924743652], "metadata": {"source_tokens": ["Mr", "##.", "Ph", "##ela", "##n", "is", "an", "ad", "##roi", "##t", "diplomat", "who", "normally", "appears", "to", "be", "solid", "##ly", "in", "control", "of", "the", "Big", "Board", "'", "##s", "factions", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Ph", "##ela", "##n", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "ad", "##roi", "##t", "diplomat", "who", "normally", "appears", "to", "be", "solid", "##ly", "in", "control", "of", "the", "Big", "Board", "'", "##s", "factions", "[unused6]", "[SEP]", "[unused1]", "an", "ad", "##roi", "##t", "diplomat", "[unused2]", "[unused3]", "to", "be", "[unused4]", "[unused5]", "solid", "##ly", "in", "control", "of", "the", "Big", "Board", "'", "##s", "factions", "[unused6]", "[SEP]", "[unused1]", "an", "ad", "##roi", "##t", "diplomat", "[unused2]", "[unused3]", "normally", "appears", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 509:  {"source": "Mr. Ridley 's decision fires the starting pistol for perhaps a costly contest between the world 's auto giants for Britain 's leading luxury - car maker .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 23013, 112, 1116, 2383, 2, 3, 8966, 4, 5, 1103, 2547, 8951, 1111, 3229, 170, 18372, 5235, 1206, 1103, 1362, 112, 1116, 12365, 21170, 1111, 2855, 112, 1116, 2020, 9886, 118, 1610, 11166, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.0063011301681399345, -0.07655453681945801, -0.07654595375061035, -0.07654595375061035, -0.07654595375061035, -0.07654595375061035, -0.07654595375061035, -0.07654595375061035, -0.07654595375061035, -0.07654595375061035], "metadata": {"source_tokens": ["Mr", "##.", "Ridley", "'", "##s", "decision", "fires", "the", "starting", "pistol", "for", "perhaps", "a", "costly", "contest", "between", "the", "world", "'", "##s", "auto", "giants", "for", "Britain", "'", "##s", "leading", "luxury", "-", "car", "maker", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Ridley", "'", "##s", "decision", "[unused2]", "[unused3]", "fires", "[unused4]", "[unused5]", "the", "starting", "pistol", "for", "perhaps", "a", "costly", "contest", "between", "the", "world", "'", "##s", "auto", "giants", "for", "Britain", "'", "##s", "leading", "luxury", "-", "car", "maker", "[unused6]", "[SEP]"]]}

input 510:  {"source": "Mr. Rifenburgh said the board still has n't acted on most of the internal report 's recommendations , pending restatement of the balance sheet .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 155, 24603, 16050, 1324, 2, 3, 1163, 4, 5, 1103, 2313, 1253, 1144, 183, 28131, 1204, 5376, 1113, 1211, 1104, 1103, 4422, 2592, 112, 1116, 11859, 117, 15498, 1832, 2193, 1880, 1104, 1103, 5233, 6837, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2313, 2, 3, 1144, 183, 28131, 1204, 5376, 4, 5, 1113, 1211, 1104, 1103, 4422, 2592, 112, 1116, 11859, 1253, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2313, 2, 3, 1144, 4, 5, 183, 28131, 1204, 5376, 1113, 1211, 1104, 1103, 4422, 2592, 112, 1116, 11859, 1253, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.010997247882187366, -0.013374683447182178, -0.26681506633758545, -0.14696112275123596, -0.12322235107421875, -0.12157964706420898, -0.12157964706420898, -0.12157964706420898, -0.12157964706420898, -0.12157964706420898], "metadata": {"source_tokens": ["Mr", "##.", "R", "##ife", "##nburg", "##h", "said", "the", "board", "still", "has", "n", "##'", "##t", "acted", "on", "most", "of", "the", "internal", "report", "'", "##s", "recommendations", ",", "pending", "rest", "##ate", "##ment", "of", "the", "balance", "sheet", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "R", "##ife", "##nburg", "##h", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "board", "still", "has", "n", "##'", "##t", "acted", "on", "most", "of", "the", "internal", "report", "'", "##s", "recommendations", ",", "pending", "rest", "##ate", "##ment", "of", "the", "balance", "sheet", "[unused6]", "[SEP]", "[unused1]", "the", "board", "[unused2]", "[unused3]", "has", "n", "##'", "##t", "acted", "[unused4]", "[unused5]", "on", "most", "of", "the", "internal", "report", "'", "##s", "recommendations", "still", "[unused6]", "[SEP]"]]}

input 511:  {"source": "Mr. Stoll suspected the intruder was one of those precocious students who has fun breaking into computers .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 1457, 12666, 2, 3, 6321, 4, 5, 1103, 1107, 24993, 1108, 1141, 1104, 1343, 3073, 2528, 9589, 1651, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1343, 3073, 2528, 9589, 1651, 2, 3, 1144, 4, 5, 4106, 4440, 1154, 7565, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1107, 24993, 2, 3, 1108, 4, 5, 1141, 1104, 1343, 3073, 2528, 9589, 1651, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.029696423560380936, -0.013761842623353004, -0.010575579479336739, -0.005290031433105469, -0.0054607391357421875, -0.0054607391357421875, -0.0054607391357421875, -0.0054607391357421875, -0.0054607391357421875, -0.0054607391357421875], "metadata": {"source_tokens": ["Mr", "##.", "St", "##oll", "suspected", "the", "in", "##truder", "was", "one", "of", "those", "pre", "##co", "##cious", "students", "who", "has", "fun", "breaking", "into", "computers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "St", "##oll", "[unused2]", "[unused3]", "suspected", "[unused4]", "[unused5]", "the", "in", "##truder", "was", "one", "of", "those", "pre", "##co", "##cious", "students", "[unused6]", "[SEP]", "[unused1]", "those", "pre", "##co", "##cious", "students", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "fun", "breaking", "into", "computers", "[unused6]", "[SEP]", "[unused1]", "the", "in", "##truder", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "one", "of", "those", "pre", "##co", "##cious", "students", "[unused6]", "[SEP]"]]}

Batch 4 Test Time =  46.01788401603699  s
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.03789043426513672
Decodertime : 0.000152587890625
g_f_logprobs : 0.03792881965637207
Decodertime : 0.0001747608184814453
g_f_logprobs : 0.03796219825744629
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.03788185119628906
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.0380549430847168
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.03784632682800293
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.03809189796447754
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.037949323654174805
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.03798317909240723
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.0379030704498291
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.038004398345947266
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.03787732124328613
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.0381011962890625
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.03793501853942871
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.03804135322570801
Decodertime : 0.000152587890625
g_f_logprobs : 0.03793931007385254
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.03800082206726074
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.037941932678222656
Decodertime : 0.00017499923706054688
g_f_logprobs : 0.03802037239074707
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.037886857986450195
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.03799295425415039
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.03792834281921387
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.03805375099182129
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.038002729415893555
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.03800821304321289
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.037920475006103516
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.03815913200378418
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.03793931007385254
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.0379786491394043
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.03790688514709473
Decodertime : 0.0001609325408935547
g_f_logprobs : 0.038047075271606445
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.03801703453063965
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.03802990913391113
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.0379788875579834
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.03801774978637695
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.03797578811645508
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.03802299499511719
Decodertime : 0.00015473365783691406
g_f_logprobs : 0.037980079650878906
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.03800320625305176
Decodertime : 0.00018334388732910156
g_f_logprobs : 0.03789854049682617
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.03800797462463379
Decodertime : 0.000156402587890625
g_f_logprobs : 0.03780055046081543
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.03800225257873535
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.038005828857421875
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.037941694259643555
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.037877798080444336
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.0379488468170166
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.03784680366516113
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.037969350814819336
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.037902116775512695
beam_search_time: 1.9772112369537354 s
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.06358146667480469
Decodertime : 0.000152587890625
g_f_logprobs : 0.06346321105957031
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.06348538398742676
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.06338882446289062
Decodertime : 0.000152587890625
g_f_logprobs : 0.06362318992614746
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.0636301040649414
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.06356406211853027
Decodertime : 0.00015854835510253906
g_f_logprobs : 0.0634608268737793
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.0635538101196289
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.06343269348144531
Decodertime : 0.0001742839813232422
g_f_logprobs : 0.0636606216430664
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.06356620788574219
Decodertime : 0.000152587890625
g_f_logprobs : 0.06356573104858398
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.0634765625
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.0635218620300293
Decodertime : 0.000152587890625
g_f_logprobs : 0.06357836723327637
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.0636589527130127
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.06352114677429199
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.06362318992614746
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.06350326538085938
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.06372237205505371
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.06351661682128906
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.06365513801574707
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.06353545188903809
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.06355905532836914
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.06358933448791504
Decodertime : 0.000152587890625
g_f_logprobs : 0.06372523307800293
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.06377100944519043
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.06371188163757324
Decodertime : 0.000156402587890625
g_f_logprobs : 0.06374168395996094
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.06392192840576172
Decodertime : 0.00017523765563964844
g_f_logprobs : 0.06356668472290039
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.06369447708129883
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.06368517875671387
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.06370115280151367
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.06368422508239746
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.06377053260803223
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.06361603736877441
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.06378507614135742
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.06368112564086914
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.0637674331665039
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.06357431411743164
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.06375718116760254
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.06365418434143066
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.06371283531188965
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.06371569633483887
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.06377983093261719
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.06382060050964355
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.0637655258178711
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.06375384330749512
beam_search_time: 3.2607452869415283 s
Decodertime : 0.0001595020294189453
g_f_logprobs : 0.09159421920776367
Decodertime : 0.000164031982421875
g_f_logprobs : 0.09090590476989746
Decodertime : 0.0001857280731201172
g_f_logprobs : 0.09116458892822266
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.09119558334350586
Decodertime : 0.000152587890625
g_f_logprobs : 0.09125256538391113
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.09114456176757812
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.09119439125061035
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.09095907211303711
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.09122014045715332
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.09117245674133301
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.09125494956970215
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.09097433090209961
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.09142494201660156
Decodertime : 0.0001556873321533203
g_f_logprobs : 0.09123635292053223
Decodertime : 0.000152587890625
g_f_logprobs : 0.0912635326385498
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.09123063087463379
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.09139180183410645
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.09171342849731445
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.09131407737731934
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.09125447273254395
Decodertime : 0.000152587890625
g_f_logprobs : 0.09119391441345215
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.09123873710632324
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.09136557579040527
Decodertime : 0.00018715858459472656
g_f_logprobs : 0.09160971641540527
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.09125328063964844
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.0911402702331543
Decodertime : 0.000152587890625
g_f_logprobs : 0.0911567211151123
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.09132122993469238
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.0912330150604248
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.09125685691833496
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.09124159812927246
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.09139084815979004
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.09134602546691895
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.09125518798828125
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.0913078784942627
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.09126067161560059
Decodertime : 0.000152587890625
g_f_logprobs : 0.0913093090057373
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.09112167358398438
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.0913081169128418
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.09142923355102539
Decodertime : 0.00015592575073242188
g_f_logprobs : 0.09140801429748535
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.09131932258605957
Decodertime : 0.000152587890625
g_f_logprobs : 0.09119653701782227
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.0912790298461914
Decodertime : 0.00018143653869628906
g_f_logprobs : 0.09127640724182129
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.09118223190307617
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.09137487411499023
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.0914914608001709
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.0913381576538086
Decodertime : 0.00016927719116210938
g_f_logprobs : 0.09122610092163086
beam_search_time: 4.643420457839966 s
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.11987876892089844
Decodertime : 0.0001513957977294922
g_f_logprobs : 0.11928462982177734
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.11935877799987793
Decodertime : 0.00015664100646972656
g_f_logprobs : 0.11960172653198242
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.11918258666992188
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.11923694610595703
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.11944770812988281
Decodertime : 0.00016999244689941406
g_f_logprobs : 0.11971783638000488
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.1193535327911377
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.11960816383361816
Decodertime : 0.00016021728515625
g_f_logprobs : 0.11952471733093262
Decodertime : 0.000152587890625
g_f_logprobs : 0.12033486366271973
Decodertime : 0.00021147727966308594
g_f_logprobs : 0.11945176124572754
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.11915946006774902
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.11935973167419434
Decodertime : 0.0001742839813232422
g_f_logprobs : 0.11950922012329102
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.1196742057800293
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.11949753761291504
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.11972618103027344
Decodertime : 0.00015211105346679688
g_f_logprobs : 0.11958551406860352
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.11948037147521973
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.11954140663146973
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.11945915222167969
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.11942172050476074
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.1196434497833252
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.11925458908081055
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.11941361427307129
Decodertime : 0.00015497207641601562
g_f_logprobs : 0.11942243576049805
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.1195211410522461
Decodertime : 0.000152587890625
g_f_logprobs : 0.11945056915283203
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.11947083473205566
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.11922049522399902
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.1195225715637207
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.11948156356811523
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.11952090263366699
Decodertime : 0.00015401840209960938
g_f_logprobs : 0.11943578720092773
Decodertime : 0.0001742839813232422
g_f_logprobs : 0.11949491500854492
Decodertime : 0.0001583099365234375
g_f_logprobs : 0.11945843696594238
Decodertime : 0.000152587890625
g_f_logprobs : 0.11960625648498535
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.11952614784240723
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.12024116516113281
Decodertime : 0.0001728534698486328
g_f_logprobs : 0.11938667297363281
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.11970734596252441
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.11948966979980469
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.11958813667297363
Decodertime : 0.00015997886657714844
g_f_logprobs : 0.11970090866088867
Decodertime : 0.00015282630920410156
g_f_logprobs : 0.11962056159973145
Decodertime : 0.0001537799835205078
g_f_logprobs : 0.11955070495605469
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.11962413787841797
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.11968517303466797
beam_search_time: 6.057825088500977 s
Decodertime : 0.0002117156982421875
g_f_logprobs : 0.14967656135559082
Decodertime : 0.000164031982421875
g_f_logprobs : 0.14830684661865234
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.14838838577270508
Decodertime : 0.0001685619354248047
g_f_logprobs : 0.14849424362182617
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.14872288703918457
Decodertime : 0.00016188621520996094
g_f_logprobs : 0.14836692810058594
Decodertime : 0.0001678466796875
g_f_logprobs : 0.14857029914855957
Decodertime : 0.00018525123596191406
g_f_logprobs : 0.1487281322479248
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.14901304244995117
Decodertime : 0.00015306472778320312
g_f_logprobs : 0.1485581398010254
Decodertime : 0.000164031982421875
g_f_logprobs : 0.14863133430480957
Decodertime : 0.00015354156494140625
g_f_logprobs : 0.14870023727416992
Decodertime : 0.00018525123596191406
g_f_logprobs : 0.1487889289855957
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.14912986755371094
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.1486217975616455
Decodertime : 0.0001518726348876953
g_f_logprobs : 0.14886069297790527
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.14858174324035645
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.14869070053100586
Decodertime : 0.000152587890625
g_f_logprobs : 0.1488187313079834
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.14882397651672363
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.14867472648620605
Decodertime : 0.000152587890625
g_f_logprobs : 0.14871788024902344
Decodertime : 0.0001544952392578125
g_f_logprobs : 0.14875364303588867
Decodertime : 0.00015425682067871094
g_f_logprobs : 0.14862990379333496
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.14873218536376953
Decodertime : 0.000152587890625
g_f_logprobs : 0.14873671531677246
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.14878034591674805
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.14866971969604492
Decodertime : 0.00018334388732910156
g_f_logprobs : 0.1487419605255127
Decodertime : 0.00015544891357421875
g_f_logprobs : 0.14912128448486328
Decodertime : 0.00017905235290527344
g_f_logprobs : 0.14890289306640625
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.14888882637023926
Decodertime : 0.00017261505126953125
g_f_logprobs : 0.14870810508728027
Decodertime : 0.00017142295837402344
g_f_logprobs : 0.1486508846282959
Decodertime : 0.00015878677368164062
g_f_logprobs : 0.14887166023254395
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.14882135391235352
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.14882779121398926
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.14865660667419434
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.1486952304840088
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.1485884189605713
Decodertime : 0.00016736984252929688
g_f_logprobs : 0.14913201332092285
Decodertime : 0.00015616416931152344
g_f_logprobs : 0.14879131317138672
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.1487572193145752
Decodertime : 0.00015234947204589844
g_f_logprobs : 0.14876151084899902
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.14887666702270508
Decodertime : 0.00015687942504882812
g_f_logprobs : 0.1486525535583496
Decodertime : 0.0001533031463623047
g_f_logprobs : 0.14882445335388184
Decodertime : 0.0001575946807861328
g_f_logprobs : 0.1485731601715088
Decodertime : 0.00015783309936523438
g_f_logprobs : 0.14870667457580566
Decodertime : 0.00018858909606933594
g_f_logprobs : 0.1490330696105957
beam_search_time: 7.521722078323364 s
Decodertime : 0.0001723766326904297
g_f_logprobs : 0.17783045768737793
Decodertime : 0.00015926361083984375
g_f_logprobs : 0.1779947280883789
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.1778566837310791
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.17784738540649414
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.17777252197265625
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.17802143096923828
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.17777395248413086
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.17783713340759277
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.17814350128173828
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.177811861038208
Decodertime : 0.00016999244689941406
g_f_logprobs : 0.17803335189819336
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.17782950401306152
Decodertime : 0.000164031982421875
g_f_logprobs : 0.1778554916381836
Decodertime : 0.000164031982421875
g_f_logprobs : 0.17786931991577148
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.1783747673034668
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.17832612991333008
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.17839908599853516
Decodertime : 0.00016069412231445312
g_f_logprobs : 0.17815756797790527
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.17824745178222656
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.17835187911987305
Decodertime : 0.00018978118896484375
g_f_logprobs : 0.17820525169372559
Decodertime : 0.00016164779663085938
g_f_logprobs : 0.17824220657348633
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.17837023735046387
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.1779649257659912
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.17836666107177734
Decodertime : 0.0001628398895263672
g_f_logprobs : 0.17821335792541504
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.17833924293518066
Decodertime : 0.000164031982421875
g_f_logprobs : 0.17827653884887695
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.17847323417663574
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.17844033241271973
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.1788620948791504
Decodertime : 0.000164031982421875
g_f_logprobs : 0.17815518379211426
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.17850017547607422
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.178513765335083
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.1786024570465088
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.17857670783996582
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.17843294143676758
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.17788171768188477
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.17847037315368652
beam_search_time: 7.016291856765747 s
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.17777538299560547
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.1776561737060547
Decodertime : 0.00018548965454101562
g_f_logprobs : 0.17794537544250488
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.17762470245361328
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.177901029586792
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.17769527435302734
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.17783737182617188
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.17753076553344727
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.17828631401062012
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.177717924118042
Decodertime : 0.00016951560974121094
g_f_logprobs : 0.17765307426452637
Decodertime : 0.00016832351684570312
g_f_logprobs : 0.1776578426361084
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.17806673049926758
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.1777191162109375
Decodertime : 0.00016880035400390625
g_f_logprobs : 0.17767119407653809
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.1778883934020996
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.17794537544250488
Decodertime : 0.00017595291137695312
g_f_logprobs : 0.17780160903930664
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.17795491218566895
Decodertime : 0.000164031982421875
g_f_logprobs : 0.17777347564697266
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.17804598808288574
Decodertime : 0.0001678466796875
g_f_logprobs : 0.1776294708251953
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.17787981033325195
Decodertime : 0.00018644332885742188
g_f_logprobs : 0.17798137664794922
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.17801523208618164
Decodertime : 0.00016450881958007812
g_f_logprobs : 0.17778992652893066
Decodertime : 0.00017309188842773438
g_f_logprobs : 0.17785048484802246
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.17783212661743164
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.17780566215515137
Decodertime : 0.00016498565673828125
g_f_logprobs : 0.17792153358459473
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.1779623031616211
beam_search_time: 5.565607786178589 s
Decodertime : 0.00016355514526367188
g_f_logprobs : 0.17782115936279297
Decodertime : 0.00015807151794433594
g_f_logprobs : 0.17755794525146484
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.1780848503112793
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.17788076400756836
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.17754197120666504
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.17784380912780762
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.1776289939880371
Decodertime : 0.0001647472381591797
g_f_logprobs : 0.17815685272216797
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.177626371383667
Decodertime : 0.00016689300537109375
g_f_logprobs : 0.17772459983825684
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.1780848503112793
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.17789125442504883
Decodertime : 0.0001621246337890625
g_f_logprobs : 0.1778709888458252
Decodertime : 0.000186920166015625
g_f_logprobs : 0.17777323722839355
Decodertime : 0.00016951560974121094
g_f_logprobs : 0.17824387550354004
Decodertime : 0.0001678466796875
g_f_logprobs : 0.17784452438354492
Decodertime : 0.0001690387725830078
g_f_logprobs : 0.1783435344696045
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.1775527000427246
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.17798542976379395
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.1781935691833496
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.17811846733093262
Decodertime : 0.00016427040100097656
g_f_logprobs : 0.1779494285583496
Decodertime : 0.00018167495727539062
g_f_logprobs : 0.17821240425109863
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.17766213417053223
beam_search_time: 4.310395240783691 s
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.17767858505249023
Decodertime : 0.0001571178436279297
g_f_logprobs : 0.1777358055114746
Decodertime : 0.0001671314239501953
g_f_logprobs : 0.17809224128723145
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.17793965339660645
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.178056001663208
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.1792593002319336
Decodertime : 0.0001704692840576172
g_f_logprobs : 0.17797183990478516
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.1778266429901123
Decodertime : 0.00017714500427246094
g_f_logprobs : 0.17846202850341797
Decodertime : 0.0001666545867919922
g_f_logprobs : 0.17767763137817383
Decodertime : 0.0001876354217529297
g_f_logprobs : 0.17813873291015625
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.17803597450256348
Decodertime : 0.00016808509826660156
g_f_logprobs : 0.17798757553100586
Decodertime : 0.00017714500427246094
g_f_logprobs : 0.17802762985229492
Decodertime : 0.00016641616821289062
g_f_logprobs : 0.17810368537902832
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.17764806747436523
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.17814421653747559
beam_search_time: 3.0556187629699707 s
Decodertime : 0.00016307830810546875
g_f_logprobs : 0.1778569221496582
Decodertime : 0.00015735626220703125
g_f_logprobs : 0.17783784866333008
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.17778515815734863
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.17778348922729492
Decodertime : 0.00016617774963378906
g_f_logprobs : 0.1779460906982422
Decodertime : 0.00016379356384277344
g_f_logprobs : 0.17792248725891113
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.177842378616333
Decodertime : 0.0001659393310546875
g_f_logprobs : 0.17801380157470703
Decodertime : 0.00017690658569335938
g_f_logprobs : 0.17842626571655273
Decodertime : 0.00016570091247558594
g_f_logprobs : 0.17775726318359375
Decodertime : 0.0001633167266845703
g_f_logprobs : 0.1776561737060547
Decodertime : 0.00016546249389648438
g_f_logprobs : 0.178145170211792
Decodertime : 0.00017404556274414062
g_f_logprobs : 0.17799115180969238
Decodertime : 0.00017023086547851562
g_f_logprobs : 0.17752671241760254
Decodertime : 0.00018715858459472656
g_f_logprobs : 0.1777186393737793
Decodertime : 0.00016999244689941406
g_f_logprobs : 0.17772746086120605
Decodertime : 0.0001652240753173828
g_f_logprobs : 0.1776900291442871
beam_search_time: 3.0523617267608643 s
input 512:  {"source": "Mr. Wathen , who says Pinkerton 's had a loss of nearly $ 8 million in 1987 under American Brands , boasts that he 's made Pinkerton 's profitable again .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 160, 9779, 1424, 2, 3, 1867, 4, 5, 10763, 20024, 112, 1116, 1125, 170, 2445, 1104, 2212, 109, 129, 1550, 1107, 2164, 1223, 1237, 12381, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 160, 9779, 1424, 2, 3, 24372, 4, 5, 1115, 1119, 112, 1116, 1189, 10763, 20024, 112, 1116, 16244, 1254, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 10763, 20024, 112, 1116, 2, 3, 1125, 4, 5, 170, 2445, 1104, 2212, 109, 129, 1550, 1107, 2164, 1223, 1237, 12381, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 112, 1116, 1189, 4, 5, 10763, 20024, 112, 1116, 16244, 1254, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017365628853440285, -0.013182763941586018, -0.056668996810913086, -0.07342790812253952, -0.08266663551330566, -0.08253908157348633, -0.08253908157348633, -0.08253908157348633, -0.08253908157348633, -0.08253908157348633], "metadata": {"source_tokens": ["Mr", "##.", "W", "##ath", "##en", ",", "who", "says", "Pink", "##erton", "'", "##s", "had", "a", "loss", "of", "nearly", "$", "8", "million", "in", "1987", "under", "American", "Brand", "##s", ",", "boasts", "that", "he", "'", "##s", "made", "Pink", "##erton", "'", "##s", "profitable", "again", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "W", "##ath", "##en", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Pink", "##erton", "'", "##s", "had", "a", "loss", "of", "nearly", "$", "8", "million", "in", "1987", "under", "American", "Brand", "##s", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "W", "##ath", "##en", "[unused2]", "[unused3]", "boasts", "[unused4]", "[unused5]", "that", "he", "'", "##s", "made", "Pink", "##erton", "'", "##s", "profitable", "again", "[unused6]", "[SEP]", "[unused1]", "Pink", "##erton", "'", "##s", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "loss", "of", "nearly", "$", "8", "million", "in", "1987", "under", "American", "Brand", "##s", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "'", "##s", "made", "[unused4]", "[unused5]", "Pink", "##erton", "'", "##s", "profitable", "again", "[unused6]", "[SEP]"]]}

input 513:  {"source": "Mr. Zayadi was previously president and chief operating officer of Zellers Inc. , a retail chain that is owned by Toronto - based Hudson 's Bay Co. , Canada 's largest department store operator .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 163, 12057, 3309, 2, 3, 1108, 4, 5, 2331, 2084, 1105, 2705, 3389, 2575, 1104, 163, 13703, 1116, 3561, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 6989, 4129, 2, 3, 1110, 2205, 4, 5, 1118, 3506, 118, 1359, 6236, 112, 1116, 2410, 3291, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 163, 12057, 3309, 2, 3, 1108, 4, 5, 2331, 2084, 1105, 2705, 3389, 2575, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.020594513043761253, -0.020550528541207314, -0.14959518611431122, -0.21073412895202637, -0.20739543437957764, -0.20739543437957764, -0.20739543437957764, -0.20739543437957764, -0.20739543437957764, -0.20739543437957764], "metadata": {"source_tokens": ["Mr", "##.", "Z", "##aya", "##di", "was", "previously", "president", "and", "chief", "operating", "officer", "of", "Z", "##eller", "##s", "Inc", "##.", ",", "a", "retail", "chain", "that", "is", "owned", "by", "Toronto", "-", "based", "Hudson", "'", "##s", "Bay", "Co", "##.", ",", "Canada", "'", "##s", "largest", "department", "store", "operator", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Z", "##aya", "##di", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "previously", "president", "and", "chief", "operating", "officer", "of", "Z", "##eller", "##s", "Inc", "[unused6]", "[SEP]", "[unused1]", "a", "retail", "chain", "[unused2]", "[unused3]", "is", "owned", "[unused4]", "[unused5]", "by", "Toronto", "-", "based", "Hudson", "'", "##s", "Bay", "Co", "##.", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "Z", "##aya", "##di", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "previously", "president", "and", "chief", "operating", "officer", "[unused6]", "[SEP]"]]}

input 514:  {"source": "Mrs. Marcos 's trial is expected to begin in March .\n"}
prediction:  {"predictions": [[1, 2823, 28138, 15541, 112, 1116, 3443, 2, 3, 1110, 2637, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2823, 28138, 15541, 112, 1116, 3443, 2, 3, 1106, 3295, 4, 5, 1107, 1345, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.002740756841376424, -0.0015546365175396204, -0.00027561187744140625, -0.0002751350402832031, -0.0002751350402832031, -0.0002751350402832031, -0.0002751350402832031, -0.0002751350402832031, -0.0002751350402832031, -0.0002751350402832031], "metadata": {"source_tokens": ["Mrs", "##.", "Marcos", "'", "##s", "trial", "is", "expected", "to", "begin", "in", "March", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mrs", "##.", "Marcos", "'", "##s", "trial", "[unused2]", "[unused3]", "is", "expected", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Mrs", "##.", "Marcos", "'", "##s", "trial", "[unused2]", "[unused3]", "to", "begin", "[unused4]", "[unused5]", "in", "March", "[unused6]", "[SEP]"]]}

input 515:  {"source": "Mrs. Marcos has n't admitted that she filed any documents such as those sought by the government .\n"}
prediction:  {"predictions": [[1, 1343, 2, 3, 4110, 4, 5, 1118, 1103, 1433, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2823, 28138, 15541, 2, 3, 1144, 183, 28131, 1204, 4120, 4, 5, 1115, 1131, 5770, 1251, 4961, 1216, 1112, 1343, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014290571212768555, -0.0009385502780787647, -0.0444645881652832, -0.03930306434631348, -0.03930306434631348, -0.03930306434631348, -0.03930306434631348, -0.03930306434631348, -0.03930306434631348, -0.03930306434631348], "metadata": {"source_tokens": ["Mrs", "##.", "Marcos", "has", "n", "##'", "##t", "admitted", "that", "she", "filed", "any", "documents", "such", "as", "those", "sought", "by", "the", "government", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "those", "[unused2]", "[unused3]", "sought", "[unused4]", "[unused5]", "by", "the", "government", "[unused6]", "[SEP]", "[unused1]", "Mrs", "##.", "Marcos", "[unused2]", "[unused3]", "has", "n", "##'", "##t", "admitted", "[unused4]", "[unused5]", "that", "she", "filed", "any", "documents", "such", "as", "those", "[unused6]", "[SEP]"]]}

input 516:  {"source": "Nixon , on the fourth day of a private visit to China , said that damage to Sino - U.S. relations was `` very great , '' calling the situation `` the most serious '' since 1972 .\n"}
prediction:  {"predictions": [[1, 11302, 2, 3, 1163, 4, 5, 1115, 3290, 1106, 21572, 118, 158, 28138, 1708, 28138, 4125, 1108, 169, 28152, 1304, 1632, 117, 112, 28131, 3516, 1103, 2820, 169, 28152, 1103, 1211, 3021, 112, 28131, 1290, 2388, 1113, 1103, 2223, 1285, 1104, 170, 2029, 3143, 1106, 1975, 6, 102, 102, 102, 1, 3290, 1106, 21572, 118, 158, 28138, 1708, 28138, 4125, 2, 3, 1108, 4, 5, 1632, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3290, 1106, 21572, 118, 158, 28138, 1708, 28138, 4125, 2, 3, 1108, 4, 5, 1632, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11302, 1113, 1103, 2223, 1285, 1104, 170, 2029, 3143, 1106, 1975, 2, 3, 1163, 4, 5, 1115, 3290, 1106, 21572, 158, 28138, 1708, 28138, 4125, 1108, 1304, 1632, 3516, 1103, 2820, 1103, 1211, 3021, 1290, 2388, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3290, 1106, 21572, 118, 158, 28138, 1708, 28138, 4125, 2, 3, 1108, 4, 5, 1632, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11302, 1113, 1103, 2223, 1285, 1104, 170, 2029, 3143, 1106, 1975, 2, 3, 1163, 4, 5, 1115, 3290, 1106, 21572, 158, 28138, 1708, 28138, 4125, 1108, 1304, 1632, 3516, 1103, 2820, 1103, 1211, 3021, 1290, 2388, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012923539616167545, -0.11421044915914536, -0.1677214652299881, -0.10187376290559769, -0.17952629923820496, -0.10346175730228424, -0.15336596965789795, -0.1658170223236084, -0.1658170223236084, -0.1658170223236084], "metadata": {"source_tokens": ["Nixon", ",", "on", "the", "fourth", "day", "of", "a", "private", "visit", "to", "China", ",", "said", "that", "damage", "to", "Sino", "-", "U", "##.", "##S", "##.", "relations", "was", "`", "##`", "very", "great", ",", "'", "##'", "calling", "the", "situation", "`", "##`", "the", "most", "serious", "'", "##'", "since", "1972", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Nixon", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "that", "damage", "to", "Sino", "-", "U", "##.", "##S", "##.", "relations", "was", "`", "##`", "very", "great", ",", "'", "##'", "calling", "the", "situation", "`", "##`", "the", "most", "serious", "'", "##'", "since", "1972", "on", "the", "fourth", "day", "of", "a", "private", "visit", "to", "China", "[unused6]", "[SEP]", "[unused1]", "damage", "to", "Sino", "-", "U", "##.", "##S", "##.", "relations", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "great", "[unused6]", "[SEP]", "[unused1]", "damage", "to", "Sino", "-", "U", "##.", "##S", "##.", "relations", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "great", "[unused6]", "[SEP]", "[unused1]", "Nixon", "on", "the", "fourth", "day", "of", "a", "private", "visit", "to", "China", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "that", "damage", "to", "Sino", "U", "##.", "##S", "##.", "relations", "was", "very", "great", "calling", "the", "situation", "the", "most", "serious", "since", "1972", "[unused6]", "[SEP]", "[unused1]", "damage", "to", "Sino", "-", "U", "##.", "##S", "##.", "relations", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "great", "[unused6]", "[SEP]", "[unused1]", "Nixon", "on", "the", "fourth", "day", "of", "a", "private", "visit", "to", "China", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "that", "damage", "to", "Sino", "U", "##.", "##S", "##.", "relations", "was", "very", "great", "calling", "the", "situation", "the", "most", "serious", "since", "1972", "[unused6]", "[SEP]"]]}

input 517:  {"source": "Norris McLaughlin is a general - practice firm that has expanded recently into such specialties as banking , labor and environmental work .\n"}
prediction:  {"predictions": [[1, 16309, 26721, 2, 3, 1110, 4, 5, 170, 1704, 118, 2415, 3016, 1115, 1144, 3631, 3055, 1154, 1216, 1957, 4338, 1112, 9339, 117, 5530, 1105, 4801, 1250, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1704, 118, 2415, 3016, 2, 3, 1144, 3631, 4, 5, 3055, 1154, 1216, 1957, 4338, 1112, 9339, 117, 5530, 1105, 4801, 1250, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0005655527347698808, -0.004854582715779543, -0.02201366424560547, -0.022014617919921875, -0.022014617919921875, -0.022014617919921875, -0.022014617919921875, -0.022014617919921875, -0.022014617919921875, -0.022014617919921875], "metadata": {"source_tokens": ["Norris", "McLaughlin", "is", "a", "general", "-", "practice", "firm", "that", "has", "expanded", "recently", "into", "such", "special", "##ties", "as", "banking", ",", "labor", "and", "environmental", "work", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Norris", "McLaughlin", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "general", "-", "practice", "firm", "that", "has", "expanded", "recently", "into", "such", "special", "##ties", "as", "banking", ",", "labor", "and", "environmental", "work", "[unused6]", "[SEP]", "[unused1]", "a", "general", "-", "practice", "firm", "[unused2]", "[unused3]", "has", "expanded", "[unused4]", "[unused5]", "recently", "into", "such", "special", "##ties", "as", "banking", ",", "labor", "and", "environmental", "work", "[unused6]", "[SEP]"]]}

input 518:  {"source": "Now Mr. Broberg , a lawyer , claims he 'd play for free .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 139, 25560, 10805, 2, 3, 3711, 4, 5, 1119, 112, 1181, 1505, 1111, 1714, 1986, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 139, 25560, 10805, 2, 3, 1110, 4, 5, 170, 4545, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 112, 1181, 1505, 4, 5, 1111, 1714, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0019130706787109375, -0.011608068831264973, -0.027935313060879707, -0.02199840545654297, -0.021998882293701172, -0.021998882293701172, -0.021998882293701172, -0.021998882293701172, -0.021998882293701172, -0.021998882293701172], "metadata": {"source_tokens": ["Now", "Mr", "##.", "B", "##robe", "##rg", ",", "a", "lawyer", ",", "claims", "he", "'", "##d", "play", "for", "free", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "B", "##robe", "##rg", "[unused2]", "[unused3]", "claims", "[unused4]", "[unused5]", "he", "'", "##d", "play", "for", "free", "Now", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "B", "##robe", "##rg", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "lawyer", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "'", "##d", "play", "[unused4]", "[unused5]", "for", "free", "[unused6]", "[SEP]"]]}

input 519:  {"source": "Now that the New York decision has been left intact , other states may follow suit .\n"}
prediction:  {"predictions": [[1, 1168, 2231, 2, 3, 1336, 2812, 4, 5, 4228, 1986, 1115, 1103, 1203, 1365, 2383, 1144, 1151, 1286, 9964, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1203, 1365, 2383, 2, 3, 1144, 1151, 1286, 4, 5, 9964, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027265159413218498, -0.01271119900047779, -0.019230365753173828, -0.020486831665039062, -0.020486831665039062, -0.020486831665039062, -0.020486831665039062, -0.020486831665039062, -0.020486831665039062, -0.020486831665039062], "metadata": {"source_tokens": ["Now", "that", "the", "New", "York", "decision", "has", "been", "left", "intact", ",", "other", "states", "may", "follow", "suit", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "other", "states", "[unused2]", "[unused3]", "may", "follow", "[unused4]", "[unused5]", "suit", "Now", "that", "the", "New", "York", "decision", "has", "been", "left", "intact", "[unused6]", "[SEP]", "[unused1]", "the", "New", "York", "decision", "[unused2]", "[unused3]", "has", "been", "left", "[unused4]", "[unused5]", "intact", "[unused6]", "[SEP]"]]}

input 520:  {"source": "Of the self - starting vacuum cleaner , he says : `` Could be Cuddles , { Mrs. Stinnett 's dog } . ''\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1867, 4, 5, 7426, 1129, 140, 22940, 2897, 117, 196, 2823, 28138, 1457, 25409, 5912, 112, 1116, 3676, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03235475346446037, -0.04027819633483887, -0.038823604583740234, -0.038823604583740234, -0.038823604583740234, -0.038823604583740234, -0.038823604583740234, -0.038823604583740234, -0.038823604583740234, -0.038823604583740234], "metadata": {"source_tokens": ["Of", "the", "self", "-", "starting", "vacuum", "cleaner", ",", "he", "says", ":", "`", "##`", "Could", "be", "C", "##udd", "##les", ",", "{", "Mrs", "##.", "St", "##inn", "##ett", "'", "##s", "dog", "}", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Could", "be", "C", "##udd", "##les", ",", "{", "Mrs", "##.", "St", "##inn", "##ett", "'", "##s", "dog", "[unused6]", "[SEP]"]]}

input 521:  {"source": "On a broader scale , the ruling could encourage other states ' courts to adopt the logic of the New York court , not only in DES cases but in other product - related lawsuits , as well .\n"}
prediction:  {"predictions": [[1, 1103, 6550, 2, 3, 1180, 8343, 4, 5, 1168, 2231, 112, 5333, 1106, 11258, 1103, 8738, 1104, 1103, 1203, 1365, 2175, 117, 1136, 1178, 1107, 18581, 1708, 2740, 1133, 1107, 1168, 3317, 118, 2272, 23005, 117, 1112, 1218, 1212, 170, 12594, 3418, 6, 102, 102, 102, 102, 102, 102, 102, 1, 1168, 2231, 5333, 2, 3, 1106, 11258, 4, 5, 1103, 8738, 1104, 1103, 1203, 1365, 2175, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01191963441669941, -0.06326401978731155, -0.24659764766693115, -0.2362828254699707, -0.2362828254699707, -0.2362828254699707, -0.2362828254699707, -0.2362828254699707, -0.2362828254699707, -0.2362828254699707], "metadata": {"source_tokens": ["On", "a", "broader", "scale", ",", "the", "ruling", "could", "encourage", "other", "states", "'", "courts", "to", "adopt", "the", "logic", "of", "the", "New", "York", "court", ",", "not", "only", "in", "DE", "##S", "cases", "but", "in", "other", "product", "-", "related", "lawsuits", ",", "as", "well", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "ruling", "[unused2]", "[unused3]", "could", "encourage", "[unused4]", "[unused5]", "other", "states", "'", "courts", "to", "adopt", "the", "logic", "of", "the", "New", "York", "court", ",", "not", "only", "in", "DE", "##S", "cases", "but", "in", "other", "product", "-", "related", "lawsuits", ",", "as", "well", "On", "a", "broader", "scale", "[unused6]", "[SEP]", "[unused1]", "other", "states", "courts", "[unused2]", "[unused3]", "to", "adopt", "[unused4]", "[unused5]", "the", "logic", "of", "the", "New", "York", "court", "[unused6]", "[SEP]"]]}

input 522:  {"source": "On a recent afternoon , Mr. Baker and a reporter go ghost - busting , visiting Kathleen Stinnett , a Lexington woman who has phoned the University of Kentucky to report mysterious happenings in her house .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 5779, 1105, 170, 6672, 2, 3, 1301, 4, 5, 7483, 118, 16118, 1158, 1212, 170, 2793, 4427, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 15134, 1590, 2, 3, 1144, 2179, 1181, 4, 5, 1103, 1239, 1104, 4875, 1106, 2592, 8198, 5664, 1116, 1107, 1123, 1402, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 5779, 1105, 170, 6672, 2, 3, 1301, 7483, 16118, 1158, 5807, 4, 5, 15182, 1457, 25409, 5912, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 5779, 1105, 170, 6672, 2, 3, 1301, 4, 5, 7483, 16118, 1158, 5807, 15182, 1457, 25409, 5912, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 5779, 1105, 170, 6672, 2, 3, 1301, 4, 5, 7483, 16118, 1158, 5807, 15182, 1457, 25409, 5912, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 5779, 1105, 170, 6672, 2, 3, 1301, 4, 5, 7483, 16118, 1158, 5807, 15182, 1457, 25409, 5912, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.036061178892850876, -0.01937435381114483, -0.10349166393280029, -0.1573592573404312, -0.15579655766487122, -0.16211409866809845, -0.21203231811523438, -0.2119591236114502, -0.2119591236114502, -0.2119591236114502], "metadata": {"source_tokens": ["On", "a", "recent", "afternoon", ",", "Mr", "##.", "Baker", "and", "a", "reporter", "go", "ghost", "-", "bust", "##ing", ",", "visiting", "Kathleen", "St", "##inn", "##ett", ",", "a", "Lexington", "woman", "who", "has", "phone", "##d", "the", "University", "of", "Kentucky", "to", "report", "mysterious", "happening", "##s", "in", "her", "house", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Baker", "and", "a", "reporter", "[unused2]", "[unused3]", "go", "[unused4]", "[unused5]", "ghost", "-", "bust", "##ing", "On", "a", "recent", "afternoon", "[unused6]", "[SEP]", "[unused1]", "a", "Lexington", "woman", "[unused2]", "[unused3]", "has", "phone", "##d", "[unused4]", "[unused5]", "the", "University", "of", "Kentucky", "to", "report", "mysterious", "happening", "##s", "in", "her", "house", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "Baker", "and", "a", "reporter", "[unused2]", "[unused3]", "go", "ghost", "bust", "##ing", "visiting", "[unused4]", "[unused5]", "Kathleen", "St", "##inn", "##ett", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "Baker", "and", "a", "reporter", "[unused2]", "[unused3]", "go", "[unused4]", "[unused5]", "ghost", "bust", "##ing", "visiting", "Kathleen", "St", "##inn", "##ett", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "Baker", "and", "a", "reporter", "[unused2]", "[unused3]", "go", "[unused4]", "[unused5]", "ghost", "bust", "##ing", "visiting", "Kathleen", "St", "##inn", "##ett", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "Baker", "and", "a", "reporter", "[unused2]", "[unused3]", "go", "[unused4]", "[unused5]", "ghost", "bust", "##ing", "visiting", "Kathleen", "St", "##inn", "##ett", "[unused6]", "[SEP]"]]}

input 523:  {"source": "One had best not dance on top of a coffin until the lid is sealed tightly shut . ''\n"}
prediction:  {"predictions": [[1, 1448, 2, 3, 1125, 1436, 1136, 2842, 4, 5, 1113, 1499, 1104, 170, 16638, 1235, 1103, 14753, 1110, 10410, 6852, 3210, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 14753, 2, 3, 1110, 10410, 4, 5, 6852, 3210, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023317774757742882, -0.07254616916179657, -0.03854179382324219, -0.038542747497558594, -0.038542747497558594, -0.038542747497558594, -0.038542747497558594, -0.038542747497558594, -0.038542747497558594, -0.038542747497558594], "metadata": {"source_tokens": ["One", "had", "best", "not", "dance", "on", "top", "of", "a", "coffin", "until", "the", "lid", "is", "sealed", "tightly", "shut", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "One", "[unused2]", "[unused3]", "had", "best", "not", "dance", "[unused4]", "[unused5]", "on", "top", "of", "a", "coffin", "until", "the", "lid", "is", "sealed", "tightly", "shut", "[unused6]", "[SEP]", "[unused1]", "the", "lid", "[unused2]", "[unused3]", "is", "sealed", "[unused4]", "[unused5]", "tightly", "shut", "[unused6]", "[SEP]"]]}

input 524:  {"source": "Only his factories in Japan and Korea , employing his followers at subsistence wages and producing everything from rifles to ginseng to expensive marble vases , kept the money flowing westward .\n"}
prediction:  {"predictions": [[1, 2809, 1117, 11615, 1107, 1999, 1105, 3577, 2, 3, 2023, 4, 5, 1103, 1948, 8342, 17222, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2809, 1117, 11615, 1107, 1999, 1105, 3577, 2, 3, 4411, 4, 5, 1917, 1121, 12385, 1106, 176, 4935, 14429, 1106, 5865, 8004, 26100, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2809, 1117, 11615, 1107, 1999, 1105, 3577, 2, 3, 16846, 4, 5, 1117, 8618, 1120, 4841, 19031, 13588, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03717818856239319, -0.035163506865501404, -0.059940434992313385, -0.12360763549804688, -0.1236107349395752, -0.1236107349395752, -0.1236107349395752, -0.1236107349395752, -0.1236107349395752, -0.1236107349395752], "metadata": {"source_tokens": ["Only", "his", "factories", "in", "Japan", "and", "Korea", ",", "employing", "his", "followers", "at", "sub", "##sistence", "wages", "and", "producing", "everything", "from", "rifles", "to", "g", "##ins", "##eng", "to", "expensive", "marble", "vase", "##s", ",", "kept", "the", "money", "flowing", "westward", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Only", "his", "factories", "in", "Japan", "and", "Korea", "[unused2]", "[unused3]", "kept", "[unused4]", "[unused5]", "the", "money", "flowing", "westward", "[unused6]", "[SEP]", "[unused1]", "Only", "his", "factories", "in", "Japan", "and", "Korea", "[unused2]", "[unused3]", "producing", "[unused4]", "[unused5]", "everything", "from", "rifles", "to", "g", "##ins", "##eng", "to", "expensive", "marble", "vase", "##s", "[unused6]", "[SEP]", "[unused1]", "Only", "his", "factories", "in", "Japan", "and", "Korea", "[unused2]", "[unused3]", "employing", "[unused4]", "[unused5]", "his", "followers", "at", "sub", "##sistence", "wages", "[unused6]", "[SEP]"]]}

input 525:  {"source": "Only when one is ascending -- or in our case descending a tad trop rapidement -- does one feel , well , airborne in a picnic basket .\n"}
prediction:  {"predictions": [[1, 1141, 2, 3, 1110, 26457, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1141, 2, 3, 1631, 4, 5, 1218, 17341, 1107, 170, 14823, 12916, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1141, 2, 3, 1110, 26457, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04034431278705597, -0.2012079358100891, -0.17482316493988037, -0.14903628826141357, -0.1491020917892456, -0.1491020917892456, -0.1491020917892456, -0.1491020917892456, -0.1491020917892456, -0.1491020917892456], "metadata": {"source_tokens": ["Only", "when", "one", "is", "ascending", "-", "##-", "or", "in", "our", "case", "descending", "a", "ta", "##d", "t", "##rop", "rapid", "##ement", "-", "##-", "does", "one", "feel", ",", "well", ",", "airborne", "in", "a", "picnic", "basket", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "one", "[unused2]", "[unused3]", "is", "ascending", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "one", "[unused2]", "[unused3]", "feel", "[unused4]", "[unused5]", "well", "airborne", "in", "a", "picnic", "basket", "[unused6]", "[SEP]", "[unused1]", "one", "[unused2]", "[unused3]", "is", "ascending", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 526:  {"source": "Osamu Nagayama , deputy president of Chugai , which spends about 15 % of its sales on research and development , was unable to pinpoint how much money Chugai would pump into Gen - Probe .\n"}
prediction:  {"predictions": [[1, 152, 3202, 13601, 11896, 2571, 11418, 2, 3, 1108, 4, 5, 3372, 1106, 10473, 7587, 1293, 1277, 1948, 17144, 21347, 1156, 11188, 1154, 9198, 118, 5096, 3962, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 152, 3202, 13601, 11896, 2571, 11418, 2, 3, 16994, 4, 5, 1164, 1405, 110, 1104, 1157, 3813, 1113, 1844, 1105, 1718, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 152, 3202, 13601, 11896, 2571, 11418, 2, 3, 1110, 5874, 2084, 1104, 4, 5, 17144, 21347, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 152, 3202, 13601, 11896, 2571, 11418, 2, 3, 1106, 10473, 7587, 4, 5, 1293, 1277, 1948, 17144, 21347, 1156, 11188, 1154, 9198, 118, 5096, 3962, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.019254200160503387, -0.040074672549963, -0.028125688433647156, -0.09199255704879761, -0.15921664237976074, -0.17634844779968262, -0.17634844779968262, -0.17634844779968262, -0.17634844779968262, -0.17634844779968262], "metadata": {"source_tokens": ["O", "##sa", "##mu", "Na", "##ga", "##yama", ",", "deputy", "president", "of", "Chu", "##gai", ",", "which", "spends", "about", "15", "%", "of", "its", "sales", "on", "research", "and", "development", ",", "was", "unable", "to", "pin", "##point", "how", "much", "money", "Chu", "##gai", "would", "pump", "into", "Gen", "-", "Pro", "##be", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "O", "##sa", "##mu", "Na", "##ga", "##yama", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "unable", "to", "pin", "##point", "how", "much", "money", "Chu", "##gai", "would", "pump", "into", "Gen", "-", "Pro", "##be", "[unused6]", "[SEP]", "[unused1]", "O", "##sa", "##mu", "Na", "##ga", "##yama", "[unused2]", "[unused3]", "spends", "[unused4]", "[unused5]", "about", "15", "%", "of", "its", "sales", "on", "research", "and", "development", "[unused6]", "[SEP]", "[unused1]", "O", "##sa", "##mu", "Na", "##ga", "##yama", "[unused2]", "[unused3]", "is", "deputy", "president", "of", "[unused4]", "[unused5]", "Chu", "##gai", "[unused6]", "[SEP]", "[unused1]", "O", "##sa", "##mu", "Na", "##ga", "##yama", "[unused2]", "[unused3]", "to", "pin", "##point", "[unused4]", "[unused5]", "how", "much", "money", "Chu", "##gai", "would", "pump", "into", "Gen", "-", "Pro", "##be", "[unused6]", "[SEP]"]]}

input 527:  {"source": "Overall , net sales of all mutual funds , excluding money market funds , fell to $ 1.9 billion in September from $ 4.2 billion in August , the trade group said .\n"}
prediction:  {"predictions": [[1, 5795, 3813, 1104, 1155, 9175, 4381, 117, 14243, 1948, 2319, 4381, 2, 3, 2204, 4, 5, 1106, 109, 122, 28138, 1580, 3775, 1107, 1347, 1121, 109, 125, 28138, 1477, 3775, 1107, 1360, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5795, 3813, 1104, 1155, 9175, 4381, 14243, 1948, 2319, 4381, 2, 3, 2204, 4, 5, 1106, 109, 122, 28138, 1580, 3775, 1107, 1347, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5795, 3813, 1104, 1155, 9175, 4381, 14243, 1948, 2319, 4381, 2, 3, 2204, 4, 5, 1106, 109, 122, 28138, 1580, 3775, 1107, 1347, 8007, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04116123914718628, -0.09899821877479553, -0.1145770400762558, -0.2650876045227051, -0.2587428092956543, -0.2587428092956543, -0.2587428092956543, -0.2587428092956543, -0.2587428092956543, -0.2587428092956543], "metadata": {"source_tokens": ["Overall", ",", "net", "sales", "of", "all", "mutual", "funds", ",", "excluding", "money", "market", "funds", ",", "fell", "to", "$", "1", "##.", "##9", "billion", "in", "September", "from", "$", "4", "##.", "##2", "billion", "in", "August", ",", "the", "trade", "group", "said", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "net", "sales", "of", "all", "mutual", "funds", ",", "excluding", "money", "market", "funds", "[unused2]", "[unused3]", "fell", "[unused4]", "[unused5]", "to", "$", "1", "##.", "##9", "billion", "in", "September", "from", "$", "4", "##.", "##2", "billion", "in", "August", "[unused6]", "[SEP]", "[unused1]", "net", "sales", "of", "all", "mutual", "funds", "excluding", "money", "market", "funds", "[unused2]", "[unused3]", "fell", "[unused4]", "[unused5]", "to", "$", "1", "##.", "##9", "billion", "in", "September", "[unused6]", "[SEP]", "[unused1]", "net", "sales", "of", "all", "mutual", "funds", "excluding", "money", "market", "funds", "[unused2]", "[unused3]", "fell", "[unused4]", "[unused5]", "to", "$", "1", "##.", "##9", "billion", "in", "September", "Overall", "[unused6]", "[SEP]"]]}

input 528:  {"source": "Panhandle Eastern Corp. said it applied , on behalf of two of its subsidiaries , to the Federal Energy Regulatory Commission for permission to build a 352 - mile , $ 273 million pipeline system from Pittsburg County , Okla. , to Independence , Miss .\n"}
prediction:  {"predictions": [[1, 6991, 9332, 1513, 2882, 13619, 2, 3, 1163, 4, 5, 1122, 3666, 1113, 6261, 1104, 1160, 1104, 1157, 22423, 1106, 1103, 3467, 5514, 23287, 26658, 2827, 1111, 6156, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6991, 9332, 1513, 2882, 13619, 2, 3, 1163, 4, 5, 1122, 3666, 1113, 6261, 1104, 1160, 1104, 1157, 22423, 1106, 1103, 3467, 5514, 23287, 26658, 2827, 1111, 6156, 1106, 3076, 170, 2588, 1477, 118, 2837, 117, 109, 1765, 1495, 1550, 15826, 1449, 1121, 15877, 9364, 1391, 117, 23330, 1742, 102, 1, 1122, 2, 3, 3666, 4, 5, 1106, 1103, 3467, 5514, 23287, 26658, 2827, 1111, 6156, 1106, 3076, 170, 2588, 1477, 118, 2837, 117, 109, 1765, 1495, 1550, 15826, 1449, 1121, 15877, 9364, 1391, 117, 23330, 1742, 28138, 117, 1106, 7824, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6991, 9332, 1513, 2882, 13619, 28138, 2, 3, 1163, 4, 5, 1122, 3666, 1113, 6261, 1104, 1160, 1104, 1157, 22423, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.054069794714450836, -0.08101028203964233, -0.12448620051145554, -0.13877873122692108, -0.33634281158447266, -0.34461498260498047, -0.34461498260498047, -0.34461498260498047, -0.34461498260498047, -0.34461498260498047], "metadata": {"source_tokens": ["Pan", "##hand", "##le", "Eastern", "Corp", "##.", "said", "it", "applied", ",", "on", "behalf", "of", "two", "of", "its", "subsidiaries", ",", "to", "the", "Federal", "Energy", "Reg", "##ulatory", "Commission", "for", "permission", "to", "build", "a", "35", "##2", "-", "mile", ",", "$", "27", "##3", "million", "pipeline", "system", "from", "Pitt", "##sburg", "County", ",", "Ok", "##la", "##.", ",", "to", "Independence", ",", "Miss", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pan", "##hand", "##le", "Eastern", "Corp", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "applied", "on", "behalf", "of", "two", "of", "its", "subsidiaries", "to", "the", "Federal", "Energy", "Reg", "##ulatory", "Commission", "for", "permission", "[unused6]", "[SEP]", "[unused1]", "Pan", "##hand", "##le", "Eastern", "Corp", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "applied", "on", "behalf", "of", "two", "of", "its", "subsidiaries", "to", "the", "Federal", "Energy", "Reg", "##ulatory", "Commission", "for", "permission", "to", "build", "a", "35", "##2", "-", "mile", ",", "$", "27", "##3", "million", "pipeline", "system", "from", "Pitt", "##sburg", "County", ",", "Ok", "##la", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "applied", "[unused4]", "[unused5]", "to", "the", "Federal", "Energy", "Reg", "##ulatory", "Commission", "for", "permission", "to", "build", "a", "35", "##2", "-", "mile", ",", "$", "27", "##3", "million", "pipeline", "system", "from", "Pitt", "##sburg", "County", ",", "Ok", "##la", "##.", ",", "to", "Independence", "[unused6]", "[SEP]", "[unused1]", "Pan", "##hand", "##le", "Eastern", "Corp", "##.", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "applied", "on", "behalf", "of", "two", "of", "its", "subsidiaries", "[unused6]", "[SEP]"]]}

input 529:  {"source": "Pennzoil 's poison pill covers five years in order to give current management enough time to put these proceeds to work in a prudent manner .\n"}
prediction:  {"predictions": [[1, 9223, 6112, 2723, 112, 1116, 11539, 21822, 2, 3, 3662, 4, 5, 1421, 1201, 1107, 1546, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9223, 6112, 2723, 112, 1116, 11539, 21822, 2, 3, 3662, 4, 5, 1421, 1201, 1107, 1546, 1106, 1660, 1954, 2635, 1536, 1159, 1106, 1508, 1292, 11283, 1106, 1250, 1107, 170, 185, 25980, 3452, 4758, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9223, 6112, 2723, 112, 1116, 11539, 21822, 2, 3, 3662, 4, 5, 1421, 1201, 1106, 1660, 1954, 2635, 1536, 1159, 1106, 1508, 1292, 11283, 1106, 1250, 1107, 170, 185, 25980, 3452, 4758, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004622170701622963, -0.03848320618271828, -0.05760858580470085, -0.12360477447509766, -0.12362194061279297, -0.12362194061279297, -0.12362194061279297, -0.12362194061279297, -0.12362194061279297, -0.12362194061279297], "metadata": {"source_tokens": ["Penn", "##zo", "##il", "'", "##s", "poison", "pill", "covers", "five", "years", "in", "order", "to", "give", "current", "management", "enough", "time", "to", "put", "these", "proceeds", "to", "work", "in", "a", "p", "##rud", "##ent", "manner", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Penn", "##zo", "##il", "'", "##s", "poison", "pill", "[unused2]", "[unused3]", "covers", "[unused4]", "[unused5]", "five", "years", "in", "order", "[unused6]", "[SEP]", "[unused1]", "Penn", "##zo", "##il", "'", "##s", "poison", "pill", "[unused2]", "[unused3]", "covers", "[unused4]", "[unused5]", "five", "years", "in", "order", "to", "give", "current", "management", "enough", "time", "to", "put", "these", "proceeds", "to", "work", "in", "a", "p", "##rud", "##ent", "manner", "[unused6]", "[SEP]", "[unused1]", "Penn", "##zo", "##il", "'", "##s", "poison", "pill", "[unused2]", "[unused3]", "covers", "[unused4]", "[unused5]", "five", "years", "to", "give", "current", "management", "enough", "time", "to", "put", "these", "proceeds", "to", "work", "in", "a", "p", "##rud", "##ent", "manner", "[unused6]", "[SEP]"]]}

input 530:  {"source": "Prime Minister Lee Kuan Yew , Singapore 's leader and one of Asia 's leading statesmen for 30 years , recently announced his intention to retire next year -- though not necessarily to end his influence .\n"}
prediction:  {"predictions": [[1, 3460, 2110, 2499, 23209, 1389, 15821, 2246, 2, 3, 1717, 4, 5, 1117, 6247, 1106, 11067, 1397, 1214, 118, 28137, 1463, 1136, 9073, 1106, 1322, 1117, 2933, 3055, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3460, 2110, 2499, 23209, 1389, 15821, 2246, 2, 3, 1110, 4, 5, 4478, 1104, 3165, 112, 1116, 2020, 2231, 2354, 1111, 1476, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3460, 2110, 2499, 23209, 1389, 15821, 2246, 2, 3, 1717, 4, 5, 1117, 6247, 1106, 11067, 1397, 1214, 1463, 1136, 9073, 1106, 1322, 1117, 2933, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3460, 2110, 2499, 23209, 1389, 15821, 2246, 2, 3, 1717, 4, 5, 1117, 6247, 1106, 11067, 1397, 1214, 1463, 1136, 9073, 1106, 1322, 1117, 2933, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03892575204372406, -0.06411910057067871, -0.07134220004081726, -0.09509006887674332, -0.2883431911468506, -0.2882373332977295, -0.2882373332977295, -0.2882373332977295, -0.2882373332977295, -0.2882373332977295], "metadata": {"source_tokens": ["Prime", "Minister", "Lee", "Ku", "##an", "Ye", "##w", ",", "Singapore", "'", "##s", "leader", "and", "one", "of", "Asia", "'", "##s", "leading", "states", "##men", "for", "30", "years", ",", "recently", "announced", "his", "intention", "to", "retire", "next", "year", "-", "##-", "though", "not", "necessarily", "to", "end", "his", "influence", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Prime", "Minister", "Lee", "Ku", "##an", "Ye", "##w", "[unused2]", "[unused3]", "announced", "[unused4]", "[unused5]", "his", "intention", "to", "retire", "next", "year", "-", "##-", "though", "not", "necessarily", "to", "end", "his", "influence", "recently", "[unused6]", "[SEP]", "[unused1]", "Prime", "Minister", "Lee", "Ku", "##an", "Ye", "##w", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Singapore", "of", "Asia", "'", "##s", "leading", "states", "##men", "for", "30", "years", "[unused6]", "[SEP]", "[unused1]", "Prime", "Minister", "Lee", "Ku", "##an", "Ye", "##w", "[unused2]", "[unused3]", "announced", "[unused4]", "[unused5]", "his", "intention", "to", "retire", "next", "year", "though", "not", "necessarily", "to", "end", "his", "influence", "[unused6]", "[SEP]", "[unused1]", "Prime", "Minister", "Lee", "Ku", "##an", "Ye", "##w", "[unused2]", "[unused3]", "announced", "[unused4]", "[unused5]", "his", "intention", "to", "retire", "next", "year", "though", "not", "necessarily", "to", "end", "his", "influence", "[unused6]", "[SEP]"]]}

input 531:  {"source": "Procter & Gamble Co. recently introduced refillable versions of four products , including Tide and Mr. Clean , in Canada , but does n't plan to bring them to the U.S. .\n"}
prediction:  {"predictions": [[1, 5096, 25857, 111, 144, 16033, 3291, 28138, 2, 3, 2234, 4, 5, 1231, 18591, 1895, 3827, 1104, 1300, 2982, 117, 1259, 27604, 1105, 1828, 28138, 17508, 3055, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5096, 25857, 111, 144, 16033, 3291, 28138, 2, 3, 2234, 4, 5, 1231, 18591, 1895, 3827, 1104, 1300, 2982, 1259, 27604, 1105, 1828, 28138, 17508, 1107, 1803, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5096, 25857, 111, 144, 16033, 3291, 28138, 2, 3, 1674, 183, 28131, 1204, 2197, 1106, 2498, 4, 5, 1172, 1106, 1103, 158, 28138, 1708, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5096, 25857, 111, 144, 16033, 3291, 28138, 2, 3, 2234, 4, 5, 1231, 18591, 1895, 3827, 1104, 1300, 2982, 1259, 27604, 1105, 1828, 28138, 17508, 1107, 1803, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.040966592729091644, -0.06558281928300858, -0.046265121549367905, -0.07726861536502838, -0.21318399906158447, -0.21416103839874268, -0.21416103839874268, -0.21416103839874268, -0.21416103839874268, -0.21416103839874268], "metadata": {"source_tokens": ["Pro", "##cter", "&", "G", "##amble", "Co", "##.", "recently", "introduced", "re", "##fill", "##able", "versions", "of", "four", "products", ",", "including", "Tide", "and", "Mr", "##.", "Clean", ",", "in", "Canada", ",", "but", "does", "n", "##'", "##t", "plan", "to", "bring", "them", "to", "the", "U", "##.", "##S", "##.", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Pro", "##cter", "&", "G", "##amble", "Co", "##.", "[unused2]", "[unused3]", "introduced", "[unused4]", "[unused5]", "re", "##fill", "##able", "versions", "of", "four", "products", ",", "including", "Tide", "and", "Mr", "##.", "Clean", "recently", "[unused6]", "[SEP]", "[unused1]", "Pro", "##cter", "&", "G", "##amble", "Co", "##.", "[unused2]", "[unused3]", "introduced", "[unused4]", "[unused5]", "re", "##fill", "##able", "versions", "of", "four", "products", "including", "Tide", "and", "Mr", "##.", "Clean", "in", "Canada", "[unused6]", "[SEP]", "[unused1]", "Pro", "##cter", "&", "G", "##amble", "Co", "##.", "[unused2]", "[unused3]", "does", "n", "##'", "##t", "plan", "to", "bring", "[unused4]", "[unused5]", "them", "to", "the", "U", "##.", "##S", "##.", "[unused6]", "[SEP]", "[unused1]", "Pro", "##cter", "&", "G", "##amble", "Co", "##.", "[unused2]", "[unused3]", "introduced", "[unused4]", "[unused5]", "re", "##fill", "##able", "versions", "of", "four", "products", "including", "Tide", "and", "Mr", "##.", "Clean", "in", "Canada", "[unused6]", "[SEP]"]]}

input 532:  {"source": "RISC technology speeds up a computer by simplifying the internal software .\n"}
prediction:  {"predictions": [[1, 155, 6258, 1658, 2815, 2, 3, 10979, 1146, 170, 2775, 1118, 27466, 8223, 22881, 1158, 4, 5, 1103, 4422, 3594, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.029207685962319374, -0.03821611404418945, -0.0385441780090332, -0.0385441780090332, -0.0385441780090332, -0.0385441780090332, -0.0385441780090332, -0.0385441780090332, -0.0385441780090332, -0.0385441780090332], "metadata": {"source_tokens": ["R", "##IS", "##C", "technology", "speeds", "up", "a", "computer", "by", "si", "##mp", "##lify", "##ing", "the", "internal", "software", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "R", "##IS", "##C", "technology", "[unused2]", "[unused3]", "speeds", "up", "a", "computer", "by", "si", "##mp", "##lify", "##ing", "[unused4]", "[unused5]", "the", "internal", "software", "[unused6]", "[SEP]"]]}

input 533:  {"source": "Rather ominously , rabbit studies reveal that RU-486 can cause birth defects , Lancet , the British medical journal , reported in 1987 .\n"}
prediction:  {"predictions": [[1, 16225, 2527, 2, 3, 7063, 4, 5, 1115, 155, 2591, 28137, 19203, 1545, 1169, 2612, 3485, 20705, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11856, 1204, 2, 3, 2103, 4, 5, 1107, 2164, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11856, 1204, 2, 3, 1110, 4, 5, 1103, 1418, 2657, 4897, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 155, 2591, 28137, 19203, 1545, 2, 3, 1169, 2612, 4, 5, 3485, 20705, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02714095078408718, -0.05228210613131523, -0.050874609500169754, -0.04079899936914444, -0.022027969360351562, -0.02202749252319336, -0.02202749252319336, -0.02202749252319336, -0.02202749252319336, -0.02202749252319336], "metadata": {"source_tokens": ["Rather", "ominous", "##ly", ",", "rabbit", "studies", "reveal", "that", "R", "##U", "##-", "##48", "##6", "can", "cause", "birth", "defects", ",", "Lance", "##t", ",", "the", "British", "medical", "journal", ",", "reported", "in", "1987", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "rabbit", "studies", "[unused2]", "[unused3]", "reveal", "[unused4]", "[unused5]", "that", "R", "##U", "##-", "##48", "##6", "can", "cause", "birth", "defects", "[unused6]", "[SEP]", "[unused1]", "Lance", "##t", "[unused2]", "[unused3]", "reported", "[unused4]", "[unused5]", "in", "1987", "[unused6]", "[SEP]", "[unused1]", "Lance", "##t", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "British", "medical", "journal", "[unused6]", "[SEP]", "[unused1]", "R", "##U", "##-", "##48", "##6", "[unused2]", "[unused3]", "can", "cause", "[unused4]", "[unused5]", "birth", "defects", "[unused6]", "[SEP]"]]}

input 534:  {"source": "Repeat customers also can purchase luxury items at reduced prices .\n"}
prediction:  {"predictions": [[1, 20777, 13448, 5793, 2, 3, 1169, 4779, 4, 5, 9886, 4454, 1120, 3549, 7352, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0006447399500757456, -0.0005125999450683594, -0.0005097389221191406, -0.0005097389221191406, -0.0005097389221191406, -0.0005097389221191406, -0.0005097389221191406, -0.0005097389221191406, -0.0005097389221191406, -0.0005097389221191406], "metadata": {"source_tokens": ["Rep", "##eat", "customers", "also", "can", "purchase", "luxury", "items", "at", "reduced", "prices", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rep", "##eat", "customers", "[unused2]", "[unused3]", "can", "purchase", "[unused4]", "[unused5]", "luxury", "items", "at", "reduced", "prices", "[unused6]", "[SEP]"]]}

input 535:  {"source": "Richard Newsom , a California state official who last year examined Lincoln 's parent , American Continental Corp. , said he also saw evidence that crimes had been committed .\n"}
prediction:  {"predictions": [[1, 2055, 3128, 4165, 2, 3, 1163, 4, 5, 1119, 1145, 1486, 2554, 1115, 6969, 1125, 1151, 4762, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1756, 1352, 2078, 2, 3, 8600, 4, 5, 4617, 112, 1116, 6486, 1314, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6969, 2, 3, 1125, 1151, 4762, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4617, 112, 1116, 6486, 2, 3, 1110, 4, 5, 1237, 9211, 13619, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02857213094830513, -0.02620820887386799, -0.06170773506164551, -0.09404325485229492, -0.10616350173950195, -0.09684467315673828, -0.09684467315673828, -0.09684467315673828, -0.09684467315673828, -0.09684467315673828], "metadata": {"source_tokens": ["Richard", "News", "##om", ",", "a", "California", "state", "official", "who", "last", "year", "examined", "Lincoln", "'", "##s", "parent", ",", "American", "Continental", "Corp", "##.", ",", "said", "he", "also", "saw", "evidence", "that", "crimes", "had", "been", "committed", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Richard", "News", "##om", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "he", "also", "saw", "evidence", "that", "crimes", "had", "been", "committed", "[unused6]", "[SEP]", "[unused1]", "a", "California", "state", "official", "[unused2]", "[unused3]", "examined", "[unused4]", "[unused5]", "Lincoln", "'", "##s", "parent", "last", "year", "[unused6]", "[SEP]", "[unused1]", "crimes", "[unused2]", "[unused3]", "had", "been", "committed", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Lincoln", "'", "##s", "parent", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "American", "Continental", "Corp", "[unused6]", "[SEP]"]]}

input 536:  {"source": "Roger M. Marino , president , was named to the new post of vice chairman .\n"}
prediction:  {"predictions": [[1, 4271, 150, 28138, 18940, 2, 3, 1108, 1417, 4, 5, 1106, 1103, 1207, 2112, 1104, 4711, 3931, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4271, 150, 28138, 18940, 2, 3, 1110, 4, 5, 2084, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0006560325855389237, -0.011107087135314941, -0.0002789497375488281, -0.0002961158752441406, -0.0002961158752441406, -0.0002961158752441406, -0.0002961158752441406, -0.0002961158752441406, -0.0002961158752441406, -0.0002961158752441406], "metadata": {"source_tokens": ["Roger", "M", "##.", "Marino", ",", "president", ",", "was", "named", "to", "the", "new", "post", "of", "vice", "chairman", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Roger", "M", "##.", "Marino", "[unused2]", "[unused3]", "was", "named", "[unused4]", "[unused5]", "to", "the", "new", "post", "of", "vice", "chairman", "[unused6]", "[SEP]", "[unused1]", "Roger", "M", "##.", "Marino", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "president", "[unused6]", "[SEP]"]]}

input 537:  {"source": "Rolls - Royce Motor Cars Inc. said it expects its U.S. sales to remain steady at about 1,200 cars in 1990 .\n"}
prediction:  {"predictions": [[1, 18856, 118, 15466, 8226, 16644, 3561, 2, 3, 1163, 4, 5, 1122, 27402, 1157, 158, 28138, 1708, 28138, 3813, 1106, 3118, 6386, 1120, 1164, 122, 28136, 10973, 1568, 3079, 1107, 1997, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 27402, 4, 5, 1157, 158, 28138, 1708, 28138, 3813, 1106, 3118, 6386, 1120, 1164, 122, 28136, 10973, 1568, 3079, 1107, 1997, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0024944718461483717, -0.017825068905949593, -0.20585370063781738, -0.2108057737350464, -0.2108057737350464, -0.2108057737350464, -0.2108057737350464, -0.2108057737350464, -0.2108057737350464, -0.2108057737350464], "metadata": {"source_tokens": ["Rolls", "-", "Royce", "Motor", "Cars", "Inc", "##.", "said", "it", "expects", "its", "U", "##.", "##S", "##.", "sales", "to", "remain", "steady", "at", "about", "1", "##,", "##20", "##0", "cars", "in", "1990", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rolls", "-", "Royce", "Motor", "Cars", "Inc", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "it", "expects", "its", "U", "##.", "##S", "##.", "sales", "to", "remain", "steady", "at", "about", "1", "##,", "##20", "##0", "cars", "in", "1990", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "expects", "[unused4]", "[unused5]", "its", "U", "##.", "##S", "##.", "sales", "to", "remain", "steady", "at", "about", "1", "##,", "##20", "##0", "cars", "in", "1990", "[unused6]", "[SEP]"]]}

input 538:  {"source": "Ryukichi Imai , Japan 's ambassador to Mexico , agrees that Mexico may be too eager .\n"}
prediction:  {"predictions": [[1, 155, 19404, 4313, 146, 1918, 1182, 2, 3, 10052, 4, 5, 1115, 2470, 1336, 1129, 1315, 9582, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 155, 19404, 4313, 146, 1918, 1182, 2, 3, 1110, 1999, 112, 1116, 9088, 1106, 4, 5, 2470, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0013000487815588713, -0.017896514385938644, -0.038166046142578125, -0.03766584396362305, -0.03766584396362305, -0.03766584396362305, -0.03766584396362305, -0.03766584396362305, -0.03766584396362305, -0.03766584396362305], "metadata": {"source_tokens": ["R", "##yuki", "##chi", "I", "##ma", "##i", ",", "Japan", "'", "##s", "ambassador", "to", "Mexico", ",", "agrees", "that", "Mexico", "may", "be", "too", "eager", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "R", "##yuki", "##chi", "I", "##ma", "##i", "[unused2]", "[unused3]", "agrees", "[unused4]", "[unused5]", "that", "Mexico", "may", "be", "too", "eager", "[unused6]", "[SEP]", "[unused1]", "R", "##yuki", "##chi", "I", "##ma", "##i", "[unused2]", "[unused3]", "is", "Japan", "'", "##s", "ambassador", "to", "[unused4]", "[unused5]", "Mexico", "[unused6]", "[SEP]"]]}

input 539:  {"source": "Second , the dollar is showing persistent strength despite a slowdown in the U.S. economy shown by economic indicators .\n"}
prediction:  {"predictions": [[1, 1103, 158, 28138, 1708, 28138, 4190, 2, 3, 2602, 4, 5, 1118, 2670, 24091, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 8876, 2, 3, 1110, 4000, 4, 5, 15970, 3220, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 8876, 2, 3, 1110, 4000, 4, 5, 15970, 3220, 2693, 170, 3345, 5455, 1107, 1103, 158, 28138, 1708, 28138, 4190, 2602, 1118, 2670, 24091, 2307, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0011829361319541931, -0.041445374488830566, -0.06469251960515976, -0.0385432243347168, -0.03854942321777344, -0.03854942321777344, -0.03854942321777344, -0.03854942321777344, -0.03854942321777344, -0.03854942321777344], "metadata": {"source_tokens": ["Second", ",", "the", "dollar", "is", "showing", "persistent", "strength", "despite", "a", "slow", "##down", "in", "the", "U", "##.", "##S", "##.", "economy", "shown", "by", "economic", "indicators", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "U", "##.", "##S", "##.", "economy", "[unused2]", "[unused3]", "shown", "[unused4]", "[unused5]", "by", "economic", "indicators", "[unused6]", "[SEP]", "[unused1]", "the", "dollar", "[unused2]", "[unused3]", "is", "showing", "[unused4]", "[unused5]", "persistent", "strength", "[unused6]", "[SEP]", "[unused1]", "the", "dollar", "[unused2]", "[unused3]", "is", "showing", "[unused4]", "[unused5]", "persistent", "strength", "despite", "a", "slow", "##down", "in", "the", "U", "##.", "##S", "##.", "economy", "shown", "by", "economic", "indicators", "Second", "[unused6]", "[SEP]"]]}

input 540:  {"source": "Sen. Mitchell is confident he has sufficient votes to block such a measure with procedural actions .\n"}
prediction:  {"predictions": [[1, 14895, 28138, 5741, 2, 3, 1110, 4, 5, 9588, 1119, 1144, 6664, 3667, 1106, 3510, 1216, 170, 4929, 1114, 5250, 27433, 3721, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1144, 4, 5, 6664, 3667, 1106, 3510, 1216, 170, 4929, 1114, 5250, 27433, 3721, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023180833086371422, -0.03159230947494507, -0.015883922576904297, -0.019302845001220703, -0.019302845001220703, -0.019302845001220703, -0.019302845001220703, -0.019302845001220703, -0.019302845001220703, -0.019302845001220703], "metadata": {"source_tokens": ["Sen", "##.", "Mitchell", "is", "confident", "he", "has", "sufficient", "votes", "to", "block", "such", "a", "measure", "with", "pro", "##cedural", "actions", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sen", "##.", "Mitchell", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "confident", "he", "has", "sufficient", "votes", "to", "block", "such", "a", "measure", "with", "pro", "##cedural", "actions", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "sufficient", "votes", "to", "block", "such", "a", "measure", "with", "pro", "##cedural", "actions", "[unused6]", "[SEP]"]]}

input 541:  {"source": "Senate Appropriations Committee Chairman Robert Byrd ( D. , W.Va . ) strongly resisted deeper cuts sought by the House .\n"}
prediction:  {"predictions": [[1, 3279, 138, 8661, 24594, 2341, 4284, 1823, 19195, 2, 3, 5473, 13672, 4, 5, 6353, 7484, 4110, 1118, 1103, 1585, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1823, 19195, 2, 3, 1110, 4284, 1104, 4, 5, 3279, 138, 8661, 24594, 2341, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00622691260650754, -0.13389116525650024, -0.05459165573120117, -0.03873109817504883, -0.03873109817504883, -0.03873109817504883, -0.03873109817504883, -0.03873109817504883, -0.03873109817504883, -0.03873109817504883], "metadata": {"source_tokens": ["Senate", "A", "##pp", "##ropriations", "Committee", "Chairman", "Robert", "Byrd", "(", "D", "##.", ",", "W", "##.", "##V", "##a", ".", ")", "strongly", "resisted", "deeper", "cuts", "sought", "by", "the", "House", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Senate", "A", "##pp", "##ropriations", "Committee", "Chairman", "Robert", "Byrd", "[unused2]", "[unused3]", "strongly", "resisted", "[unused4]", "[unused5]", "deeper", "cuts", "sought", "by", "the", "House", "[unused6]", "[SEP]", "[unused1]", "Robert", "Byrd", "[unused2]", "[unused3]", "is", "Chairman", "of", "[unused4]", "[unused5]", "Senate", "A", "##pp", "##ropriations", "Committee", "[unused6]", "[SEP]"]]}

input 542:  {"source": "Separately , Ford and Mazda Motor Corp. 's U.S. sales arm said they are recalling about 88,500 1988 - model Mercury Tracers and 220,000 1986 , 1987 and 1988 model Mazda 323s equipped with 1.6 - liter fuel - injected engines to replace the oil filler cap .\n"}
prediction:  {"predictions": [[1, 4100, 1105, 7085, 26604, 8226, 13619, 28138, 112, 1116, 158, 28138, 1708, 28138, 3813, 1981, 2, 3, 1163, 4, 5, 1152, 1132, 25839, 1164, 5385, 28136, 22682, 2115, 118, 2235, 10080, 22681, 1733, 1105, 10423, 28136, 7629, 1568, 2177, 117, 2164, 1105, 2115, 2235, 7085, 26604, 2724, 1495, 1116, 102, 1, 1152, 2, 3, 1132, 25839, 4, 5, 1164, 5385, 28136, 22682, 2115, 2235, 10080, 22681, 1733, 1105, 10423, 28136, 7629, 1568, 2177, 2164, 1105, 2115, 2235, 7085, 26604, 2724, 1495, 1116, 5440, 1114, 122, 28138, 1545, 118, 27146, 4251, 118, 21881, 4540, 1106, 4971, 1103, 2949, 5475, 1200, 6707, 102, 1, 4100, 1105, 7085, 26604, 8226, 13619, 28138, 112, 1116, 158, 28138, 1708, 28138, 3813, 1981, 2, 3, 1163, 4, 5, 1152, 1132, 25839, 1164, 5385, 28136, 22682, 2115, 2235, 10080, 22681, 1733, 1105, 10423, 28136, 7629, 1568, 2177, 2164, 1105, 2115, 2235, 7085, 26604, 2724, 1495, 1116, 5440, 1114, 102, 1, 4100, 1105, 7085, 26604, 8226, 13619, 28138, 112, 1116, 158, 28138, 1708, 28138, 3813, 1981, 2, 3, 1163, 4, 5, 1152, 1132, 25839, 1164, 5385, 28136, 22682, 2115, 2235, 10080, 22681, 1733, 1105, 10423, 28136, 7629, 1568, 2177, 2164, 1105, 2115, 2235, 7085, 26604, 2724, 1495, 1116, 5440, 1114, 102, 1, 1152, 2, 3, 1132, 25839, 4, 5, 1164, 5385, 28136, 22682, 2115, 2235, 10080, 22681, 1733, 1105, 10423, 28136, 7629, 1568, 2177, 2164, 1105, 2115, 2235, 7085, 26604, 2724, 1495, 1116, 5440, 1114, 122, 28138, 1545, 27146, 4251, 21881, 4540, 1106, 4971, 1103, 2949, 5475, 1200, 6707, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023012977093458176, -0.09105949103832245, -0.05702728405594826, -0.06484005600214005, -0.08132580667734146, -0.29680299758911133, -0.2580881118774414, -0.2580881118774414, -0.2580881118774414, -0.2580881118774414], "metadata": {"source_tokens": ["Sep", "##arate", "##ly", ",", "Ford", "and", "Ma", "##zda", "Motor", "Corp", "##.", "'", "##s", "U", "##.", "##S", "##.", "sales", "arm", "said", "they", "are", "recalling", "about", "88", "##,", "##500", "1988", "-", "model", "Mercury", "Trace", "##rs", "and", "220", "##,", "##00", "##0", "1986", ",", "1987", "and", "1988", "model", "Ma", "##zda", "32", "##3", "##s", "equipped", "with", "1", "##.", "##6", "-", "liter", "fuel", "-", "injected", "engines", "to", "replace", "the", "oil", "fill", "##er", "cap", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Ford", "and", "Ma", "##zda", "Motor", "Corp", "##.", "'", "##s", "U", "##.", "##S", "##.", "sales", "arm", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "they", "are", "recalling", "about", "88", "##,", "##500", "1988", "-", "model", "Mercury", "Trace", "##rs", "and", "220", "##,", "##00", "##0", "1986", ",", "1987", "and", "1988", "model", "Ma", "##zda", "32", "##3", "##s", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "are", "recalling", "[unused4]", "[unused5]", "about", "88", "##,", "##500", "1988", "model", "Mercury", "Trace", "##rs", "and", "220", "##,", "##00", "##0", "1986", "1987", "and", "1988", "model", "Ma", "##zda", "32", "##3", "##s", "equipped", "with", "1", "##.", "##6", "-", "liter", "fuel", "-", "injected", "engines", "to", "replace", "the", "oil", "fill", "##er", "cap", "[SEP]", "[unused1]", "Ford", "and", "Ma", "##zda", "Motor", "Corp", "##.", "'", "##s", "U", "##.", "##S", "##.", "sales", "arm", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "they", "are", "recalling", "about", "88", "##,", "##500", "1988", "model", "Mercury", "Trace", "##rs", "and", "220", "##,", "##00", "##0", "1986", "1987", "and", "1988", "model", "Ma", "##zda", "32", "##3", "##s", "equipped", "with", "[SEP]", "[unused1]", "Ford", "and", "Ma", "##zda", "Motor", "Corp", "##.", "'", "##s", "U", "##.", "##S", "##.", "sales", "arm", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "they", "are", "recalling", "about", "88", "##,", "##500", "1988", "model", "Mercury", "Trace", "##rs", "and", "220", "##,", "##00", "##0", "1986", "1987", "and", "1988", "model", "Ma", "##zda", "32", "##3", "##s", "equipped", "with", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "are", "recalling", "[unused4]", "[unused5]", "about", "88", "##,", "##500", "1988", "model", "Mercury", "Trace", "##rs", "and", "220", "##,", "##00", "##0", "1986", "1987", "and", "1988", "model", "Ma", "##zda", "32", "##3", "##s", "equipped", "with", "1", "##.", "##6", "liter", "fuel", "injected", "engines", "to", "replace", "the", "oil", "fill", "##er", "cap", "[unused6]", "[SEP]"]]}

input 543:  {"source": "Shaw Industries , which agreed to acquire Armstrong World Industries ' carpet operations for an undisclosed price , rose 2 1\\/4 to 26 1\\/8 .\n"}
prediction:  {"predictions": [[1, 7802, 10699, 2, 3, 2675, 4, 5, 1106, 9703, 8800, 1291, 10699, 112, 10797, 2500, 1111, 1126, 20031, 3945, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 7802, 10699, 2, 3, 3152, 4, 5, 123, 122, 28148, 28139, 1527, 1106, 1744, 122, 28148, 28139, 1604, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04389737918972969, -0.03042595461010933, -0.13251399993896484, -0.1289839744567871, -0.1289839744567871, -0.1289839744567871, -0.1289839744567871, -0.1289839744567871, -0.1289839744567871, -0.1289839744567871], "metadata": {"source_tokens": ["Shaw", "Industries", ",", "which", "agreed", "to", "acquire", "Armstrong", "World", "Industries", "'", "carpet", "operations", "for", "an", "undisclosed", "price", ",", "rose", "2", "1", "##\\", "##/", "##4", "to", "26", "1", "##\\", "##/", "##8", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Shaw", "Industries", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "acquire", "Armstrong", "World", "Industries", "'", "carpet", "operations", "for", "an", "undisclosed", "price", "[unused6]", "[SEP]", "[unused1]", "Shaw", "Industries", "[unused2]", "[unused3]", "rose", "[unused4]", "[unused5]", "2", "1", "##\\", "##/", "##4", "to", "26", "1", "##\\", "##/", "##8", "[unused6]", "[SEP]"]]}

input 544:  {"source": "Sidley will maintain its association with the Hashidate Law Office in Tokyo .\n"}
prediction:  {"predictions": [[1, 17916, 1926, 2, 3, 1209, 4731, 4, 5, 1157, 3852, 1114, 1103, 10736, 3031, 9216, 2601, 3060, 1107, 4839, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0005212696851231158, -0.0011181831359863281, -0.0012288093566894531, -0.0012288093566894531, -0.0012288093566894531, -0.0012288093566894531, -0.0012288093566894531, -0.0012288093566894531, -0.0012288093566894531, -0.0012288093566894531], "metadata": {"source_tokens": ["Sid", "##ley", "will", "maintain", "its", "association", "with", "the", "Has", "##hi", "##date", "Law", "Office", "in", "Tokyo", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Sid", "##ley", "[unused2]", "[unused3]", "will", "maintain", "[unused4]", "[unused5]", "its", "association", "with", "the", "Has", "##hi", "##date", "Law", "Office", "in", "Tokyo", "[unused6]", "[SEP]"]]}

input 545:  {"source": "Similar studies are expected to reveal how stroke patients ' brains regroup -- a first step toward finding ways to bolster that process and speed rehabilitation .\n"}
prediction:  {"predictions": [[1, 12250, 2527, 2, 3, 1132, 2637, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12250, 2527, 2, 3, 1106, 7063, 4, 5, 1293, 6625, 4420, 112, 16570, 1231, 16016, 118, 28137, 170, 1148, 2585, 1755, 4006, 3242, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6625, 4420, 16570, 1231, 16016, 2, 3, 1110, 4, 5, 170, 1148, 2585, 1755, 4006, 3242, 1106, 171, 23681, 2083, 1115, 1965, 1105, 2420, 14178, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02385893650352955, -0.05622464045882225, -0.12274771183729172, -0.07626461982727051, -0.07631683349609375, -0.07631683349609375, -0.07631683349609375, -0.07631683349609375, -0.07631683349609375, -0.07631683349609375], "metadata": {"source_tokens": ["Similar", "studies", "are", "expected", "to", "reveal", "how", "stroke", "patients", "'", "brains", "re", "##group", "-", "##-", "a", "first", "step", "toward", "finding", "ways", "to", "b", "##ols", "##ter", "that", "process", "and", "speed", "rehabilitation", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Similar", "studies", "[unused2]", "[unused3]", "are", "expected", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Similar", "studies", "[unused2]", "[unused3]", "to", "reveal", "[unused4]", "[unused5]", "how", "stroke", "patients", "'", "brains", "re", "##group", "-", "##-", "a", "first", "step", "toward", "finding", "ways", "[unused6]", "[SEP]", "[unused1]", "stroke", "patients", "brains", "re", "##group", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "first", "step", "toward", "finding", "ways", "to", "b", "##ols", "##ter", "that", "process", "and", "speed", "rehabilitation", "[unused6]", "[SEP]"]]}

input 546:  {"source": "Since the real estate unit also includes debt , the imputed value of the real estate itself is close to $ 3 billion .\n"}
prediction:  {"predictions": [[1, 1103, 24034, 18527, 2860, 1104, 1103, 1842, 3327, 2, 3, 1110, 4, 5, 1601, 1106, 109, 124, 3775, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1842, 3327, 2587, 2, 3, 2075, 4, 5, 6695, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02659986913204193, -0.026191679760813713, -0.035923004150390625, -0.03404402732849121, -0.03404402732849121, -0.03404402732849121, -0.03404402732849121, -0.03404402732849121, -0.03404402732849121, -0.03404402732849121], "metadata": {"source_tokens": ["Since", "the", "real", "estate", "unit", "also", "includes", "debt", ",", "the", "imp", "##uted", "value", "of", "the", "real", "estate", "itself", "is", "close", "to", "$", "3", "billion", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "imp", "##uted", "value", "of", "the", "real", "estate", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "close", "to", "$", "3", "billion", "[unused6]", "[SEP]", "[unused1]", "the", "real", "estate", "unit", "[unused2]", "[unused3]", "includes", "[unused4]", "[unused5]", "debt", "[unused6]", "[SEP]"]]}

input 547:  {"source": "Six years ago , Judge O'Kicki was voted president of the Pennsylvania Conference of State Trial Judges by the state 's 400 judges .\n"}
prediction:  {"predictions": [[1, 5274, 152, 28131, 2428, 5345, 1182, 2, 3, 1108, 4751, 4, 5, 2084, 1104, 1103, 2680, 3047, 1104, 1426, 12819, 21312, 1118, 1103, 1352, 112, 1116, 3434, 7030, 4995, 1201, 2403, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5274, 152, 28131, 2428, 5345, 1182, 2, 3, 1108, 4751, 4, 5, 2084, 1104, 1103, 2680, 3047, 1104, 1426, 12819, 21312, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004649670794606209, -0.050203919410705566, -0.0772085189819336, -0.07725787162780762, -0.07725787162780762, -0.07725787162780762, -0.07725787162780762, -0.07725787162780762, -0.07725787162780762, -0.07725787162780762], "metadata": {"source_tokens": ["Six", "years", "ago", ",", "Judge", "O", "##'", "##K", "##ick", "##i", "was", "voted", "president", "of", "the", "Pennsylvania", "Conference", "of", "State", "Trial", "Judges", "by", "the", "state", "'", "##s", "400", "judges", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Judge", "O", "##'", "##K", "##ick", "##i", "[unused2]", "[unused3]", "was", "voted", "[unused4]", "[unused5]", "president", "of", "the", "Pennsylvania", "Conference", "of", "State", "Trial", "Judges", "by", "the", "state", "'", "##s", "400", "judges", "Six", "years", "ago", "[unused6]", "[SEP]", "[unused1]", "Judge", "O", "##'", "##K", "##ick", "##i", "[unused2]", "[unused3]", "was", "voted", "[unused4]", "[unused5]", "president", "of", "the", "Pennsylvania", "Conference", "of", "State", "Trial", "Judges", "[unused6]", "[SEP]"]]}

input 548:  {"source": "Sometimes , if you have a headache , you can go out and walk it right off . ''\n"}
prediction:  {"predictions": [[1, 1128, 2, 3, 1138, 4, 5, 170, 16320, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1128, 2, 3, 1169, 1301, 4, 5, 1149, 1105, 2647, 1122, 1268, 1228, 5875, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0037205854896456003, -0.07759746164083481, -0.1208486557006836, -0.1343553066253662, -0.1343553066253662, -0.1343553066253662, -0.1343553066253662, -0.1343553066253662, -0.1343553066253662, -0.1343553066253662], "metadata": {"source_tokens": ["Sometimes", ",", "if", "you", "have", "a", "headache", ",", "you", "can", "go", "out", "and", "walk", "it", "right", "off", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "you", "[unused2]", "[unused3]", "have", "[unused4]", "[unused5]", "a", "headache", "[unused6]", "[SEP]", "[unused1]", "you", "[unused2]", "[unused3]", "can", "go", "[unused4]", "[unused5]", "out", "and", "walk", "it", "right", "off", "Sometimes", "[unused6]", "[SEP]"]]}

input 549:  {"source": "Soviets remain in charge of education programs , a former head of an African military tribunal for executions is in charge of culture , and a hard - line Polish communist in exile directs the human - rights and peace division .\n"}
prediction:  {"predictions": [[1, 170, 1662, 118, 1413, 3129, 8356, 1107, 8879, 2, 3, 26818, 4, 5, 1103, 1769, 118, 2266, 1105, 3519, 2417, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1393, 1246, 1104, 1126, 2170, 1764, 23893, 1111, 26107, 2, 3, 1110, 4, 5, 1107, 2965, 1104, 2754, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 16359, 2, 3, 3118, 4, 5, 1107, 2965, 1104, 1972, 2648, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012161129154264927, -0.030848674476146698, -0.015701131895184517, -0.03862428665161133, -0.03862476348876953, -0.03862476348876953, -0.03862476348876953, -0.03862476348876953, -0.03862476348876953, -0.03862476348876953], "metadata": {"source_tokens": ["Soviets", "remain", "in", "charge", "of", "education", "programs", ",", "a", "former", "head", "of", "an", "African", "military", "tribunal", "for", "executions", "is", "in", "charge", "of", "culture", ",", "and", "a", "hard", "-", "line", "Polish", "communist", "in", "exile", "directs", "the", "human", "-", "rights", "and", "peace", "division", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "hard", "-", "line", "Polish", "communist", "in", "exile", "[unused2]", "[unused3]", "directs", "[unused4]", "[unused5]", "the", "human", "-", "rights", "and", "peace", "division", "[unused6]", "[SEP]", "[unused1]", "a", "former", "head", "of", "an", "African", "military", "tribunal", "for", "executions", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "in", "charge", "of", "culture", "[unused6]", "[SEP]", "[unused1]", "Soviets", "[unused2]", "[unused3]", "remain", "[unused4]", "[unused5]", "in", "charge", "of", "education", "programs", "[unused6]", "[SEP]"]]}

input 550:  {"source": "Standard & Poor 's 500 - Stock Index climbed 5.29 to 340.36 , the Dow Jones Equity Market Index added 4.70 to 318.79 and the New York Stock Exchange Composite Index climbed 2.65 to\n"}
prediction:  {"predictions": [[1, 1103, 26535, 2690, 25083, 6923, 10146, 2, 3, 1896, 4, 5, 125, 28138, 20829, 1106, 1955, 1604, 28138, 1559, 1580, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1203, 1365, 9924, 7855, 3291, 24729, 13068, 10146, 2, 3, 5998, 4, 5, 123, 28138, 27677, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 26535, 2690, 25083, 6923, 10146, 2, 3, 1896, 4, 5, 125, 28138, 20829, 1106, 1955, 1604, 28138, 1559, 1580, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1203, 1365, 9924, 7855, 3291, 24729, 13068, 10146, 2, 3, 5998, 4, 5, 123, 28138, 27677, 1106, 1103, 1203, 1365, 9924, 7855, 3291, 24729, 13068, 10146, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1203, 1365, 9924, 7855, 3291, 24729, 13068, 10146, 2, 3, 5998, 4, 5, 123, 28138, 27677, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03482672572135925, -0.06473682820796967, -0.11164546757936478, -0.12796445190906525, -0.13171172142028809, -0.23481440544128418, -0.23083281517028809, -0.23083281517028809, -0.23083281517028809, -0.23083281517028809], "metadata": {"source_tokens": ["Standard", "&", "Poor", "'", "##s", "500", "-", "Stock", "Index", "climbed", "5", "##.", "##29", "to", "340", "##.", "##36", ",", "the", "Dow", "Jones", "Equity", "Market", "Index", "added", "4", "##.", "##70", "to", "31", "##8", "##.", "##7", "##9", "and", "the", "New", "York", "Stock", "Exchange", "Co", "##mpo", "##site", "Index", "climbed", "2", "##.", "##65", "to"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Dow", "Jones", "Equity", "Market", "Index", "[unused2]", "[unused3]", "added", "[unused4]", "[unused5]", "4", "##.", "##70", "to", "31", "##8", "##.", "##7", "##9", "[unused6]", "[SEP]", "[unused1]", "the", "New", "York", "Stock", "Exchange", "Co", "##mpo", "##site", "Index", "[unused2]", "[unused3]", "climbed", "[unused4]", "[unused5]", "2", "##.", "##65", "[unused6]", "[SEP]", "[unused1]", "the", "Dow", "Jones", "Equity", "Market", "Index", "[unused2]", "[unused3]", "added", "[unused4]", "[unused5]", "4", "##.", "##70", "to", "31", "##8", "##.", "##7", "##9", "[unused6]", "[SEP]", "[unused1]", "the", "New", "York", "Stock", "Exchange", "Co", "##mpo", "##site", "Index", "[unused2]", "[unused3]", "climbed", "[unused4]", "[unused5]", "2", "##.", "##65", "to", "the", "New", "York", "Stock", "Exchange", "Co", "##mpo", "##site", "Index", "[unused6]", "[SEP]", "[unused1]", "the", "New", "York", "Stock", "Exchange", "Co", "##mpo", "##site", "Index", "[unused2]", "[unused3]", "climbed", "[unused4]", "[unused5]", "2", "##.", "##65", "[unused6]", "[SEP]"]]}

input 551:  {"source": "Strong sales so far this year are certain to turn the tide , but even the 25 % market share that Nissan expects in 1989 will leave it far below its position at the beginning of the decade .\n"}
prediction:  {"predictions": [[1, 11661, 3813, 1177, 1677, 1142, 1214, 2, 3, 1132, 4, 5, 2218, 1106, 1885, 1103, 12600, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1256, 1103, 1512, 110, 2319, 2934, 1115, 17574, 27402, 1107, 2056, 2, 3, 1209, 1817, 4, 5, 1122, 1677, 2071, 1157, 1700, 1120, 1103, 2150, 1104, 1103, 4967, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 17574, 2, 3, 27402, 4, 5, 1107, 2056, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0531766340136528, -0.028690453618764877, -0.06548993289470673, -0.1473853588104248, -0.1492903232574463, -0.1492903232574463, -0.1492903232574463, -0.1492903232574463, -0.1492903232574463, -0.1492903232574463], "metadata": {"source_tokens": ["Strong", "sales", "so", "far", "this", "year", "are", "certain", "to", "turn", "the", "tide", ",", "but", "even", "the", "25", "%", "market", "share", "that", "Nissan", "expects", "in", "1989", "will", "leave", "it", "far", "below", "its", "position", "at", "the", "beginning", "of", "the", "decade", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Strong", "sales", "so", "far", "this", "year", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "certain", "to", "turn", "the", "tide", "[unused6]", "[SEP]", "[unused1]", "even", "the", "25", "%", "market", "share", "that", "Nissan", "expects", "in", "1989", "[unused2]", "[unused3]", "will", "leave", "[unused4]", "[unused5]", "it", "far", "below", "its", "position", "at", "the", "beginning", "of", "the", "decade", "[unused6]", "[SEP]", "[unused1]", "Nissan", "[unused2]", "[unused3]", "expects", "[unused4]", "[unused5]", "in", "1989", "[unused6]", "[SEP]"]]}

input 552:  {"source": "Student job postings at Boston University slip 10 % this year following a 10 % drop in 1988 .\n"}
prediction:  {"predictions": [[1, 7646, 2261, 15537, 1116, 1120, 2859, 1239, 2, 3, 7324, 4, 5, 1275, 110, 1142, 1214, 1378, 170, 1275, 110, 3968, 1107, 2115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023260263726115227, -0.0761251449584961, -0.07613587379455566, -0.07613587379455566, -0.07613587379455566, -0.07613587379455566, -0.07613587379455566, -0.07613587379455566, -0.07613587379455566, -0.07613587379455566], "metadata": {"source_tokens": ["Student", "job", "posting", "##s", "at", "Boston", "University", "slip", "10", "%", "this", "year", "following", "a", "10", "%", "drop", "in", "1988", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Student", "job", "posting", "##s", "at", "Boston", "University", "[unused2]", "[unused3]", "slip", "[unused4]", "[unused5]", "10", "%", "this", "year", "following", "a", "10", "%", "drop", "in", "1988", "[unused6]", "[SEP]"]]}

input 553:  {"source": "THE CHIEF NURSING officer can be responsible for more than 1,000 employees and at least one - third of a hospital 's budget ; a head nurse typically oversees up to 80 employees and $ 8 million .\n"}
prediction:  {"predictions": [[1, 7462, 24890, 17444, 2271, 151, 19556, 13882, 11780, 2575, 2, 3, 1169, 1129, 4, 5, 2784, 1111, 1167, 1190, 122, 28136, 7629, 1568, 4570, 1105, 1120, 1655, 1141, 118, 1503, 1104, 170, 2704, 112, 1116, 4788, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1246, 7439, 2, 3, 3417, 25312, 4, 5, 1146, 1106, 2908, 4570, 1105, 109, 129, 1550, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017100505530834198, -0.03928454965353012, -0.03221607208251953, -0.03222203254699707, -0.03222203254699707, -0.03222203254699707, -0.03222203254699707, -0.03222203254699707, -0.03222203254699707, -0.03222203254699707], "metadata": {"source_tokens": ["THE", "CH", "##IE", "##F", "N", "##UR", "##SI", "##NG", "officer", "can", "be", "responsible", "for", "more", "than", "1", "##,", "##00", "##0", "employees", "and", "at", "least", "one", "-", "third", "of", "a", "hospital", "'", "##s", "budget", ";", "a", "head", "nurse", "typically", "oversees", "up", "to", "80", "employees", "and", "$", "8", "million", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "THE", "CH", "##IE", "##F", "N", "##UR", "##SI", "##NG", "officer", "[unused2]", "[unused3]", "can", "be", "[unused4]", "[unused5]", "responsible", "for", "more", "than", "1", "##,", "##00", "##0", "employees", "and", "at", "least", "one", "-", "third", "of", "a", "hospital", "'", "##s", "budget", "[unused6]", "[SEP]", "[unused1]", "a", "head", "nurse", "[unused2]", "[unused3]", "typically", "oversees", "[unused4]", "[unused5]", "up", "to", "80", "employees", "and", "$", "8", "million", "[unused6]", "[SEP]"]]}

input 554:  {"source": "Takeover stock traders noted that with the junk - bond market in disarray , Georgia - Pacific 's bid is an indication of where the takeover game is headed : namely , industrial companies can continue bidding for one another , but financial buyers such as leveraged buy - out firms will be at a disadvantage in obtaining financing .\n"}
prediction:  {"predictions": [[1, 5055, 5909, 4482, 14552, 2, 3, 2382, 4, 5, 1115, 1114, 1103, 22323, 118, 7069, 2319, 1107, 4267, 9724, 6447, 117, 3260, 118, 2662, 112, 1116, 6875, 1110, 1126, 12754, 1104, 1187, 1103, 17748, 1342, 1110, 2917, 131, 8199, 117, 3924, 2557, 1169, 2760, 19520, 1111, 1141, 1330, 117, 102, 1, 2798, 19682, 1216, 1112, 24228, 1181, 4417, 118, 1149, 9780, 2, 3, 1209, 1129, 4, 5, 1120, 170, 22611, 1107, 11621, 13080, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 17748, 1342, 2, 3, 1110, 2917, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3924, 2557, 2, 3, 1169, 2760, 4, 5, 19520, 1111, 1141, 1330, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3260, 2662, 112, 1116, 6875, 2, 3, 1110, 4, 5, 1126, 12754, 1104, 1187, 1103, 17748, 1342, 1110, 2917, 131, 8199, 117, 3924, 2557, 1169, 2760, 19520, 1111, 1141, 1330, 1114, 1103, 22323, 118, 7069, 2319, 1107, 4267, 9724, 6447, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3924, 2557, 2, 3, 1169, 2760, 4, 5, 19520, 1111, 1141, 1330, 8199, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02140987478196621, -0.02983362227678299, -0.09335308521986008, -0.14630575478076935, -0.12889188528060913, -0.201785609126091, -0.17382466793060303, -0.17564189434051514, -0.17564189434051514, -0.17564189434051514], "metadata": {"source_tokens": ["Take", "##over", "stock", "traders", "noted", "that", "with", "the", "junk", "-", "bond", "market", "in", "di", "##sar", "##ray", ",", "Georgia", "-", "Pacific", "'", "##s", "bid", "is", "an", "indication", "of", "where", "the", "takeover", "game", "is", "headed", ":", "namely", ",", "industrial", "companies", "can", "continue", "bidding", "for", "one", "another", ",", "but", "financial", "buyers", "such", "as", "leverage", "##d", "buy", "-", "out", "firms", "will", "be", "at", "a", "disadvantage", "in", "obtaining", "financing", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Take", "##over", "stock", "traders", "[unused2]", "[unused3]", "noted", "[unused4]", "[unused5]", "that", "with", "the", "junk", "-", "bond", "market", "in", "di", "##sar", "##ray", ",", "Georgia", "-", "Pacific", "'", "##s", "bid", "is", "an", "indication", "of", "where", "the", "takeover", "game", "is", "headed", ":", "namely", ",", "industrial", "companies", "can", "continue", "bidding", "for", "one", "another", ",", "[SEP]", "[unused1]", "financial", "buyers", "such", "as", "leverage", "##d", "buy", "-", "out", "firms", "[unused2]", "[unused3]", "will", "be", "[unused4]", "[unused5]", "at", "a", "disadvantage", "in", "obtaining", "financing", "[unused6]", "[SEP]", "[unused1]", "the", "takeover", "game", "[unused2]", "[unused3]", "is", "headed", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "industrial", "companies", "[unused2]", "[unused3]", "can", "continue", "[unused4]", "[unused5]", "bidding", "for", "one", "another", "[unused6]", "[SEP]", "[unused1]", "Georgia", "Pacific", "'", "##s", "bid", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "an", "indication", "of", "where", "the", "takeover", "game", "is", "headed", ":", "namely", ",", "industrial", "companies", "can", "continue", "bidding", "for", "one", "another", "with", "the", "junk", "-", "bond", "market", "in", "di", "##sar", "##ray", "[unused6]", "[SEP]", "[unused1]", "industrial", "companies", "[unused2]", "[unused3]", "can", "continue", "[unused4]", "[unused5]", "bidding", "for", "one", "another", "namely", "[unused6]", "[SEP]"]]}

input 555:  {"source": "Technology stocks bore the brunt of the OTC market 's recent sell - off , and traders say it 's natural that they rebound sharply now that the market has turned around .\n"}
prediction:  {"predictions": [[1, 3529, 17901, 2, 3, 8475, 4, 5, 1103, 9304, 8355, 1104, 1103, 152, 9481, 2319, 112, 1116, 2793, 4582, 118, 1228, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 14552, 2, 3, 1474, 4, 5, 1122, 112, 1116, 2379, 1115, 1152, 1231, 8346, 8930, 1208, 1208, 1115, 1103, 2319, 1144, 1454, 1213, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2319, 2, 3, 1144, 1454, 1213, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1231, 8346, 8930, 4, 5, 1208, 1115, 1103, 2319, 1144, 1454, 1213, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.011160056106746197, -0.048071011900901794, -0.04285648465156555, -0.12075427919626236, -0.12355875968933105, -0.12355899810791016, -0.12355899810791016, -0.12355899810791016, -0.12355899810791016, -0.12355899810791016], "metadata": {"source_tokens": ["Technology", "stocks", "bore", "the", "br", "##unt", "of", "the", "O", "##TC", "market", "'", "##s", "recent", "sell", "-", "off", ",", "and", "traders", "say", "it", "'", "##s", "natural", "that", "they", "re", "##bound", "sharply", "now", "that", "the", "market", "has", "turned", "around", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Technology", "stocks", "[unused2]", "[unused3]", "bore", "[unused4]", "[unused5]", "the", "br", "##unt", "of", "the", "O", "##TC", "market", "'", "##s", "recent", "sell", "-", "off", "[unused6]", "[SEP]", "[unused1]", "traders", "[unused2]", "[unused3]", "say", "[unused4]", "[unused5]", "it", "'", "##s", "natural", "that", "they", "re", "##bound", "sharply", "now", "now", "that", "the", "market", "has", "turned", "around", "[unused6]", "[SEP]", "[unused1]", "the", "market", "[unused2]", "[unused3]", "has", "turned", "around", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "re", "##bound", "sharply", "[unused4]", "[unused5]", "now", "that", "the", "market", "has", "turned", "around", "[unused6]", "[SEP]"]]}

input 556:  {"source": "That compares with 3.5 % butterfat for whole milk .\n"}
prediction:  {"predictions": [[1, 1337, 2, 3, 26153, 4, 5, 1114, 124, 28138, 1571, 110, 13742, 8057, 1204, 1111, 2006, 6831, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00015726088895462453, -0.00016832351684570312, -0.000171661376953125, -0.000171661376953125, -0.000171661376953125, -0.000171661376953125, -0.000171661376953125, -0.000171661376953125, -0.000171661376953125, -0.000171661376953125], "metadata": {"source_tokens": ["That", "compares", "with", "3", "##.", "##5", "%", "butter", "##fa", "##t", "for", "whole", "milk", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "That", "[unused2]", "[unused3]", "compares", "[unused4]", "[unused5]", "with", "3", "##.", "##5", "%", "butter", "##fa", "##t", "for", "whole", "milk", "[unused6]", "[SEP]"]]}

input 557:  {"source": "The $ 150 million in senior subordinated floating - rate notes were targeted to be offered at a price to float four percentage points above the three - month LIBOR .\n"}
prediction:  {"predictions": [[1, 1109, 109, 4214, 1550, 1107, 2682, 16469, 1181, 8379, 118, 2603, 3697, 2, 3, 1127, 9271, 4, 5, 1106, 1129, 2356, 1120, 170, 3945, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 109, 4214, 1550, 1107, 2682, 16469, 1181, 8379, 118, 2603, 3697, 2, 3, 1127, 9271, 4, 5, 1106, 1129, 2356, 1120, 170, 3945, 1106, 15666, 1300, 6556, 1827, 1807, 1103, 1210, 118, 2370, 149, 27954, 9565, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006498107220977545, -0.017670888453722, -0.21110951900482178, -0.211769700050354, -0.211769700050354, -0.211769700050354, -0.211769700050354, -0.211769700050354, -0.211769700050354, -0.211769700050354], "metadata": {"source_tokens": ["The", "$", "150", "million", "in", "senior", "subordinate", "##d", "floating", "-", "rate", "notes", "were", "targeted", "to", "be", "offered", "at", "a", "price", "to", "float", "four", "percentage", "points", "above", "the", "three", "-", "month", "L", "##IB", "##OR", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "$", "150", "million", "in", "senior", "subordinate", "##d", "floating", "-", "rate", "notes", "[unused2]", "[unused3]", "were", "targeted", "[unused4]", "[unused5]", "to", "be", "offered", "at", "a", "price", "[unused6]", "[SEP]", "[unused1]", "The", "$", "150", "million", "in", "senior", "subordinate", "##d", "floating", "-", "rate", "notes", "[unused2]", "[unused3]", "were", "targeted", "[unused4]", "[unused5]", "to", "be", "offered", "at", "a", "price", "to", "float", "four", "percentage", "points", "above", "the", "three", "-", "month", "L", "##IB", "##OR", "[unused6]", "[SEP]"]]}

input 558:  {"source": "The 41 - year - old Mr. Azoff , a former rock 'n' roll manager , is credited with turning around MCA 's once - moribund music division in his six years at the company .\n"}
prediction:  {"predictions": [[1, 1109, 3746, 118, 1214, 118, 1385, 1828, 28138, 138, 6112, 3101, 2, 3, 1110, 5175, 4, 5, 1114, 3219, 1213, 24955, 112, 1116, 1517, 118, 182, 9012, 7925, 3276, 1390, 2417, 1107, 1117, 1565, 1201, 1120, 1103, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 3746, 118, 1214, 1385, 1828, 28138, 138, 6112, 3101, 2, 3, 1110, 5175, 4, 5, 1114, 3219, 1213, 24955, 112, 1116, 1517, 182, 9012, 7925, 3276, 1390, 2417, 1107, 1117, 1565, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 3746, 118, 1214, 1385, 1828, 28138, 138, 6112, 3101, 2, 3, 1110, 5175, 4, 5, 1114, 3219, 1213, 24955, 112, 1116, 1517, 182, 9012, 7925, 3276, 1390, 2417, 1107, 1117, 1565, 1201, 1107, 1117, 1565, 1201, 1120, 1103, 1419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.013996336609125137, -0.08391353487968445, -0.11348190158605576, -0.3006628751754761, -0.2984597682952881, -0.2984597682952881, -0.2984597682952881, -0.2984597682952881, -0.2984597682952881, -0.2984597682952881], "metadata": {"source_tokens": ["The", "41", "-", "year", "-", "old", "Mr", "##.", "A", "##zo", "##ff", ",", "a", "former", "rock", "'", "##n", "##'", "roll", "manager", ",", "is", "credited", "with", "turning", "around", "MCA", "'", "##s", "once", "-", "m", "##ori", "##bu", "##nd", "music", "division", "in", "his", "six", "years", "at", "the", "company", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "41", "-", "year", "-", "old", "Mr", "##.", "A", "##zo", "##ff", "[unused2]", "[unused3]", "is", "credited", "[unused4]", "[unused5]", "with", "turning", "around", "MCA", "'", "##s", "once", "-", "m", "##ori", "##bu", "##nd", "music", "division", "in", "his", "six", "years", "at", "the", "company", "[unused6]", "[SEP]", "[unused1]", "The", "41", "-", "year", "old", "Mr", "##.", "A", "##zo", "##ff", "[unused2]", "[unused3]", "is", "credited", "[unused4]", "[unused5]", "with", "turning", "around", "MCA", "'", "##s", "once", "m", "##ori", "##bu", "##nd", "music", "division", "in", "his", "six", "years", "[unused6]", "[SEP]", "[unused1]", "The", "41", "-", "year", "old", "Mr", "##.", "A", "##zo", "##ff", "[unused2]", "[unused3]", "is", "credited", "[unused4]", "[unused5]", "with", "turning", "around", "MCA", "'", "##s", "once", "m", "##ori", "##bu", "##nd", "music", "division", "in", "his", "six", "years", "in", "his", "six", "years", "at", "the", "company", "[unused6]", "[SEP]"]]}

input 559:  {"source": "The Chemical spokeswoman said the bank has examined its methodologies and internal controls .\n"}
prediction:  {"predictions": [[1, 1109, 10957, 2910, 1116, 9462, 2, 3, 1163, 4, 5, 1103, 3085, 1144, 8600, 1157, 3442, 20941, 1105, 4422, 7451, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 3085, 2, 3, 1144, 8600, 4, 5, 1157, 3442, 20941, 1105, 4422, 7451, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00014835855108685791, -0.036273472011089325, -0.0005369186401367188, -0.0005707740783691406, -0.0005707740783691406, -0.0005707740783691406, -0.0005707740783691406, -0.0005707740783691406, -0.0005707740783691406, -0.0005707740783691406], "metadata": {"source_tokens": ["The", "Chemical", "spoke", "##s", "##woman", "said", "the", "bank", "has", "examined", "its", "method", "##ologies", "and", "internal", "controls", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Chemical", "spoke", "##s", "##woman", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "bank", "has", "examined", "its", "method", "##ologies", "and", "internal", "controls", "[unused6]", "[SEP]", "[unused1]", "the", "bank", "[unused2]", "[unused3]", "has", "examined", "[unused4]", "[unused5]", "its", "method", "##ologies", "and", "internal", "controls", "[unused6]", "[SEP]"]]}

input 560:  {"source": "The Lone Star Steel lawsuit also asks the court to rule that Lone Star Technologies is jointly responsible for a $ 4.5 million Lone Star Steel pension payment that was due , but was n't paid , in September and that the parent company ca n't recover the amount from its subsidiary if the parent company makes the payment .\n"}
prediction:  {"predictions": [[1, 1109, 19511, 2537, 8180, 9680, 2, 3, 4390, 4, 5, 1103, 2175, 1106, 3013, 1115, 19511, 2537, 14164, 1110, 10824, 2784, 1111, 170, 109, 125, 28138, 1571, 1550, 19511, 2537, 8180, 12966, 7727, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 109, 125, 28138, 1571, 1550, 19511, 2537, 8180, 12966, 7727, 2, 3, 1108, 4, 5, 1496, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6486, 1419, 2, 3, 11019, 183, 28131, 1204, 3004, 4, 5, 1107, 1347, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6486, 1419, 2, 3, 11019, 183, 28131, 1204, 8680, 4, 5, 1103, 2971, 1121, 1157, 7049, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 19511, 2537, 14164, 2, 3, 1110, 4, 5, 10824, 2784, 1111, 170, 109, 125, 28138, 1571, 1550, 19511, 2537, 8180, 12966, 7727, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6486, 1419, 2, 3, 11019, 183, 28131, 1204, 8680, 4, 5, 1103, 2971, 1191, 1103, 6486, 1419, 2228, 1103, 7727, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6486, 1419, 2, 3, 2228, 4, 5, 1103, 7727, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6486, 1419, 2, 3, 11019, 183, 28131, 1204, 8680, 4, 5, 1103, 2971, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 6486, 1419, 2, 3, 11019, 183, 28131, 1204, 8680, 4, 5, 1103, 2971, 6, 102, 102, 1, 1103, 6486, 1419, 2, 3, 11019, 183, 28131, 1204, 8680, 4, 5, 1103, 2971, 6, 102, 102]], "predicted_log_probs": [-0.037666358053684235, -0.055327821522951126, -0.09705209732055664, -0.0815531387925148, -0.08689849823713303, -0.11228400468826294, -0.15087947249412537, -0.17226453125476837, -0.18625488877296448, -0.1697891503572464], "metadata": {"source_tokens": ["The", "Lone", "Star", "Steel", "lawsuit", "also", "asks", "the", "court", "to", "rule", "that", "Lone", "Star", "Technologies", "is", "jointly", "responsible", "for", "a", "$", "4", "##.", "##5", "million", "Lone", "Star", "Steel", "pension", "payment", "that", "was", "due", ",", "but", "was", "n", "##'", "##t", "paid", ",", "in", "September", "and", "that", "the", "parent", "company", "ca", "n", "##'", "##t", "recover", "the", "amount", "from", "its", "subsidiary", "if", "the", "parent", "company", "makes", "the", "payment", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Lone", "Star", "Steel", "lawsuit", "[unused2]", "[unused3]", "asks", "[unused4]", "[unused5]", "the", "court", "to", "rule", "that", "Lone", "Star", "Technologies", "is", "jointly", "responsible", "for", "a", "$", "4", "##.", "##5", "million", "Lone", "Star", "Steel", "pension", "payment", "[unused6]", "[SEP]", "[unused1]", "a", "$", "4", "##.", "##5", "million", "Lone", "Star", "Steel", "pension", "payment", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "due", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "ca", "n", "##'", "##t", "paid", "[unused4]", "[unused5]", "in", "September", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "ca", "n", "##'", "##t", "recover", "[unused4]", "[unused5]", "the", "amount", "from", "its", "subsidiary", "[unused6]", "[SEP]", "[unused1]", "Lone", "Star", "Technologies", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "jointly", "responsible", "for", "a", "$", "4", "##.", "##5", "million", "Lone", "Star", "Steel", "pension", "payment", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "ca", "n", "##'", "##t", "recover", "[unused4]", "[unused5]", "the", "amount", "if", "the", "parent", "company", "makes", "the", "payment", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "makes", "[unused4]", "[unused5]", "the", "payment", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "ca", "n", "##'", "##t", "recover", "[unused4]", "[unused5]", "the", "amount", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "ca", "n", "##'", "##t", "recover", "[unused4]", "[unused5]", "the", "amount", "[unused6]", "[SEP]", "[unused1]", "the", "parent", "company", "[unused2]", "[unused3]", "ca", "n", "##'", "##t", "recover", "[unused4]", "[unused5]", "the", "amount", "[unused6]", "[SEP]"]]}

input 561:  {"source": "The National Transportation Safety Board ruled that pilots failed to set the plane 's wing flaps and slats properly for takeoff and failed to make mandatory preflight checks that would have detected the error .\n"}
prediction:  {"predictions": [[1, 1109, 1305, 8373, 9218, 2464, 2, 3, 4741, 4, 5, 1115, 8486, 2604, 1106, 1383, 1103, 4261, 112, 1116, 3092, 23841, 1116, 1105, 188, 16236, 1116, 7513, 1111, 22149, 1105, 2604, 1106, 1294, 11839, 3073, 2087, 4568, 15008, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 11839, 3073, 2087, 4568, 15008, 2, 3, 1156, 1138, 11168, 4, 5, 1103, 7353, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8486, 2, 3, 2604, 4, 5, 1106, 1294, 11839, 3073, 2087, 4568, 15008, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8486, 2, 3, 2604, 4, 5, 1106, 1294, 11839, 3073, 2087, 4568, 15008, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8486, 2, 3, 2604, 4, 5, 1106, 1294, 11839, 3073, 2087, 4568, 15008, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8486, 2, 3, 2604, 4, 5, 1106, 1294, 11839, 3073, 2087, 4568, 15008, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.020046131685376167, -0.017857417464256287, -0.03964056074619293, -0.06982438266277313, -0.08263617008924484, -0.08704415708780289, -0.31441640853881836, -0.32996702194213867, -0.32996702194213867, -0.32996702194213867], "metadata": {"source_tokens": ["The", "National", "Transportation", "Safety", "Board", "ruled", "that", "pilots", "failed", "to", "set", "the", "plane", "'", "##s", "wing", "flap", "##s", "and", "s", "##lat", "##s", "properly", "for", "takeoff", "and", "failed", "to", "make", "mandatory", "pre", "##f", "##light", "checks", "that", "would", "have", "detected", "the", "error", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "National", "Transportation", "Safety", "Board", "[unused2]", "[unused3]", "ruled", "[unused4]", "[unused5]", "that", "pilots", "failed", "to", "set", "the", "plane", "'", "##s", "wing", "flap", "##s", "and", "s", "##lat", "##s", "properly", "for", "takeoff", "and", "failed", "to", "make", "mandatory", "pre", "##f", "##light", "checks", "[unused6]", "[SEP]", "[unused1]", "mandatory", "pre", "##f", "##light", "checks", "[unused2]", "[unused3]", "would", "have", "detected", "[unused4]", "[unused5]", "the", "error", "[unused6]", "[SEP]", "[unused1]", "pilots", "[unused2]", "[unused3]", "failed", "[unused4]", "[unused5]", "to", "make", "mandatory", "pre", "##f", "##light", "checks", "[unused6]", "[SEP]", "[unused1]", "pilots", "[unused2]", "[unused3]", "failed", "[unused4]", "[unused5]", "to", "make", "mandatory", "pre", "##f", "##light", "checks", "[unused6]", "[SEP]", "[unused1]", "pilots", "[unused2]", "[unused3]", "failed", "[unused4]", "[unused5]", "to", "make", "mandatory", "pre", "##f", "##light", "checks", "[unused6]", "[SEP]", "[unused1]", "pilots", "[unused2]", "[unused3]", "failed", "[unused4]", "[unused5]", "to", "make", "mandatory", "pre", "##f", "##light", "checks", "[unused6]", "[SEP]"]]}

input 562:  {"source": "The New Orleans oil and gas exploration and diving operations company added that it does n't expect any further adverse financial impact from the restructuring .\n"}
prediction:  {"predictions": [[1, 1109, 1203, 5705, 2949, 1105, 3245, 10016, 1105, 10398, 2500, 1419, 2, 3, 1896, 4, 5, 1115, 1122, 1674, 183, 28131, 1204, 5363, 1251, 1748, 16798, 2798, 3772, 1121, 1103, 20841, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1674, 183, 28131, 1204, 5363, 4, 5, 1251, 1748, 16798, 2798, 3772, 1121, 1103, 20841, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0007538094068877399, -0.004673168994486332, -0.03220510482788086, -0.03220558166503906, -0.03220558166503906, -0.03220558166503906, -0.03220558166503906, -0.03220558166503906, -0.03220558166503906, -0.03220558166503906], "metadata": {"source_tokens": ["The", "New", "Orleans", "oil", "and", "gas", "exploration", "and", "diving", "operations", "company", "added", "that", "it", "does", "n", "##'", "##t", "expect", "any", "further", "adverse", "financial", "impact", "from", "the", "restructuring", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "New", "Orleans", "oil", "and", "gas", "exploration", "and", "diving", "operations", "company", "[unused2]", "[unused3]", "added", "[unused4]", "[unused5]", "that", "it", "does", "n", "##'", "##t", "expect", "any", "further", "adverse", "financial", "impact", "from", "the", "restructuring", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "does", "n", "##'", "##t", "expect", "[unused4]", "[unused5]", "any", "further", "adverse", "financial", "impact", "from", "the", "restructuring", "[unused6]", "[SEP]"]]}

input 563:  {"source": "The Second Section index , which fell 36.87 points Friday , was down 21.44 points , or 0.59 % , to close at 3636.06 .\n"}
prediction:  {"predictions": [[1, 1109, 2307, 6177, 7448, 2, 3, 2204, 4, 5, 3164, 28138, 1604, 1559, 1827, 5286, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2307, 6177, 7448, 2, 3, 1108, 4, 5, 1205, 1626, 28138, 25041, 1827, 117, 1137, 121, 28138, 1571, 1580, 110, 117, 1106, 1601, 1120, 3164, 22997, 28138, 1568, 1545, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2307, 6177, 7448, 2, 3, 1108, 4, 5, 1626, 28138, 25041, 1827, 1137, 121, 28138, 1571, 1580, 110, 1106, 1601, 1120, 3164, 22997, 28138, 1568, 1545, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.028605256229639053, -0.057175640016794205, -0.08109517395496368, -0.11910891532897949, -0.11934709548950195, -0.11934709548950195, -0.11934709548950195, -0.11934709548950195, -0.11934709548950195, -0.11934709548950195], "metadata": {"source_tokens": ["The", "Second", "Section", "index", ",", "which", "fell", "36", "##.", "##8", "##7", "points", "Friday", ",", "was", "down", "21", "##.", "##44", "points", ",", "or", "0", "##.", "##5", "##9", "%", ",", "to", "close", "at", "36", "##36", "##.", "##0", "##6", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Second", "Section", "index", "[unused2]", "[unused3]", "fell", "[unused4]", "[unused5]", "36", "##.", "##8", "##7", "points", "Friday", "[unused6]", "[SEP]", "[unused1]", "The", "Second", "Section", "index", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "down", "21", "##.", "##44", "points", ",", "or", "0", "##.", "##5", "##9", "%", ",", "to", "close", "at", "36", "##36", "##.", "##0", "##6", "[unused6]", "[SEP]", "[unused1]", "The", "Second", "Section", "index", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "21", "##.", "##44", "points", "or", "0", "##.", "##5", "##9", "%", "to", "close", "at", "36", "##36", "##.", "##0", "##6", "[unused6]", "[SEP]"]]}

input 564:  {"source": "The Soviets complicated the issue by offering to include light tanks , which are as light as 10 tons .\n"}
prediction:  {"predictions": [[1, 1109, 16359, 2, 3, 8277, 1103, 2486, 1118, 4733, 4, 5, 1106, 1511, 1609, 6977, 117, 1134, 1132, 1112, 1609, 1112, 1275, 5606, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1609, 6977, 2, 3, 1132, 4, 5, 1112, 1609, 1112, 1275, 5606, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04651596024632454, -0.05460389330983162, -0.03228282928466797, -0.03264188766479492, -0.03264188766479492, -0.03264188766479492, -0.03264188766479492, -0.03264188766479492, -0.03264188766479492, -0.03264188766479492], "metadata": {"source_tokens": ["The", "Soviets", "complicated", "the", "issue", "by", "offering", "to", "include", "light", "tanks", ",", "which", "are", "as", "light", "as", "10", "tons", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "Soviets", "[unused2]", "[unused3]", "complicated", "the", "issue", "by", "offering", "[unused4]", "[unused5]", "to", "include", "light", "tanks", ",", "which", "are", "as", "light", "as", "10", "tons", "[unused6]", "[SEP]", "[unused1]", "light", "tanks", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "as", "light", "as", "10", "tons", "[unused6]", "[SEP]"]]}

input 565:  {"source": "The U.S. market , too , is dominated by a giant , International Business Machines Corp .\n"}
prediction:  {"predictions": [[1, 1109, 158, 28138, 1708, 28138, 2319, 2, 3, 1110, 6226, 4, 5, 1118, 170, 4994, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 4994, 2, 3, 1110, 4, 5, 1570, 3518, 7792, 1116, 13619, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.044329795986413956, -0.05086676776409149, -0.15242862701416016, -0.15146493911743164, -0.15146493911743164, -0.15146493911743164, -0.15146493911743164, -0.15146493911743164, -0.15146493911743164, -0.15146493911743164], "metadata": {"source_tokens": ["The", "U", "##.", "##S", "##.", "market", ",", "too", ",", "is", "dominated", "by", "a", "giant", ",", "International", "Business", "Machine", "##s", "Corp", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "U", "##.", "##S", "##.", "market", "[unused2]", "[unused3]", "is", "dominated", "[unused4]", "[unused5]", "by", "a", "giant", "[unused6]", "[SEP]", "[unused1]", "a", "giant", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "International", "Business", "Machine", "##s", "Corp", "[unused6]", "[SEP]"]]}

input 566:  {"source": "The basket product , while it has got off to a slow start , is being supported by some big brokerage firms -- another member of Mr. Phelan 's splintered constituency .\n"}
prediction:  {"predictions": [[1, 1109, 12916, 3317, 117, 1229, 1122, 1144, 1400, 1228, 1106, 170, 3345, 1838, 2, 3, 1110, 1217, 2726, 4, 5, 1118, 1199, 1992, 24535, 2553, 9780, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1144, 1400, 1228, 4, 5, 1106, 170, 3345, 1838, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 12916, 3317, 1229, 1122, 1144, 1400, 1228, 1106, 170, 3345, 1838, 2, 3, 1110, 1217, 2726, 4, 5, 1118, 1199, 1992, 24535, 2553, 9780, 1330, 1420, 1104, 1828, 28138, 7642, 9945, 1179, 112, 1116, 188, 1643, 22761, 5686, 5269, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.024228457361459732, -0.025100596249103546, -0.03971390426158905, -0.032309770584106445, -0.032308101654052734, -0.032308101654052734, -0.032308101654052734, -0.032308101654052734, -0.032308101654052734, -0.032308101654052734], "metadata": {"source_tokens": ["The", "basket", "product", ",", "while", "it", "has", "got", "off", "to", "a", "slow", "start", ",", "is", "being", "supported", "by", "some", "big", "broker", "##age", "firms", "-", "##-", "another", "member", "of", "Mr", "##.", "Ph", "##ela", "##n", "'", "##s", "s", "##p", "##lint", "##ered", "constituency", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "basket", "product", ",", "while", "it", "has", "got", "off", "to", "a", "slow", "start", "[unused2]", "[unused3]", "is", "being", "supported", "[unused4]", "[unused5]", "by", "some", "big", "broker", "##age", "firms", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "has", "got", "off", "[unused4]", "[unused5]", "to", "a", "slow", "start", "[unused6]", "[SEP]", "[unused1]", "The", "basket", "product", "while", "it", "has", "got", "off", "to", "a", "slow", "start", "[unused2]", "[unused3]", "is", "being", "supported", "[unused4]", "[unused5]", "by", "some", "big", "broker", "##age", "firms", "another", "member", "of", "Mr", "##.", "Ph", "##ela", "##n", "'", "##s", "s", "##p", "##lint", "##ered", "constituency", "[unused6]", "[SEP]"]]}

input 567:  {"source": "The campaign , a patriotic celebration of the 200th anniversary of the Bill of Rights , does n't mention cigarettes or smoking ; cigarette ads have been prohibited on television since 1971 .\n"}
prediction:  {"predictions": [[1, 1109, 2322, 2, 3, 1674, 183, 28131, 1204, 4734, 4, 5, 16595, 1137, 9987, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9983, 17641, 2, 3, 1138, 1151, 11018, 4, 5, 1113, 1778, 1290, 2507, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2322, 2, 3, 1110, 4, 5, 170, 22435, 7978, 1104, 1103, 2363, 1582, 5453, 1104, 1103, 2617, 1104, 5399, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03689417988061905, -0.001923590898513794, -0.0075780050829052925, -0.03332948684692383, -0.032330989837646484, -0.032330989837646484, -0.032330989837646484, -0.032330989837646484, -0.032330989837646484, -0.032330989837646484], "metadata": {"source_tokens": ["The", "campaign", ",", "a", "patriotic", "celebration", "of", "the", "200", "##th", "anniversary", "of", "the", "Bill", "of", "Rights", ",", "does", "n", "##'", "##t", "mention", "cigarettes", "or", "smoking", ";", "cigarette", "ads", "have", "been", "prohibited", "on", "television", "since", "1971", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "campaign", "[unused2]", "[unused3]", "does", "n", "##'", "##t", "mention", "[unused4]", "[unused5]", "cigarettes", "or", "smoking", "[unused6]", "[SEP]", "[unused1]", "cigarette", "ads", "[unused2]", "[unused3]", "have", "been", "prohibited", "[unused4]", "[unused5]", "on", "television", "since", "1971", "[unused6]", "[SEP]", "[unused1]", "The", "campaign", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "a", "patriotic", "celebration", "of", "the", "200", "##th", "anniversary", "of", "the", "Bill", "of", "Rights", "[unused6]", "[SEP]"]]}

input 568:  {"source": "The centerpiece of that complex , the Landmark Tower , will be Japan 's tallest building when it is completed in 1993 .\n"}
prediction:  {"predictions": [[1, 1109, 2057, 9641, 1104, 1115, 2703, 2, 3, 1209, 1129, 4, 5, 1999, 112, 1116, 14369, 1459, 1165, 1122, 1110, 2063, 1107, 1949, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 1110, 2063, 4, 5, 1107, 1949, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1115, 2703, 2, 3, 1110, 4, 5, 1103, 18405, 5646, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00883498601615429, -0.035767704248428345, -0.02767142280936241, -0.023251056671142578, -0.02303934097290039, -0.02303934097290039, -0.02303934097290039, -0.02303934097290039, -0.02303934097290039, -0.02303934097290039], "metadata": {"source_tokens": ["The", "center", "##piece", "of", "that", "complex", ",", "the", "Landmark", "Tower", ",", "will", "be", "Japan", "'", "##s", "tallest", "building", "when", "it", "is", "completed", "in", "1993", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "center", "##piece", "of", "that", "complex", "[unused2]", "[unused3]", "will", "be", "[unused4]", "[unused5]", "Japan", "'", "##s", "tallest", "building", "when", "it", "is", "completed", "in", "1993", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "is", "completed", "[unused4]", "[unused5]", "in", "1993", "[unused6]", "[SEP]", "[unused1]", "that", "complex", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "Landmark", "Tower", "[unused6]", "[SEP]"]]}

input 569:  {"source": "The company said the fastener business `` has been under severe cost pressures for some time . ''\n"}
prediction:  {"predictions": [[1, 1109, 1419, 2, 3, 1163, 4, 5, 1103, 2698, 24475, 1671, 169, 28152, 1144, 1151, 1223, 5199, 2616, 16390, 1111, 1199, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2698, 24475, 1671, 2, 3, 1144, 1151, 4, 5, 1223, 5199, 2616, 16390, 1111, 1199, 1159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0008786392281763256, -0.018224764615297318, -0.0031442642211914062, -0.0030226707458496094, -0.0030226707458496094, -0.0030226707458496094, -0.0030226707458496094, -0.0030226707458496094, -0.0030226707458496094, -0.0030226707458496094], "metadata": {"source_tokens": ["The", "company", "said", "the", "fast", "##ener", "business", "`", "##`", "has", "been", "under", "severe", "cost", "pressures", "for", "some", "time", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "company", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "fast", "##ener", "business", "`", "##`", "has", "been", "under", "severe", "cost", "pressures", "for", "some", "time", "[unused6]", "[SEP]", "[unused1]", "the", "fast", "##ener", "business", "[unused2]", "[unused3]", "has", "been", "[unused4]", "[unused5]", "under", "severe", "cost", "pressures", "for", "some", "time", "[unused6]", "[SEP]"]]}

input 570:  {"source": "The conviction stemmed from federal charges of consumer fraud for sale of phony infant apple juice between 1978 and 1983 .\n"}
prediction:  {"predictions": [[1, 1109, 10774, 2, 3, 8175, 4611, 4, 5, 1121, 2877, 4917, 1104, 8440, 10258, 1111, 4688, 1104, 185, 8613, 1183, 11551, 12075, 12362, 1206, 2406, 1105, 2278, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.002798875095322728, -0.024186134338378906, -0.032964229583740234, -0.032964229583740234, -0.032964229583740234, -0.032964229583740234, -0.032964229583740234, -0.032964229583740234, -0.032964229583740234, -0.032964229583740234], "metadata": {"source_tokens": ["The", "conviction", "stem", "##med", "from", "federal", "charges", "of", "consumer", "fraud", "for", "sale", "of", "p", "##hon", "##y", "infant", "apple", "juice", "between", "1978", "and", "1983", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "conviction", "[unused2]", "[unused3]", "stem", "##med", "[unused4]", "[unused5]", "from", "federal", "charges", "of", "consumer", "fraud", "for", "sale", "of", "p", "##hon", "##y", "infant", "apple", "juice", "between", "1978", "and", "1983", "[unused6]", "[SEP]"]]}

input 571:  {"source": "The discount rate on three - month Treasury bills rose slightly from the average rate at Monday 's auction to 7.79 % for a bond - equivalent yield of 8.04 % .\n"}
prediction:  {"predictions": [[1, 1109, 23290, 2603, 1113, 1210, 118, 2370, 11712, 10020, 2, 3, 3152, 4, 5, 2776, 1121, 1103, 1903, 2603, 1120, 6356, 112, 1116, 11046, 1106, 128, 28138, 1559, 1580, 110, 1111, 170, 7069, 118, 4976, 10972, 1104, 129, 28138, 1568, 1527, 110, 6, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 23290, 2603, 1113, 1210, 118, 2370, 11712, 10020, 2, 3, 3152, 4, 5, 2776, 1121, 1103, 1903, 2603, 1120, 6356, 112, 1116, 11046, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 23290, 2603, 1113, 1210, 118, 2370, 11712, 10020, 2, 3, 3152, 4, 5, 2776, 1121, 1103, 1903, 2603, 1120, 6356, 112, 1116, 11046, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 23290, 2603, 1113, 1210, 118, 2370, 11712, 10020, 2, 3, 3152, 4, 5, 2776, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.022308407351374626, -0.08937748521566391, -0.1495884209871292, -0.14035384356975555, -0.3398396968841553, -0.34444308280944824, -0.34444308280944824, -0.34444308280944824, -0.34444308280944824, -0.34444308280944824], "metadata": {"source_tokens": ["The", "discount", "rate", "on", "three", "-", "month", "Treasury", "bills", "rose", "slightly", "from", "the", "average", "rate", "at", "Monday", "'", "##s", "auction", "to", "7", "##.", "##7", "##9", "%", "for", "a", "bond", "-", "equivalent", "yield", "of", "8", "##.", "##0", "##4", "%", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "discount", "rate", "on", "three", "-", "month", "Treasury", "bills", "[unused2]", "[unused3]", "rose", "[unused4]", "[unused5]", "slightly", "from", "the", "average", "rate", "at", "Monday", "'", "##s", "auction", "to", "7", "##.", "##7", "##9", "%", "for", "a", "bond", "-", "equivalent", "yield", "of", "8", "##.", "##0", "##4", "%", "[unused6]", "[SEP]", "[unused1]", "The", "discount", "rate", "on", "three", "-", "month", "Treasury", "bills", "[unused2]", "[unused3]", "rose", "[unused4]", "[unused5]", "slightly", "from", "the", "average", "rate", "at", "Monday", "'", "##s", "auction", "[unused6]", "[SEP]", "[unused1]", "The", "discount", "rate", "on", "three", "-", "month", "Treasury", "bills", "[unused2]", "[unused3]", "rose", "[unused4]", "[unused5]", "slightly", "from", "the", "average", "rate", "at", "Monday", "'", "##s", "auction", "[unused6]", "[SEP]", "[unused1]", "The", "discount", "rate", "on", "three", "-", "month", "Treasury", "bills", "[unused2]", "[unused3]", "rose", "[unused4]", "[unused5]", "slightly", "[unused6]", "[SEP]"]]}

input 572:  {"source": "The dollar drew strength from the stock market 's climb .\n"}
prediction:  {"predictions": [[1, 1109, 8876, 2, 3, 3583, 4, 5, 3220, 1121, 1103, 4482, 2319, 112, 1116, 6767, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0003299713134765625, -8.487701416015625e-05, -9.965896606445312e-05, -9.965896606445312e-05, -9.965896606445312e-05, -9.965896606445312e-05, -9.965896606445312e-05, -9.965896606445312e-05, -9.965896606445312e-05, -9.965896606445312e-05], "metadata": {"source_tokens": ["The", "dollar", "drew", "strength", "from", "the", "stock", "market", "'", "##s", "climb", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "dollar", "[unused2]", "[unused3]", "drew", "[unused4]", "[unused5]", "strength", "from", "the", "stock", "market", "'", "##s", "climb", "[unused6]", "[SEP]"]]}

input 573:  {"source": "The effect is that lawsuits that might have been barred because they were filed too late could proceed because of the one - year extension .\n"}
prediction:  {"predictions": [[1, 1109, 2629, 2, 3, 1110, 4, 5, 1115, 23005, 1115, 1547, 1138, 1151, 17081, 1272, 1152, 1127, 5770, 1315, 1523, 1180, 10980, 1272, 1104, 1103, 1141, 118, 1214, 4973, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 23005, 1115, 1547, 1138, 1151, 17081, 1272, 1152, 1127, 5770, 1315, 1523, 2, 3, 1180, 10980, 4, 5, 1272, 1104, 1103, 1141, 118, 1214, 4973, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 23005, 2, 3, 1547, 1138, 1151, 17081, 4, 5, 1272, 1152, 1127, 5770, 1315, 1523, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0012586042284965515, -0.029295293614268303, -0.03650636225938797, -0.16365432739257812, -0.17664194107055664, -0.17664194107055664, -0.17664194107055664, -0.17664194107055664, -0.17664194107055664, -0.17664194107055664], "metadata": {"source_tokens": ["The", "effect", "is", "that", "lawsuits", "that", "might", "have", "been", "barred", "because", "they", "were", "filed", "too", "late", "could", "proceed", "because", "of", "the", "one", "-", "year", "extension", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "effect", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "that", "lawsuits", "that", "might", "have", "been", "barred", "because", "they", "were", "filed", "too", "late", "could", "proceed", "because", "of", "the", "one", "-", "year", "extension", "[unused6]", "[SEP]", "[unused1]", "lawsuits", "that", "might", "have", "been", "barred", "because", "they", "were", "filed", "too", "late", "[unused2]", "[unused3]", "could", "proceed", "[unused4]", "[unused5]", "because", "of", "the", "one", "-", "year", "extension", "[unused6]", "[SEP]", "[unused1]", "lawsuits", "[unused2]", "[unused3]", "might", "have", "been", "barred", "[unused4]", "[unused5]", "because", "they", "were", "filed", "too", "late", "[unused6]", "[SEP]"]]}

input 574:  {"source": "The executives had profited handsomely by building American National Can Co. , Triangle 's chief asset .\n"}
prediction:  {"predictions": [[1, 1109, 14011, 2, 3, 1125, 5022, 1174, 8542, 1193, 1118, 1459, 4, 5, 1237, 1305, 2825, 3291, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1237, 1305, 2825, 3291, 28138, 2, 3, 1110, 4, 5, 20742, 112, 1116, 2705, 13274, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.037923313677310944, -0.051732465624809265, -0.02201223373413086, -0.022016048431396484, -0.022016048431396484, -0.022016048431396484, -0.022016048431396484, -0.022016048431396484, -0.022016048431396484, -0.022016048431396484], "metadata": {"source_tokens": ["The", "executives", "had", "profit", "##ed", "handsome", "##ly", "by", "building", "American", "National", "Can", "Co", "##.", ",", "Triangle", "'", "##s", "chief", "asset", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "executives", "[unused2]", "[unused3]", "had", "profit", "##ed", "handsome", "##ly", "by", "building", "[unused4]", "[unused5]", "American", "National", "Can", "Co", "##.", "[unused6]", "[SEP]", "[unused1]", "American", "National", "Can", "Co", "##.", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "Triangle", "'", "##s", "chief", "asset", "[unused6]", "[SEP]"]]}

input 575:  {"source": "The field took off in 1985 after scientists at Britain 's Sheffield University developed a handy , compact magnet for brain stimulation .\n"}
prediction:  {"predictions": [[1, 1109, 1768, 2, 3, 1261, 1228, 4, 5, 1107, 2210, 1170, 6479, 1120, 2855, 112, 1116, 8139, 1239, 1872, 170, 25997, 117, 10114, 24197, 1111, 3575, 23842, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6479, 1120, 2855, 112, 1116, 8139, 1239, 2, 3, 1872, 4, 5, 170, 25997, 117, 10114, 24197, 1111, 3575, 23842, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0013572692405432463, -0.003167867660522461, -0.0322573184967041, -0.032207489013671875, -0.032207489013671875, -0.032207489013671875, -0.032207489013671875, -0.032207489013671875, -0.032207489013671875, -0.032207489013671875], "metadata": {"source_tokens": ["The", "field", "took", "off", "in", "1985", "after", "scientists", "at", "Britain", "'", "##s", "Sheffield", "University", "developed", "a", "handy", ",", "compact", "magnet", "for", "brain", "stimulation", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "field", "[unused2]", "[unused3]", "took", "off", "[unused4]", "[unused5]", "in", "1985", "after", "scientists", "at", "Britain", "'", "##s", "Sheffield", "University", "developed", "a", "handy", ",", "compact", "magnet", "for", "brain", "stimulation", "[unused6]", "[SEP]", "[unused1]", "scientists", "at", "Britain", "'", "##s", "Sheffield", "University", "[unused2]", "[unused3]", "developed", "[unused4]", "[unused5]", "a", "handy", ",", "compact", "magnet", "for", "brain", "stimulation", "[unused6]", "[SEP]"]]}

input 576:  {"source": "The fitness craze itself has gone soft , the survey found .\n"}
prediction:  {"predictions": [[1, 1103, 5980, 2, 3, 1276, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 12691, 172, 26342, 2, 3, 1144, 2065, 4, 5, 2991, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.044262029230594635, -0.0201684832572937, -0.0006489753723144531, -0.0006117820739746094, -0.0006117820739746094, -0.0006117820739746094, -0.0006117820739746094, -0.0006117820739746094, -0.0006117820739746094, -0.0006117820739746094], "metadata": {"source_tokens": ["The", "fitness", "c", "##raze", "itself", "has", "gone", "soft", ",", "the", "survey", "found", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "survey", "[unused2]", "[unused3]", "found", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "The", "fitness", "c", "##raze", "[unused2]", "[unused3]", "has", "gone", "[unused4]", "[unused5]", "soft", "[unused6]", "[SEP]"]]}

input 577:  {"source": "The forest - products concern currently has about 38 million shares outstanding .\n"}
prediction:  {"predictions": [[1, 1109, 3304, 118, 2982, 4517, 2, 3, 1144, 4, 5, 1164, 3383, 1550, 6117, 6976, 1971, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0008360210340470076, -0.00885152816772461, -0.00884246826171875, -0.00884246826171875, -0.00884246826171875, -0.00884246826171875, -0.00884246826171875, -0.00884246826171875, -0.00884246826171875, -0.00884246826171875], "metadata": {"source_tokens": ["The", "forest", "-", "products", "concern", "currently", "has", "about", "38", "million", "shares", "outstanding", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "forest", "-", "products", "concern", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "about", "38", "million", "shares", "outstanding", "currently", "[unused6]", "[SEP]"]]}

input 578:  {"source": "The government , already buffeted by high interest rates and a slowing economy , has been badly hurt by last week 's shake - up in Mrs. Thatcher 's cabinet .\n"}
prediction:  {"predictions": [[1, 1109, 1433, 117, 1640, 171, 9435, 27860, 1118, 1344, 2199, 5600, 1105, 170, 20098, 4190, 2, 3, 1144, 1151, 6118, 2644, 4, 5, 1118, 1314, 1989, 112, 1116, 5854, 118, 1146, 1107, 2823, 28138, 23300, 112, 1116, 6109, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1433, 2, 3, 171, 9435, 27860, 4, 5, 1118, 1344, 2199, 5600, 1105, 170, 20098, 4190, 1640, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012516672722995281, -0.009522534906864166, -0.07645344734191895, -0.07645511627197266, -0.07645511627197266, -0.07645511627197266, -0.07645511627197266, -0.07645511627197266, -0.07645511627197266, -0.07645511627197266], "metadata": {"source_tokens": ["The", "government", ",", "already", "b", "##uff", "##eted", "by", "high", "interest", "rates", "and", "a", "slowing", "economy", ",", "has", "been", "badly", "hurt", "by", "last", "week", "'", "##s", "shake", "-", "up", "in", "Mrs", "##.", "Thatcher", "'", "##s", "cabinet", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "government", ",", "already", "b", "##uff", "##eted", "by", "high", "interest", "rates", "and", "a", "slowing", "economy", "[unused2]", "[unused3]", "has", "been", "badly", "hurt", "[unused4]", "[unused5]", "by", "last", "week", "'", "##s", "shake", "-", "up", "in", "Mrs", "##.", "Thatcher", "'", "##s", "cabinet", "[unused6]", "[SEP]", "[unused1]", "The", "government", "[unused2]", "[unused3]", "b", "##uff", "##eted", "[unused4]", "[unused5]", "by", "high", "interest", "rates", "and", "a", "slowing", "economy", "already", "[unused6]", "[SEP]"]]}

input 579:  {"source": "The issue is backed by a 12 % letter of credit from Credit Suisse .\n"}
prediction:  {"predictions": [[1, 1109, 2486, 2, 3, 1110, 5534, 4, 5, 1118, 170, 1367, 110, 2998, 1104, 4755, 1121, 14032, 15463, 19202, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00018106265633832663, -0.0003085136413574219, -0.0004687309265136719, -0.0004687309265136719, -0.0004687309265136719, -0.0004687309265136719, -0.0004687309265136719, -0.0004687309265136719, -0.0004687309265136719, -0.0004687309265136719], "metadata": {"source_tokens": ["The", "issue", "is", "backed", "by", "a", "12", "%", "letter", "of", "credit", "from", "Credit", "Su", "##isse", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "issue", "[unused2]", "[unused3]", "is", "backed", "[unused4]", "[unused5]", "by", "a", "12", "%", "letter", "of", "credit", "from", "Credit", "Su", "##isse", "[unused6]", "[SEP]"]]}

input 580:  {"source": "The last time IBM tapped the corporate debt market was in April 1988 , when it offered $ 500 million of debt securities .\n"}
prediction:  {"predictions": [[1, 1122, 2, 3, 2356, 4, 5, 109, 2260, 1550, 1104, 6695, 19313, 1364, 2115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1314, 1159, 9768, 10316, 1103, 6214, 6695, 2319, 2, 3, 1108, 4, 5, 1107, 1364, 2115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9768, 2, 3, 10316, 4, 5, 1103, 6214, 6695, 2319, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07348284870386124, -0.08369795978069305, -0.11130528897047043, -0.14609932899475098, -0.14076709747314453, -0.14076709747314453, -0.14076709747314453, -0.14076709747314453, -0.14076709747314453, -0.14076709747314453], "metadata": {"source_tokens": ["The", "last", "time", "IBM", "tapped", "the", "corporate", "debt", "market", "was", "in", "April", "1988", ",", "when", "it", "offered", "$", "500", "million", "of", "debt", "securities", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "it", "[unused2]", "[unused3]", "offered", "[unused4]", "[unused5]", "$", "500", "million", "of", "debt", "securities", "April", "1988", "[unused6]", "[SEP]", "[unused1]", "The", "last", "time", "IBM", "tapped", "the", "corporate", "debt", "market", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "in", "April", "1988", "[unused6]", "[SEP]", "[unused1]", "IBM", "[unused2]", "[unused3]", "tapped", "[unused4]", "[unused5]", "the", "corporate", "debt", "market", "[unused6]", "[SEP]"]]}

input 581:  {"source": "The latest 10 - year notes ended at about 100 16\\/32 to yield 7.90 % , compared with 100 11\\/32 to yield 7.93 % on Friday .\n"}
prediction:  {"predictions": [[1, 1109, 6270, 1275, 118, 1214, 3697, 2, 3, 2207, 4, 5, 1120, 1164, 1620, 1479, 28148, 28139, 17101, 1106, 10972, 128, 28138, 21500, 110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 6270, 1275, 1214, 3697, 2, 3, 2207, 4, 5, 1120, 1164, 1620, 1479, 28148, 28139, 17101, 1106, 10972, 128, 28138, 21500, 110, 3402, 1114, 1620, 1429, 28148, 28139, 17101, 1106, 10972, 128, 28138, 1580, 1495, 110, 1113, 5286, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02390197105705738, -0.052851732820272446, -0.23539650440216064, -0.2236652374267578, -0.2236652374267578, -0.2236652374267578, -0.2236652374267578, -0.2236652374267578, -0.2236652374267578, -0.2236652374267578], "metadata": {"source_tokens": ["The", "latest", "10", "-", "year", "notes", "ended", "at", "about", "100", "16", "##\\", "##/", "##32", "to", "yield", "7", "##.", "##90", "%", ",", "compared", "with", "100", "11", "##\\", "##/", "##32", "to", "yield", "7", "##.", "##9", "##3", "%", "on", "Friday", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "latest", "10", "-", "year", "notes", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "at", "about", "100", "16", "##\\", "##/", "##32", "to", "yield", "7", "##.", "##90", "%", "[unused6]", "[SEP]", "[unused1]", "The", "latest", "10", "year", "notes", "[unused2]", "[unused3]", "ended", "[unused4]", "[unused5]", "at", "about", "100", "16", "##\\", "##/", "##32", "to", "yield", "7", "##.", "##90", "%", "compared", "with", "100", "11", "##\\", "##/", "##32", "to", "yield", "7", "##.", "##9", "##3", "%", "on", "Friday", "[unused6]", "[SEP]"]]}

input 582:  {"source": "The market 's tempo was helped by the dollar 's resiliency , he said .\n"}
prediction:  {"predictions": [[1, 1109, 2319, 112, 1116, 16655, 2, 3, 1108, 2375, 4, 5, 1118, 1103, 8876, 112, 1116, 1231, 5053, 7174, 7232, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2319, 112, 1116, 16655, 1108, 2375, 1118, 1103, 8876, 112, 1116, 1231, 5053, 7174, 7232, 2, 3, 1163, 4, 5, 1119, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0018942045280709863, -0.03459286689758301, -0.0011949539184570312, -0.0012192726135253906, -0.0012192726135253906, -0.0012192726135253906, -0.0012192726135253906, -0.0012192726135253906, -0.0012192726135253906, -0.0012192726135253906], "metadata": {"source_tokens": ["The", "market", "'", "##s", "tempo", "was", "helped", "by", "the", "dollar", "'", "##s", "re", "##si", "##lie", "##ncy", ",", "he", "said", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "market", "'", "##s", "tempo", "[unused2]", "[unused3]", "was", "helped", "[unused4]", "[unused5]", "by", "the", "dollar", "'", "##s", "re", "##si", "##lie", "##ncy", "[unused6]", "[SEP]", "[unused1]", "The", "market", "'", "##s", "tempo", "was", "helped", "by", "the", "dollar", "'", "##s", "re", "##si", "##lie", "##ncy", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "he", "[unused6]", "[SEP]"]]}

input 583:  {"source": "The offering was priced with an 8.95 % coupon rate at 99.1875 % to yield 9.19 % .\n"}
prediction:  {"predictions": [[1, 1109, 4733, 2, 3, 1108, 23812, 4, 5, 1114, 1126, 129, 28138, 1580, 1571, 110, 8707, 1320, 2603, 1120, 4850, 28138, 15292, 26253, 110, 1106, 10972, 130, 28138, 16382, 110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 4733, 2, 3, 1108, 23812, 4, 5, 1106, 10972, 130, 28138, 16382, 110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.008307510986924171, -0.05866390839219093, -0.0762786865234375, -0.07628607749938965, -0.07628607749938965, -0.07628607749938965, -0.07628607749938965, -0.07628607749938965, -0.07628607749938965, -0.07628607749938965], "metadata": {"source_tokens": ["The", "offering", "was", "priced", "with", "an", "8", "##.", "##9", "##5", "%", "coup", "##on", "rate", "at", "99", "##.", "##18", "##75", "%", "to", "yield", "9", "##.", "##19", "%", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "offering", "[unused2]", "[unused3]", "was", "priced", "[unused4]", "[unused5]", "with", "an", "8", "##.", "##9", "##5", "%", "coup", "##on", "rate", "at", "99", "##.", "##18", "##75", "%", "to", "yield", "9", "##.", "##19", "%", "[unused6]", "[SEP]", "[unused1]", "The", "offering", "[unused2]", "[unused3]", "was", "priced", "[unused4]", "[unused5]", "to", "yield", "9", "##.", "##19", "%", "[unused6]", "[SEP]"]]}

input 584:  {"source": "The office may also be able to advise foreign and multinational clients on international law and general matters .\n"}
prediction:  {"predictions": [[1, 1109, 1701, 2, 3, 1336, 1145, 1129, 4, 5, 1682, 1106, 19961, 2880, 1105, 24924, 7550, 1113, 1835, 1644, 1105, 1704, 5218, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.001668472308665514, -0.07610893249511719, -0.07611536979675293, -0.07611536979675293, -0.07611536979675293, -0.07611536979675293, -0.07611536979675293, -0.07611536979675293, -0.07611536979675293, -0.07611536979675293], "metadata": {"source_tokens": ["The", "office", "may", "also", "be", "able", "to", "advise", "foreign", "and", "multinational", "clients", "on", "international", "law", "and", "general", "matters", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "office", "[unused2]", "[unused3]", "may", "also", "be", "[unused4]", "[unused5]", "able", "to", "advise", "foreign", "and", "multinational", "clients", "on", "international", "law", "and", "general", "matters", "[unused6]", "[SEP]"]]}

input 585:  {"source": "The operative definition of newsworthiness will favor virtually unrestrained use of personal , sensitive and intimate facts .\n"}
prediction:  {"predictions": [[1, 1109, 13035, 5754, 1104, 2371, 4189, 8405, 2, 3, 1209, 5010, 4, 5, 9024, 18366, 11098, 1174, 1329, 1104, 2357, 117, 7246, 1105, 10666, 9193, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0001914501190185547, -0.000278472900390625, -0.00027751922607421875, -0.00027751922607421875, -0.00027751922607421875, -0.00027751922607421875, -0.00027751922607421875, -0.00027751922607421875, -0.00027751922607421875, -0.00027751922607421875], "metadata": {"source_tokens": ["The", "operative", "definition", "of", "news", "##worth", "##iness", "will", "favor", "virtually", "unrest", "##rain", "##ed", "use", "of", "personal", ",", "sensitive", "and", "intimate", "facts", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "operative", "definition", "of", "news", "##worth", "##iness", "[unused2]", "[unused3]", "will", "favor", "[unused4]", "[unused5]", "virtually", "unrest", "##rain", "##ed", "use", "of", "personal", ",", "sensitive", "and", "intimate", "facts", "[unused6]", "[SEP]"]]}

input 586:  {"source": "The price was n't disclosed but one analyst estimated that it was $ 150 million .\n"}
prediction:  {"predictions": [[1, 1141, 14582, 2, 3, 3555, 4, 5, 1115, 1122, 1108, 109, 4214, 1550, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 3945, 2, 3, 1108, 183, 28131, 1204, 23617, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.027671754360198975, -0.0018295136978849769, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578, -0.02200031280517578], "metadata": {"source_tokens": ["The", "price", "was", "n", "##'", "##t", "disclosed", "but", "one", "analyst", "estimated", "that", "it", "was", "$", "150", "million", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "one", "analyst", "[unused2]", "[unused3]", "estimated", "[unused4]", "[unused5]", "that", "it", "was", "$", "150", "million", "[unused6]", "[SEP]", "[unused1]", "The", "price", "[unused2]", "[unused3]", "was", "n", "##'", "##t", "disclosed", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 587:  {"source": "The prices of most corn , soybean and wheat futures contracts dropped slightly as farmers in the Midwest continued to rebuild stockpiles that were depleted by the 1988 drought .\n"}
prediction:  {"predictions": [[1, 4482, 24898, 1116, 2, 3, 1127, 25403, 4, 5, 1118, 1103, 2115, 16076, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 7352, 1104, 1211, 11184, 117, 1177, 1183, 3962, 1389, 1105, 11773, 2174, 1116, 8216, 2, 3, 2434, 2776, 4, 5, 1112, 6915, 1107, 1103, 14661, 1598, 1106, 15596, 4482, 24898, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6915, 1107, 1103, 14661, 2, 3, 1106, 15596, 4, 5, 4482, 24898, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.034754395484924316, -0.014495604671537876, -0.09569507837295532, -0.03220772743225098, -0.03220772743225098, -0.03220772743225098, -0.03220772743225098, -0.03220772743225098, -0.03220772743225098, -0.03220772743225098], "metadata": {"source_tokens": ["The", "prices", "of", "most", "corn", ",", "so", "##y", "##be", "##an", "and", "wheat", "future", "##s", "contracts", "dropped", "slightly", "as", "farmers", "in", "the", "Midwest", "continued", "to", "rebuild", "stock", "##pile", "##s", "that", "were", "depleted", "by", "the", "1988", "drought", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "stock", "##pile", "##s", "[unused2]", "[unused3]", "were", "depleted", "[unused4]", "[unused5]", "by", "the", "1988", "drought", "[unused6]", "[SEP]", "[unused1]", "The", "prices", "of", "most", "corn", ",", "so", "##y", "##be", "##an", "and", "wheat", "future", "##s", "contracts", "[unused2]", "[unused3]", "dropped", "slightly", "[unused4]", "[unused5]", "as", "farmers", "in", "the", "Midwest", "continued", "to", "rebuild", "stock", "##pile", "##s", "[unused6]", "[SEP]", "[unused1]", "farmers", "in", "the", "Midwest", "[unused2]", "[unused3]", "to", "rebuild", "[unused4]", "[unused5]", "stock", "##pile", "##s", "[unused6]", "[SEP]"]]}

input 588:  {"source": "The senior subordinated debentures maturing in 2004 are targeted to be offered at a yield of between 12 5\\/8 % to 12 3\\/4 % .\n"}
prediction:  {"predictions": [[1, 1109, 2682, 16469, 1181, 1260, 19145, 10374, 22591, 6660, 1107, 1516, 2, 3, 1132, 9271, 4, 5, 1106, 1129, 2356, 1120, 170, 10972, 1104, 1206, 1367, 126, 28148, 28139, 1604, 110, 1106, 1367, 124, 28148, 28139, 1527, 110, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 2682, 16469, 1181, 1260, 19145, 10374, 22591, 6660, 1107, 1516, 2, 3, 1132, 9271, 4, 5, 1106, 1129, 2356, 1120, 170, 10972, 1104, 1206, 1367, 126, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 28148, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.029983127489686012, -0.10197317600250244, -0.07702493667602539, -0.07687044143676758, -0.07687044143676758, -0.07687044143676758, -0.07687044143676758, -0.07687044143676758, -0.07687044143676758, -0.07687044143676758], "metadata": {"source_tokens": ["The", "senior", "subordinate", "##d", "de", "##bent", "##ures", "mat", "##uring", "in", "2004", "are", "targeted", "to", "be", "offered", "at", "a", "yield", "of", "between", "12", "5", "##\\", "##/", "##8", "%", "to", "12", "3", "##\\", "##/", "##4", "%", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "senior", "subordinate", "##d", "de", "##bent", "##ures", "mat", "##uring", "in", "2004", "[unused2]", "[unused3]", "are", "targeted", "[unused4]", "[unused5]", "to", "be", "offered", "at", "a", "yield", "of", "between", "12", "5", "##\\", "##/", "##8", "%", "to", "12", "3", "##\\", "##/", "##4", "%", "[unused6]", "[SEP]", "[unused1]", "The", "senior", "subordinate", "##d", "de", "##bent", "##ures", "mat", "##uring", "in", "2004", "[unused2]", "[unused3]", "are", "targeted", "[unused4]", "[unused5]", "to", "be", "offered", "at", "a", "yield", "of", "between", "12", "5", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "##\\", "[SEP]"]]}

input 589:  {"source": "The share price was languishing at about 400 pence before Ford 's Sept. 19 announcement of its interest in a minority stake .\n"}
prediction:  {"predictions": [[1, 1109, 2934, 3945, 2, 3, 1108, 2495, 2118, 6592, 12802, 4, 5, 1120, 1164, 3434, 8228, 2093, 1196, 4100, 112, 1116, 20456, 28138, 1627, 8679, 1104, 1157, 2199, 1107, 170, 7309, 8219, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.017627770081162453, -0.0326838493347168, -0.03615880012512207, -0.03615880012512207, -0.03615880012512207, -0.03615880012512207, -0.03615880012512207, -0.03615880012512207, -0.03615880012512207, -0.03615880012512207], "metadata": {"source_tokens": ["The", "share", "price", "was", "la", "##ng", "##ui", "##shing", "at", "about", "400", "pen", "##ce", "before", "Ford", "'", "##s", "Sept", "##.", "19", "announcement", "of", "its", "interest", "in", "a", "minority", "stake", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "share", "price", "[unused2]", "[unused3]", "was", "la", "##ng", "##ui", "##shing", "[unused4]", "[unused5]", "at", "about", "400", "pen", "##ce", "before", "Ford", "'", "##s", "Sept", "##.", "19", "announcement", "of", "its", "interest", "in", "a", "minority", "stake", "[unused6]", "[SEP]"]]}

input 590:  {"source": "The surprise announcement came after the IRS broke off negotiations with Mr. Hunt on a settlement of the one - time tycoon 's personal bankruptcy case .\n"}
prediction:  {"predictions": [[1, 1109, 3774, 8679, 2, 3, 1338, 4, 5, 1170, 1103, 146, 8900, 2795, 1228, 7624, 1114, 1828, 28138, 7928, 1113, 170, 3433, 1104, 1103, 1141, 118, 1159, 189, 1183, 18201, 112, 1116, 2357, 11102, 1692, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 146, 8900, 2, 3, 2795, 1228, 4, 5, 7624, 1114, 1828, 28138, 7928, 1113, 170, 3433, 1104, 1103, 1141, 118, 1159, 189, 1183, 18201, 112, 1116, 2357, 11102, 1692, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00045628295629285276, -0.01027881633490324, -0.07694721221923828, -0.0769493579864502, -0.0769493579864502, -0.0769493579864502, -0.0769493579864502, -0.0769493579864502, -0.0769493579864502, -0.0769493579864502], "metadata": {"source_tokens": ["The", "surprise", "announcement", "came", "after", "the", "I", "##RS", "broke", "off", "negotiations", "with", "Mr", "##.", "Hunt", "on", "a", "settlement", "of", "the", "one", "-", "time", "t", "##y", "##coon", "'", "##s", "personal", "bankruptcy", "case", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "surprise", "announcement", "[unused2]", "[unused3]", "came", "[unused4]", "[unused5]", "after", "the", "I", "##RS", "broke", "off", "negotiations", "with", "Mr", "##.", "Hunt", "on", "a", "settlement", "of", "the", "one", "-", "time", "t", "##y", "##coon", "'", "##s", "personal", "bankruptcy", "case", "[unused6]", "[SEP]", "[unused1]", "the", "I", "##RS", "[unused2]", "[unused3]", "broke", "off", "[unused4]", "[unused5]", "negotiations", "with", "Mr", "##.", "Hunt", "on", "a", "settlement", "of", "the", "one", "-", "time", "t", "##y", "##coon", "'", "##s", "personal", "bankruptcy", "case", "[unused6]", "[SEP]"]]}

input 591:  {"source": "The tax has raised less than one billion marks ( $ 545.3 million ) annually in recent years , but the government has been reluctant to abolish the levy for budgetary concerns .\n"}
prediction:  {"predictions": [[1, 1103, 1433, 2, 3, 1144, 1151, 4, 5, 12061, 1106, 170, 15792, 2944, 1103, 5837, 7170, 1111, 4788, 3113, 5365, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 3641, 2, 3, 1144, 2120, 4, 5, 1750, 1190, 1141, 3775, 6216, 6089, 1107, 2793, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1433, 2, 3, 1106, 170, 15792, 2944, 4, 5, 1103, 5837, 7170, 1111, 4788, 3113, 5365, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 3641, 2, 3, 1144, 2120, 4, 5, 1750, 1190, 1141, 3775, 6216, 109, 4335, 1571, 28138, 1495, 1550, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.028980839997529984, -0.01343171764165163, -0.0557752326130867, -0.11051204055547714, -0.07665586471557617, -0.07665371894836426, -0.07665371894836426, -0.07665371894836426, -0.07665371894836426, -0.07665371894836426], "metadata": {"source_tokens": ["The", "tax", "has", "raised", "less", "than", "one", "billion", "marks", "(", "$", "54", "##5", "##.", "##3", "million", ")", "annually", "in", "recent", "years", ",", "but", "the", "government", "has", "been", "reluctant", "to", "a", "##bol", "##ish", "the", "le", "##vy", "for", "budget", "##ary", "concerns", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "government", "[unused2]", "[unused3]", "has", "been", "[unused4]", "[unused5]", "reluctant", "to", "a", "##bol", "##ish", "the", "le", "##vy", "for", "budget", "##ary", "concerns", "[unused6]", "[SEP]", "[unused1]", "The", "tax", "[unused2]", "[unused3]", "has", "raised", "[unused4]", "[unused5]", "less", "than", "one", "billion", "marks", "annually", "in", "recent", "years", "[unused6]", "[SEP]", "[unused1]", "the", "government", "[unused2]", "[unused3]", "to", "a", "##bol", "##ish", "[unused4]", "[unused5]", "the", "le", "##vy", "for", "budget", "##ary", "concerns", "[unused6]", "[SEP]", "[unused1]", "The", "tax", "[unused2]", "[unused3]", "has", "raised", "[unused4]", "[unused5]", "less", "than", "one", "billion", "marks", "$", "54", "##5", "##.", "##3", "million", "[unused6]", "[SEP]"]]}

input 592:  {"source": "The three existing plants and their land will be sold .\n"}
prediction:  {"predictions": [[1, 1109, 1210, 3685, 3546, 1105, 1147, 1657, 2, 3, 1209, 1129, 1962, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0012794663198292255, -0.000415802001953125, -0.00037860870361328125, -0.00037860870361328125, -0.00037860870361328125, -0.00037860870361328125, -0.00037860870361328125, -0.00037860870361328125, -0.00037860870361328125, -0.00037860870361328125], "metadata": {"source_tokens": ["The", "three", "existing", "plants", "and", "their", "land", "will", "be", "sold", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "three", "existing", "plants", "and", "their", "land", "[unused2]", "[unused3]", "will", "be", "sold", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 593:  {"source": "The two leaders are expected to discuss changes sweeping the East bloc as well as human - rights issues , regional disputes and economic cooperation .\n"}
prediction:  {"predictions": [[1, 1109, 1160, 3478, 2, 3, 1132, 2637, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1160, 3478, 2, 3, 1106, 6265, 4, 5, 2607, 13194, 1103, 1689, 171, 27089, 1112, 1218, 1112, 1769, 118, 2266, 2492, 117, 2918, 12530, 1105, 2670, 7395, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.014553070068359375, -0.02219454012811184, -0.07633209228515625, -0.07633090019226074, -0.07633090019226074, -0.07633090019226074, -0.07633090019226074, -0.07633090019226074, -0.07633090019226074, -0.07633090019226074], "metadata": {"source_tokens": ["The", "two", "leaders", "are", "expected", "to", "discuss", "changes", "sweeping", "the", "East", "b", "##loc", "as", "well", "as", "human", "-", "rights", "issues", ",", "regional", "disputes", "and", "economic", "cooperation", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "two", "leaders", "[unused2]", "[unused3]", "are", "expected", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "The", "two", "leaders", "[unused2]", "[unused3]", "to", "discuss", "[unused4]", "[unused5]", "changes", "sweeping", "the", "East", "b", "##loc", "as", "well", "as", "human", "-", "rights", "issues", ",", "regional", "disputes", "and", "economic", "cooperation", "[unused6]", "[SEP]"]]}

input 594:  {"source": "The two sides are also discussing certain business ventures involving cable rights to Columbia 's movies .\n"}
prediction:  {"predictions": [[1, 1109, 1160, 3091, 2, 3, 1132, 1145, 10751, 4, 5, 2218, 1671, 20135, 5336, 6095, 2266, 1106, 3132, 112, 1116, 5558, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2218, 1671, 20135, 2, 3, 5336, 4, 5, 6095, 2266, 1106, 3132, 112, 1116, 5558, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.019140323624014854, -0.19136273860931396, -0.03336544334888458, -0.00160980224609375, -0.0020055770874023438, -0.0020055770874023438, -0.0020055770874023438, -0.0020055770874023438, -0.0020055770874023438, -0.0020055770874023438], "metadata": {"source_tokens": ["The", "two", "sides", "are", "also", "discussing", "certain", "business", "ventures", "involving", "cable", "rights", "to", "Columbia", "'", "##s", "movies", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "two", "sides", "[unused2]", "[unused3]", "are", "also", "discussing", "[unused4]", "[unused5]", "certain", "business", "ventures", "involving", "cable", "rights", "to", "Columbia", "'", "##s", "movies", "[unused6]", "[SEP]"]]}

input 595:  {"source": "There 's light at the end of the tunnel for municipals , '' he said , adding that he expects prices to `` inch up '' in the near term .\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 1163, 4, 5, 5321, 1115, 1119, 27402, 7352, 1106, 169, 28152, 4305, 1146, 112, 28131, 1107, 1103, 1485, 1858, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 27402, 4, 5, 7352, 1106, 4305, 1146, 1107, 1103, 1485, 1858, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02550032176077366, -0.055795032531023026, -0.19627094268798828, -0.20498108863830566, -0.20498108863830566, -0.20498108863830566, -0.20498108863830566, -0.20498108863830566, -0.20498108863830566, -0.20498108863830566], "metadata": {"source_tokens": ["There", "'", "##s", "light", "at", "the", "end", "of", "the", "tunnel", "for", "municipal", "##s", ",", "'", "##'", "he", "said", ",", "adding", "that", "he", "expects", "prices", "to", "`", "##`", "inch", "up", "'", "##'", "in", "the", "near", "term", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "adding", "that", "he", "expects", "prices", "to", "`", "##`", "inch", "up", "'", "##'", "in", "the", "near", "term", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "expects", "[unused4]", "[unused5]", "prices", "to", "inch", "up", "in", "the", "near", "term", "[unused6]", "[SEP]"]]}

input 596:  {"source": "They claim to have busted spirits , poltergeists and other spooks in hundreds of houses around the country .\n"}
prediction:  {"predictions": [[1, 1220, 2, 3, 3548, 4, 5, 1106, 1138, 16118, 1174, 9494, 117, 185, 17772, 1200, 2176, 3681, 1105, 1168, 188, 5674, 5926, 1116, 1107, 5229, 1104, 2725, 1213, 1103, 1583, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.015017892234027386, -0.03221583366394043, -0.032208919525146484, -0.032208919525146484, -0.032208919525146484, -0.032208919525146484, -0.032208919525146484, -0.032208919525146484, -0.032208919525146484, -0.032208919525146484], "metadata": {"source_tokens": ["They", "claim", "to", "have", "bust", "##ed", "spirits", ",", "p", "##olt", "##er", "##ge", "##ists", "and", "other", "s", "##po", "##ok", "##s", "in", "hundreds", "of", "houses", "around", "the", "country", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "They", "[unused2]", "[unused3]", "claim", "[unused4]", "[unused5]", "to", "have", "bust", "##ed", "spirits", ",", "p", "##olt", "##er", "##ge", "##ists", "and", "other", "s", "##po", "##ok", "##s", "in", "hundreds", "of", "houses", "around", "the", "country", "[unused6]", "[SEP]"]]}

input 597:  {"source": "This involves trade - offs and { it } cuts against the grain of existing consumer and even provider conceptions of what is ` necessary . ' ''\n"}
prediction:  {"predictions": [[1, 1188, 2, 3, 6808, 4, 5, 2597, 118, 12822, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1122, 2, 3, 7484, 4, 5, 1222, 1103, 9478, 1104, 3685, 8440, 1105, 1256, 11482, 17890, 1116, 1104, 1184, 1110, 3238, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.020455041900277138, -0.011114831082522869, -0.07661318778991699, -0.07660245895385742, -0.07660245895385742, -0.07660245895385742, -0.07660245895385742, -0.07660245895385742, -0.07660245895385742, -0.07660245895385742], "metadata": {"source_tokens": ["This", "involves", "trade", "-", "offs", "and", "{", "it", "}", "cuts", "against", "the", "grain", "of", "existing", "consumer", "and", "even", "provider", "conception", "##s", "of", "what", "is", "`", "necessary", ".", "'", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "[unused2]", "[unused3]", "involves", "[unused4]", "[unused5]", "trade", "-", "offs", "[unused6]", "[SEP]", "[unused1]", "it", "[unused2]", "[unused3]", "cuts", "[unused4]", "[unused5]", "against", "the", "grain", "of", "existing", "consumer", "and", "even", "provider", "conception", "##s", "of", "what", "is", "necessary", "[unused6]", "[SEP]"]]}

input 598:  {"source": "This is the U.N. group that managed to traduce its own charter of promoting education , science and culture .\n"}
prediction:  {"predictions": [[1, 1188, 2, 3, 1110, 4, 5, 1103, 158, 28138, 2249, 28138, 1372, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 158, 28138, 2249, 28138, 1372, 2, 3, 2374, 1106, 189, 9871, 15776, 4, 5, 1157, 1319, 7394, 1104, 7495, 1972, 117, 2598, 1105, 2754, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.010416285134851933, -0.02869962342083454, -0.022036075592041016, -0.022035598754882812, -0.022035598754882812, -0.022035598754882812, -0.022035598754882812, -0.022035598754882812, -0.022035598754882812, -0.022035598754882812], "metadata": {"source_tokens": ["This", "is", "the", "U", "##.", "##N", "##.", "group", "that", "managed", "to", "t", "##rad", "##uce", "its", "own", "charter", "of", "promoting", "education", ",", "science", "and", "culture", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "the", "U", "##.", "##N", "##.", "group", "[unused6]", "[SEP]", "[unused1]", "the", "U", "##.", "##N", "##.", "group", "[unused2]", "[unused3]", "managed", "to", "t", "##rad", "##uce", "[unused4]", "[unused5]", "its", "own", "charter", "of", "promoting", "education", ",", "science", "and", "culture", "[unused6]", "[SEP]"]]}

input 599:  {"source": "This provision met early and strong resistance from investment bankers worried about disruptions in their clients ' portfolios .\n"}
prediction:  {"predictions": [[1, 1188, 9348, 2, 3, 1899, 4, 5, 1346, 1105, 2012, 4789, 1121, 5151, 15304, 1116, 4472, 1164, 23730, 1116, 1107, 1147, 7550, 112, 12256, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1346, 1105, 2012, 4789, 1121, 5151, 15304, 1116, 2, 3, 4472, 4, 5, 1164, 23730, 1116, 1107, 1147, 7550, 12256, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00468809250742197, -0.06064258888363838, -0.02201223373413086, -0.022012710571289062, -0.022012710571289062, -0.022012710571289062, -0.022012710571289062, -0.022012710571289062, -0.022012710571289062, -0.022012710571289062], "metadata": {"source_tokens": ["This", "provision", "met", "early", "and", "strong", "resistance", "from", "investment", "banker", "##s", "worried", "about", "disruption", "##s", "in", "their", "clients", "'", "portfolio", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "This", "provision", "[unused2]", "[unused3]", "met", "[unused4]", "[unused5]", "early", "and", "strong", "resistance", "from", "investment", "banker", "##s", "worried", "about", "disruption", "##s", "in", "their", "clients", "'", "portfolio", "##s", "[unused6]", "[SEP]", "[unused1]", "early", "and", "strong", "resistance", "from", "investment", "banker", "##s", "[unused2]", "[unused3]", "worried", "[unused4]", "[unused5]", "about", "disruption", "##s", "in", "their", "clients", "portfolio", "##s", "[unused6]", "[SEP]"]]}

input 600:  {"source": "This week , New York City announced a 10 - point policy patterned on the federal bill of rights for taxpayers .\n"}
prediction:  {"predictions": [[1, 1203, 1365, 1392, 2, 3, 1717, 4, 5, 170, 1275, 118, 1553, 2818, 4844, 1174, 1113, 1103, 2877, 4550, 1104, 2266, 1111, 3641, 27452, 1188, 1989, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1275, 118, 1553, 2818, 2, 3, 4844, 1174, 4, 5, 1113, 1103, 2877, 4550, 1104, 2266, 1111, 3641, 27452, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0011885083513334394, -0.0034133351873606443, -0.07662367820739746, -0.07662296295166016, -0.07662296295166016, -0.07662296295166016, -0.07662296295166016, -0.07662296295166016, -0.07662296295166016, -0.07662296295166016], "metadata": {"source_tokens": ["This", "week", ",", "New", "York", "City", "announced", "a", "10", "-", "point", "policy", "pattern", "##ed", "on", "the", "federal", "bill", "of", "rights", "for", "tax", "##payers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "New", "York", "City", "[unused2]", "[unused3]", "announced", "[unused4]", "[unused5]", "a", "10", "-", "point", "policy", "pattern", "##ed", "on", "the", "federal", "bill", "of", "rights", "for", "tax", "##payers", "This", "week", "[unused6]", "[SEP]", "[unused1]", "a", "10", "-", "point", "policy", "[unused2]", "[unused3]", "pattern", "##ed", "[unused4]", "[unused5]", "on", "the", "federal", "bill", "of", "rights", "for", "tax", "##payers", "[unused6]", "[SEP]"]]}

input 601:  {"source": "Though Mr. Packer has since sold his stake , Courtaulds is moving to keep its institutional shareholders happy .\n"}
prediction:  {"predictions": [[1, 2031, 18318, 3680, 2, 3, 1110, 2232, 4, 5, 1106, 1712, 1157, 15040, 16741, 2816, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 14667, 1200, 2, 3, 1144, 1962, 4, 5, 1117, 8219, 1290, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.042576827108860016, -0.00529654324054718, -0.04114818572998047, -0.041616201400756836, -0.041616201400756836, -0.041616201400756836, -0.041616201400756836, -0.041616201400756836, -0.041616201400756836, -0.041616201400756836], "metadata": {"source_tokens": ["Though", "Mr", "##.", "Pack", "##er", "has", "since", "sold", "his", "stake", ",", "Court", "##aul", "##ds", "is", "moving", "to", "keep", "its", "institutional", "shareholders", "happy", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Court", "##aul", "##ds", "[unused2]", "[unused3]", "is", "moving", "[unused4]", "[unused5]", "to", "keep", "its", "institutional", "shareholders", "happy", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "Pack", "##er", "[unused2]", "[unused3]", "has", "sold", "[unused4]", "[unused5]", "his", "stake", "since", "[unused6]", "[SEP]"]]}

input 602:  {"source": "To avoid a runoff , one candidate would have to win 50 % of the vote -- a feat that most analysts consider impossible with so many candidates running .\n"}
prediction:  {"predictions": [[1, 1177, 1242, 4765, 2, 3, 1919, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1141, 3234, 2, 3, 1106, 1782, 4, 5, 1851, 110, 1104, 1103, 2992, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1211, 22018, 2, 3, 4615, 4, 5, 4763, 1114, 1177, 1242, 4765, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.048334814608097076, -0.03821290284395218, -0.11196012049913406, -0.3191337585449219, -0.3355743885040283, -0.3355743885040283, -0.3355743885040283, -0.3355743885040283, -0.3355743885040283, -0.3355743885040283], "metadata": {"source_tokens": ["To", "avoid", "a", "runoff", ",", "one", "candidate", "would", "have", "to", "win", "50", "%", "of", "the", "vote", "-", "##-", "a", "feat", "that", "most", "analysts", "consider", "impossible", "with", "so", "many", "candidates", "running", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "so", "many", "candidates", "[unused2]", "[unused3]", "running", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "one", "candidate", "[unused2]", "[unused3]", "to", "win", "[unused4]", "[unused5]", "50", "%", "of", "the", "vote", "[unused6]", "[SEP]", "[unused1]", "most", "analysts", "[unused2]", "[unused3]", "consider", "[unused4]", "[unused5]", "impossible", "with", "so", "many", "candidates", "[unused6]", "[SEP]"]]}

input 603:  {"source": "To increase their share of that business , jewelry makers such as Crystal Brands Inc. 's Trifari and Monet units and Swank Inc. , maker of Anne Klein jewelry , are launching new lines with as much fanfare as the fragrance companies .\n"}
prediction:  {"predictions": [[1, 12731, 12525, 1216, 1112, 9048, 12381, 1116, 3561, 28138, 112, 1116, 18491, 21975, 1105, 22401, 2105, 2338, 1105, 11956, 1377, 3561, 2, 3, 1132, 12611, 4, 5, 1207, 2442, 1114, 1112, 1277, 5442, 14154, 1112, 1103, 175, 20484, 10555, 2557, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12731, 12525, 1216, 1112, 9048, 12381, 1116, 3561, 28138, 112, 1116, 18491, 21975, 1105, 22401, 2105, 2338, 1105, 11956, 1377, 3561, 2, 3, 1132, 12611, 4, 5, 1207, 2442, 1706, 2773, 1147, 2934, 1104, 1115, 1671, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12731, 12525, 1216, 1112, 9048, 12381, 1116, 3561, 28138, 112, 1116, 18491, 21975, 1105, 22401, 2105, 2338, 1105, 11956, 1377, 3561, 28138, 2, 3, 1110, 4, 5, 11166, 1104, 3967, 12782, 12731, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.029603445902466774, -0.07597390562295914, -0.09923909604549408, -0.18591749668121338, -0.2062145471572876, -0.2062145471572876, -0.2062145471572876, -0.2062145471572876, -0.2062145471572876, -0.2062145471572876], "metadata": {"source_tokens": ["To", "increase", "their", "share", "of", "that", "business", ",", "jewelry", "makers", "such", "as", "Crystal", "Brand", "##s", "Inc", "##.", "'", "##s", "Tri", "##fari", "and", "Mon", "##et", "units", "and", "Swan", "##k", "Inc", "##.", ",", "maker", "of", "Anne", "Klein", "jewelry", ",", "are", "launching", "new", "lines", "with", "as", "much", "fan", "##fare", "as", "the", "f", "##rag", "##rance", "companies", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "jewelry", "makers", "such", "as", "Crystal", "Brand", "##s", "Inc", "##.", "'", "##s", "Tri", "##fari", "and", "Mon", "##et", "units", "and", "Swan", "##k", "Inc", "[unused2]", "[unused3]", "are", "launching", "[unused4]", "[unused5]", "new", "lines", "with", "as", "much", "fan", "##fare", "as", "the", "f", "##rag", "##rance", "companies", "[unused6]", "[SEP]", "[unused1]", "jewelry", "makers", "such", "as", "Crystal", "Brand", "##s", "Inc", "##.", "'", "##s", "Tri", "##fari", "and", "Mon", "##et", "units", "and", "Swan", "##k", "Inc", "[unused2]", "[unused3]", "are", "launching", "[unused4]", "[unused5]", "new", "lines", "To", "increase", "their", "share", "of", "that", "business", "[unused6]", "[SEP]", "[unused1]", "jewelry", "makers", "such", "as", "Crystal", "Brand", "##s", "Inc", "##.", "'", "##s", "Tri", "##fari", "and", "Mon", "##et", "units", "and", "Swan", "##k", "Inc", "##.", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "maker", "of", "Anne", "Klein", "jewelry", "[unused6]", "[SEP]"]]}

input 604:  {"source": "To make them directly comparable , each index is based on the close of 1969 equaling 100 .\n"}
prediction:  {"predictions": [[1, 1296, 7448, 2, 3, 1110, 1359, 4, 5, 1113, 1103, 1601, 1104, 2540, 4463, 1158, 1620, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0004169064050074667, -0.009124755859375, -0.00928497314453125, -0.00928497314453125, -0.00928497314453125, -0.00928497314453125, -0.00928497314453125, -0.00928497314453125, -0.00928497314453125, -0.00928497314453125], "metadata": {"source_tokens": ["To", "make", "them", "directly", "comparable", ",", "each", "index", "is", "based", "on", "the", "close", "of", "1969", "equal", "##ing", "100", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "each", "index", "[unused2]", "[unused3]", "is", "based", "[unused4]", "[unused5]", "on", "the", "close", "of", "1969", "equal", "##ing", "100", "[unused6]", "[SEP]"]]}

input 605:  {"source": "To my knowledge , no government entities , including the EPA , are pursuing UV - B measurements .\n"}
prediction:  {"predictions": [[1, 1185, 1433, 11659, 117, 1259, 1103, 20875, 2, 3, 1132, 12137, 4, 5, 26331, 118, 139, 12307, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0034122944343835115, -0.0106201171875, -0.011664390563964844, -0.011664390563964844, -0.011664390563964844, -0.011664390563964844, -0.011664390563964844, -0.011664390563964844, -0.011664390563964844, -0.011664390563964844], "metadata": {"source_tokens": ["To", "my", "knowledge", ",", "no", "government", "entities", ",", "including", "the", "EPA", ",", "are", "pursuing", "UV", "-", "B", "measurements", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "no", "government", "entities", ",", "including", "the", "EPA", "[unused2]", "[unused3]", "are", "pursuing", "[unused4]", "[unused5]", "UV", "-", "B", "measurements", "[unused6]", "[SEP]"]]}

input 606:  {"source": "Tom Panelli had a perfectly good reason for not using the $ 300 rowing machine he bought three years ago .\n"}
prediction:  {"predictions": [[1, 2545, 20339, 2646, 2, 3, 1125, 4, 5, 170, 6150, 1363, 2255, 1111, 1136, 1606, 1103, 109, 3127, 18656, 3395, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 109, 3127, 18656, 3395, 2, 3, 3306, 4, 5, 1210, 1201, 2403, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.012419575825333595, -0.02573574334383011, -0.02200174331665039, -0.022003650665283203, -0.022003650665283203, -0.022003650665283203, -0.022003650665283203, -0.022003650665283203, -0.022003650665283203, -0.022003650665283203], "metadata": {"source_tokens": ["Tom", "Panel", "##li", "had", "a", "perfectly", "good", "reason", "for", "not", "using", "the", "$", "300", "rowing", "machine", "he", "bought", "three", "years", "ago", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Tom", "Panel", "##li", "[unused2]", "[unused3]", "had", "[unused4]", "[unused5]", "a", "perfectly", "good", "reason", "for", "not", "using", "the", "$", "300", "rowing", "machine", "[unused6]", "[SEP]", "[unused1]", "the", "$", "300", "rowing", "machine", "[unused2]", "[unused3]", "bought", "[unused4]", "[unused5]", "three", "years", "ago", "[unused6]", "[SEP]"]]}

input 607:  {"source": "U.S. makers have under 10 % share , compared with half the market in Europe and 80 % at home .\n"}
prediction:  {"predictions": [[1, 158, 28138, 1708, 28138, 12525, 2, 3, 1138, 4, 5, 1223, 1275, 110, 2934, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 158, 28138, 1708, 28138, 12525, 2, 3, 1138, 4, 5, 1223, 1275, 110, 2934, 3402, 1114, 1544, 1103, 2319, 1107, 1980, 1105, 2908, 110, 1120, 1313, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006889960262924433, -0.007489105686545372, -0.0406491756439209, -0.04217648506164551, -0.04217648506164551, -0.04217648506164551, -0.04217648506164551, -0.04217648506164551, -0.04217648506164551, -0.04217648506164551], "metadata": {"source_tokens": ["U", "##.", "##S", "##.", "makers", "have", "under", "10", "%", "share", ",", "compared", "with", "half", "the", "market", "in", "Europe", "and", "80", "%", "at", "home", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "U", "##.", "##S", "##.", "makers", "[unused2]", "[unused3]", "have", "[unused4]", "[unused5]", "under", "10", "%", "share", "[unused6]", "[SEP]", "[unused1]", "U", "##.", "##S", "##.", "makers", "[unused2]", "[unused3]", "have", "[unused4]", "[unused5]", "under", "10", "%", "share", "compared", "with", "half", "the", "market", "in", "Europe", "and", "80", "%", "at", "home", "[unused6]", "[SEP]"]]}

input 608:  {"source": "USG Corp. agreed to sell its headquarters building here to Manufacturers Life Insurance Co. of Toronto , and will lease the 19 - story facility until it moves to a new quarters in 1992 .\n"}
prediction:  {"predictions": [[1, 1646, 2349, 13619, 2, 3, 2675, 4, 5, 1106, 4582, 1157, 3834, 1459, 1303, 1106, 2268, 16205, 11179, 24990, 2583, 11037, 3291, 28138, 1104, 3506, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1646, 2349, 13619, 28138, 2, 3, 1209, 10549, 4, 5, 1103, 1627, 118, 1642, 3695, 1235, 1122, 5279, 1106, 170, 1207, 7541, 1107, 1924, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1646, 2349, 13619, 28138, 2, 3, 1209, 10549, 4, 5, 1103, 1627, 1642, 3695, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1646, 2349, 13619, 28138, 2, 3, 2675, 4, 5, 1106, 4582, 1157, 3834, 1459, 1303, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1646, 2349, 13619, 28138, 2, 3, 2675, 4, 5, 1106, 4582, 1157, 3834, 1459, 1303, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0426083579659462, -0.06089635565876961, -0.16403935849666595, -0.17064303159713745, -0.20117124915122986, -0.2866332530975342, -0.2865588665008545, -0.2865588665008545, -0.2865588665008545, -0.2865588665008545], "metadata": {"source_tokens": ["US", "##G", "Corp", "##.", "agreed", "to", "sell", "its", "headquarters", "building", "here", "to", "Man", "##uf", "##act", "##urers", "Life", "Insurance", "Co", "##.", "of", "Toronto", ",", "and", "will", "lease", "the", "19", "-", "story", "facility", "until", "it", "moves", "to", "a", "new", "quarters", "in", "1992", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "US", "##G", "Corp", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "sell", "its", "headquarters", "building", "here", "to", "Man", "##uf", "##act", "##urers", "Life", "Insurance", "Co", "##.", "of", "Toronto", "[unused6]", "[SEP]", "[unused1]", "US", "##G", "Corp", "##.", "[unused2]", "[unused3]", "will", "lease", "[unused4]", "[unused5]", "the", "19", "-", "story", "facility", "until", "it", "moves", "to", "a", "new", "quarters", "in", "1992", "[unused6]", "[SEP]", "[unused1]", "US", "##G", "Corp", "##.", "[unused2]", "[unused3]", "will", "lease", "[unused4]", "[unused5]", "the", "19", "story", "facility", "[unused6]", "[SEP]", "[unused1]", "US", "##G", "Corp", "##.", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "sell", "its", "headquarters", "building", "here", "[unused6]", "[SEP]", "[unused1]", "US", "##G", "Corp", "##.", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "sell", "its", "headquarters", "building", "here", "[unused6]", "[SEP]"]]}

input 609:  {"source": "Under a merger agreement reached Sept. 14 , the UAL board agreed to reimburse certain of the buy - out group 's expenses out of company funds even if the transaction was n't completed , provided the group did n't breach the agreement .\n"}
prediction:  {"predictions": [[1, 1103, 158, 12507, 2313, 2, 3, 2675, 4, 5, 1106, 1231, 4060, 19364, 2217, 2218, 1104, 1103, 4417, 118, 1149, 1372, 112, 1116, 11928, 1149, 1104, 1419, 4381, 1256, 1191, 1103, 13618, 1108, 183, 28131, 1204, 2063, 2831, 170, 7256, 3311, 1680, 20456, 28138, 1489, 6, 102, 102, 102, 102, 1, 1103, 158, 12507, 2313, 2, 3, 2675, 4, 5, 1106, 1231, 4060, 19364, 2217, 2218, 1104, 1103, 4417, 118, 1149, 1372, 112, 1116, 11928, 1256, 1191, 1103, 13618, 1108, 183, 28131, 1204, 2063, 2136, 1103, 1372, 1225, 183, 28131, 1204, 13275, 1103, 3311, 6, 102, 102, 102, 102, 102, 102, 1, 1103, 158, 12507, 2313, 2, 3, 2675, 4, 5, 1106, 1231, 4060, 19364, 2217, 2218, 1104, 1103, 4417, 118, 1149, 1372, 112, 1116, 11928, 1149, 1104, 1419, 4381, 1256, 1191, 1103, 13618, 1108, 183, 28131, 1204, 2063, 2136, 1103, 1372, 1225, 183, 28131, 1204, 13275, 1103, 3311, 6, 102, 102, 1, 1103, 158, 12507, 2313, 2, 3, 2675, 4, 5, 1106, 1231, 4060, 19364, 2217, 2218, 1104, 1103, 4417, 118, 1149, 1372, 112, 1116, 11928, 1149, 1104, 1419, 4381, 1256, 1191, 1103, 13618, 1108, 183, 28131, 1204, 2063, 2136, 1103, 1372, 1225, 183, 28131, 1204, 13275, 1103, 3311, 6, 102, 102, 1, 1103, 158, 12507, 2313, 2, 3, 2675, 4, 5, 1106, 1231, 4060, 19364, 2217, 2218, 1104, 1103, 4417, 118, 1149, 1372, 112, 1116, 11928, 1149, 1104, 1419, 4381, 1256, 1191, 1103, 13618, 1108, 183, 28131, 1204, 2063, 2136, 1103, 1372, 1225, 183, 28131, 1204, 13275, 1103, 3311, 2831, 170, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04124568775296211, -0.07848212122917175, -0.09521300345659256, -0.10587123781442642, -0.10383982956409454, -0.33864283561706543, -0.34514904022216797, -0.34514904022216797, -0.34514904022216797, -0.34514904022216797], "metadata": {"source_tokens": ["Under", "a", "merger", "agreement", "reached", "Sept", "##.", "14", ",", "the", "U", "##AL", "board", "agreed", "to", "re", "##im", "##bur", "##se", "certain", "of", "the", "buy", "-", "out", "group", "'", "##s", "expenses", "out", "of", "company", "funds", "even", "if", "the", "transaction", "was", "n", "##'", "##t", "completed", ",", "provided", "the", "group", "did", "n", "##'", "##t", "breach", "the", "agreement", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "U", "##AL", "board", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "re", "##im", "##bur", "##se", "certain", "of", "the", "buy", "-", "out", "group", "'", "##s", "expenses", "out", "of", "company", "funds", "even", "if", "the", "transaction", "was", "n", "##'", "##t", "completed", "Under", "a", "merger", "agreement", "reached", "Sept", "##.", "14", "[unused6]", "[SEP]", "[unused1]", "the", "U", "##AL", "board", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "re", "##im", "##bur", "##se", "certain", "of", "the", "buy", "-", "out", "group", "'", "##s", "expenses", "even", "if", "the", "transaction", "was", "n", "##'", "##t", "completed", "provided", "the", "group", "did", "n", "##'", "##t", "breach", "the", "agreement", "[unused6]", "[SEP]", "[unused1]", "the", "U", "##AL", "board", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "re", "##im", "##bur", "##se", "certain", "of", "the", "buy", "-", "out", "group", "'", "##s", "expenses", "out", "of", "company", "funds", "even", "if", "the", "transaction", "was", "n", "##'", "##t", "completed", "provided", "the", "group", "did", "n", "##'", "##t", "breach", "the", "agreement", "[unused6]", "[SEP]", "[unused1]", "the", "U", "##AL", "board", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "re", "##im", "##bur", "##se", "certain", "of", "the", "buy", "-", "out", "group", "'", "##s", "expenses", "out", "of", "company", "funds", "even", "if", "the", "transaction", "was", "n", "##'", "##t", "completed", "provided", "the", "group", "did", "n", "##'", "##t", "breach", "the", "agreement", "[unused6]", "[SEP]", "[unused1]", "the", "U", "##AL", "board", "[unused2]", "[unused3]", "agreed", "[unused4]", "[unused5]", "to", "re", "##im", "##bur", "##se", "certain", "of", "the", "buy", "-", "out", "group", "'", "##s", "expenses", "out", "of", "company", "funds", "even", "if", "the", "transaction", "was", "n", "##'", "##t", "completed", "provided", "the", "group", "did", "n", "##'", "##t", "breach", "the", "agreement", "Under", "a", "[SEP]"]]}

input 610:  {"source": "Under the debt - equity program , potential investors will submit sealed bids on the percentage of discount they are willing to purchase the debt at , and the bids will be allocated based on these discount offers .\n"}
prediction:  {"predictions": [[1, 3209, 9660, 2, 3, 1209, 12295, 4, 5, 10410, 23733, 1113, 1103, 6556, 1104, 23290, 2831, 1103, 6695, 118, 12288, 1788, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 23733, 2, 3, 1209, 1129, 11117, 4, 5, 1359, 1113, 1292, 23290, 3272, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1152, 2, 3, 1132, 4, 5, 4988, 1106, 4779, 1103, 6695, 1120, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0218446496874094, -0.059652600437402725, -0.03778757154941559, -0.15345501899719238, -0.1737734079360962, -0.17377352714538574, -0.17377352714538574, -0.17377352714538574, -0.17377352714538574, -0.17377352714538574], "metadata": {"source_tokens": ["Under", "the", "debt", "-", "equity", "program", ",", "potential", "investors", "will", "submit", "sealed", "bids", "on", "the", "percentage", "of", "discount", "they", "are", "willing", "to", "purchase", "the", "debt", "at", ",", "and", "the", "bids", "will", "be", "allocated", "based", "on", "these", "discount", "offers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "potential", "investors", "[unused2]", "[unused3]", "will", "submit", "[unused4]", "[unused5]", "sealed", "bids", "on", "the", "percentage", "of", "discount", "Under", "the", "debt", "-", "equity", "program", "[unused6]", "[SEP]", "[unused1]", "the", "bids", "[unused2]", "[unused3]", "will", "be", "allocated", "[unused4]", "[unused5]", "based", "on", "these", "discount", "offers", "[unused6]", "[SEP]", "[unused1]", "they", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "willing", "to", "purchase", "the", "debt", "at", "[unused6]", "[SEP]"]]}

input 611:  {"source": "Unemployment has reached 27.6 % in Azerbaijan , 25.7 % in Tadzhikistan , 22.8 % in Uzbekistan , 18.8 % in Turkmenia , 18 % in Armenia and 16.3 % in Kirgizia , the Communist Party newspaper said .\n"}
prediction:  {"predictions": [[1, 12118, 5521, 1643, 26179, 1880, 2, 3, 1144, 1680, 4, 5, 1765, 28138, 1545, 110, 1107, 7955, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 5248, 1786, 3054, 2, 3, 1163, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12118, 5521, 1643, 26179, 1880, 2, 3, 1144, 1680, 4, 5, 1765, 28138, 1545, 110, 1107, 7955, 1512, 28138, 1559, 110, 1107, 26741, 23239, 15860, 5108, 1659, 28138, 1604, 110, 1107, 18245, 1407, 28138, 1604, 110, 1107, 17037, 4661, 2354, 1465, 1407, 110, 1107, 9917, 1105, 1479, 28138, 1495, 102, 1, 12118, 5521, 1643, 26179, 1880, 2, 3, 1144, 1680, 4, 5, 1765, 28138, 1545, 110, 1107, 7955, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12118, 5521, 1643, 26179, 1880, 2, 3, 1144, 1680, 4, 5, 1765, 28138, 1545, 110, 1107, 7955, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12118, 5521, 1643, 26179, 1880, 2, 3, 1144, 1680, 4, 5, 1765, 28138, 1545, 110, 1107, 7955, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 12118, 5521, 1643, 26179, 1880, 2, 3, 1144, 1680, 4, 5, 1765, 28138, 1545, 110, 1107, 7955, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06912877410650253, -0.08410006761550903, -0.07207734137773514, -0.15802906453609467, -0.16173018515110016, -0.18533873558044434, -0.19104953110218048, -0.2126922607421875, -0.21278321743011475, -0.21278321743011475], "metadata": {"source_tokens": ["Un", "##em", "##p", "##loy", "##ment", "has", "reached", "27", "##.", "##6", "%", "in", "Azerbaijan", ",", "25", "##.", "##7", "%", "in", "Tad", "##zhi", "##kis", "##tan", ",", "22", "##.", "##8", "%", "in", "Uzbekistan", ",", "18", "##.", "##8", "%", "in", "Tu", "##rk", "##men", "##ia", ",", "18", "%", "in", "Armenia", "and", "16", "##.", "##3", "%", "in", "Ki", "##rg", "##iz", "##ia", ",", "the", "Communist", "Party", "newspaper", "said", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Un", "##em", "##p", "##loy", "##ment", "[unused2]", "[unused3]", "has", "reached", "[unused4]", "[unused5]", "27", "##.", "##6", "%", "in", "Azerbaijan", "[unused6]", "[SEP]", "[unused1]", "the", "Communist", "Party", "newspaper", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "Un", "##em", "##p", "##loy", "##ment", "[unused2]", "[unused3]", "has", "reached", "[unused4]", "[unused5]", "27", "##.", "##6", "%", "in", "Azerbaijan", "25", "##.", "##7", "%", "in", "Tad", "##zhi", "##kis", "##tan", "22", "##.", "##8", "%", "in", "Uzbekistan", "18", "##.", "##8", "%", "in", "Tu", "##rk", "##men", "##ia", "18", "%", "in", "Armenia", "and", "16", "##.", "##3", "[SEP]", "[unused1]", "Un", "##em", "##p", "##loy", "##ment", "[unused2]", "[unused3]", "has", "reached", "[unused4]", "[unused5]", "27", "##.", "##6", "%", "in", "Azerbaijan", "[unused6]", "[SEP]", "[unused1]", "Un", "##em", "##p", "##loy", "##ment", "[unused2]", "[unused3]", "has", "reached", "[unused4]", "[unused5]", "27", "##.", "##6", "%", "in", "Azerbaijan", "[unused6]", "[SEP]", "[unused1]", "Un", "##em", "##p", "##loy", "##ment", "[unused2]", "[unused3]", "has", "reached", "[unused4]", "[unused5]", "27", "##.", "##6", "%", "in", "Azerbaijan", "[unused6]", "[SEP]", "[unused1]", "Un", "##em", "##p", "##loy", "##ment", "[unused2]", "[unused3]", "has", "reached", "[unused4]", "[unused5]", "27", "##.", "##6", "%", "in", "Azerbaijan", "[unused6]", "[SEP]"]]}

input 612:  {"source": "Vernon E. Jordan was elected to the board of this transportation services concern .\n"}
prediction:  {"predictions": [[1, 11459, 142, 28138, 4421, 2, 3, 1108, 1809, 4, 5, 1106, 1103, 2313, 1104, 1142, 6312, 1826, 4517, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00021121616009622812, -0.0002865791320800781, -0.000316619873046875, -0.000316619873046875, -0.000316619873046875, -0.000316619873046875, -0.000316619873046875, -0.000316619873046875, -0.000316619873046875, -0.000316619873046875], "metadata": {"source_tokens": ["Vernon", "E", "##.", "Jordan", "was", "elected", "to", "the", "board", "of", "this", "transportation", "services", "concern", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Vernon", "E", "##.", "Jordan", "[unused2]", "[unused3]", "was", "elected", "[unused4]", "[unused5]", "to", "the", "board", "of", "this", "transportation", "services", "concern", "[unused6]", "[SEP]"]]}

input 613:  {"source": "Warner Communications Inc. , which is being acquired by Time Warner , has filed a $ 1 billion breach - of - contract suit against Sony and the two producers .\n"}
prediction:  {"predictions": [[1, 6049, 6345, 3561, 2, 3, 1110, 1217, 2888, 4, 5, 1118, 2614, 6049, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6049, 6345, 3561, 28138, 2, 3, 1144, 5770, 4, 5, 170, 109, 122, 3775, 13275, 118, 1104, 118, 2329, 4228, 1222, 8028, 1105, 1103, 1160, 6419, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.038587652146816254, -0.0393281914293766, -0.07633137702941895, -0.07633042335510254, -0.07633042335510254, -0.07633042335510254, -0.07633042335510254, -0.07633042335510254, -0.07633042335510254, -0.07633042335510254], "metadata": {"source_tokens": ["Warner", "Communications", "Inc", "##.", ",", "which", "is", "being", "acquired", "by", "Time", "Warner", ",", "has", "filed", "a", "$", "1", "billion", "breach", "-", "of", "-", "contract", "suit", "against", "Sony", "and", "the", "two", "producers", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Warner", "Communications", "Inc", "[unused2]", "[unused3]", "is", "being", "acquired", "[unused4]", "[unused5]", "by", "Time", "Warner", "[unused6]", "[SEP]", "[unused1]", "Warner", "Communications", "Inc", "##.", "[unused2]", "[unused3]", "has", "filed", "[unused4]", "[unused5]", "a", "$", "1", "billion", "breach", "-", "of", "-", "contract", "suit", "against", "Sony", "and", "the", "two", "producers", "[unused6]", "[SEP]"]]}

input 614:  {"source": "Warner has a five - year exclusive contract with Mr. Guber and Mr. Peters that requires them to make movies exclusively at the Warner Bros. studio .\n"}
prediction:  {"predictions": [[1, 6049, 2, 3, 1144, 4, 5, 170, 1421, 118, 1214, 7114, 2329, 1114, 1828, 28138, 144, 15209, 1197, 1105, 1828, 28138, 12648, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 144, 15209, 1197, 1105, 1828, 28138, 12648, 2, 3, 5315, 4, 5, 1172, 1106, 1294, 5558, 7097, 1120, 1103, 6049, 10145, 28138, 2362, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.009627618826925755, -0.01710660196840763, -0.032243967056274414, -0.03359723091125488, -0.03359723091125488, -0.03359723091125488, -0.03359723091125488, -0.03359723091125488, -0.03359723091125488, -0.03359723091125488], "metadata": {"source_tokens": ["Warner", "has", "a", "five", "-", "year", "exclusive", "contract", "with", "Mr", "##.", "G", "##ube", "##r", "and", "Mr", "##.", "Peters", "that", "requires", "them", "to", "make", "movies", "exclusively", "at", "the", "Warner", "Bros", "##.", "studio", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Warner", "[unused2]", "[unused3]", "has", "[unused4]", "[unused5]", "a", "five", "-", "year", "exclusive", "contract", "with", "Mr", "##.", "G", "##ube", "##r", "and", "Mr", "##.", "Peters", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "G", "##ube", "##r", "and", "Mr", "##.", "Peters", "[unused2]", "[unused3]", "requires", "[unused4]", "[unused5]", "them", "to", "make", "movies", "exclusively", "at", "the", "Warner", "Bros", "##.", "studio", "[unused6]", "[SEP]"]]}

input 615:  {"source": "While the campaign was Mr. Gibbons 's idea , however , he wo n't be paying for it : The donations will come out of the chain 's national advertising fund , which is financed by the franchisees .\n"}
prediction:  {"predictions": [[1, 1103, 4129, 112, 1116, 1569, 6437, 5841, 2, 3, 1110, 14395, 4, 5, 1118, 1103, 5801, 1279, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2322, 2, 3, 1108, 4, 5, 1828, 28138, 25759, 112, 1116, 1911, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 192, 1186, 183, 28131, 1204, 1129, 6573, 4, 5, 1111, 1122, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 11725, 2, 3, 1209, 1435, 4, 5, 1149, 1104, 1103, 4129, 112, 1116, 1569, 6437, 5841, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.03315240889787674, -0.06628682464361191, -0.07483962178230286, -0.028487473726272583, -0.3363518714904785, -0.34020566940307617, -0.34020566940307617, -0.34020566940307617, -0.34020566940307617, -0.34020566940307617], "metadata": {"source_tokens": ["While", "the", "campaign", "was", "Mr", "##.", "Gibbons", "'", "##s", "idea", ",", "however", ",", "he", "w", "##o", "n", "##'", "##t", "be", "paying", "for", "it", ":", "The", "donations", "will", "come", "out", "of", "the", "chain", "'", "##s", "national", "advertising", "fund", ",", "which", "is", "financed", "by", "the", "franchise", "##es", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "chain", "'", "##s", "national", "advertising", "fund", "[unused2]", "[unused3]", "is", "financed", "[unused4]", "[unused5]", "by", "the", "franchise", "##es", "[unused6]", "[SEP]", "[unused1]", "the", "campaign", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "Mr", "##.", "Gibbons", "'", "##s", "idea", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "w", "##o", "n", "##'", "##t", "be", "paying", "[unused4]", "[unused5]", "for", "it", "[unused6]", "[SEP]", "[unused1]", "The", "donations", "[unused2]", "[unused3]", "will", "come", "[unused4]", "[unused5]", "out", "of", "the", "chain", "'", "##s", "national", "advertising", "fund", "[unused6]", "[SEP]"]]}

input 616:  {"source": "With companies such as Honda Motor Co. , Toyota Motor Corp. and Nissan Motor Co. running so - called transplant auto operations , Japanese auto production in the U.S. will reach one million vehicles this year .\n"}
prediction:  {"predictions": [[1, 1983, 12365, 1707, 1107, 1103, 158, 28138, 1708, 28138, 2, 3, 1209, 2519, 4, 5, 1141, 1550, 4011, 1142, 1214, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 17574, 8226, 3291, 28138, 2, 3, 1919, 4, 5, 1177, 118, 1270, 26965, 12365, 2500, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.005510240793228149, -0.06748998165130615, -0.15122461318969727, -0.1512136459350586, -0.1512136459350586, -0.1512136459350586, -0.1512136459350586, -0.1512136459350586, -0.1512136459350586, -0.1512136459350586], "metadata": {"source_tokens": ["With", "companies", "such", "as", "Honda", "Motor", "Co", "##.", ",", "Toyota", "Motor", "Corp", "##.", "and", "Nissan", "Motor", "Co", "##.", "running", "so", "-", "called", "transplant", "auto", "operations", ",", "Japanese", "auto", "production", "in", "the", "U", "##.", "##S", "##.", "will", "reach", "one", "million", "vehicles", "this", "year", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Japanese", "auto", "production", "in", "the", "U", "##.", "##S", "##.", "[unused2]", "[unused3]", "will", "reach", "[unused4]", "[unused5]", "one", "million", "vehicles", "this", "year", "[unused6]", "[SEP]", "[unused1]", "Nissan", "Motor", "Co", "##.", "[unused2]", "[unused3]", "running", "[unused4]", "[unused5]", "so", "-", "called", "transplant", "auto", "operations", "[unused6]", "[SEP]"]]}

input 617:  {"source": "With more than 15 million exercise bikes sold in the past five years , he adds , `` a lot of garages , basements and attics must be populated with them . ''\n"}
prediction:  {"predictions": [[1, 1167, 1190, 1405, 1550, 6730, 20852, 2, 3, 1962, 4, 5, 1107, 1103, 1763, 1421, 1201, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 9807, 4, 5, 170, 1974, 1104, 7419, 1116, 117, 8078, 1116, 1105, 19554, 1116, 1538, 1129, 10240, 1114, 1172, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 1974, 1104, 7419, 1116, 8078, 1116, 1105, 19554, 1116, 2, 3, 1538, 1129, 10240, 4, 5, 1114, 1172, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.004837738815695047, -0.016018781810998917, -0.20968544483184814, -0.06576844304800034, -0.03235197067260742, -0.03229331970214844, -0.03229331970214844, -0.03229331970214844, -0.03229331970214844, -0.03229331970214844], "metadata": {"source_tokens": ["With", "more", "than", "15", "million", "exercise", "bikes", "sold", "in", "the", "past", "five", "years", ",", "he", "adds", ",", "`", "##`", "a", "lot", "of", "garage", "##s", ",", "basement", "##s", "and", "attic", "##s", "must", "be", "populated", "with", "them", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "more", "than", "15", "million", "exercise", "bikes", "[unused2]", "[unused3]", "sold", "[unused4]", "[unused5]", "in", "the", "past", "five", "years", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "adds", "[unused4]", "[unused5]", "a", "lot", "of", "garage", "##s", ",", "basement", "##s", "and", "attic", "##s", "must", "be", "populated", "with", "them", "[unused6]", "[SEP]"]]}

input 618:  {"source": "With real estate experts Olympia & York and Samuel Zell 's Itel owning close to 40 % of Santa Fe 's stock , management was under pressure -- in a favored phrase of Wall Street -- to quickly `` maximize values . ''\n"}
prediction:  {"predictions": [[1, 2635, 2, 3, 1108, 4, 5, 1223, 2997, 1107, 170, 12578, 7224, 1104, 6250, 1715, 1106, 1976, 12477, 8745, 19092, 4718, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1842, 3327, 8724, 18279, 111, 1365, 1105, 4424, 163, 3991, 112, 1116, 1135, 1883, 2, 3, 21554, 4, 5, 1601, 1106, 1969, 110, 1104, 3364, 11907, 112, 1116, 4482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2635, 2, 3, 1108, 4, 5, 1223, 2997, 1106, 1976, 12477, 8745, 19092, 4718, 1556, 1842, 3327, 8724, 18279, 111, 1365, 1105, 4424, 163, 3991, 112, 1116, 1135, 1883, 21554, 1601, 1106, 1969, 110, 1104, 3364, 11907, 112, 1116, 4482, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2635, 2, 3, 1108, 4, 5, 1223, 2997, 1106, 1976, 12477, 8745, 19092, 4718, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2635, 2, 3, 1108, 4, 5, 1223, 2997, 1106, 1976, 12477, 8745, 19092, 4718, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.13254103064537048, -0.020433442667126656, -0.06955017894506454, -0.16057248413562775, -0.17792917788028717, -0.21248507499694824, -0.2125256061553955, -0.2125256061553955, -0.2125256061553955, -0.2125256061553955], "metadata": {"source_tokens": ["With", "real", "estate", "experts", "Olympia", "&", "York", "and", "Samuel", "Z", "##ell", "'", "##s", "It", "##el", "owning", "close", "to", "40", "%", "of", "Santa", "Fe", "'", "##s", "stock", ",", "management", "was", "under", "pressure", "-", "##-", "in", "a", "favored", "phrase", "of", "Wall", "Street", "-", "##-", "to", "quickly", "`", "##`", "ma", "##xi", "##mize", "values", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "management", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "under", "pressure", "in", "a", "favored", "phrase", "of", "Wall", "Street", "to", "quickly", "ma", "##xi", "##mize", "values", "[unused6]", "[SEP]", "[unused1]", "real", "estate", "experts", "Olympia", "&", "York", "and", "Samuel", "Z", "##ell", "'", "##s", "It", "##el", "[unused2]", "[unused3]", "owning", "[unused4]", "[unused5]", "close", "to", "40", "%", "of", "Santa", "Fe", "'", "##s", "stock", "[unused6]", "[SEP]", "[unused1]", "management", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "under", "pressure", "to", "quickly", "ma", "##xi", "##mize", "values", "With", "real", "estate", "experts", "Olympia", "&", "York", "and", "Samuel", "Z", "##ell", "'", "##s", "It", "##el", "owning", "close", "to", "40", "%", "of", "Santa", "Fe", "'", "##s", "stock", "[unused6]", "[SEP]", "[unused1]", "management", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "under", "pressure", "to", "quickly", "ma", "##xi", "##mize", "values", "[unused6]", "[SEP]", "[unused1]", "management", "[unused2]", "[unused3]", "was", "[unused4]", "[unused5]", "under", "pressure", "to", "quickly", "ma", "##xi", "##mize", "values", "[unused6]", "[SEP]"]]}

input 619:  {"source": "Within two hours , viewers pledged over $ 400,000 , according to a Red Cross executive .\n"}
prediction:  {"predictions": [[1, 6827, 2, 3, 18215, 4, 5, 1166, 109, 3434, 28136, 7629, 1568, 5360, 1160, 2005, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 6827, 2, 3, 18215, 4, 5, 1166, 109, 3434, 28136, 7629, 1568, 2452, 1106, 170, 2156, 3156, 3275, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.016881678253412247, -0.007034290581941605, -0.0761415958404541, -0.0761418342590332, -0.0761418342590332, -0.0761418342590332, -0.0761418342590332, -0.0761418342590332, -0.0761418342590332, -0.0761418342590332], "metadata": {"source_tokens": ["Within", "two", "hours", ",", "viewers", "pledged", "over", "$", "400", "##,", "##00", "##0", ",", "according", "to", "a", "Red", "Cross", "executive", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "viewers", "[unused2]", "[unused3]", "pledged", "[unused4]", "[unused5]", "over", "$", "400", "##,", "##00", "##0", "Within", "two", "hours", "[unused6]", "[SEP]", "[unused1]", "viewers", "[unused2]", "[unused3]", "pledged", "[unused4]", "[unused5]", "over", "$", "400", "##,", "##00", "##0", "according", "to", "a", "Red", "Cross", "executive", "[unused6]", "[SEP]"]]}

input 620:  {"source": "Workers at two Chilean mines , Los Bronces and El Soldado , which belong to the Exxon - owned Minera Disputado group , will vote Thursday on whether to strike after a two - year labor pact ends today .\n"}
prediction:  {"predictions": [[1, 170, 1160, 118, 1214, 5530, 24920, 2, 3, 3769, 4, 5, 2052, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8736, 1120, 1160, 12208, 7785, 2, 3, 1209, 2992, 4, 5, 9170, 1113, 2480, 1106, 4585, 1170, 170, 1160, 118, 1214, 5530, 24920, 3769, 2052, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1160, 12208, 7785, 2, 3, 6772, 4, 5, 1106, 1103, 16409, 21501, 118, 2205, 9139, 1611, 12120, 20080, 15012, 2572, 1372, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1160, 12208, 7785, 2, 3, 1209, 2992, 4, 5, 9170, 1113, 2480, 1106, 4585, 1170, 170, 1160, 118, 1214, 5530, 24920, 3769, 2052, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1160, 12208, 7785, 2, 3, 1209, 2992, 4, 5, 9170, 1113, 2480, 1106, 4585, 1170, 170, 1160, 118, 1214, 5530, 24920, 3769, 2052, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05214328691363335, -0.08411906659603119, -0.04657382890582085, -0.11176329106092453, -0.12417079508304596, -0.26923811435699463, -0.2691631317138672, -0.2691631317138672, -0.2691631317138672, -0.2691631317138672], "metadata": {"source_tokens": ["Workers", "at", "two", "Chilean", "mines", ",", "Los", "B", "##ron", "##ces", "and", "El", "Sol", "##dad", "##o", ",", "which", "belong", "to", "the", "Ex", "##xon", "-", "owned", "Mine", "##ra", "Di", "##sp", "##uta", "##do", "group", ",", "will", "vote", "Thursday", "on", "whether", "to", "strike", "after", "a", "two", "-", "year", "labor", "pact", "ends", "today", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "a", "two", "-", "year", "labor", "pact", "[unused2]", "[unused3]", "ends", "[unused4]", "[unused5]", "today", "[unused6]", "[SEP]", "[unused1]", "Workers", "at", "two", "Chilean", "mines", "[unused2]", "[unused3]", "will", "vote", "[unused4]", "[unused5]", "Thursday", "on", "whether", "to", "strike", "after", "a", "two", "-", "year", "labor", "pact", "ends", "today", "[unused6]", "[SEP]", "[unused1]", "two", "Chilean", "mines", "[unused2]", "[unused3]", "belong", "[unused4]", "[unused5]", "to", "the", "Ex", "##xon", "-", "owned", "Mine", "##ra", "Di", "##sp", "##uta", "##do", "group", "[unused6]", "[SEP]", "[unused1]", "two", "Chilean", "mines", "[unused2]", "[unused3]", "will", "vote", "[unused4]", "[unused5]", "Thursday", "on", "whether", "to", "strike", "after", "a", "two", "-", "year", "labor", "pact", "ends", "today", "[unused6]", "[SEP]", "[unused1]", "two", "Chilean", "mines", "[unused2]", "[unused3]", "will", "vote", "[unused4]", "[unused5]", "Thursday", "on", "whether", "to", "strike", "after", "a", "two", "-", "year", "labor", "pact", "ends", "today", "[unused6]", "[SEP]"]]}

input 621:  {"source": "Years ago , he collaborated with the new music gurus Peter Serkin and Fred Sherry in the very countercultural chamber group Tashi , which won audiences over to dreaded contemporary scores like Messiaen 's `` Quartet for the End of Time . ''\n"}
prediction:  {"predictions": [[1, 1119, 2, 3, 8303, 4, 5, 1114, 1103, 1207, 1390, 176, 14022, 1943, 19536, 4314, 1105, 5291, 1153, 6234, 1107, 1103, 1304, 4073, 19418, 5383, 1372, 5848, 2403, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1304, 4073, 19418, 5383, 1372, 2, 3, 1281, 4, 5, 9569, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1304, 4073, 19418, 5383, 1372, 22515, 5933, 2, 3, 1281, 4, 5, 9569, 1106, 18410, 1174, 3793, 7432, 1176, 2508, 19828, 27237, 112, 1116, 11861, 1111, 1103, 5135, 1104, 2614, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 8303, 4, 5, 1114, 1103, 1207, 1390, 176, 14022, 1943, 19536, 4314, 1105, 5291, 1153, 6234, 1107, 1103, 1304, 4073, 19418, 5383, 1372, 22515, 5933, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 8303, 4, 5, 1114, 1103, 1207, 1390, 176, 14022, 1943, 19536, 4314, 1105, 5291, 1153, 6234, 5848, 2403, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 8303, 4, 5, 1114, 1103, 1207, 1390, 176, 14022, 1943, 19536, 4314, 1105, 5291, 1153, 6234, 1107, 1103, 1304, 4073, 19418, 5383, 1372, 22515, 5933, 6, 102, 102, 1, 1119, 2, 3, 8303, 4, 5, 1114, 1103, 1207, 1390, 176, 14022, 1943, 19536, 4314, 1105, 5291, 1153, 6234, 5848, 2403, 6, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.028709780424833298, -0.15735608339309692, -0.08918396383523941, -0.08255750685930252, -0.32780909538269043, -0.11837631464004517, -0.10366341471672058, -0.12334009259939194, -0.28273868560791016, -0.2786906957626343], "metadata": {"source_tokens": ["Years", "ago", ",", "he", "collaborated", "with", "the", "new", "music", "g", "##urus", "Peter", "Ser", "##kin", "and", "Fred", "She", "##rry", "in", "the", "very", "counter", "##cultural", "chamber", "group", "Ta", "##shi", ",", "which", "won", "audiences", "over", "to", "dread", "##ed", "contemporary", "scores", "like", "Me", "##ssi", "##aen", "'", "##s", "`", "##`", "Quartet", "for", "the", "End", "of", "Time", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "he", "[unused2]", "[unused3]", "collaborated", "[unused4]", "[unused5]", "with", "the", "new", "music", "g", "##urus", "Peter", "Ser", "##kin", "and", "Fred", "She", "##rry", "in", "the", "very", "counter", "##cultural", "chamber", "group", "Years", "ago", "[unused6]", "[SEP]", "[unused1]", "the", "very", "counter", "##cultural", "chamber", "group", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "audiences", "[unused6]", "[SEP]", "[unused1]", "the", "very", "counter", "##cultural", "chamber", "group", "Ta", "##shi", "[unused2]", "[unused3]", "won", "[unused4]", "[unused5]", "audiences", "to", "dread", "##ed", "contemporary", "scores", "like", "Me", "##ssi", "##aen", "'", "##s", "Quartet", "for", "the", "End", "of", "Time", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "collaborated", "[unused4]", "[unused5]", "with", "the", "new", "music", "g", "##urus", "Peter", "Ser", "##kin", "and", "Fred", "She", "##rry", "in", "the", "very", "counter", "##cultural", "chamber", "group", "Ta", "##shi", "[unused6]", "[SEP]"]]}

input 622:  {"source": "Yesterday , Mr. Matthews , now a consultant with the Stamford , Conn. , firm Matthews & Johnston , quipped , `` I think he 'll be very good at that { new job } .\n"}
prediction:  {"predictions": [[1, 1828, 28138, 12495, 2, 3, 186, 6592, 10438, 4, 5, 146, 1341, 1119, 112, 2339, 1129, 1304, 1363, 1120, 1115, 196, 1207, 2261, 21997, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 12495, 2, 3, 1110, 4, 5, 1208, 170, 9496, 1114, 1103, 24944, 16752, 1179, 28138, 3016, 12495, 111, 10675, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 112, 2339, 1129, 4, 5, 1363, 1120, 1115, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.02654513530433178, -0.08812234550714493, -0.10522173345088959, -0.12344098091125488, -0.12344050407409668, -0.12344050407409668, -0.12344050407409668, -0.12344050407409668, -0.12344050407409668, -0.12344050407409668], "metadata": {"source_tokens": ["Yesterday", ",", "Mr", "##.", "Matthews", ",", "now", "a", "consultant", "with", "the", "Stamford", ",", "Con", "##n", "##.", ",", "firm", "Matthews", "&", "Johnston", ",", "q", "##ui", "##pped", ",", "`", "##`", "I", "think", "he", "'", "##ll", "be", "very", "good", "at", "that", "{", "new", "job", "}", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Mr", "##.", "Matthews", "[unused2]", "[unused3]", "q", "##ui", "##pped", "[unused4]", "[unused5]", "I", "think", "he", "'", "##ll", "be", "very", "good", "at", "that", "{", "new", "job", "Yesterday", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "Matthews", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "now", "a", "consultant", "with", "the", "Stamford", "Con", "##n", "##.", "firm", "Matthews", "&", "Johnston", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "'", "##ll", "be", "[unused4]", "[unused5]", "good", "at", "that", "[unused6]", "[SEP]"]]}

input 623:  {"source": "Yet the Soviet leader 's readiness to embark on foreign visits and steady accumulation of personal power , particularly since the last Politburo reshuffle on Sept. 30 , do not suggest that Mr. Gorbachev is on the verge of being toppled ; nor does he look likely to reverse the powers of perestroika .\n"}
prediction:  {"predictions": [[1, 1103, 2461, 2301, 112, 1116, 25922, 2, 3, 1106, 9712, 24063, 4, 5, 1113, 2880, 7508, 1105, 6386, 23168, 1104, 2357, 1540, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 1314, 17129, 2875, 19364, 1186, 1231, 16138, 13327, 1113, 20456, 2, 3, 1202, 1136, 5996, 4, 5, 1115, 1828, 28138, 3414, 26281, 12804, 1964, 1110, 1113, 1103, 18691, 1104, 1217, 1499, 13229, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1440, 4, 5, 2620, 1106, 7936, 1103, 3758, 1104, 1679, 2556, 21418, 1968, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1828, 28138, 3414, 26281, 12804, 1964, 2, 3, 1110, 4, 5, 1113, 1103, 18691, 1104, 1217, 1499, 13229, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 2461, 2301, 112, 1116, 25922, 2, 3, 1106, 9712, 24063, 4, 5, 1113, 2880, 7508, 1105, 6386, 23168, 1104, 2357, 1540, 2521, 1290, 1103, 1314, 17129, 2875, 19364, 1186, 1231, 16138, 13327, 1113, 20456, 1476, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06319068372249603, -0.04974266514182091, -0.060695309191942215, -0.03826388716697693, -0.08747123181819916, -0.2875049114227295, -0.28760671615600586, -0.28760671615600586, -0.28760671615600586, -0.28760671615600586], "metadata": {"source_tokens": ["Yet", "the", "Soviet", "leader", "'", "##s", "readiness", "to", "em", "##bark", "on", "foreign", "visits", "and", "steady", "accumulation", "of", "personal", "power", ",", "particularly", "since", "the", "last", "Pol", "##it", "##bur", "##o", "re", "##shu", "##ffle", "on", "Sept", "##.", "30", ",", "do", "not", "suggest", "that", "Mr", "##.", "Go", "##rb", "##ache", "##v", "is", "on", "the", "verge", "of", "being", "top", "##pled", ";", "nor", "does", "he", "look", "likely", "to", "reverse", "the", "powers", "of", "per", "##est", "##roi", "##ka", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "Soviet", "leader", "'", "##s", "readiness", "[unused2]", "[unused3]", "to", "em", "##bark", "[unused4]", "[unused5]", "on", "foreign", "visits", "and", "steady", "accumulation", "of", "personal", "power", "[unused6]", "[SEP]", "[unused1]", "the", "last", "Pol", "##it", "##bur", "##o", "re", "##shu", "##ffle", "on", "Sept", "[unused2]", "[unused3]", "do", "not", "suggest", "[unused4]", "[unused5]", "that", "Mr", "##.", "Go", "##rb", "##ache", "##v", "is", "on", "the", "verge", "of", "being", "top", "##pled", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "look", "[unused4]", "[unused5]", "likely", "to", "reverse", "the", "powers", "of", "per", "##est", "##roi", "##ka", "[unused6]", "[SEP]", "[unused1]", "Mr", "##.", "Go", "##rb", "##ache", "##v", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "on", "the", "verge", "of", "being", "top", "##pled", "[unused6]", "[SEP]", "[unused1]", "the", "Soviet", "leader", "'", "##s", "readiness", "[unused2]", "[unused3]", "to", "em", "##bark", "[unused4]", "[unused5]", "on", "foreign", "visits", "and", "steady", "accumulation", "of", "personal", "power", "particularly", "since", "the", "last", "Pol", "##it", "##bur", "##o", "re", "##shu", "##ffle", "on", "Sept", "30", "[unused6]", "[SEP]"]]}

input 624:  {"source": "`` Business across the country is spending more time addressing this issue , '' says Sen. Edward Kennedy ( D. , Mass . ) .\n"}
prediction:  {"predictions": [[1, 3518, 1506, 1103, 1583, 1110, 5369, 1167, 1159, 13735, 1142, 2486, 2, 3, 1867, 4, 5, 14895, 28138, 2594, 5107, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3518, 1506, 1103, 1583, 2, 3, 1110, 5369, 4, 5, 1167, 1159, 13735, 1142, 2486, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.021934663876891136, -0.006750809494405985, -0.12104201316833496, -0.12080264091491699, -0.12080264091491699, -0.12080264091491699, -0.12080264091491699, -0.12080264091491699, -0.12080264091491699, -0.12080264091491699], "metadata": {"source_tokens": ["`", "##`", "Business", "across", "the", "country", "is", "spending", "more", "time", "addressing", "this", "issue", ",", "'", "##'", "says", "Sen", "##.", "Edward", "Kennedy", "(", "D", "##.", ",", "Mass", ".", ")", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Business", "across", "the", "country", "is", "spending", "more", "time", "addressing", "this", "issue", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Sen", "##.", "Edward", "Kennedy", "[unused6]", "[SEP]", "[unused1]", "Business", "across", "the", "country", "[unused2]", "[unused3]", "is", "spending", "[unused4]", "[unused5]", "more", "time", "addressing", "this", "issue", "[unused6]", "[SEP]"]]}

input 625:  {"source": "`` I ca n't believe they ( GM ) will let Ford have a free run , '' said Stephen Reitman , a European auto industry analyst at UBS - Phillips & Drew .\n"}
prediction:  {"predictions": [[1, 146, 11019, 183, 28131, 1204, 2059, 1152, 113, 14748, 114, 1209, 1519, 4100, 1138, 170, 1714, 1576, 2, 3, 1163, 4, 5, 3620, 11336, 2875, 1399, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3620, 11336, 2875, 1399, 2, 3, 1110, 170, 1735, 12365, 2380, 14582, 1120, 4, 5, 158, 9782, 7651, 111, 8633, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 146, 2, 3, 11019, 183, 28131, 1204, 2059, 4, 5, 1152, 113, 14748, 114, 1209, 1519, 4100, 1138, 170, 1714, 1576, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.026687193661928177, -0.08818191289901733, -0.09008113294839859, -0.11910796165466309, -0.12132573127746582, -0.12132573127746582, -0.12132573127746582, -0.12132573127746582, -0.12132573127746582, -0.12132573127746582], "metadata": {"source_tokens": ["`", "##`", "I", "ca", "n", "##'", "##t", "believe", "they", "(", "GM", ")", "will", "let", "Ford", "have", "a", "free", "run", ",", "'", "##'", "said", "Stephen", "Re", "##it", "##man", ",", "a", "European", "auto", "industry", "analyst", "at", "U", "##BS", "-", "Phillips", "&", "Drew", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "I", "ca", "n", "##'", "##t", "believe", "they", "(", "GM", ")", "will", "let", "Ford", "have", "a", "free", "run", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "Stephen", "Re", "##it", "##man", "[unused6]", "[SEP]", "[unused1]", "Stephen", "Re", "##it", "##man", "[unused2]", "[unused3]", "is", "a", "European", "auto", "industry", "analyst", "at", "[unused4]", "[unused5]", "U", "##BS", "Phillips", "&", "Drew", "[unused6]", "[SEP]", "[unused1]", "I", "[unused2]", "[unused3]", "ca", "n", "##'", "##t", "believe", "[unused4]", "[unused5]", "they", "(", "GM", ")", "will", "let", "Ford", "have", "a", "free", "run", "[unused6]", "[SEP]"]]}

input 626:  {"source": "`` I do n't foresee any shortages over the next few months , '' says Ken Allen , an official of Operating Engineers Local 3 in San Francisco .\n"}
prediction:  {"predictions": [[1, 146, 1202, 183, 28131, 1204, 24387, 18628, 1251, 25630, 1166, 1103, 1397, 1374, 1808, 2, 3, 1867, 4, 5, 5928, 4522, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 146, 2, 3, 1202, 183, 28131, 1204, 24387, 18628, 4, 5, 1251, 25630, 1166, 1103, 1397, 1374, 1808, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 5928, 4522, 2, 3, 1110, 1126, 2078, 1104, 4, 5, 20961, 8665, 5328, 124, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.007538755889981985, -0.02881798893213272, -0.06402914971113205, -0.12344026565551758, -0.12342596054077148, -0.12342596054077148, -0.12342596054077148, -0.12342596054077148, -0.12342596054077148, -0.12342596054077148], "metadata": {"source_tokens": ["`", "##`", "I", "do", "n", "##'", "##t", "fore", "##see", "any", "shortages", "over", "the", "next", "few", "months", ",", "'", "##'", "says", "Ken", "Allen", ",", "an", "official", "of", "Operating", "Engineers", "Local", "3", "in", "San", "Francisco", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "I", "do", "n", "##'", "##t", "fore", "##see", "any", "shortages", "over", "the", "next", "few", "months", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Ken", "Allen", "[unused6]", "[SEP]", "[unused1]", "I", "[unused2]", "[unused3]", "do", "n", "##'", "##t", "fore", "##see", "[unused4]", "[unused5]", "any", "shortages", "over", "the", "next", "few", "months", "[unused6]", "[SEP]", "[unused1]", "Ken", "Allen", "[unused2]", "[unused3]", "is", "an", "official", "of", "[unused4]", "[unused5]", "Operating", "Engineers", "Local", "3", "[unused6]", "[SEP]"]]}

input 627:  {"source": "`` I wo n't be throwing 90 mph , but I will throw 80 - plus , '' he says .\n"}
prediction:  {"predictions": [[1, 146, 2, 3, 1209, 4932, 4, 5, 2908, 118, 4882, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 146, 2, 3, 192, 1186, 183, 28131, 1204, 1129, 6558, 4, 5, 3078, 4955, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 146, 1209, 4932, 2908, 118, 4882, 2, 3, 1867, 4, 5, 1119, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.07207360863685608, -0.032919660210609436, -0.1212482675909996, -0.023118019104003906, -0.02284526824951172, -0.02284526824951172, -0.02284526824951172, -0.02284526824951172, -0.02284526824951172, -0.02284526824951172], "metadata": {"source_tokens": ["`", "##`", "I", "w", "##o", "n", "##'", "##t", "be", "throwing", "90", "mph", ",", "but", "I", "will", "throw", "80", "-", "plus", ",", "'", "##'", "he", "says", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "I", "[unused2]", "[unused3]", "will", "throw", "[unused4]", "[unused5]", "80", "-", "plus", "[unused6]", "[SEP]", "[unused1]", "I", "[unused2]", "[unused3]", "w", "##o", "n", "##'", "##t", "be", "throwing", "[unused4]", "[unused5]", "90", "mph", "[unused6]", "[SEP]", "[unused1]", "I", "will", "throw", "80", "-", "plus", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "he", "[unused6]", "[SEP]"]]}

input 628:  {"source": "`` If working capital financing is not provided , '' he said , `` the RTC may have to slow { S&L sales } or dump acquired assets through fire sales .\n"}
prediction:  {"predictions": [[1, 1684, 2364, 13080, 2, 3, 1110, 1136, 2136, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1119, 2, 3, 1163, 4, 5, 1103, 155, 9481, 1336, 1138, 1106, 3345, 196, 156, 28130, 2162, 3813, 1137, 17549, 2888, 6661, 1194, 1783, 3813, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 155, 9481, 2, 3, 1336, 1138, 4, 5, 1106, 3345, 156, 28130, 2162, 3813, 1137, 17549, 2888, 6661, 1409, 1684, 2364, 13080, 1110, 1136, 2136, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1103, 155, 9481, 2, 3, 1336, 1138, 4, 5, 1106, 3345, 156, 28130, 2162, 3813, 1137, 17549, 2888, 6661, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.056849606335163116, -0.05051792412996292, -0.08060155063867569, -0.10290579497814178, -0.12358832359313965, -0.12359499931335449, -0.12359499931335449, -0.12359499931335449, -0.12359499931335449, -0.12359499931335449], "metadata": {"source_tokens": ["`", "##`", "If", "working", "capital", "financing", "is", "not", "provided", ",", "'", "##'", "he", "said", ",", "`", "##`", "the", "R", "##TC", "may", "have", "to", "slow", "{", "S", "##&", "##L", "sales", "}", "or", "dump", "acquired", "assets", "through", "fire", "sales", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "working", "capital", "financing", "[unused2]", "[unused3]", "is", "not", "provided", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "he", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "the", "R", "##TC", "may", "have", "to", "slow", "{", "S", "##&", "##L", "sales", "or", "dump", "acquired", "assets", "through", "fire", "sales", "[unused6]", "[SEP]", "[unused1]", "the", "R", "##TC", "[unused2]", "[unused3]", "may", "have", "[unused4]", "[unused5]", "to", "slow", "S", "##&", "##L", "sales", "or", "dump", "acquired", "assets", "If", "working", "capital", "financing", "is", "not", "provided", "[unused6]", "[SEP]", "[unused1]", "the", "R", "##TC", "[unused2]", "[unused3]", "may", "have", "[unused4]", "[unused5]", "to", "slow", "S", "##&", "##L", "sales", "or", "dump", "acquired", "assets", "[unused6]", "[SEP]"]]}

input 629:  {"source": "`` It 's a super - exciting set of discoveries , '' says Bert Vogelstein , a Johns Hopkins University researcher who has just found a gene pivotal to the triggering of colon cancer .\n"}
prediction:  {"predictions": [[1, 1135, 112, 1116, 170, 7688, 118, 11215, 1383, 1104, 17707, 2, 3, 1867, 4, 5, 15035, 159, 27732, 7879, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 170, 11673, 10055, 1239, 11325, 2, 3, 1144, 1198, 1276, 4, 5, 170, 5565, 22927, 1106, 1103, 9887, 1158, 1104, 1884, 4934, 4182, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 112, 1116, 4, 5, 170, 7688, 118, 11215, 1383, 1104, 17707, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.023771248757839203, -0.0051420023664832115, -0.08409591764211655, -0.07652020454406738, -0.07652068138122559, -0.07652068138122559, -0.07652068138122559, -0.07652068138122559, -0.07652068138122559, -0.07652068138122559], "metadata": {"source_tokens": ["`", "##`", "It", "'", "##s", "a", "super", "-", "exciting", "set", "of", "discoveries", ",", "'", "##'", "says", "Bert", "V", "##ogel", "##stein", ",", "a", "Johns", "Hopkins", "University", "researcher", "who", "has", "just", "found", "a", "gene", "pivotal", "to", "the", "trigger", "##ing", "of", "co", "##lon", "cancer", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "'", "##s", "a", "super", "-", "exciting", "set", "of", "discoveries", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Bert", "V", "##ogel", "##stein", "[unused6]", "[SEP]", "[unused1]", "a", "Johns", "Hopkins", "University", "researcher", "[unused2]", "[unused3]", "has", "just", "found", "[unused4]", "[unused5]", "a", "gene", "pivotal", "to", "the", "trigger", "##ing", "of", "co", "##lon", "cancer", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "'", "##s", "[unused4]", "[unused5]", "a", "super", "-", "exciting", "set", "of", "discoveries", "[unused6]", "[SEP]"]]}

input 630:  {"source": "`` It 's a wait - and - see attitude , '' said Dave Vellante , vice president of storage research for International Data Corp .\n"}
prediction:  {"predictions": [[1, 1135, 112, 1116, 170, 3074, 118, 1105, 118, 1267, 7533, 2, 3, 1163, 4, 5, 4111, 159, 7772, 11656, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4111, 159, 7772, 11656, 2, 3, 1110, 4711, 2084, 1104, 4, 5, 5092, 1844, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1135, 2, 3, 112, 1116, 4, 5, 170, 3074, 1105, 1267, 7533, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4111, 159, 7772, 11656, 2, 3, 1110, 4, 5, 4711, 2084, 1104, 5092, 1844, 1111, 1570, 7154, 13619, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.026681596413254738, -0.0410316064953804, -0.0900697261095047, -0.11705966293811798, -0.022115230560302734, -0.023840904235839844, -0.023840904235839844, -0.023840904235839844, -0.023840904235839844, -0.023840904235839844], "metadata": {"source_tokens": ["`", "##`", "It", "'", "##s", "a", "wait", "-", "and", "-", "see", "attitude", ",", "'", "##'", "said", "Dave", "V", "##ella", "##nte", ",", "vice", "president", "of", "storage", "research", "for", "International", "Data", "Corp", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "'", "##s", "a", "wait", "-", "and", "-", "see", "attitude", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "Dave", "V", "##ella", "##nte", "[unused6]", "[SEP]", "[unused1]", "Dave", "V", "##ella", "##nte", "[unused2]", "[unused3]", "is", "vice", "president", "of", "[unused4]", "[unused5]", "storage", "research", "[unused6]", "[SEP]", "[unused1]", "It", "[unused2]", "[unused3]", "'", "##s", "[unused4]", "[unused5]", "a", "wait", "and", "see", "attitude", "[unused6]", "[SEP]", "[unused1]", "Dave", "V", "##ella", "##nte", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "vice", "president", "of", "storage", "research", "for", "International", "Data", "Corp", "[unused6]", "[SEP]"]]}

input 631:  {"source": "`` It 's really bizarre , '' says Albert Lerman , creative director at the Wells Rich Greene ad agency .\n"}
prediction:  {"predictions": [[1, 1135, 112, 1116, 1541, 15507, 2, 3, 1867, 4, 5, 3986, 3180, 7990, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 3986, 3180, 7990, 2, 3, 1110, 6228, 1900, 1120, 4, 5, 1103, 7909, 8864, 10983, 8050, 4792, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.01824318617582321, -0.004721993114799261, -0.03308415412902832, -0.03262948989868164, -0.03262948989868164, -0.03262948989868164, -0.03262948989868164, -0.03262948989868164, -0.03262948989868164, -0.03262948989868164], "metadata": {"source_tokens": ["`", "##`", "It", "'", "##s", "really", "bizarre", ",", "'", "##'", "says", "Albert", "Le", "##rman", ",", "creative", "director", "at", "the", "Wells", "Rich", "Greene", "ad", "agency", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "It", "'", "##s", "really", "bizarre", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Albert", "Le", "##rman", "[unused6]", "[SEP]", "[unused1]", "Albert", "Le", "##rman", "[unused2]", "[unused3]", "is", "creative", "director", "at", "[unused4]", "[unused5]", "the", "Wells", "Rich", "Greene", "ad", "agency", "[unused6]", "[SEP]"]]}

input 632:  {"source": "`` Most of the LBO guys do n't know how to run a business anyway . ''\n"}
prediction:  {"predictions": [[1, 2082, 1104, 1103, 149, 23904, 3713, 2, 3, 1202, 183, 28131, 1204, 1221, 4, 5, 1293, 1106, 1576, 170, 1671, 4050, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.0015097856521606445, -0.03733348846435547, -0.038346290588378906, -0.038346290588378906, -0.038346290588378906, -0.038346290588378906, -0.038346290588378906, -0.038346290588378906, -0.038346290588378906, -0.038346290588378906], "metadata": {"source_tokens": ["`", "##`", "Most", "of", "the", "L", "##BO", "guys", "do", "n", "##'", "##t", "know", "how", "to", "run", "a", "business", "anyway", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Most", "of", "the", "L", "##BO", "guys", "[unused2]", "[unused3]", "do", "n", "##'", "##t", "know", "[unused4]", "[unused5]", "how", "to", "run", "a", "business", "anyway", "[unused6]", "[SEP]"]]}

input 633:  {"source": "`` Most people -- whether in Toledo , Tucson or Topeka -- have n't got a clue who we are , '' says Guy L. Smith , Philip Morris 's vice president of corporate affairs .\n"}
prediction:  {"predictions": [[1, 2082, 1234, 118, 28137, 2480, 1107, 13459, 117, 18740, 1137, 3299, 19413, 118, 28137, 1138, 183, 28131, 1204, 1400, 170, 9956, 1150, 1195, 1132, 2, 3, 1867, 4, 5, 6173, 149, 28138, 2159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2082, 1234, 118, 28137, 2480, 1107, 13459, 117, 18740, 1137, 3299, 19413, 118, 28137, 1138, 183, 28131, 1204, 1400, 170, 9956, 1150, 1195, 1132, 2, 3, 1867, 4, 5, 6173, 149, 28138, 2159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2082, 1234, 118, 28137, 2480, 1107, 13459, 117, 18740, 1137, 3299, 19413, 118, 28137, 1138, 183, 28131, 1204, 1400, 170, 9956, 1150, 1195, 1132, 2, 3, 1867, 4, 5, 6173, 149, 28138, 2159, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2082, 1234, 2480, 1107, 13459, 18740, 1137, 3299, 19413, 2, 3, 1138, 183, 28131, 1204, 1400, 4, 5, 170, 9956, 1150, 1195, 1132, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04125373065471649, -0.09914864599704742, -0.11672648787498474, -0.08478923887014389, -0.2637747526168823, -0.26377594470977783, -0.26377594470977783, -0.26377594470977783, -0.26377594470977783, -0.26377594470977783], "metadata": {"source_tokens": ["`", "##`", "Most", "people", "-", "##-", "whether", "in", "Toledo", ",", "Tucson", "or", "Top", "##eka", "-", "##-", "have", "n", "##'", "##t", "got", "a", "clue", "who", "we", "are", ",", "'", "##'", "says", "Guy", "L", "##.", "Smith", ",", "Philip", "Morris", "'", "##s", "vice", "president", "of", "corporate", "affairs", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Most", "people", "-", "##-", "whether", "in", "Toledo", ",", "Tucson", "or", "Top", "##eka", "-", "##-", "have", "n", "##'", "##t", "got", "a", "clue", "who", "we", "are", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Guy", "L", "##.", "Smith", "[unused6]", "[SEP]", "[unused1]", "Most", "people", "-", "##-", "whether", "in", "Toledo", ",", "Tucson", "or", "Top", "##eka", "-", "##-", "have", "n", "##'", "##t", "got", "a", "clue", "who", "we", "are", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Guy", "L", "##.", "Smith", "[unused6]", "[SEP]", "[unused1]", "Most", "people", "-", "##-", "whether", "in", "Toledo", ",", "Tucson", "or", "Top", "##eka", "-", "##-", "have", "n", "##'", "##t", "got", "a", "clue", "who", "we", "are", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Guy", "L", "##.", "Smith", "[unused6]", "[SEP]", "[unused1]", "Most", "people", "whether", "in", "Toledo", "Tucson", "or", "Top", "##eka", "[unused2]", "[unused3]", "have", "n", "##'", "##t", "got", "[unused4]", "[unused5]", "a", "clue", "who", "we", "are", "[unused6]", "[SEP]"]]}

input 634:  {"source": "`` Nobody told us ; nobody called us , '' says an official close to the case who asked not to be named .\n"}
prediction:  {"predictions": [[1, 1103, 1692, 2, 3, 1455, 4, 5, 1136, 1106, 1129, 1417, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 9913, 1500, 1366, 2, 3, 1867, 4, 5, 1126, 2078, 1601, 1106, 1103, 1692, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 8582, 2, 3, 1270, 4, 5, 1366, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.006545952521264553, -0.07846005260944366, -0.08356636762619019, -0.03853750228881836, -0.038535118103027344, -0.038535118103027344, -0.038535118103027344, -0.038535118103027344, -0.038535118103027344, -0.038535118103027344], "metadata": {"source_tokens": ["`", "##`", "Nobody", "told", "us", ";", "nobody", "called", "us", ",", "'", "##'", "says", "an", "official", "close", "to", "the", "case", "who", "asked", "not", "to", "be", "named", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "the", "case", "[unused2]", "[unused3]", "asked", "[unused4]", "[unused5]", "not", "to", "be", "named", "[unused6]", "[SEP]", "[unused1]", "Nobody", "told", "us", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "an", "official", "close", "to", "the", "case", "[unused6]", "[SEP]", "[unused1]", "nobody", "[unused2]", "[unused3]", "called", "[unused4]", "[unused5]", "us", "[unused6]", "[SEP]"]]}

input 635:  {"source": "`` Nothing can be better than this , '' says Don Sider , owner of the West Palm Beach Tropics .\n"}
prediction:  {"predictions": [[1, 4302, 1169, 1129, 1618, 1190, 1142, 2, 3, 1867, 4, 5, 1790, 6383, 1197, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1790, 6383, 1197, 2, 3, 1110, 3172, 1104, 4, 5, 1103, 1537, 10739, 3808, 157, 27098, 1116, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 4302, 2, 3, 1169, 1129, 4, 5, 1618, 1190, 1142, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.00884016789495945, -0.008802157826721668, -0.03234105929732323, -0.0021915435791015625, -0.0020580291748046875, -0.0020580291748046875, -0.0020580291748046875, -0.0020580291748046875, -0.0020580291748046875, -0.0020580291748046875], "metadata": {"source_tokens": ["`", "##`", "Nothing", "can", "be", "better", "than", "this", ",", "'", "##'", "says", "Don", "Side", "##r", ",", "owner", "of", "the", "West", "Palm", "Beach", "T", "##ropic", "##s", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Nothing", "can", "be", "better", "than", "this", "[unused2]", "[unused3]", "says", "[unused4]", "[unused5]", "Don", "Side", "##r", "[unused6]", "[SEP]", "[unused1]", "Don", "Side", "##r", "[unused2]", "[unused3]", "is", "owner", "of", "[unused4]", "[unused5]", "the", "West", "Palm", "Beach", "T", "##ropic", "##s", "[unused6]", "[SEP]", "[unused1]", "Nothing", "[unused2]", "[unused3]", "can", "be", "[unused4]", "[unused5]", "better", "than", "this", "[unused6]", "[SEP]"]]}

input 636:  {"source": "`` Now everything '' -- such as program trading and wide stock market swings -- `` that everyone had pushed back in their consciousness is just sitting right there . ''\n"}
prediction:  {"predictions": [[1, 2490, 1125, 2873, 1171, 1107, 1147, 8418, 2, 3, 1110, 1198, 2807, 4, 5, 1268, 1175, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2490, 2, 3, 1125, 2873, 4, 5, 1171, 1107, 1147, 8418, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.05232943221926689, -0.027656743302941322, -0.07699894905090332, -0.07666158676147461, -0.07666158676147461, -0.07666158676147461, -0.07666158676147461, -0.07666158676147461, -0.07666158676147461, -0.07666158676147461], "metadata": {"source_tokens": ["`", "##`", "Now", "everything", "'", "##'", "-", "##-", "such", "as", "program", "trading", "and", "wide", "stock", "market", "swings", "-", "##-", "`", "##`", "that", "everyone", "had", "pushed", "back", "in", "their", "consciousness", "is", "just", "sitting", "right", "there", ".", "'", "##'"], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "everyone", "had", "pushed", "back", "in", "their", "consciousness", "[unused2]", "[unused3]", "is", "just", "sitting", "[unused4]", "[unused5]", "right", "there", "[unused6]", "[SEP]", "[unused1]", "everyone", "[unused2]", "[unused3]", "had", "pushed", "[unused4]", "[unused5]", "back", "in", "their", "consciousness", "[unused6]", "[SEP]"]]}

input 637:  {"source": "`` The bottom line is that if we can get that { Warsaw Pact } superiority brought down to parity , we ought to keep pressing ahead as quickly as possible .\n"}
prediction:  {"predictions": [[1, 1109, 3248, 1413, 2, 3, 1110, 4, 5, 1115, 1191, 1195, 1169, 1243, 1115, 196, 7760, 27175, 198, 21378, 1814, 1205, 1106, 14247, 1785, 117, 1195, 11454, 1106, 1712, 7675, 3075, 1112, 1976, 1112, 1936, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1195, 2, 3, 11454, 4, 5, 1106, 1712, 7675, 3075, 1112, 1976, 1112, 1936, 1191, 1195, 1169, 1243, 1115, 196, 7760, 27175, 198, 21378, 1814, 1205, 1106, 14247, 1785, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1195, 2, 3, 11454, 4, 5, 1106, 1712, 7675, 3075, 1112, 1976, 1112, 1936, 1191, 1195, 1169, 1243, 1115, 196, 7760, 27175, 198, 21378, 1814, 1205, 1106, 14247, 1785, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1195, 2, 3, 11454, 4, 5, 1106, 1712, 7675, 3075, 1112, 1976, 1112, 1936, 1191, 1195, 1169, 1243, 1115, 196, 7760, 27175, 21378, 1814, 1205, 1106, 14247, 1785, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.003420876804739237, -0.04644552618265152, -0.07616718858480453, -0.08931739628314972, -0.20538294315338135, -0.20945000648498535, -0.20945000648498535, -0.20945000648498535, -0.20945000648498535, -0.20945000648498535], "metadata": {"source_tokens": ["`", "##`", "The", "bottom", "line", "is", "that", "if", "we", "can", "get", "that", "{", "Warsaw", "Pact", "}", "superiority", "brought", "down", "to", "par", "##ity", ",", "we", "ought", "to", "keep", "pressing", "ahead", "as", "quickly", "as", "possible", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "bottom", "line", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "that", "if", "we", "can", "get", "that", "{", "Warsaw", "Pact", "}", "superiority", "brought", "down", "to", "par", "##ity", ",", "we", "ought", "to", "keep", "pressing", "ahead", "as", "quickly", "as", "possible", "[unused6]", "[SEP]", "[unused1]", "we", "[unused2]", "[unused3]", "ought", "[unused4]", "[unused5]", "to", "keep", "pressing", "ahead", "as", "quickly", "as", "possible", "if", "we", "can", "get", "that", "{", "Warsaw", "Pact", "}", "superiority", "brought", "down", "to", "par", "##ity", "[unused6]", "[SEP]", "[unused1]", "we", "[unused2]", "[unused3]", "ought", "[unused4]", "[unused5]", "to", "keep", "pressing", "ahead", "as", "quickly", "as", "possible", "if", "we", "can", "get", "that", "{", "Warsaw", "Pact", "}", "superiority", "brought", "down", "to", "par", "##ity", "[unused6]", "[SEP]", "[unused1]", "we", "[unused2]", "[unused3]", "ought", "[unused4]", "[unused5]", "to", "keep", "pressing", "ahead", "as", "quickly", "as", "possible", "if", "we", "can", "get", "that", "{", "Warsaw", "Pact", "superiority", "brought", "down", "to", "par", "##ity", "[unused6]", "[SEP]"]]}

input 638:  {"source": "`` The only people who are flying are those who have to , '' said Frank Moore , chairman of the Australian Tourist Industry Association .\n"}
prediction:  {"predictions": [[1, 1109, 1178, 1234, 1150, 1132, 3754, 1132, 1343, 2, 3, 1163, 4, 5, 2748, 4673, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1178, 1234, 1150, 1132, 3754, 2, 3, 1132, 4, 5, 1343, 1150, 1138, 1106, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 2748, 4673, 2, 3, 1110, 3931, 1104, 4, 5, 1103, 1925, 3124, 1776, 7358, 1791, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1109, 1178, 1234, 2, 3, 1132, 3754, 4, 5, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.06396634131669998, -0.05806262046098709, -0.04498559236526489, -0.06396020948886871, -0.03228139877319336, -0.032279253005981445, -0.032279253005981445, -0.032279253005981445, -0.032279253005981445, -0.032279253005981445], "metadata": {"source_tokens": ["`", "##`", "The", "only", "people", "who", "are", "flying", "are", "those", "who", "have", "to", ",", "'", "##'", "said", "Frank", "Moore", ",", "chairman", "of", "the", "Australian", "Tour", "##ist", "Industry", "Association", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "The", "only", "people", "who", "are", "flying", "are", "those", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "Frank", "Moore", "[unused6]", "[SEP]", "[unused1]", "The", "only", "people", "who", "are", "flying", "[unused2]", "[unused3]", "are", "[unused4]", "[unused5]", "those", "who", "have", "to", "[unused6]", "[SEP]", "[unused1]", "Frank", "Moore", "[unused2]", "[unused3]", "is", "chairman", "of", "[unused4]", "[unused5]", "the", "Australian", "Tour", "##ist", "Industry", "Association", "[unused6]", "[SEP]", "[unused1]", "The", "only", "people", "[unused2]", "[unused3]", "are", "flying", "[unused4]", "[unused5]", "[unused6]", "[SEP]"]]}

input 639:  {"source": "`` To allow this massive level of unfettered federal borrowing without prior congressional approval would be irresponsible , '' said Rep. Fortney Stark ( D. , Calif. ) , who has introduced a bill to limit the RTC 's authority to issue debt .\n"}
prediction:  {"predictions": [[1, 20777, 28138, 3144, 4695, 13562, 2, 3, 1144, 2234, 4, 5, 170, 4550, 1106, 5310, 1103, 155, 9481, 112, 1116, 3748, 1106, 2486, 6695, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1706, 2621, 1142, 4672, 1634, 1104, 8362, 8124, 16616, 2877, 20055, 1158, 1443, 2988, 10974, 5684, 1156, 1129, 178, 11604, 26408, 2, 3, 1163, 4, 5, 20777, 28138, 3144, 4695, 13562, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 1706, 2621, 1142, 4672, 1634, 1104, 8362, 8124, 16616, 2877, 20055, 1158, 1443, 2988, 10974, 5684, 1156, 1129, 178, 11604, 26408, 2, 3, 1163, 4, 5, 20777, 28138, 3144, 4695, 13562, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20777, 28138, 3144, 4695, 13562, 2, 3, 1110, 4, 5, 141, 28138, 11917, 8914, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20777, 28138, 3144, 4695, 13562, 2, 3, 1110, 4, 5, 141, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 1, 20777, 28138, 3144, 4695, 13562, 2, 3, 1110, 4, 5, 141, 28138, 6, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 10, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102]], "predicted_log_probs": [-0.04745214432477951, -0.04395481199026108, -0.10062583535909653, -0.11651738733053207, -0.21523205935955048, -0.22506527602672577, -0.2695220708847046, -0.2695479393005371, -0.2695479393005371, -0.2695479393005371], "metadata": {"source_tokens": ["`", "##`", "To", "allow", "this", "massive", "level", "of", "un", "##fe", "##ttered", "federal", "borrow", "##ing", "without", "prior", "congressional", "approval", "would", "be", "i", "##rre", "##sponsible", ",", "'", "##'", "said", "Rep", "##.", "Fort", "##ney", "Stark", "(", "D", "##.", ",", "Cal", "##if", "##.", ")", ",", "who", "has", "introduced", "a", "bill", "to", "limit", "the", "R", "##TC", "'", "##s", "authority", "to", "issue", "debt", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "Rep", "##.", "Fort", "##ney", "Stark", "[unused2]", "[unused3]", "has", "introduced", "[unused4]", "[unused5]", "a", "bill", "to", "limit", "the", "R", "##TC", "'", "##s", "authority", "to", "issue", "debt", "[unused6]", "[SEP]", "[unused1]", "To", "allow", "this", "massive", "level", "of", "un", "##fe", "##ttered", "federal", "borrow", "##ing", "without", "prior", "congressional", "approval", "would", "be", "i", "##rre", "##sponsible", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "Rep", "##.", "Fort", "##ney", "Stark", "[unused6]", "[SEP]", "[unused1]", "To", "allow", "this", "massive", "level", "of", "un", "##fe", "##ttered", "federal", "borrow", "##ing", "without", "prior", "congressional", "approval", "would", "be", "i", "##rre", "##sponsible", "[unused2]", "[unused3]", "said", "[unused4]", "[unused5]", "Rep", "##.", "Fort", "##ney", "Stark", "[unused6]", "[SEP]", "[unused1]", "Rep", "##.", "Fort", "##ney", "Stark", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "D", "##.", "Cal", "##if", "##.", "[unused6]", "[SEP]", "[unused1]", "Rep", "##.", "Fort", "##ney", "Stark", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "D", "##.", "[unused6]", "[SEP]", "[unused1]", "Rep", "##.", "Fort", "##ney", "Stark", "[unused2]", "[unused3]", "is", "[unused4]", "[unused5]", "D", "##.", "[unused6]", "[SEP]"]]}

Batch 5 Test Time =  54.21229815483093  s
Decodertime : 0.0002377033233642578
g_f_logprobs : 0.008791446685791016
Decodertime : 0.00020742416381835938
g_f_logprobs : 0.007698535919189453
Decodertime : 0.0001838207244873047
g_f_logprobs : 0.007066965103149414
Decodertime : 0.00016689300537109375
g_f_logprobs : 0.006448984146118164
Decodertime : 0.0001552104949951172
g_f_logprobs : 0.006119966506958008
Decodertime : 0.00014853477478027344
g_f_logprobs : 0.00580143928527832
Decodertime : 0.00014209747314453125
g_f_logprobs : 0.005532741546630859
Decodertime : 0.00015115737915039062
g_f_logprobs : 0.005467653274536133
Decodertime : 0.00014019012451171875
g_f_logprobs : 0.005465984344482422
Decodertime : 0.0001399517059326172
g_f_logprobs : 0.005414247512817383
Decodertime : 0.00014019012451171875
g_f_logprobs : 0.005405902862548828
beam_search_time: 0.08792901039123535 s
Decodertime : 0.00013518333435058594
g_f_logprobs : 0.00957489013671875
Decodertime : 0.00013828277587890625
g_f_logprobs : 0.0095367431640625
Decodertime : 0.00014662742614746094
g_f_logprobs : 0.009541749954223633
Decodertime : 0.00013899803161621094
g_f_logprobs : 0.009567022323608398
Decodertime : 0.00014019012451171875
g_f_logprobs : 0.009528875350952148
Decodertime : 0.00014019012451171875
g_f_logprobs : 0.009551286697387695
Decodertime : 0.00013971328735351562
g_f_logprobs : 0.009539127349853516
Decodertime : 0.00016236305236816406
g_f_logprobs : 0.009544134140014648
Decodertime : 0.0001392364501953125
g_f_logprobs : 0.009570837020874023
Decodertime : 0.0001404285430908203
g_f_logprobs : 0.009553670883178711
Decodertime : 0.0001399517059326172
g_f_logprobs : 0.009557962417602539
beam_search_time: 0.12153863906860352 s
Decodertime : 0.00013518333435058594
g_f_logprobs : 0.013696432113647461
Decodertime : 0.0001380443572998047
g_f_logprobs : 0.013664722442626953
beam_search_time: 0.03029012680053711 s
input 640:  {"source": "`` We were oversold and today we bounced back .\n"}
prediction:  {"predictions": [[1, 1284, 2, 3, 1127, 17074, 11015, 4, 5, 6, 102, 102, 1, 1195, 2, 3, 13990, 4, 5, 1171, 2052, 6, 102, 102, 10, 102, 102]], "predicted_log_probs": [-0.10465595871210098, -0.01415333990007639, -0.0002765655517578125], "metadata": {"source_tokens": ["`", "##`", "We", "were", "overs", "##old", "and", "today", "we", "bounced", "back", "."], "example_ids": "None", "validation": false, "gradients": false, "confidences": "None"}, "predicted_tokens": [["[unused1]", "We", "[unused2]", "[unused3]", "were", "overs", "##old", "[unused4]", "[unused5]", "[unused6]", "[SEP]", "[unused1]", "we", "[unused2]", "[unused3]", "bounced", "[unused4]", "[unused5]", "back", "today", "[unused6]", "[SEP]"]]}

Batch 6 Test Time =  0.2831594944000244  s
Ending prediction
Total Time =  371.66943073272705  s
============== PROCESSING OUTPUTS ==============
{'<arg1>': '[unused1]', '</arg1>': '[unused2]', '<rel>': '[unused3]', '</rel>': '[unused4]', '<arg2>': '[unused5]', '</arg2>': '[unused6]', 'SENT': '[unused7]', 'PRED': '[unused8]', '@COPY@': '[unused9]', 'EOE': '[unused10]'}
models/imojie_bs8_cd0/test/carb_1/output_7.jsonl
models/imojie_bs8_cd0/test/carb_1/output_2.jsonl
models/imojie_bs8_cd0/test/carb_1/output_4.jsonl
============== EVALUATING OVER CARB ==============
/u/hbeyer/anaconda3/envs/imojie/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.
  warnings.warn(message, FutureWarning)
INFO:root:Writing PR curve of Allennlp to models/imojie_bs8_cd0/test/carb_1/pro_output_2.txt.dat
AUC: 0.337	 Optimal (precision, recall, F1): (0.619, 0.465, 0.531)	Zero Conf (precision, recall, F1): (0.61, 0.466, 0.528)
/u/hbeyer/anaconda3/envs/imojie/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.
  warnings.warn(message, FutureWarning)
INFO:root:Writing PR curve of Allennlp to models/imojie_bs8_cd0/test/carb_1/pro_output_4.txt.dat
AUC: 0.115	 Optimal (precision, recall, F1): (0.581, 0.174, 0.268)	Zero Conf (precision, recall, F1): (0.581, 0.174, 0.268)
/u/hbeyer/anaconda3/envs/imojie/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.
  warnings.warn(message, FutureWarning)
INFO:root:Writing PR curve of Allennlp to models/imojie_bs8_cd0/test/carb_1/pro_output_7.txt.dat
AUC: 0.323	 Optimal (precision, recall, F1): (0.672, 0.439, 0.531)	Zero Conf (precision, recall, F1): (0.669, 0.44, 0.531)
============== COMPILING RESULTS ==============
Best Sum Scores =  (61.90/46.50/53.10, 33.70, 61.00/46.60/52.80)
total time: 2021-12-31 18:52:50.483527 - 2021-12-31 18:43:37.459292 = 0:09:13.024222
(traintime: 0:00:00.000004; testtime: 0:09:13.024218)
[?2004h(imojie) [01;32mhbeyer@mlserv1[00m:[01;34m~/imojie-master[00m$ 